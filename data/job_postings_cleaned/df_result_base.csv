job_id,job_title,job_description,job_posted_at_datetime_utc,extraction_date,job_highlights.Qualifications,job_highlights.Responsibilities,is_valid_job,ai_mentions,ai_details,data_mentions,data_details
nFB7ISC3OFcsdxK7AAAAAA==,"Senior Manager, Data Science - US Card (Resiliency Intelligence)","Senior Manager, Data Science - US Card (Resiliency Intelligence)

Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making.

As a Data Scientist at Capital One, you’ll be part of a team that’s leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives.

Team Description

The Resiliency Intelligence team helps our customers regain financial stability and drive business value through personalized solutions at scale. This is crucially important for customers that encounter financial hardship and need personalized resources to resolve outstanding balances.

To achieve this, we use supervised and reinforcement learning models to predict customer needs and recommend optimal solutions. We write custom Python libraries and use open-source ML libraries like XGBoost, scikit-learn, and statsmodels. Our models define the treatment for millions of customers on a daily basis and your code will run in analytical and production environments.

Our team’s ML solutions meaningfully impact the income of the US Card business and are a key value generator for the company.

Role Description

In this role, you will:
• Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love
• Leverage a broad stack of technologies — Python, Kubernetes, AWS, H2O, Spark, and more — to reveal the insights hidden within huge volumes of numeric and textual data
• Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation
• Flex your interpersonal skills to translate the complexity of your work into tangible business goals

The Ideal Candidate is:
• Customer first. You love the process of analyzing and creating, but also share our passion to do the right thing. You know at the end of the day it’s about making the right decision for our customers.
• Creative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You’re not afraid to share a new idea.
• A leader. You challenge conventional thinking and work with stakeholders to identify and improve the status quo. You’re passionate about talent development for your own team and beyond.
• Technical. You’re comfortable with open-source languages and are passionate about developing further. You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms.

Basic Qualifications:
• Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:
• A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 7 years of experience performing data analytics
• A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 5 years of experience performing data analytics
• A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 2 years of experience performing data analytics
• At least 2 years of experience leveraging open source programming languages for large scale data analysis
• At least 2 years of experience working with machine learning
• At least 2 years of experience utilizing relational databases

Preferred Qualifications:
• PhD in “STEM” field (Science, Technology, Engineering, or Mathematics) plus 4 years of experience in data analytics
• At least 1 year of experience working with AWS
• At least 1 year of experience managing people
• At least 5 years’ experience in Python, Scala, or R for large scale data analysis
• At least 5 years’ experience with machine learning

Capital One will consider sponsoring a new qualified applicant for employment authorization for this position.

The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.

Cambridge, MA: $225,400 - $257,200 for Sr Mgr, Data Science

Chicago, IL: $204,900 - $233,800 for Sr Mgr, Data Science

McLean, VA: $225,400 - $257,200 for Sr Mgr, Data Science

New York, NY: $245,900 - $280,600 for Sr Mgr, Data Science

Richmond, VA: $204,900 - $233,800 for Sr Mgr, Data Science

Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate’s offer letter.

This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.

Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.

This role is expected to accept applications for a minimum of 5 business days.

No agencies please. Capital One is an equal opportunity employer (EOE, including disability/vet) committed to non-discrimination in compliance with applicable federal, state, and local laws. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",2025-07-23T00:00:00.000Z,2025-07-25,"['Customer first', 'You thrive on bringing definition to big, undefined problems', 'You love asking questions and pushing hard to find answers', 'You’re passionate about talent development for your own team and beyond', 'Technical', 'You’re comfortable with open-source languages and are passionate about developing further', 'You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms', 'Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:', ""A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 7 years of experience performing data analytics"", ""A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 5 years of experience performing data analytics"", 'A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 2 years of experience performing data analytics', 'At least 2 years of experience leveraging open source programming languages for large scale data analysis', 'At least 2 years of experience working with machine learning', 'At least 2 years of experience utilizing relational databases']","['This is crucially important for customers that encounter financial hardship and need personalized resources to resolve outstanding balances', 'To achieve this, we use supervised and reinforcement learning models to predict customer needs and recommend optimal solutions', 'We write custom Python libraries and use open-source ML libraries like XGBoost, scikit-learn, and statsmodels', 'Our models define the treatment for millions of customers on a daily basis and your code will run in analytical and production environments', 'Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love', 'Leverage a broad stack of technologies — Python, Kubernetes, AWS, H2O, Spark, and more — to reveal the insights hidden within huge volumes of numeric and textual data', 'Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation', 'Flex your interpersonal skills to translate the complexity of your work into tangible business goals', 'You challenge conventional thinking and work with stakeholders to identify and improve the status quo']",True,[],,"['Supervised Learning', 'Reinforcement Learning', 'Python', 'XGBoost', 'scikit-learn', 'statsmodels', 'Relational Databases', 'Machine Learning Model Lifecycle', 'AWS', 'Kubernetes', 'H2O', 'Spark']","Supervised Learning: Used to build predictive models that forecast customer needs and recommend optimal financial solutions.; Reinforcement Learning: Applied to develop models that optimize recommendations for customers facing financial hardship.; Python: Primary programming language used to write custom libraries and develop data science solutions.; XGBoost: Open-source machine learning library utilized for building predictive models in production and analytical environments.; scikit-learn: Open-source ML library used for developing machine learning models as part of the data science workflow.; statsmodels: Library used for statistical modeling and analysis within the data science team.; Relational Databases: Used for managing and querying large volumes of structured data to support analytics and modeling.; Machine Learning Model Lifecycle: Involves all phases from design, training, evaluation, validation, to implementation of models.; AWS: Cloud computing platform leveraged to handle large-scale data processing and model deployment.; Kubernetes: Used to orchestrate containerized applications and support scalable deployment of data science solutions.; H2O: Technology used as part of the machine learning stack to build scalable models.; Spark: Big data processing framework employed to analyze large volumes of numeric and textual data."
XdrEhkRRuZAndmnAAAAAAA==,Sr. Data Scientist,"Job#: 2082495

Job Description:

REQUIRED QUALIFICATIONS
• Ability to read, write, speak and understand English
• Expert-level skills and experience with python, SQL, ESRI, Alteryx, Tableau, and/or other data visualization tools
• Advanced-level skills with one or more scripting, analysis, or ETL languages and ability to rapidly learn new languages or techniques
• Familiarity with modern machine learning technology and tools in order to produce model scoring code.
• Expert-level logical and analytic skills
• Broad experience and solid theoretical foundation of the properties of the major families of machine learning models (regression, decision trees, clustering, SVMs, neural networks).
• Command of advanced mathematical concepts including calculus, PDEs, probability, and statistics, and the ability to independently learn any necessary additional concepts
• Strong synthesis and presentation skills
• Ability to communicate results and recommendations to a wide variety of audiences
• Basic understanding of data architecture, data warehouse and data marts
• Demonstrated ability and desire to continually expand skill set, and learn from and teach others
• Extensive experience with large data sets and the tools to obtain, transform, and store data on Big Data and streaming services

Education
• Bachelors degree in computer science, statistics, operations research and/or equivalent combination of education and experience.

Related Work Experience Number of Years
• Data manipulation and statistical modeling as a Scientist, Consultant,
• Architect, DBA, or Engineer - 5+
• SQL/R/SAS Programming - 5+

PREFERRED QUALIFICATIONS
• Experience in the telecommunications industry, or two other consumer-based industries
• Experience applying various data analysis techniques across various languages, databases, and data sources.
• Operations-research background, in particular focused on large labor operations such as field ops, technical support, and sales
• Background with Cable systems and operations
• Experience with Hadoop, particularly HIVE and Spark
• Knowledge of other relevant tools such as SAS, SPSS, Alteryx, Linux
• Alteryx Certification is very desirable.
• Knowledge of other relevant techniques such as text analysis and text mining
• Familiarity with the open-source ecosystems surrounding R (CRAN), Python (PyPi), and/or Hadoop

EEO Employer

Apex Systems is an equal opportunity employer. We do not discriminate or allow discrimination on the basis of race, color, religion, creed, sex (including pregnancy, childbirth, breastfeeding, or related medical conditions), age, sexual orientation, gender identity, national origin, ancestry, citizenship, genetic information, registered domestic partner status, marital status, disability, status as a crime victim, protected veteran status, political affiliation, union membership, or any other characteristic protected by law. Apex will consider qualified applicants with criminal histories in a manner consistent with the requirements of applicable law. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation in using our website for a search or application, please contact our Employee Services Department at or .

Apex Systems is a world-class IT services company that serves thousands of clients across the globe. When you join Apex, you become part of a team that values innovation, collaboration, and continuous learning. We offer quality career resources, training, certifications, development opportunities, and a comprehensive benefits package. Our commitment to excellence is reflected in many awards, including ClearlyRated's Best of Staffing in Talent Satisfaction in the United States and Great Place to Work in the United Kingdom and Mexico.

Apex Benefits Overview: Apex offers a range of supplemental benefits, including medical, dental, vision, life, disability, and other insurance plans that offer an optional layer of financial protection. We offer an ESPP (employee stock purchase program) and a 401K program which allows you to contribute typically within 30 days of starting, with a company match after 12 months of tenure. Apex also offers a HSA (Health Savings Account on the HDHP plan), a SupportLinc Employee Assistance Program (EAP) with up to 8 free counseling sessions, a corporate discount savings program and other discounts. In terms of professional development, Apex hosts an on-demand training program, provides access to certification prep and a library of technical and leadership courses/books/seminars once you have 6+ months of tenure, and certification discounts and other perks to associations that include CompTIA and IIBA. Apex has a dedicated customer service team for our Consultants that can address questions around benefits and other resources, as well as a certified Career Coach. You can access a full list of our benefits, programs, support teams and resources within our 'Welcome Packet' as well, which an Apex team member can provide.",2025-07-22T00:00:00.000Z,2025-07-25,"['Ability to read, write, speak and understand English', 'Expert-level skills and experience with python, SQL, ESRI, Alteryx, Tableau, and/or other data visualization tools', 'Advanced-level skills with one or more scripting, analysis, or ETL languages and ability to rapidly learn new languages or techniques', 'Familiarity with modern machine learning technology and tools in order to produce model scoring code', 'Expert-level logical and analytic skills', 'Broad experience and solid theoretical foundation of the properties of the major families of machine learning models (regression, decision trees, clustering, SVMs, neural networks)', 'Command of advanced mathematical concepts including calculus, PDEs, probability, and statistics, and the ability to independently learn any necessary additional concepts', 'Strong synthesis and presentation skills', 'Ability to communicate results and recommendations to a wide variety of audiences', 'Basic understanding of data architecture, data warehouse and data marts', 'Demonstrated ability and desire to continually expand skill set, and learn from and teach others', 'Extensive experience with large data sets and the tools to obtain, transform, and store data on Big Data and streaming services', 'Bachelors degree in computer science, statistics, operations research and/or equivalent combination of education and experience', 'Related Work Experience Number of Years', 'Data manipulation and statistical modeling as a Scientist, Consultant,', 'Architect, DBA, or Engineer - 5+', 'SQL/R/SAS Programming - 5+']",,True,[],,"['Python', 'SQL', 'ESRI', 'Alteryx', 'Tableau', 'Scripting and ETL languages', 'Machine learning models', 'Mathematical concepts', 'Data architecture and warehousing', 'Big Data and streaming services', 'Hadoop ecosystem', 'R programming', 'SAS and SPSS', 'Text analysis and text mining']","Python: Used as a primary programming language for data manipulation, analysis, and scripting in the role.; SQL: Utilized for querying and managing data within databases, essential for data extraction and manipulation.; ESRI: Applied as a geographic information system tool for spatial data analysis and visualization.; Alteryx: Used for data preparation, blending, and advanced analytics workflows, including ETL processes.; Tableau: Employed for creating data visualizations and dashboards to communicate insights effectively.; Scripting and ETL languages: Advanced skills required to write scripts and develop ETL pipelines for data processing and transformation.; Machine learning models: Experience with major families of models such as regression, decision trees, clustering, SVMs, and neural networks for predictive analytics and model scoring.; Mathematical concepts: Command of advanced mathematics including calculus, partial differential equations, probability, and statistics to support modeling and analysis.; Data architecture and warehousing: Basic understanding of data architecture, data warehouses, and data marts to support data storage and retrieval.; Big Data and streaming services: Experience working with large datasets and tools to obtain, transform, and store data in big data and streaming environments.; Hadoop ecosystem: Familiarity with Hadoop and related tools such as Hive and Spark for distributed data processing and analytics.; R programming: Experience with R and its open-source ecosystem (CRAN) for statistical analysis and data science tasks.; SAS and SPSS: Knowledge of statistical software packages used for data analysis and modeling.; Text analysis and text mining: Applied techniques for extracting insights from unstructured text data."
vikyPvnmOOVrMK3UAAAAAA==,Senior Data Scientist,"Job Number: R0221820

Data Scientist, Senior
The Opportunity:

As a data scientist, you're excited at the prospect of unlocking the secrets held by a data set, and you're fascinated by the possibilities presented by IoT, machine learning, and artificial intelligence. In an increasingly connected world, massive amounts of structured and unstructured data open new opportunities. As a data scientist at Booz Allen, you can help turn these complex data sets into useful information to solve global challenges. Across private and public sectors-from fraud detection to cancer research to national intelligence-we need you to help find the answers in the data.

On our team, you'll use your leadership skills and data science expertise to create real-world impact. You'll work closely with clients to understand their questions and needs, and then dig into their data-rich environments to find the pieces of their information puzzle. You'll guide teammates and lead the development of algorithms and systems. You'll use the right combination of tools and frameworks to turn sets of disparate data points into objective answers to advise your clients as they make informed decisions. Ultimately, you'll provide a deep understanding of the data, what it all means, and how it can be used.

Work with us as we use data science for good.

Join us. The world can't wait.

You Have:
• 5+ years of experience developing and deploying AI/ML models in enterprise or government environments
• Experience fine-tuning and applying Large Language Models (LLMs), such as GPT, LLaMA, or Claude for NLP and generative tasks
• Experience programming in Python and with ML frameworks, such as PyTorch, TensorFlow, or Scikit-learn
• Experience with data analytics, feature engineering, and building end-to-end ML pipelines
• Experience integrating AI/ML models into secure or cloud-hosted environments, such as AWS or Azure
• Knowledge of vector databases and retrieval-augmented generation (RAG) pipelines
• Knowledge of RMF, STIGs, and DoD cybersecurity compliance practices
• Secret clearance
• Bachelor's degree
• CompTIA Security+ CE certification

Nice If You Have:
• 5+ years of experience in Cloud deployments
• 5+ years of experience in solutions architecture
• Experience working in an Agile environment
• Possession of excellent collaboration and oral and written communication skills, including documentation
• Master's degree

Clearance:

Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required.

Compensation

At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen's benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.

Salary at Booz Allen is determined by various factors, including but not limited to location, the individual's particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $99,000.00 to $225,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen's total compensation package for employees. This posting will close within 90 days from the Posting Date.

Identity Statement

As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud.

Work Model
Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.
• If this position is listed as remote or hybrid, you'll periodically work from a Booz Allen or client site facility.
• If this position is listed as onsite, you'll work with colleagues and clients in person, as needed for the specific role.

Commitment to Non-Discrimination

All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law.",2025-07-21T00:00:00.000Z,2025-07-25,"['5+ years of experience developing and deploying AI/ML models in enterprise or government environments', 'Experience fine-tuning and applying Large Language Models (LLMs), such as GPT, LLaMA, or Claude for NLP and generative tasks', 'Experience programming in Python and with ML frameworks, such as PyTorch, TensorFlow, or Scikit-learn', 'Experience with data analytics, feature engineering, and building end-to-end ML pipelines', 'Experience integrating AI/ML models into secure or cloud-hosted environments, such as AWS or Azure', 'Knowledge of vector databases and retrieval-augmented generation (RAG) pipelines', 'Knowledge of RMF, STIGs, and DoD cybersecurity compliance practices', 'Secret clearance', ""Bachelor's degree"", 'CompTIA Security+ CE certification', '5+ years of experience in Cloud deployments', '5+ years of experience in solutions architecture', 'Experience working in an Agile environment', 'Possession of excellent collaboration and oral and written communication skills, including documentation', ""Master's degree"", 'Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required']","[""On our team, you'll use your leadership skills and data science expertise to create real-world impact"", ""You'll work closely with clients to understand their questions and needs, and then dig into their data-rich environments to find the pieces of their information puzzle"", ""You'll guide teammates and lead the development of algorithms and systems"", ""You'll use the right combination of tools and frameworks to turn sets of disparate data points into objective answers to advise your clients as they make informed decisions"", ""Ultimately, you'll provide a deep understanding of the data, what it all means, and how it can be used"", ""If this position is listed as remote or hybrid, you'll periodically work from a Booz Allen or client site facility"", ""If this position is listed as onsite, you'll work with colleagues and clients in person, as needed for the specific role""]",True,"['Large Language Models', 'Deep Learning Frameworks', 'Retrieval-Augmented Generation']","Large Language Models: Fine-tuning and applying large language models (LLMs) such as GPT, LLaMA, or Claude for natural language processing and generative AI tasks.; Deep Learning Frameworks: Using deep learning frameworks like PyTorch and TensorFlow specifically for neural network model development and fine-tuning of AI models.; Retrieval-Augmented Generation: Utilizing retrieval-augmented generation (RAG) pipelines and vector databases to enhance generative AI capabilities by combining retrieval of relevant information with language model generation.","['Machine Learning', 'Feature Engineering', 'Data Analytics', 'ML Frameworks', 'Python Programming', 'ML Pipelines', 'Cloud Integration']","Machine Learning: Developing and deploying machine learning models in enterprise or government environments to extract insights and solve complex problems from structured and unstructured data.; Feature Engineering: Applying feature engineering techniques to prepare and transform data for building effective machine learning models and end-to-end ML pipelines.; Data Analytics: Performing data analytics to understand data-rich environments and extract meaningful information to support client decision-making.; ML Frameworks: Using machine learning frameworks such as Scikit-learn for traditional ML model development and deployment.; Python Programming: Programming in Python to develop, fine-tune, and deploy machine learning and data analytics solutions.; ML Pipelines: Building end-to-end machine learning pipelines to automate data processing, model training, and deployment workflows.; Cloud Integration: Integrating AI and machine learning models into secure or cloud-hosted environments such as AWS or Azure to support scalable and compliant deployments."
KOEcsjTne8KUqX0sAAAAAA==,Senior Data Scientist (U.S. Citizen/Security Clearance Required) Jobs,"Task Force Talent is seeking a senior Data Scientist with an active TS/SCI FSP security clearance to support a unique government contract. Our client for this role is a small company with both commercial and government sector customers. They work on very interesting, usually highly technical roles in cybersecurity, software development, data science, and related areas for well-known companies and government organizations. They have a high bar; however, they also have top compensation, benefits, and a strong company culture not found at larger firms. This is rewarding work that cannot be done elsewhere.

The primary responsibility of this role is developing technical capabilities that can produce insights from large, complex data sets. Further details will be provided to qualified candidates after an initial interview.

Target salary range is $180k - $205k, depending on experience level.

All positions are full-time, in-office, usually in a SCIF.

If you apply but this company is not a fit, we will consider you for other available positions as well. We have several clients seeking very similar skill sets.

Not your dream job, but perfect for a friend? You can submit a referral and get a check for $2000 or more: https://www.taskforcetalent.com/referral/
(Terms and conditions apply.)

_______________________________________________________________________________________________________________________________________________

Qualifications
• U.S. citizen with active TS/SCI FSP security clearance. (Sorry, we are unable to sponsor or upgrade clearances for this role.)
• 10+ years of relevant experience, including
• data modeling and visualization
• developing, managing, and exploiting various types of databases
• ETL
• assessing data quality and integrity
• building/maintaining CI/CD pipelines
• Experience with:
• Python, SQL, and NiFI
• AWS or Azure cloud
• Git/GitHub

____________________________________________________________________________________________________________________________________

Interview Process

The process typically involves an initial phone screen followed by technical interviews. Contigent offers are usually made quickly, within a week or two. Depending on the level of experience and terms of the contract, additional interviews may be required with a prime contractor/partners or the end customer.

_____________________________________________________________________________________________________________________________________

About us:

Task Force Talent is a specialized recruiting firm for science, engineering, and security careers. Our clients include seed to Series B startups working on AI, cybersecurity, quantum computing, and other novel technologies. We also work with small to medium size government contractors, and we help leading venture capital firms find talent for their portfolio companies. We have hundreds of jobs available and consider all applicants for all roles, now and in the future. Our goal is to find the best fit for you!

If you don't see the perfect fit, simply use our general application at: https://taskforcetalent.breezy.hr/p/5bbc3c44433e-single-application-for-all-jobs-general",2025-07-22T00:00:00.000Z,2025-07-25,"['U.S. citizen with active TS/SCI FSP security clearance', '10+ years of relevant experience, including', 'data modeling and visualization', 'ETL', 'Python, SQL, and NiFI', 'AWS or Azure cloud', 'Depending on the level of experience and terms of the contract, additional interviews may be required with a prime contractor/partners or the end customer']","['The primary responsibility of this role is developing technical capabilities that can produce insights from large, complex data sets', 'developing, managing, and exploiting various types of databases', 'assessing data quality and integrity', 'building/maintaining CI/CD pipelines']",True,[],,"['Data Modeling and Visualization', 'ETL (Extract, Transform, Load)', 'Python', 'SQL', 'NiFi', 'AWS or Azure Cloud', 'CI/CD Pipelines', 'Data Quality and Integrity Assessment', 'Git/GitHub']","Data Modeling and Visualization: This role involves creating models and visual representations to extract insights from large, complex data sets.; ETL (Extract, Transform, Load): The job requires experience in ETL processes to manage and prepare data for analysis.; Python: Python is used as a primary programming language for data manipulation and analysis tasks.; SQL: SQL is utilized for managing and querying various types of databases.; NiFi: NiFi is employed for data flow automation and management within data pipelines.; AWS or Azure Cloud: Experience with cloud platforms like AWS or Azure is necessary for deploying and managing data solutions.; CI/CD Pipelines: Building and maintaining continuous integration and continuous deployment pipelines is part of the role to support data workflows and software development.; Data Quality and Integrity Assessment: The role includes assessing and ensuring the quality and integrity of data used for analysis.; Git/GitHub: Version control tools like Git and GitHub are used for managing code and collaboration."
0vkoqsWaaHsrLgRiAAAAAA==,"Senior Manager, Data Science - US Card (Resiliency Intelligence)","Senior Manager, Data Science - US Card (Resiliency Intelligence)

Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making.

As a Data Scientist at Capital One, you'll be part of a team that's leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives.

Team Description

The Resiliency Intelligence team helps our customers regain financial stability and drive business value through personalized solutions at scale. This is crucially important for customers that encounter financial hardship and need personalized resources to resolve outstanding balances.

To achieve this, we use supervised and reinforcement learning models to predict customer needs and recommend optimal solutions. We write custom Python libraries and use open-source ML libraries like XGBoost, scikit-learn, and statsmodels. Our models define the treatment for millions of customers on a daily basis and your code will run in analytical and production environments.

Our team's ML solutions meaningfully impact the income of the US Card business and are a key value generator for the company.

Role Description

In this role, you will:
• Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love
• Leverage a broad stack of technologies - Python, Kubernetes, AWS, H2O, Spark, and more - to reveal the insights hidden within huge volumes of numeric and textual data
• Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation
• Flex your interpersonal skills to translate the complexity of your work into tangible business goals

The Ideal Candidate is:
• Customer first. You love the process of analyzing and creating, but also share our passion to do the right thing. You know at the end of the day it's about making the right decision for our customers.
• Creative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You're not afraid to share a new idea.
• A leader. You challenge conventional thinking and work with stakeholders to identify and improve the status quo. You're passionate about talent development for your own team and beyond.
• Technical. You're comfortable with open-source languages and are passionate about developing further. You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms.

Basic Qualifications:
• Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:
• A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 7 years of experience performing data analytics
• A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 5 years of experience performing data analytics
• A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 2 years of experience performing data analytics
• At least 2 years of experience leveraging open source programming languages for large scale data analysis
• At least 2 years of experience working with machine learning
• At least 2 years of experience utilizing relational databases

Preferred Qualifications:
• PhD in ""STEM"" field (Science, Technology, Engineering, or Mathematics) plus 4 years of experience in data analytics
• At least 1 year of experience working with AWS
• At least 1 year of experience managing people
• At least 5 years' experience in Python, Scala, or R for large scale data analysis
• At least 5 years' experience with machine learning

Capital One will consider sponsoring a new qualified applicant for employment authorization for this position.

The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.

Cambridge, MA: $225,400 - $257,200 for Sr Mgr, Data Science

Chicago, IL: $204,900 - $233,800 for Sr Mgr, Data Science

McLean, VA: $225,400 - $257,200 for Sr Mgr, Data Science

New York, NY: $245,900 - $280,600 for Sr Mgr, Data Science

Richmond, VA: $204,900 - $233,800 for Sr Mgr, Data Science

Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate's offer letter.

This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.

Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at theCapital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.

This role is expected to accept applications for a minimum of 5 business days.

No agencies please. Capital One is an equal opportunity employer (EOE, including disability/vet) committed to non-discrimination in compliance with applicable federal, state, and local laws. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City's Fair Chance Act; Philadelphia's Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",2025-07-24T00:00:00.000Z,2025-07-25,"['Customer first', 'You thrive on bringing definition to big, undefined problems', 'You love asking questions and pushing hard to find answers', ""You're passionate about talent development for your own team and beyond"", 'Technical', ""You're comfortable with open-source languages and are passionate about developing further"", 'You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms', 'Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:', ""A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 7 years of experience performing data analytics"", ""A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 5 years of experience performing data analytics"", 'A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 2 years of experience performing data analytics', 'At least 2 years of experience leveraging open source programming languages for large scale data analysis', 'At least 2 years of experience working with machine learning', 'At least 2 years of experience utilizing relational databases']","['This is crucially important for customers that encounter financial hardship and need personalized resources to resolve outstanding balances', 'To achieve this, we use supervised and reinforcement learning models to predict customer needs and recommend optimal solutions', 'We write custom Python libraries and use open-source ML libraries like XGBoost, scikit-learn, and statsmodels', 'Our models define the treatment for millions of customers on a daily basis and your code will run in analytical and production environments', 'Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love', 'Leverage a broad stack of technologies - Python, Kubernetes, AWS, H2O, Spark, and more - to reveal the insights hidden within huge volumes of numeric and textual data', 'Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation', 'Flex your interpersonal skills to translate the complexity of your work into tangible business goals', 'You challenge conventional thinking and work with stakeholders to identify and improve the status quo']",True,[],,"['Supervised Learning', 'Reinforcement Learning', 'Python', 'XGBoost', 'Scikit-learn', 'Statsmodels', 'Relational Databases', 'Machine Learning', 'Python Libraries', 'Kubernetes', 'AWS', 'H2O', 'Spark']","Supervised Learning: Used to build models that predict customer needs and recommend optimal solutions in the financial domain.; Reinforcement Learning: Applied to develop models that help predict customer needs and recommend personalized financial solutions.; Python: Used for writing custom libraries and developing data science solutions within both analytical and production environments.; XGBoost: An open-source machine learning library utilized for building predictive models impacting millions of customers daily.; Scikit-learn: An open-source machine learning library used to develop and implement models for customer treatment and financial decision-making.; Statsmodels: Used as part of the open-source ML libraries to support statistical modeling in data science solutions.; Relational Databases: Utilized for managing and querying large-scale structured data essential for analytics and model development.; Machine Learning: Employed throughout all phases of model development including design, training, evaluation, validation, and implementation to drive business value.; Python Libraries: Custom libraries developed to support machine learning and data analysis workflows in production and analytical settings.; Kubernetes: Part of the technology stack leveraged to manage scalable computing environments for data science workloads.; AWS: Cloud computing platform used to support large-scale data analysis and machine learning model deployment.; H2O: Technology used within the data science stack to build and deploy machine learning models at scale.; Spark: Utilized to process and analyze huge volumes of numeric and textual data efficiently."
g2BI_dwhDGqBZXgcAAAAAA==,"Senior Associate, Data Scientist","Senior Associate, Data Scientist

Senior Associate, Data Scientist - US Card Bureau Data Strategy Team

Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making.

As a Data Scientist at Capital One, you’ll be part of a team that’s leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives.

Team Description

Credit bureau data is at the heart of underwriting decisions at US Card. The Bureau Data Strategy team produces one of the most highly-used datasets in all of Capital One from raw credit bureau data. The team is responsible for generating insights, extracting value from Bureau Data and shaping the future of how credit bureau data is used in underwriting at Capital One. The team also owns the monitoring solution to promptly alert users to potential production errors with these features.

Role Description

In this role, you will:
• Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love
• Leverage a broad stack of technologies — Python, Conda, AWS, H2O, Spark, and more — to reveal the insights hidden within huge volumes of numeric and textual data
• Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation
• Flex your interpersonal skills to translate the complexity of your work into tangible business goals

The Ideal Candidate is:
• Innovative. You continually research and evaluate emerging technologies. You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them.
• Creative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You’re not afraid to share a new idea.
• Technical. You’re comfortable with open-source languages and are passionate about developing further. You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms.
• Statistically-minded. You’ve built models, validated them, and backtested them. You know how to interpret a confusion matrix or a ROC curve. You have experience with clustering, classification, sentiment analysis, time series, and deep learning.
• A data guru. “Big data” doesn’t faze you. You have the skills to retrieve, combine, and analyze data from a variety of sources and structures. You know understanding the data is often the key to great data science.

Basic Qualifications:
• Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:
• A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 2 years of experience performing data analytics
• A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration

Preferred Qualifications:
• Master’s Degree in “STEM” field (Science, Technology, Engineering, or Mathematics), or PhD in “STEM” field (Science, Technology, Engineering, or Mathematics)
• Experience working with PySpark
• At least 2 years’ experience in Python, Scala, or R
• At least 2 years’ experience with machine learning
• At least 2 years’ experience with SQL

Capital One will consider sponsoring a new qualified applicant for employment authorization for this position.

The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.

McLean, VA: $133,000 - $151,800 for Sr Assoc, Data Science

New York, NY: $145,100 - $165,600 for Sr Assoc, Data Science

Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate’s offer letter.

This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.

Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.

This role is expected to accept applications for a minimum of 5 business days.

No agencies please. Capital One is an equal opportunity employer (EOE, including disability/vet) committed to non-discrimination in compliance with applicable federal, state, and local laws. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",2025-07-16T00:00:00.000Z,2025-07-25,"['You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them', 'You thrive on bringing definition to big, undefined problems', 'You love asking questions and pushing hard to find answers', 'You’re comfortable with open-source languages and are passionate about developing further', 'You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms', 'Statistically-minded', 'You know how to interpret a confusion matrix or a ROC curve', 'You have experience with clustering, classification, sentiment analysis, time series, and deep learning', 'A data guru', 'You have the skills to retrieve, combine, and analyze data from a variety of sources and structures', 'You know understanding the data is often the key to great data science', 'Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:', ""A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 2 years of experience performing data analytics"", ""A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration""]","['The team is responsible for generating insights, extracting value from Bureau Data and shaping the future of how credit bureau data is used in underwriting at Capital One', 'The team also owns the monitoring solution to promptly alert users to potential production errors with these features', 'Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love', 'Leverage a broad stack of technologies — Python, Conda, AWS, H2O, Spark, and more — to reveal the insights hidden within huge volumes of numeric and textual data', 'Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation', 'Flex your interpersonal skills to translate the complexity of your work into tangible business goals', 'You continually research and evaluate emerging technologies', 'You’ve built models, validated them, and backtested them']",True,[],,"['Statistical Modeling', 'Machine Learning', 'Clustering', 'Classification', 'Sentiment Analysis', 'Time Series Analysis', 'Deep Learning', 'Data Retrieval and Integration', 'Data Monitoring and Alerting', 'Python', 'Conda', 'AWS', 'H2O', 'Spark', 'PySpark', 'SQL', 'Model Validation and Backtesting', 'Confusion Matrix and ROC Curve Interpretation']","Statistical Modeling: Used to personalize credit card offers and generate insights from credit bureau data to support underwriting decisions.; Machine Learning: Building models through all phases including design, training, evaluation, validation, and implementation to extract value from large datasets.; Clustering: Applied as part of data science techniques to analyze and segment data for better insights.; Classification: Used to categorize data and support predictive modeling in underwriting and other business decisions.; Sentiment Analysis: Employed to analyze textual data as part of extracting insights from large volumes of numeric and textual data.; Time Series Analysis: Used to analyze data over time, supporting modeling and forecasting tasks relevant to the business.; Deep Learning: Experience with deep learning methods is valued for advanced modeling tasks within the data science team.; Data Retrieval and Integration: Skills to retrieve, combine, and analyze data from various sources and structures to enable effective data science solutions.; Data Monitoring and Alerting: Owning monitoring solutions to promptly alert users to potential production errors in data features.; Python: Used as a primary programming language for data science and machine learning model development.; Conda: Utilized as an environment and package management system to support data science workflows.; AWS: Cloud computing platform leveraged to handle large-scale data processing and model deployment.; H2O: Machine learning platform used to build and deploy models efficiently on large datasets.; Spark: Big data processing framework used to handle and analyze huge volumes of numeric and textual data.; PySpark: Python API for Spark used to process large-scale data and build machine learning models.; SQL: Used for querying and managing relational databases to support data analytics and model building.; Model Validation and Backtesting: Practices to ensure model accuracy and reliability by validating and backtesting predictive models.; Confusion Matrix and ROC Curve Interpretation: Techniques used to evaluate classification model performance and interpret results."
18oCPxMqXOGheocuAAAAAA==,"Data Scientist Assoc., Mid. and Sr. Jobs","Overview

Iron EagleX (IEX), a wholly owned subsidiary of General Dynamics Information Technology, delivers agile IT and Intelligence solutions. Combining small-team flexibility with global scale, IEX leverages emerging technologies to provide innovative, user-focused solutions that empower organizations and end users to operate smarter, faster, and more securely in dynamic environments.

Responsibilities

We are looking for Associate, Mid level and Senior Level Data Scientists to support a customer onsite in Arlington, Virginia.

These positions are contingent upon the award of a contract. Work is expected to begin in August 2025.

Job Description:
• Design, develop, and implement data models, algorithms, and machine learning pipelines to solve complex defense-related problems.
• Analyze large, structured and unstructured datasets from multiple sources, including sensor data, signals intelligence, satellite imagery, and operational reports.
• Collaborate with analysts, engineers, and military subject matter experts to define problems, collect requirements, and deliver insights in support of strategic and tactical decisions.
• Build dashboards, data visualizations, and interactive tools to communicate analytical findings to non-technical audiences and senior leadership.
• Conduct data quality assessments and recommend enhancements to existing data systems and processes.
• Participate in research and development of AI/ML capabilities applicable to defense and intelligence missions.

Qualifications

Required Skills & Experience:
• Experience applying data science techniques in a professional setting, preferably within the DoD or Intelligence Community.
• Proficiency in Python, R, or similar programming languages.
• Experience with SQL and NoSQL databases, and data processing frameworks (e.g., Spark, Hadoop).
• Familiarity with machine learning libraries (e.g., Scikit-learn, TensorFlow, PyTorch).
• Strong understanding of statistical modeling, predictive analytics, and data mining techniques.
• Experience supporting military or national security missions.
• Familiarity with DoD data platforms and cloud environments (e.g., AWS GovCloud, Azure Government).
• Due to U.S. Government contract requirements, only U.S. citizens are eligible for this role.

Education & Certifications:
• Bachelor's or Master's degree in Data Science, Computer Science, Statistics, Mathematics, Engineering, or related field.

Security Clearance:
• TS/SCI clearance is required

Benefits:
• National Health, vision, and dental plans
• 20 days of PTO and 11 paid holidays
• Life Insurance
• Short - and long-term disability plans
• 401(K) retirement plans
• Incentive and recognition programs
• Relocation opportunities

Equal Opportunity Employer / Individuals with Disabilities / Protected Veterans",2025-07-17T00:00:00.000Z,2025-07-25,"['Experience applying data science techniques in a professional setting, preferably within the DoD or Intelligence Community', 'Proficiency in Python, R, or similar programming languages', 'Experience with SQL and NoSQL databases, and data processing frameworks (e.g., Spark, Hadoop)', 'Familiarity with machine learning libraries (e.g., Scikit-learn, TensorFlow, PyTorch)', 'Strong understanding of statistical modeling, predictive analytics, and data mining techniques', 'Experience supporting military or national security missions', 'Familiarity with DoD data platforms and cloud environments (e.g., AWS GovCloud, Azure Government)', 'Due to U.S. Government contract requirements, only U.S. citizens are eligible for this role', ""Bachelor's or Master's degree in Data Science, Computer Science, Statistics, Mathematics, Engineering, or related field"", 'TS/SCI clearance is required']","['We are looking for Associate, Mid level and Senior Level Data Scientists to support a customer onsite in Arlington, Virginia', 'Design, develop, and implement data models, algorithms, and machine learning pipelines to solve complex defense-related problems', 'Analyze large, structured and unstructured datasets from multiple sources, including sensor data, signals intelligence, satellite imagery, and operational reports', 'Collaborate with analysts, engineers, and military subject matter experts to define problems, collect requirements, and deliver insights in support of strategic and tactical decisions', 'Build dashboards, data visualizations, and interactive tools to communicate analytical findings to non-technical audiences and senior leadership', 'Conduct data quality assessments and recommend enhancements to existing data systems and processes', 'Participate in research and development of AI/ML capabilities applicable to defense and intelligence missions']",True,"['Deep Learning Frameworks', 'Artificial Intelligence and Machine Learning Research']",Deep Learning Frameworks: Use of TensorFlow and PyTorch for developing AI/ML capabilities applicable to defense and intelligence missions.; Artificial Intelligence and Machine Learning Research: Participate in research and development of AI/ML capabilities to support defense and intelligence objectives.,"['Data Modeling', 'Machine Learning Pipelines', 'Data Analysis', 'Data Visualization and Dashboards', 'Data Quality Assessment', 'Statistical Modeling', 'Predictive Analytics', 'Data Mining', 'Programming Languages', 'Databases and Data Processing Frameworks', 'Machine Learning Libraries', 'Cloud Environments']","Data Modeling: Design, develop, and implement data models to solve complex defense-related problems.; Machine Learning Pipelines: Design, develop, and implement machine learning pipelines to address complex defense-related challenges.; Data Analysis: Analyze large, structured and unstructured datasets from multiple sources, including sensor data, signals intelligence, satellite imagery, and operational reports.; Data Visualization and Dashboards: Build dashboards, data visualizations, and interactive tools to communicate analytical findings to non-technical audiences and senior leadership.; Data Quality Assessment: Conduct data quality assessments and recommend enhancements to existing data systems and processes.; Statistical Modeling: Apply strong understanding of statistical modeling techniques in data science projects.; Predictive Analytics: Utilize predictive analytics methods to support defense and intelligence missions.; Data Mining: Employ data mining techniques to extract insights from complex datasets.; Programming Languages: Use Python, R, or similar programming languages for data science tasks.; Databases and Data Processing Frameworks: Work with SQL and NoSQL databases, and data processing frameworks such as Spark and Hadoop.; Machine Learning Libraries: Familiarity with machine learning libraries including Scikit-learn, TensorFlow, and PyTorch.; Cloud Environments: Experience with DoD data platforms and cloud environments like AWS GovCloud and Azure Government."
Gbav3WbCOvLIce_kAAAAAA==,Sr. Data Scientist,"Knowledge Management, Inc. (KMI) has the leadership and experience to deliver innovative technology, logistics and management solutions to meet real mission requirements. KMI is a Minority Business Enterprise (MBE) and Small Disadvantage Business (SDB) that specializes in Logistics, Warehouse Services, Distance Learning/Training, Enterprise Solutions, Financial Management Support, Program Management, Intelligence Analysis & Threat Assessment, and Data Analytics/Operations Research. Since 1998, our solutions and services have helped our clients improve performance, drive cost and operational effectives, and map technology needs for tomorrow's requirements.

Title: Sr. Data Scientist

Location: Pentagon (onsite)

Positions: 1

Duration: Multi-year contract

Start date: Around September 15

Security Clearance: Minimum of a DOD Secret clearance

Salary: Please provide your salary requirement

Education/Experience: Minimum of 8 years of experience with U.S. Marine Corps logistics systems (12 years without degree)

Job Description: Knowledge Management, Inc. is seeking an experienced Sr. Data Scientist who is intimately familiar with Marine Corps logistics systems and Operational Research & Statistical Analysis methods to support the U.S. Marine Corps customer. This position will focus on analyzing and interpreting complex logistics data, building effective data visualization tools, and developing logistics documentation, plans, and briefs to support attainment of the highest levels of equipment readiness in the most cost-effective manner.

Key Responsibilities:
• Analyze and interpret U.S. Marine Corps logistics data
• Develop metrics and data visualization tools
• Identify and recommend logistics strategies to optimize supply chain and logistics operations.
• Collaborating with cross-functional teams
• Support continuous improvement initiatives

Minimum Qualifications:
• Bachelor's degree in business, operations research, Data Analytics, Computer Science, or a similar field.
• Minimum of 8 years of experience with U.S. Marine Corps logistics systems (12 years without degree)
• Strong analytical and problem-solving skills, with a focus on logistics and supply chain management.
• Must hold an active DoD Secret security clearance.

Desired Qualifications:
• Ability to work independently and meet deadlines in a robust work environment.

Security Clearance:
• Active DoD Secret security clearance required.

Work Environment:
• Onsite in Pentagon working spaces

Availability

This position is anticipated to be available on or about 15 September 2025

Benefits: All full-time employees are eligible to participate in our benefits programs:
• Health, dental, and vision insurance
• 401(k) retirement plan
• Paid time off (PTO) and holidays
• Group Term Life and Accidental Death and Dismemberment Insurance
• Voluntary Term Life Insurance
• Short and Long-term disability insurance

Equal Employment Opportunity Statement. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

E-Verify Statement. Knowledge Management, Inc. participates in E-Verify and will provide the federal government with your Form I-9 information to confirm that you are authorized to work in the U.S. If E-Verify cannot confirm that you are authorized to work, KMI is required to give you written instructions and an opportunity to contact Department of Homeland Security (DHS) or Social Security Administration (SSA) so you can begin to resolve the issue before the employer can take any action against you, including terminating your employment. Employers can only use E-Verify once you have accepted a job offer and completed the Form I-9.

Pay Transparency Non-Discrimination Provision. Knowledge Management, Inc. will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor's legal duty to furnish information. 41 CFR 60-1.35(c)

Disability Statement. If you have a disability and need reasonable accommodation or assistance at any point in the application or onboarding process, please email us at .",2025-07-15T00:00:00.000Z,2025-07-25,"['Security Clearance: Minimum of a DOD Secret clearance', 'Education/Experience: Minimum of 8 years of experience with U.S. Marine Corps logistics systems (12 years without degree)', 'Job Description: Knowledge Management, Inc. is seeking an experienced Sr', 'Data Scientist who is intimately familiar with Marine Corps logistics systems and Operational Research & Statistical Analysis methods to support the U.S. Marine Corps customer', ""Bachelor's degree in business, operations research, Data Analytics, Computer Science, or a similar field"", 'Minimum of 8 years of experience with U.S. Marine Corps logistics systems (12 years without degree)', 'Strong analytical and problem-solving skills, with a focus on logistics and supply chain management', 'Must hold an active DoD Secret security clearance', 'Active DoD Secret security clearance required']","['This position will focus on analyzing and interpreting complex logistics data, building effective data visualization tools, and developing logistics documentation, plans, and briefs to support attainment of the highest levels of equipment readiness in the most cost-effective manner', 'Analyze and interpret U.S. Marine Corps logistics data', 'Develop metrics and data visualization tools', 'Identify and recommend logistics strategies to optimize supply chain and logistics operations', 'Collaborating with cross-functional teams', 'Support continuous improvement initiatives', 'Onsite in Pentagon working spaces']",True,[],,"['Operational Research & Statistical Analysis', 'Data Visualization Tools', 'Logistics Data Analysis']",Operational Research & Statistical Analysis: Used to analyze and interpret complex logistics data to support U.S. Marine Corps logistics systems and optimize supply chain and logistics operations.; Data Visualization Tools: Developed to create effective metrics and visual representations of logistics data to support equipment readiness and decision-making.; Logistics Data Analysis: Focuses on analyzing and interpreting complex logistics data to identify strategies for optimizing supply chain and logistics operations.
j0D1iMNi9cjZUJ6cAAAAAA==,Senior Data Scientist (OBI Advanced Analytic Method Augmentation Jobs,"Senior Data Scientist (OBI Advanced Analytic Method Augmentation) - OBIQUA

Location Virginia, Reston

Department BUSINESS DEVELOPMENT

Employment Duration Full Time

Celestar Corporation is seeking a Senior Data Scientist (OBI Advanced Analytic Method Augmentation) to support The Defense Intelligence Agency ( DIA) under the Object Based Intelligence and Quality Assurance (OBIQUA) task order. The primary place of performance will be at DIA Facilities across the National Capital Region (NCR). If interested and meet the qualifications, we encourage you to apply for this rewarding and impactful opportunity.

ANTICIPATED AWARD: December 2025/ January 2026
ANTICIPATED START: February/March 2026
PERIOD OF PERFORMANCE:1 Base Year + 3 Option Years
LOCATION: DIA Facilities across the National Capital Region (NCR)

CLEARANCE REQUIREMENT: Active TS/SCI with a Current CI Poly

About Us:

Celestar, a proud Veteran-Owned company, offers highly competitive salaries and benefits. Our comprehensive benefits package includes company-paid employee and family dental insurance, employee health insurance, life insurance, and disability coverage. Additionally, we provide a 401(k)-retirement plan with company matching, paid holidays, and personal time off.

Responsibilities:

This opportunity will support multiple DIA initiatives, including the Machine-Assisted Rapid-Repository System (MARS), Object Management Services (OMS), and Object-Based Intelligence (OBI).

• The Senior Data Scientist (OBI Advanced Analytic Method Augmentation), Conducts data analytics, data engineering, data mining, exploratory analysis, predictive analysis, and statistical analysis, and uses scientific techniques to correlate data into graphical, written, visual and verbal narrative products, enabling more informed analytic decisions.

• Proactively retrieves information from various sources, analyzes it for better understanding about the data set, and builds AI tools that automate certain processes.

• Duties typically include: creating various ML-based tools or processes, such as recommendation engines or automated lead scoring systems.

• Performs statistical analysis, applies data mining techniques, and builds high quality prediction systems.

• Should be skilled in data visualization and use of graphical applications, including Microsoft Office (Power BI) and Tableau; major data science languages, such as Rand Python; managing and merging of disparate data sources, preferably through R, Python, or SQL; statistical analysis; and data mining algorithms.

• Should have prior experience with large data multi-INT analytics, ML, and automated predictive analytics.

• Designs, develops, and evaluates leading-edge algorithmic intelligence concepts, practices, and technologies for implementation into all-source analysis tradecraft, assessments, production, and dissemination.

• Proposes advanced statistical or mathematical techniques and methodology that may permit identification and evaluation of alternatives, assists in model formulation or experimental test design, and shares jointly in team responsibility for development of advanced analytic techniques and assessments.

• Evaluates data science, artificial intelligence, and other advanced analytic methods for risks, biases, and limitations that would distort conclusions.

• Conducts continuous independent research on methods of analysis in government, industry, and academia to keep abreast of the state of the art, keeps senior leadership apprised of the advances and applicability to programs.

• Utilizes in-depth knowledge of relevant theories, techniques, procedures and processes to investigate, prototype, and evaluate technologies to improve all-source intelligence analysis.

• Provides technical input into and participates in the development of software and computer graphics systems.

• Performs research studies to understand the process of augmenting or automating all source analytic processes using various computer models.

• Provides incremental enhancements to tools, capabilities, processes, and methods.

• Possesses in-depth knowledge and experience in using data analytics, data engineering, data mining, exploratory analysis, predictive analysis, and statistical analysis, and scientific techniques to correlate data into graphical, written, visual and verbal narrative products, enabling more informed analytic decisions.

• Writes either R or Python scripts to drive data science workflows, have experience using SQL, and managing and merging of disparate data sources, preferably through R, Python, or SQL; statistical analysis; and data mining algorithms.

• Possesses prior experience with large data, spatial data, multi-INT analytics, ML, and automated predictive analytics.

• Works with ambiguous information, deconstruct key questions, leverage spatial data, exploit application programming interfaces, suggest methodologies, develop data schemas to structure observations. This requires working knowledge of coding and scripting, information science, mathematics, machine learning, visual analytic modeling tools, and relevant Standard Operating Procedures (SOPs) to create repeatable, widely applicable procedures to support all-source intelligence analysis and production.

• Creates and works in distributed analytic environments, scaling algorithms to work on increasingly large and complex datasets that are larger than RAM.

• Serves as the primary POC for data science expertise, ensuring tradecraft compliance and analytic standards as it relates to data science techniques on the contract.

• Provides advice on emerging data science methods, tools, algorithms, training, or requirements to advance DIA's analytic edge in its use of data science.

• Works with DIA vendors and the software developers to implement distributed algorithms to work on increasingly large and complex data sets.

• Review and evaluate OBI documentation submitted by advanced analytic (AA) owners to ensure compliance with tradecraft standards and adherence to best practices in AI system development and deployment.

• Assess OBI documentation for completeness, accuracy, and thoroughness, and provide detailed feedback to owners and developers.

• Provide consultation and guidance to data and AA owners, developers, and stakeholders on OBI governance and knowledge modeling, including best practices for system development, testing, and deployment.

• Assist analytic methodologists and AA owners in translating technical documentation into analytic tradecraft compliant language.

• Collaborate with stakeholders to develop, implement, and refine best practices for translating technical documentation into tradecraft compliant language

• Review and edit translated documentation to ensure accuracy, completeness, and adherence to tradecraft standards.

• Collaborate with the Computer Scientist to develop and implement testing methodologies for system validation and evaluation.

• Conduct audits to ensure compliant use of systems for approved use-cases in all source analysis.

• Develop and maintain a repository of audit findings and recommendations to facilitate knowledge sharing and best practices across the organization.

• Design and execute TEVV protocols to evaluate the performance, robustness, and fairness of systems in all source analysis contexts.

• Develop and apply statistical models and methods to analyze TEVV results and identify areas for improvement.

• Collaborate with stakeholders to develop and implement corrective actions to address TEVV findings.

• Develop and track performance metrics to evaluate the effectiveness of systems in all source analysis.

• Analyze and interpret performance metrics to identify trends, patterns, and areas for improvement.

• Collaborate with stakeholders to develop and implement data-driven decision-making processes to inform system development and improvement.

• Develop and refine methodologies for evaluating system performance, robustness, and fairness in all source analysis contexts.

• Collaborate with stakeholders to develop and implement best practices for system development, testing, and deployment.

• Supports capability development by contributing, editing, and storing code in Government owned/controlled source version control repositories.

Required qualifications/skills:

• Minimum 12 years of experience related to the specific labor category with at least a portion of the experience within the last 2 years with a master's degree.

-OR-

• A minimum of 17 years of experience related to the specific labor category with at least a portion of the experience within the last 2 years with a bachelor's degree.

• Possesses a professional or graduate certificate in data science from a university, major online learning platform (all business for Data Scientists at any experience level).

• Demonstrates ability to work independently and with minimal oversight.

Come on board with a company that Values its Employees!

Celestar Corporation is an Equal Opportunity Employer. The Celestar Corporation prohibits discrimination, harassment, and retaliation in employment based on race; color; religion; genetic information; national origin; sex (including same-sex); sexual orientation; gender identity; pregnancy, childbirth, or related medical conditions; age; disability or handicap; citizenship status; marital status; service member/protected veteran status; or any other category protected by federal, state, or local law.",2025-07-18T00:00:00.000Z,2025-07-25,"['CLEARANCE REQUIREMENT: Active TS/SCI with a Current CI Poly', 'Should be skilled in data visualization and use of graphical applications, including Microsoft Office (Power BI) and Tableau; major data science languages, such as Rand Python; managing and merging of disparate data sources, preferably through R, Python, or SQL; statistical analysis; and data mining algorithms', 'Should have prior experience with large data multi-INT analytics, ML, and automated predictive analytics', 'Writes either R or Python scripts to drive data science workflows, have experience using SQL, and managing and merging of disparate data sources, preferably through R, Python, or SQL; statistical analysis; and data mining algorithms', 'Possesses prior experience with large data, spatial data, multi-INT analytics, ML, and automated predictive analytics', 'This requires working knowledge of coding and scripting, information science, mathematics, machine learning, visual analytic modeling tools, and relevant Standard Operating Procedures (SOPs) to create repeatable, widely applicable procedures to support all-source intelligence analysis and production', ""Minimum 12 years of experience related to the specific labor category with at least a portion of the experience within the last 2 years with a master's degree"", ""A minimum of 17 years of experience related to the specific labor category with at least a portion of the experience within the last 2 years with a bachelor's degree"", 'Possesses a professional or graduate certificate in data science from a university, major online learning platform (all business for Data Scientists at any experience level)', 'Demonstrates ability to work independently and with minimal oversight']","['This opportunity will support multiple DIA initiatives, including the Machine-Assisted Rapid-Repository System (MARS), Object Management Services (OMS), and Object-Based Intelligence (OBI)', 'The Senior Data Scientist (OBI Advanced Analytic Method Augmentation), Conducts data analytics, data engineering, data mining, exploratory analysis, predictive analysis, and statistical analysis, and uses scientific techniques to correlate data into graphical, written, visual and verbal narrative products, enabling more informed analytic decisions', 'Proactively retrieves information from various sources, analyzes it for better understanding about the data set, and builds AI tools that automate certain processes', 'Duties typically include: creating various ML-based tools or processes, such as recommendation engines or automated lead scoring systems', 'Performs statistical analysis, applies data mining techniques, and builds high quality prediction systems', 'Designs, develops, and evaluates leading-edge algorithmic intelligence concepts, practices, and technologies for implementation into all-source analysis tradecraft, assessments, production, and dissemination', 'Proposes advanced statistical or mathematical techniques and methodology that may permit identification and evaluation of alternatives, assists in model formulation or experimental test design, and shares jointly in team responsibility for development of advanced analytic techniques and assessments', 'Evaluates data science, artificial intelligence, and other advanced analytic methods for risks, biases, and limitations that would distort conclusions', 'Conducts continuous independent research on methods of analysis in government, industry, and academia to keep abreast of the state of the art, keeps senior leadership apprised of the advances and applicability to programs', 'Utilizes in-depth knowledge of relevant theories, techniques, procedures and processes to investigate, prototype, and evaluate technologies to improve all-source intelligence analysis', 'Provides technical input into and participates in the development of software and computer graphics systems', 'Performs research studies to understand the process of augmenting or automating all source analytic processes using various computer models', 'Provides incremental enhancements to tools, capabilities, processes, and methods', 'Possesses in-depth knowledge and experience in using data analytics, data engineering, data mining, exploratory analysis, predictive analysis, and statistical analysis, and scientific techniques to correlate data into graphical, written, visual and verbal narrative products, enabling more informed analytic decisions', 'Works with ambiguous information, deconstruct key questions, leverage spatial data, exploit application programming interfaces, suggest methodologies, develop data schemas to structure observations', 'Creates and works in distributed analytic environments, scaling algorithms to work on increasingly large and complex datasets that are larger than RAM', 'Serves as the primary POC for data science expertise, ensuring tradecraft compliance and analytic standards as it relates to data science techniques on the contract', ""Provides advice on emerging data science methods, tools, algorithms, training, or requirements to advance DIA's analytic edge in its use of data science"", 'Works with DIA vendors and the software developers to implement distributed algorithms to work on increasingly large and complex data sets', 'Review and evaluate OBI documentation submitted by advanced analytic (AA) owners to ensure compliance with tradecraft standards and adherence to best practices in AI system development and deployment', 'Assess OBI documentation for completeness, accuracy, and thoroughness, and provide detailed feedback to owners and developers', 'Provide consultation and guidance to data and AA owners, developers, and stakeholders on OBI governance and knowledge modeling, including best practices for system development, testing, and deployment', 'Assist analytic methodologists and AA owners in translating technical documentation into analytic tradecraft compliant language', 'Collaborate with stakeholders to develop, implement, and refine best practices for translating technical documentation into tradecraft compliant language', 'Review and edit translated documentation to ensure accuracy, completeness, and adherence to tradecraft standards', 'Collaborate with the Computer Scientist to develop and implement testing methodologies for system validation and evaluation', 'Conduct audits to ensure compliant use of systems for approved use-cases in all source analysis', 'Develop and maintain a repository of audit findings and recommendations to facilitate knowledge sharing and best practices across the organization', 'Design and execute TEVV protocols to evaluate the performance, robustness, and fairness of systems in all source analysis contexts', 'Develop and apply statistical models and methods to analyze TEVV results and identify areas for improvement', 'Collaborate with stakeholders to develop and implement corrective actions to address TEVV findings', 'Develop and track performance metrics to evaluate the effectiveness of systems in all source analysis', 'Analyze and interpret performance metrics to identify trends, patterns, and areas for improvement', 'Collaborate with stakeholders to develop and implement data-driven decision-making processes to inform system development and improvement', 'Develop and refine methodologies for evaluating system performance, robustness, and fairness in all source analysis contexts', 'Collaborate with stakeholders to develop and implement best practices for system development, testing, and deployment', 'Supports capability development by contributing, editing, and storing code in Government owned/controlled source version control repositories']",True,['Artificial Intelligence Tools Automation'],"Artificial Intelligence Tools Automation: Builds AI tools that automate certain intelligence analytic processes, enhancing efficiency and decision-making.","['Data Analytics', 'Data Engineering', 'Data Mining', 'Exploratory Data Analysis', 'Predictive Analysis', 'Statistical Analysis', 'Machine Learning', 'Data Visualization', 'Programming Languages (R, Python, SQL)', 'Multi-INT Analytics', 'Distributed Analytics and Scalable Algorithms', 'Algorithm Development', 'Data Science Tradecraft Compliance', 'Technical Documentation and Knowledge Modeling', 'Testing, Evaluation, Validation, and Verification (TEVV)', 'Performance Metrics and Data-Driven Decision Making', 'Version Control and Code Management']","Data Analytics: Conducts data analytics to extract insights and support informed analytic decisions in intelligence analysis contexts.; Data Engineering: Performs data engineering tasks including managing and merging disparate data sources using R, Python, or SQL to support large-scale intelligence data workflows.; Data Mining: Applies data mining techniques to discover patterns and build high-quality predictive systems for intelligence analysis.; Exploratory Data Analysis: Conducts exploratory analysis to better understand data sets and inform subsequent modeling and decision-making processes.; Predictive Analysis: Builds automated predictive analytics and ML-based tools such as recommendation engines and lead scoring systems to enhance intelligence assessments.; Statistical Analysis: Performs statistical analysis and develops statistical models to evaluate system performance, robustness, and fairness in all-source analysis contexts.; Machine Learning: Creates and applies machine learning models and automated predictive analytics to support multi-INT analytics and intelligence tradecraft.; Data Visualization: Utilizes data visualization tools including Microsoft Power BI and Tableau to create graphical and visual narrative products for analytic decisions.; Programming Languages (R, Python, SQL): Writes scripts in R and Python and uses SQL for data science workflows, managing data sources, and implementing data mining algorithms.; Multi-INT Analytics: Leverages multi-intelligence (multi-INT) data sources and spatial data to perform complex intelligence analysis and predictive modeling.; Distributed Analytics and Scalable Algorithms: Develops and implements distributed algorithms to scale analytics on large and complex datasets exceeding RAM capacity.; Algorithm Development: Designs, develops, and evaluates advanced algorithmic intelligence concepts and analytic techniques for all-source intelligence analysis.; Data Science Tradecraft Compliance: Ensures compliance with analytic standards and tradecraft in the application of data science techniques within intelligence workflows.; Technical Documentation and Knowledge Modeling: Reviews, translates, and refines technical documentation into tradecraft-compliant language and provides guidance on governance and knowledge modeling.; Testing, Evaluation, Validation, and Verification (TEVV): Designs and executes TEVV protocols to assess system performance, robustness, fairness, and compliance in intelligence analysis systems.; Performance Metrics and Data-Driven Decision Making: Develops and analyzes performance metrics to identify trends and inform corrective actions and improvements in analytic systems.; Version Control and Code Management: Contributes to capability development by editing and storing code in government-owned or controlled source version control repositories."
e3bHDqC3T7JHo0tUAAAAAA==,Sr Staff Data Scientist,"Job Description Summary
As a Sr Staff Data Scientist, you will lead and work within teams as a technical domain expert addressing statistical, machine learning, and artificial intelligence problems in a commercial technology and consultancy development environment. You will be part of a data science or cross-disciplinary team driving AI business solutions involving large, complex data sets. Potential application areas include time series forecasting, machine learning regression and classification, root cause analysis (RCA), simulation and optimization, large language models, and computer vision. The ideal candidate will be responsible for developing and deploying machine learning models in production environments. This role requires a strong technical background, excellent problem-solving skills, and the ability to work collaboratively with data engineers, analysts, and other stakeholders.

Job Description

Roles and Responsibilities:
• Understand business problems and identify opportunities to implement data science solutions.
• Develop, verify, and validate analytics to address customer needs and opportunities.
• Design, develop, and deploy machine learning models and algorithms
• Work in technical teams on the development, deployment, and application of applied analytics, predictive analytics, and prescriptive analytics.
• Develop and maintain pipelines for Retrieval-Augmented Generation (RAG) and Large Language Models (LLM).
• Collaborate with data scientists to optimize RAG and LLM pipelines for performance and accuracy.
• Utilize semantic and ontology technologies to enhance data integration and retrieval. Ensure data is semantically enriched to support advanced analytics and machine learning models.
• Interact with cloud services and develop and deploy models within cloud environments such as AWS, Azure, Google Cloud, and Databricks
• Perform exploratory and targeted data analyses using descriptive statistics and other methods.
• Work with data engineers on data quality assessment, data cleansing, data analytics, and model productionization
• Generate reports, annotated code, and other projects artifacts to document, archive, and communicate your work and outcomes.
• Communicate methods, findings, and hypotheses with stakeholders.
• Mentor colleagues in technical areas and drive standardization across the analytics enterprise
• Review data science/AI projects for technical rigor

Minimum Qualifications:
• Bachelor’s degree from accredited university or college with minimum of 6 years of professional experience OR associates degree with minimum of 8 years of professional experience
• 4 years proficiency in Python (mandatory)
• 3 years demonstrated expertise in cloud platforms (e.g. AWS, Azure, Google Cloud, Databricks) and their machine learning services
• 3 years demonstrated expertise working and leading in team settings in various roles
• Note: Military experience is equivalent to professional experience

Eligibility Requirement:
• Legal authorization to work in the U.S. is required. We will not sponsor individuals for employment visas, now or in the future, for this job.

Desired Characteristics:
• Demonstrated skill in defining and delivering customer value.
• Demonstrated expertise communicating complex information to executive stakeholders
• Demonstrated expertise in critical thinking and problem-solving methods
• Demonstrated experience deploying and managing CI/CD pipelines
• Demonstrated skill in data management methods and analytic scaling
• Demonstrated skill in prescriptive analytics and analytic prototyping.
• Demonstrated skill in solutions integration
• Demonstrated skill in serving as a change agent.
• Demonstrated skill in working in ambiguous environments.

Note:

To comply with US immigration and other legal requirements, it is necessary to specify the minimum number of years' experience required for any role based within the USA. For roles outside of the USA, to ensure compliance with applicable legislation, the JDs should focus on the substantive level of experience required for the role and a minimum number of years should NOT be used.

This Job Description is intended to provide a high level guide to the role. However, it is not intended to amend or otherwise restrict/expand the duties required from each individual employee as set out in their respective employment contract and/or as otherwise agreed between an employee and their manager.

Additional Job Description

Compensation Grade

SPB3

This role requires access to U.S. export-controlled information. If applicable, final offers will be contingent on ability to obtain authorization for access to U.S. export-controlled information from the U.S. Government.

Additional Information

GE Aerospace offers a great work environment, professional development, challenging careers, and competitive compensation. GE Aerospace is an Equal Opportunities Employer. Employment decisions are made without regard to race, color, religion, national or ethnic origin, sex, sexual orientation, gender identity or expression, age, disability, protected veteran status or other characteristics protected by law.

GE Aerospace will only employ those who are legally authorized to work in the United States for this opening.

Relocation Assistance Provided: Yes",2025-07-23T00:00:00.000Z,2025-07-25,"['This role requires a strong technical background, excellent problem-solving skills, and the ability to work collaboratively with data engineers, analysts, and other stakeholders', 'Bachelor’s degree from accredited university or college with minimum of 6 years of professional experience OR associates degree with minimum of 8 years of professional experience', '4 years proficiency in Python (mandatory)', '3 years demonstrated expertise in cloud platforms (e.g', 'AWS, Azure, Google Cloud, Databricks) and their machine learning services', '3 years demonstrated expertise working and leading in team settings in various roles', 'Note: Military experience is equivalent to professional experience', 'Legal authorization to work in the U.S. is required', ""To comply with US immigration and other legal requirements, it is necessary to specify the minimum number of years' experience required for any role based within the USA"", 'For roles outside of the USA, to ensure compliance with applicable legislation, the JDs should focus on the substantive level of experience required for the role and a minimum number of years should NOT be used']","['As a Sr Staff Data Scientist, you will lead and work within teams as a technical domain expert addressing statistical, machine learning, and artificial intelligence problems in a commercial technology and consultancy development environment', 'You will be part of a data science or cross-disciplinary team driving AI business solutions involving large, complex data sets', 'Potential application areas include time series forecasting, machine learning regression and classification, root cause analysis (RCA), simulation and optimization, large language models, and computer vision', 'The ideal candidate will be responsible for developing and deploying machine learning models in production environments', 'Understand business problems and identify opportunities to implement data science solutions', 'Develop, verify, and validate analytics to address customer needs and opportunities', 'Design, develop, and deploy machine learning models and algorithms', 'Work in technical teams on the development, deployment, and application of applied analytics, predictive analytics, and prescriptive analytics', 'Develop and maintain pipelines for Retrieval-Augmented Generation (RAG) and Large Language Models (LLM)', 'Collaborate with data scientists to optimize RAG and LLM pipelines for performance and accuracy', 'Utilize semantic and ontology technologies to enhance data integration and retrieval', 'Ensure data is semantically enriched to support advanced analytics and machine learning models', 'Interact with cloud services and develop and deploy models within cloud environments such as AWS, Azure, Google Cloud, and Databricks', 'Perform exploratory and targeted data analyses using descriptive statistics and other methods', 'Work with data engineers on data quality assessment, data cleansing, data analytics, and model productionization', 'Generate reports, annotated code, and other projects artifacts to document, archive, and communicate your work and outcomes', 'Communicate methods, findings, and hypotheses with stakeholders', 'Mentor colleagues in technical areas and drive standardization across the analytics enterprise', 'Review data science/AI projects for technical rigor']",True,"['Large Language Models (LLMs)', 'Retrieval-Augmented Generation (RAG)', 'Computer Vision']","Large Language Models (LLMs): Developed, deployed, and optimized within pipelines to support AI business solutions involving natural language understanding and generation.; Retrieval-Augmented Generation (RAG): Implemented and maintained pipelines that combine retrieval of relevant information with generative AI models to enhance performance and accuracy in AI applications.; Computer Vision: Applied as a potential AI application area involving image and video data analysis using modern AI techniques.","['Time Series Forecasting', 'Regression Models', 'Classification Models', 'Root Cause Analysis (RCA)', 'Simulation and Optimization', 'Machine Learning Models', 'Applied Analytics', 'Predictive Analytics', 'Prescriptive Analytics', 'Retrieval-Augmented Generation (RAG) Pipelines', 'Semantic and Ontology Technologies', 'Exploratory and Targeted Data Analysis', 'Data Quality Assessment and Cleansing', 'Model Productionization', 'Cloud Platforms and Machine Learning Services', 'Python Programming', 'CI/CD Pipelines']","Time Series Forecasting: Used as a potential application area for predictive analytics to analyze and forecast data trends over time in business problems.; Regression Models: Applied in machine learning regression tasks to develop predictive models addressing customer needs and opportunities.; Classification Models: Used in machine learning classification tasks to categorize data and support business solutions.; Root Cause Analysis (RCA): Employed to identify underlying causes of issues within data and business processes to improve solutions.; Simulation and Optimization: Applied to model complex systems and optimize outcomes as part of advanced analytics and prescriptive analytics.; Machine Learning Models: Designed, developed, and deployed in production environments to solve business problems and drive AI business solutions.; Applied Analytics: Involved in the development, deployment, and application of analytics techniques to address real-world business challenges.; Predictive Analytics: Used to forecast future outcomes based on historical data to support decision-making.; Prescriptive Analytics: Applied to recommend actions based on data insights and analytic prototyping to optimize business processes.; Retrieval-Augmented Generation (RAG) Pipelines: Developed and maintained to enhance data retrieval and generation capabilities in conjunction with large language models.; Semantic and Ontology Technologies: Utilized to enrich data semantically, improving data integration, retrieval, and supporting advanced analytics and machine learning models.; Exploratory and Targeted Data Analysis: Performed using descriptive statistics and other methods to understand data characteristics and inform model development.; Data Quality Assessment and Cleansing: Collaborated with data engineers to ensure data integrity and prepare data for analytics and model productionization.; Model Productionization: Involved in deploying machine learning models into production environments for operational use.; Cloud Platforms and Machine Learning Services: Interacted with and deployed models within cloud environments such as AWS, Azure, Google Cloud, and Databricks to leverage scalable infrastructure and services.; Python Programming: Used as the primary programming language for developing machine learning models, analytics, and data processing pipelines.; CI/CD Pipelines: Deployed and managed continuous integration and continuous deployment pipelines to automate model and analytics delivery."
Ovm-G7mZRL8v1phBAAAAAA==,Senior Data Scientist 451 Jobs,"Description: NSI requires a Senior Data Scientist to support an upcoming Naval Air Warfare Center Aircraft Division Lakehurst Mission Operations & Integration (MO&I) Department Contractor Support Services Program Office. The Senior Data Scientist will develop and implement data strategies that align with business objectives, ensuring effective utilization of data assets across the organization. Collaborate with cross-functional teams, including engineering, product development, and business stakeholders, to understand their needs and deliver data-driven solutions. Overseeing data collection, storage, and maintenance, you will ensure data integrity and security and enforce data governance policies. Staying current with advancements in data science and machine learning, drive innovation and continuous improvement within the team. Additionally, communicate findings and recommendations to senior management and other stakeholders, translating complex technical concepts into actionable business insights. Utilizing advanced analytics tools and technologies, you will enhance data processing and analysis capabilities, ensuring the scalability and efficiency of data solutions.

Location: Lakehurst, NJ

Education: BS in Computer Science, Mathematics, Statistics, Data Science or related scientific /technical discipline.

Experience: Requires a minimum of ten (10) years of data science experience; over five (5) years of programming experience (e.g., C++, JAVA) of the most current generation.

Security Clearance: Secret Clearance is required. Must be a U.S. citizen.

Special Notes/Instructions: NSI is a privately held, small but quickly growing company with headquarters in Lexington Park, Maryland within 5 miles of the Patuxent River Naval Air Station. Established in 2004, we are now celebrating 21 years of excellence in providing quality products and services to the Department of Defense. Our benefits package includes medical, dental, vision, Long Term Disability, Life Insurance, Short Term Disability, paid time off, paid holidays, flexible spending account, employee assistance program, tuition assistance program, 401k Plan with company match as well as a fun and enthusiastic work environment!

To Apply: NSI offers a team-oriented work environment and competitive compensation and employee benefits package. If you have a commitment to excellence and want to join our team of top caliber professionals, we invite you to submit your resume electronically by visiting our careers website at: https://n-s-i.us/careers/apply/.

Quality, Integrity, Teamwork, Success - that's NSI!

NSI is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status.",2025-07-24T00:00:00.000Z,2025-07-25,"['Education: BS in Computer Science, Mathematics, Statistics, Data Science or related scientific /technical discipline', 'Experience: Requires a minimum of ten (10) years of data science experience; over five (5) years of programming experience (e.g., C++, JAVA) of the most current generation', 'Security Clearance: Secret Clearance is required', 'Must be a U.S. citizen']","['Description: NSI requires a Senior Data Scientist to support an upcoming Naval Air Warfare Center Aircraft Division Lakehurst Mission Operations & Integration (MO&I) Department Contractor Support Services Program Office', 'The Senior Data Scientist will develop and implement data strategies that align with business objectives, ensuring effective utilization of data assets across the organization', 'Collaborate with cross-functional teams, including engineering, product development, and business stakeholders, to understand their needs and deliver data-driven solutions', 'Overseeing data collection, storage, and maintenance, you will ensure data integrity and security and enforce data governance policies', 'Staying current with advancements in data science and machine learning, drive innovation and continuous improvement within the team', 'Additionally, communicate findings and recommendations to senior management and other stakeholders, translating complex technical concepts into actionable business insights', 'Utilizing advanced analytics tools and technologies, you will enhance data processing and analysis capabilities, ensuring the scalability and efficiency of data solutions']",True,[],,"['Data Strategy Development', 'Data Governance', 'Cross-Functional Collaboration', 'Advanced Analytics Tools', 'Data Science and Machine Learning', 'Communication of Insights']","Data Strategy Development: Develop and implement data strategies that align with business objectives to ensure effective utilization of data assets across the organization.; Data Governance: Oversee data collection, storage, and maintenance to ensure data integrity and security, and enforce data governance policies.; Cross-Functional Collaboration: Collaborate with engineering, product development, and business stakeholders to understand their needs and deliver data-driven solutions.; Advanced Analytics Tools: Utilize advanced analytics tools and technologies to enhance data processing and analysis capabilities, ensuring scalability and efficiency of data solutions.; Data Science and Machine Learning: Stay current with advancements in data science and machine learning to drive innovation and continuous improvement within the team.; Communication of Insights: Communicate findings and recommendations to senior management and other stakeholders by translating complex technical concepts into actionable business insights."
xR4raTaIOb_Gja9mAAAAAA==,Senior Data Scientist,"An exciting career awaits you

At MPC, we're committed to being a great place to work - one that welcomes new ideas, encourages diverse perspectives, develops our people, and fosters a collaborative team environment.

Position Summary

We are seeking a highly skilled and experienced Sr. Data Scientist to join our dynamic Data Science and AI team. In this role, you will be instrumental in transforming data into actionable insights and innovative solutions, driving forward our business strategy. You will leverage advanced machine learning, statistical techniques, and analytical prowess to solve complex business challenges, collaborating closely with cross-functional teams to design, develop, and deploy scalable AI-driven models and algorithms.
This position belongs to a family of jobs with increasing responsibility, competency, and skill level. Actual position title and pay grade will be based on the selected candidate's experience and qualifications.

Key Responsibilities
• Leads multiple data science projects ensuring alignment with business goals.
• Develops predictive models and integrates them with Business Intelligence tools.
• Develops and maintains data pipelines for efficient data retrieval and processing. Collaborates with applications and data engineering teams for deploying models at scale.
• Mentors junior data scientists in model development and data handling.
• Engages with Senior Leadership to inform strategic decisions using business intelligence insights.
• Researches and adopts cutting-edge technologies and methodologies in data science.
• Manages stakeholder expectations and delivers actionable solutions.
• Oversees data processing pipelines ensuring data quality and consistency.
• Drives ethical considerations in model deployment and data utilization.
• Collaborates with external partners, research institutions, and subject matter experts to gather domain-specific knowledge and datasets.
• Performs exploratory data analysis to identify patterns, insights, and communicate findings.
• Engage in the ideation and prototyping of new solutions to meet emerging business requirements.
• Utilize advanced machine learning techniques (e.g., deep learning, NLP, computer vision, reinforcement learning) to create innovative solutions.

Education and Experience
• Bachelor's Degree in Information Technology or related field required.
• Master's or Ph.D. in Computer Science, Statistics, Mathematics, or a related field preferred
• 5+ years of relevant experience required.
• Expertise in Python and proficiency in ML frameworks (TensorFlow, PyTorch, scikit-learn).
• Deep understanding of ML algorithms (supervised, unsupervised learning, and deep learning) and their applications.
• Strong problem-solving, critical thinking, and analytical capabilities.

Skills
• Artificial Intelligence (AI) and Machine Learning (ML) - Understanding of AI/ML concepts, algorithms, and platforms to design architectures that support intelligent systems and enable AI-driven applications.
• Business Domain Knowledge - Understanding of business processes, industry trends, and market dynamics to provide relevant and actionable insights for strategic decision-making.
• Communication and Collaboration - Excellent communication skills to effectively interact with stakeholders, gather requirements, present architectural proposals, and collaborate with cross-functional teams.
• Data Analysis - The process of measuring and managing organizational data, identifying methodological best practices, and conducting statistical analyses.
• Data Ethics & Responsible Innovation - Knowledge of ethical considerations related to data usage, data-driven technologies, and strategies to mitigate biases in data-driven decision-making.
• Data Mining and Extraction - Data mining is sorting through data to identify patterns and establish relationships. Data mining parameters include: Association - looking for patterns where one event is connected to another event Sequence or path analysis - looking for patterns where one event leads to another later event Classification - looking for new patterns [May result in a change in the way the data is organized but that's ok] Clustering - finding and visually documenting groups of facts not previously known Forecasting - discovering patterns in data that can lead to reasonable predictions about the future Data mining techniques are used in mathematics, cybernetics, and genetics. Web mining, a type of data mining used in customer relationship management [CRM], takes advantage of the huge amount of information gathered by a Web site to look for patterns in user behavior.
• Data Monetization and Data Science - Familiarity with data monetization strategies and techniques, such as data commercialization, data marketplaces, and data value realization.
• Natural Language Processing - Proficiency in analyzing and extracting insights from unstructured text data, including sentiment analysis, topic modeling, and language understanding.
• Problem-Solving and Analytical Thinking - Strong problem-solving skills to identify architectural challenges, analyze requirements, evaluate options, and propose effective solutions.
• Reporting and Dashboarding - The ability to access information from databases, forms, and other sources, and prepare reports according to requirements.
• Statistical Analysis - Statistical Analysis is used in support of decision-making and includes fundamental principles such as data collection and sampling, random variable types and probability distributions, sampling, and population distributions, making estimations from samples, hypothesis testing, and statistical process control.

As an energy industry leader, our career opportunities fuel personal and professional growth.

Location:
San Antonio, Texas

Job Requisition ID:
00017703

Pay Min/Max:
$104,300.00 - $179,800.00 Salary

Grade:
11 - 12

Location Address:
19100 Ridgewood Pkwy

Additional locations:
Denver CO, Findlay, Ohio

Education:
Bachelors: Information Technology (Required)

Employee Group:
Full time

Employee Subgroup:
Regular

Marathon Petroleum Company LP is an Equal Opportunity Employer and gives consideration for employment to qualified applicants without discrimination on the basis of race, color, religion, creed, sex, gender (including pregnancy, childbirth, breastfeeding or related medical conditions), sexual orientation, gender identity, gender expression, reproductive health decision-making, age, mental or physical disability, medical condition or AIDS/HIV status, ancestry, national origin, genetic information, military, veteran status, marital status, citizenship or any other status protected by applicable federal, state, or local laws. If you would like more information about your EEO rights as an applicant, click here .

If you need a reasonable accommodation for any part of the application process at Marathon Petroleum LP, please contact our Human Resources Department at . Please specify the reasonable accommodation you are requesting, along with the job posting number in which you may be interested. A Human Resources representative will review your request and contact you to discuss a reasonable accommodation. Marathon Petroleum offers a total rewards program which includes, but is not limited to, access to health, vision, and dental insurance, paid time off, 401k matching program, paid parental leave, and educational reimbursement. Detailed benefit information is available at mympcbenefits.com . The hired candidate will also be eligible for a discretionary company-sponsored annual bonus program.

Equal Opportunity Employer: Veteran / Disability

We will consider all qualified Applicants for employment, including those with arrest or conviction records, in a manner consistent with the requirements of applicable state and local laws. In reviewing criminal history in connection with a conditional offer of employment, Marathon will consider the key responsibilities of the role.",2025-07-17T00:00:00.000Z,2025-07-25,"['We are seeking a highly skilled and experienced Sr', ""Bachelor's Degree in Information Technology or related field required"", '5+ years of relevant experience required', 'Expertise in Python and proficiency in ML frameworks (TensorFlow, PyTorch, scikit-learn)', 'Deep understanding of ML algorithms (supervised, unsupervised learning, and deep learning) and their applications', 'Strong problem-solving, critical thinking, and analytical capabilities', 'Artificial Intelligence (AI) and Machine Learning (ML) - Understanding of AI/ML concepts, algorithms, and platforms to design architectures that support intelligent systems and enable AI-driven applications', 'Business Domain Knowledge - Understanding of business processes, industry trends, and market dynamics to provide relevant and actionable insights for strategic decision-making', 'Communication and Collaboration - Excellent communication skills to effectively interact with stakeholders, gather requirements, present architectural proposals, and collaborate with cross-functional teams', 'Data Analysis - The process of measuring and managing organizational data, identifying methodological best practices, and conducting statistical analyses', 'Data Ethics & Responsible Innovation - Knowledge of ethical considerations related to data usage, data-driven technologies, and strategies to mitigate biases in data-driven decision-making', 'Data Monetization and Data Science - Familiarity with data monetization strategies and techniques, such as data commercialization, data marketplaces, and data value realization', 'Natural Language Processing - Proficiency in analyzing and extracting insights from unstructured text data, including sentiment analysis, topic modeling, and language understanding', 'Problem-Solving and Analytical Thinking - Strong problem-solving skills to identify architectural challenges, analyze requirements, evaluate options, and propose effective solutions', 'Reporting and Dashboarding - The ability to access information from databases, forms, and other sources, and prepare reports according to requirements', 'Bachelors: Information Technology (Required)']","['In this role, you will be instrumental in transforming data into actionable insights and innovative solutions, driving forward our business strategy', 'You will leverage advanced machine learning, statistical techniques, and analytical prowess to solve complex business challenges, collaborating closely with cross-functional teams to design, develop, and deploy scalable AI-driven models and algorithms', 'This position belongs to a family of jobs with increasing responsibility, competency, and skill level', 'Leads multiple data science projects ensuring alignment with business goals', 'Develops predictive models and integrates them with Business Intelligence tools', 'Develops and maintains data pipelines for efficient data retrieval and processing', 'Collaborates with applications and data engineering teams for deploying models at scale', 'Mentors junior data scientists in model development and data handling', 'Engages with Senior Leadership to inform strategic decisions using business intelligence insights', 'Researches and adopts cutting-edge technologies and methodologies in data science', 'Manages stakeholder expectations and delivers actionable solutions', 'Oversees data processing pipelines ensuring data quality and consistency', 'Drives ethical considerations in model deployment and data utilization', 'Collaborates with external partners, research institutions, and subject matter experts to gather domain-specific knowledge and datasets', 'Performs exploratory data analysis to identify patterns, insights, and communicate findings', 'Engage in the ideation and prototyping of new solutions to meet emerging business requirements', 'Utilize advanced machine learning techniques (e.g., deep learning, NLP, computer vision, reinforcement learning) to create innovative solutions', 'Data Mining and Extraction - Data mining is sorting through data to identify patterns and establish relationships', ""Data mining parameters include: Association - looking for patterns where one event is connected to another event Sequence or path analysis - looking for patterns where one event leads to another later event Classification - looking for new patterns [May result in a change in the way the data is organized but that's ok] Clustering - finding and visually documenting groups of facts not previously known Forecasting - discovering patterns in data that can lead to reasonable predictions about the future Data mining techniques are used in mathematics, cybernetics, and genetics"", 'Web mining, a type of data mining used in customer relationship management [CRM], takes advantage of the huge amount of information gathered by a Web site to look for patterns in user behavior', 'Statistical Analysis - Statistical Analysis is used in support of decision-making and includes fundamental principles such as data collection and sampling, random variable types and probability distributions, sampling, and population distributions, making estimations from samples, hypothesis testing, and statistical process control']",True,"['Artificial Intelligence', 'Natural Language Processing with AI', 'Deep Learning for AI', 'Computer Vision for AI', 'Reinforcement Learning for AI', 'Machine Learning Frameworks for AI']","Artificial Intelligence: Understands AI concepts, algorithms, and platforms to design architectures that support intelligent systems and enable AI-driven applications.; Natural Language Processing with AI: Utilizes NLP techniques specifically in the context of AI to analyze and extract insights from unstructured text data.; Deep Learning for AI: Applies deep learning neural network methods as part of AI-driven model development and deployment.; Computer Vision for AI: Employs computer vision techniques within AI frameworks to create innovative solutions.; Reinforcement Learning for AI: Uses reinforcement learning methods in AI to develop autonomous and adaptive models and solutions.; Machine Learning Frameworks for AI: Uses AI-relevant ML frameworks such as TensorFlow and PyTorch to develop and deploy neural network-based AI models.","['Predictive Modeling', 'Business Intelligence Tools', 'Data Pipelines', 'Exploratory Data Analysis', 'Machine Learning Algorithms', 'Deep Learning', 'Natural Language Processing', 'Computer Vision', 'Reinforcement Learning', 'Python', 'ML Frameworks', 'Statistical Analysis', 'Data Mining', 'Web Mining', 'Data Monetization', 'Data Ethics', 'Reporting and Dashboarding']","Predictive Modeling: Develops predictive models and integrates them with Business Intelligence tools to support business goals and decision-making.; Business Intelligence Tools: Uses BI tools to integrate predictive models and provide actionable insights for strategic decisions.; Data Pipelines: Develops and maintains data pipelines for efficient data retrieval, processing, and ensuring data quality and consistency.; Exploratory Data Analysis: Performs exploratory data analysis to identify patterns, insights, and communicate findings to stakeholders.; Machine Learning Algorithms: Utilizes advanced machine learning techniques including supervised and unsupervised learning to solve complex business challenges.; Deep Learning: Applies deep learning methods as part of advanced machine learning techniques to create innovative solutions.; Natural Language Processing: Proficient in analyzing and extracting insights from unstructured text data, including sentiment analysis, topic modeling, and language understanding.; Computer Vision: Uses computer vision techniques as part of advanced machine learning to develop innovative AI-driven solutions.; Reinforcement Learning: Employs reinforcement learning methods to develop innovative machine learning models and solutions.; Python: Expertise in Python programming language for developing machine learning models and data science solutions.; ML Frameworks: Proficiency in machine learning frameworks such as TensorFlow, PyTorch, and scikit-learn for model development and deployment.; Statistical Analysis: Applies statistical analysis principles including data collection, sampling, probability distributions, hypothesis testing, and statistical process control to support decision-making.; Data Mining: Uses data mining techniques to identify patterns and relationships in data, including association, sequence/path analysis, classification, clustering, and forecasting.; Web Mining: Applies web mining techniques to analyze large volumes of web data for customer relationship management and user behavior pattern identification.; Data Monetization: Familiarity with strategies and techniques for data commercialization, data marketplaces, and realizing data value.; Data Ethics: Drives ethical considerations in model deployment and data utilization, including strategies to mitigate biases in data-driven decision-making.; Reporting and Dashboarding: Prepares reports and dashboards by accessing information from databases and other sources to meet business requirements."
hiPwBaWcFXanqlFtAAAAAA==,"Data Scientist, Senior Jobs","Job Number: R0221333

Data Scientist, Senior

The Opportunity:

Are you intrigued by the power of machine learning and generative AI to solve real-world challenges? In today's data-driven world, we are seeking professionals ready to architect, develop, and deploy scalable, production-ready analytics solutions that transform massive volumes of structured and unstructured data into actionable insights. Join our team to apply your skills in data science, visualization, and UI / UX design to mission-critical intelligence work.

You'll work side by side with mission partners to understand their objectives and navigate data rich environments. As a key contributor, you will design and operationalize machine learning models, predictive analytics, and web-based tools using both streaming and batch data pipelines. You'll bring intelligence analysis into the future through agile collaboration and by building interactive visual interfaces that translate the results of advanced AI models into meaningful decisions. We emphasize end-to-end development from rapid prototyping to deployment in cloud-based environments ensuring that your solutions are aligned with current architecture while remaining adaptable for future innovation.

Join us. The world can't wait.

You Have:
• 6+ years of experience in data science, analytics, or machine learning
• Experience with Python for data wrangling, modeling, and visualization, including Pandas, NumPy, Matplotlib, and Seaborn
• Experience crafting prompts for Gen AI Large Language Models (LLM)
• Experience developing UI / UX solutions using JavaScript, HTML5, and CSS3
• Experience in object-oriented languages such as Python, Java, C++, or C#
• Experience with machine learning frameworks such as TensorFlow, PyTorch, or scikit-learn
• Knowledge of cloud platforms such as AWS, Azure, or GCP, including model hosting and containerization such as Docker and Kubernetes
• Ability to build and deploy production-grade models and analytics tools
• TS/SCI clearance with a polygraph
• HS diploma or GED

Nice If You Have:
• Experience working with streaming data technologies such as Apache Kafka and Flink, and distributed systems such as Hadoop and Spark
• Experience with Agile methodologies, automated testing, and DevOps practices
• Experience in open-source databases such as MySQL, PostgreSQL, or SQLite
• Knowledge of USINDOPACOM area of responsibility
• Knowledge of intelligence analysis frameworks, operational systems, and tools
• Knowledge of data-centric architecture, including security, scalability, and data governance
• Ability to move analytic prototypes into fully operational mission environments
• Bachelor's degree in a Science, Technology, Engineering, or Mathematics (STEM) field such as CS or Data Science preferred; Master's degree in a STEM field such as CS or Data Science a plus

Clearance:

Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information ; TS/SCI clearance with polygraph is required.

Compensation

At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen's benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.

Salary at Booz Allen is determined by various factors, including but not limited to location, the individual's particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $99,000.00 to $225,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen's total compensation package for employees. This posting will close within 90 days from the Posting Date.

Identity Statement

As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud.

Work Model

Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.
• If this position is listed as remote or hybrid, you'll periodically work from a Booz Allen or client site facility.
• If this position is listed as onsite, you'll work with colleagues and clients in person, as needed for the specific role.

Commitment to Non-Discrimination

All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law.",2025-07-19T00:00:00.000Z,2025-07-25,"['6+ years of experience in data science, analytics, or machine learning', 'Experience with Python for data wrangling, modeling, and visualization, including Pandas, NumPy, Matplotlib, and Seaborn', 'Experience crafting prompts for Gen AI Large Language Models (LLM)', 'Experience developing UI / UX solutions using JavaScript, HTML5, and CSS3', 'Experience in object-oriented languages such as Python, Java, C++, or C#', 'Experience with machine learning frameworks such as TensorFlow, PyTorch, or scikit-learn', 'Knowledge of cloud platforms such as AWS, Azure, or GCP, including model hosting and containerization such as Docker and Kubernetes', 'Ability to build and deploy production-grade models and analytics tools', 'TS/SCI clearance with a polygraph', 'HS diploma or GED', 'Experience working with streaming data technologies such as Apache Kafka and Flink, and distributed systems such as Hadoop and Spark', 'Experience with Agile methodologies, automated testing, and DevOps practices', 'Experience in open-source databases such as MySQL, PostgreSQL, or SQLite', 'Knowledge of USINDOPACOM area of responsibility', 'Knowledge of intelligence analysis frameworks, operational systems, and tools', 'Knowledge of data-centric architecture, including security, scalability, and data governance', 'Ability to move analytic prototypes into fully operational mission environments', 'Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information ; TS/SCI clearance with polygraph is required']","['Join our team to apply your skills in data science, visualization, and UI / UX design to mission-critical intelligence work', ""You'll work side by side with mission partners to understand their objectives and navigate data rich environments"", 'As a key contributor, you will design and operationalize machine learning models, predictive analytics, and web-based tools using both streaming and batch data pipelines', ""You'll bring intelligence analysis into the future through agile collaboration and by building interactive visual interfaces that translate the results of advanced AI models into meaningful decisions"", ""If this position is listed as remote or hybrid, you'll periodically work from a Booz Allen or client site facility"", ""If this position is listed as onsite, you'll work with colleagues and clients in person, as needed for the specific role""]",True,"['Generative AI Large Language Models', 'Deep Learning Frameworks']",Generative AI Large Language Models: Crafting prompts for generative AI large language models (LLMs) to leverage advanced AI capabilities in solving real-world challenges and enhancing intelligence analysis.; Deep Learning Frameworks: Using deep learning frameworks such as TensorFlow and PyTorch specifically for neural network development and deployment in AI model building.,"['Machine Learning', 'Python', 'Data Visualization', 'Streaming and Batch Data Pipelines', 'Machine Learning Frameworks', 'Cloud Platforms and Containerization', 'Streaming Data Technologies and Distributed Systems', 'Open-Source Databases', 'Agile Methodologies and DevOps Practices']","Machine Learning: Designing and operationalizing machine learning models and predictive analytics to transform data into actionable insights and support mission-critical intelligence work.; Python: Using Python for data wrangling, modeling, and visualization, including libraries such as Pandas, NumPy, Matplotlib, and Seaborn to process and analyze data.; Data Visualization: Building interactive visual interfaces that translate the results of advanced models into meaningful decisions, supporting intelligence analysis.; Streaming and Batch Data Pipelines: Developing and utilizing both streaming and batch data pipelines to handle large volumes of structured and unstructured data for analytics and model deployment.; Machine Learning Frameworks: Employing frameworks such as TensorFlow, PyTorch, and scikit-learn to develop and deploy machine learning models.; Cloud Platforms and Containerization: Using cloud platforms like AWS, Azure, or GCP for model hosting and leveraging containerization technologies such as Docker and Kubernetes to deploy production-grade models and analytics tools.; Streaming Data Technologies and Distributed Systems: Experience with Apache Kafka, Flink, Hadoop, and Spark to manage and process streaming data and distributed computing environments.; Open-Source Databases: Working with databases such as MySQL, PostgreSQL, or SQLite to store and query data for analytics and model support.; Agile Methodologies and DevOps Practices: Applying Agile methodologies, automated testing, and DevOps practices to ensure rapid prototyping, deployment, and operationalization of analytics solutions."
jWxFAP0iymu5r3AzAAAAAA==,"Senior Data Scientist, AI Foundations","Senior Data Scientist, AI Foundations

Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making.

As a Data Scientist at Capital One, you’ll be part of a team that’s leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives.

Team Description

AI Foundations Specialist Models Data Science team builds and ships state of the art scalable architecture, AI/ML solutions for Capital One’s award-winning mobile app. We partner with product, tech and design teams to deliver app features that delight customers with dynamic and personalized experiences, enable them to chat with Capital One’s digital assistant Eno, or search for useful contents. You will be the driving force to experiment, innovate and create next generation experiences powered by the latest emerging generative AI technologies.

In this role, you will:
• Partner with a cross-functional team of data scientists, software engineers, machine learning engineers and product managers to deliver AI powered products that change how customers interact with their money.
• Leverage a broad stack of technologies — Pytorch, AWS Ultraclusters, Hugging Face, LangChain, Lightning, VectorDBs, and more — to reveal the insights hidden within huge volumes of numeric and textual data.
• Be the expert in Natural Language Processing (NLP) to harness the power of Large Language Models (LLMs), adapt and finetune them for customer facing applications and features.
• Build machine learning and NLP models through all phases of development, from design through training, evaluation, and validation; partnering with engineering teams to operationalize them in scalable and resilient production systems that serve 80+ million customers.
• Flex your interpersonal skills to translate the complexity of your work into tangible business goals.

The Ideal Candidate is:
• Customer first. You love the process of analyzing and creating, but also share our passion to do the right thing. You know at the end of the day it’s about making the right decision for our customers.
• Innovative. You continually research and evaluate emerging technologies. You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them.
• Creative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You’re not afraid to share a new idea.
• A leader. You challenge conventional thinking and work with stakeholders to identify and improve the status quo. You're passionate about talent development for your own team and beyond.
• Technical. You’re comfortable with advanced ML and DL technologies including language models and are passionate about developing further. You have hands-on experience working with LLMs and solutions using open-source tools and cloud computing platforms.
• Influential. You are passionate about AI/ML and can bring along a cross functional team in breakthrough innovations. You communicate clearly and effectively to share your findings with non-technical audiences.
• You are experienced in training language models or large computer vision models as well as have expertise in one or more key subdomains such as: training optimization, self-supervised learning, explainability, RLHF.
• You have an engineering mindset as shown by a track record of delivering models at scale both in training data and inference volumes. You have experience in delivering libraries, platforms, or solution level code to existing products.

Basic Qualifications:
• Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:
• A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 2 years of experience performing data analytics
• A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration

Preferred Qualifications:
• Master’s Degree in “STEM” field (Science, Technology, Engineering, or Mathematics), or PhD in “STEM” field (Science, Technology, Engineering, or Mathematics)
• Experience working with AWS
• At least 2 years’ experience in Python, Scala, or R
• At least 2 years’ experience with machine learning
• At least 2 years’ experience with SQL

Capital One will consider sponsoring a new qualified applicant for employment authorization for this position.

The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.

New York, NY: $145,100 - $165,600 for Sr Assoc, Data Science

San Jose, CA: $145,100 - $165,600 for Sr Assoc, Data Science

Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate’s offer letter.

This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.

Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.

This role is expected to accept applications for a minimum of 5 business days.

No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",2025-07-20T00:00:00.000Z,2025-07-25,"['Customer first', 'You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them', 'You thrive on bringing definition to big, undefined problems', 'You love asking questions and pushing hard to find answers', ""You're passionate about talent development for your own team and beyond"", 'Technical', 'You’re comfortable with advanced ML and DL technologies including language models and are passionate about developing further', 'You have hands-on experience working with LLMs and solutions using open-source tools and cloud computing platforms', 'Influential', 'You are passionate about AI/ML and can bring along a cross functional team in breakthrough innovations', 'You communicate clearly and effectively to share your findings with non-technical audiences', 'You are experienced in training language models or large computer vision models as well as have expertise in one or more key subdomains such as: training optimization, self-supervised learning, explainability, RLHF', 'You have an engineering mindset as shown by a track record of delivering models at scale both in training data and inference volumes', 'You have experience in delivering libraries, platforms, or solution level code to existing products', 'Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:', ""A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 2 years of experience performing data analytics"", ""A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration""]","['You will be the driving force to experiment, innovate and create next generation experiences powered by the latest emerging generative AI technologies', 'Partner with a cross-functional team of data scientists, software engineers, machine learning engineers and product managers to deliver AI powered products that change how customers interact with their money', 'Leverage a broad stack of technologies — Pytorch, AWS Ultraclusters, Hugging Face, LangChain, Lightning, VectorDBs, and more — to reveal the insights hidden within huge volumes of numeric and textual data', 'Be the expert in Natural Language Processing (NLP) to harness the power of Large Language Models (LLMs), adapt and finetune them for customer facing applications and features', 'Build machine learning and NLP models through all phases of development, from design through training, evaluation, and validation; partnering with engineering teams to operationalize them in scalable and resilient production systems that serve 80+ million customers', 'Flex your interpersonal skills to translate the complexity of your work into tangible business goals', 'You continually research and evaluate emerging technologies', 'You challenge conventional thinking and work with stakeholders to identify and improve the status quo']",True,"['Large Language Models', 'Generative AI', 'PyTorch', 'Hugging Face', 'LangChain', 'Lightning', 'Vector Databases', 'Training Optimization', 'Self-Supervised Learning', 'Explainability', 'Reinforcement Learning from Human Feedback']","Large Language Models: Harness the power of Large Language Models (LLMs) by adapting and finetuning them for customer-facing applications and features, enabling advanced AI-powered products.; Generative AI: Experiment, innovate, and create next generation experiences powered by the latest emerging generative AI technologies to deliver dynamic and personalized customer experiences.; PyTorch: Use PyTorch as a deep learning framework to build, train, and deploy neural network models, including language models.; Hugging Face: Utilize Hugging Face tools and libraries to access, fine-tune, and deploy transformer-based models and other state-of-the-art AI models.; LangChain: Leverage LangChain framework to build applications powered by language models, enabling integration of LLMs with external data and tools.; Lightning: Use Lightning (PyTorch Lightning) to simplify and accelerate deep learning model development and training workflows.; Vector Databases: Employ vector databases to efficiently store and retrieve high-dimensional embeddings generated by AI models for search and recommendation applications.; Training Optimization: Apply techniques to optimize the training process of large language and computer vision models to improve efficiency and performance.; Self-Supervised Learning: Use self-supervised learning methods to train models on unlabeled data, enhancing model capabilities without requiring extensive labeled datasets.; Explainability: Incorporate explainability techniques to interpret and understand AI model decisions, improving transparency and trust.; Reinforcement Learning from Human Feedback: Implement reinforcement learning from human feedback (RLHF) to fine-tune language models based on human preferences and improve alignment with user needs.","['Machine Learning', 'Natural Language Processing', 'Data Analytics', 'SQL', 'Python', 'Scala', 'R', 'AWS Cloud Computing']","Machine Learning: Build machine learning models through all phases of development, from design through training, evaluation, and validation; partnering with engineering teams to operationalize them in scalable and resilient production systems that serve 80+ million customers.; Natural Language Processing: Be the expert in Natural Language Processing (NLP) to harness the power of Large Language Models, adapt and finetune them for customer facing applications and features.; Data Analytics: Perform data analytics using quantitative skills in statistics, economics, operations research, analytics, mathematics, or computer science, supported by at least 2 years of experience.; SQL: Use SQL for data querying and manipulation as part of the data science and analytics workflow.; Python: Use Python programming language for data science and machine learning tasks, with at least 2 years of experience preferred.; Scala: Use Scala programming language for data science and machine learning tasks, with at least 2 years of experience preferred.; R: Use R programming language for data science and machine learning tasks, with at least 2 years of experience preferred.; AWS Cloud Computing: Leverage AWS cloud computing platforms, including AWS Ultraclusters, to handle large-scale data processing and model training workloads."
M_MpaS5ifiBn0kjBAAAAAA==,Senior Data Scientist Jobs,"ManTech seeks a motivated, career and customer-oriented Senior Data Scientist to join our team in Doral, FL.

Responsibilities include but are not limited to:
• Develop and implement data strategies and frameworks
• Identify data requirements, establish comprehensive data governance policies, and ensure data quality and integrity across the organization
• Design and implement data collection, storage, and retrieval processes to optimize data management and accessibility and conduct complex data analysis and modeling to derive valuable insights and recommendations for program management and decision-making
• Use advanced statistical techniques, data mining, and machine learning algorithms to uncover patterns, trends, and correlations within the data
• Provide actionable insights that drive strategic initiatives and enhance overall program performance. Create advanced reports, dashboards, and visualizations to effectively communicate program performance, KPIs, and trends. Leverage data visualization tools, such as Tableau or Power BI, to present complex data in a clear and concise manner, enabling stakeholders to make informed decisions
• Contribute to the development and implementation of data-driven initiatives, stay up-to-date with the latest advancements in data analytics, emerging technologies, and industry best practices, and ensure the organization remains at the forefront of data management and analysis
• Provide technical expertise in data analytics. Provide direction and mentorship to subordinate staff

Minimum Qualifications:
• Bachelor's degree in relevant field and a minimum of 9 years of relevant experience OR a Master's degree and 7 years of experience OR PhD and 5 years of experience.
• High School diploma and 4 years of additional experience or Associate's Degree and 2 years of additional experience may be exchanged in lieu of a required Bachelor's degree
• Experience in data science, data analysis, or a related field, with a proven track record of successfully developing and implementing data-driven solutions.
• Strong understanding of statistical modeling, machine learning algorithms, and data mining techniques. Proficiency in data analysis tools and languages (e.g., Python with pandas, scikit-learn, R, SQL). Experience with data visualization tools (e.g., Tableau, Power BI) and knowledge of data warehousing and data lake concepts.
• Experience with Big Data technologies (e.g., Hadoop, Spark).
• Experience in developing and implementing data strategies and frameworks. Understanding of data governance principles and best practices. Ability to identify data requirements and ensure data quality and integrity. Experience with data collection, storage, and retrieval processes. Strong analytical and problem-solving skills, with the ability to extract insights from complex data sets. Ability to identify patterns, trends, and correlations in data. Ability to translate data insights into actionable recommendations.
• DoD 8570.01-M IAT Level II certification.

Preferred Qualifications:
• PhD, Master's degree OR Bachelor's degree in Data Science, Information Technology, Cybersecurity, Computer Science, or related field.
• Experience supporting DoD programs and with cloud-based technologies, Risk Management Framework, and Zero Trust Architecture.
• Knowledge of data security and privacy regulations. Experience with data storytelling and presentation skills.
• Experience with advanced analytics techniques (e.g., deep learning, natural language processing). Specialized skills including cloud-based data platforms (e.g., AWS, Azure, GCP). Relevant certifications in data science or data analytics (e.g., Certified Analytics Professional (CAP)).ITIL certification.
• Experience at a DoD Combatant Command (e.g., SOUTHCOM, NORTHCOM, CENTCOM, CYBERCOM, INDOPACOM, EUCOM, AFRICOM, STRATCOM, TRANSCOM, SOCOM, SPACECOM) or a component is desired.

Clearance Requirements:
• Must possess an interim Secret clearance with the ability to obtain a Secret clearance

Physical Requirements:
• The person in this position must be able to remain in a stationary position 50% of the time. Occasionally move about inside the office to access file cabinets, office machinery, or to communicate with co-workers, management, and customers, via email, phone, and or virtual communication, which may involve delivering presentations.",2025-07-19T00:00:00.000Z,2025-07-25,"[""Bachelor's degree in relevant field and a minimum of 9 years of relevant experience OR a Master's degree and 7 years of experience OR PhD and 5 years of experience"", ""High School diploma and 4 years of additional experience or Associate's Degree and 2 years of additional experience may be exchanged in lieu of a required Bachelor's degree"", 'Experience in data science, data analysis, or a related field, with a proven track record of successfully developing and implementing data-driven solutions', 'Strong understanding of statistical modeling, machine learning algorithms, and data mining techniques', 'Proficiency in data analysis tools and languages (e.g., Python with pandas, scikit-learn, R, SQL)', 'Experience with data visualization tools (e.g., Tableau, Power BI) and knowledge of data warehousing and data lake concepts', 'Experience with Big Data technologies (e.g., Hadoop, Spark)', 'Experience in developing and implementing data strategies and frameworks', 'Understanding of data governance principles and best practices', 'Ability to identify data requirements and ensure data quality and integrity', 'Experience with data collection, storage, and retrieval processes', 'Strong analytical and problem-solving skills, with the ability to extract insights from complex data sets', 'Ability to identify patterns, trends, and correlations in data', 'Ability to translate data insights into actionable recommendations', 'DoD 8570.01-M IAT Level II certification', 'Experience with data storytelling and presentation skills', 'Experience with advanced analytics techniques (e.g., deep learning, natural language processing)', 'Specialized skills including cloud-based data platforms (e.g., AWS, Azure, GCP)', 'Relevant certifications in data science or data analytics (e.g., Certified Analytics Professional (CAP)).ITIL certification', 'Must possess an interim Secret clearance with the ability to obtain a Secret clearance', 'The person in this position must be able to remain in a stationary position 50% of the time']","['Develop and implement data strategies and frameworks', 'Identify data requirements, establish comprehensive data governance policies, and ensure data quality and integrity across the organization', 'Design and implement data collection, storage, and retrieval processes to optimize data management and accessibility and conduct complex data analysis and modeling to derive valuable insights and recommendations for program management and decision-making', 'Use advanced statistical techniques, data mining, and machine learning algorithms to uncover patterns, trends, and correlations within the data', 'Provide actionable insights that drive strategic initiatives and enhance overall program performance', 'Create advanced reports, dashboards, and visualizations to effectively communicate program performance, KPIs, and trends', 'Leverage data visualization tools, such as Tableau or Power BI, to present complex data in a clear and concise manner, enabling stakeholders to make informed decisions', 'Contribute to the development and implementation of data-driven initiatives, stay up-to-date with the latest advancements in data analytics, emerging technologies, and industry best practices, and ensure the organization remains at the forefront of data management and analysis', 'Provide technical expertise in data analytics', 'Provide direction and mentorship to subordinate staff', 'Occasionally move about inside the office to access file cabinets, office machinery, or to communicate with co-workers, management, and customers, via email, phone, and or virtual communication, which may involve delivering presentations']",True,"['Deep Learning', 'Natural Language Processing']",Deep Learning: Apply neural network-based advanced analytics techniques to extract insights and enhance data modeling capabilities.; Natural Language Processing: Use AI-driven methods to analyze and interpret human language data as part of advanced analytics initiatives.,"['Data Strategies and Frameworks', 'Data Governance', 'Data Collection, Storage, and Retrieval', 'Advanced Statistical Techniques', 'Data Mining', 'Machine Learning Algorithms', 'Data Analysis Tools and Languages', 'Data Visualization Tools', 'Data Warehousing and Data Lakes', 'Big Data Technologies', 'Statistical Modeling', 'Data Quality and Integrity', 'Analytical and Problem-Solving Skills', 'Data Storytelling and Presentation Skills', 'Advanced Analytics Techniques', 'Cloud-Based Data Platforms']","Data Strategies and Frameworks: Develop and implement organizational approaches to manage and utilize data effectively, ensuring alignment with business goals and data governance policies.; Data Governance: Establish comprehensive policies and practices to ensure data quality, integrity, and compliance across the organization.; Data Collection, Storage, and Retrieval: Design and implement processes to optimize how data is gathered, stored, and accessed to support efficient data management and analysis.; Advanced Statistical Techniques: Apply sophisticated statistical methods to analyze data, uncover patterns, and support decision-making.; Data Mining: Use techniques to explore large datasets to identify patterns, trends, and correlations relevant to program management and strategic initiatives.; Machine Learning Algorithms: Utilize algorithms to build predictive models and uncover insights from data, supporting data-driven decision-making.; Data Analysis Tools and Languages: Proficiency in tools and programming languages such as Python (with pandas and scikit-learn), R, and SQL to perform data manipulation, analysis, and modeling.; Data Visualization Tools: Leverage tools like Tableau and Power BI to create reports, dashboards, and visualizations that communicate complex data insights clearly to stakeholders.; Data Warehousing and Data Lakes: Knowledge of concepts and architectures for storing and managing large volumes of structured and unstructured data to support analytics.; Big Data Technologies: Experience with platforms such as Hadoop and Spark to process and analyze large-scale datasets efficiently.; Statistical Modeling: Develop and apply models to represent data relationships and support predictive analytics.; Data Quality and Integrity: Ensure accuracy, consistency, and reliability of data throughout its lifecycle to support trustworthy analysis and reporting.; Analytical and Problem-Solving Skills: Ability to extract meaningful insights from complex datasets and translate them into actionable recommendations.; Data Storytelling and Presentation Skills: Communicate data-driven insights effectively through narratives and visualizations to influence decision-making.; Advanced Analytics Techniques: Apply sophisticated methods including deep learning and natural language processing to enhance data analysis capabilities.; Cloud-Based Data Platforms: Utilize cloud services such as AWS, Azure, and GCP to support scalable data storage, processing, and analytics."
2GNIxKQ51Ih345PyAAAAAA==,STE - Senior Data Analyst Jobs,"Description

BlueForce Inc. is seeking a Senior Data Analyst in support of HQ USAF Sponsored or Supported Wargaming The Senior Data Analyst will conduct activities to plan, execute, manage, and analyze throughout all phases of HQ USAF wargames including concept development, objective analysis, assessment planning, game design, event planning, management and execution, and post-game analysis. Primary locations are Joint Base Andrews, MD, Joint Base Anacostia-Bolling and The Pentagon.
• **Position is Subject to Contract Award***

Duties and Responsibilities :
• Develops and implements software and database applications to support wargame design, execution, and analysis.
• Manages wargame CoP (e.g. ForceTracker) and coordinates, compiles and updates data (e.g., Operational Order of Battle, Facilities, Installations, etc.) from wargame participants and external data providers (e.g., intelligence community) to ensure accurate representation for wargames.
• Advises principal engineer when updates to software and database applications are required.
• Assists pre-game, concurrent, and/or post-game analysis.

Qualifications

Minimum Qualifications:
• Active TS/SCI security clearance.
• Master's degree or above with a minimum of ten (10) years of experience in modeling, simulations, or operations research analysis.
• Experience developing wargame tools and in providing wargame or operational analysis.
• Excellent communication skills in terms of writing and presenting briefings.

Desired Qualifications:
• Military wargame experience.",2025-07-25T02:00:00.000Z,2025-07-25,"['Active TS/SCI security clearance', ""Master's degree or above with a minimum of ten (10) years of experience in modeling, simulations, or operations research analysis"", 'Experience developing wargame tools and in providing wargame or operational analysis', 'Excellent communication skills in terms of writing and presenting briefings']","['BlueForce Inc. is seeking a Senior Data Analyst in support of HQ USAF Sponsored or Supported Wargaming The Senior Data Analyst will conduct activities to plan, execute, manage, and analyze throughout all phases of HQ USAF wargames including concept development, objective analysis, assessment planning, game design, event planning, management and execution, and post-game analysis', 'Develops and implements software and database applications to support wargame design, execution, and analysis', 'Manages wargame CoP (e.g. ForceTracker) and coordinates, compiles and updates data (e.g., Operational Order of Battle, Facilities, Installations, etc.) from wargame participants and external data providers (e.g., intelligence community) to ensure accurate representation for wargames', 'Advises principal engineer when updates to software and database applications are required', 'Assists pre-game, concurrent, and/or post-game analysis']",False,,,,
OLbn6rBegU2ASEx_AAAAAA==,"Cleared Data Scientists in MD, to 175k - FS Poly Jobs","Who We Are
Stanley Reid is your one-stop shop for connecting with top contractors and exciting IC/DoD opportunities. We're a team of experts who go beyond just finding jobs, providing personalized guidance to match your unique skills and goals to the perfect fit. Our focus? A stress-free job search for you. Let's chat and unlock your career potential!

About Our Client
Forget typical data science firms obsessed with deploying models, our client thrives on unconventional solutions to real-world problems, using massive datasets and open-ended exploration like a research lab. More than technical whizzes, their team values creativity, engagement, and understanding your organization. They prioritize attracting and developing highly skilled minds. With many holding advanced degrees, they foster a culture of continuous learning and encourage pushing boundaries, staying at the forefront of their field. With competitive benefits, a vibrant culture, and multiple locations (including options with TELEWORK), they're ideal for passionate data scientists seeking to collaborate with the best. They don't just analyze, they predict the future - if you want to push boundaries and make a real impact, this might be your perfect match.

The Role
As a Senior Data Scientist, you'll lead research initiatives, proving and implementing groundbreaking solutions to advanced AI problems. Recognized as an expert within the field, you'll spearhead the exploration of new technologies, pushing boundaries and driving impact.

Responsibilities include:
Design and execute cutting-edge research programs.
Develop and demonstrate innovative solutions to complex AI challenges.
Lead a team of engineers/scientists in solution implementation.

What You'll Bring
15+ years of experience in Engineering, Computer Science, or STEM field (or equivalent with advanced degrees).
Proven track record of leading & delivering innovative solutions.
Deep expertise in AI technologies and methodologies.
Exceptional leadership and communication skills.

Clearance Requirements
TS/SCI with FS Polygraph (no clearance upgrades or CCAs). Please note, YOU MUST have the required clearance for consideration.

Location
Fort Meade, MD

Ready for next steps?
Apply online at https://careers.stanleyreid.com/, or contact our MD team for more info: mwhitford@stanleyreid.com, asmith@stanleyreid.com.

We look forward to exploring opportunities with you!

Please note: We are constantly expanding our network of opportunities and do our best to keep our openings current as they open and close. We encourage you to apply and connect with us even if a directly matching role isn't currently listed (or available), as new opportunities arise frequently. Due to the large volume of applications we receive daily, we are not able to individually follow-up to confirm receipt of submitted information or provide other status updates. You will hear from us if there is a match!

Reviewed & reposted (03/12/2025)",2025-07-24T00:00:00.000Z,2025-07-25,"['15+ years of experience in Engineering, Computer Science, or STEM field (or equivalent with advanced degrees)', 'Proven track record of leading & delivering innovative solutions', 'Deep expertise in AI technologies and methodologies', 'Exceptional leadership and communication skills', 'TS/SCI with FS Polygraph (no clearance upgrades or CCAs)', 'Please note, YOU MUST have the required clearance for consideration']","['More than technical whizzes, their team values creativity, engagement, and understanding your organization', 'They prioritize attracting and developing highly skilled minds', ""As a Senior Data Scientist, you'll lead research initiatives, proving and implementing groundbreaking solutions to advanced AI problems"", ""Recognized as an expert within the field, you'll spearhead the exploration of new technologies, pushing boundaries and driving impact"", 'Design and execute cutting-edge research programs', 'Develop and demonstrate innovative solutions to complex AI challenges', 'Lead a team of engineers/scientists in solution implementation']",True,['Advanced AI Technologies'],"Advanced AI Technologies: Developing and demonstrating innovative solutions to complex AI challenges, spearheading exploration of new AI technologies, and pushing boundaries in the AI field.",['Data Science Research'],Data Science Research: Leading research initiatives to explore and implement innovative data-driven solutions using massive datasets and open-ended exploration.
bU7z1i-Xp3rNeGmeAAAAAA==,Lead Data Science With LLM and NLP,"Title-Lead Data Science With LLM and NLP

Location-Mason OH

Mode Of Hire- Contract

Mode Of Work- onsite

Role Summary:

We are hiring a Senior Data Scientist with deep expertise in AI agent architectures, LLMs, NLP, and hands-on development experience with AXA Protocols and Model Context Protocols (MCP).

This role is integral in building interoperable, context-aware, and self-improving agents that interact across clinical, administrative, and benefits platforms.

We are looking for Senior Data Scientist with XX+ Years

Skill X X+ Yers Exp - AI agent architectures, LLMs, NLP developing A2A Protocols and Model Context Protocols (MCP)
Skill X - X+ Yers Exp - LLMs and NLP models (e.g., medical BERT, BioGPT)
SKill X - X+ Yers Exp - retrieval-augmented generation (RAG)
Skill X X+ Yers Exp - coding experience in Python, with proficiency in ML/NLP libraries
Skill X - X+ Yers Exp - healthcare data standards like FHIR, HLX, ICD/CPT, X1X EDI formats.
Skill X - X+ Yers Exp - AWS, Azure, or Google Cloud Platform including Kubernetes, Docker, and CI/CD

Preferred Qualifications
Deep understanding of MCP + VectorDB integration for dynamic agent memory and retrieval.
Prior work on LLM-based agents in production systems or large-scale healthcare operations.
Experience with voice AI, automated care navigation, or AI triage tools.
Published research or patents in agent systems, LLM architectures, or contextual AI frameworks.",2025-07-24T00:00:00.000Z,2025-07-25,"['We are looking for Senior Data Scientist with XX+ Years', 'Skill X X+ Yers Exp - AI agent architectures, LLMs, NLP developing A2A Protocols and Model Context Protocols (MCP)', 'Skill X - X+ Yers Exp - LLMs and NLP models (e.g., medical BERT, BioGPT)', 'SKill X - X+ Yers Exp - retrieval-augmented generation (RAG)', 'Skill X X+ Yers Exp - coding experience in Python, with proficiency in ML/NLP libraries', 'Skill X - X+ Yers Exp - healthcare data standards like FHIR, HLX, ICD/CPT, X1X EDI formats', 'Skill X - X+ Yers Exp - AWS, Azure, or Google Cloud Platform including Kubernetes, Docker, and CI/CD', 'Deep understanding of MCP + VectorDB integration for dynamic agent memory and retrieval', 'Prior work on LLM-based agents in production systems or large-scale healthcare operations', 'Experience with voice AI, automated care navigation, or AI triage tools', 'Published research or patents in agent systems, LLM architectures, or contextual AI frameworks']","['We are hiring a Senior Data Scientist with deep expertise in AI agent architectures, LLMs, NLP, and hands-on development experience with AXA Protocols and Model Context Protocols (MCP)', 'This role is integral in building interoperable, context-aware, and self-improving agents that interact across clinical, administrative, and benefits platforms']",True,"['Large Language Models', 'Natural Language Processing', 'AI Agent Architectures', 'Model Context Protocols', 'Retrieval-Augmented Generation', 'Vector Databases', 'Voice AI and Automated Care Navigation']","Large Language Models: The job involves deep expertise in LLMs including development and deployment of LLM-based agents in production healthcare systems.; Natural Language Processing: Experience with NLP models such as medical BERT and BioGPT is required, focusing on AI agent architectures and contextual understanding.; AI Agent Architectures: The role focuses on building interoperable, context-aware, and self-improving AI agents that operate across clinical, administrative, and benefits platforms.; Model Context Protocols: Hands-on development experience with Model Context Protocols (MCP) and AXA Protocols is essential for managing AI agent interactions.; Retrieval-Augmented Generation: Expertise in retrieval-augmented generation (RAG) techniques is required to enhance AI agent memory and retrieval capabilities.; Vector Databases: Deep understanding of VectorDB integration is needed for dynamic agent memory and retrieval in AI systems.; Voice AI and Automated Care Navigation: Experience with voice AI, automated care navigation, and AI triage tools is preferred to support healthcare AI applications.","['Python', 'Healthcare Data Standards', 'Cloud Platforms and DevOps Tools']","Python: The role requires coding experience in Python with proficiency in machine learning and NLP libraries.; Healthcare Data Standards: Experience with healthcare data standards such as FHIR, HLX, ICD/CPT, and X12 EDI formats is required.; Cloud Platforms and DevOps Tools: Proficiency in AWS, Azure, or Google Cloud Platform including Kubernetes, Docker, and CI/CD pipelines is necessary."
54AX23B3l6L8myBvAAAAAA==,Senior Technology Consultant- Data Science - CTJ- Poly Jobs,"We are looking to hire a Senior Technology Consultant - Data Science to join Microsoft Federal.

Microsoft is on a mission to empower every person and every organization on the planet to achieve more. Our culture is centered on embracing a growth mindset, a theme of inspiring excellence, and encouraging teams and leaders to bring their best each day. Growth mindset encourages each of us to lean in and learn what matters most to our customers, to create the foundational knowledge that enables us to make customer-first decisions in everything we do. In doing so, we create life-changing innovations that impact billions of lives around the world. You can help us achieve our mission.

The Microsoft Federal organization was established to address the unique mission, legal/regulatory requirements, and procurement rules and processes of the United States Government (USG). Microsoft Federal is committed to ensuring its resources - including appropriately qualified, experienced, and certified personnel (with necessary security clearances or otherwise) are available as needed to meet USG evolving needs. To that end, Microsoft embraces, as a mission-critical philosophy, flexibility in the recruiting, hiring, and workforce assignment of Microsoft Federal personnel. Microsoft Federal personnel can expect to serve in various roles in the Microsoft Federal organization during the course of their career to meet evolving USG needs, regardless of segment - Civilian, Defense, or intelligence community.

Are you ready to seize and opportunity to build advanced Artificial Intelligence (AI) and Machine Learning (ML) solutions leveraging the robust capabilities of the Microsoft Azure cloud? Do you thrive on taking a customer's vision from brainstorming on a white board to operational capability that drives Digital Transformation? If so, then the Delivery Data Scientist role in Microsoft Consulting is the right career for you!

Responsibilities

Our Delivery Data Scientists work within a team of project managers, solution architects and consultants to deliver Azure cloud AI/ML consulting engagements; typical responsibilities include:
• Educating our customers and partners on the power of AI/ML using the Azure Cloud
• Interacting with senior executives and key stakeholders in our customers to formulate AI/ML solutions that address challenges facing their organizations
• Developing and maintaining a high level of technical proficiency in Azure AI/ML cloud services
• Creating and sharing IP that leverages AI/ML Azure cloud services
• Other
• Embody our culture and values

Qualifications

Required/Minimum Qualifications:
• Bachelor's Degree in Computer Science , Engineering, Finance, Business, or related field AND 3+ years leadership experience in relevant area of business
• OR equivalent experience.

Other Requirements:

Security Clearance Requirements: Candidates must be able to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings:
• The successful candidate must have an active U.S. Government Top Secret Clearance with access to Sensitive Compartmented Information (SCI) based on a Single Scope Background Investigation (SSBI) with Polygraph. Ability to meet Microsoft, customer and/or government security screening requirements are required for this role. Failure to maintain or obtain the appropriate U.S. Government clearance and/or customer screening requirements may result in employment action up to and including termination.
• Clearance Verification: This position requires successful verification of the stated security clearance to meet federal government customer requirements. You will be asked to provide clearance verification information prior to an offer of employment.
• Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter.
• Citizenship & Citizenship Verification: This position requires verification of U.S. citizenship due to citizenship-based legal restrictions. Specifically, this position supports United States federal, state, and/or local United States government agency customer and is subject to certain citizenship-based restrictions where required or permitted by applicable law. To meet this legal requirement, citizenship will be verified via a valid passport, or other approved documents, or verified US government Clearance

Additional/Preferred Qualifications:
• Microsoft Development Experience such as C# Software development, .NET framework, Power Shell, SQL Server, JavaScript/HTML, Active Directory, Identity Management, Code troubleshooting
• Technical certifications based on domain (e.g., Azure, SharePoint).M365/O365, SharePoint, CoPilot, Teams
• Azure (Networking, Infrastructure, App Dev, Identity, Active Directory, Azure Stack, etc.)
• Business Applications (Dynamics 365, CRM, etc.)
• Data & AI (SQL, Azure SQL, Azure Data Factory, PowerBI, etc.)
• Identity & Networking (Azure, MIM, O365, etc.)
• Infrastructure (Win10, WVD, MECM, SCCM, etc.)
• Intelligent Communications (Teams, Exchange, Skype for Business, etc.)
• Modern Service Management/Adoption Change Management (MSM/ACM)
• PowerApps/Power Platform
• Project (Project Server Customization, Test, and Implementation)
• UX/UI & Accessibility
• Security & Identity (Sentinel, Azure Security Center, Microsoft Defender for Cloud)

Technology Consulting IC4 - The typical base pay range for this role across the U.S. is USD $100,000 - $193,800 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $126,100 - $204,000 per year.

Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here: https://careers.microsoft.com/us/en/us-corporate-pay

Microsoft will accept applications for the role until July 28th, 2025.

Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form .

Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.

#MCAPSA",2025-07-17T00:00:00.000Z,2025-07-25,"[""Bachelor's Degree in Computer Science , Engineering, Finance, Business, or related field AND 3+ years leadership experience in relevant area of business"", 'OR equivalent experience', 'Security Clearance Requirements: Candidates must be able to meet Microsoft, customer and/or government security screening requirements are required for this role', 'The successful candidate must have an active U.S. Government Top Secret Clearance with access to Sensitive Compartmented Information (SCI) based on a Single Scope Background Investigation (SSBI) with Polygraph', 'Ability to meet Microsoft, customer and/or government security screening requirements are required for this role', 'Failure to maintain or obtain the appropriate U.S. Government clearance and/or customer screening requirements may result in employment action up to and including termination', 'Clearance Verification: This position requires successful verification of the stated security clearance to meet federal government customer requirements', 'You will be asked to provide clearance verification information prior to an offer of employment', 'Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter', 'Citizenship & Citizenship Verification: This position requires verification of U.S. citizenship due to citizenship-based legal restrictions', 'Specifically, this position supports United States federal, state, and/or local United States government agency customer and is subject to certain citizenship-based restrictions where required or permitted by applicable law', 'To meet this legal requirement, citizenship will be verified via a valid passport, or other approved documents, or verified US government Clearance']","['Our Delivery Data Scientists work within a team of project managers, solution architects and consultants to deliver Azure cloud AI/ML consulting engagements; typical responsibilities include:', 'Educating our customers and partners on the power of AI/ML using the Azure Cloud', 'Interacting with senior executives and key stakeholders in our customers to formulate AI/ML solutions that address challenges facing their organizations', 'Developing and maintaining a high level of technical proficiency in Azure AI/ML cloud services', 'Creating and sharing IP that leverages AI/ML Azure cloud services', 'Embody our culture and values']",True,"['Azure AI Services', 'Artificial Intelligence', 'Machine Learning on Azure']","Azure AI Services: The role requires developing and maintaining technical proficiency in Azure AI cloud services to build and deliver AI/ML solutions for customers.; Artificial Intelligence: The position focuses on building advanced AI solutions leveraging Azure cloud capabilities to help customers achieve digital transformation and solve organizational challenges.; Machine Learning on Azure: The job involves consulting on machine learning solutions using Azure cloud services, including educating customers and formulating AI/ML strategies tailored to their needs.","['Machine Learning', 'Azure Data Factory', 'SQL', 'Power BI', 'Data & AI']","Machine Learning: The role involves delivering consulting engagements that leverage machine learning capabilities on the Azure cloud to address customer challenges and drive digital transformation.; Azure Data Factory: Experience with Azure Data Factory is preferred, indicating involvement in building and managing data pipelines within the Azure cloud environment.; SQL: SQL Server knowledge is preferred, highlighting the importance of querying and managing relational databases as part of data-related tasks.; Power BI: Power BI is mentioned as a preferred skill, suggesting responsibilities related to creating business intelligence dashboards and visualizations to support data-driven decision making.; Data & AI: The job requires proficiency in data and AI technologies on Azure, including SQL, Azure SQL, Azure Data Factory, and Power BI, to build and deploy data science and analytics solutions."
ZLVc42U-lOpMGFNIAAAAAA==,Senior Data Analyst Jobs,"JANUS Research Group is seeking a Senior Data Analyst in support of HQ USAF Sponsored or Supported Wargaming The Senior Data Analyst will conduct activities to plan, execute, manage, and analyze throughout all phases of HQ USAF wargames including concept development, objective analysis, assessment planning, game design, event planning, management and execution, and post-game analysis. Primary locations are Joint Base Andrews, MD, Joint Base Anacostia-Bolling and The Pentagon.
• **Position is Subject to Contract Award***

Duties and Responsibilities:
• Develops and implements software and database applications to support wargame design, execution, and analysis.
• Manages wargame CoP (e.g. ForceTracker) and coordinates, compiles and updates data (e.g., Operational Order of Battle, Facilities, Installations, etc.) from wargame participants and external data providers (e.g., intelligence community) to ensure accurate representation for wargames.
• Advises principal engineer when updates to software and database applications are required.
• Assists pre-game, concurrent, and/or post-game analysis.

Qualifications

Minimum Qualifications:
• Active TS/SCI security clearance.
• Master's degree or above with a minimum of ten (10) years of experience in modeling, simulations, or operations research analysis.
• Experience developing wargame tools and in providing wargame or operational analysis.
• Excellent communication skills in terms of writing and presenting briefings.

Desired Qualifications:
• Military wargame experience.

Benefits: 401(k), Paid Time Off (PTO), Paid Holidays, Medical and Dental Plans, Life and Disability insurance, Education Assistance (and more).

JANUS strives to provide opportunities for career growth through training and development. We also offer an attractive comprehensive benefit package to include health and welfare plans and financial products. As part of a total rewards program, employees can benefit from our referral bonus program, and other various employee awards. JANUS Research Group takes pride in our benefit package and rewards program which has earned us the certification of a Great Place to Work™

JANUS Research Group provides reasonable accommodation so that qualified applicants with a disability may participate in the selection process. Please advise us of any accommodations you request to express interest in a position by e-mailing: Alisha Pollard, Director of Human Resources at alisha.pollard@janusresearch.com or calling (706) 364-9100. Please state your request for assistance in your message. Only reasonable accommodation requests related to applying for a specific position within JANUS Research Group will be reviewed at the e-mail address and phone number supplied. Thank you for considering a career with JANUS Research Group.

JANUS Research Group participates in the Electronic Employment Verification Program. Please click the E-Verify link below for more information.

E-Verify

JANUS Research Group is an equal opportunity/ affirmative action employer. It is company policy to provide equal opportunity in all areas of employment practice without regard to race, color, religion, sex, sexual orientation, national origin, age, marital status, veteran status, citizenship, or disability.

This contractor and subcontractor shall abide by the requirements of 41 CFR 60-1.4(a), 60-300.5(a) and 60-741.5(a). These regulations prohibit discrimination against qualified individuals based on their status as protected veterans or individuals with disabilities and prohibit discrimination against all individuals based on their race, color, religion, sex, or national origin. Moreover, these regulations require that covered prime contractors and subcontractors take affirmative action to employ and advance in employment qualified individuals without regard to race, color, religion, sex, national origin, protected veteran status or disability.",2025-07-22T00:00:00.000Z,2025-07-25,"['Active TS/SCI security clearance', ""Master's degree or above with a minimum of ten (10) years of experience in modeling, simulations, or operations research analysis"", 'Experience developing wargame tools and in providing wargame or operational analysis', 'Excellent communication skills in terms of writing and presenting briefings']","['JANUS Research Group is seeking a Senior Data Analyst in support of HQ USAF Sponsored or Supported Wargaming The Senior Data Analyst will conduct activities to plan, execute, manage, and analyze throughout all phases of HQ USAF wargames including concept development, objective analysis, assessment planning, game design, event planning, management and execution, and post-game analysis', 'Develops and implements software and database applications to support wargame design, execution, and analysis', 'Manages wargame CoP (e.g. ForceTracker) and coordinates, compiles and updates data (e.g., Operational Order of Battle, Facilities, Installations, etc.) from wargame participants and external data providers (e.g., intelligence community) to ensure accurate representation for wargames', 'Advises principal engineer when updates to software and database applications are required', 'Assists pre-game, concurrent, and/or post-game analysis']",False,,,,
7rVkGrihy04aQlXdAAAAAA==,Senior Data Scientist (Risk & Compliance),"Description:
• *100% Remote**

Our client, an industry leader in financial services and money transfers, has an excellent opportunity for a Senior Data Scientist (Risk & Compliance) to work on a 6+ month contract opportunity. Work will be remote, candidates local to Denver preferred. The Senior Data Scientist will manage the entire lifecycle of data science projects, from conception to deployment, while also mentoring junior team members and collaborating with other departments. You are responsible for developing and implementing advanced statistical and machine learning models, creating reports and presentations, and communicating findings to stakeholders. You will also play a key role in driving data-informed decision-making and contributing to the strategic direction of the organization.

Due to client requirement, applicants must be willing and able to work on a w2 basis. For our w2 consultants, we offer a great benefits package that includes Medical, Dental, and Vision benefits, 401k with company matching, and life insurance.

Rate: $75 - $87 / hr. w2

Responsibilities:
• Project Management: Leading and managing end to end data science projects, defining objectives, define requirements, and ensuring timely delivery.
• Model Development & Implementation: Developing and validating machine learning and statistical models, implementing predictive models, and optimizing existing ones.
• Data Analysis & Insights: Analyzing large datasets, identifying trends and patterns, and extracting actionable insights to inform business decisions.
• Collaboration & Communication: Working with cross-functional teams and stakeholders, including engineering, product, and business stakeholders, to translate complex data into actionable strategies.
• Mentorship & Guidance: Providing guidance and mentorship to junior data scientists, sharing expertise, and fostering their professional growth.
• Staying Updated: Keeping abreast of the latest advancements in data science and AI, exploring new tools and techniques, and identifying opportunities for innovation.
• Strategic Input: Contributing to the development of data-driven strategies and providing input on technical approaches for projects.

Experience Requirements:
• 5+ years of industry experience in applied machine learning, with 2+ years focused on deep learning and neural network applications.
• Experience in Banking, Payments or Financial Services leading in detecting and preventing digital fraud, scams and social engineering.
• Able to quickly understand our current Risk Models with the goal of building a flexible AI solution that partners with our current risk tools to maintains our high standards for Risk Prevention and Compliance while providing flexibility to effectively run our business.
• Expertise in statistical modeling, machine learning algorithms, and data mining techniques.
• Experience navigating difficult scenarios developing and implementing execution ideas with minimal guidance.
• Proficiency in programming languages like Python or R.

Education Requirements:
• Bachelor's degree in Computer Science, Statistics, Applied Math, or related field (Master's or PhD strongly preferred).

Skills, experience, and other compensable factors will be considered when determining pay rate. The pay range provided in this posting reflects a W2 hourly rate; other employment options may be available that may result in pay outside of the provided range.

W2 employees of Eliassen Group who are regularly scheduled to work 30 or more hours per week are eligible for the following benefits: medical (choice of 3 plans), dental, vision, pre-tax accounts, other voluntary benefits including life and disability insurance, 401(k) with match, and sick time if required by law in the worked-in state/locality.
Please be advised- If anyone reaches out to you about an open position connected with Eliassen Group, please confirm that they have an Eliassen.com email address and never provide personal or financial information to anyone who is not clearly associated with Eliassen Group. If you have any indication of fraudulent activity, please contact

About Eliassen Group:

Eliassen Group is a leading strategic consulting company for human-powered solutions. For over 30 years, Eliassen has helped thousands of companies reach further and achieve more with their technology solutions, financial, risk & compliance, and advisory solutions, and clinical solutions. With offices from coast to coast and throughout Europe, Eliassen provides a local community presence, balanced with international reach. Eliassen Group strives to positively impact the lives of their employees, clients, consultants, and the communities in which they operate.

Eliassen Group is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.

Don't miss out on our referral program! If we hire a candidate that you refer us to then you can be eligible for a $1,000 referral check!",2025-07-14T00:00:00.000Z,2025-07-25,"['Due to client requirement, applicants must be willing and able to work on a w2 basis', '5+ years of industry experience in applied machine learning, with 2+ years focused on deep learning and neural network applications', 'Experience in Banking, Payments or Financial Services leading in detecting and preventing digital fraud, scams and social engineering', 'Able to quickly understand our current Risk Models with the goal of building a flexible AI solution that partners with our current risk tools to maintains our high standards for Risk Prevention and Compliance while providing flexibility to effectively run our business', 'Expertise in statistical modeling, machine learning algorithms, and data mining techniques', 'Experience navigating difficult scenarios developing and implementing execution ideas with minimal guidance', 'Proficiency in programming languages like Python or R']","['Work will be remote, candidates local to Denver preferred', 'The Senior Data Scientist will manage the entire lifecycle of data science projects, from conception to deployment, while also mentoring junior team members and collaborating with other departments', 'You are responsible for developing and implementing advanced statistical and machine learning models, creating reports and presentations, and communicating findings to stakeholders', 'You will also play a key role in driving data-informed decision-making and contributing to the strategic direction of the organization', 'Project Management: Leading and managing end to end data science projects, defining objectives, define requirements, and ensuring timely delivery', 'Model Development & Implementation: Developing and validating machine learning and statistical models, implementing predictive models, and optimizing existing ones', 'Data Analysis & Insights: Analyzing large datasets, identifying trends and patterns, and extracting actionable insights to inform business decisions', 'Collaboration & Communication: Working with cross-functional teams and stakeholders, including engineering, product, and business stakeholders, to translate complex data into actionable strategies', 'Mentorship & Guidance: Providing guidance and mentorship to junior data scientists, sharing expertise, and fostering their professional growth', 'Staying Updated: Keeping abreast of the latest advancements in data science and AI, exploring new tools and techniques, and identifying opportunities for innovation', 'Strategic Input: Contributing to the development of data-driven strategies and providing input on technical approaches for projects']",True,['Deep Learning'],"Deep Learning: Applying deep learning and neural network techniques for advanced modeling in fraud detection, scams, and social engineering prevention within financial services.","['Machine Learning', 'Statistical Modeling', 'Data Analysis', 'Risk Models', 'Python', 'R']","Machine Learning: Developing and validating machine learning models to support risk and compliance functions, including predictive modeling and optimization of existing models.; Statistical Modeling: Applying advanced statistical models to analyze data and support decision-making in risk prevention and compliance.; Data Analysis: Analyzing large datasets to identify trends, patterns, and actionable insights that inform business decisions and strategic direction.; Risk Models: Understanding and enhancing current risk models to build flexible solutions that maintain high standards for risk prevention and compliance.; Python: Using Python programming language for implementing machine learning and statistical models as part of data science projects.; R: Utilizing R programming language for statistical analysis and model development in risk and compliance contexts."
FhX3tdkq7XTgImwEAAAAAA==,Sr Data Scientist - Merchandise Scaling (Applied ML),"The pay range is $95,000.00 - $171,000.00

Pay is based on several factors which vary based on position. These include labor markets and in some instances may include education, work experience and certifications. In addition to your pay, Target cares about and invests in you as a team member, so that you can take care of yourself and your family. Target offers eligible team members and their dependents comprehensive health benefits and programs, which may include medical, vision, dental, life insurance and more, to help you and your family take care of your whole selves. Other benefits for eligible team members include 401(k), employee discount, short term disability, long term disability, paid sick leave, paid national holidays, and paid vacation. Find competitive benefits from financial and education to well-being and beyond at ;br>
JOIN TARGET AS A SENIOR DATA SCIENTIST - MERCH SCALING

About us:

Working at Target means helping all families discover the joy of everyday life. We bring that vision to life through our values and culture. Learn more about Target here.

A role with Target Data Sciences means the chance to help develop and manage state of the art predictive algorithms that use data at scale to automate and optimize decisions at scale. Whether you join our Statistics, Optimization or Machine Learning teams, you'll be challenged to harness Target's impressive data breadth to build the algorithms that power solutions our partners in Marketing, Supply Chain Optimization, Network Security and Personalization rely on.

Every Scientist on Target's Data Sciences team can expect modeling and data science, software/product development of highly performant code for Model Performance, to elevate Target's culture, and apply retail domain knowledge.

As Sr Data Scientist, you will join a Target Tech team responsible for Merchandising Assortment Data Science products. You will collaborate with Product, Tech, and business partners to solve retail challenges at scale for our merchandising organization. You will design, develop, deploy, and maintain data science models and tools. You'll work closely with data scientists, engineers, and business partners to continuously learn and address evolving business needs. You'll also collaborate with product and engineering partners on peer teams to build and productionize enterprise merchandising solutions.

Core responsibilities of this job are articulated within this job description. Job duties may change at any time due to business needs.

About you:
• PhD/MS/BS in Applied Mathematics, Statistics, Operations Research, Industrial Engineering, Physics, Computer Science or related quantitative field
• 3 plus years of experience cleaning, transforming and analyzing large datasets for insights leading to business improvements
• Experience developing, testing, and maintaining large codebases in a collaborative environment while meeting industry best practices
• Demonstrated knowledge of mathematical and statistical concepts, data structures, algorithm design, data analysis, optimization, simulations and visualizations applied to business problems
• Good working knowledge of Python for machine learning - including supervised and unsupervised methods and their applications
• Experience deploying solutions with large-scale business impact
• Self-driven and results-oriented, with the ability to meet tight timelines
• Strong team player with the ability to collaborate across geographies/time zones
• Excellent written and verbal communication skills

This position will operate as a Hybrid/Flex for Your Day work arrangement based on Target's needs. A Hybrid/Flex for Your Day work arrangement means the team member's core role will need to be performed both onsite at the Target HQ MN location the role is assigned to and virtually, depending upon what your role, team and tasks require for that day. Work duties cannot be performed outside of the country of the primary work location, unless otherwise prescribed by Target. Click here if you are curious to learn more about Minnesota.

Benefits Eligibility
Please paste this url into your preferred browser to learn about benefits eligibility for this role: _D

Americans with Disabilities Act (ADA)

In compliance with state and federal laws, Target will make reasonable accommodations for applicants with disabilities. If a reasonable accommodation is needed to participate in the job application or interview process, please reach out to

Application deadline is : 09/28/2025",2025-07-11T00:00:00.000Z,2025-07-25,"['PhD/MS/BS in Applied Mathematics, Statistics, Operations Research, Industrial Engineering, Physics, Computer Science or related quantitative field', '3 plus years of experience cleaning, transforming and analyzing large datasets for insights leading to business improvements', 'Experience developing, testing, and maintaining large codebases in a collaborative environment while meeting industry best practices', 'Demonstrated knowledge of mathematical and statistical concepts, data structures, algorithm design, data analysis, optimization, simulations and visualizations applied to business problems', 'Good working knowledge of Python for machine learning - including supervised and unsupervised methods and their applications', 'Experience deploying solutions with large-scale business impact', 'Self-driven and results-oriented, with the ability to meet tight timelines', 'Strong team player with the ability to collaborate across geographies/time zones', 'Excellent written and verbal communication skills', ""This position will operate as a Hybrid/Flex for Your Day work arrangement based on Target's needs""]","['A role with Target Data Sciences means the chance to help develop and manage state of the art predictive algorithms that use data at scale to automate and optimize decisions at scale', ""Whether you join our Statistics, Optimization or Machine Learning teams, you'll be challenged to harness Target's impressive data breadth to build the algorithms that power solutions our partners in Marketing, Supply Chain Optimization, Network Security and Personalization rely on"", ""Every Scientist on Target's Data Sciences team can expect modeling and data science, software/product development of highly performant code for Model Performance, to elevate Target's culture, and apply retail domain knowledge"", 'As Sr Data Scientist, you will join a Target Tech team responsible for Merchandising Assortment Data Science products', 'You will collaborate with Product, Tech, and business partners to solve retail challenges at scale for our merchandising organization', 'You will design, develop, deploy, and maintain data science models and tools', ""You'll work closely with data scientists, engineers, and business partners to continuously learn and address evolving business needs"", ""You'll also collaborate with product and engineering partners on peer teams to build and productionize enterprise merchandising solutions"", 'Core responsibilities of this job are articulated within this job description', 'Job duties may change at any time due to business needs', ""A Hybrid/Flex for Your Day work arrangement means the team member's core role will need to be performed both onsite at the Target HQ MN location the role is assigned to and virtually, depending upon what your role, team and tasks require for that day""]",True,[],,"['Predictive Modeling', 'Supervised and Unsupervised Learning', 'Data Cleaning and Transformation', 'Algorithm Design and Optimization', 'Data Science Model Development and Deployment', 'Statistical Analysis and Simulations', 'Collaborative Software Development']","Predictive Modeling: Develop and manage state-of-the-art predictive algorithms that use data at scale to automate and optimize decisions in merchandising and other business areas.; Supervised and Unsupervised Learning: Apply supervised and unsupervised machine learning methods using Python to solve retail challenges and improve merchandising assortment products.; Data Cleaning and Transformation: Clean, transform, and analyze large datasets to generate insights that lead to business improvements in merchandising and retail operations.; Algorithm Design and Optimization: Utilize mathematical and statistical concepts, algorithm design, and optimization techniques to address business problems and improve model performance.; Data Science Model Development and Deployment: Design, develop, deploy, and maintain data science models and tools for enterprise merchandising solutions with large-scale business impact.; Statistical Analysis and Simulations: Apply statistical concepts, data analysis, simulations, and visualizations to support decision-making and optimize merchandising strategies.; Collaborative Software Development: Develop, test, and maintain large codebases in a collaborative environment following industry best practices to support data science and machine learning projects."
msyDjsdH77JYpdO3AAAAAA==,"Principal Associate, Data Scientist, Model Risk Office","Principal Associate, Data Scientist, Model Risk Office

Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making. As a Data Scientist at Capital One, you’ll be part of a team that’s leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives.

In Capital One’s Model Risk Office, we defend the company against model failures and find new ways of making better decisions with models. We use our statistics, software engineering, and business expertise to drive the best outcomes in both Risk Management and the Enterprise. We understand that we can’t prepare for tomorrow by focusing on today, so we invest in the future: investing in new skills, building better tools, and maintaining a network of trusted partners. We learn from past mistakes, and develop increasingly powerful techniques to avoid their repetition.

In this role, you will:
• Partner with a cross-functional team of data scientists, software engineers, and product managers to identify and quantify risks associated with models
• Leverage a broad stack of technologies — Python, Conda, AWS, Spark, and more — to reveal the insights hidden within data
• Build statistical/machine learning models to challenge “champion models” that are deployed in production today
• Contribute to the model governance of the next generation of machine learning models
• Flex your interpersonal skills to present how model risks could impact the business to executives

The Ideal Candidate is:
• Innovative. You continually research and evaluate emerging technologies. You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them.
• Creative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You’re not afraid to share a new idea.
• Technical. You’re comfortable with open-source languages and are passionate about developing further. You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms.
• Statistically-minded. You’ve built models, validated them, and backtested them. You know how to interpret a confusion matrix or a ROC curve. You have experience with clustering, classification, sentiment analysis, time series, and deep learning.
• A data guru. “Big data” doesn’t faze you. You have the skills to retrieve, combine, and analyze data from a variety of sources and structures. You know understanding the data is often the key to great data science.

Basic Qualifications:
• Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:
• A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 5 years of experience performing data analytics
• A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 3 years of experience performing data analytics
• A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field)

Preferred Qualifications:
• Master’s Degree in “STEM” field (Science, Technology, Engineering, or Mathematics) plus 3 years of experience in data analytics, or PhD in “STEM” field (Science, Technology, Engineering, or Mathematics)
• At least 1 year of experience working with AWS
• At least 3 years’ experience in Python, Scala, or R
• At least 3 years’ experience with machine learning
• At least 3 years’ experience with SQL

Capital One will consider sponsoring a new qualified applicant for employment authorization for this position.

This role is Hybrid, with associates expected to consistently spend three days per week in the office.

The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.

McLean, VA: $158,600 - $181,000 for Princ Associate, Data Science

Richmond, VA: $144,200 - $164,600 for Princ Associate, Data Science

Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate’s offer letter.

This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.

Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.

This role is expected to accept applications for a minimum of 5 business days.

No agencies please. Capital One is an equal opportunity employer (EOE, including disability/vet) committed to non-discrimination in compliance with applicable federal, state, and local laws. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",2025-07-07T00:00:00.000Z,2025-07-25,"['You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them', 'You thrive on bringing definition to big, undefined problems', 'You love asking questions and pushing hard to find answers', 'You’re comfortable with open-source languages and are passionate about developing further', 'You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms', 'Statistically-minded', 'You know how to interpret a confusion matrix or a ROC curve', 'You have experience with clustering, classification, sentiment analysis, time series, and deep learning', 'A data guru', 'You have the skills to retrieve, combine, and analyze data from a variety of sources and structures', 'You know understanding the data is often the key to great data science', 'Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:', ""A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 5 years of experience performing data analytics"", ""A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 3 years of experience performing data analytics"", 'A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field)', 'Capital One will consider sponsoring a new qualified applicant for employment authorization for this position']","['Partner with a cross-functional team of data scientists, software engineers, and product managers to identify and quantify risks associated with models', 'Leverage a broad stack of technologies — Python, Conda, AWS, Spark, and more — to reveal the insights hidden within data', 'Build statistical/machine learning models to challenge “champion models” that are deployed in production today', 'Contribute to the model governance of the next generation of machine learning models', 'Flex your interpersonal skills to present how model risks could impact the business to executives', 'You continually research and evaluate emerging technologies', 'You’ve built models, validated them, and backtested them', 'This role is Hybrid, with associates expected to consistently spend three days per week in the office']",True,[],,"['Statistical Modeling', 'Machine Learning Models', 'Model Validation and Backtesting', 'Clustering', 'Classification', 'Sentiment Analysis', 'Time Series Analysis', 'Deep Learning', 'Python', 'Conda', 'AWS (Amazon Web Services)', 'Spark', 'SQL', 'Model Governance']","Statistical Modeling: Used to build and validate models that assess and quantify risks associated with financial products, supporting decision-making in risk management.; Machine Learning Models: Built and validated to challenge existing production models and contribute to next-generation model governance within the Model Risk Office.; Model Validation and Backtesting: Performed to ensure the accuracy and reliability of models, including interpreting confusion matrices and ROC curves to assess model performance.; Clustering: Applied as a statistical method to group data points for analysis and model development in risk assessment.; Classification: Used as a supervised learning technique to categorize data for predictive modeling and risk evaluation.; Sentiment Analysis: Employed as part of data science solutions to analyze textual data and extract insights relevant to model risk and decision-making.; Time Series Analysis: Utilized to analyze sequential data over time for forecasting and risk modeling purposes.; Deep Learning: Experience with deep learning techniques is noted, likely applied to complex data modeling tasks within the risk office.; Python: Used as a primary programming language for developing data science solutions, building models, and data analysis.; Conda: Utilized as a package and environment management system to support Python-based data science workflows.; AWS (Amazon Web Services): Leveraged as a cloud computing platform to handle big data processing, storage, and model deployment.; Spark: Used for big data processing and analytics to manage and analyze large-scale datasets efficiently.; SQL: Applied to retrieve, combine, and analyze data from various structured sources as part of data preparation and analysis.; Model Governance: Involved in overseeing and managing the lifecycle and compliance of machine learning models to ensure their reliability and regulatory adherence."
L5wOvziyLx6DO_acAAAAAA==,Data Scientist,"Job Family:
Data Science Consulting

Travel Required:
None

Clearance Required:
Active Top Secret SCI (TS/SCI)

What You Will Do:

This Data Scientist role will work as part of a Data & AI consulting team to support data visualization, business analytics, data management, and digital engineering processes for major Program Executive Offices (PEOs) at the National Geospatial-Intelligence Agency (NGA). A strong understanding of data visualization is essential to help the PEOs understand how to effectively monitor their operations through reporting dashboards, tools, and the creation of data sets. This role will be located on client site and requires excellent communication skills to coordinate status updates and visualization or digital engineering initiatives. Seeking a candidate with the ability to proactively identify program needs and help the office mature its operational reporting, business analytics, and data processes in line with technology/data solutions advancement. Specific duties will include:
• Integrate, develop, and maintain analytic visualizations and tools to evaluate and communicate office statoperations.
• Work with multiple types of data sources, such as Jira, Excel, and SQL databases to develop visualizations; work with data at varying maturity levels and create relationships between disparate sources to maximize analyses.
• Interpret a wide range of data for the purpose of measuring a major technology program's performance and impact to mission. Help communicate that performance measurement to Senior leaders and inform decisions such as investment/divestment, prioritization, and operational strategies.
• Use storytelling and user interface design methods to develop/maintain Tableau dashboards to address program management needs, catered to specific audience groups. Design dashboards to be visually appealing, intuitive, and user friendly, containing a high volume of information in concise graphics/tables/metrics.
• Manage an inventory of implemented dashboards, other analytic products and current product backlog for implementation.
• Demoing visualizations/analytic products to Agency Senior and program leadership - utilize effective communication skills to convey purpose, use cases applicability, and impact, and solicit feedback for product enhancement.
• Understanding of effective data management and data visualization project documentation such as SOPs, data definitions/dictionaries, data process flows, Confluence pages
• Help evolve program analytics with automation, connecting to unstructured sources, and other Enterprise solutions (such as data format/process to support LLM)

What You Will Need:
• An ACTIVE and MAINTAINED TS/SCI Federal or DoD security clearance; must UPGRADE and MAINTAIN a TS/SCI with a COUNTERINTELLIGENCE (CI) polygraph
• Bachelor's Degree
• Minimum of EIGHT (8) years of working experience
• Demonstrated experience developing visualizations and conducting data analysis
• Demonstrated experience utilizing computer programs, software, or some coding language

What Would Be Nice To Have:
• Demonstrated experience developing visualizations in Tableau
• Demonstrated ability to proactively identify methods and approaches to expand and enhance the analytic capacity.
• Demonstrated experience working with commercial-off-the-shelf (COTS) statistical software or tools for data visualization (i.e., SPSS, SAS, MatLab, etc.).
• Demonstrated experience data mining, to include developing, manipulating, or maintaining databases.
• Experience with Python, MySQL, D3, SPSS, SAS, Visual Basic, or R to summarize statistical data and create documents, reports and presentations.
• Demonstrated experience effectively communicating with various partners, stakeholders, or customers on the value of statistical and data science methods.
• Demonstrated experience embracing and participating in a culture of knowledge sharing to broaden the understanding of advanced methods.
• Understanding and/or experience developing AI/ML or working with AI platform tools

What We Offer:

Guidehouse offers a comprehensive, total rewards package that includes competitive compensation and a flexible benefits package that reflects our commitment to creating a diverse and supportive workplace.

Benefits include:
• Medical, Rx, Dental & Vision Insurance
• Personal and Family Sick Time & Company Paid Holidays
• Position may be eligible for a discretionary variable incentive bonus
• Parental Leave and Adoption Assistance
• 401(k) Retirement Plan
• Basic Life & Supplemental Life
• Health Savings Account, Dental/Vision & Dependent Care Flexible Spending Accounts
• Short-Term & Long-Term Disability
• Student Loan PayDown
• Tuition Reimbursement, Personal Development & Learning Opportunities
• Skills Development & Certifications
• Employee Referral Program
• Corporate Sponsored Events & Community Outreach
• Emergency Back-Up Childcare Program
• Mobility Stipend

About Guidehouse

Guidehouse is an Equal Opportunity Employer-Protected Veterans, Individuals with Disabilities or any other basis protected by law, ordinance, or regulation.

Guidehouse will consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of applicable law or ordinance including the Fair Chance Ordinance of Los Angeles and San Francisco.

If you have visited our website for information about employment opportunities, or to apply for a position, and you require an accommodation, please contact Guidehouse Recruiting at 1- or via email at All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodation.

All communication regarding recruitment for a Guidehouse position will be sent from Guidehouse email domains including @guidehouse.com or Correspondence received by an applicant from any other domain should be considered unauthorized and will not be honored by Guidehouse. Note that Guidehouse will never charge a fee or require a money transfer at any stage of the recruitment process and does not collect fees from educational institutions for participation in a recruitment event. Never provide your banking information to a third party purporting to need that information to proceed in the hiring process.

If any person or organization demands money related to a job opportunity with Guidehouse, please report the matter to Guidehouse's Ethics Hotline. If you want to check the validity of correspondence you have received, please contact Guidehouse is not responsible for losses incurred (monetary or otherwise) from an applicant's dealings with unauthorized third parties.

Guidehouse does not accept unsolicited resumes through or from search firms or staffing agencies. All unsolicited resumes will be considered the property of Guidehouse and Guidehouse will not be obligated to pay a placement fee.",2025-07-20T00:00:00.000Z,2025-07-25,"['An ACTIVE and MAINTAINED TS/SCI Federal or DoD security clearance; must UPGRADE and MAINTAIN a TS/SCI with a COUNTERINTELLIGENCE (CI) polygraph', ""Bachelor's Degree"", 'Minimum of EIGHT (8) years of working experience', 'Demonstrated experience developing visualizations and conducting data analysis', 'Demonstrated experience utilizing computer programs, software, or some coding language', 'Demonstrated experience developing visualizations in Tableau', 'Demonstrated ability to proactively identify methods and approaches to expand and enhance the analytic capacity', 'Demonstrated experience working with commercial-off-the-shelf (COTS) statistical software or tools for data visualization (i.e., SPSS, SAS, MatLab, etc.)', 'Demonstrated experience data mining, to include developing, manipulating, or maintaining databases', 'Experience with Python, MySQL, D3, SPSS, SAS, Visual Basic, or R to summarize statistical data and create documents, reports and presentations', 'Demonstrated experience effectively communicating with various partners, stakeholders, or customers on the value of statistical and data science methods', 'Demonstrated experience embracing and participating in a culture of knowledge sharing to broaden the understanding of advanced methods', 'Understanding and/or experience developing AI/ML or working with AI platform tools']","['This Data Scientist role will work as part of a Data & AI consulting team to support data visualization, business analytics, data management, and digital engineering processes for major Program Executive Offices (PEOs) at the National Geospatial-Intelligence Agency (NGA)', 'A strong understanding of data visualization is essential to help the PEOs understand how to effectively monitor their operations through reporting dashboards, tools, and the creation of data sets', 'This role will be located on client site and requires excellent communication skills to coordinate status updates and visualization or digital engineering initiatives', 'Seeking a candidate with the ability to proactively identify program needs and help the office mature its operational reporting, business analytics, and data processes in line with technology/data solutions advancement', 'Integrate, develop, and maintain analytic visualizations and tools to evaluate and communicate office statoperations', 'Work with multiple types of data sources, such as Jira, Excel, and SQL databases to develop visualizations; work with data at varying maturity levels and create relationships between disparate sources to maximize analyses', ""Interpret a wide range of data for the purpose of measuring a major technology program's performance and impact to mission"", 'Help communicate that performance measurement to Senior leaders and inform decisions such as investment/divestment, prioritization, and operational strategies', 'Use storytelling and user interface design methods to develop/maintain Tableau dashboards to address program management needs, catered to specific audience groups', 'Design dashboards to be visually appealing, intuitive, and user friendly, containing a high volume of information in concise graphics/tables/metrics', 'Manage an inventory of implemented dashboards, other analytic products and current product backlog for implementation', 'Demoing visualizations/analytic products to Agency Senior and program leadership - utilize effective communication skills to convey purpose, use cases applicability, and impact, and solicit feedback for product enhancement', 'Understanding of effective data management and data visualization project documentation such as SOPs, data definitions/dictionaries, data process flows, Confluence pages', 'Help evolve program analytics with automation, connecting to unstructured sources, and other Enterprise solutions (such as data format/process to support LLM)']",True,['Large Language Models'],"Large Language Models: Support data format and process development to integrate with LLMs, indicating involvement with AI platform tools and evolving program analytics to connect with unstructured data sources.","['Data Visualization', 'Business Analytics', 'Data Management', 'SQL', 'Tableau', 'Statistical Software Tools', 'Data Mining', 'Python', 'MySQL', 'D3.js', 'Visual Basic', 'R Programming']","Data Visualization: Develop and maintain analytic visualizations and dashboards using tools like Tableau to monitor operations and communicate program performance to leadership.; Business Analytics: Support business analytics processes to measure program performance, inform decision-making, and enhance analytic capacity.; Data Management: Manage data sources including Jira, Excel, and SQL databases, create relationships between disparate data sources, and maintain data documentation such as SOPs, data dictionaries, and process flows.; SQL: Utilize SQL databases as a data source for developing visualizations and conducting data analysis.; Tableau: Develop and maintain dashboards tailored to specific audience groups, focusing on user interface design and storytelling to present complex data effectively.; Statistical Software Tools: Use commercial off-the-shelf statistical software such as SPSS, SAS, and MatLab for data visualization and analysis.; Data Mining: Develop, manipulate, and maintain databases to extract and summarize statistical data for reporting and presentations.; Python: Employ Python programming for data summarization, analysis, and visualization tasks.; MySQL: Use MySQL databases as part of data management and analysis workflows.; D3.js: Utilize D3.js for creating dynamic and interactive data visualizations.; Visual Basic: Apply Visual Basic programming to support data summarization and reporting.; R Programming: Use R for statistical data analysis and creating reports and presentations."
bmNB0Pq_1UeBMrgkAAAAAA==,Data Scientist Jobs,"ASRC Federal is a leading government contractor furthering missions in space, public health and defense. As an Alaska Native owned corporation, our work helps secure an enduring future for our shareholders. Join our team and discover why we are a top veteran employer and Certified Great Place to Work™

ASRC Federal Business Innovation, LLC is a premier provider of systems engineering, software engineering, system integration and project management services for real-time, mission-critical defense systems. As an Alaska Native owned corporation, our work helps secure an enduring future for our shareholders. Join our team and discover why we are a top veteran employer and Certified Great Place to Work™ .

We are seeking a highly motivated Data Scientist to support our USAF contract on Robbins AFB, GA. This project is in support of the 402d Software Engineering Group (SWEG) at Robins Air Force Base, GA. The Data Scientist supports the 402d SWEG's mission by working closely with engineers, developers, administrators and other technical teams supporting a variety of weapon system platforms and airframes such as the F-15 and F-35 fighters, the B-1B bomber, the C-5 and C-130 cargo planes, the MQ-9 Reaper and the HH-60 Pave Hawk helicopter. All work will be performed on base.

This position offers a $5,000 Sign-On/Referral Bonus.

Responsibilities
• Design and develop sophisticated data models, machine learning algorithms, and AI solutions to address complex engineering and operational challenges within defense systems.
• Implement and integrate machine learning and AI models into production environments, enhancing system capabilities in areas such as predictive analytics, automation, and decision-making processes.
• Work closely with multidisciplinary teams, including software engineers and system architects, to understand requirements, ensure proper data usage, and develop solutions aligned with project goals.

Requirements
• Bachelor's degree or higher in Data Science, Computer Science, or a related field.
• Secret clearance or Interim Secret clearance required to start. ASRC is willing to consider candidates who do not yet have a clearance; however, candidates must obtain an Interim Secret clearance before beginning employment. U.S. citizenship (required).
• A minimum of 5 years of experience in Artificial Intelligence (AI) design, development, and maturation.
• Proven experience in implementing and training machine learning models, including the development and application of generative AI, advanced data analytics, and supervised and unsupervised learning models.
• Experience in deploying AI models to production environments.
• Proficiency in Python programming and experience developing models in a cloud-based environment.
• Ability to work independently at a Senior level, with minimal supervision or assistance from junior staff.

Schedule
• Facilities are open 6am-6pm - you can work with your customer leadership to set hours
• You can flex time during the 2 week pay cycle - avoid using PTO for appointments
• A compressed work schedule may be available at the discretion of work center leadership (i.e. 4/10 or 9/80)

Why ASRC?

As a wholly owned subsidiary of Arctic Slope Regional Corporation, an Alaska Native Corporation, we are inspired by the Iñupiat culture. We embrace stewardship and the idea of using every resource effectively; teamwork when striving to achieve goals and building a collaborative environment; integrity in adhering to high moral principles and professional standards; respect in welcoming and regarding the differing opinions, experiences, rights and traditions of others; accountability in that we meet our commitments and take responsibility for our results; and continuous improvement, always striving to make things better, raising the bar and staying humble.

Advantages of Working at ASRC Federal:
• Purpose-Driven Careers: Join a company recognized as a:
• Certified Great Place to Work
• Military Times' Best for Vets Employer
• Military.com's Top 25 Veteran Employer
• Comprehensive Benefits:
• Insurance Coverage: Comprehensive plans for medical, dental, vision, life insurance, and short-term/long-term disability
• Paid Leave: Inclusive policies for bereavement, military obligations, and parental needs, along with 11 paid holidays annually
• Retirement Savings: A 401(k) plan with a generous company match and immediate vesting to help secure your financial future
• Incentives: Employee referral bonuses to reward you for helping grow the ASRC Federal Family
• Learning and Development:
• After 90 days of employment, regular full-time employees are eligible for our professional development program. This includes annual funding for:
• Pursuing Associate's, Bachelor's, or Graduate Degrees
• Obtaining industry-standard professional certifications
• Participating in professional certificate programs
• Covering registration fees for professional conferences
• Centers of Excellence : We established the Centers of Excellence to build, leverage and grow our technological capabilities, best practices and offer professional development for our technical teams. They contain many Communities of Practice which are forums that offer a platform to share ideas, best practices, innovations, and to collaborate with technical peers.

Embark on a career with ASRC Federal Business Innovation, LLC, where your growth, purpose, and well-being are at the forefront of what we do!

We invest in the lives of our employees, both in and out of the workplace, by providing competitive pay and benefits packages. Benefits offered may include health care, dental, vision, life insurance; 401(k); education assistance; paid time off including PTO, holidays, and any other paid leave required by law.

EEO Statement

ASRC Federal and its Subsidiaries are Equal Opportunity employers. All qualified applicants will receive consideration for employment without regard to race, gender, color, age, sexual orientation, gender identification, national origin, religion, marital status, ancestry, citizenship, disability, protected veteran status, or any other factor prohibited by applicable law.",2025-07-25T02:00:00.000Z,2025-07-25,"[""Bachelor's degree or higher in Data Science, Computer Science, or a related field"", 'Secret clearance or Interim Secret clearance required to start', 'ASRC is willing to consider candidates who do not yet have a clearance; however, candidates must obtain an Interim Secret clearance before beginning employment', 'U.S. citizenship (required)', 'A minimum of 5 years of experience in Artificial Intelligence (AI) design, development, and maturation', 'Proven experience in implementing and training machine learning models, including the development and application of generative AI, advanced data analytics, and supervised and unsupervised learning models', 'Experience in deploying AI models to production environments', 'Proficiency in Python programming and experience developing models in a cloud-based environment', 'Ability to work independently at a Senior level, with minimal supervision or assistance from junior staff', ""Pursuing Associate's, Bachelor's, or Graduate Degrees"", 'Obtaining industry-standard professional certifications']","['Design and develop sophisticated data models, machine learning algorithms, and AI solutions to address complex engineering and operational challenges within defense systems', 'Implement and integrate machine learning and AI models into production environments, enhancing system capabilities in areas such as predictive analytics, automation, and decision-making processes', 'Work closely with multidisciplinary teams, including software engineers and system architects, to understand requirements, ensure proper data usage, and develop solutions aligned with project goals']",True,['Artificial Intelligence'],"Artificial Intelligence: Design, development, and maturation of AI solutions to address complex engineering and operational challenges within defense systems; implementation and deployment of AI models to production environments to enhance automation and decision-making processes.","['Machine Learning', 'Supervised Learning', 'Unsupervised Learning', 'Generative AI', 'Advanced Data Analytics', 'Predictive Analytics', 'Python Programming', 'Cloud-Based Model Development']","Machine Learning: Design and development of machine learning algorithms to solve complex engineering and operational challenges within defense systems; implementation and integration of machine learning models into production environments to enhance predictive analytics, automation, and decision-making.; Supervised Learning: Application of supervised learning models as part of the development and training of machine learning models for defense system challenges.; Unsupervised Learning: Application of unsupervised learning models as part of the development and training of machine learning models for defense system challenges.; Generative AI: Development and application of generative AI models as part of implementing advanced data analytics and AI solutions for defense systems.; Advanced Data Analytics: Use of advanced data analytics techniques in conjunction with machine learning and AI models to address operational challenges and improve system capabilities.; Predictive Analytics: Enhancement of system capabilities through predictive analytics enabled by machine learning and AI model integration into production environments.; Python Programming: Proficiency in Python programming used for developing machine learning and AI models in a cloud-based environment.; Cloud-Based Model Development: Experience developing machine learning and AI models within cloud-based environments to support deployment and scalability."
-1hEf6Rm6gqcogwzAAAAAA==,"Manager, Data Science - AI Foundations","Manager, Data Science - AI Foundations

Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making.

As a Data Scientist at Capital One, you’ll be part of a team that’s leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives.

Team Description

AI Foundations Specialist Models Data Science team builds and ships state of the art scalable architecture, AI/ML solutions for Capital One’s award-winning mobile app. We partner with product, tech and design teams to deliver app features that delight customers with dynamic and personalized experiences, enable them to chat with Capital One’s digital assistant Eno, or search for useful contents. You will be the driving force to experiment, innovate and create next generation experiences powered by the latest emerging generative AI technologies.

In this role, you will:
• Partner with a cross-functional team of data scientists, software engineers, machine learning engineers and product managers to deliver AI powered products that change how customers interact with their money.
• Leverage a broad stack of technologies — Pytorch, AWS Ultraclusters, Hugging Face, LangChain, Lightning, VectorDBs, and more — to reveal the insights hidden within huge volumes of numeric and textual data.
• Be the expert in Natural Language Processing (NLP) to harness the power of Large Language Models (LLMs), adapt and finetune them for customer facing applications and features.
• Build machine learning and NLP models through all phases of development, from design through training, evaluation, and validation; partnering with engineering teams to operationalize them in scalable and resilient production systems that serve 80+ million customers.
• Flex your interpersonal skills to translate the complexity of your work into tangible business goals.

The Ideal Candidate is:
• Customer first. You love the process of analyzing and creating, but also share our passion to do the right thing. You know at the end of the day it’s about making the right decision for our customers.
• Innovative. You continually research and evaluate emerging technologies. You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them.
• Creative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You’re not afraid to share a new idea.
• A leader. You challenge conventional thinking and work with stakeholders to identify and improve the status quo. You're passionate about talent development for your own team and beyond.
• Technical. You’re comfortable with advanced ML and DL technologies including language models and are passionate about developing further. You have hands-on experience working with LLMs and solutions using open-source tools and cloud computing platforms.
• Influential. You are passionate about AI/ML and can bring along a cross functional team in breakthrough innovations. You communicate clearly and effectively to share your findings with non-technical audiences.
• You are experienced in training language models or large computer vision models as well as have expertise in one or more key subdomains such as: training optimization, self-supervised learning, explainability, RLHF.
• You have an engineering mindset as shown by a track record of delivering models at scale both in training data and inference volumes. You have experience in delivering libraries, platforms, or solution level code to existing products.

Basic Qualifications:
• Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:
• A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 6 years of experience performing data analytics
• A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 4 years of experience performing data analytics
• A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 1 year of experience performing data analytics
• At least 1 year of experience leveraging open source programming languages for large scale data analysis
• At least 1 year of experience working with machine learning
• At least 1 year of experience utilizing relational databases

Preferred Qualifications:
• PhD in “STEM” field (Science, Technology, Engineering, or Mathematics)
• Experience working with AWS
• At least 4 years’ experience in Python, Scala, or R
• At least 4 years’ experience with machine learning
• At least 4 years’ experience with SQL

Capital One will consider sponsoring a new qualified applicant for employment authorization for this position.

The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.

McLean, VA: $193,400 - $220,700 for Mgr, Data Science

New York, NY: $211,000 - $240,800 for Mgr, Data Science

San Jose, CA: $211,000 - $240,800 for Mgr, Data Science

Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate’s offer letter.

This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.

Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.

This role is expected to accept applications for a minimum of 5 business days.

No agencies please. Capital One is an equal opportunity employer (EOE, including disability/vet) committed to non-discrimination in compliance with applicable federal, state, and local laws. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",2025-07-08T00:00:00.000Z,2025-07-25,"['Customer first', 'You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them', 'You thrive on bringing definition to big, undefined problems', 'You love asking questions and pushing hard to find answers', ""You're passionate about talent development for your own team and beyond"", 'Technical', 'You’re comfortable with advanced ML and DL technologies including language models and are passionate about developing further', 'You have hands-on experience working with LLMs and solutions using open-source tools and cloud computing platforms', 'Influential', 'You are passionate about AI/ML and can bring along a cross functional team in breakthrough innovations', 'You communicate clearly and effectively to share your findings with non-technical audiences', 'You are experienced in training language models or large computer vision models as well as have expertise in one or more key subdomains such as: training optimization, self-supervised learning, explainability, RLHF', 'You have an engineering mindset as shown by a track record of delivering models at scale both in training data and inference volumes', 'You have experience in delivering libraries, platforms, or solution level code to existing products', 'Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:', ""A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 6 years of experience performing data analytics"", ""A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 4 years of experience performing data analytics"", 'A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 1 year of experience performing data analytics', 'At least 1 year of experience leveraging open source programming languages for large scale data analysis', 'At least 1 year of experience working with machine learning', 'At least 1 year of experience utilizing relational databases']","['You will be the driving force to experiment, innovate and create next generation experiences powered by the latest emerging generative AI technologies', 'Partner with a cross-functional team of data scientists, software engineers, machine learning engineers and product managers to deliver AI powered products that change how customers interact with their money', 'Leverage a broad stack of technologies — Pytorch, AWS Ultraclusters, Hugging Face, LangChain, Lightning, VectorDBs, and more — to reveal the insights hidden within huge volumes of numeric and textual data', 'Be the expert in Natural Language Processing (NLP) to harness the power of Large Language Models (LLMs), adapt and finetune them for customer facing applications and features', 'Build machine learning and NLP models through all phases of development, from design through training, evaluation, and validation; partnering with engineering teams to operationalize them in scalable and resilient production systems that serve 80+ million customers', 'Flex your interpersonal skills to translate the complexity of your work into tangible business goals', 'You continually research and evaluate emerging technologies', 'You challenge conventional thinking and work with stakeholders to identify and improve the status quo']",True,"['Large Language Models (LLMs)', 'Generative AI', 'PyTorch', 'Hugging Face', 'LangChain', 'Lightning', 'Vector Databases', 'Training Optimization', 'Self-Supervised Learning', 'Explainability', 'Reinforcement Learning from Human Feedback (RLHF)']","Large Language Models (LLMs): Central to building customer-facing applications by adapting and fine-tuning these models to deliver personalized and dynamic experiences.; Generative AI: Leveraged to create next-generation customer experiences powered by emerging AI technologies.; PyTorch: Used as a deep learning framework to develop and train neural network models including LLMs.; Hugging Face: Utilized as an open-source platform and library for accessing, fine-tuning, and deploying transformer-based language models.; LangChain: Employed to build AI applications that integrate LLMs with external data sources and workflows.; Lightning: Used as a framework to streamline and scale deep learning model training and deployment.; Vector Databases: Applied to efficiently store and retrieve high-dimensional embeddings for AI-powered search and recommendation features.; Training Optimization: Expertise in improving the efficiency and effectiveness of training large AI models.; Self-Supervised Learning: Used as a technique to train models on unlabeled data to improve performance and generalization.; Explainability: Applied to interpret and understand AI model decisions, enhancing transparency and trust.; Reinforcement Learning from Human Feedback (RLHF): Used to fine-tune AI models by incorporating human feedback to improve alignment with user needs.","['Statistical Modeling', 'Relational Databases', 'Machine Learning', 'Natural Language Processing (NLP)', 'Model Training and Evaluation', 'Data Analytics', 'Python, Scala, R', 'SQL']","Statistical Modeling: Used historically to personalize credit card offers and drive data-driven decision-making at scale.; Relational Databases: Utilized for managing and querying structured data as part of data analytics and machine learning workflows.; Machine Learning: Applied to build predictive models and data-driven solutions that improve customer experiences and financial decision-making.; Natural Language Processing (NLP): Employed to build models that process and understand textual data, enabling features like digital assistants and content search.; Model Training and Evaluation: Involves all phases of machine learning model development including design, training, evaluation, and validation to ensure robust performance.; Data Analytics: Performed using open source programming languages and relational databases to analyze large-scale numeric and textual data.; Python, Scala, R: Programming languages used for data analysis, machine learning model development, and data processing.; SQL: Used for querying and managing data within relational databases."
Dj-wVQK6Iss0u5ovAAAAAA==,Senior Data Scientist - Product,"Job#: 2081102

Job Description:

Role Responsibilities:
• Design, build, and evaluate machine learning and deep learning models for classification, regression, recommendation, NLP, computer vision, and time-series forecasting.
• Apply deep learning techniques (e.g., CNNs, RNNs, LSTMs, Transformers) to solve complex, data-intensive problems.
• Lead the development of ML products, from model prototyping through production deployment, performance monitoring, and continuous improvement.
• Select appropriate architectures and hyperparameters, optimize model performance, and use proper evaluation metrics (e.g., AUC, F1, BLEU, IoU, perplexity) based on the use case.
• Collaborate with product managers and engineers to translate business challenges into deployable solutions using AI/ML.
• Design automated pipelines for data preprocessing, feature engineering, training, and inference (batch or real-time).
• Evaluate model drift, monitor performance post-deployment, and implement retraining pipelines as part of a production MLOps system.
• Mentor junior data scientists, contribute to code reviews, and lead technical discussions across the data science and engineering teams.

Role Requirements:
• Bachelor's degree in Computer Science, Statistics, Applied Math, or related field (Master's or PhD strongly preferred).
• 5+ years of industry experience in applied machine learning, with 2+ years focused on deep learning and neural network applications.
• Experience in Banking, Payments or Financial Services formulating AI data solutions that allow us to leverage our data to know our customers better and target our resources for better market penetration and focused attention and education.
• Proficiency in Python and ML libraries such as scikit-learn, XGBoost, TensorFlow, Keras, or PyTorch.
• Deep understanding of neural networks, model regularization, overfitting/underfitting prevention, and GPU-accelerated training.
• Experience with customer data enrichments.
• Proven track record of building, evaluating, and deploying machine learning models at scale in production environments.
• Experience with cloud platforms (AWS/Google Cloud Platform/Azure), containerization, and model serving technologies.
• Excellent communication skills, with the ability to present complex findings to both technical and non-technical stakeholders.
• Hands-on experience with real-world applications of deep learning, such as recommendation engines, fraud detection, customer segmentation, document summarization, image recognition, or speech processing.
• Familiarity with MLOps tools (e.g., MLflow, SageMaker, Airflow, Kubeflow).
• Experience with CI/CD for ML, feature stores, and real-time inference systems.
• Contributions to academic research, open-source ML projects, or ML/AI patents

EEO Employer

Apex Systems is an equal opportunity employer. We do not discriminate or allow discrimination on the basis of race, color, religion, creed, sex (including pregnancy, childbirth, breastfeeding, or related medical conditions), age, sexual orientation, gender identity, national origin, ancestry, citizenship, genetic information, registered domestic partner status, marital status, disability, status as a crime victim, protected veteran status, political affiliation, union membership, or any other characteristic protected by law. Apex will consider qualified applicants with criminal histories in a manner consistent with the requirements of applicable law. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation in using our website for a search or application, please contact our Employee Services Department at or .

Apex Systems is a world-class IT services company that serves thousands of clients across the globe. When you join Apex, you become part of a team that values innovation, collaboration, and continuous learning. We offer quality career resources, training, certifications, development opportunities, and a comprehensive benefits package. Our commitment to excellence is reflected in many awards, including ClearlyRated's Best of Staffing in Talent Satisfaction in the United States and Great Place to Work in the United Kingdom and Mexico.

Apex Benefits Overview: Apex offers a range of supplemental benefits, including medical, dental, vision, life, disability, and other insurance plans that offer an optional layer of financial protection. We offer an ESPP (employee stock purchase program) and a 401K program which allows you to contribute typically within 30 days of starting, with a company match after 12 months of tenure. Apex also offers a HSA (Health Savings Account on the HDHP plan), a SupportLinc Employee Assistance Program (EAP) with up to 8 free counseling sessions, a corporate discount savings program and other discounts. In terms of professional development, Apex hosts an on-demand training program, provides access to certification prep and a library of technical and leadership courses/books/seminars once you have 6+ months of tenure, and certification discounts and other perks to associations that include CompTIA and IIBA. Apex has a dedicated customer service team for our Consultants that can address questions around benefits and other resources, as well as a certified Career Coach. You can access a full list of our benefits, programs, support teams and resources within our 'Welcome Packet' as well, which an Apex team member can provide.",2025-07-21T00:00:00.000Z,2025-07-25,"['5+ years of industry experience in applied machine learning, with 2+ years focused on deep learning and neural network applications', 'Experience in Banking, Payments or Financial Services formulating AI data solutions that allow us to leverage our data to know our customers better and target our resources for better market penetration and focused attention and education', 'Proficiency in Python and ML libraries such as scikit-learn, XGBoost, TensorFlow, Keras, or PyTorch', 'Deep understanding of neural networks, model regularization, overfitting/underfitting prevention, and GPU-accelerated training', 'Experience with customer data enrichments', 'Proven track record of building, evaluating, and deploying machine learning models at scale in production environments', 'Experience with cloud platforms (AWS/Google Cloud Platform/Azure), containerization, and model serving technologies', 'Excellent communication skills, with the ability to present complex findings to both technical and non-technical stakeholders', 'Hands-on experience with real-world applications of deep learning, such as recommendation engines, fraud detection, customer segmentation, document summarization, image recognition, or speech processing', 'Familiarity with MLOps tools (e.g., MLflow, SageMaker, Airflow, Kubeflow)', 'Experience with CI/CD for ML, feature stores, and real-time inference systems', 'Contributions to academic research, open-source ML projects, or ML/AI patents']","['Design, build, and evaluate machine learning and deep learning models for classification, regression, recommendation, NLP, computer vision, and time-series forecasting', 'Apply deep learning techniques (e.g., CNNs, RNNs, LSTMs, Transformers) to solve complex, data-intensive problems', 'Lead the development of ML products, from model prototyping through production deployment, performance monitoring, and continuous improvement', 'Select appropriate architectures and hyperparameters, optimize model performance, and use proper evaluation metrics (e.g., AUC, F1, BLEU, IoU, perplexity) based on the use case', 'Collaborate with product managers and engineers to translate business challenges into deployable solutions using AI/ML', 'Design automated pipelines for data preprocessing, feature engineering, training, and inference (batch or real-time)', 'Evaluate model drift, monitor performance post-deployment, and implement retraining pipelines as part of a production MLOps system', 'Mentor junior data scientists, contribute to code reviews, and lead technical discussions across the data science and engineering teams']",True,['Transformers'],"Transformers: Apply Transformer architectures as part of deep learning techniques to solve complex, data-intensive problems including NLP and computer vision tasks.","['Machine Learning', 'Deep Learning', 'Evaluation Metrics', 'Feature Engineering', 'Data Pipelines', 'MLOps', 'Python', 'ML Libraries', 'Cloud Platforms', 'Containerization and Model Serving', 'Customer Data Enrichment']","Machine Learning: Design, build, and evaluate machine learning models for classification, regression, recommendation, NLP, computer vision, and time-series forecasting; lead development of ML products from prototyping through production deployment and continuous improvement; proven track record of building, evaluating, and deploying ML models at scale in production environments.; Deep Learning: Apply deep learning techniques such as CNNs, RNNs, LSTMs, and Transformers to solve complex, data-intensive problems; hands-on experience with real-world applications including recommendation engines, fraud detection, customer segmentation, document summarization, image recognition, and speech processing; deep understanding of neural networks, model regularization, overfitting/underfitting prevention, and GPU-accelerated training.; Evaluation Metrics: Select appropriate architectures and hyperparameters, optimize model performance, and use evaluation metrics such as AUC, F1, BLEU, IoU, and perplexity based on the use case.; Feature Engineering: Design automated pipelines for data preprocessing and feature engineering as part of training and inference workflows, supporting batch or real-time processing.; Data Pipelines: Design automated pipelines for data preprocessing, feature engineering, training, and inference (batch or real-time); implement retraining pipelines to evaluate model drift and monitor performance post-deployment as part of production MLOps systems.; MLOps: Evaluate model drift, monitor performance post-deployment, and implement retraining pipelines within production MLOps systems; familiarity with MLOps tools such as MLflow, SageMaker, Airflow, and Kubeflow; experience with CI/CD for ML, feature stores, and real-time inference systems.; Python: Proficiency in Python programming language used for developing machine learning and deep learning models.; ML Libraries: Experience with machine learning libraries including scikit-learn and XGBoost for traditional ML, and TensorFlow, Keras, and PyTorch for deep learning model development.; Cloud Platforms: Experience with cloud platforms such as AWS, Google Cloud Platform, and Azure for deploying and serving machine learning models.; Containerization and Model Serving: Experience with containerization technologies and model serving tools to deploy machine learning models in production environments.; Customer Data Enrichment: Experience working with customer data enrichment to improve data quality and model inputs for better targeting and segmentation."
QN_ILKZJ_sCHUaNrAAAAAA==,"Manager, Data Science","Manager, Data Science

Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making.

As a Data Scientist at Capital One, you'll be part of a team that's leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives.

Team Description

As a member of the Shopping ML & Data Engineering team, you'll be joining a growth-stage line of business with a startup mindset as we build technology to save our customers money.

As a startup minded line of business, you'll have the experience working in a fast-paced environment full of greenfield problem-solving. You'll collaborate with an Agile team dedicated to productionizing machine learning applications, models and systems at scale. You'll drive and deliver the development and implementation of machine learning models using existing and emerging technology platforms. You'll lead in researching our next generation of models and recommendation systems to deliver value to our customers. You will use tools like SQL, Python, Pytorch, Transformers, language models, and other statistical tools.

Role Description

In this role, you will:
• Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love
• Leverage a broad stack of technologies - Python, Conda, AWS, H2O, Spark, and more - to reveal the insights hidden within huge volumes of numeric and textual data
• Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation
• Flex your interpersonal skills to translate the complexity of your work into tangible business goals

The Ideal Candidate is:
• Customer first. You love the process of analyzing and creating, but also share our passion to do the right thing. You know at the end of the day it's about making the right decision for our customers.
• Innovative. You continually research and evaluate emerging technologies. You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them.
• Creative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You're not afraid to share a new idea.
• A data guru. ""Big data"" doesn't faze you. You have the skills to retrieve, combine, and analyze data from a variety of sources and structures. You know understanding the data is often the key to great data science.

Basic Qualifications:
• Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:
• A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 6 years of experience performing data analytics
• A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 4 years of experience performing data analytics
• A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 1 year of experience performing data analytics
• At least 1 year of experience leveraging open source programming languages for large scale data analysis
• At least 1 year of experience working with machine learning
• At least 1 year of experience utilizing relational databases

Preferred Qualifications:
• PhD in ""STEM"" field (Science, Technology, Engineering, or Mathematics) plus 3 years of experience in data analytics
• At least 1 year of experience working with AWS
• At least 4 years' experience in Python, Scala, or R for large scale data analysis
• At least 4 years' experience with machine learning
• At least 4 years' experience with SQL

Capital One will consider sponsoring a new qualified applicant for employment authorization for this position.

The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.

McLean, VA: $193,400 - $220,700 for Mgr, Data Science

New York, NY: $211,000 - $240,800 for Mgr, Data Science

Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate's offer letter.

This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.

Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.

This role is expected to accept applications for a minimum of 5 business days.

No agencies please. Capital One is an equal opportunity employer (EOE, including disability/vet) committed to non-discrimination in compliance with applicable federal, state, and local laws. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City's Fair Chance Act; Philadelphia's Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",2025-06-26T00:00:00.000Z,2025-07-25,"['Customer first', 'You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them', 'You thrive on bringing definition to big, undefined problems', 'You love asking questions and pushing hard to find answers', 'You have the skills to retrieve, combine, and analyze data from a variety of sources and structures', 'You know understanding the data is often the key to great data science', 'Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:', ""A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 6 years of experience performing data analytics"", ""A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 4 years of experience performing data analytics"", 'A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 1 year of experience performing data analytics', 'At least 1 year of experience leveraging open source programming languages for large scale data analysis', 'At least 1 year of experience working with machine learning', 'At least 1 year of experience utilizing relational databases']","[""As a startup minded line of business, you'll have the experience working in a fast-paced environment full of greenfield problem-solving"", ""You'll collaborate with an Agile team dedicated to productionizing machine learning applications, models and systems at scale"", ""You'll drive and deliver the development and implementation of machine learning models using existing and emerging technology platforms"", ""You'll lead in researching our next generation of models and recommendation systems to deliver value to our customers"", 'You will use tools like SQL, Python, Pytorch, Transformers, language models, and other statistical tools', 'Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love', 'Leverage a broad stack of technologies - Python, Conda, AWS, H2O, Spark, and more - to reveal the insights hidden within huge volumes of numeric and textual data', 'Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation', 'Flex your interpersonal skills to translate the complexity of your work into tangible business goals', 'You continually research and evaluate emerging technologies']",True,"['Transformers', 'Language Models']","Transformers: Used specifically as a modern AI architecture for language models to enhance machine learning applications involving natural language processing.; Language Models: Applied as AI models to process and generate human language, supporting advanced recommendation systems and other AI-driven features.","['Statistical Modeling', 'Relational Databases', 'Machine Learning', 'SQL', 'Python', 'PyTorch', 'Transformers', 'Language Models', 'Conda', 'AWS', 'H2O', 'Spark']","Statistical Modeling: Used to personalize credit card offers and analyze large volumes of numeric and textual data to reveal insights and support data-driven decision-making.; Relational Databases: Utilized for storing and querying large-scale structured data, supporting data retrieval and analysis.; Machine Learning: Applied to build, train, evaluate, validate, and implement predictive models and recommendation systems at scale to deliver customer value.; SQL: Used for querying and managing data within relational databases as part of data analysis and model development workflows.; Python: A primary programming language used for data analysis, machine learning model development, and working with various data science tools and libraries.; PyTorch: Employed as a framework for building and training machine learning models, including deep learning architectures.; Transformers: Used as part of language model development and implementation to enhance machine learning applications involving textual data.; Language Models: Leveraged to process and analyze textual data, supporting recommendation systems and other machine learning applications.; Conda: Used as an environment and package management system to support reproducible data science workflows and dependency management.; AWS: Utilized as a cloud platform to support large-scale data storage, processing, and machine learning model deployment.; H2O: Applied as a machine learning platform to build and deploy scalable predictive models.; Spark: Used for distributed data processing and analytics on large datasets to support machine learning and data engineering tasks."
0RyW4ivnA3vAdnu5AAAAAA==,Senior Data Scientist - Risk & Compliance,"Job#: 2081100

Job Description:

Role Responsibilities:
• Project Management: Leading and managing end to end data science projects, defining objectives, define requirements, and ensuring timely delivery.
• Model Development & Implementation: Developing and validating machine learning and statistical models, implementing predictive models, and optimizing existing ones.
• Data Analysis & Insights: Analyzing large datasets, identifying trends and patterns, and extracting actionable insights to inform business decisions.
• Collaboration & Communication: Working with cross-functional teams and stakeholders, including engineering, product, and business stakeholders, to translate complex data into actionable strategies.
• Mentorship & Guidance: Providing guidance and mentorship to junior data scientists, sharing expertise, and fostering their professional growth.
• Staying Updated: Keeping abreast of the latest advancements in data science and AI, exploring new tools and techniques, and identifying opportunities for innovation.
• Strategic Input: Contributing to the development of data-driven strategies and providing input on technical approaches for projects.

Role Requirements:
• Bachelor's degree in Computer Science, Statistics, Applied Math, or related field (Master's or PhD strongly preferred).
• 5+ years of industry experience in applied machine learning, with 2+ years focused on deep learning and neural network applications.
• Experience in Banking, Payments or Financial Services leading in detecting and preventing digital fraud, scams and social engineering.
• Able to quickly understand our current Risk Models with the goal of building a flexible AI solution that partners with our current risk tools to maintains our high standards for Risk Prevention and Compliance while providing flexibility to effectively run our business.
• Expertise in statistical modeling, machine learning algorithms, and data mining techniques.
• Experience navigating difficult scenarios developing and implementing execution ideas with minimal guidance.
• Proficiency in programming languages like Python or R.
• Ability to create clear and concise visualizations to communicate complex data.
• Ability to create clear and standard data models to communicate with the stakeholders and to capture the semantics of the data and the complex semi-structured content.
• Strong analytical and problem-solving skills, with the ability to tackle complex business challenges.
• Excellent communication and presentation skills to effectively convey findings to both technical and non-technical audiences.
• Experience and willingness to lead and mentor a team, providing guidance and support to junior members.

EEO Employer

Apex Systems is an equal opportunity employer. We do not discriminate or allow discrimination on the basis of race, color, religion, creed, sex (including pregnancy, childbirth, breastfeeding, or related medical conditions), age, sexual orientation, gender identity, national origin, ancestry, citizenship, genetic information, registered domestic partner status, marital status, disability, status as a crime victim, protected veteran status, political affiliation, union membership, or any other characteristic protected by law. Apex will consider qualified applicants with criminal histories in a manner consistent with the requirements of applicable law. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation in using our website for a search or application, please contact our Employee Services Department at or .

Apex Systems is a world-class IT services company that serves thousands of clients across the globe. When you join Apex, you become part of a team that values innovation, collaboration, and continuous learning. We offer quality career resources, training, certifications, development opportunities, and a comprehensive benefits package. Our commitment to excellence is reflected in many awards, including ClearlyRated's Best of Staffing in Talent Satisfaction in the United States and Great Place to Work in the United Kingdom and Mexico.

Apex Benefits Overview: Apex offers a range of supplemental benefits, including medical, dental, vision, life, disability, and other insurance plans that offer an optional layer of financial protection. We offer an ESPP (employee stock purchase program) and a 401K program which allows you to contribute typically within 30 days of starting, with a company match after 12 months of tenure. Apex also offers a HSA (Health Savings Account on the HDHP plan), a SupportLinc Employee Assistance Program (EAP) with up to 8 free counseling sessions, a corporate discount savings program and other discounts. In terms of professional development, Apex hosts an on-demand training program, provides access to certification prep and a library of technical and leadership courses/books/seminars once you have 6+ months of tenure, and certification discounts and other perks to associations that include CompTIA and IIBA. Apex has a dedicated customer service team for our Consultants that can address questions around benefits and other resources, as well as a certified Career Coach. You can access a full list of our benefits, programs, support teams and resources within our 'Welcome Packet' as well, which an Apex team member can provide.",2025-07-21T00:00:00.000Z,2025-07-25,"['5+ years of industry experience in applied machine learning, with 2+ years focused on deep learning and neural network applications', 'Experience in Banking, Payments or Financial Services leading in detecting and preventing digital fraud, scams and social engineering', 'Able to quickly understand our current Risk Models with the goal of building a flexible AI solution that partners with our current risk tools to maintains our high standards for Risk Prevention and Compliance while providing flexibility to effectively run our business', 'Expertise in statistical modeling, machine learning algorithms, and data mining techniques', 'Experience navigating difficult scenarios developing and implementing execution ideas with minimal guidance', 'Proficiency in programming languages like Python or R', 'Ability to create clear and concise visualizations to communicate complex data', 'Ability to create clear and standard data models to communicate with the stakeholders and to capture the semantics of the data and the complex semi-structured content', 'Strong analytical and problem-solving skills, with the ability to tackle complex business challenges', 'Excellent communication and presentation skills to effectively convey findings to both technical and non-technical audiences', 'Experience and willingness to lead and mentor a team, providing guidance and support to junior members']","['Project Management: Leading and managing end to end data science projects, defining objectives, define requirements, and ensuring timely delivery', 'Model Development & Implementation: Developing and validating machine learning and statistical models, implementing predictive models, and optimizing existing ones', 'Data Analysis & Insights: Analyzing large datasets, identifying trends and patterns, and extracting actionable insights to inform business decisions', 'Collaboration & Communication: Working with cross-functional teams and stakeholders, including engineering, product, and business stakeholders, to translate complex data into actionable strategies', 'Mentorship & Guidance: Providing guidance and mentorship to junior data scientists, sharing expertise, and fostering their professional growth', 'Staying Updated: Keeping abreast of the latest advancements in data science and AI, exploring new tools and techniques, and identifying opportunities for innovation', 'Strategic Input: Contributing to the development of data-driven strategies and providing input on technical approaches for projects']",True,['Artificial Intelligence'],Artificial Intelligence: Building flexible AI solutions that integrate with existing risk tools to enhance risk prevention and compliance while maintaining business flexibility.,"['Machine Learning', 'Statistical Modeling', 'Deep Learning', 'Data Analysis', 'Data Visualization', 'Data Modeling', 'Python', 'R']","Machine Learning: Developing and validating machine learning models to support risk and compliance objectives, including predictive modeling and optimization of existing models.; Statistical Modeling: Applying statistical modeling techniques to analyze data and build risk models for fraud detection and compliance.; Deep Learning: Utilizing deep learning and neural network applications for advanced modeling in risk prevention and compliance.; Data Analysis: Analyzing large datasets to identify trends, patterns, and actionable insights that inform business decisions related to risk and compliance.; Data Visualization: Creating clear and concise visualizations to communicate complex data findings effectively to both technical and non-technical stakeholders.; Data Modeling: Developing clear and standard data models to capture the semantics of data and complex semi-structured content for communication with stakeholders.; Python: Using Python programming language for implementing machine learning models, data analysis, and other data science tasks.; R: Using R programming language for statistical analysis, modeling, and data science workflows."
Rt-lAc6aN-1QgYeeAAAAAA==,Data Scientist - Fraud & Risk,"GA DHS - Data Scientist

Hybrid- GA

We are seeking a highly analytical and detail-oriented Data Scientist with experience in Risk and Fraud analytics to join our growing team. This role will focus on developing and deploying machine learning models, statistical methods, and data-driven strategies to detect risky behaviors and prevent fraudulent activities across our products and services.

Key Responsibilities
• Collect, clean, and analyze large, complex datasets from multiple sources.
• Develop predictive models and machine learning algorithms to support decision-making and improve business performance.
• Translatebusiness problems into data-driven solutions with measurable impact.
• Develop and deploy machine learning models to detect, predict, and prevent fraudulent transactions and behavior patterns.
• Analyze large volumes of structured and unstructured data from multiple sources to identify fraud trends and root causes.
• Collaborate with fraud operations, engineering, and compliance teams to implement real-time fraud detection solutions.
• Design and monitor KPIs to evaluate model performance and improve fraud detection systems over time.
• Conduct deep-dive investigations into fraud cases, creating detailed reports and actionable insights.
• Stay current with emerging fraud techniques, industry best practices, and data science tools.

Required Qualifications
• Bachelor s or master s degree in data science, Computer Science, Statistics, Mathematics, Economics or a related field.
• 10+ years of professional experience in data science
• Proficient in Python, SQL, SAS and machine learning techniques
• Experience in responsible use of AI if used in solution design
• Strong analytical skills and the ability to identify patterns and trends from data
• Experience working with large datasets and cloud platforms (e.g., AWS, Google Cloud Platform, Azure).
• Strong understanding of supervised and unsupervised fraud detection techniques, including anomaly detection, behavioral modeling, and network analysis.
• Experience with visualization tools like Tableau and Power BI.",2025-07-22T00:00:00.000Z,2025-07-25,"['Bachelor s or master s degree in data science, Computer Science, Statistics, Mathematics, Economics or a related field', '10+ years of professional experience in data science', 'Proficient in Python, SQL, SAS and machine learning techniques', 'Experience in responsible use of AI if used in solution design', 'Strong analytical skills and the ability to identify patterns and trends from data', 'Experience working with large datasets and cloud platforms (e.g., AWS, Google Cloud Platform, Azure)', 'Strong understanding of supervised and unsupervised fraud detection techniques, including anomaly detection, behavioral modeling, and network analysis', 'Experience with visualization tools like Tableau and Power BI']","['This role will focus on developing and deploying machine learning models, statistical methods, and data-driven strategies to detect risky behaviors and prevent fraudulent activities across our products and services', 'Collect, clean, and analyze large, complex datasets from multiple sources', 'Develop predictive models and machine learning algorithms to support decision-making and improve business performance', 'Translatebusiness problems into data-driven solutions with measurable impact', 'Develop and deploy machine learning models to detect, predict, and prevent fraudulent transactions and behavior patterns', 'Analyze large volumes of structured and unstructured data from multiple sources to identify fraud trends and root causes', 'Collaborate with fraud operations, engineering, and compliance teams to implement real-time fraud detection solutions', 'Design and monitor KPIs to evaluate model performance and improve fraud detection systems over time', 'Conduct deep-dive investigations into fraud cases, creating detailed reports and actionable insights', 'Stay current with emerging fraud techniques, industry best practices, and data science tools']",True,[],,"['Machine Learning Models', 'Statistical Methods', 'Supervised and Unsupervised Learning', 'Data Cleaning and Analysis', 'Predictive Modeling', 'SQL', 'Python', 'SAS', 'Cloud Platforms', 'Data Visualization Tools', 'Anomaly Detection', 'Behavioral Modeling', 'Network Analysis']","Machine Learning Models: Develop and deploy machine learning models to detect, predict, and prevent fraudulent transactions and behavior patterns, supporting decision-making and improving business performance.; Statistical Methods: Apply statistical methods to analyze data and develop data-driven strategies for detecting risky behaviors and preventing fraud.; Supervised and Unsupervised Learning: Utilize supervised and unsupervised fraud detection techniques, including anomaly detection, behavioral modeling, and network analysis, to identify fraud trends and root causes.; Data Cleaning and Analysis: Collect, clean, and analyze large, complex datasets from multiple sources to support fraud detection and risk analytics.; Predictive Modeling: Develop predictive models to support decision-making and improve business performance in fraud and risk detection.; SQL: Use SQL to query and manage large datasets relevant to fraud and risk analytics.; Python: Leverage Python programming for data analysis, machine learning model development, and deployment in fraud detection.; SAS: Utilize SAS software for statistical analysis and modeling in fraud and risk analytics.; Cloud Platforms: Work with cloud platforms such as AWS, Google Cloud Platform, and Azure to handle large datasets and deploy fraud detection solutions.; Data Visualization Tools: Use visualization tools like Tableau and Power BI to design and monitor KPIs and create reports that provide actionable insights into fraud cases.; Anomaly Detection: Apply anomaly detection techniques as part of unsupervised learning methods to identify unusual patterns indicative of fraud.; Behavioral Modeling: Use behavioral modeling to understand and detect fraudulent behavior patterns.; Network Analysis: Employ network analysis techniques to detect fraud by analyzing relationships and interactions within data."
UUkFI02qhxFHE3faAAAAAA==,Senior Data Analyst Jobs,"ManTech seeks a motivated, career- and customer-oriented Senior Data Analyst to join our innovative team in Ashburn, VA. This is a hybrid position with 2 days onsite and 3 days remote.

Each day U.S. Customs and Border Protection (CBP) oversees the massive flow of people, capital, and products that enter and depart the United States via air, land, sea, and cyberspace. The volume and complexity of both physical and virtual border crossings require the application of ""big data"" solutions to promote efficient trade and travel.

Responsibilities include but are not limited to:
• Perform exploratory data analysis using statistical techniques to identify significant trends, patterns, correlations, and anomalies.
• Independently identify solutions for assigned business problems, and routinely collaborate with enterprise/application architects, database architects, data scientists, and mission stakeholders.
• Extract, clean, and transform data associated within an identified problem space to help build predictive models as well as develop appropriate supporting documentation.
• Leverage knowledge of a variety of statistical and machine learning techniques.
• Execute projects including those intended to identify patterns and/or anomalies.
• Research information as necessary.
• Brief project management, technical design, and outcomes to both technical and non-technical audiences including senior stakeholders throughout the project lifecycle through written as well as virtual reporting.

Minimum Qualifications:
• HS Diploma/GED and 15-20 years, AS/AA and 13-18 years, BS/BA and 7-12 years, MS/MA/MBA, and 5-9 years, PhD/Doctorate and 3-7 years
• Proficiency using Python, R, Scala, or JavaScript and related packages for development and analysis.
• Experience working in field of entity resolution, analytics, data mining or name matching.
• Hands on experience with one or more relational database systems (e.g., Oracle, MySQL, Postgres)
• Hands on experience with SQL
• Strong written and verbal communication skills.

Preferred Qualifications:
• Bachelor's degree and 7 to 12 years of experience or a master's degree and 5 to 9 years of experience in business analytics, statistics, data science, information technology, economics, mathematics, statistics, computer science, physical science, engineering or a related field
• Proficiency in statistical modeling.
• A passion for low-level/embedded data/science analytics.
• Experience in cloud computing/cloud storage.
• Conceptual understanding of - and/or prior experiences related to - data profiling, fuzzy matching, entity resolution, and signal detection theory
• Prior National Targeting Center (NTC) experience, preferably with proficiency in operational data analysis.
• Experience working within an Agile development environment.

Clearance Requirements:
• Must be a U.S. citizen with the ability to obtain DHS CBP suitability prior to starting this position.

Physical Requirements:
• The person in this position needs to occasionally move about inside the office to access file cabinets, office machinery, or to communicate with coworkers, management, and customers, which may involve delivering presentations.",2025-07-19T00:00:00.000Z,2025-07-25,"['HS Diploma/GED and 15-20 years, AS/AA and 13-18 years, BS/BA and 7-12 years, MS/MA/MBA, and 5-9 years, PhD/Doctorate and 3-7 years', 'Proficiency using Python, R, Scala, or JavaScript and related packages for development and analysis', 'Experience working in field of entity resolution, analytics, data mining or name matching', 'Hands on experience with one or more relational database systems (e.g., Oracle, MySQL, Postgres)', 'Hands on experience with SQL', 'Strong written and verbal communication skills', 'Must be a U.S. citizen with the ability to obtain DHS CBP suitability prior to starting this position', 'The person in this position needs to occasionally move about inside the office to access file cabinets, office machinery, or to communicate with coworkers, management, and customers, which may involve delivering presentations']","['This is a hybrid position with 2 days onsite and 3 days remote', 'Each day U.S. Customs and Border Protection (CBP) oversees the massive flow of people, capital, and products that enter and depart the United States via air, land, sea, and cyberspace', 'The volume and complexity of both physical and virtual border crossings require the application of ""big data"" solutions to promote efficient trade and travel', 'Perform exploratory data analysis using statistical techniques to identify significant trends, patterns, correlations, and anomalies', 'Independently identify solutions for assigned business problems, and routinely collaborate with enterprise/application architects, database architects, data scientists, and mission stakeholders', 'Extract, clean, and transform data associated within an identified problem space to help build predictive models as well as develop appropriate supporting documentation', 'Leverage knowledge of a variety of statistical and machine learning techniques', 'Execute projects including those intended to identify patterns and/or anomalies', 'Research information as necessary', 'Brief project management, technical design, and outcomes to both technical and non-technical audiences including senior stakeholders throughout the project lifecycle through written as well as virtual reporting']",True,[],,"['Exploratory Data Analysis', 'Statistical Techniques', 'Predictive Modeling', 'Machine Learning Techniques', 'Data Extraction, Cleaning, and Transformation', 'Entity Resolution', 'Data Mining', 'SQL', 'Relational Database Systems', 'Programming Languages for Data Analysis', 'Statistical Modeling', 'Big Data Solutions', 'Data Profiling', 'Signal Detection Theory', 'Agile Development Environment', 'Cloud Computing and Cloud Storage']","Exploratory Data Analysis: Used to identify significant trends, patterns, correlations, and anomalies in data to support business problem solving.; Statistical Techniques: Applied to analyze data for trends, patterns, and anomalies as part of exploratory data analysis and predictive modeling.; Predictive Modeling: Building models based on extracted, cleaned, and transformed data to forecast outcomes relevant to business problems.; Machine Learning Techniques: Leveraged various statistical and machine learning methods to identify patterns and anomalies in data.; Data Extraction, Cleaning, and Transformation: Performed on data within the problem space to prepare it for analysis and predictive modeling.; Entity Resolution: Experience working in fields involving entity resolution, fuzzy matching, and name matching to improve data quality and analytics.; Data Mining: Applied to discover patterns and insights from large datasets relevant to border security and trade efficiency.; SQL: Used for querying and managing data within relational database systems such as Oracle, MySQL, and Postgres.; Relational Database Systems: Hands-on experience with systems like Oracle, MySQL, and Postgres to store and manage data for analysis.; Programming Languages for Data Analysis: Proficiency in Python, R, Scala, or JavaScript and related packages to develop and analyze data solutions.; Statistical Modeling: Applied to analyze data and support business analytics and decision-making processes.; Big Data Solutions: Applied to manage and analyze the large volume and complexity of data related to physical and virtual border crossings.; Data Profiling: Conceptual understanding and experience related to assessing data quality and characteristics to support analytics.; Signal Detection Theory: Applied concepts to identify signals (patterns or anomalies) within complex data sets.; Agile Development Environment: Experience working within Agile frameworks to manage and deliver data analytics projects efficiently.; Cloud Computing and Cloud Storage: Experience with cloud technologies to support data storage and computing needs for analytics projects."
d2tLs81XH-GUTsjhAAAAAA==,"Principal Associate, Data Science - Model Risk Office","Principal Associate, Data Science - Model Risk Office

Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making.

As a Data Scientist at Capital One, you’ll be part of a team that’s leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives.

Team Description:

In Capital One’s Model Risk Office, we defend the company against model failures and find new ways of making better decisions with models. We use our statistics, software engineering, and business expertise to drive the best outcomes in both Risk Management and the Enterprise. We understand that we can’t prepare for tomorrow by focusing on today, so we invest in the future: investing in new skills, building better tools, and maintaining a network of trusted partners. We learn from past mistakes, and develop increasingly powerful techniques to avoid their repetition.

In this role, you will:
• Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love
• Leverage a broad stack of technologies — Python, Conda, AWS, H2O, Spark, and more — to reveal the insights hidden within huge volumes of numeric and textual data
• Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation
• Flex your interpersonal skills to translate the complexity of your work into tangible business goals
• Document your analyses and risk assessments in validation reports that are subject to audit and regulatory review

The Ideal Candidate is:
• Innovative. You continually research and evaluate emerging technologies. You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them.
• Creative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You’re not afraid to share a new idea.
• Technical. You’re comfortable with open-source languages and are passionate about developing further. You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms.
• Statistically-minded. You’ve built models, validated them, and backtested them. You know how to interpret a confusion matrix or a ROC curve. You have experience with clustering, classification, sentiment analysis, time series, and deep learning.
• A data guru. “Big data” doesn’t faze you. You have the skills to retrieve, combine, and analyze data from a variety of sources and structures. You know understanding the data is often the key to great data science.
• Detailed-oriented. You can understand and apply Capital One’s Model Policy while leveraging your technical expertise to assess potential model risks

Basic Qualifications:
• Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date :
• A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 5 years of experience performing data analytics
• A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 3 years of experience performing data analytics
• A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field)

Preferred Qualifications:
• Master’s Degree in “STEM” field (Science, Technology, Engineering, or Mathematics) plus 3 years of experience in data analytics, or PhD in “STEM” field (Science, Technology, Engineering, or Mathematics)
• At least 1 year of experience working with AWS
• At least 1 year of experience working with Generative AI
• At least 3 years’ experience in Python, Scala, or R for large scale data analysis
• At least 3 years’ experience with machine learning
• At least 3 years’ experience with SQL
• At least 3 years’ experience building or validating models to detect financial crimes

Capital One will consider sponsoring a new qualified applicant for employment authorization for this position.

The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.

McLean, VA: $158,600 - $181,000 for Princ Associate, Data Science

Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate’s offer letter.

This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.

Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.

This role is expected to accept applications for a minimum of 5 business days.

No agencies please. Capital One is an equal opportunity employer (EOE, including disability/vet) committed to non-discrimination in compliance with applicable federal, state, and local laws. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",2025-07-17T00:00:00.000Z,2025-07-25,"['You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them', 'You thrive on bringing definition to big, undefined problems', 'You love asking questions and pushing hard to find answers', 'You’re comfortable with open-source languages and are passionate about developing further', 'You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms', 'Statistically-minded', 'You know how to interpret a confusion matrix or a ROC curve', 'You have experience with clustering, classification, sentiment analysis, time series, and deep learning', 'A data guru', 'You have the skills to retrieve, combine, and analyze data from a variety of sources and structures', 'You know understanding the data is often the key to great data science', 'Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date :', ""A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 5 years of experience performing data analytics"", ""A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 3 years of experience performing data analytics"", 'A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field)']","['Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love', 'Leverage a broad stack of technologies — Python, Conda, AWS, H2O, Spark, and more — to reveal the insights hidden within huge volumes of numeric and textual data', 'Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation', 'Flex your interpersonal skills to translate the complexity of your work into tangible business goals', 'Document your analyses and risk assessments in validation reports that are subject to audit and regulatory review', 'You continually research and evaluate emerging technologies', 'You’ve built models, validated them, and backtested them', 'You can understand and apply Capital One’s Model Policy while leveraging your technical expertise to assess potential model risks']",True,['Generative AI'],"Generative AI: Experience with generative AI technologies is preferred, indicating involvement with modern AI methods beyond traditional machine learning.","['Statistical Modeling', 'Python', 'Conda', 'AWS', 'H2O', 'Spark', 'Machine Learning Models', 'Model Validation and Backtesting', 'Clustering', 'Classification', 'Sentiment Analysis', 'Time Series Analysis', 'Deep Learning', 'SQL', 'Data Retrieval and Integration', 'Confusion Matrix and ROC Curve Interpretation']","Statistical Modeling: Used to personalize credit card offers and drive data-driven decision-making in financial services.; Python: A primary programming language used for data science solutions and large scale data analysis.; Conda: A package and environment management system leveraged to manage dependencies and environments for data science projects.; AWS: Cloud computing platform used for data storage, processing, and analytics, with at least one year of experience preferred.; H2O: An open-source machine learning platform used to build and deploy machine learning models at scale.; Spark: A big data processing framework used to handle huge volumes of numeric and textual data efficiently.; Machine Learning Models: Built through all phases including design, training, evaluation, validation, and implementation to support risk management and financial crime detection.; Model Validation and Backtesting: Processes to ensure model accuracy, reliability, and compliance with regulatory standards.; Clustering: A statistical method used for grouping data points, applied in model development and analysis.; Classification: A supervised learning technique used to categorize data, relevant for detecting financial crimes and risk assessment.; Sentiment Analysis: Analyzing textual data to extract sentiment, used as part of data insights.; Time Series Analysis: Analyzing sequential data over time, applied in model development and risk assessment.; Deep Learning: Applied as part of advanced modeling techniques to improve predictive accuracy and insights.; SQL: Used for querying and managing structured data in relational databases.; Data Retrieval and Integration: Skills to retrieve, combine, and analyze data from various sources and structures to support data science workflows.; Confusion Matrix and ROC Curve Interpretation: Techniques used to evaluate classification model performance and effectiveness."
IP3-YmuaqDpmJhu9AAAAAA==,"Sr Data Scientist (RAG systems, LLMs)","Hi,
The following requirement is open with our client.
Title : Sr Data Scientist (RAG systems, LLMs)
Client : Infovision
Duration : Long-term
Location : Dallas, TX - Onsite

Job Overview
We're looking for a highly skilled and experienced Data Scientist to help lead this transformation. If you're passionate about turning complex data into actionable insights, advancing the frontiers of anomaly detection, transformers, and Retrieval-Augmented Generation (RAG), and pushing the boundaries of what AI can do, this is your opportunity. Telecom experience is a must, but what matters most is your curiosity, creativity, and deep expertise in machine learning.

Job Requirements:
• 12+ Year of overall IT Experience
• Bachelor's degree in Computer Science, Data Science, AI/ML, or a related technical field from an accredited university, or equivalent work experience.
• Minimum 8 years of relevant work experience.
• Should have experience in Telcom Industry
• Strong experience in machine learning, deep learning, and AI frameworks (e.g., TensorFlow, PyTorch, Scikit-Learn).
• Hands-on experience with RAG systems, transformers, and NLP models.
• Expertise in anomaly detection techniques, including statistical and ML-based approaches.
• Strong background in data preprocessing, feature engineering, and model evaluation.
• Training/Pretraining/Fine-tuning LLMs and ML experience with large datasets.
• Excellent problem-solving and analytical skills.
• Networking technology background.

Preferred Qualifications:
• Advanced degree (MS/PhD) in Computer Science, Data Science, AI/ML, or a related field.
• Familiarity with graph databases and knowledge graphs for information retrieval.
• Contributions to research publications, open-source projects, or AI/ML communities.
• Understanding of AI governance and implementation.",2025-07-14T00:00:00.000Z,2025-07-25,"['Telecom experience is a must, but what matters most is your curiosity, creativity, and deep expertise in machine learning', '12+ Year of overall IT Experience', ""Bachelor's degree in Computer Science, Data Science, AI/ML, or a related technical field from an accredited university, or equivalent work experience"", 'Minimum 8 years of relevant work experience', 'Should have experience in Telcom Industry', 'Strong experience in machine learning, deep learning, and AI frameworks (e.g., TensorFlow, PyTorch, Scikit-Learn)', 'Hands-on experience with RAG systems, transformers, and NLP models', 'Expertise in anomaly detection techniques, including statistical and ML-based approaches', 'Strong background in data preprocessing, feature engineering, and model evaluation', 'Training/Pretraining/Fine-tuning LLMs and ML experience with large datasets', 'Excellent problem-solving and analytical skills', 'Networking technology background']","[""If you're passionate about turning complex data into actionable insights, advancing the frontiers of anomaly detection, transformers, and Retrieval-Augmented Generation (RAG), and pushing the boundaries of what AI can do, this is your opportunity""]",True,"['Retrieval-Augmented Generation', 'Large Language Models', 'Transformers', 'Deep Learning Frameworks', 'Natural Language Processing']","Retrieval-Augmented Generation: Hands-on experience with Retrieval-Augmented Generation (RAG) systems is required to enhance language models with external knowledge retrieval capabilities.; Large Language Models: The role involves training, pretraining, and fine-tuning large language models (LLMs) for telecom-related NLP tasks.; Transformers: Experience with transformer architectures is necessary for developing advanced NLP models and AI applications.; Deep Learning Frameworks: Proficiency in deep learning frameworks such as TensorFlow and PyTorch is required for building and deploying neural network models.; Natural Language Processing: Hands-on experience with NLP models is needed to process and analyze telecom text data using AI techniques.","['Machine Learning', 'Anomaly Detection', 'Data Preprocessing', 'Feature Engineering', 'Model Evaluation', 'Scikit-Learn']",Machine Learning: The job requires strong experience in machine learning techniques and applying them to telecom data for actionable insights and anomaly detection.; Anomaly Detection: Expertise in statistical and machine learning-based anomaly detection techniques is needed to identify unusual patterns in telecom data.; Data Preprocessing: A strong background in data preprocessing is required to prepare telecom datasets for modeling and analysis.; Feature Engineering: The role involves feature engineering to create meaningful input variables for machine learning models.; Model Evaluation: Experience in evaluating machine learning models to ensure accuracy and reliability in telecom applications is necessary.; Scikit-Learn: Experience with Scikit-Learn is required as part of the machine learning framework toolkit for building and evaluating models.
BKMzSlD6Rlg6w4-UAAAAAA==,Data Scientist (Data Scientist 3) 23033 Jobs,"Requisition Number: 23033

Required Travel: 0 - 10%

Employment Type: Full Time/Salaried/Exempt

Anticipated Salary Range: $109,269.00 - $140,000.00

Security Clearance: Secret

Level of Experience: Senior HI

This opportunity resides with All-Domain Operations (ADO), a business group within HII's Mission Technologies division. All-Domain Operations comprises multi-domain operations, platforms and logistics, and intelligence operations.

HII designs, develops, integrates and manages the sensors, systems and other assets necessary to support integrated ISR operations and accelerated decision-making. With data fusion and mission management capabilities for the Department of Defense, the combatant commands and the intelligence community, HII advances the mission around the globe.

Meet HII's Mission Technologies Division
Our team of more than 7,000 professionals worldwide delivers all-domain expertise and advanced technologies in service of mission partners across the globe. Mission Technologies is leading the next evolution of national defense - the data evolution - by accelerating a breadth of national security solutions for government and commercial customers. Our capabilities range from C5ISR, AI and Big Data, cyber operations and synthetic training environments to fleet sustainment, environmental remediation and the largest family of unmanned underwater vehicles in every class. Find the role that's right for you. Apply today. We look forward to meeting you.

To learn more about Mission Technologies, click here for a short video: https://vimeo.com/732533072

Summary:

HII Mission Technologies has been selected as one of Military.com's ""Top 25 Employers for Veterans in 2024"" and we are a Forbes Best Large Employer for 2021-2024!

Are you ready to take your career to the next level? We are seeking talented and motivated Data Scientists to join our team!

HII-Mission Technologies is seeking an experienced and innovative Data Scientist to join our team in Honolulu, Hawaii. The successful candidate will be responsible for the application of complex and advanced scientific theories, concepts, principles, and processes. Recognized within the company and the technical community as an authority in one or more scientific disciplines, you will play a critical role in developing and implementing cutting-edge solutions to address complex technical and business challenges.

#LI-SF1

What You Will Do:

As a leader in your field, you will contribute to the planning, oversight, execution, and evaluation of multiple advanced technical and scientific projects. You will work collaboratively with senior personnel, program managers, and external organizations, while maintaining a strong liaison with staff and customers.

Key Responsibilities
• Research & Development: Develop advanced concepts, techniques, and standards to address technical challenges and drive innovation.
• Thought Leadership: Publish professional and scientific papers and patents to establish and maintain thought leadership in the technical community.
• Application Development: Create and implement new applications based on professional principles and theories, enhancing the organization's capabilities.
• Collaboration: Partner with cross-functional teams to integrate innovative data solutions into broader organizational strategies.
• Problem Solving: Utilize advanced data analytics, machine learning, and statistical methods to deliver actionable insights for complex organizational challenges.
• Technology Implementation: Advocate for and implement state-of-the-art technologies to maintain the organization's competitive edge in data science.
• Project Oversight: Manage the planning and execution of multiple projects, ensuring alignment with organizational goals and stakeholder needs.
• Compliance & Ethics: Ensure adherence to ethical data handling practices and compliance with relevant data governance frameworks.

What We're Looking For:
• 5 years relevant experience with Bachelors in related field; 3 years relevant experience with Masters in related field; 0 years experience with PhD or Juris Doctorate in related field; or High School Diploma or equivalent and 9 years relevant experience.
• Exceptional problem-solving skills and the ability to derive insights from complex datasets.
• Excellent written and verbal communication skills, with experience presenting to technical audiences.
• Active DoD Secret level clearance

HII is more than a job - it's an opportunity to build a new future. We offer competitive benefits such as best-in-class medical, dental and vision plan choices; wellness resources; employee assistance programs; Savings Plan Options (401(k)); financial planning tools, life insurance; employee discounts; paid holidays and paid time off; tuition reimbursement; as well as early childhood and post-secondary education scholarships. Bonus/other non-recurrent compensation is occasionally offered for qualified positions, and if applicable to this role will be addressed by the recruiter at the screening phase of application.

Why HII
We build the world's most powerful, survivable naval ships and defense technology solutions that safeguard our seas, sky, land, space and cyber. Our workforce includes skilled tradespeople; artificial intelligence, machine learning (AI/ML) experts; engineers; technologists; scientists; logistics experts; and business administration professionals.

Recognized as one of America's top large company employers, we are a values and ethics driven organization that puts people's safety and well-being first. Regardless of your role or where you serve, at HII, you'll find a supportive and welcoming environment, competitive benefits, and valuable educational and training programs for continual career growth at every stage of your career.

Together we are working to ensure a future where everyone can be free and thrive.
All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, physical or mental disability, age, or veteran status or any other basis protected by federal, state, or local law.

Do You Need Assistance?
If you need a reasonable accommodation for any part of the employment process, please send an e-mail to buildyourcareer@hii-co.com and let us know the nature of your request and your contact information. Reasonable accommodations are considered on a case-by-case basis. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this email address. Additionally, you may also call 1-844-849-8463 for assistance. Press #3 for HII Mission Technologies.",2025-07-25T15:00:00.000Z,2025-07-25,"['The successful candidate will be responsible for the application of complex and advanced scientific theories, concepts, principles, and processes', '5 years relevant experience with Bachelors in related field; 3 years relevant experience with Masters in related field; 0 years experience with PhD or Juris Doctorate in related field; or High School Diploma or equivalent and 9 years relevant experience', 'Exceptional problem-solving skills and the ability to derive insights from complex datasets', 'Excellent written and verbal communication skills, with experience presenting to technical audiences', 'Active DoD Secret level clearance']","['All-Domain Operations comprises multi-domain operations, platforms and logistics, and intelligence operations', 'HII designs, develops, integrates and manages the sensors, systems and other assets necessary to support integrated ISR operations and accelerated decision-making', 'With data fusion and mission management capabilities for the Department of Defense, the combatant commands and the intelligence community, HII advances the mission around the globe', 'Recognized within the company and the technical community as an authority in one or more scientific disciplines, you will play a critical role in developing and implementing cutting-edge solutions to address complex technical and business challenges', 'As a leader in your field, you will contribute to the planning, oversight, execution, and evaluation of multiple advanced technical and scientific projects', 'You will work collaboratively with senior personnel, program managers, and external organizations, while maintaining a strong liaison with staff and customers', 'Research & Development: Develop advanced concepts, techniques, and standards to address technical challenges and drive innovation', 'Thought Leadership: Publish professional and scientific papers and patents to establish and maintain thought leadership in the technical community', ""Application Development: Create and implement new applications based on professional principles and theories, enhancing the organization's capabilities"", 'Collaboration: Partner with cross-functional teams to integrate innovative data solutions into broader organizational strategies', 'Problem Solving: Utilize advanced data analytics, machine learning, and statistical methods to deliver actionable insights for complex organizational challenges', ""Technology Implementation: Advocate for and implement state-of-the-art technologies to maintain the organization's competitive edge in data science"", 'Project Oversight: Manage the planning and execution of multiple projects, ensuring alignment with organizational goals and stakeholder needs', 'Compliance & Ethics: Ensure adherence to ethical data handling practices and compliance with relevant data governance frameworks']",True,[],,"['Data Analytics', 'Machine Learning', 'Statistical Methods', 'Data Fusion', 'Application Development', 'Data Governance']",Data Analytics: Utilize advanced data analytics to deliver actionable insights for complex organizational challenges.; Machine Learning: Apply machine learning methods to solve complex technical and business problems and drive innovation.; Statistical Methods: Use statistical methods to analyze complex datasets and support decision-making processes.; Data Fusion: Support integrated ISR operations through data fusion capabilities to enhance mission management for defense and intelligence communities.; Application Development: Create and implement new applications based on professional scientific principles and theories to enhance organizational capabilities.; Data Governance: Ensure adherence to ethical data handling practices and compliance with relevant data governance frameworks.
pz9qdlT5XuoksyxlAAAAAA==,Systems Engineer (SE1/SE2/SE3)  Data Science & Complex Systems,"CCS Global Tech is a rapidly growing Information Technology company with a diverse portfolio of technology products and services and a large network of industry partnerships. With over 22 years of being a successful business with a global talent pool and presence, CCS is a certified Microsoft Gold Partner and specializes in delivering expert Microsoft based solutions for technical and business needs. We have been recognized by Inc. 500 Magazine as one of the fastest growing small companies in the Unites States. we are a Tier 1 vendor for the City and County of San Francisco for Cloud Services, Staffing Services and Training Services. For this multi-year opportunity with a diverse set of needs to address, we are currently focusing on establishing partnerships with individuals as well as companies who can help us enhance our overall service portfolio, cut lead times, and ultimately help us deliver successfully. We currently hold sizable Government accounts in the San Francisco bay area including City and County of San Francisco, San Mateo County, and Santa Clara County. We take great pride in our global reach and local influence. Your experience alongside our highly skilled and talented internal team who guide you along the way, offers key insights into what helps you stand out in a competitive job market. If you are a partner company, please submit resumes with contact information of your own W2 Consultants only. Submitted consultants are expected to have excellent communication skills.

Overview:

We are seeking a Systems Engineer (SE1 SE3) with a strong foundation in complex systems-of-systems engineering and a passion for data science, natural language processing (NLP), and machine learning (ML). This role supports mission-critical efforts to extract, process, and analyze data from unstructured and semi-structured sources to drive strategic insights and operational effectiveness.

Application Process:

Interested candidates should submit their resume detailing their qualifications and experience.

Security Clearance Requirements:
• U.S. Citizenship required
• Active TS/SCI Security Clearance with Polygraph

Key Responsibilities:
• Apply systems engineering principles to design, analyze, and manage complex systems-of-systems architectures
• Extract and transform data from unstructured/semi-structured sources (e.g., PDFs, CONOPS, DoDAF artifacts) using tools such as Apache Tika and PDFMiner
• Develop and apply NLP and ML models to derive insights from textual and structured data
• Conduct qualitative analysis and present findings through data visualization and storytelling
• Collaborate with cross-functional teams to translate mission needs into technical solutions
• Develop and maintain scripts and tools using Python, R, and frameworks such as TensorFlow or PyTorch
• Support the development of system documentation, including requirements specifications, interface definitions, and test plans

Education & Experience Requirements:

Systems Engineer Level 1 (SE1):
• Bachelor's degree in System Engineering, Computer Science, Information Systems, Engineering Science, Engineering Management, or related discipline from an accredited college or university
• Seven (7) years of experience as a Systems Engineer in programs and contracts of similar scope, type, and complexity

Systems Engineer Level 2 (SE2):
• Bachelor's degree as stated above
• Fourteen (14) years of experience as a Systems Engineer in similar roles

Systems Engineer Level 3 (SE3):
• Bachelor's degree as stated above
• Twenty (20) years of experience as a Systems Engineer in similar roles

Note: Five (5) years of additional Systems Engineering experience may be substituted for a Bachelor's degree

Required Skills & Abilities:
• Experience in systems engineering for complex, multi-domain systems
• Proficiency with NLP and ML techniques and tools
• Expertise in data extraction from unstructured/semi-structured documents
• Programming in Python and/or R
• Experience with frameworks such as TensorFlow, PyTorch, Apache Tika, and PDFMiner
• Strong analytical and problem-solving skills with high attention to detail

Desired Skills:
• Familiarity with Department of Defense (DoD) systems, documentation standards, and mission environments
• Experience with data governance, metadata tagging, and schema alignment for enterprise analytics

Fringe Benefits:
• Health Insurance: Comprehensive medical, dental, and vision plans
• Retirement Plan: 401(k) with company match
• Paid Time Off: Generous PTO policy including vacation, sick leave, and holidays
• Professional Development: Opportunities for training, certifications, and career advancement
• Work-Life Balance: Flexible work schedules and remote work options
• Wellness Programs: Employee assistance programs, wellness initiatives, and gym membership discounts

Why Join Us?
• Impactful Work: Contribute to critical government projects that make a difference
• Career Growth: Take advantage of professional development and advancement opportunities
• Supportive Environment: Collaborate in a flexible, team-oriented workplace that values balance
• Competitive Compensation: Enjoy a competitive salary and comprehensive benefits package",2025-07-22T00:00:00.000Z,2025-07-25,"['Interested candidates should submit their resume detailing their qualifications and experience', 'U.S. Citizenship required', 'Active TS/SCI Security Clearance with Polygraph', ""Bachelor's degree in System Engineering, Computer Science, Information Systems, Engineering Science, Engineering Management, or related discipline from an accredited college or university"", 'Seven (7) years of experience as a Systems Engineer in programs and contracts of similar scope, type, and complexity', ""Bachelor's degree as stated above"", 'Fourteen (14) years of experience as a Systems Engineer in similar roles', ""Bachelor's degree as stated above"", 'Twenty (20) years of experience as a Systems Engineer in similar roles', ""Note: Five (5) years of additional Systems Engineering experience may be substituted for a Bachelor's degree"", 'Experience in systems engineering for complex, multi-domain systems', 'Proficiency with NLP and ML techniques and tools', 'Expertise in data extraction from unstructured/semi-structured documents', 'Programming in Python and/or R', 'Experience with frameworks such as TensorFlow, PyTorch, Apache Tika, and PDFMiner', 'Strong analytical and problem-solving skills with high attention to detail']","['Submitted consultants are expected to have excellent communication skills', 'This role supports mission-critical efforts to extract, process, and analyze data from unstructured and semi-structured sources to drive strategic insights and operational effectiveness', 'Apply systems engineering principles to design, analyze, and manage complex systems-of-systems architectures', 'Extract and transform data from unstructured/semi-structured sources (e.g., PDFs, CONOPS, DoDAF artifacts) using tools such as Apache Tika and PDFMiner', 'Develop and apply NLP and ML models to derive insights from textual and structured data', 'Conduct qualitative analysis and present findings through data visualization and storytelling', 'Collaborate with cross-functional teams to translate mission needs into technical solutions', 'Develop and maintain scripts and tools using Python, R, and frameworks such as TensorFlow or PyTorch', 'Support the development of system documentation, including requirements specifications, interface definitions, and test plans']",True,"['TensorFlow', 'PyTorch']",TensorFlow: Use TensorFlow framework to develop and apply neural network models as part of machine learning and NLP tasks.; PyTorch: Use PyTorch framework to develop and apply neural network models as part of machine learning and NLP tasks.,"['Natural Language Processing', 'Machine Learning', 'Data Extraction from Unstructured/Semi-structured Sources', 'Python Programming', 'R Programming', 'Data Visualization and Storytelling']","Natural Language Processing: Develop and apply NLP models to derive insights from textual and structured data extracted from unstructured and semi-structured sources such as PDFs and DoDAF artifacts.; Machine Learning: Develop and apply ML models to analyze data and drive strategic insights and operational effectiveness in mission-critical efforts.; Data Extraction from Unstructured/Semi-structured Sources: Extract and transform data from unstructured and semi-structured documents using tools like Apache Tika and PDFMiner to support analysis and insight generation.; Python Programming: Develop and maintain scripts and tools using Python to support data processing, analysis, and model development.; R Programming: Develop and maintain scripts and tools using R to support data processing, analysis, and model development.; Data Visualization and Storytelling: Conduct qualitative analysis and present findings through data visualization and storytelling to communicate insights effectively."
gcu5TL4WgQ8LDCeMAAAAAA==,"Data Scientist (Secret Clearance in Suffolk, VA) Jobs","Our Deloitte Cyber team understands the unique challenges and opportunities businesses face in cybersecurity. Join our team to deliver powerful solutions to help our clients navigate the ever-changing threat landscape. Through powerful solutions and managed services that simplify complexity, we enable our clients to operate with resilience, grow with confidence, and proactively manage to secure success.

Work You'll Do:

Provide and oversee system design, data systems analysis, and implementation of tools and technologies to meet our Client's mission and information needs. Support development and implementation of DON data strategies.

The Team:

Deloitte's Government and Public Services (GPS) practice - our people, ideas, technology and outcomes-is designed for impact. Serving federal, state, & local government clients as well as public higher education institutions, our team of over 15,000+ professionals brings fresh perspective to help clients anticipate disruption, reimagine the possible, and fulfill their mission promise.

Our Cyber Strategy & Transformation offering develops and transforms cyber programs in line with a client's strategic objectives, regulatory requirements, and risk appetite. It keeps the enterprise a step ahead of the evolving threat landscape and gives stakeholders confidence in the organization's cyber posture. Includes design of the cyber organization, governance, and risk assessments.

Qualifications:

Required:
• Bachelor's degree required.
• Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future.
• Active Secret required.
• Must be local to the Hampton Roads area and able to come onsite in Suffolk, VA for 5 days a week.
• At least 5+ years of experience developing software and databases using modern software tools and frameworks.
• 5+ years of the following experience:
• Established and maintained data pipelines using Python and SQL
• Delivered demonstrations at various professional symposiums
• Led requirements gathering engagements with stakeholders
• Led quality assurance reviews of projects

As used in this posting, ""Deloitte"" means Deloitte Transactions and Business Analytics LLP, a subsidiary of Deloitte LLP. Please see www.deloitte.com/us/about for a detailed description of the legal structure of Deloitte LLP and its subsidiaries.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.

Information for applicants with a need for accommodation: https://www2.deloitte.com/us/en/pages/careers/articles/join-deloitte-assistance-for-disabled-applicants.html",2025-07-22T00:00:00.000Z,2025-07-25,"[""Bachelor's degree required"", 'Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future', 'Active Secret required', 'Must be local to the Hampton Roads area and able to come onsite in Suffolk, VA for 5 days a week', 'At least 5+ years of experience developing software and databases using modern software tools and frameworks', '5+ years of the following experience:', 'Established and maintained data pipelines using Python and SQL', 'Led requirements gathering engagements with stakeholders', 'Led quality assurance reviews of projects']","[""Provide and oversee system design, data systems analysis, and implementation of tools and technologies to meet our Client's mission and information needs"", 'Support development and implementation of DON data strategies', ""It keeps the enterprise a step ahead of the evolving threat landscape and gives stakeholders confidence in the organization's cyber posture"", 'Includes design of the cyber organization, governance, and risk assessments', 'Delivered demonstrations at various professional symposiums']",True,[],,"['Data Pipelines', 'Python', 'SQL']","Data Pipelines: Responsible for establishing and maintaining data pipelines using Python and SQL to support client mission and information needs.; Python: Used as a modern software tool to develop software and databases, including building and maintaining data pipelines.; SQL: Utilized for database development and managing data pipelines to meet client data strategy requirements."
MoTsdRVI_VQZ46nNAAAAAA==,Data Engineer Jobs,"Primary Senior Data Engineer Responsibilities:

Provide technical monitoring and oversight to multiple projects as they integrate data analysis & automation into their workflow

Guide technical development through assessment and evaluation of customized solutions that meet evolving project requirements

Oversee the development of data solutions to assist and accelerate government research and development

Conduct appropriate testing on all developed infrastructures

Senior Data Engineer Required Qualifications:

Must be a U.S. citizen with the ability to obtain/maintain a Top Secret security clearance

Bachelor’s degree in Computer Science, Information Technology, Operations Research, Mathematics, Physics along with a minimum of 5 to 7 years of relevant industry or academic experience

Remote work is approved for this role

Occasional Travel is required

Strong programming skills in Python and SQL, and experience with other languages (GO, C++, etc.)

Communicate complex quantitative matters in a clear, precise, and actionable manner

Strong sense of ownership and attention to detail

Senior Data Engineer Desired Qualifications:

Advanced degree in Computer Science, Information Technology, Operations Research, Mathematics, Physics or a related field

Related experience in cybersecurity and/or binary analysis

Strong willingness to expand the knowledge base

Acumen for autonomous work alongside a collaborative team",2025-07-24T00:00:00.000Z,2025-07-25,"['Must be a U.S. citizen with the ability to obtain/maintain a Top Secret security clearance', 'Bachelor’s degree in Computer Science, Information Technology, Operations Research, Mathematics, Physics along with a minimum of 5 to 7 years of relevant industry or academic experience', 'Remote work is approved for this role', 'Occasional Travel is required', 'Strong programming skills in Python and SQL, and experience with other languages (GO, C++, etc.)', 'Communicate complex quantitative matters in a clear, precise, and actionable manner', 'Strong sense of ownership and attention to detail', 'Advanced degree in Computer Science, Information Technology, Operations Research, Mathematics, Physics or a related field', 'Related experience in cybersecurity and/or binary analysis', 'Strong willingness to expand the knowledge base', 'Acumen for autonomous work alongside a collaborative team']","['Provide technical monitoring and oversight to multiple projects as they integrate data analysis & automation into their workflow', 'Guide technical development through assessment and evaluation of customized solutions that meet evolving project requirements', 'Oversee the development of data solutions to assist and accelerate government research and development', 'Conduct appropriate testing on all developed infrastructures']",False,,,,
76N88hiAX0Vi-aMyAAAAAA==,"Data Scientist II, Supply Chain Retail Technology","The salary range for this position is $121,000 - $132,000 per year. The base salary offered may vary depending on location, job-related knowledge, skills, and experience.

This is a hybrid-onsite role. Employees are expected to be in our Boston, MA office Tuesdays-Thursday, and work remotely Mondays and Fridays.

Who We Are

The Supply Chain Retail Technology Data Science team is dedicated to understanding and optimizing user interactions with our Supply Chain & Retail Technology suite of tools and products. SCRT Data Science is responsible for integrating analytics into the DNA of these growing tech teams, unlocking the insights that will guide the business in our quest for cost-efficient, perfect orders, at scale, with AI and data science techniques playing a crucial role in processing vast datasets and predicting optimal outcomes. We bring a multidisciplinary blend of analytical aptitude, technical expertise, business strategy, and stakeholder management. Moreover, we're a highly collaborative, supportive team that values learning, psychological safety, and intentional career development.

What You'll Do
• Own the insights that inform the SCRT product roadmap, including driving outcomes within Fulfillment, Transportation and Service Technology.
• Perform deep-dive analysis, including the application of advanced analytical techniques and data science models, to solve critical and complex business problems.
• Leverage AI-powered platforms and tools to enhance existing analytical frameworks, automate data discovery, identify hidden patterns, and generate prescriptive recommendations, accelerating the delivery of actionable insights to product and engineering teams.
• Collaborate with all facets of the organization including product management, engineering, and creative design to identify the most impactful ways for data and analytics to drive decision making.
• Become the subject matter expert for data, analytics, and testing for your area to ensure accurate and proper interpretation of core metrics and user behavior.
• Build machine learning proof-of-concepts by developing Python code to train models and visualize their outputs, in order to demonstrate the art of the possible to stakeholders.
• Develop data visualizations, including reports, dashboards, and analyses in Looker and GBQ to distribute data insights in an easily digestible manner.
• Stay abreast of the latest advancements in AI and machine learning, particularly as they apply to supply chain, logistics, and service technology, and advocate for their strategic adoption to maintain a competitive analytical edge.

What You'll Need
• Proficient knowledge of SQL and statistical programming language(s) such as Python, R, SAS, or SPSS (Python preferred)
• Expert at conducting quantitative analyses on large and complex data sets, including ability to explain techniques to both technical and non-technical stakeholders.
• Experience with experimental test design (e.g., A/B testing; Multivariate and Multi-Armed Bandit) and statistical analysis to drive business decision making.
• Experience in using AI-powered platforms to enhance and accelerate Data Science output (i.e. generating SQL and researching techniques using ChatGPT, analyzing text using Gemini Pro...)
• Experience with data visualization software (e.g. Google Looker Studio/Looker, Tableau, PowerBI).
• Experience applying data science techniques and partnering with business teams on agile model development.
• Strong written and verbal communication skills covering objectives, status, results, and recommendations.
• Bachelors in computer science, engineering, math, statistics, economics, Operations Research, Industrial engineering or other quantitative discipline; Masters preferred.
• 3+ years work experience in relevant field

About Wayfair Inc.

Wayfair is one of the world's largest online destinations for the home. Whether you work in our global headquarters in Boston, or in our warehouses or offices throughout the world, we're reinventing the way people shop for their homes. Through our commitment to industry-leading technology and creative problem-solving, we are confident that Wayfair will be home to the most rewarding work of your career. If you're looking for rapid growth, constant learning, and dynamic challenges, then you'll find that amazing career opportunities are knocking.

No matter who you are, Wayfair is a place you can call home. We're a community of innovators, risk-takers, and trailblazers who celebrate our differences, and know that our unique perspectives make us stronger, smarter, and well-positioned for success. We value and rely on the collective voices of our employees, customers, community, and suppliers to help guide us as we build a better Wayfair - and world - for all. Every voice, every perspective matters. That's why we're proud to be an equal opportunity employer. We do not discriminate on the basis of race, color, ethnicity, ancestry, religion, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, veteran status, genetic information, or any other legally protected characteristic.

Your personal data is processed in accordance with our Candidate Privacy Notice ( If you have any questions or wish to exercise your rights under applicable privacy and data protection laws, please contact us at",2025-07-19T00:00:00.000Z,2025-07-25,"['Expert at conducting quantitative analyses on large and complex data sets, including ability to explain techniques to both technical and non-technical stakeholders', 'Experience with experimental test design (e.g., A/B testing; Multivariate and Multi-Armed Bandit) and statistical analysis to drive business decision making', 'Experience in using AI-powered platforms to enhance and accelerate Data Science output (i.e. generating SQL and researching techniques using ChatGPT, analyzing text using Gemini Pro...)', 'Experience with data visualization software (e.g', 'Experience applying data science techniques and partnering with business teams on agile model development', 'Strong written and verbal communication skills covering objectives, status, results, and recommendations', '3+ years work experience in relevant field']","['Own the insights that inform the SCRT product roadmap, including driving outcomes within Fulfillment, Transportation and Service Technology', 'Perform deep-dive analysis, including the application of advanced analytical techniques and data science models, to solve critical and complex business problems', 'Leverage AI-powered platforms and tools to enhance existing analytical frameworks, automate data discovery, identify hidden patterns, and generate prescriptive recommendations, accelerating the delivery of actionable insights to product and engineering teams', 'Collaborate with all facets of the organization including product management, engineering, and creative design to identify the most impactful ways for data and analytics to drive decision making', 'Become the subject matter expert for data, analytics, and testing for your area to ensure accurate and proper interpretation of core metrics and user behavior', 'Build machine learning proof-of-concepts by developing Python code to train models and visualize their outputs, in order to demonstrate the art of the possible to stakeholders', 'Develop data visualizations, including reports, dashboards, and analyses in Looker and GBQ to distribute data insights in an easily digestible manner', 'Stay abreast of the latest advancements in AI and machine learning, particularly as they apply to supply chain, logistics, and service technology, and advocate for their strategic adoption to maintain a competitive analytical edge']",True,"['AI-Powered Platforms', 'ChatGPT', 'Gemini Pro']","AI-Powered Platforms: Leveraged to enhance existing analytical frameworks, automate data discovery, identify hidden patterns, and generate prescriptive recommendations, thereby accelerating delivery of actionable insights to product and engineering teams.; ChatGPT: Utilized as an AI-powered tool to generate SQL queries and research techniques, enhancing and accelerating data science output.; Gemini Pro: Used as an AI-powered platform for text analysis to support data science tasks and improve analytical capabilities.","['SQL', 'Python', 'R', 'SAS', 'SPSS', 'A/B Testing', 'Multivariate Testing', 'Multi-Armed Bandit', 'Data Visualization', 'Looker', 'Google BigQuery (GBQ)', 'Tableau', 'PowerBI', 'Machine Learning', 'Advanced Analytical Techniques']","SQL: Used for querying and managing large and complex datasets to support data analysis and insights generation.; Python: Employed for developing machine learning proof-of-concepts, training models, and visualizing outputs to demonstrate possibilities to stakeholders.; R: Mentioned as a statistical programming language option for conducting quantitative analyses and statistical modeling.; SAS: Listed as a statistical programming language option for quantitative analysis and statistical modeling.; SPSS: Included as a statistical programming language option for conducting quantitative analyses and statistical modeling.; A/B Testing: Used as an experimental test design technique to drive business decision making through controlled experiments.; Multivariate Testing: Applied as an experimental design method to evaluate multiple variables simultaneously for business insights.; Multi-Armed Bandit: Utilized as an experimental test design approach to optimize decision making by balancing exploration and exploitation.; Data Visualization: Involves creating reports, dashboards, and analyses using tools like Looker, Google BigQuery (GBQ), Tableau, and PowerBI to distribute data insights effectively.; Looker: Used as a data visualization and reporting tool to create dashboards and distribute insights in an accessible format.; Google BigQuery (GBQ): Employed as a data warehousing and querying platform to support data visualization and analysis workflows.; Tableau: Mentioned as a data visualization software used to create interactive dashboards and reports for business stakeholders.; PowerBI: Used as a business intelligence tool for data visualization and reporting to support decision making.; Machine Learning: Applied to build proof-of-concept models using Python to solve complex business problems and demonstrate potential solutions.; Advanced Analytical Techniques: Used to perform deep-dive analyses and develop data science models that address critical and complex business challenges."
_gZKL81fh2RZAVeSAAAAAA==,Data Scientist/Engineer - Entry/Junior Level,"This a Full Remote job, the offer is available from: California (USA)

2024 is finally here and we hope the Job market improves however as per a resume builder survey based on response from more than 900 companies 4 out of 10 companies are planning to have layoffs in 2024 or have a hiring freeze. Almost 390,000 tech employees have been laid off since 2022 and it's still ongoing. The effect of this has led hundreds of thousands of laid off Tech employees competing with existing Jobseekers.

AI is replacing many normal jobs which were done by people. As per news reports Google is planning to Client off 30,000 employees in its ad sales who will be replaed by AI ad technology.

Entry level Job seekers struggle to get responses to their applications, are getting ghosted after interviews. In such a scenario the Job seekers need to differentiate themselves by ensuring to obtain exceptional skills and technologies so that they can wear multiple roles at a client as clients now would want to expand roles and responsibilities assigned to a particular job to save costs.

Since 2010 Synergisticit has helped Jobseekers differentiate themselves by providing candidates the requisite skills and experience to outperform at interviews and clients. Here at SynergisticIT We just don't focus on getting you a Job we make careers.

All Positions are open for all visas and US citizens

We are matchmakers we provide clients with candidates who can perform from day 1 of starting work. In this challenging economy every client wants to save $$$'s and they want the best value for their money. Jobseekers need to self-evaluate if they have the requisite skills to meet client requirements and needs as Clients now post covid can also hire remote workers which increases even more competition for jobseekers.

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart lab s etc to name a few.

We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.

We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

We also offer Skill and technology enhancement programs for candidates who are either missing skills or are lacking Industry/Client experience with Projects and skills. Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. If a Jobseeker is qualified with enough skills and have hands on project work at clients then they should be good to be submitted to clients. Shortlisting and selection are totally based on clients discretion not ours.

If you applied for a job and got emails from our skill enhancement team please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team.

please check the below links to see success outcomes of our candidates and our participation at different Tech industry events and how we are different from other organizations in helping Jobseekers secure Tech careers

https://www.synergisticit.com/candidate-outcomes/

We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please see us exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023

https://reg.rf.oracle.com/flow/oracle/cwoh23/OCWExhibitorCatalog/page/OCWexhibitorcatalog

https://youtu.be/Rfn8Y0gnfL8?si=p2V4KFv5HukJXTrn

https://youtu.be/-HkNN1ag6Zk?si=1NRfgsvL_HJMVb6Q

https://www.youtube.com/watch?v=NVBU9RYZ6UI

https://www.youtube.com/watch?v=EmO7NrWHkLM

https://www.youtube.com/watch?v=OAFOhcGy9Z8

For preparing for interviews please visit https://www.synergisticit.com/interview-questions/

We are looking for the right matching candidates for our clients

Please apply via the job posting

REQUIRED SKILLS For Java /Full stack/Software Programmer

· Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

· Highly motivated, self-learner, and technically inquisitive

· Experience in programming language Java and understanding of the software development life cycle

· Project work on the skills

· Knowledge of Core Java , javascript , C++ or software programming

· Spring boot, Microservices, Docker, Jenkins and REST API's experience

· Excellent written and verbal communication skills

For data Science/Machine learning Positions

REQUIRED SKILLS

· Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

· Project work on the technologies needed

· Highly motivated, self-learner, and technically inquisitive

· Experience in programming language Java and understanding of the software development life cycle

· Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools

· Excellent written and verbal communication skills

Preferred skills: NLP, Text mining, Tableau, PowerBI, SAS, Tensorflow

If you get emails from our skill enhancement team please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates

This offer from ""SynergisticIT"" has been enriched by Jobgether.com and got a 72% flex score.",2025-07-21T00:00:00.000Z,2025-07-25,"['Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry', 'Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio', 'If a Jobseeker is qualified with enough skills and have hands on project work at clients then they should be good to be submitted to clients', 'REQUIRED SKILLS For Java /Full stack/Software Programmer', 'Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT', 'Highly motivated, self-learner, and technically inquisitive', 'Experience in programming language Java and understanding of the software development life cycle', 'Project work on the skills', 'Knowledge of Core Java , javascript , C++ or software programming', ""Spring boot, Microservices, Docker, Jenkins and REST API's experience"", 'Excellent written and verbal communication skills', 'For data Science/Machine learning Positions', 'Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT', 'Project work on the technologies needed', 'Highly motivated, self-learner, and technically inquisitive', 'Experience in programming language Java and understanding of the software development life cycle', 'Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools', 'Excellent written and verbal communication skills']",,True,['TensorFlow'],"TensorFlow: TensorFlow is preferred for machine learning and deep learning projects, indicating use of neural network frameworks.","['Statistics', 'SAS', 'Python', 'Data Visualization Tools', 'Machine Learning', 'Computer Vision', 'Java', 'Core Java', 'JavaScript', 'C++', 'Spring Boot', 'Microservices', 'Docker', 'Jenkins', 'REST APIs', 'NLP', 'Project Work']","Statistics: Knowledge of statistics is required for data science and machine learning positions to analyze and interpret data effectively.; SAS: Experience with SAS is preferred for data analysis and statistical modeling tasks.; Python: Python programming skills are needed for data science and machine learning projects, including data manipulation and analysis.; Data Visualization Tools: Familiarity with data visualization tools such as Tableau and PowerBI is preferred to create dashboards and visual reports.; Machine Learning: Machine learning knowledge is required for data science roles, including project work on relevant technologies.; Computer Vision: Experience or knowledge in computer vision is mentioned as part of the data science skill set.; Java: Java programming experience is required, including understanding of the software development life cycle, relevant for both data science and software development roles.; Core Java: Knowledge of Core Java is required for software programming tasks.; JavaScript: JavaScript knowledge is required for software programming and full stack development.; C++: C++ programming knowledge is required for software programming.; Spring Boot: Experience with Spring Boot framework is required for building microservices and backend applications.; Microservices: Experience with microservices architecture is required for software development roles.; Docker: Docker experience is required for containerization and deployment of applications.; Jenkins: Jenkins experience is required for continuous integration and continuous deployment (CI/CD) pipelines.; REST APIs: Experience with REST APIs is required for building and consuming web services.; NLP: Natural Language Processing is a preferred skill for text mining and data analysis tasks.; Project Work: Hands-on project experience is emphasized as important for demonstrating skills in data science, machine learning, and software development."
Jb1RDQ_HhaFRXyACAAAAAA==,Data Scientist/Senior Exploitation Specialist Jobs,"Overview

Iron EagleX (IEX), a wholly owned subsidiary of General Dynamics Information Technology, delivers agile IT and Intelligence solutions. Combining small-team flexibility with global scale, IEX leverages emerging technologies to provide innovative, user-focused solutions that empower organizations and end users to operate smarter, faster, and more securely in dynamic environments.

Responsibilities

Job Description:

The Senior Data Scientist will be responsible for querying, visualizing, aggregating, correlating, and analyzing big data across intel disciplines on-site at multiple NGA locations in Tampa, FL, St. Louis, MO or Springfield, VA optimizing existing databases to improve response time. The DS will also be required to script in Visual Basic, R, python and work with ArcGIS, Excel, SPSS, SAS, MatLab, R, etc. to maintain, access, and move data from databases and applications to include: SQL databases, ArcServer, NoSQL databases, Excel, and Tableau.

Job Duties Include (but not limited to):
• Develop methods for querying, visualizing, aggregating, correlating, and analyzing big data across intelligence disciplines.
• Optimize existing databases to speed up the query, input, export, and visualization of data.
• Work with AOS and NGA CENTCOM (AOB) teams to develop strategies for exposing new datasets and create migration plans for legacy datasets.
• Build custom solutions (tools, processes, etc.) to automate or assist analytic endeavors as submitted by AOS and AOB leadership and analytic units.
• Write scripts in Visual Basic, R, Python or other software for statistical models using large datasets to extract patterns, relationships, and anticipatory behaviors that are repeatable, efficient, hypothesis testing, and knowledge capture.
• Solve complex GEOINT analysis problem sets; understand concepts associated with structured data and relational databases.
• Maintain, move, and manipulate data between applications, using appropriate software; SQL databases, ArcServer, table data, relational/NoSQL DBMS, Microsoft EXCEL spreadsheets, ACCESS database management system, Tableau, Insights, ORACLE, and analyst provided data for ingest and cleaning.
• Develop tradecraft techniques, training solutions for discovery, preparation, manipulation and normalization of big data so that methods are repeatable and can be explained to users.

Qualifications

Required Skills & Experience:
• Must have a background with intelligence experience, including providing analysis and data science to an intelligence mission.
• Must be able to operate at a senior level and in an independent environment.
• These individuals will be some of the only data science support this office has ever received directly.
• Must be proficient at creating processes around large data sets to identify analytical discoveries.
• Must be able to take these discoveries and provide them through visualizations that are easily integrated into daily operations.
• Able to apply structured processes to enrich or manage data
• Able to apply GEOINT standards and quality.
• Able to communicate with clarity and accuracy both verbally and written.
• Due to U.S. Government contract requirements, only U.S. citizens are eligible for this role.

Education & Certifications:
• Bachelor's degree in Computer Science is preferred

Security Clearance:
• An active TS/SCI security clearance is Required

Benefits:
• National health, vision, and dental plans
• 20 days of PTO and 11 paid holidays
• Life Insurance
• Short- and long-term disability plans
• 401(K) retirement plan
• Incentive and recognition programs
• Relocation opportunities

Equal Opportunity Employer / Individuals with Disabilities / Protected Veterans",2025-07-21T00:00:00.000Z,2025-07-25,"['The DS will also be required to script in Visual Basic, R, python and work with ArcGIS, Excel, SPSS, SAS, MatLab, R, etc', 'to maintain, access, and move data from databases and applications to include: SQL databases, ArcServer, NoSQL databases, Excel, and Tableau', 'Must have a background with intelligence experience, including providing analysis and data science to an intelligence mission', 'Must be able to operate at a senior level and in an independent environment', 'These individuals will be some of the only data science support this office has ever received directly', 'Must be proficient at creating processes around large data sets to identify analytical discoveries', 'Must be able to take these discoveries and provide them through visualizations that are easily integrated into daily operations', 'Able to apply structured processes to enrich or manage data', 'Able to apply GEOINT standards and quality', 'Able to communicate with clarity and accuracy both verbally and written', 'Due to U.S. Government contract requirements, only U.S. citizens are eligible for this role', 'An active TS/SCI security clearance is Required']","['The Senior Data Scientist will be responsible for querying, visualizing, aggregating, correlating, and analyzing big data across intel disciplines on-site at multiple NGA locations in Tampa, FL, St. Louis, MO or Springfield, VA optimizing existing databases to improve response time', 'Develop methods for querying, visualizing, aggregating, correlating, and analyzing big data across intelligence disciplines', 'Optimize existing databases to speed up the query, input, export, and visualization of data', 'Work with AOS and NGA CENTCOM (AOB)', 'teams to develop strategies for exposing new datasets and create migration plans for legacy datasets', 'Build custom solutions (tools, processes, etc.)', 'to automate or assist analytic endeavors as submitted by AOS and AOB leadership and analytic units', 'Write scripts in Visual Basic, R, Python or other software for statistical models using large datasets to extract patterns, relationships, and anticipatory behaviors that are repeatable, efficient, hypothesis testing, and knowledge capture', 'Solve complex GEOINT analysis problem sets; understand concepts associated with structured data and relational databases', 'Maintain, move, and manipulate data between applications, using appropriate software; SQL databases, ArcServer, table data, relational/NoSQL DBMS, Microsoft EXCEL spreadsheets, ACCESS database management system, Tableau, Insights, ORACLE, and analyst provided data for ingest and cleaning', 'Develop tradecraft techniques, training solutions for discovery, preparation, manipulation and normalization of big data so that methods are repeatable and can be explained to users']",True,[],,"['Big Data Analytics', 'Statistical Modeling', 'Data Visualization', 'Database Management', 'Data Integration and ETL', 'Scripting and Programming Languages', 'Geospatial Intelligence (GEOINT) Analysis', 'Data Preparation and Normalization']","Big Data Analytics: Responsible for querying, visualizing, aggregating, correlating, and analyzing large datasets across intelligence disciplines to extract meaningful insights and improve operational response times.; Statistical Modeling: Writing scripts in Visual Basic, R, and Python to develop statistical models that identify patterns, relationships, and anticipatory behaviors in large datasets, supporting hypothesis testing and knowledge capture.; Data Visualization: Creating visualizations that effectively communicate analytical discoveries and are easily integrated into daily operations, using tools such as Tableau and Excel.; Database Management: Maintaining, accessing, moving, and optimizing data stored in various database systems including SQL databases, NoSQL databases, ArcServer, Oracle, and Access to improve query performance and data handling.; Data Integration and ETL: Developing processes and custom tools to automate data ingestion, cleaning, migration, and normalization from legacy and new datasets to ensure repeatable and explainable data workflows.; Scripting and Programming Languages: Utilizing programming languages such as Visual Basic, R, and Python to support data manipulation, statistical analysis, and automation of analytic processes.; Geospatial Intelligence (GEOINT) Analysis: Applying GEOINT standards and quality measures to solve complex geospatial analysis problems using structured data and relational databases, often involving ArcGIS and ArcServer.; Data Preparation and Normalization: Developing tradecraft techniques and training solutions for the discovery, preparation, manipulation, and normalization of big data to ensure consistent and repeatable analytic methods."
8YiP-FtLhRFLwhfuAAAAAA==,"Member of Technical Staff, Data Scientist, Copilot Memory and Personalization","Overview

As Microsoft continues to push the boundaries of AI, we are on the lookout for passionate individuals to work with us on the most interesting and challenging AI questions of our time. Our vision is bold and broad - to build systems that have true artificial intelligence across agents, applications, services, and infrastructure. It's also inclusive: we aim to make AI accessible to all - consumers, businesses, developers - so that everyone can realize its benefits.

Microsoft AI (MAI) is seeking experienced Data Scientists to help build Copilot memory and personalization - AI that remembers, evolves, and grows with each user. You'll work in a highly collaborative, fast-paced environment to develop systems that deepen memory with every interaction, personalize experiences to reflect each user's unique style and goals, and make interactions feel more like working with a trusted partner than using a tool.

Microsoft's mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.

By applying to this U.S. Mountain View, CA you are required to be local to the San Francisco area and in office 3 days a week.

Responsibilities

In this role, you will:
• Develop and improve evaluation methodologies to assess model output quality, for both machine eval and human eval metrics and coverage.
• Design and implement scalable data pipelines to extract, transform, and structure product logs for evaluation use cases.
• Stay current on the latest in LLM research on evaluation and prompting.
• Drive actionable product insights, opportunity analyses, and metric tracking to guide product direction and success.
• Drive new ways of instrumentation and measurement approach to evaluate new feature performance through experimentation.
• Design and maintain core data pipelines and conduct hands-on analysis of large-scale telemetry data using advanced algorithms and tools.
• Articulate insights, storyboard with data and communicate to influence leadership and other key decision makers.
• Stay current on the latest in LLM research on evaluation and prompting.
• Enjoy working in a fast-paced, design-driven, product development cycle.

Qualifications

Required Qualifications
• Doctorate in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 1+ year(s) data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results)
• OR Master's Degree in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 3+ years data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results)
• OR Bachelor's Degree in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 5+ years data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results)
• OR equivalent experience.
• 1+ year customer-facing, project-delivery experience, professional services, and/or consulting experience.

Preferred Qualifications
• Doctorate in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 5+ year(s) data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results)
• OR Master's Degree in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 7+ years data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results)
• OR Bachelor's Degree in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 10+ years data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results)
• OR equivalent experience.
• Experience in designing core data pipelines and conduct hands-on analysis of large-scale telemetry data using advanced algorithms and tools.
• Experience building or evaluating LLM applications in production.

Data Science IC4 - The typical base pay range for this role across the U.S. is USD $119,800 - $234,700 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $158,400 - $258,000 per year.

Data Science IC5 - The typical base pay range for this role across the U.S. is USD $139,900 - $274,800 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $188,000 - $304,200 per year.

Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here:

Microsoft will accept applications and processes offers for these roles on an ongoing basis.

#Copilot #MicrosoftAI",2025-06-29T00:00:00.000Z,2025-07-25,"['Doctorate in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 1+ year(s) data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results)', ""OR Master's Degree in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 3+ years data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results)"", ""OR Bachelor's Degree in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 5+ years data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results)"", 'OR equivalent experience', '1+ year customer-facing, project-delivery experience, professional services, and/or consulting experience']","[""You'll work in a highly collaborative, fast-paced environment to develop systems that deepen memory with every interaction, personalize experiences to reflect each user's unique style and goals, and make interactions feel more like working with a trusted partner than using a tool"", 'By applying to this U.S. Mountain View, CA you are required to be local to the San Francisco area and in office 3 days a week', 'Develop and improve evaluation methodologies to assess model output quality, for both machine eval and human eval metrics and coverage', 'Design and implement scalable data pipelines to extract, transform, and structure product logs for evaluation use cases', 'Stay current on the latest in LLM research on evaluation and prompting', 'Drive actionable product insights, opportunity analyses, and metric tracking to guide product direction and success', 'Drive new ways of instrumentation and measurement approach to evaluate new feature performance through experimentation', 'Design and maintain core data pipelines and conduct hands-on analysis of large-scale telemetry data using advanced algorithms and tools', 'Articulate insights, storyboard with data and communicate to influence leadership and other key decision makers', 'Stay current on the latest in LLM research on evaluation and prompting', 'Enjoy working in a fast-paced, design-driven, product development cycle']",True,"['Large Language Models', 'Prompt Engineering', 'Copilot Memory and Personalization AI']","Large Language Models: Stay current on the latest research related to large language models (LLMs), particularly focusing on evaluation and prompting techniques.; Prompt Engineering: Engage with the latest prompting methods for LLMs to improve model interaction and output quality.; Copilot Memory and Personalization AI: Develop AI systems that remember, evolve, and personalize user experiences by deepening memory with every interaction to create trusted partner-like interactions.","['Evaluation Methodologies', 'Data Pipelines', 'Statistical Techniques', 'Advanced Algorithms', 'Product Analytics and Metric Tracking', 'Experimentation and Instrumentation', 'Data Storytelling and Communication']","Evaluation Methodologies: Develop and improve methodologies to assess model output quality using both machine evaluation and human evaluation metrics and coverage.; Data Pipelines: Design, implement, and maintain scalable data pipelines to extract, transform, and structure product logs and large-scale telemetry data for evaluation and analysis purposes.; Statistical Techniques: Apply statistical techniques to manage structured and unstructured data and report results as part of data science responsibilities.; Advanced Algorithms: Use advanced algorithms and tools to conduct hands-on analysis of large-scale telemetry data to derive actionable insights.; Product Analytics and Metric Tracking: Drive actionable product insights, opportunity analyses, and metric tracking to guide product direction and success.; Experimentation and Instrumentation: Develop new instrumentation and measurement approaches to evaluate new feature performance through experimentation.; Data Storytelling and Communication: Articulate insights and storyboard with data to communicate findings effectively and influence leadership and key decision makers."
2p_CYDqO1K29DnsSAAAAAA==,Navy Sepass Geospatial Data Scientist Jobs,"Koniag IT Systems, LLC is seeking a Geospatial Data Scientist to provide enterprise-level geospatial intelligence (GEOINT) systems engineering support for the U.S. Navy. This senior-level position requires an individual who brings extensive expertise in GEOINT architectures, systems integration, and advanced geospatial analysis. The ideal candidate will serve as a technical leader and subject matter expert, providing guidance on complex GEOINT systems, enterprise architecture, and analytical methodologies. This position requires an active TS/SCI clearance.

We offer competitive compensation and an exceptional benefits package, including health, dental, and vision insurance, a 401 (k) with company matching, flexible spending accounts, paid holidays, three weeks of paid time off, and more.

Education and Experience:
• Bachelor of Science degree: 12-15 years of experience in a related field.
• Master of Science degree: 10-13 years of experience in a related field.
• PhD: 10+ years of experience in a related field

Essential responsibilities, Functions, & Duties
• The Data Scientist will provide advisory and assistance support by assessing enterprise geospatial technologies, workflows, processes, procedures, and products in use across the NSG community and providing systems analysis and recommendations to support the Surf Eagle Enterprise Geographic Information System (GIS) Strategy
• The Data Scientist will contribute to the Enterprise GIS Strategy, assist with implementing strategic initiatives, research future technologies, and provide documentation and recommendations to appropriately leverage technological advances and align program stakeholders to the Enterprise GIS Strategy.
• The Data Scientist will monitor resource allocation for SEP and provide resource tracking, resource leveling, and resource allocation assessments for the Surf Eagle development.
• The Data Scientist will perform the full spectrum of systems engineering activities to implement an efficient, cost-effective architecture for the SEP.
• The Data Scientist will prepare and maintain NAVOCEANO and FNMOC-specific architecture views to provide a foundational framework for representing Surf Eagle architecture across the program and determining interoperability within the organizations and across the NSG and DoD.
• The Data Scientist will document existing production processes to include performance metrics to ensure the architecture is adequately managing existing requirements.
• The Data Scientist will identify performance concerns and recommend solutions.
• The Data Scientist will propose infrastructure changes and review other proposed infrastructure changes to ensure the changes align with the approved architecture.
• The Data Scientist will provide support to and assist in COMNAVMETOCCOM's transition to the Intelligence Community Information Technology Enterprise.
• The Data Scientist will provide support in life cycle management, configuration management and change management.
• The Data Scientist will advise the SEP PM on strategic needs for program evolution, including detailed roadmaps for Information Technology infrastructure based on requirements and resulting capabilities of national standards
• The Data Scientist will attend and participate in forums as required by the COR.

Required Skills and Competencies:
• Work independently or as part of a team as needed.
• Strong analytical and problem-solving skills
• Excellent communication abilities

Our Equal Employment Opportunity Policy

The company is an equal opportunity employer. The company shall not discriminate against any employee or applicant because of race, color, religion, creed, ethnicity, sex, sexual orientation, gender or gender identity (except where gender is a bona fide occupational qualification), national origin or ancestry, age, disability, citizenship, military/veteran status, marital status, genetic information or any other characteristic protected by applicable federal, state, or local law. We are committed to equal employment opportunity in all decisions related to employment, promotion, wages, benefits, and all other privileges, terms, and conditions of employment.

The company is dedicated to seeking all qualified applicants. If you require an accommodation to navigate or apply for a position on our website, please get in touch with Heaven Wood via e-mail at [email protected] or by calling 703-488-9377 to request accommodations.

Koniag Government Services (KGS) is an Alaska Native Owned corporation supporting the values and traditions of our native communities through an agile employee and corporate culture that delivers Enterprise Solutions, Professional Services and Operational Management to Federal Government Agencies. As a wholly owned subsidiary of Koniag, we apply our proven commercial solutions to a deep knowledge of Defense and Civilian missions to provide forward leaning technical, professional, and operational solutions. KGS enables successful mission outcomes for our customers through solution-oriented business partnerships and a commitment to exceptional service delivery. We ensure long-term success with a continuous improvement approach while balancing the collective interests of our customers, employees, and native communities. For more information, please visit www.koniag-gs.com.

Equal Opportunity Employer/Veterans/Disabled. Shareholder Preference in accordance with Public Law 88-352.",2025-07-22T00:00:00.000Z,2025-07-25,"['This senior-level position requires an individual who brings extensive expertise in GEOINT architectures, systems integration, and advanced geospatial analysis', 'Bachelor of Science degree: 12-15 years of experience in a related field', 'Master of Science degree: 10-13 years of experience in a related field', 'PhD: 10+ years of experience in a related field', 'Work independently or as part of a team as needed', 'Strong analytical and problem-solving skills', 'Excellent communication abilities']","['The ideal candidate will serve as a technical leader and subject matter expert, providing guidance on complex GEOINT systems, enterprise architecture, and analytical methodologies', 'The Data Scientist will provide advisory and assistance support by assessing enterprise geospatial technologies, workflows, processes, procedures, and products in use across the NSG community and providing systems analysis and recommendations to support the Surf Eagle Enterprise Geographic Information System (GIS) Strategy', 'The Data Scientist will contribute to the Enterprise GIS Strategy, assist with implementing strategic initiatives, research future technologies, and provide documentation and recommendations to appropriately leverage technological advances and align program stakeholders to the Enterprise GIS Strategy', 'The Data Scientist will monitor resource allocation for SEP and provide resource tracking, resource leveling, and resource allocation assessments for the Surf Eagle development', 'The Data Scientist will perform the full spectrum of systems engineering activities to implement an efficient, cost-effective architecture for the SEP', 'The Data Scientist will prepare and maintain NAVOCEANO and FNMOC-specific architecture views to provide a foundational framework for representing Surf Eagle architecture across the program and determining interoperability within the organizations and across the NSG and DoD', 'The Data Scientist will document existing production processes to include performance metrics to ensure the architecture is adequately managing existing requirements', 'The Data Scientist will identify performance concerns and recommend solutions', 'The Data Scientist will propose infrastructure changes and review other proposed infrastructure changes to ensure the changes align with the approved architecture', ""The Data Scientist will provide support to and assist in COMNAVMETOCCOM's transition to the Intelligence Community Information Technology Enterprise"", 'The Data Scientist will provide support in life cycle management, configuration management and change management', 'The Data Scientist will advise the SEP PM on strategic needs for program evolution, including detailed roadmaps for Information Technology infrastructure based on requirements and resulting capabilities of national standards', 'The Data Scientist will attend and participate in forums as required by the COR']",False,,,,
K24fatQuZpsBE5vTAAAAAA==,Senior Business Analyst,"Summary

NiCE is seeking a Senior Business Analyst to join their team. This role focuses on data science and analysis, acting as a subject matter expert in applying statistics and machine learning to business operations. The Senior Business Analyst will conduct research, identify business insights to improve customer experience and operational efficiencies, and partner with cross-functional teams. Responsibilities include data analysis, prototyping, evaluating performance, and presenting findings to leadership. The role requires a versatile individual with strong relational database and core BI skills, with business ownership for Services Delivery and Support organizations. The ideal candidate will drive innovation in products, processes, and support by investigating AI opportunities.

Must Have
• Degree in data science, computer science, or related fields OR 3+ years of data science work experience
• Advanced knowledge of statistics
• Experience with data analysis tools and strong analytical skills
• Experience in researching and implementing algorithms using R, Python, Scala, Java or others
• Experience in data management & modeling, developing dashboards using BI tools like PowerBI, Tableau, Domo
• 4+ years of experience working with business teams to understand objectives and requirements
• Strong verbal and written communication, listening, and presentation skills
• Ability to work cross-functionally and communicate to all business levels
• Fluent English

Good To Have
• Experience with new and existing data analysis tools
• Ability to manipulate and analyze complex, high-volume, high-dimensionality data
• Experience exploring undefined business problems using structured and unstructured data
• Drive collection of new data and refinement of existing data sources
• Provide business improvement recommendations
• Analyze, report, and present on findings and behavioral trends
• Spur future product, process, and support innovation
• Investigate AI opportunities

At NiCE, we don’t limit our challenges. We challenge our limits. Always. We’re ambitious. We’re game changers. And we play to win. We set the highest standards and execute beyond them. And if you’re like us, we can offer you the ultimate career opportunity that will light a fire within you.

Location: Salt Lake City, UT (office based, hybrid work schedule)

The Senior Business Analyst will operate in the realm of data science/analysis and serve as subject matter experts on the application of statistics and machine learning into business operations.

This role will conduct research and analysis to identify business insights that seek to improve the Customer Experience and overall business efficiencies (productivity, cost, value).

In this role you will be analyzing data and partnering with cross functional teams to identify objectives, opportunities, and make business recommendations. Your work will be both analytical and experimental in nature and include prototyping of new analysis, investigating data, evaluating performance, and summarizing your findings back to key leaders for action.

You are expected to be a versatile individual with strong relational database and core BI skills. Business ownership related to the Services Delivery and Support organizations

Responsibilities:
• Research, design, and develop data analysis leveraging new and existing tools
• Manipulate and analyze complex, high-volume, high-dimensionality data from varying sources
• Explore high-level, undefined ideas and business problems using structured and unstructured data
• Drive the collection of new data and the refinement of existing data sources
• Provide business improvement recommendations through careful consideration of business value and data analysis
• Analyze, report, and present on findings and behavioral trends
• Spur future product, process, and support innovation
• Investigate AI opportunities to enhance the customer experience, reduce manual work, and/or automate remedial tasks

Requirements:
• Degree in data science, computer science, or related fields (or relative equivalent, 3+ years of data science work experience). Advanced knowledge of statistics
• Experience with data analysis tools and capabilities; strong analytical skills
• Experience in researching and implementing algorithms using R, Python, Scala, Java or others
• Experience in data management & modeling, developing dashboards and reports for target set of metrics; inclusive of calculated fields and dynamic dashboards using Industry grade BI Tools like PowerBI, Tableau, Domo, etc.
• 4 or more years of experience in working with business teams to understand objectives, requirements
• Strong verbal and written communication skills, listening skills, and effective presentation skills
• Ability to work cross functionally and communicate to all levels of the business
• Fluent English - a must

About NiCE

NICE Ltd. (NASDAQ: NICE) software products are used by 25,000+ global businesses, including 85 of the Fortune 100 corporations, to deliver extraordinary customer experiences, fight financial crime and ensure public safety. Every day, NiCE software manages more than 120 million customer interactions and monitors 3+ billion financial transactions.

Known as an innovation powerhouse that excels in AI, cloud and digital, NiCE is consistently recognized as the market leader in its domains, with over 8,500 employees across 30+ countries.

NiCE is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, age, sex, marital status, ancestry, neurotype, physical or mental disability, veteran status, gender identity, sexual orientation or any other category protected by law.",2025-07-10T00:00:00.000Z,2025-07-25,"['Degree in data science, computer science, or related fields OR 3+ years of data science work experience', 'Advanced knowledge of statistics', 'Experience with data analysis tools and strong analytical skills', 'Experience in researching and implementing algorithms using R, Python, Scala, Java or others', 'Experience in data management & modeling, developing dashboards using BI tools like PowerBI, Tableau, Domo', '4+ years of experience working with business teams to understand objectives and requirements', 'Strong verbal and written communication, listening, and presentation skills', 'Ability to work cross-functionally and communicate to all business levels', 'Fluent English', 'Experience with new and existing data analysis tools', 'Ability to manipulate and analyze complex, high-volume, high-dimensionality data', 'Experience exploring undefined business problems using structured and unstructured data', 'Drive collection of new data and refinement of existing data sources', 'Provide business improvement recommendations', 'Analyze, report, and present on findings and behavioral trends', 'Spur future product, process, and support innovation', 'You are expected to be a versatile individual with strong relational database and core BI skills', 'Business ownership related to the Services Delivery and Support organizations', 'Degree in data science, computer science, or related fields (or relative equivalent, 3+ years of data science work experience)', 'Advanced knowledge of statistics', 'Experience with data analysis tools and capabilities; strong analytical skills', 'Experience in researching and implementing algorithms using R, Python, Scala, Java or others', 'Experience in data management & modeling, developing dashboards and reports for target set of metrics; inclusive of calculated fields and dynamic dashboards using Industry grade BI Tools like PowerBI, Tableau, Domo, etc', '4 or more years of experience in working with business teams to understand objectives, requirements', 'Strong verbal and written communication skills, listening skills, and effective presentation skills', 'Ability to work cross functionally and communicate to all levels of the business', 'Fluent English - a must']","['This role focuses on data science and analysis, acting as a subject matter expert in applying statistics and machine learning to business operations', 'The Senior Business Analyst will conduct research, identify business insights to improve customer experience and operational efficiencies, and partner with cross-functional teams', 'Responsibilities include data analysis, prototyping, evaluating performance, and presenting findings to leadership', 'The role requires a versatile individual with strong relational database and core BI skills, with business ownership for Services Delivery and Support organizations', 'The ideal candidate will drive innovation in products, processes, and support by investigating AI opportunities', 'The Senior Business Analyst will operate in the realm of data science/analysis and serve as subject matter experts on the application of statistics and machine learning into business operations', 'This role will conduct research and analysis to identify business insights that seek to improve the Customer Experience and overall business efficiencies (productivity, cost, value)', 'In this role you will be analyzing data and partnering with cross functional teams to identify objectives, opportunities, and make business recommendations', 'Your work will be both analytical and experimental in nature and include prototyping of new analysis, investigating data, evaluating performance, and summarizing your findings back to key leaders for action', 'Research, design, and develop data analysis leveraging new and existing tools', 'Manipulate and analyze complex, high-volume, high-dimensionality data from varying sources', 'Explore high-level, undefined ideas and business problems using structured and unstructured data', 'Drive the collection of new data and the refinement of existing data sources', 'Provide business improvement recommendations through careful consideration of business value and data analysis', 'Analyze, report, and present on findings and behavioral trends', 'Spur future product, process, and support innovation', 'Investigate AI opportunities to enhance the customer experience, reduce manual work, and/or automate remedial tasks']",True,['AI Opportunities Investigation'],"AI Opportunities Investigation: The role involves investigating AI opportunities to enhance customer experience, reduce manual work, and automate remedial tasks, indicating an interest in applying modern AI techniques to business processes.","['Statistics', 'Machine Learning', 'Data Analysis Tools', 'Data Management and Modeling', 'Business Intelligence (BI) Tools', 'Relational Databases', 'Data Exploration with Structured and Unstructured Data', 'Prototyping and Performance Evaluation']","Statistics: The role requires advanced knowledge of statistics to apply statistical methods for business operations and data analysis.; Machine Learning: The job involves applying machine learning techniques to business operations and conducting research and prototyping of new analyses using machine learning algorithms.; Data Analysis Tools: Experience with various data analysis tools such as R, Python, Scala, and Java is required to research, implement algorithms, and analyze data.; Data Management and Modeling: The position includes responsibilities for managing and modeling data, including driving the collection of new data and refining existing data sources.; Business Intelligence (BI) Tools: Developing dashboards and reports using industry-grade BI tools like PowerBI, Tableau, and Domo is a key responsibility to support business metrics and visualization.; Relational Databases: Strong skills in relational databases are necessary to manipulate and analyze complex, high-volume, and high-dimensional data from various sources.; Data Exploration with Structured and Unstructured Data: The role involves exploring undefined business problems using both structured and unstructured data to identify insights and opportunities.; Prototyping and Performance Evaluation: The job includes prototyping new analyses, investigating data, evaluating performance, and summarizing findings for leadership to drive business improvements."
VfSdEFPB8XE0uiclAAAAAA==,Senior Cyber Data Scientist Jobs,"Description

SAIC is looking for a Cyber Data Scientist/Analyst Senior to support the Enterprise Security Operations Center (ESOC) at the National Nuclear Security Administration (NNSA) to monitor, detect, and respond to safeguard the Nuclear Security Enterprise (NSE) ensuring the integrity, confidentiality, and availability identifying, detecting, preventing, and coordinating the response and recovery efforts in response to cyber threats to protect the NNSA's critical production environments and information and operational technology systems. Work will be located at the customer facility in Las Vegas, NV, or Washington, DC and will require a Top Secret or DOEQ clearance to start.

This opportunity is contingent upon award.

Responsibilities and Duties:
• Deep understanding of cybersecurity principles, data science techniques, and machine learning.
• Ability to articulate technical concepts clearly to both technical and non-technical audiences.
• Strong analytical and problem-solving skills to handle security incidents and vulnerabilities.
• Ability to work effectively with other IT teams, stakeholders, and external partners.

Qualifications

Requirements and Skills
• Bachelor's degree in computer science, Information Security, Data Science, or a related field is required; OR Master's degree in Cybersecurity, Data Science, or a related field.
• A minimum of 7 years of experience in cybersecurity, data science is required.
• Proficiency in data analysis, machine learning, and cybersecurity principles.
• Experience in leading a team, managing projects, and providing technical guidance to junior team members is crucial.
• Strong analytical and problem-solving skills to handle security incidents and vulnerabilities.
• Ability to work effectively with other IT teams, stakeholders, and external partners.
• One of the following certifications is required: CISSP, CLDS, CADSAI-CYBER.
• A DOE Q or Top Secret level security clearance is required to start.
• Must be able to maintain a DOE Q level security clearance.",2025-07-22T00:00:00.000Z,2025-07-25,"[""Bachelor's degree in computer science, Information Security, Data Science, or a related field is required; OR Master's degree in Cybersecurity, Data Science, or a related field"", 'A minimum of 7 years of experience in cybersecurity, data science is required', 'Proficiency in data analysis, machine learning, and cybersecurity principles', 'Experience in leading a team, managing projects, and providing technical guidance to junior team members is crucial', 'Strong analytical and problem-solving skills to handle security incidents and vulnerabilities', 'Ability to work effectively with other IT teams, stakeholders, and external partners', 'One of the following certifications is required: CISSP, CLDS, CADSAI-CYBER', 'A DOE Q or Top Secret level security clearance is required to start', 'Must be able to maintain a DOE Q level security clearance']","['Work will be located at the customer facility in Las Vegas, NV, or Washington, DC and will require a Top Secret or DOEQ clearance to start', 'Deep understanding of cybersecurity principles, data science techniques, and machine learning', 'Ability to articulate technical concepts clearly to both technical and non-technical audiences', 'Strong analytical and problem-solving skills to handle security incidents and vulnerabilities', 'Ability to work effectively with other IT teams, stakeholders, and external partners']",True,[],,"['Cybersecurity Principles', 'Data Science Techniques', 'Machine Learning']","Cybersecurity Principles: The job requires a deep understanding of cybersecurity principles to identify, detect, prevent, and respond to cyber threats protecting critical production environments and operational technology systems.; Data Science Techniques: The role involves applying data science techniques to analyze security incidents and vulnerabilities within the cybersecurity domain.; Machine Learning: Proficiency in machine learning is required to support cybersecurity operations, including monitoring, detecting, and responding to cyber threats."
u9HcyQcPlAli2Oy1AAAAAA==,Data Scientist Jobs,"In support of XM30 Program Executive Office Ground Combat Systems (PEO GCS) at the Detroit Arsenal Amentum is currently seeking a qualified candidate to serve as a Data Scientist who is experienced working with a diverse team. Other duties may be assigned to support client and contract deliverables. Travel may be required but estimated at less than 10%. This position is currently onsite.

Essential Responsibilities:
• Apply data science principles, concepts, and practices to analyze systems, processes, and operational challenges using scientific methods and techniques
• Perform analytics on complex datasets to identify patterns, trends, and insights that support organizational decision-making
• Develop automated approaches leveraging artificial intelligence / machine learning (AI/ML) and natural language processing (NLP) to streamline the input of programs, processes, and reports for XM30
• Develop data visualization solutions to address operational problems
• Analyze, interpret, and apply data science methodologies in various situations, recommending solutions to senior analysts
• Prepare comprehensive reports, documentation, and correspondence that clearly communicate factual and procedural information
• Conduct minor phases of larger analytical assignments, ensuring quality and alignment with project objectives
• Analyze problems to identify significant factors, gather pertinent data, and develop practical, evidence-based solutions
• Collaborate effectively with team members and stakeholders across functional areas
• Plan and organize work to meet project deadlines and organizational priorities
• Continually expand knowledge of data science techniques and technologies to enhance analytical capabilities
Minimum Requirements:
• U.S. citizenship
• Secret Clearance
• Bachelor's degree and 5+ years experience in Data Science, Computer Science, Statistics, Mathematics, or related field; or a Master degree in Data Science
• Experience applying scientific methods to analyze systems, processes, and operational problems
• CADIQ
• Knowledge of mathematics and statistical analysis
• Demonstrated ability to prepare clear reports and documentation
• Experience analyzing and interpreting data to recommend practical solutions
• Strong problem-solving skills with ability to identify significant factors and gather relevant data
• Excellent collaboration and communication skills
• Ability to plan and organize work effectively
• Position will require occasional travel.
Preferred Qualifications:
• Active Public Trust designation
• Advanced degree in Data Science, Computer Science, Statistics, or related field
• Proficiency in programming languages such as Python, R, or SQL
• Knowledge of Logistics Data Analysis Center (LDAC)
• Enterprise Product Data Management (Windchill)
• Experience with data visualization tools (Tableau, Power BI, etc.)
• Knowledge of machine learning techniques and applications
• Background in big data technologies and cloud computing platforms
• General Experience or knowledge with Provisioning, Cataloging, Structure Content Development (RPSTL, etc)
• Maintenance planning either at a contractor or a user (soldier, etc)
• General Experience or knowledge with developing logistic support and maintenance actions affecting materiel readiness.

Amentum is proud to be an Equal Opportunity Employer. Our hiring practices provide equal opportunity for employment without regard to race, sex, sexual orientation, pregnancy (including pregnancy, childbirth, breastfeeding, or medical conditions related to pregnancy, childbirth, or breastfeeding), age, ancestry, United States military or veteran status, color, religion, creed, marital or domestic partner status, medical condition, genetic information, national origin, citizenship status, low-income status, or mental or physical disability so long as the essential functions of the job can be performed with or without reasonable accommodation, or any other protected category under federal, state, or local law. Learn more about your rights under Federal laws and supplemental language at Labor Laws Posters .",2025-07-25T02:00:00.000Z,2025-07-25,"['U.S. citizenship', 'Secret Clearance', ""Bachelor's degree and 5+ years experience in Data Science, Computer Science, Statistics, Mathematics, or related field; or a Master degree in Data Science"", 'Experience applying scientific methods to analyze systems, processes, and operational problems', 'CADIQ', 'Knowledge of mathematics and statistical analysis', 'Demonstrated ability to prepare clear reports and documentation', 'Experience analyzing and interpreting data to recommend practical solutions', 'Strong problem-solving skills with ability to identify significant factors and gather relevant data', 'Excellent collaboration and communication skills', 'Ability to plan and organize work effectively', 'Position will require occasional travel']","['Other duties may be assigned to support client and contract deliverables', 'Travel may be required but estimated at less than 10%', 'Apply data science principles, concepts, and practices to analyze systems, processes, and operational challenges using scientific methods and techniques', 'Perform analytics on complex datasets to identify patterns, trends, and insights that support organizational decision-making', 'Develop automated approaches leveraging artificial intelligence / machine learning (AI/ML) and natural language processing (NLP) to streamline the input of programs, processes, and reports for XM30', 'Develop data visualization solutions to address operational problems', 'Analyze, interpret, and apply data science methodologies in various situations, recommending solutions to senior analysts', 'Prepare comprehensive reports, documentation, and correspondence that clearly communicate factual and procedural information', 'Conduct minor phases of larger analytical assignments, ensuring quality and alignment with project objectives', 'Analyze problems to identify significant factors, gather pertinent data, and develop practical, evidence-based solutions', 'Collaborate effectively with team members and stakeholders across functional areas', 'Plan and organize work to meet project deadlines and organizational priorities', 'Continually expand knowledge of data science techniques and technologies to enhance analytical capabilities']",True,['Artificial Intelligence'],"Artificial Intelligence: Leveraging artificial intelligence techniques to develop automated approaches that streamline program, process, and report inputs for XM30.","['Data Science Principles', 'Data Analytics', 'Machine Learning', 'Natural Language Processing', 'Data Visualization', 'Statistical Analysis', 'Programming Languages', 'Reporting and Documentation', 'Problem Solving with Data', 'Big Data Technologies', 'Business Intelligence Tools']","Data Science Principles: Applying data science principles, concepts, and practices to analyze systems, processes, and operational challenges using scientific methods and techniques.; Data Analytics: Performing analytics on complex datasets to identify patterns, trends, and insights that support organizational decision-making.; Machine Learning: Developing automated approaches leveraging machine learning to streamline the input of programs, processes, and reports for XM30.; Natural Language Processing: Using natural language processing techniques to automate and improve the input of programs, processes, and reports for XM30.; Data Visualization: Developing data visualization solutions to address operational problems and support decision-making.; Statistical Analysis: Applying knowledge of mathematics and statistical analysis to analyze and interpret data for recommending practical solutions.; Programming Languages: Using programming languages such as Python, R, or SQL to perform data analysis and develop data science solutions.; Reporting and Documentation: Preparing comprehensive reports, documentation, and correspondence that clearly communicate factual and procedural information.; Problem Solving with Data: Analyzing problems to identify significant factors, gather pertinent data, and develop practical, evidence-based solutions.; Big Data Technologies: Having background knowledge in big data technologies and cloud computing platforms to support data science tasks.; Business Intelligence Tools: Experience with data visualization tools such as Tableau and Power BI to create dashboards and visual analytics."
WIxMPf-oM0kHz_ZkAAAAAA==,Data Scientist / Digital Commerce Marketing Analytics Consultant,"This role will focus on leveraging advanced analytics to drive insights and optimize digital commerce and retail media strategies. The ideal candidate will have a proven track record of working with digital commerce-related technologies and a strong background in data science, advanced analytics and data to drive business outcomes.

Key Responsibilities:
• Data Analysis and Modeling:
• Analyze digital commerce and retail media data to identify factors driving higher or lower conversion rates.
• Develop and implement predictive models to determine overarching insights and recommendations in order to optimize bids on keywords based on volume and profit driven by incremental share of voice.
• Utilize complex SQL logic to ETL disparate data tables and sources.
• Apply machine learning algorithms and statistical techniques to uncover hidden relationships and correlations within large first party datasets.
• Strategic Insights and Recommendations:
• Provide actionable recommendations to improve search spending and conversion rates.
• Present findings and insights to senior leadership and stakeholders using visualizations and interactive dashboards designed for non-technical audiences.
• Drive the development of strategic recommendations on analytics projects associated with business unit strategy in close collaboration with key leaders across the organization.
• Project Management and Collaboration:
• Handle end to end framing, execution and communication of advanced analytics projects to distill insights for senior business leaders in support of strategic business plans.
• Collaborate with cross-functional teams to integrate data-driven insights into strategic decision-making processes.
• Manage the engagement of advanced analytics projects, including external suppliers, to ensure projects are executed accurately, timely, and cost-efficiently.
• Proactively take on additional responsibilities and projects as needed to continuously improve performance.
• Data Management and QA:
• Act as an SME for first/zero party data sources, including evaluating data quality and completeness, identifying gaps, and determining ways to improve data utility.
• Partner with data management and stewards to maintain and enhance data quality by applying data governance policies and procedures, performing data validation and quality checks, and resolving data quality issues.
Qualifications:
• Ideal candidates should possess a strong familiarity with marketing terminology, including but not limited to: Customer Acquisition Cost (CAC), Impressions, Click-Through Rate (CTR), Conversion Rate, Glance Views, Return on Ad Spend (ROAS), Search Engine Optimization (SEO), Customer Lifetime Value (CLV), Attribution Modeling.
• Bachelor's or Master's degree in Data Science, Statistics, Computer Science, or a related field.
• 3+ years of experience in data science and advanced analytics, preferably in digital commerce or retail media.
• Proficiency in programming languages such as Python or R.
• Experience with data visualization tools like Tableau or Power BI.
• Strong analytical skills with the ability to interpret complex data sets and provide actionable insights.
• Excellent communication skills, with the ability to present complex information in a clear and concise manner.
• Experience with machine learning algorithms and statistical modeling techniques.
• Familiarity with digital marketing metrics and KPIs as stated above.
Preferred Qualifications:
• Experience working with large datasets and cloud-based data platforms (e.g., AWS, Azure).
• Knowledge of digital advertising platforms and tools (e.g., Amazon Marketing Cloud, Google Ads, Facebook Ads).
• Strong problem-solving skills and attention to detail.
• Ability to work independently and manage multiple projects simultaneously.
• CPG (Consumer Packaged Goods) analytics background preferred.
Kavaliro provides Equal Employment Opportunities to all employees and applicants. All qualified applicants will receive consideration for employment without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state, or local laws. Kavaliro is committed to the full inclusion of all qualified individuals. In keeping with our commitment, Kavaliro will take the steps to assure that people with disabilities are provided reasonable accommodations. Accordingly, if reasonable accommodation is required to fully participate in the job application or interview process, to perform the essential functions of the position, and/or to receive all other benefits and privileges of employment, please respond to this posting to connect with a company representative.",2025-06-28T00:00:00.000Z,2025-07-25,"['Ideal candidates should possess a strong familiarity with marketing terminology, including but not limited to: Customer Acquisition Cost (CAC), Impressions, Click-Through Rate (CTR), Conversion Rate, Glance Views, Return on Ad Spend (ROAS), Search Engine Optimization (SEO), Customer Lifetime Value (CLV), Attribution Modeling', ""Bachelor's or Master's degree in Data Science, Statistics, Computer Science, or a related field"", '3+ years of experience in data science and advanced analytics, preferably in digital commerce or retail media', 'Proficiency in programming languages such as Python or R', 'Experience with data visualization tools like Tableau or Power BI', 'Strong analytical skills with the ability to interpret complex data sets and provide actionable insights', 'Excellent communication skills, with the ability to present complex information in a clear and concise manner', 'Experience with machine learning algorithms and statistical modeling techniques', 'Familiarity with digital marketing metrics and KPIs as stated above']","['This role will focus on leveraging advanced analytics to drive insights and optimize digital commerce and retail media strategies', 'The ideal candidate will have a proven track record of working with digital commerce-related technologies and a strong background in data science, advanced analytics and data to drive business outcomes', 'Data Analysis and Modeling:', 'Analyze digital commerce and retail media data to identify factors driving higher or lower conversion rates', 'Develop and implement predictive models to determine overarching insights and recommendations in order to optimize bids on keywords based on volume and profit driven by incremental share of voice', 'Utilize complex SQL logic to ETL disparate data tables and sources', 'Apply machine learning algorithms and statistical techniques to uncover hidden relationships and correlations within large first party datasets', 'Strategic Insights and Recommendations:', 'Provide actionable recommendations to improve search spending and conversion rates', 'Present findings and insights to senior leadership and stakeholders using visualizations and interactive dashboards designed for non-technical audiences', 'Drive the development of strategic recommendations on analytics projects associated with business unit strategy in close collaboration with key leaders across the organization', 'Project Management and Collaboration:', 'Handle end to end framing, execution and communication of advanced analytics projects to distill insights for senior business leaders in support of strategic business plans', 'Collaborate with cross-functional teams to integrate data-driven insights into strategic decision-making processes', 'Manage the engagement of advanced analytics projects, including external suppliers, to ensure projects are executed accurately, timely, and cost-efficiently', 'Proactively take on additional responsibilities and projects as needed to continuously improve performance', 'Data Management and QA:', 'Act as an SME for first/zero party data sources, including evaluating data quality and completeness, identifying gaps, and determining ways to improve data utility', 'Partner with data management and stewards to maintain and enhance data quality by applying data governance policies and procedures, performing data validation and quality checks, and resolving data quality issues']",True,[],,"['Predictive Modeling', 'SQL', 'Machine Learning Algorithms', 'Data Visualization Tools', 'Advanced Analytics', 'Data Quality and Governance', 'Statistical Modeling Techniques', 'Programming Languages', 'Digital Marketing Metrics and KPIs']","Predictive Modeling: Develop and implement predictive models to generate insights and recommendations for optimizing keyword bids based on volume and profit.; SQL: Utilize complex SQL logic to extract, transform, and load (ETL) data from disparate tables and sources.; Machine Learning Algorithms: Apply machine learning algorithms and statistical techniques to uncover hidden relationships and correlations within large first-party datasets.; Data Visualization Tools: Use tools like Tableau or Power BI to create visualizations and interactive dashboards for presenting findings to non-technical audiences and senior leadership.; Advanced Analytics: Leverage advanced analytics to drive insights and optimize digital commerce and retail media strategies, including strategic recommendations and business outcome improvements.; Data Quality and Governance: Evaluate data quality and completeness, identify gaps, improve data utility, and partner with data stewards to maintain and enhance data quality through governance policies, validation, and quality checks.; Statistical Modeling Techniques: Employ statistical modeling techniques alongside machine learning to analyze data and support predictive insights.; Programming Languages: Proficiency in Python or R for data analysis, modeling, and advanced analytics tasks.; Digital Marketing Metrics and KPIs: Familiarity with marketing metrics such as Customer Acquisition Cost (CAC), Impressions, Click-Through Rate (CTR), Conversion Rate, Return on Ad Spend (ROAS), Customer Lifetime Value (CLV), and Attribution Modeling to inform analytics and recommendations."
_n08oRCBfg_0HZYmAAAAAA==,Data Science & Operations Research Analyst - Senior Jobs,"Join our team at Core One! Our mission is to be at the forefront of devising analytical, operational and technical solutions to our Nation's most complex national security challenges. In order to achieve our mission, Core One values people first! We are committed to recruiting, nurturing, and retaining top talent! We offer a competitive total compensation package that sets us apart from our competition. Core One is a team-oriented, dynamic, and growing company that values exceptional performance!
• This position requires an active TS/SCI clearance.*
Responsibilities:
Provide data science (DS) and operations research (OR) capabilities on-site for a combatant command Operation Assessment Division. Design, develop, and apply a variety of data collection and decision analytics processes and applications, including the employment of mathematical, statistical, and other analytic methods. Identify effective, efficient, and innovative technical solutions for meeting Division data and automation requirements, including potential artificial intelligence (AI) and machine learning (ML) solutions. Develop automated applications, data visualizations, information displays, decision briefings, analytic papers, and facilitate senior leadership decisions with analytic products. Identify and develop data stream interfaces for authoritative data sources to support assessments and risk analysis. Integrate Division functions and products into the Command and Control of the Information Environment (C2IE) system, MAVEN Smart Systems, and/or Advana. Build digital solutions using programming applications (e.g., R, R/Shiny, Python) to digitalize and partially or fully automate data collection, analysis, and staff processes while accelerating the rate at which the Division can execute tasks. Develop and lead small teams in the development of real-time/near real-time data visualization and analysis methodologies and analytic tools. Participate in client operational planning processes in support of Joint planning. Support Knowledge Management and Information processes requirements.

Basic Qualifications:
• Possess a Bachelor's Degree and a Master of Arts or Master of Science degree, with one of the degrees being in a related technical field, such as operations research, data science, math, engineering, science, or computer science.
• 12 years of combined professional DS/OR experience, with a minimum of 5 years of related DS/OR experience at a Combatant Command staff, Joint or Combined Command Headquarters, or Defense Department equivalent.
• High levels of proficiency using the following applications: R, R-Shiny, Python, Python-Shiny, SQL/POSTRESQL, Microsoft Office applications, and Microsoft SharePoint
• Functional knowledge of MAVEN Smart Systems, C2IE, Advana, AI, ML, Git, and Large Learning Models
• Top Secret (TS)/Secure Compartmented Information (SCI) clearance is required. Applicants are subject to a security investigation and need to meet eligibility requirements for access to classified information.

Additional Qualifications:
• Ability to work independently or as the leader or member of a small team in conducting analysis in support of assessments with high visibility, unusual urgency or program criticality; requiring a variety of OR and DS techniques and tools.
• Possession of excellent oral and written communication skills with the ability to communicate, prepare correspondence, and make formal presentations at the 4-Star General Officer/Flag Officer level.
• Ability to develop and support new analytic capabilities as requirements evolve within the command for assessments.
• Knowledge of Joint Warfighting and Combatant Command functions.
Security Clearance:
• Active TS/SCI clearance is required

Core One is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, gender identity, sexual orientation, national origin, or protected veteran status and will not be discriminated against on the basis of disability.",2025-07-19T00:00:00.000Z,2025-07-25,"[""Possess a Bachelor's Degree and a Master of Arts or Master of Science degree, with one of the degrees being in a related technical field, such as operations research, data science, math, engineering, science, or computer science"", '12 years of combined professional DS/OR experience, with a minimum of 5 years of related DS/OR experience at a Combatant Command staff, Joint or Combined Command Headquarters, or Defense Department equivalent', 'High levels of proficiency using the following applications: R, R-Shiny, Python, Python-Shiny, SQL/POSTRESQL, Microsoft Office applications, and Microsoft SharePoint', 'Functional knowledge of MAVEN Smart Systems, C2IE, Advana, AI, ML, Git, and Large Learning Models', 'Top Secret (TS)/Secure Compartmented Information (SCI) clearance is required', 'Applicants are subject to a security investigation and need to meet eligibility requirements for access to classified information', 'Ability to work independently or as the leader or member of a small team in conducting analysis in support of assessments with high visibility, unusual urgency or program criticality; requiring a variety of OR and DS techniques and tools', 'Possession of excellent oral and written communication skills with the ability to communicate, prepare correspondence, and make formal presentations at the 4-Star General Officer/Flag Officer level', 'Ability to develop and support new analytic capabilities as requirements evolve within the command for assessments', 'Knowledge of Joint Warfighting and Combatant Command functions', 'Active TS/SCI clearance is required']","['Provide data science (DS) and operations research (OR) capabilities on-site for a combatant command Operation Assessment Division', 'Design, develop, and apply a variety of data collection and decision analytics processes and applications, including the employment of mathematical, statistical, and other analytic methods', 'Identify effective, efficient, and innovative technical solutions for meeting Division data and automation requirements, including potential artificial intelligence (AI) and machine learning (ML) solutions', 'Develop automated applications, data visualizations, information displays, decision briefings, analytic papers, and facilitate senior leadership decisions with analytic products', 'Identify and develop data stream interfaces for authoritative data sources to support assessments and risk analysis', 'Integrate Division functions and products into the Command and Control of the Information Environment (C2IE) system, MAVEN Smart Systems, and/or Advana', 'Build digital solutions using programming applications (e.g., R, R/Shiny, Python) to digitalize and partially or fully automate data collection, analysis, and staff processes while accelerating the rate at which the Division can execute tasks', 'Develop and lead small teams in the development of real-time/near real-time data visualization and analysis methodologies and analytic tools', 'Participate in client operational planning processes in support of Joint planning', 'Support Knowledge Management and Information processes requirements']",True,"['Large Language Models', 'Artificial Intelligence', 'Machine Learning']",Large Language Models: Have functional knowledge of large learning models as part of potential artificial intelligence solutions to meet Division data and automation requirements.; Artificial Intelligence: Identify and evaluate potential AI solutions to enhance data and automation capabilities within the Operation Assessment Division.; Machine Learning: Consider and apply machine learning solutions to improve data analytics and automation processes in support of command assessments and decision-making.,"['Data Science', 'Operations Research', 'R Programming', 'Python Programming', 'SQL/PostgreSQL', 'Data Visualization', 'Data Stream Interfaces', 'Analytic Methods', 'MLOps', 'Git', 'Knowledge Management', 'Business Intelligence Tools']","Data Science: Provide data science capabilities on-site for a combatant command Operation Assessment Division, including designing, developing, and applying data collection and decision analytics processes using mathematical, statistical, and other analytic methods.; Operations Research: Apply operations research techniques to support assessments and decision analytics within a combatant command environment, including the use of mathematical and statistical methods.; R Programming: Use R and R-Shiny to build digital solutions that automate data collection, analysis, and staff processes, and to develop real-time or near real-time data visualization and analysis methodologies.; Python Programming: Utilize Python and Python-Shiny to develop automated applications and digital solutions that enhance data collection, analysis, and operational efficiency.; SQL/PostgreSQL: Employ SQL and PostgreSQL for managing and interfacing with authoritative data sources to support assessments and risk analysis.; Data Visualization: Develop data visualizations and information displays to facilitate senior leadership decisions and support analytic products.; Data Stream Interfaces: Identify and develop interfaces for authoritative data streams to support assessments and risk analysis within the command environment.; Analytic Methods: Design and apply a variety of mathematical, statistical, and analytic methods to support decision analytics and operational assessments.; MLOps: Possess functional knowledge of machine learning operations to support potential AI and ML solutions within the Division's data and automation requirements.; Git: Use Git for version control and collaboration in developing data science and analytic solutions.; Knowledge Management: Support knowledge management and information process requirements to enhance operational planning and analytic capabilities.; Business Intelligence Tools: Develop analytic tools and dashboards integrated into systems like MAVEN Smart Systems, C2IE, and Advana to support command and control functions."
FtYf8CMHxr7yuuEPAAAAAA==,Data Scientist Jobs,"This is a U.S. based position. All of the programs we support require U.S. citizenship to be eligible for employment. All work must be conducted within the continental U.S.

Who we are:

Raft ( https://TeamRaft.com ) is a customer-obsessed non-traditional small business with a purposeful focus on Distributed Data Systems, Platforms at Scale, and Complex Application Development, with headquarters in McLean, VA. Our range of clients includes innovative federal and public agencies leveraging design thinking, cutting-edge tech stack, and cloud-native ecosystem. We build digital solutions that impact the lives of millions of Americans.

About the role:

As a Data Scientist, you will work in cross-functional teams with data at all stages of the analysis lifecycle to derive actionable insight while translating mission needs into an end-to-end analytical approach to achieve results. Your role involves performing pre-analytics areas of data collection and understanding, data cleansing and integration, and data storage and retrieval.

You will determine appropriate analytics based on data and desired outcomes using techniques including feature detection, statistics, data mining, predictive modeling, machine learning, natural language processing, and business intelligence. You'll interpret the validity of results and communicate the meaning of those results while following a scientific approach to generate value from data, verifying results at each step.

This role is contingent on contract award.

What we are looking for:
Associate: Bachelor's degree with 2+ years of related experience or Master's degree. Works on assignments requiring judgment and initiative under supervision. Develops solutions to technical problems of limited to moderate scope following established procedures.

Standard: Bachelor's degree with 5+ years of related experience, Master's degree with 3+ years of experience, or PhD. Works independently providing technical solutions to complex problems with considerable latitude in approaches.

Senior: Bachelor's degree with 9+ years of related experience, Master's degree with 7+ years of experience, or PhD with 4+ years of experience. Recognized authority providing innovative solutions to complex technical problems and leading advanced development efforts.

Experience with data wrangling, analytics, visualization software and programming languages, analytics methods for big data, machine learning, natural language processing, statistical analysis, and data mining techniques.

Highly preferred:
• Advanced degrees in data science, statistics, or related fields.
• Experience with big data platforms and tools.
• Knowledge of scientific research methodologies and result validation techniques.

Clearance Requirements:
• Active Top Secret with ability to obtain and maintain SCI

Work Type:
• Onsite in Colorado Springs, CO
• May require up to 10% travel

Salary Range:
• $115,000 - $180,000
• The determination of compensation is predicated upon a candidate's comprehensive experience, demonstrated skill, and proven abilities

What we will offer you:
• Highly competitive salary
• Fully covered healthcare, dental, and vision coverage
• 401(k) and company match
• Take as you need PTO + 11 paid holidays
• Education & training benefits
• Generous Referral Bonuses
• And More!

Our Vision Statement:

We bridge the gap between humans and data through radical transparency and our obsession with the mission.

Our Customer Obsession:

We will approach every deliverable like it's a product. We will adopt a customer-obsessed mentality. As we grow, and our footprint becomes larger, teams and employees will treat each other not only as teammates but customers. We must live the customer-obsessed mindset, always. This will help us scale and it will translate to the interactions that our Rafters have with their clients and other product teams that they integrate with. Our culture will enable our success and set us apart from other companies.

How do we get there?

Public-sector modernization is critical for us to live in a better world. We, at Raft, want to innovate and solve complex problems. And, if we are successful, our generation and the ones that follow us will live in a delightful, efficient, and accessible world where out-of-box thinking, and collaboration is a norm.

Raft's core philosophy is Ubuntu: I Am, Because We are. We support our ""nadi"" by elevating the other Rafters. We work as a hyper collaborative team where each team member brings a unique perspective, adding value that did not exist before. People make Raft special. We celebrate each other and our cognitive and cultural diversity. We are devoted to our practice of innovation and collaboration.

We're an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.",2025-07-25T15:00:00.000Z,2025-07-25,"[""Associate: Bachelor's degree with 2+ years of related experience or Master's degree"", ""Standard: Bachelor's degree with 5+ years of related experience, Master's degree with 3+ years of experience, or PhD"", 'Works independently providing technical solutions to complex problems with considerable latitude in approaches', ""Senior: Bachelor's degree with 9+ years of related experience, Master's degree with 7+ years of experience, or PhD with 4+ years of experience"", 'Recognized authority providing innovative solutions to complex technical problems and leading advanced development efforts', 'Experience with data wrangling, analytics, visualization software and programming languages, analytics methods for big data, machine learning, natural language processing, statistical analysis, and data mining techniques', 'Active Top Secret with ability to obtain and maintain SCI']","['As a Data Scientist, you will work in cross-functional teams with data at all stages of the analysis lifecycle to derive actionable insight while translating mission needs into an end-to-end analytical approach to achieve results', 'Your role involves performing pre-analytics areas of data collection and understanding, data cleansing and integration, and data storage and retrieval', 'You will determine appropriate analytics based on data and desired outcomes using techniques including feature detection, statistics, data mining, predictive modeling, machine learning, natural language processing, and business intelligence', ""You'll interpret the validity of results and communicate the meaning of those results while following a scientific approach to generate value from data, verifying results at each step"", 'Works on assignments requiring judgment and initiative under supervision', 'Develops solutions to technical problems of limited to moderate scope following established procedures', 'May require up to 10% travel']",True,[],,"['Data Wrangling', 'Analytics Methods for Big Data', 'Feature Detection', 'Statistical Analysis', 'Data Mining', 'Predictive Modeling', 'Machine Learning', 'Natural Language Processing', 'Business Intelligence']","Data Wrangling: Involves performing pre-analytics tasks such as data collection, cleansing, integration, storage, and retrieval to prepare data for analysis.; Analytics Methods for Big Data: Applying analytical techniques suitable for large-scale data to derive actionable insights and support decision-making.; Feature Detection: Using techniques to identify relevant features in data that contribute to predictive modeling and analysis outcomes.; Statistical Analysis: Employing statistical methods to interpret data, validate results, and support scientific approaches in deriving value from data.; Data Mining: Utilizing data mining techniques to discover patterns and relationships within data to inform predictive modeling and business intelligence.; Predictive Modeling: Developing models that use historical data to predict future outcomes, supporting mission needs and analytical objectives.; Machine Learning: Applying machine learning techniques to analyze data and build models that improve decision-making and predictive accuracy.; Natural Language Processing: Using NLP techniques to analyze and interpret textual data as part of the analytical approach to achieve results.; Business Intelligence: Leveraging BI tools and methods to visualize data and communicate insights effectively to stakeholders."
rTGWz-jOqmLvvZ1EAAAAAA==,"Member of Technical Staff, Experimentation Data Scientist","At Microsoft, we are committed to advancing the frontiers of artificial intelligence in ways that are bold, responsible, and inclusive. Our vision is to build intelligent systems-spanning agents, applications, services, and infrastructure-that empower every person and organization on the planet to achieve more. We believe AI should be accessible to all: consumers, businesses, and developers alike.

The Microsoft AI (MAI) team is looking for an Experimentation Data Scientist to help shape the next generation of personal AI experiences through Copilot. This role involves managing and analyzing experiments to provide actionable insights that drive product improvements and user experience enhancements.

Key Responsibilities:
• Experimentation Management: Collaborate with feature teams to design, implement, and debug experiments. Conduct ad hoc analysis to understand metrics and user behavior changes.
• Statistical Analysis: Perform power analysis and experimental inference to ensure the validity and reliability of experiments.
• Data Analysis: Utilize SQL and Python to pull and analyze data quickly, providing insights into user behavior and experiment outcomes.
• Collaboration: Work closely with partners to ensure robust telemetry and instrumentation and with feature teams to design and implement experiments.

Qualifications
• Bachelor's Degree in Statistics, Econometrics, Computer Science, Electrical or Computer Engineering, or related field AND 6+ years related experience (e.g., statistics, predictive analytics, research)
• OR Master's Degree in Statistics, Econometrics, Computer Science, Electrical or Computer Engineering, or related field AND 4+ years related experience (e.g., statistics, predictive analytics, research)
• OR Doctorate in Statistics, Econometrics, Computer Science, Electrical or Computer Engineering, or related field AND 3+ years related experience (e.g., statistics, predictive analytics, research)
• OR equivalent experience.
• Strong background in statistics, economics, or a related field.
• Proficiency in SQL and Python.
• Experience with online A/B testing.
• Ability to conduct power analysis and experimental inference.
• Strong problem-solving skills and attention to detail.
• Excellent communication and collaboration skills.

Preferred Qualifications:
• Experience in a similar role within a data science or analytics team.
• Familiarity with telemetry and instrumentation frameworks.

Data Science IC5 - The typical base pay range for this role across the U.S. is USD $139,900 - $274,800 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $188,000 - $304,200 per year.

Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here:

Microsoft will accept applications for the role until Month Day, Year.

Microsoft's mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.

#MAI Copilot",2025-07-12T00:00:00.000Z,2025-07-25,"[""Bachelor's Degree in Statistics, Econometrics, Computer Science, Electrical or Computer Engineering, or related field AND 6+ years related experience (e.g., statistics, predictive analytics, research)"", ""OR Master's Degree in Statistics, Econometrics, Computer Science, Electrical or Computer Engineering, or related field AND 4+ years related experience (e.g., statistics, predictive analytics, research)"", 'OR Doctorate in Statistics, Econometrics, Computer Science, Electrical or Computer Engineering, or related field AND 3+ years related experience (e.g., statistics, predictive analytics, research)', 'OR equivalent experience', 'Strong background in statistics, economics, or a related field', 'Proficiency in SQL and Python', 'Experience with online A/B testing', 'Ability to conduct power analysis and experimental inference', 'Strong problem-solving skills and attention to detail', 'Excellent communication and collaboration skills']","['This role involves managing and analyzing experiments to provide actionable insights that drive product improvements and user experience enhancements', 'Experimentation Management: Collaborate with feature teams to design, implement, and debug experiments', 'Conduct ad hoc analysis to understand metrics and user behavior changes', 'Statistical Analysis: Perform power analysis and experimental inference to ensure the validity and reliability of experiments', 'Data Analysis: Utilize SQL and Python to pull and analyze data quickly, providing insights into user behavior and experiment outcomes', 'Collaboration: Work closely with partners to ensure robust telemetry and instrumentation and with feature teams to design and implement experiments']",True,[],,"['Experimentation Management', 'Statistical Analysis', 'SQL', 'Python', 'Online A/B Testing', 'Telemetry and Instrumentation']","Experimentation Management: Managing and analyzing experiments by collaborating with feature teams to design, implement, and debug experiments that provide actionable insights for product and user experience improvements.; Statistical Analysis: Performing power analysis and experimental inference to ensure the validity and reliability of experiments.; SQL: Using SQL to pull and analyze data quickly to gain insights into user behavior and experiment outcomes.; Python: Utilizing Python for data analysis to extract insights from experiment data and user behavior.; Online A/B Testing: Experience conducting online A/B testing to evaluate the impact of product features and changes on user behavior and metrics.; Telemetry and Instrumentation: Working closely with partners to ensure robust telemetry and instrumentation frameworks are in place to support data collection and experiment design."
YqXeVDPZnyloL4yhAAAAAA==,"Technical Data Analyst with Healthcare / Okemos, MI","We are seeking a highly skilled data science/analytics contractor with hands-on experience in SQL, DBT, and Tableau, and a strong understanding of Medicaid and Medicare dental data. This individual will help drive insights, automation, and model development in support of utilization-based scoring, claims optimization, and policy evaluation initiatives. Primary Job Responsibilities:
• Design and maintain DBT models within a medallion data architecture
• Write performant SQL to transform and analyze large datasets (primarily in Snowflake)
• Build Tableau dashboards for executive and operational stakeholders, focused on dental claims, utilization trends, and benefit impact
• Interpret Medicaid/Medicare dental data for care progression, cost modeling, and policy scenarios
• Collaborate across data science, actuarial, and operations teams to deliver insights
• Ensure data quality, validation, and documentation for auditability
Must have Technical Skills:
• Strong SQL skills and experience with cloud data warehouses (Snowflake preferred)
• Proficiency with DBT for modular data modeling, testing, and documentation
• Expertise in Tableau for building visually compelling, user-friendly dashboards
• Experience working with Medicaid and/or Medicare dental data (e.g., CDT codes, utilization patterns, benefit design)
• Strong understanding of healthcare claims data structures and dental domain terminology
• Excellent problem-solving and stakeholder communication skills
Nice to have technical skills:
• Exposure to benefit expansion analysis, or dental claims optimization
• Familiarity with Git, CI/CD workflows.
• Python skills for data transformation or ML support",2025-07-09T00:00:00.000Z,2025-07-25,"['We are seeking a highly skilled data science/analytics contractor with hands-on experience in SQL, DBT, and Tableau, and a strong understanding of Medicaid and Medicare dental data', 'Proficiency with DBT for modular data modeling, testing, and documentation', 'Expertise in Tableau for building visually compelling, user-friendly dashboards', 'Experience working with Medicaid and/or Medicare dental data (e.g., CDT codes, utilization patterns, benefit design)', 'Strong understanding of healthcare claims data structures and dental domain terminology', 'Excellent problem-solving and stakeholder communication skills', 'Exposure to benefit expansion analysis, or dental claims optimization', 'Familiarity with Git, CI/CD workflows', 'Python skills for data transformation or ML support']","['This individual will help drive insights, automation, and model development in support of utilization-based scoring, claims optimization, and policy evaluation initiatives', 'Design and maintain DBT models within a medallion data architecture', 'Write performant SQL to transform and analyze large datasets (primarily in Snowflake)', 'Build Tableau dashboards for executive and operational stakeholders, focused on dental claims, utilization trends, and benefit impact', 'Interpret Medicaid/Medicare dental data for care progression, cost modeling, and policy scenarios', 'Collaborate across data science, actuarial, and operations teams to deliver insights', 'Ensure data quality, validation, and documentation for auditability']",True,[],,"['SQL', 'DBT', 'Tableau', 'Healthcare Claims Data', 'Data Quality and Validation', 'Data Science Collaboration', 'Python', 'Benefit Expansion Analysis', 'Git and CI/CD']","SQL: Used to write performant queries for transforming and analyzing large datasets primarily in Snowflake cloud data warehouse.; DBT: Used for designing, maintaining, modular data modeling, testing, and documentation within a medallion data architecture.; Tableau: Used to build visually compelling, user-friendly dashboards for executive and operational stakeholders focused on dental claims, utilization trends, and benefit impact.; Healthcare Claims Data: Involves interpreting Medicaid and Medicare dental data, including CDT codes, utilization patterns, benefit design, and dental domain terminology for care progression, cost modeling, and policy evaluation.; Data Quality and Validation: Ensuring data quality, validation, and documentation to maintain auditability of data and models.; Data Science Collaboration: Collaborating across data science, actuarial, and operations teams to deliver insights supporting utilization-based scoring, claims optimization, and policy evaluation.; Python: Used for data transformation and supporting machine learning tasks.; Benefit Expansion Analysis: Exposure to analyzing benefit expansion or dental claims optimization to support policy and operational decisions.; Git and CI/CD: Familiarity with version control and continuous integration/continuous deployment workflows to support development and automation."
cD4EfZ4utwJ23pWwAAAAAA==,Data Analyst Jobs,"Overview

We are looking for you to join our team as a Senior Data Analyst. This position focuses on data analysis for law enforcement support, requiring a combination of investigative data expertise, analytical skills, and the ability to work under high-pressure, mission-critical environments. This role will involve working with diverse data sets, ensuring accuracy and integrity while supporting ongoing criminal and civil investigations.

Our ideal candidate has a blend of technical acumen, attention to detail, and the ability to engage with law enforcement agencies. We are looking for more than just a ""Data Analyst""-this role requires a technologist with excellent communication skills, customer service, and a passion for data and problem-solving.

Contributions

Key Responsibilities:
• Data Analysis and Trend Recognition: Compile and analyze data from multiple sources, identifying trends across various data sets, locations, and targets.
• Data Accuracy and Assessment: Monitor data for accuracy, integrity, authenticity, and relevancy. Identify intelligence gaps and assess data viability for investigative purposes.
• Investigative Support: Collaborate with teams to examine data gathered from criminal and civil investigations, developing methodologies to exploit investigative information.
• Quality Control & Reporting: Participate in the development of work products, conducting periodic progress reviews and ensuring quality control of findings. Regularly report findings to lead personnel.
• Data Entry: Perform data entry from both hard and soft copies into large-scale data processing systems, utilizing tools like optical character readers, scanners, and digital cameras as appropriate.
• Law Enforcement Support: Provide critical law enforcement support, interacting with various agencies through multiple channels of communication, while managing data under tight timelines in a high-pressure environment.
• Data Visualization and Tools: Leverage MS Excel, Power BI, or similar tools to design and build formulas, charts, pivot tables, and manipulate unstructured data from different platforms.
• You will be part of our Data Exploitation Practice!

Qualifications

Required:
• Ability to hold a position of SECRET clearance level with the US government.
• Bachelor's Degree and 1 year of work experience OR 5 years of work experience and no degree.
• 3+ years of experience in SQL and Python
• 5+ years of experience using data analytic/visualization tools such as MS Excel, Power BI, or others to design charts, create formulas, and analyze unstructured data (can be job or education-based).
• 2+ years of experience manipulating unstructured data from different platforms; and experience in IT, statistics, computer information systems, auditing, investigative, mathematics, and units of measure
• Skilled at multi-tasking in a fast-paced environment while maintaining clear communications with stakeholders.
• Must be local to El, Paso TX or willing to drive on site 5 days a week.
• Applicants selected will be subject to a Government background investigation and must meet eligibility and suitability requirements.

Preferred:
• Experience providing support to a 24/7 law enforcement operations unit.
• Military or law enforcement background or exposure.
• Law enforcement/drug data desired.
• Ability to manage multiple tasks in a high-paced environment, including collaboration
with various teams.
• Strong analytical skills for identifying trends, gaps, and ensuring data accuracy and
• Experience with documenting processes and developing SOPs for data handling and
• Demonstrated experience in reverse engineering and validation of data processes.
• Ability to communicate findings and updates effectively during briefings and team

About steampunk

Steampunk relies on several factors to determine salary, including but not limited to geographic location, contractual requirements, education, knowledge, skills, competencies, and experience. The projected compensation range for this position is $50,000 to $115,000. The estimate displayed represents a typical annual salary range for this position. Annual salary is just one aspect of Steampunk's total compensation package for employees. Learn more about additional Steampunk benefits here.

Identity Statement

As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud.

Steampunk is a Change Agent in the Federal contracting industry, bringing new thinking to clients in the Homeland, Federal Civilian, Health and DoD sectors. Through our Human-Centered delivery methodology, we are fundamentally changing the expectations our Federal clients have for true shared accountability in solving their toughest mission challenges. As an employee owned company, we focus on investing in our employees to enable them to do the greatest work of their careers - and rewarding them for outstanding contributions to our growth. If you want to learn more about our story, visit http://www.steampunk.com .

We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law. Steampunk participates in the E-Verify program.",2025-07-25T01:00:00.000Z,2025-07-25,"['Our ideal candidate has a blend of technical acumen, attention to detail, and the ability to engage with law enforcement agencies', 'We are looking for more than just a ""Data Analyst""-this role requires a technologist with excellent communication skills, customer service, and a passion for data and problem-solving', 'Ability to hold a position of SECRET clearance level with the US government', ""Bachelor's Degree and 1 year of work experience OR 5 years of work experience and no degree"", '3+ years of experience in SQL and Python', '5+ years of experience using data analytic/visualization tools such as MS Excel, Power BI, or others to design charts, create formulas, and analyze unstructured data (can be job or education-based)', '2+ years of experience manipulating unstructured data from different platforms; and experience in IT, statistics, computer information systems, auditing, investigative, mathematics, and units of measure', 'Skilled at multi-tasking in a fast-paced environment while maintaining clear communications with stakeholders', 'Must be local to El, Paso TX or willing to drive on site 5 days a week', 'Applicants selected will be subject to a Government background investigation and must meet eligibility and suitability requirements', 'with various teams', 'Strong analytical skills for identifying trends, gaps, and ensuring data accuracy and', 'Experience with documenting processes and developing SOPs for data handling and', 'Demonstrated experience in reverse engineering and validation of data processes', 'Ability to communicate findings and updates effectively during briefings and team']","['This position focuses on data analysis for law enforcement support, requiring a combination of investigative data expertise, analytical skills, and the ability to work under high-pressure, mission-critical environments', 'This role will involve working with diverse data sets, ensuring accuracy and integrity while supporting ongoing criminal and civil investigations', 'Data Analysis and Trend Recognition: Compile and analyze data from multiple sources, identifying trends across various data sets, locations, and targets', 'Data Accuracy and Assessment: Monitor data for accuracy, integrity, authenticity, and relevancy', 'Identify intelligence gaps and assess data viability for investigative purposes', 'Investigative Support: Collaborate with teams to examine data gathered from criminal and civil investigations, developing methodologies to exploit investigative information', 'Quality Control & Reporting: Participate in the development of work products, conducting periodic progress reviews and ensuring quality control of findings', 'Regularly report findings to lead personnel', 'Data Entry: Perform data entry from both hard and soft copies into large-scale data processing systems, utilizing tools like optical character readers, scanners, and digital cameras as appropriate', 'Law Enforcement Support: Provide critical law enforcement support, interacting with various agencies through multiple channels of communication, while managing data under tight timelines in a high-pressure environment', 'Data Visualization and Tools: Leverage MS Excel, Power BI, or similar tools to design and build formulas, charts, pivot tables, and manipulate unstructured data from different platforms', 'You will be part of our Data Exploitation Practice!']",True,[],,"['SQL', 'Python', 'Data Visualization Tools', 'Data Analysis and Trend Recognition', 'Data Accuracy and Assessment', 'Investigative Data Support', 'Quality Control and Reporting', 'Data Entry and Processing Systems', 'Unstructured Data Manipulation']","SQL: Used for querying and manipulating data as part of the data analysis tasks in support of law enforcement investigations.; Python: Utilized for data analysis and manipulation, supporting investigative data expertise and analytical skills required for the role.; Data Visualization Tools: Includes MS Excel, Power BI, and similar tools used to design charts, create formulas, build pivot tables, and manipulate unstructured data from various platforms to support reporting and trend recognition.; Data Analysis and Trend Recognition: Involves compiling and analyzing data from multiple sources to identify trends across various data sets, locations, and targets relevant to criminal and civil investigations.; Data Accuracy and Assessment: Monitoring data for accuracy, integrity, authenticity, and relevancy, identifying intelligence gaps, and assessing data viability for investigative purposes.; Investigative Data Support: Collaborating with teams to examine data gathered from investigations and developing methodologies to exploit investigative information effectively.; Quality Control and Reporting: Participating in the development of work products, conducting progress reviews, ensuring quality control of findings, and regularly reporting results to lead personnel.; Data Entry and Processing Systems: Performing data entry from hard and soft copies into large-scale data processing systems using tools like optical character readers, scanners, and digital cameras.; Unstructured Data Manipulation: Handling and analyzing unstructured data from different platforms as part of investigative and analytical responsibilities."
vKkHH38qQ79zzWC2AAAAAA==,"Data Scientist__ Detroit, MI (Onsite)","Hi,

Hope you are doing well!

Please have a look below JD * if you are interested, please confirm your best salary ?

Role- Data Scientist

Location- Detroit, MI

Role- Only Fulltime

Salary- $120K

Description:
• Demonstrated ability to deal with and process data from real-world sources.
• Experience performing Exploratory Data Analysis (EDA).
• Experience with model development (statistical modeling, machine learning).
• Familiarity with the process of deploying models into production or working alongside teams that do.
• Proven ability to translate business questions into data-driven problems.
• Ability to translate data analysis results and model insights into clear, business-oriented solutions.
• Proficiency in at least one major programming language used in data science (e.g., Python, R).

Skills Preferred:
• Experience working with cloud computing platforms, particularly Google Cloud Platform (Google Cloud Platform).
• Experience with specific machine learning frameworks (e.g., scikit-learn, TensorFlow, PyTorch).

Experience Required:
• Experience with data manipulation and analysis libraries/tools (e.g., Pandas, SQL).

Experience Preferred:
• Experience in Auto Industry

Education Required:
• PhD in Statistics, Mathematics, Computer Science, or a closely related quantitative field.
• Additional Safety Training/Licensing/Personal Protection Requirements:

Additional Information
• Hybrid now, but it can be changed to onsite if corporate requires. 1 day a week now, but it can be changed.

Ravi Kumar

Desk: |Cell-",2025-07-09T00:00:00.000Z,2025-07-25,"['Demonstrated ability to deal with and process data from real-world sources', 'Experience performing Exploratory Data Analysis (EDA)', 'Experience with model development (statistical modeling, machine learning)', 'Familiarity with the process of deploying models into production or working alongside teams that do', 'Proven ability to translate business questions into data-driven problems', 'Ability to translate data analysis results and model insights into clear, business-oriented solutions', 'Proficiency in at least one major programming language used in data science (e.g., Python, R)', 'Experience with data manipulation and analysis libraries/tools (e.g., Pandas, SQL)', 'PhD in Statistics, Mathematics, Computer Science, or a closely related quantitative field', 'Additional Safety Training/Licensing/Personal Protection Requirements:']",,True,[],,"['Exploratory Data Analysis', 'Statistical Modeling', 'Machine Learning', 'Python', 'R', 'Pandas', 'SQL', 'scikit-learn', 'TensorFlow', 'PyTorch', 'Google Cloud Platform']","Exploratory Data Analysis: Used to analyze and summarize data from real-world sources to understand patterns and inform model development.; Statistical Modeling: Applied for developing predictive models as part of the model development process.; Machine Learning: Involved in model development and deployment, including working with teams to deploy models into production.; Python: Used as a major programming language for data science tasks including data manipulation and model development.; R: Used as a major programming language for data science tasks including data manipulation and model development.; Pandas: Utilized for data manipulation and analysis as part of the data processing workflow.; SQL: Used for querying and managing data from databases to support data analysis and model development.; scikit-learn: Used as a machine learning framework for model development.; TensorFlow: Used as a machine learning framework for model development.; PyTorch: Used as a machine learning framework for model development.; Google Cloud Platform: Used as a cloud computing platform to support data science workflows and potentially model deployment."
hY9Ds7YI15ZaREFdAAAAAA==,Data Engineer Jobs,"Position: Data Engineer
Location: Centennial, CO
Clearance: TS/SCI Required

Grey Matters Defense Solutions stands at the forefront of developing advanced software solutions tailored to support the mission of the U.S. warfighter. With a commitment to excellence, we foster a culture grounded in a growth mindset, empowering our team to drive progress through bold actions, integrity, collaboration, and innovation. Our employees are dedicated to these core values, and together, we create impactful, mission-critical solutions that redefine the cutting-edge of defense technology. Join us at Grey Matters Defense Solutions, where your work has purpose, and your contributions fuel the future of national security.

Must have a TS/SCI for all positions

Grey Matters Defense Solutions is seeking a talented and dedicated Data Engineer

About the job:
• The position of Data Engineer for the Talon Ark Program is responsible for maintaining and designing new features for the data pipeline. The pipeline end-to-end goes from our Analyst to our Data Scientist on the program. This position is responsible for maintaining the collection of data from various sources, presenting data to the analyst, gathering and curating the inputs from the analyst, and producing the vehicle through which the Data Scientist can use the data created. This position requires a high level of problem-solving skills, and the ability to research using vast amounts of resources to arrive at a solution. The position works closely with the Analyst and Data Scientist on the program to create a viable solution for the customer. What is produced in this position is mainly for the sake of serving the Analyst and Data Scientist. However, creating and maintaining good data is a key factor in making this program successful.
Key Responsibilities:
• Collect data for analysis
• Filter data prior to showing it to analyst based on needs of models
• Provide Analyst with platform to make annotations to data
• Collect and curate annotations from Analyst
• Maintain database where annotations and their related metadata is stored
• Provide and maintain Data Scientist's access to database for the purpose of making datasets

About you:
• Python [ Pandas, NumPy, PyTorch, Ultralytics]
• Docker
• Understanding of python data manipulation packages [Pandas, NumPy, PyTorch, Dask]
• Use of APIs (some that are documented and not documented)
• Understanding of relational database design and maintenance
• Understanding of Software Design Patterns and their implementations
• Ability to do own research and implement new solutions

Preferred Skills:
• Python big data manipulation libraries (ex. PyArrow)
• Python distributed processing libraries (ex. Ray)
• Continuous Integration/Continuous Development (CICD)
• Scaling pipeline architecture

Join our team of exceptional developers, architects, and data scientists!

All qualified applicants will receive consideration for employment regardless of race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Salary Range: $125,000 - $165,000 + 25% SEP

Grey Matters Defense Solutions offer a comprehensive benefits package including medical, dental, vision, life insurance, short-term and long-term disability.

Additional Benefits:
• SEP IRA 25% of base salary
• PTO Six weeks
• IBA 12.5%
• Employee assistance program
• Employee discount
• Flexible spending account
• Health savings account
• Referral program

Grey Matters Defense Solutions' most valuable assets are the more than 60 employees, consisting of data scientists, custom software developers, and analysts/subject matter experts, with senior-level personnel formerly from DIA, NRO, NSA and the US Armed Forces. Our employees have a depth of analytical knowledge which provides them with deep understanding of managing and delivering products within government systems. Grey Matters Defense Solutions provides transformational leadership building award-winning teams and products.

Join our team of exceptional developers, architects and data scientists!

Visit us at www.greymattersdefense.com
https://www.linkedin.com/company/grey-matters-defense-solutions/
""Know Your Rights: Workplace Discrimination is Illegal""
Questions contact: [email protected]",2025-07-24T00:00:00.000Z,2025-07-25,"['Grey Matters Defense Solutions is seeking a talented and dedicated Data Engineer', 'This position requires a high level of problem-solving skills, and the ability to research using vast amounts of resources to arrive at a solution', 'Python [ Pandas, NumPy, PyTorch, Ultralytics]', 'Understanding of python data manipulation packages [Pandas, NumPy, PyTorch, Dask]', 'Use of APIs (some that are documented and not documented)', 'Understanding of relational database design and maintenance', 'Understanding of Software Design Patterns and their implementations', 'Ability to do own research and implement new solutions', 'Python distributed processing libraries (ex']","['This position is responsible for maintaining the collection of data from various sources, presenting data to the analyst, gathering and curating the inputs from the analyst, and producing the vehicle through which the Data Scientist can use the data created', 'The position works closely with the Analyst and Data Scientist on the program to create a viable solution for the customer', 'What is produced in this position is mainly for the sake of serving the Analyst and Data Scientist', 'However, creating and maintaining good data is a key factor in making this program successful', 'Collect data for analysis', 'Filter data prior to showing it to analyst based on needs of models', 'Provide Analyst with platform to make annotations to data', 'Collect and curate annotations from Analyst', 'Maintain database where annotations and their related metadata is stored', ""Provide and maintain Data Scientist's access to database for the purpose of making datasets"", 'Continuous Integration/Continuous Development (CICD)', 'Scaling pipeline architecture']",False,,,,
u17_iIJaFDOi1TxNAAAAAA==,Data Analyst Jobs,"Overview

Iron EagleX (IEX), a wholly owned subsidiary of General Dynamics Information Technology, delivers agile IT and Intelligence solutions. Combining small-team flexibility with global scale, IEX leverages emerging technologies to provide innovative, user-focused solutions that empower organizations and end users to operate smarter, faster, and more securely in dynamic environments.

Responsibilities

Contract Overview:

The Data Technical Support (DTS) contract provides data science professionals to the United States Special Operations Command's (USSOCOM) Intelligence Data Science Team (IDST) and Special Operations Forces Acquisitions, Technology & Logistics (SOF AT&L).

The IDST is a government-led team focused on data analytics efforts within the USSOCOM Directorate of Intelligence (J2) and its subordinate command's intelligence lines of effort. The IDST helps USSOCOM intelligence analysts by turning the Command's data into actionable information. The IDST team may also engage with the USSOCOM Chief Digital and Artificial Intelligence Office (CDAO), Knowledge Management (KM), and other HQ entities.

The DTS contract provides permanently assigned data science professionals to the USSOCOM Headquarters, Theater Special Operations Commands, and Component Commands. Additionally, the DTS contract may provide temporary support (Temporary Duty / deployment) to worldwide Special Operations Joint Task Forces, Combined Joint Special Operations Task Forces, Special Operations Task Forces, and Special Operations Command Forward Elements.

Job Description:

Data Analyst - Data Analysts support the IDST by using technology to mine complex, voluminous, and different varieties of data from various sources and platforms to collect, analyze, and compile data to meet customer needs.

This position is in SOCSOUTH, Homestead, FL.

Job Duties Include (but are not limited to):
• Identify new sources of data and methods to improve data collection, analysis, and reporting
• Collect customer requirements
• Determine technical issues
• Design algorithms and data manipulation capabilities using R, Python, C++, JavaScript, Go, and other known programming languages.
• Build data solutions, tools, and capabilities to enable self-service frameworks for data consumers to monitor and report on data.
• Improve the quality of data use and usability by driving an understanding and adherence to the principles of data quality management including metadata, lineage, and business definitions
• Work collaboratively with Intelligence and Data analysis teams to produce qualitative and quantitative data that support Intelligence products.

Qualifications

Required Skills & Experience:
• Experience providing services similar in required tasks, scope, and complexity.
• Due to US Government Contract Requirements, only US Citizens are eligible for this role.

Education & Certifications:
• Possess a minimum of a bachelor's degree in computer science discipline or equivalent.

Security Clearance:
• Current Top-Secret clearance with SCI eligibility is required

Benefits:
• National health, vision, and dental plans
• 20 days of PTO and 11 paid holidays
• Life Insurance
• Short- and long-term disability plans
• 401(K) retirement plan
• Incentive and recognition programs
• Relocation opportunities

Equal Opportunity Employer / Individuals with Disabilities / Protected Veterans",2025-07-23T00:00:00.000Z,2025-07-25,"['Experience providing services similar in required tasks, scope, and complexity', 'Due to US Government Contract Requirements, only US Citizens are eligible for this role', ""Possess a minimum of a bachelor's degree in computer science discipline or equivalent"", 'Current Top-Secret clearance with SCI eligibility is required']","[""The Data Technical Support (DTS) contract provides data science professionals to the United States Special Operations Command's (USSOCOM) Intelligence Data Science Team (IDST) and Special Operations Forces Acquisitions, Technology & Logistics (SOF AT&L)"", ""The IDST helps USSOCOM intelligence analysts by turning the Command's data into actionable information"", 'The IDST team may also engage with the USSOCOM Chief Digital and Artificial Intelligence Office (CDAO), Knowledge Management (KM), and other HQ entities', 'The DTS contract provides permanently assigned data science professionals to the USSOCOM Headquarters, Theater Special Operations Commands, and Component Commands', 'Additionally, the DTS contract may provide temporary support (Temporary Duty / deployment) to worldwide Special Operations Joint Task Forces, Combined Joint Special Operations Task Forces, Special Operations Task Forces, and Special Operations Command Forward Elements', 'Data Analyst - Data Analysts support the IDST by using technology to mine complex, voluminous, and different varieties of data from various sources and platforms to collect, analyze, and compile data to meet customer needs', 'Identify new sources of data and methods to improve data collection, analysis, and reporting', 'Collect customer requirements', 'Determine technical issues', 'Design algorithms and data manipulation capabilities using R, Python, C++, JavaScript, Go, and other known programming languages', 'Build data solutions, tools, and capabilities to enable self-service frameworks for data consumers to monitor and report on data', 'Improve the quality of data use and usability by driving an understanding and adherence to the principles of data quality management including metadata, lineage, and business definitions', 'Work collaboratively with Intelligence and Data analysis teams to produce qualitative and quantitative data that support Intelligence products']",True,[],,"['Data Mining', 'Data Collection', 'Data Analysis', 'Algorithm Design', 'Programming Languages', 'Data Solutions Development', 'Data Quality Management', 'Collaboration with Intelligence Teams']","Data Mining: Used to extract complex, voluminous, and diverse data from various sources and platforms to support analysis and reporting needs.; Data Collection: Identifying new sources and methods to gather data effectively to meet customer requirements.; Data Analysis: Analyzing collected data to compile actionable information that supports intelligence products and customer needs.; Algorithm Design: Designing algorithms and data manipulation capabilities using programming languages such as R, Python, C++, JavaScript, and Go to process and analyze data.; Programming Languages: Utilizing languages including R, Python, C++, JavaScript, and Go to develop data solutions and tools.; Data Solutions Development: Building tools and capabilities that enable self-service frameworks for data consumers to monitor and report on data.; Data Quality Management: Improving data usability by ensuring adherence to principles such as metadata management, data lineage, and business definitions.; Collaboration with Intelligence Teams: Working jointly with intelligence and data analysis teams to produce qualitative and quantitative data supporting intelligence products."
ujHBqekAy1MAOLjvAAAAAA==,Data Engineer (Multi-levels Mid-Senior) Jobs,"Overview

Credence is one of the largest privately held technologies services company in the country, repeatedly recognized as a top place to work, and have been on the Inc. 5000 Fastest Growing Private Companies list for the last 12 years. We practice servant leadership and believe that by focusing on the success of our clients, team members, and partners, we all achieve greater success.

At Credence, we support our clients' mission-critical needs, powered by technology. We provide cutting-edge solutions, including AI/ML, enterprise modernization, and advanced intelligence capabilities, to the largest defense and health federal organizations. Through partnership and trust, we increase mission success for warfighters and secure our nation for a better future.

We value innovation, integrity, and continuous learning-and we are committed to investing in the next generation of tech talent.

This is an upcoming opportunity in late 2025 for highly motivated Data Engineer(s) to join our growing team. In this role, you will leverage your hands-on experience with foundational code for data pipelines and data base migrations to design, develop, and implement AI models and machine learning algorithms to support a variety of high-impact projects. This position is ideal for an engineer ready to deepen their expertise in AI/ML and automation, taking on exciting technical challenges at the Mid and Senior levels at multiple locations
Responsibilities include, but are not limited to the duties listed below
• Must have demonstrated experience deploying solutions and production experience with applications
• Experience supporting designing, developing, and deploying machine learning models and AI-driven solutions will be key for the successful candidate in this role.
• Collaborate with cross-functional teams, including data scientists, software engineers, product managers, and client stakeholders to understand, evaluate and deliver AI solutions that meet the requirements.
• Conduct data preparation, feature engineering, model selection, training and optimization to ensure optimal performance from the AI models.
• Design and implement AI solutions using the latest Generative AI technologies and foundation models / large-language models (LLMs).
• Develop automation scripts for MLOps pipelines in cloud using Infrastructure as Code (IaC) for ML model deployment in model inferencing workflows, following best practices of model versioning and CI/CD deployments.
• Manage AI model performance post-deployment and support AI tool development and best practices
• Stay updated on AI & ML trends and write clean, maintainable and well-documented code following industry standards
Education, Requirements and Qualifications
• Bachelor's or Master's degree in Computer Science, Artificial Intelligence, Machine Learning, or a related field.
• US citizenship with the ability to obtain successful DoD TOP SECRET security clearance required.
• Mid-Level Data Scientist 3-7 years of hands-on experience in AI/ML development & deployments of AI projects and/or
• Senior Level Data Scientist 10+ years of hands-on experience in AI/ML development & deployments of AI projects.
• Strong knowledge of AI/ML techniques, including supervised, unsupervised, and reinforcement learning, with expertise in Python, AI/ML key libraries, and basic LLM concepts
• Experience with cloud platforms (AWS, GCP, or Azure) and containerization tools (Docker, Kubernetes).
• Experience using ML frameworks and tools in the cloud, such as Amazon Sagemaker.
• Strong problem-solving skills and the ability to work both independently and as part of a team.
• Excellent communication skills, with the ability to convey complex technical concepts to non-technical stakeholders.
Working Conditions and Physical Requirements

Please join us, as together we build a better world one mission at a time powered by Technology and its People!

Locations:

HQ- McLean VA - Tyson's Corner - Hybrid

Dayton OH, Wright Patterson AFB - On-site

Warner Robbins GA, Robins AFB - On-site

Hampton VA, Langley AFB - On-site

Sumter SC, Shaw AFB - On-site

#LI-Hybrid

#veteranemployment #militaryspouse #milspouse #hireavet #militaryveteran #militaryfriendly #transitioningmilitary #veterans #militarytransition #militaryfamilies #msep #militarytocivilian #military #federalcontractingjobs #defensecontracting #defenseindustryjobs",2025-07-25T02:00:00.000Z,2025-07-25,"[""Bachelor's or Master's degree in Computer Science, Artificial Intelligence, Machine Learning, or a related field"", 'US citizenship with the ability to obtain successful DoD TOP SECRET security clearance required', 'Mid-Level Data Scientist 3-7 years of hands-on experience in AI/ML development & deployments of AI projects and/or', 'Senior Level Data Scientist 10+ years of hands-on experience in AI/ML development & deployments of AI projects', 'Strong knowledge of AI/ML techniques, including supervised, unsupervised, and reinforcement learning, with expertise in Python, AI/ML key libraries, and basic LLM concepts', 'Experience with cloud platforms (AWS, GCP, or Azure) and containerization tools (Docker, Kubernetes)', 'Experience using ML frameworks and tools in the cloud, such as Amazon Sagemaker', 'Strong problem-solving skills and the ability to work both independently and as part of a team', 'Excellent communication skills, with the ability to convey complex technical concepts to non-technical stakeholders']","['In this role, you will leverage your hands-on experience with foundational code for data pipelines and data base migrations to design, develop, and implement AI models and machine learning algorithms to support a variety of high-impact projects', 'This position is ideal for an engineer ready to deepen their expertise in AI/ML and automation, taking on exciting technical challenges at the Mid and Senior levels at multiple locations', 'Must have demonstrated experience deploying solutions and production experience with applications', 'Experience supporting designing, developing, and deploying machine learning models and AI-driven solutions will be key for the successful candidate in this role', 'Collaborate with cross-functional teams, including data scientists, software engineers, product managers, and client stakeholders to understand, evaluate and deliver AI solutions that meet the requirements', 'Conduct data preparation, feature engineering, model selection, training and optimization to ensure optimal performance from the AI models', 'Design and implement AI solutions using the latest Generative AI technologies and foundation models / large-language models (LLMs)', 'Develop automation scripts for MLOps pipelines in cloud using Infrastructure as Code (IaC) for ML model deployment in model inferencing workflows, following best practices of model versioning and CI/CD deployments', 'Manage AI model performance post-deployment and support AI tool development and best practices', 'Stay updated on AI & ML trends and write clean, maintainable and well-documented code following industry standards']",True,"['Generative AI', 'Large Language Models', 'AI Model Deployment and Management']","Generative AI: The role includes designing and implementing AI solutions using the latest Generative AI technologies to build advanced AI-driven applications.; Large Language Models: Experience with foundation models and large language models (LLMs) is required for developing AI solutions and understanding basic LLM concepts.; AI Model Deployment and Management: Responsibilities include deploying AI models in production, managing AI model performance post-deployment, and supporting AI tool development and best practices.","['Data Pipelines', 'Machine Learning Models', 'Feature Engineering', 'Model Selection and Training', 'Supervised Learning', 'Unsupervised Learning', 'Reinforcement Learning', 'Python Programming', 'Cloud Platforms', 'Containerization Tools', 'ML Frameworks and Tools', 'MLOps Pipelines']","Data Pipelines: The role involves hands-on experience with foundational code for data pipelines and database migrations to support AI and machine learning projects.; Machine Learning Models: Responsibilities include designing, developing, deploying, and optimizing machine learning models to support high-impact projects.; Feature Engineering: The job requires conducting feature engineering as part of data preparation to ensure optimal model performance.; Model Selection and Training: The candidate will perform model selection, training, and optimization to achieve the best performance from AI models.; Supervised Learning: The role requires strong knowledge and application of supervised learning techniques in AI/ML development.; Unsupervised Learning: The candidate must have expertise in unsupervised learning methods as part of AI/ML techniques used in the role.; Reinforcement Learning: Experience with reinforcement learning is required as part of the AI/ML techniques applied in the job.; Python Programming: Expertise in Python and AI/ML key libraries is essential for developing and deploying AI and machine learning solutions.; Cloud Platforms: Experience with cloud platforms such as AWS, GCP, or Azure is necessary for deploying and managing machine learning models and data workflows.; Containerization Tools: The job involves using containerization tools like Docker and Kubernetes to support deployment and scalability of AI/ML applications.; ML Frameworks and Tools: Experience with machine learning frameworks and tools in the cloud, including Amazon SageMaker, is required for model development and deployment.; MLOps Pipelines: Developing automation scripts for MLOps pipelines using Infrastructure as Code (IaC) is part of the responsibilities to support ML model deployment and inferencing workflows."
5uF80EeGMYCqCMh2AAAAAA==,"Senior Associate, Data Scientist","Senior Associate, Data Scientist

Senior Associate,Data Scientist - US Card Bureau Data Strategy Team

Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making.

As a Data Scientist at Capital One, you'll be part of a team that's leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives.

Team Description

Credit bureau data is at the heart of underwriting decisions at US Card. The Bureau Data Strategy team produces one of the most highly-used datasets in all of Capital One from raw credit bureau data. The team is responsible for generating insights, extracting value from Bureau Data and shaping the future of how credit bureau data is used in underwriting at Capital One. The team also owns the monitoring solution to promptly alert users to potential production errors with these features.

Role Description

In this role, you will:
• Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love
• Leverage a broad stack of technologies - Python, Conda, AWS, H2O, Spark, and more - to reveal the insights hidden within huge volumes of numeric and textual data
• Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation
• Flex your interpersonal skills to translate the complexity of your work into tangible business goals

The Ideal Candidate is:
• Innovative. You continually research and evaluate emerging technologies. You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them.
• Creative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You're not afraid to share a new idea.
• Technical. You're comfortable with open-source languages and are passionate about developing further. You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms.
• Statistically-minded. You've built models, validated them, and backtested them. You know how to interpret a confusion matrix or a ROC curve. You have experience with clustering, classification, sentiment analysis, time series, and deep learning.
• A data guru. ""Big data"" doesn't faze you. You have the skills to retrieve, combine, and analyze data from a variety of sources and structures. You know understanding the data is often the key to great data science.

Basic Qualifications:
• Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:
• A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 2 years of experience performing data analytics
• A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration

Preferred Qualifications:
• Master's Degree in ""STEM"" field (Science, Technology, Engineering, or Mathematics), or PhD in ""STEM"" field (Science, Technology, Engineering, or Mathematics)
• Experience working with PySpark
• At least 2 years' experience in Python, Scala, or R
• At least 2 years' experience with machine learning
• At least 2 years' experience with SQL

Capital One will consider sponsoring a new qualified applicant for employment authorization for this position.

The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.

McLean, VA: $133,000 - $151,800 for Sr Assoc, Data Science

New York, NY: $145,100 - $165,600 for Sr Assoc, Data Science

Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate's offer letter.

This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.

Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at theCapital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.

This role is expected to accept applications for a minimum of 5 business days.

No agencies please. Capital One is an equal opportunity employer (EOE, including disability/vet) committed to non-discrimination in compliance with applicable federal, state, and local laws. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City's Fair Chance Act; Philadelphia's Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",2025-07-17T00:00:00.000Z,2025-07-25,"['You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them', 'You thrive on bringing definition to big, undefined problems', 'You love asking questions and pushing hard to find answers', ""You're comfortable with open-source languages and are passionate about developing further"", 'You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms', 'Statistically-minded', 'You know how to interpret a confusion matrix or a ROC curve', 'You have experience with clustering, classification, sentiment analysis, time series, and deep learning', 'A data guru', 'You have the skills to retrieve, combine, and analyze data from a variety of sources and structures', 'You know understanding the data is often the key to great data science', 'Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:', ""A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 2 years of experience performing data analytics"", ""A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration""]","['The team is responsible for generating insights, extracting value from Bureau Data and shaping the future of how credit bureau data is used in underwriting at Capital One', 'The team also owns the monitoring solution to promptly alert users to potential production errors with these features', 'Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love', 'Leverage a broad stack of technologies - Python, Conda, AWS, H2O, Spark, and more - to reveal the insights hidden within huge volumes of numeric and textual data', 'Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation', 'Flex your interpersonal skills to translate the complexity of your work into tangible business goals', 'You continually research and evaluate emerging technologies', ""You've built models, validated them, and backtested them""]",True,[],,"['Statistical Modeling', 'Credit Bureau Data Analysis', 'Python', 'Conda', 'AWS', 'H2O', 'Spark', 'Machine Learning Models', 'Clustering', 'Classification', 'Sentiment Analysis', 'Time Series Analysis', 'Deep Learning', 'Confusion Matrix and ROC Curve Interpretation', 'SQL', 'PySpark', 'Scala', 'R']","Statistical Modeling: Used to personalize credit card offers and generate insights from credit bureau data to support underwriting decisions.; Credit Bureau Data Analysis: Extracting value and generating insights from raw credit bureau data to shape underwriting processes and monitor production errors.; Python: Utilized as part of the technology stack to analyze large volumes of numeric and textual data and develop data science solutions.; Conda: Used as part of the technology stack to manage environments and dependencies for data science workflows.; AWS: Cloud computing platform leveraged to process and analyze large-scale data sets and support data science solutions.; H2O: Employed as a machine learning platform to build and deploy models on large datasets.; Spark: Used for big data processing and analytics, including working with PySpark for distributed data processing.; Machine Learning Models: Built through all phases including design, training, evaluation, validation, backtesting, and implementation to support business goals.; Clustering: Applied as a statistical method for grouping data points to uncover patterns within credit bureau data.; Classification: Used to categorize data points, likely for credit risk or underwriting decisions.; Sentiment Analysis: Performed as part of data analysis to interpret textual data.; Time Series Analysis: Used to analyze data points collected or recorded at specific time intervals, relevant for modeling and forecasting.; Deep Learning: Applied as part of advanced modeling techniques to improve predictive performance.; Confusion Matrix and ROC Curve Interpretation: Used to evaluate and validate classification models' performance.; SQL: Used to retrieve and combine data from various sources and structures for analysis.; PySpark: Experience with PySpark for distributed data processing and analytics on big data.; Scala: Used as a programming language for data processing and analytics.; R: Used for statistical analysis and data science tasks."
KfyGieO3W0E2DuJeAAAAAA==,Data Scientist Jobs,"Description
• Supporting to the Combat Plans Division (CPD) of the 616th Operations Center in execution of the 16th Air Force's mission located in San Antonio, Texas
• Using mathematical and statistical expertise, along with natural curiosity to identify statistical trends and anomalies
• While mining, interpreting, and cleaning data, this person will be relied on to ask questions, connect the dots, and uncover hidden opportunities for the customer and subordinate units
• Being part of a team of multi-discipline specialists and planners, the data scientist will coordinate with internal and external customers to mine, analyze, and turn the data into finished planning, intelligence and/or assessment products through various big data analytic methods
• Working closely with operational and all-source intelligence information, and specifically with OSINT

FILLING THIS POSITION IS CONTINGENT UPON AWARD

#LI-DG1

Requirements
• Knowledge of software for data analysis
• Experience in military writing and graphics display tools
• Ability to work in a team of diverse specialties
• Briefing and oration skills
• Knowledge of major geopolitical issues and major areas of responsibility (AOR)
• Experience data mining from multiple sources
• Understanding of Open-Source Intelligence (OSINT) and its operational application

Desired Skills
• Familiarity with Intelligence support to air and/or cyber tasking order (ATO/CTO) cycle and construction; ability to read and understand these formats
• Prior experience working in a NAF or MAJCOM air operations center, multinational Combined AOC, joint/other Service equivalent
• Working knowledge of Joint and USAF doctrine, specifically cyber and ISR employment
• Diverse understanding of cultures, languages outside of the U.S.
• Basic understanding of programming languages, such as Python

Clearance Information

SRC IS A CONTRACTOR FOR THE U.S. GOVERNMENT, THIS POSITION WILL REQUIRE U.S. CITIZENSHIP AS WELL AS, A U.S. GOVERNMENT SECURITY CLEARANCE AT THE TOP SECRET / SCI LEVEL

Travel Requirements
• Required, 10%.

About Us

Scientific Research Corporation is an advanced information technology and engineering company that provides innovative products and services to government and private industry, as well as independent institutions. At the core of our capabilities is a seasoned team of highly skilled engineers and scientists with multidisciplinary backgrounds. This team is challenged daily to provide cutting edge technology solutions to our clients.

SRC offers a generous benefit package, including medical, dental, and vision plans, 401(k) with a company match, life insurance, vacation and sick paid time off accruals starting at 10 days of vacation and 5 days of sick leave annually, 11 paid holidays, tuition reimbursement, and a work environment that encourages excellence and more. For positions requiring a security clearance, selected applicants will be subject to a government security investigation and must meet eligibility requirements for access to classified information.

EEO

Scientific Research Corporation is an equal opportunity employer that does not discriminate in employment.

All qualified applicants will receive consideration for employment without regard to their race, color, religion, sex, age, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other protected characteristic under federal, state or local law.

Scientific Research Corporation endeavors to make www.scires.com accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact jobs@scires.com for assistance. This contact information is for accommodation requests only and cannot be used to inquire about the status of applications.",2025-07-25T16:00:00.000Z,2025-07-25,"['Knowledge of software for data analysis', 'Experience in military writing and graphics display tools', 'Ability to work in a team of diverse specialties', 'Briefing and oration skills', 'Knowledge of major geopolitical issues and major areas of responsibility (AOR)', 'Experience data mining from multiple sources', 'Understanding of Open-Source Intelligence (OSINT) and its operational application', 'CITIZENSHIP AS WELL AS, A U.S. GOVERNMENT SECURITY CLEARANCE AT THE TOP SECRET / SCI LEVEL', 'Required, 10%']","[""Supporting to the Combat Plans Division (CPD) of the 616th Operations Center in execution of the 16th Air Force's mission located in San Antonio, Texas"", 'Using mathematical and statistical expertise, along with natural curiosity to identify statistical trends and anomalies', 'While mining, interpreting, and cleaning data, this person will be relied on to ask questions, connect the dots, and uncover hidden opportunities for the customer and subordinate units', 'Being part of a team of multi-discipline specialists and planners, the data scientist will coordinate with internal and external customers to mine, analyze, and turn the data into finished planning, intelligence and/or assessment products through various big data analytic methods', 'Working closely with operational and all-source intelligence information, and specifically with OSINT']",True,[],,"['Data Mining', 'Statistical Analysis', 'Data Cleaning and Interpretation', 'Big Data Analytics', 'Open-Source Intelligence (OSINT)', 'Python Programming']","Data Mining: Used to extract and analyze data from multiple sources to identify trends, anomalies, and hidden opportunities relevant to military and intelligence operations.; Statistical Analysis: Applied mathematical and statistical expertise to identify statistical trends and anomalies in data to support operational decision-making.; Data Cleaning and Interpretation: Involves mining, interpreting, and cleaning data to ensure accuracy and usability for intelligence and planning products.; Big Data Analytics: Utilized various big data analytic methods to transform raw data into finished planning, intelligence, and assessment products.; Open-Source Intelligence (OSINT): Understanding and operational application of OSINT to support intelligence activities and decision-making.; Python Programming: Basic understanding of Python programming language to support data analysis tasks."
IkHCXIwwAbWdvnuvAAAAAA==,Data Analyst/Scientist (ES4),"Epsilon C5I (, a division of Epsilon Systems Solutions, is a 100 percent employee-owned company founded in 1998 with more than 20 locations serving the Department of Defense, Department of Energy, Department of Homeland Security, non-profit and commercial customers. The Dayton division has recently been named as one of only five prime awardees for the 10-year, $4.7 billion NOVASTAR contract supporting the National Air and Space Intelligence Center (NASIC), WPAFB, Ohio.

The Dayton division is currently searching for a Data Analyst/Scientist (ES4). Candidate will provide in-depth analytical support for NASIC focusing on long-term trends and campaign planning. Additionally, the candidate shall leverage Python, R, SQL, and/or MATLAB to analyze large datasets, employing statistical modeling, data visualization, and forecasting. A key part of your role involves automating workflows with tools like MIST, Excel, Pandas, and NumPy, and developing scripts for efficient data handling. Your daily work will involve creating reports, databases, and interactive dashboards to inform operational decisions and capability assessments.

Candidates must be able to work independently and as part of a technical team and have effective oral and written communication skills. Successful candidates will have strong problem solving and critical thinking skills.

Most of the work supports the Scientific and Technical Intelligence community. This challenging position requires a diverse set of technical and task management skills and allows for the opportunity to contribute immediately to important, meaningful work. Desire an active TS/SCI clearance. Work is performed onsite in the Dayton, Ohio area.

Duties and Responsibilities:

Needs to be able to collect, clean, preprocess, and consolidate unfiltered, unstructured datasets from data feeds such as MIST/FADE & thresher

Familiarity with csv, json, txt, APIs, Python, R, SQL, and MATLAB.

Experience with Application Programming Interfaces (APIs) and develop scripts or lightweight applications to streamline data extraction, transformation, and loading (ETL) processes.

Background knowledge on Unmanned Aerial Systems (UAS) (Bonus)

Background knowledge or experience primarily in INDOPACOM, but also EUCOM and CENTCOM AORs.

Provide in-depth analytical support for long-term trending assessments and production focused on Unmanned Aerial Systems (UAS) scenario-based campaign planning and execution.

Creating and executing data-driven analyses using advanced computational methods to identify trends, patterns, and strategic implications in UAS activity.

Utilizing data science tools and programming languages- including but not limited to Python, R, SQL, and MATLAB-to collect, process, and analyze large structured and unstructured datasets. To include statistical modeling, data visualization, geospatial analysis, and time-series forecasting techniques.

Integrate and automate workflows utilizing IC tools such as the Multi-Intelligence Spatial Temporal Tool (MIST), and create custom analytics solutions leveraging Excel, Pandas, NumPy, and other data manipulation libraries.

Required Qualifications:

Bachelor's degree in Electrical Engineering, Physical Sciences, Computer Engineering, Data Science, Computer Science, Software Engineering, or other closely related fields.

10+ years of relevant experience in engineering, science, or mathematics.

Applicant must have an active DoD Top Secret Security Clearance, with SCI eligibility.

Applicant must reside within commuting distance to WPAFB, OH or willing to relocate to the area.

Technical leadership experience.

Must have strong written communication skills, possess good people skills, demonstrate strong attention to detail and have the desire to work on a highly focused technical team of engineers, analysts, and scientists.

Possess effective communication and be able to collaborate with Customers, and cross-functional teams, document technical processes, and present solutions to stakeholders.

Must be able to prioritize tasks effectively, manage deadlines, and handle multiple projects simultaneously.

Excellent organizational skills and keen attention to detail, with the ability to multitask and prioritize effectively in a fast-paced, dynamic work environment.

Enthusiasm for learning and adapting to new technologies and methodologies.

Preferred Qualifications:

All Source intelligence experience

Demonstrated ability to drive technological innovation within an organization.

Recognized expert technologist with 10+ year experience in analytic solution development related to signal processing, data science, machine learning, or other similar technology.

Familiarity with AI/ML models to process and analyze large datasets.

Previous IC or DoD program/project work experience.

ADA Notations:
• Regular communication (hearing/speaking).
• Noise conditions range from very quiet to very noisy.
• Prolonged use of computer (typing/keyboarding).
• Frequently required to sit for long periods of time, stand, and walk.
• Ability to travel by car, air or other means of transportation, if required.

Epsilon Systems Solutions, Inc. is an equal opportunity employer. Qualified candidates will be considered without regard to legally protected characteristics.",2025-06-26T00:00:00.000Z,2025-07-25,"['Candidates must be able to work independently and as part of a technical team and have effective oral and written communication skills', 'Successful candidates will have strong problem solving and critical thinking skills', 'Most of the work supports the Scientific and Technical Intelligence community', 'This challenging position requires a diverse set of technical and task management skills and allows for the opportunity to contribute immediately to important, meaningful work', 'Desire an active TS/SCI clearance', 'Familiarity with csv, json, txt, APIs, Python, R, SQL, and MATLAB', 'Experience with Application Programming Interfaces (APIs) and develop scripts or lightweight applications to streamline data extraction, transformation, and loading (ETL) processes', 'Background knowledge on Unmanned Aerial Systems (UAS) (Bonus)', 'Background knowledge or experience primarily in INDOPACOM, but also EUCOM and CENTCOM AORs', ""Bachelor's degree in Electrical Engineering, Physical Sciences, Computer Engineering, Data Science, Computer Science, Software Engineering, or other closely related fields"", '10+ years of relevant experience in engineering, science, or mathematics', 'Applicant must have an active DoD Top Secret Security Clearance, with SCI eligibility', 'Applicant must reside within commuting distance to WPAFB, OH or willing to relocate to the area', 'Technical leadership experience', 'Must have strong written communication skills, possess good people skills, demonstrate strong attention to detail and have the desire to work on a highly focused technical team of engineers, analysts, and scientists', 'Possess effective communication and be able to collaborate with Customers, and cross-functional teams, document technical processes, and present solutions to stakeholders', 'Must be able to prioritize tasks effectively, manage deadlines, and handle multiple projects simultaneously', 'Excellent organizational skills and keen attention to detail, with the ability to multitask and prioritize effectively in a fast-paced, dynamic work environment', 'Enthusiasm for learning and adapting to new technologies and methodologies', 'All Source intelligence experience', 'Demonstrated ability to drive technological innovation within an organization', 'Recognized expert technologist with 10+ year experience in analytic solution development related to signal processing, data science, machine learning, or other similar technology', 'Familiarity with AI/ML models to process and analyze large datasets', 'Previous IC or DoD program/project work experience', 'Prolonged use of computer (typing/keyboarding)', 'Frequently required to sit for long periods of time, stand, and walk', 'Ability to travel by car, air or other means of transportation, if required']","['Candidate will provide in-depth analytical support for NASIC focusing on long-term trends and campaign planning', 'Additionally, the candidate shall leverage Python, R, SQL, and/or MATLAB to analyze large datasets, employing statistical modeling, data visualization, and forecasting', 'A key part of your role involves automating workflows with tools like MIST, Excel, Pandas, and NumPy, and developing scripts for efficient data handling', 'Your daily work will involve creating reports, databases, and interactive dashboards to inform operational decisions and capability assessments', 'Needs to be able to collect, clean, preprocess, and consolidate unfiltered, unstructured datasets from data feeds such as MIST/FADE & thresher', 'Provide in-depth analytical support for long-term trending assessments and production focused on Unmanned Aerial Systems (UAS) scenario-based campaign planning and execution', 'Creating and executing data-driven analyses using advanced computational methods to identify trends, patterns, and strategic implications in UAS activity', 'Utilizing data science tools and programming languages- including but not limited to Python, R, SQL, and MATLAB-to collect, process, and analyze large structured and unstructured datasets', 'To include statistical modeling, data visualization, geospatial analysis, and time-series forecasting techniques', 'Integrate and automate workflows utilizing IC tools such as the Multi-Intelligence Spatial Temporal Tool (MIST), and create custom analytics solutions leveraging Excel, Pandas, NumPy, and other data manipulation libraries']",True,[],,"['Python', 'R', 'SQL', 'MATLAB', 'Statistical Modeling', 'Data Visualization', 'Time-Series Forecasting', 'Data Cleaning and Preprocessing', 'ETL (Extract, Transform, Load)', 'Pandas', 'NumPy', 'Excel', 'Multi-Intelligence Spatial Temporal Tool (MIST)', 'APIs', 'Geospatial Analysis', 'Machine Learning']","Python: Used as a primary programming language to analyze large structured and unstructured datasets, automate workflows, and develop scripts for efficient data handling.; R: Employed for statistical modeling, data visualization, and analyzing large datasets as part of data science tasks.; SQL: Utilized to query and manage large datasets, supporting data extraction and analysis workflows.; MATLAB: Applied for data analysis, statistical modeling, and processing large datasets within the analytical support role.; Statistical Modeling: Used to analyze data trends and patterns, supporting long-term trending assessments and forecasting.; Data Visualization: Creating visual representations of data to inform operational decisions and capability assessments.; Time-Series Forecasting: Applied techniques to predict trends over time, particularly for scenario-based campaign planning and execution.; Data Cleaning and Preprocessing: Collecting, cleaning, preprocessing, and consolidating unfiltered, unstructured datasets from various data feeds.; ETL (Extract, Transform, Load): Developing scripts and lightweight applications to streamline data extraction, transformation, and loading processes.; Pandas: Used as a data manipulation library to automate workflows and handle data efficiently.; NumPy: Employed for numerical data processing and automation of data workflows.; Excel: Leveraged to create custom analytics solutions and automate workflows.; Multi-Intelligence Spatial Temporal Tool (MIST): Integrated and automated workflows using this IC tool to support data analysis and operational decision-making.; APIs: Experience with Application Programming Interfaces to extract and process data programmatically.; Geospatial Analysis: Used to analyze spatial data relevant to Unmanned Aerial Systems (UAS) activity and campaign planning.; Machine Learning: Familiarity with AI/ML models to process and analyze large datasets, supporting analytic solution development."
B20-wXs7f5F0FLLRAAAAAA==,Data Scientist Jobs,"ManTech seeks a motivated, career and customer oriented Senior Data Scientist SME to join our team in Ashburn, Virginia. This position is onsite two days a week.

Each day U.S. Customs and Border Protection (CBP) oversees the massive flow of people, capital, and products that enter and depart the United States via air, land, sea, and cyberspace. The volume and complexity of both physical and virtual border crossings require the application of solutions to promote efficient trade and travel.

Responsibilities include but are not limited to:
• Lead and perform hands-on data and threat/intel analysis leading to development of analytics solutions (e.g. predictive models, visual analytics reports), to support CBP users conduct law enforcement mission critical activities.
• Demonstrate proficiency in extracting, cleaning, and transforming CBP transactional and associated data sets within an identified problem space to build predictive models as well as develop appropriate supporting documentation.
• Leverage knowledge of a variety of statistical and machine learning techniques to develop, evaluate, and deploy new predictive analytical models that directly inform mission decisions.
• Utilize and explore variety of statistical/modeling tools and languages to compare and assess best performing Machine Learning results.
• Execute projects including those intended to identify patterns and/or anomalies in large datasets; perform automated text/data classification and categorization as well as entity recognition, resolution and extraction; and named entity matching.

Minimum Qualifications:
• HS Diploma/GED and 20+ years or AS/AA and 18+ years or BS/BA and 12+ years or MS/MA/MBA and 9+ years or PhD/Doctorate and 7+ years
• Experience in full-lifecycle development, deployment and monitoring of machine learning models to multiple platforms (on-prem/cloud etc.) and applying advanced analytics solutions to solve complex business problems
• Experience with programming languages including R, Python, Scala, Java, SQL/Spark
• Experience constructing and executing queries to extract data in support of EDA and model development
• Experience with evaluating, implementing and optimizing AI/ML algorithms to address constraints with large and imbalanced datasets.
• Experience with entity resolution (e.g., record linking, named entity matching, deduplication/ disambiguation)
• Experience with unsupervised and supervised machine learning techniques and methods
• Experience/Proficiency in conducting development and integration activities to deploy, assess and update AI/ML models into applications for end-user use and evaluation.

Preferred Qualifications:
• Proficiency with Unsupervised Machine Learning methods including Cluster Analysis (e.g., K-means, K-nearest Neighbor, Hierarchical, Deep Belief Networks, Principal Component Analysis), Segmentation, etc.
• Proficiency with Auto ML tools and platforms, such as AWS Sagemaker, DataRobot or DataBricks
• Experience with big data technologies (e.g., Hadoop, HIVE, HDFS, HBase, MapReduce, Spark, Kafka, Sqoop)
• Master's Degree in mathematics, statistics, computer science/engineering, or other related technical fields with equivalent practical experience

Clearance Requirements:
• Must be a US Citizen and able to obtain and maintain a U.S. Customs and Border Protection (CBP) suitability.
• Must be eligible to obtain and maintain a Top Secret

Physical Requirements:
• Must be able to be in a stationary position more than 50% of the time.
• Must be able to communicate, converse, and exchange information with peers and senior personnel.
• Constantly operates a computer and other office productivity machinery, such as a computer.",,2025-07-25,,,True,[],,"['Predictive Models', 'Data Extraction, Cleaning, and Transformation', 'Statistical and Machine Learning Techniques', 'Exploratory Data Analysis (EDA)', 'Entity Resolution', 'Unsupervised Machine Learning Methods', 'AutoML Tools and Platforms', 'Big Data Technologies', 'Programming Languages for Data Science', 'Machine Learning Model Lifecycle Management', 'Automated Text/Data Classification and Categorization']","Predictive Models: Used to develop analytics solutions that support law enforcement mission critical activities by predicting outcomes based on CBP transactional and associated data.; Data Extraction, Cleaning, and Transformation: Involves extracting, cleaning, and transforming CBP transactional and associated data sets within an identified problem space to prepare data for predictive modeling.; Statistical and Machine Learning Techniques: Applied to develop, evaluate, and deploy new predictive analytical models that inform mission decisions, including supervised and unsupervised learning methods.; Exploratory Data Analysis (EDA): Constructing and executing queries to extract data in support of exploratory data analysis and model development.; Entity Resolution: Techniques such as record linking, named entity matching, deduplication, and disambiguation used to identify and resolve entities within datasets.; Unsupervised Machine Learning Methods: Includes cluster analysis methods like K-means, K-nearest Neighbor, Hierarchical clustering, Deep Belief Networks, and Principal Component Analysis used for segmentation and pattern identification.; AutoML Tools and Platforms: Utilization of automated machine learning platforms such as AWS Sagemaker, DataRobot, and DataBricks to streamline model development and deployment.; Big Data Technologies: Experience with technologies like Hadoop, HIVE, HDFS, HBase, MapReduce, Spark, Kafka, and Sqoop to handle large-scale data processing and analytics.; Programming Languages for Data Science: Use of R, Python, Scala, Java, SQL, and Spark for data extraction, analysis, model development, and deployment.; Machine Learning Model Lifecycle Management: Full-lifecycle development, deployment, and monitoring of machine learning models across multiple platforms including on-premises and cloud environments.; Automated Text/Data Classification and Categorization: Execution of projects involving automated classification, categorization, entity recognition, resolution, and extraction to identify patterns and anomalies in large datasets."
GUK-1LrCOzXGi2q7AAAAAA==,Sr Data Scientist,"Job#: 2080195

Job Description:

Job Title: Sr. Data Scientist

Job Location: Columbus, OH (Onsite)

Pay Range: $56/hr-$66/hr

Contract Length: 3 Months (Contract-to-hire)

JOB DESCRIPTION

Job Title

Senior Data Scientist

Overview:

Our Enterprise Data and Analytics team is growing, and were looking for an outstanding Senior Data Scientist to join our team. In this role, you will leverage machine learning, segmentation, and statistical inference on huge data sets to improve how we understand our customers and the communities we serve. We need data and analytics to meet our goals.

As we advance our data science and analytics capabilities, we want experts in modeling complex business problems and discovering business insights using statistical, algorithmic, mining, and visualization techniques. The Senior Data Scientist contributes to building and developing the organization's data infrastructure and supports the senior leadership with insights, management reports, and analysis for decision-making processes.

Responsibilities:

Performs advanced analytics methods to extract value from business data

Performs large-scale experimentation and build data-driven models to answer business questions

Conducts research on cutting-edge techniques and tools in machine learning/deep learning/artificial intelligence

Determines requirements that will be used to train and evolve deep learning models and algorithms

Articulates a vision and roadmap for the exploitation of data as a valued corporate asset

Influences product teams through presentation of data-based recommendations

Evangelizes best practices to analytics and products teams

Owns the entire model development process, from identifying the business requirements, data sourcing, model fitting, presenting results, and production scoring

Skills:

Up-to-date knowledge of machine learning and data analytics tools and techniques

Strong knowledge in predictive modeling methodology

Experienced at leveraging both structured and unstructured data sources

Willingness and ability to learn new technologies on the job

Demonstrated ability to communicate complex results to technical and non-technical audiences

Demonstrated ability to work effectively in teams as well as independently across multiple tasks while meeting aggressive timelines

Strategic, intellectually curious thinker with focus on outcomes

Professional image with the ability to form relationships across functions

Strong experience with R/RStudio, Python, SAS, SQL, NoSQL
• Strong experience with Cloud Machine Learning technologies (e.g., AWS Sagemaker)
• Strong experience with machine learning environments (e.g., TensorFlow, scikit-learn, caret)

Strong understanding of statistical methods and skills such as Bayesian Networks Inference, linear and non-linear regression, hierarchical, mixed models/multi-level modeling

Financial Services background preferred

Experience:

1-3 years work and/or educational experience in machine learning or cloud computing, experience using statistics and machine learning to solve complex business problems, experience conducting statistical analysis with advanced statistical software, experience scripting languages, and packages, experience building and deploying predictive models, experience web scraping, and scalable data pipelines and experience with big data analysis tools and techniques.

Education:
• Master's degree in computer science, statistics, economics or related fields

EEO Employer

Apex Systems is an equal opportunity employer. We do not discriminate or allow discrimination on the basis of race, color, religion, creed, sex (including pregnancy, childbirth, breastfeeding, or related medical conditions), age, sexual orientation, gender identity, national origin, ancestry, citizenship, genetic information, registered domestic partner status, marital status, disability, status as a crime victim, protected veteran status, political affiliation, union membership, or any other characteristic protected by law. Apex will consider qualified applicants with criminal histories in a manner consistent with the requirements of applicable law. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation in using our website for a search or application, please contact our Employee Services Department at or .

Apex Systems is a world-class IT services company that serves thousands of clients across the globe. When you join Apex, you become part of a team that values innovation, collaboration, and continuous learning. We offer quality career resources, training, certifications, development opportunities, and a comprehensive benefits package. Our commitment to excellence is reflected in many awards, including ClearlyRated's Best of Staffing in Talent Satisfaction in the United States and Great Place to Work in the United Kingdom and Mexico.

Apex Benefits Overview: Apex offers a range of supplemental benefits, including medical, dental, vision, life, disability, and other insurance plans that offer an optional layer of financial protection. We offer an ESPP (employee stock purchase program) and a 401K program which allows you to contribute typically within 30 days of starting, with a company match after 12 months of tenure. Apex also offers a HSA (Health Savings Account on the HDHP plan), a SupportLinc Employee Assistance Program (EAP) with up to 8 free counseling sessions, a corporate discount savings program and other discounts. In terms of professional development, Apex hosts an on-demand training program, provides access to certification prep and a library of technical and leadership courses/books/seminars once you have 6+ months of tenure, and certification discounts and other perks to associations that include CompTIA and IIBA. Apex has a dedicated customer service team for our Consultants that can address questions around benefits and other resources, as well as a certified Career Coach. You can access a full list of our benefits, programs, support teams and resources within our 'Welcome Packet' as well, which an Apex team member can provide.",,2025-07-25,,,True,['Deep Learning'],"Deep Learning: Research and development of deep learning models and algorithms, including determining requirements to train and evolve these models.","['Machine Learning', 'Statistical Methods', 'Predictive Modeling', 'Data Pipelines', 'SQL and NoSQL', 'R and RStudio', 'Python', 'SAS', 'Cloud Machine Learning Technologies', 'Machine Learning Frameworks', 'Data Analytics Tools and Techniques', 'Big Data Analysis Tools']","Machine Learning: Used to build predictive models and solve complex business problems by leveraging both structured and unstructured data sources.; Statistical Methods: Includes Bayesian Networks Inference, linear and non-linear regression, hierarchical and mixed/multi-level modeling applied to modeling complex business problems and extracting insights from data.; Predictive Modeling: Developing and deploying models to answer business questions and support decision-making processes.; Data Pipelines: Building scalable data pipelines to process large-scale data for analysis and model development.; SQL and NoSQL: Used for data sourcing and managing structured and unstructured data.; R and RStudio: Utilized for statistical analysis, data manipulation, and model development.; Python: Used for scripting, data analysis, and building machine learning models.; SAS: Applied for advanced statistical analysis and modeling.; Cloud Machine Learning Technologies: Experience with cloud platforms like AWS SageMaker to build, train, and deploy machine learning models.; Machine Learning Frameworks: Experience with TensorFlow, scikit-learn, and caret for developing and deploying machine learning models.; Data Analytics Tools and Techniques: Used to perform advanced analytics, segmentation, statistical inference, and visualization to extract value from business data.; Big Data Analysis Tools: Applied for handling and analyzing large datasets to support data-driven decision making."
PVL34lmAQd7hYR1QAAAAAA==,Senior Data Analyst Jobs,"Description

Data Analyst (Huntsville Alabama)

At B&A, we foster and embrace a distinct set of values that we live by and instill in all aspects of our organization: dedication, commitment, partnership, trust, and recognition. We have incorporated these values into successful delivery for our customers since 1988. B&A believes in ensuring its employees feel deeply connected to B&A, recognizing successes and hard work, and providing continuous opportunities to learn and grow. Our people are entrepreneurial thinkers that combine mindset, vision, and experience to drive value - not only to us as an organization, but to the clients we support. We promote a collaborative culture with our clients, and with each other, as one team working towards a common vision. We'd love for you to join our team!

Job Summary

B&A is looking for a Data Analyst to join a contract with a federal government client in support of an important mission with an Army project his position requires employees to be located in the Huntsville, AL area in order to report to work on-site at Redstone.

Responsibilities
• Provide highly complex data mining, statistical analysis, trend analysis, and causal analysis.
• Perform as a technical lead responsible for monitoring and providing monthly contract reports and deliverables.
• Responsible for integrating multiple disciplines in an operations research team and translating applicable methods into language and application understandable by operational managers throughout the organization.
• Review and provide quality control methods on products.
• Prepare and update training materials to ensure newly assigned personnel gain an understanding of key analytic tools, procedures, and methodologies used.
• Take structured and unstructured data and distill the information into a cohesive analytical product for a contracting functional business area audience.
• Support pattern analysis methods to formulate recommendations to operational managers based upon exploiting patterns in the past, current, and anticipated operational environment.

Education and Experience
• 8+ years in a technical field
• BA/BS in a relevant field is required.

Required Skills
• Must have a high proficiency in Power BI and have held a previous position as a Power BI Consultant.
• Have experience advising senior DoD decision makers on methodologies, results, and conclusions from applied operations research. The primary tools used for research services include, but are not limited to, Logistics Management Program, Vantage, Virtual Contracting Enterprise, General Fund Enterprise Business System (GFEBS), SAP Business Objects/Web Intelligence Reports, Microsoft SharePoint, Army-specific contract writing systems (Procurement Desktop Defense (PD2) and Procurement Automated Data and Document System (PADDS)), and various Government and Commercial business process automation systems.
• Personnel should have strong data manipulation and problem-solving skills.
• Must have strong technical skills in areas such as statistics, programming languages like R or Python, SQL (Structured Query Language), data visualization, and data cleaning and preparation
• Have good communication skills and problem-solving ability.

Security Clearance
• Active Secret clearance is required.

More About B&A:

Notable Clients
B&A has grown to be a company that is trusted by our clients for exceptional service, innovative solutions, and inspired employees. Our service extends through federal, state, and local Government, the private sector, and higher education. Some of our notable clients include Department of Homeland Security, U.S. Customs and Border Protection, U.S. Senate, U.S. Courts, U.S. Census Bureau, U.S. Navy, and more.

Benefits and Programs

B&A is proud to offer three robust individual and family medical plans to full time employees, including a Health Savings Account (HSA) option as well as two tiers of dental coverage, vision, life & AD&D, disability, accident, hospital indemnity, and critical illness insurance. In addition to these benefits, B&A employees enjoy paid time off, B&A sponsored trainings and certifications, pet insurance benefits, commuter transit benefits and a free subscription to a virtual exercise platform (NEOU). B&A's 401(k) plan is available to all employees and includes a company matching contribution.

B&A has launched several programs to focus on employee engagement, wellness, and assistance. These include:
• The B&A Cares program: 30/60/90-day wellness check ins, personal development, financial management, and stress management seminars, and more
• A formal mentorship program
• Job shadowing and cross training opportunities
• Brand Ambassador program
• Employee Assistance Program (EAP) - Access to various support resources to include counseling, legal guidance, financial planning, and more
• Monthly teambuilding events
• B&A Annual Wellness Challenges: #StepWithB&A, #WalkDuringLunchWithB&A, #VolunteeringWithB&A, #ExerciseDuringLunchWithB&A, and more

At B&A, we place significant importance on improving the communities and lives of citizens across the nation through our involvement, technology expertise, and employees. B&A puts an emphasis on charitable efforts in the Northern Virginia area, including Capital Area Food Bank pantry drives, book donations, Hope for Henry Foundation events, and many more. In recognition of all these efforts, B&A has been named a Companies as Responsive Employers (CARE) award recipient by Northern Virginia Family Services and nominated by the Northern Virginia Chamber of Commerce for Outstanding Corporate Citizenship Award.

EEO

B&A provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, disability, genetic information, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state and local laws. B&A complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities. This policy covers conduct occurring at B&A's offices, and other workplaces (including client sites) and all other locations where B&A is providing services, and to all work-related activities.

B&A participates in e-Verify. We provide the Social Security Administration (SSA) and, if necessary, the Department of Homeland Security (DHS) with information from each new employee's I-9 Form to confirm work authorization.",,2025-07-25,,,True,[],,"['Statistical Analysis', 'Operations Research Methods', 'Data Visualization with Power BI', 'Data Manipulation and Cleaning', 'Programming with R and Python', 'SQL (Structured Query Language)', 'Quality Control Methods', 'Pattern Analysis', 'Business Intelligence Tools']","Statistical Analysis: Used to perform complex data mining, trend analysis, and causal analysis to support operational decision-making in a federal government context.; Operations Research Methods: Applied to integrate multiple disciplines and translate analytical methods into actionable insights for operational managers.; Data Visualization with Power BI: Required high proficiency in Power BI to create reports and dashboards for monitoring and delivering monthly contract reports and analytics products.; Data Manipulation and Cleaning: Involves preparing structured and unstructured data into cohesive analytical products and ensuring data quality through cleaning and preparation techniques.; Programming with R and Python: Used for statistical programming and data analysis tasks to support complex analytics and problem-solving.; SQL (Structured Query Language): Utilized for querying and managing data within various government and commercial business process automation systems.; Quality Control Methods: Applied to review and ensure the accuracy and reliability of analytical products and reports.; Pattern Analysis: Used to identify and exploit patterns in past, current, and anticipated operational environments to formulate recommendations for operational managers.; Business Intelligence Tools: Experience with SAP Business Objects/Web Intelligence Reports and other BI tools to support data reporting and decision-making."
yI7QAjplPR6bzEDNAAAAAA==,Data Analyst - Senior Jobs,"Data Analyst - Senior

Job Category: Information Technology

Time Type: Full time

Minimum Clearance Required to Start: Secret

Employee Type: Regular

Percentage of Travel Required: Up to 10%

Type of Travel: Local
• * *

CACI is seeking an experienced Data A nalyst to support our customer, U.S. Southern Command (USSOUTHCOM), in Doral, Florida. This position is contingent upon award of the USSOUTHCOM Cyber Information Technology Enterprise Services (SCITES).

Key Responsibilities

Data Analyst S enior :
• Ability to partner with USSOUTHCOM to understand their questions and needs and then dig into their data-rich environments to find the pieces of their information puzzle
• P rovide a deep understanding of data and what the information means and how it can be used to make an impact helping USSOUTHCOM acquire cutting-edge capabilities
• Share your data analytics expertise with team members to support client and stakeholder relationships
• Research, develop, and test data methodologies, and generate cross-functional solutions through collection and analysis of data sets
• Lead impactful work and guide decision-making across multiple organizations
• Apply skills and analytical expertise by simplifying technical requirements and trends, based on audience
• Present data findings and recommendations to clients and stakeholders using your knowledge of databases, scripting languages, and Microsoft Office Suite
• Establish quantitative and qualitative metrics and key performance indicators to drive technical outcomes
• Apply data visualization through different formats

Required Skills :
• Batchelor's Degree in STEM and 5 years of experience
• DoD Secret security clearance with ability to obtain Top Secret
• Grow your communication and technical skills by merging data to create data-centric solutions

-
________________________________________________________________________________________

What You Can Expect:

A culture of integrity.

At CACI, we place character and innovation at the center of everything we do. As a valued team member, you'll be part of a high-performing group dedicated to our customer's missions and driven by a higher purpose - to ensure the safety of our nation.

An environment of trust.

CACI values the unique contributions that every employee brings to our company and our customers - every day. You'll have the autonomy to take the time you need through a unique flexible time off benefit and have access to robust learning resources to make your ambitions a reality.

A focus on continuous growth.

Together, we will advance our nation's most critical missions, build on our lengthy track record of business success, and find opportunities to break new ground - in your career and in our legacy.

Your potential is limitless. So is ours.

Learn more about CACI here.

________________________________________________________________________________________

Pay Range: There are a host of factors that can influence final salary including, but not limited to, geographic location, Federal Government contract labor categories and contract wage rates, relevant prior work experience, specific skills and competencies, education, and certifications. Our employees value the flexibility at CACI that allows them to balance quality work and their personal lives. We offer competitive compensation, benefits and learning and development opportunities. Our broad and competitive mix of benefits options is designed to support and protect employees and their families. At CACI, you will receive comprehensive benefits such as; healthcare, wellness, financial, retirement, family support, continuing education, and time off benefits. Learn more here .

The proposed salary range for this position is:
$90,300-$189,600

CACI is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, age, national origin, disability, status as a protected veteran, or any other protected characteristic.",,2025-07-25,,,True,[],,"['Data Analysis', 'Data Methodologies', 'Data Visualization', 'Quantitative and Qualitative Metrics', 'Scripting Languages', 'Databases', 'Microsoft Office Suite']","Data Analysis: Used to understand customer questions and needs by exploring data-rich environments to extract meaningful information that supports decision-making and capability acquisition.; Data Methodologies: Researching, developing, and testing various data methodologies to generate cross-functional solutions through collection and analysis of data sets.; Data Visualization: Applying different formats of data visualization to present findings and recommendations effectively to clients and stakeholders.; Quantitative and Qualitative Metrics: Establishing key performance indicators and metrics to drive technical outcomes and measure impact.; Scripting Languages: Utilizing scripting languages to support data analysis and presentation of data findings.; Databases: Using knowledge of databases to access, manage, and analyze data relevant to client needs.; Microsoft Office Suite: Employing Microsoft Office tools to present data findings and support communication with clients and stakeholders."
yoVv58rWQmBHm6H6AAAAAA==,"Senior Data Analyst, Management Data Analysis","About us

National Grid is hiring a Senior Data Analyst for our NY Electric and Data Systems department in Syracuse, NY.

Every day we deliver safe and secure energy to homes, communities, and businesses. We are there when people need us the most. We connect people to the energy they need for the lives they live.

The pace of change in society and our industry is accelerating and our expertise and track record puts us in an unparalleled position to shape the sustainable future of our industry. To be successful we must anticipate the needs of our customers, reducing the cost of energy delivery today and pioneering the flexible energy systems of tomorrow. This requires us to deliver on our promises and always look for new opportunities to grow, both ourselves and our business.

Job Purpose

National Grid is committed to Digital Transformation and is building a best-in-class utility of the future. The NY Electric Data and Systems team is responsible for delivering solutions which support a data driven organization and advance National Grid toward our digital future.

The core function of this role is to help the organization utilize data to facilitate sound decisions that deliver safe, reliable, clean and affordable electric power to our customers.

This analyst will work closely with business teams in Operations, Asset Management and Engineering, as well as IT, digital product and platform teams. This analyst will bring the capability to create data insights form data sets, reports and dashboards; conduct analysis independently and in partnership with business teams; assist in the enhancement of existing digital products and the design of new ones; and help close the quality gaps by defining logic and requirements that meet our business needs. Tasks will include solution delivery, data and process mapping, and data change management to secure the reliability and safety of National Grids information.

Key Accountabilities

Support National Grids data transformation activities, this includes but is not limited to:
• Conducting rigorous analysis of data quality and analytics use cases, collaboration with subject matter experts and performing comprehensive technical evaluations.
• Constructing reports and data visualizations which support the business processes.
• Identifying, evaluating, presenting and recommending options to all levels of leadership(along with effort/impact/risk of each).
• Develop and apply domain knowledge and work as a fully engaged member of the NY Electric Data & Systems team.
• Provide data guidance and support to digital projects and initiatives.
• Support preparation of materials for communications, training and key stakeholder readouts.
• Ability to quickly understand business and data processes, identify customer pain points and help translate business needs into solutions.
• Ability to take a roughly defined approach or hypotheses, identify core intentions and ramifications, and use these insights to refine business assumptions.
• Ability to perform data analytics (including SQL knowledge) and creation of reports/dashboards to communicate meaningful insights.
• Ability to assist with change management and product rollout plans, including presentating materials to senior stakeholders, training material development, and communications plans.
• Ability to manage competing priorities and meet deadlines.
• Ability to effectively partner with stakeholders and build relationships.

Conduct data quality assements and root cause analysis of data issues. Work with business and IT stakeholders to implement necessary changes and improvements.
• Develop details data process maps and documentation (current and to-be state) for NY Electric workflows and projects.

Supervisory/Interpersonal- Experience Required
• Ability to communicate to stakeholders at all levels in the organization.
• Work well in a team.

Qualifications
• Bachelors degree in a STEM discipline with 4 years of related experience, however candidates with equivalent experience will be considered.
• Practical experience with data models, relational databases and development of SQL series.
• Experience conducting structured business analysis and generation of well defined requirements.
• Experience with complete data flows and relationship to business process.
• Knowledge of digital product implementation fundamentals, digital ways of working, and Agile methodologies.
• Demonstrated effectiveness communicating with both technical and non-technical audiences.
• Experience implementing change within an organization.

More Information

Salary: $97,000 - $107,000

This position has a career path which provides for advancement opportunities within and across bands as you develop and evolve in the position; gaining experience, expertise and acquiring and applying technical skills. Internal candidates will be assessed and provided offers against the minimum qualifications of this role and their individual experience.

National Grid is an equal opportunity employer that values a broad diversity of talent, knowledge, experience and expertise. We foster a culture of inclusion that drives employee engagement to deliver superior performance to the communities we serve. National Grid is proud to be an affirmative action employer. We encourage minorities, women, individuals with disabilities and protected veterans to join the National Grid team.

#LI-KC1",,2025-07-25,,,True,[],,"['SQL', 'Data Visualization', 'Data Quality Assessment', 'Data Process Mapping', 'Business Analysis', 'Data Models and Relational Databases', 'Dashboards and Reporting', 'Change Management', 'Agile Methodologies']",SQL: Used for performing data analytics and creating reports and dashboards to communicate meaningful insights.; Data Visualization: Constructing reports and visualizations to support business processes and decision-making.; Data Quality Assessment: Conducting rigorous analysis of data quality and root cause analysis of data issues to improve data reliability and safety.; Data Process Mapping: Developing detailed data process maps and documentation for current and future state workflows and projects.; Business Analysis: Conducting structured business analysis and generating well-defined requirements to translate business needs into data solutions.; Data Models and Relational Databases: Practical experience with data models and relational databases to support data-driven decision making.; Dashboards and Reporting: Creating reports and dashboards to communicate insights and support business teams and leadership.; Change Management: Assisting with change management and product rollout plans including training material development and communications to stakeholders.; Agile Methodologies: Knowledge of digital product implementation fundamentals and Agile ways of working to support digital transformation initiatives.
l0WHl7tPrmnuo4TaAAAAAA==,Senior Data Analyst Jobs,"Description

Job Description

The Company:

ICF is a mission-driven company filled with people who care deeply about improving the lives of others and making the world a better place. Our core values include Embracing Difference; we seek candidates who are passionate about building a culture that encourages, embraces, and hires dimensions of difference.

The Team:

Our Health Engineering Solutions (HES) team works side by side with customers to articulate a vision for success, and then make it happen. We know success doesn't happen by accident. It takes the right team of people, working together on the right solutions for the customer. We are looking for a seasoned Senior Backend Engineer who will be a key driver to make this happen.

The Work:

ICF is seeking a SeniorData Analystto support our Health Engineering Solutions (HES) CMS client team. This role is ideal for a detail-oriented professional with a strong background in data quality assessment, data augmentation, and migration planning. The Senior Data Analyst will work closely with cross-functional teams to ensure the integrity, completeness, and readiness of data for advanced analytics and system integration.

Key Responsibilities:
• Support data collection and augmentation efforts to prepare datasets for downstream analysis and reporting.
• Implement data quality and completeness checks to assess the state of new data files and related resources.
• Identify discrepancies, duplications, and anomalies through pre-validation checks on incoming data types.
• Document known data integrity and quality issues, and collaborate with relevant teams to support remediation planning.
• Load and evaluate sample datasets in the WODD backend system to assess data volume, format, and quality issues.
• Assist in forecasting and planning data migration efforts, including estimating data readiness and transformation needs.
• Collaborate with program implementation, and reporting teams to ensure high-quality data is available for analytics.
• Present findings and recommendations to stakeholders in a clear and actionable format.

Qualifications:
• 6+ years of experience as a data analyst and a Bachelor's degree (Computer Science, Data Science, Math, or equivalent)
• 4+ years of experience with Python and SQL
• 2+ year of experience working with large and complex datasets.
• Must reside in the U.S. and have lived and worked in the U.S. for 3 of the last 5 years.
• Must be able to obtain and maintain a Public Trust clearance.

Professional Skills:
• Strong attention to detail and thoroughness in data validation and documentation.
• Flexibility and adaptability to respond to evolving data requirements and project needs.
• Excellent interpersonal skills and a collaborative, professional attitude.
• Strong analytical, problem-solving, and decision-making capabilities.

Preferred Skills:
• Experience in the healthcare industry and/or federal government contracting.
• Prior experience working remotely in a full-time capacity
• Working at ICF
• ICF is a global advisory and technology services provider, but we're not your typical consultants. We combine unmatched expertise with cutting-edge technology to help clients solve their most complex challenges, navigate change, and shape the future.
• We can only solve the world's toughest challenges by building an inclusive workplace that allows everyone to thrive. We are an equal opportunity employer, committed to hiring regardless of any protected characteristic, such as race, ethnicity, national origin, color, sex, gender identity/expression, sexual orientation, religion, age, disability status, or military/veteran status.
• Together, our employees are empowered to share their expertise and collaborate with others to achieve personal and professional goals. For more information, please read our EEO & AA policy.
• Reasonable Accommodations are available, including, but not limited to, for disabled veterans, individuals with disabilities, and individuals with sincerely held religious beliefs, in all phases of the application and employment process. To request an accommodation please email icfcareercenter@icf.com and we will be happy to assist. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.
• Read more about workplace discrimination rights, the Pay Transparency Statement, or our benefit offerings which are included in the Transparency in (Benefits) Coverage Act.

Working at ICF
ICF is a global advisory and technology services provider, but we're not your typical consultants. We combine unmatched expertise with cutting-edge technology to help clients solve their most complex challenges, navigate change, and shape the future.

We can only solve the world's toughest challenges by building a workplace that allows everyone to thrive. We are an equal opportunity employer . Together, our employees are empowered to share their expertise and collaborate with others to achieve personal and professional goals. For more information, please read our EEO policy.

Reasonable Accommodations are available, including, but not limited to, for disabled veterans, individuals with disabilities, and individuals with sincerely held religious beliefs, in all phases of the application and employment process. To request an accommodation, please email Candidateaccommodation@icf.com and we will be happy to assist . All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

Read more about workplacediscriminationrigh t s or our benefit offerings which are included in the Transparency in (Benefits) Coverage Act.

Candidate AI Usage Policy

At ICF, we are committed to ensuring a fair interview process for all candidates based on their own skills and knowledge. As part of this commitment, the use of artificial intelligence (AI) tools to generate or assist with responses during interviews (whether in-person or virtual) is not permitted . This policy is in place to maintain the integrity and authenticity of the interview process.

However, we understand that some candidates may require accommodation that involves the use of AI. If such an accommodation is needed, candidates are instructed to contact us in advance at candidateaccommodation@icf.com . We are dedicated to providing the necessary support to ensure that all candidates have an equal opportunity to succeed.

Pay Range - There are multiple factors that are considered in determining final pay for a position, including, but not limited to, relevant work experience, skills, certifications and competencies that align to the specified role, geographic location, education and certifications as well as contract provisions regarding labor categories that are specific to the position.

The pay range for this position based on full-time employment is :
$73,722.00 - $125,327.00

Nationwide Remote Office (US99)",2025-07-24T00:00:00.000Z,2025-07-25,"[""6+ years of experience as a data analyst and a Bachelor's degree (Computer Science, Data Science, Math, or equivalent)"", '4+ years of experience with Python and SQL', '2+ year of experience working with large and complex datasets', 'Must reside in the U.S. and have lived and worked in the U.S. for 3 of the last 5 years', 'Must be able to obtain and maintain a Public Trust clearance', 'Strong attention to detail and thoroughness in data validation and documentation', 'Flexibility and adaptability to respond to evolving data requirements and project needs', 'Excellent interpersonal skills and a collaborative, professional attitude', 'Strong analytical, problem-solving, and decision-making capabilities']","['This role is ideal for a detail-oriented professional with a strong background in data quality assessment, data augmentation, and migration planning', 'The Senior Data Analyst will work closely with cross-functional teams to ensure the integrity, completeness, and readiness of data for advanced analytics and system integration', 'Support data collection and augmentation efforts to prepare datasets for downstream analysis and reporting', 'Implement data quality and completeness checks to assess the state of new data files and related resources', 'Identify discrepancies, duplications, and anomalies through pre-validation checks on incoming data types', 'Document known data integrity and quality issues, and collaborate with relevant teams to support remediation planning', 'Load and evaluate sample datasets in the WODD backend system to assess data volume, format, and quality issues', 'Assist in forecasting and planning data migration efforts, including estimating data readiness and transformation needs', 'Collaborate with program implementation, and reporting teams to ensure high-quality data is available for analytics', 'Present findings and recommendations to stakeholders in a clear and actionable format']",True,[],,"['Data Quality Assessment', 'Data Augmentation', 'Data Migration Planning', 'Python', 'SQL', 'Data Validation', 'Data Documentation']","Data Quality Assessment: Used to evaluate the integrity, completeness, and readiness of data for advanced analytics and system integration by implementing data quality and completeness checks and identifying discrepancies, duplications, and anomalies through pre-validation checks.; Data Augmentation: Supporting data collection and augmentation efforts to prepare datasets for downstream analysis and reporting, enhancing the dataset for better analytics outcomes.; Data Migration Planning: Assisting in forecasting and planning data migration efforts, including estimating data readiness and transformation needs to ensure smooth data transfer and integration.; Python: Utilized as a primary programming language for data analysis tasks, including working with large and complex datasets.; SQL: Used for querying and managing large and complex datasets to support data analysis and reporting.; Data Validation: Performing thorough data validation and documentation to ensure data accuracy and reliability for analytics and reporting.; Data Documentation: Documenting known data integrity and quality issues and collaborating with relevant teams to support remediation planning."
6cU9Z12IdFtIzkGiAAAAAA==,"Data Scientist, Mid Jobs","Job Number: R0223031

Data Scientist, Mid

The Opportunity:

As a data scientist, you're excited at the prospect of unlocking the secrets held by a data set, and you're fascinated by the possibilities presented by IoT, machine learning, and artificial intelligence. In an increasingly connected world, massive amounts of structured and unstructured data open new opportunities. As a data scientist at Booz Allen, you can help turn these complex data sets into useful information to solve global challenges. Across private and public sectors-from fraud detection to cancer research to national intelligence-we need you to help find the answers in the data.

On our team, you'll use your analytical skills and data science knowledge to create real-world impact. You'll work closely with your clients to understand their questions and needs, and then dig into their data-rich environments to find the pieces of their information puzzle. You'll develop algorithms and systems and use the right combination of tools and frameworks to turn sets of disparate data points into objective answers to help clients make informed decisions. Ultimately, you'll provide a deep understanding of the data, what it all means, and how it can be used.

Work with us as we use data science for good.

Join us. The world can't wait.

You Have:
• 2+ years of experience with data exploration, data cleaning, data analysis, data visualization, or data mining
• 2+ years of experience with statistical and general-purpose programming languages for data analysis
• Experience analyzing structured and unstructured data sources
• Experience developing predictive data models, quantitative analyses and visualization of targeted data sources
• Experience working with Palantir Foundry Envision
• Experience working effectively in teams and interfacing with clients
• Experience developing visually compelling PowerPoint decks and products to support client delivery
• Knowledge of text mining or machine learning (ML) techniques, artificial intelligence (AI), or natural language processing (NLP)
• Secret clearance
• Bachelor's degree

Nice If You Have:
• 2+ years of experience in the development of algorithms leveraging R, Python, or SQL/NoSQL
• 2+ years of experience with distributed data and computing tools, including MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL
• 2+ years of experience with ML, AI or NLP
• Experience with visualization packages, including Plotly, Seaborn, or ggplot2
• Experience working with Advana or Vault
• Possession of strong verbal and written communication skills
• TS/SCI clearance
• Master's degree

Clearance:

Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required.

Compensation

At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen's benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.

Salary at Booz Allen is determined by various factors, including but not limited to location, the individual's particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $77,600.00 to $176,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen's total compensation package for employees. This posting will close within 90 days from the Posting Date.

Identity Statement

As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud.

Work Model

Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.
• If this position is listed as remote or hybrid, you'll periodically work from a Booz Allen or client site facility.
• If this position is listed as onsite, you'll work with colleagues and clients in person, as needed for the specific role.

Commitment to Non-Discrimination

All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law.",2025-07-23T00:00:00.000Z,2025-07-25,"['2+ years of experience with data exploration, data cleaning, data analysis, data visualization, or data mining', '2+ years of experience with statistical and general-purpose programming languages for data analysis', 'Experience analyzing structured and unstructured data sources', 'Experience developing predictive data models, quantitative analyses and visualization of targeted data sources', 'Experience working with Palantir Foundry Envision', 'Experience working effectively in teams and interfacing with clients', 'Experience developing visually compelling PowerPoint decks and products to support client delivery', 'Knowledge of text mining or machine learning (ML) techniques, artificial intelligence (AI), or natural language processing (NLP)', 'Secret clearance', ""Bachelor's degree"", '2+ years of experience in the development of algorithms leveraging R, Python, or SQL/NoSQL', '2+ years of experience with distributed data and computing tools, including MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL', '2+ years of experience with ML, AI or NLP', 'Experience with visualization packages, including Plotly, Seaborn, or ggplot2', 'Experience working with Advana or Vault', 'Possession of strong verbal and written communication skills', 'TS/SCI clearance', ""Master's degree"", 'Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required']","[""On our team, you'll use your analytical skills and data science knowledge to create real-world impact"", ""You'll work closely with your clients to understand their questions and needs, and then dig into their data-rich environments to find the pieces of their information puzzle"", ""You'll develop algorithms and systems and use the right combination of tools and frameworks to turn sets of disparate data points into objective answers to help clients make informed decisions"", ""Ultimately, you'll provide a deep understanding of the data, what it all means, and how it can be used"", ""If this position is listed as remote or hybrid, you'll periodically work from a Booz Allen or client site facility"", ""If this position is listed as onsite, you'll work with colleagues and clients in person, as needed for the specific role""]",True,['Artificial Intelligence (AI)'],"Artificial Intelligence (AI): Knowledge and experience with AI techniques, including machine learning and natural language processing, to develop intelligent systems and models that support client needs.","['Data Exploration and Cleaning', 'Statistical and General-Purpose Programming Languages', 'Predictive Data Modeling', 'Data Visualization', 'Text Mining and Natural Language Processing (NLP)', 'Distributed Data and Computing Tools', 'Algorithm Development']","Data Exploration and Cleaning: Experience with exploring, cleaning, and analyzing both structured and unstructured data sources to prepare data for further analysis and modeling.; Statistical and General-Purpose Programming Languages: Use of programming languages such as R, Python, and SQL/NoSQL for data analysis, algorithm development, and predictive modeling.; Predictive Data Modeling: Development of predictive models and quantitative analyses to extract insights and support decision-making based on targeted data sources.; Data Visualization: Creation of visual representations of data using tools like Plotly, Seaborn, ggplot2, and Palantir Foundry Envision to communicate findings effectively to clients.; Text Mining and Natural Language Processing (NLP): Application of text mining and NLP techniques to analyze unstructured text data as part of data science projects.; Distributed Data and Computing Tools: Experience with distributed computing frameworks and tools such as MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, and MySQL to handle large-scale data processing and analysis.; Algorithm Development: Design and implementation of algorithms leveraging programming languages and data science techniques to solve client problems and extract meaningful insights."
fT5VGjF4Q3RHr25lAAAAAA==,Data Scientist Jobs,"Data Scientist

Job Category: Information Technology

Time Type: Full time

Minimum Clearance Required to Start: TS/SCI with Polygraph

Employee Type: Regular

Percentage of Travel Required: None

Type of Travel: None
• * *

The Opportunity:

Are you a curious intrinsically motivated person looking to work in an entrepreneurial IC office? If so, we are seeking an experienced Senior Data Scientist to join our innovative analytics team. The ideal candidate will have a strong background in multi-cloud environments, machine learning, and scalable data solutions, with the ability to design and implement cutting-edge analytics capabilities.

Responsibilities
• Design and implement data science frameworks across multi-cloud environments
• Develop machine learning models for data analysis and automation, including building RAG models for AWS Bedrock
• Automate analytic solutions and build scalable analytics capabilities
• Collaborate with the Mission team to gather requirements across various teams
• Assess and implement new technologies and tools to enhance data capabilities
• Support data webforms (SQL databases) and processes for API connections, including drag-and-drop data functionality
• Lead complex data science projects from conception to implementation
• Develop real-time data processing solutions and data solutions at scale
• Integrate AI/ML with applications and systems
• Mentor junior data scientists and contribute to the overall growth of the data science team
• Communicate findings and recommendations to both technical and non-technical stakeholders

Qualifications
Required:
• Degree in Computer Science, Statistics, Mathematics, or related field
• 7+ years of experience in data science or related field, plus additional 3+ years' experience in a complimentary function
• Strong programming skills in Python, SCALA, and/or UNIX shell scripting
• Expertise in machine learning techniques and statistical analysis
• Proficiency in SQL and NoSQL databases
• Experience with big data platforms such as Hadoop, Spark, and Kafka
• Cloud computing expertise across AWS, Azure, and other
• Experience in designing and implementing real-time data processing solutions
• Strong understanding of AI/ML applications in systems and software
• Excellent problem-solving and communication skills
• Experience with data visualization tools (e.g., Tableau, PowerBI)

Desired:
• Experience in IC
• Familiarity with drag-and-drop data tools and API integrations

-
________________________________________________________________________________________

What You Can Expect:

A culture of integrity.

At CACI, we place character and innovation at the center of everything we do. As a valued team member, you'll be part of a high-performing group dedicated to our customer's missions and driven by a higher purpose - to ensure the safety of our nation.

An environment of trust.

CACI values the unique contributions that every employee brings to our company and our customers - every day. You'll have the autonomy to take the time you need through a unique flexible time off benefit and have access to robust learning resources to make your ambitions a reality.

A focus on continuous growth.

Together, we will advance our nation's most critical missions, build on our lengthy track record of business success, and find opportunities to break new ground - in your career and in our legacy.

Your potential is limitless. So is ours.

Learn more about CACI here.

________________________________________________________________________________________

Pay Range: There are a host of factors that can influence final salary including, but not limited to, geographic location, Federal Government contract labor categories and contract wage rates, relevant prior work experience, specific skills and competencies, education, and certifications. Our employees value the flexibility at CACI that allows them to balance quality work and their personal lives. We offer competitive compensation, benefits and learning and development opportunities. Our broad and competitive mix of benefits options is designed to support and protect employees and their families. At CACI, you will receive comprehensive benefits such as; healthcare, wellness, financial, retirement, family support, continuing education, and time off benefits. Learn more here .

The proposed salary range for this position is:
$120,800 - $265,800

CACI is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, age, national origin, disability, status as a protected veteran, or any other protected characteristic.",2025-07-23T00:00:00.000Z,2025-07-25,"['Minimum Clearance Required to Start: TS/SCI with Polygraph', 'If so, we are seeking an experienced Senior Data Scientist to join our innovative analytics team', 'The ideal candidate will have a strong background in multi-cloud environments, machine learning, and scalable data solutions, with the ability to design and implement cutting-edge analytics capabilities', 'Degree in Computer Science, Statistics, Mathematics, or related field', ""7+ years of experience in data science or related field, plus additional 3+ years' experience in a complimentary function"", 'Strong programming skills in Python, SCALA, and/or UNIX shell scripting', 'Expertise in machine learning techniques and statistical analysis', 'Proficiency in SQL and NoSQL databases', 'Experience with big data platforms such as Hadoop, Spark, and Kafka', 'Cloud computing expertise across AWS, Azure, and other', 'Experience in designing and implementing real-time data processing solutions', 'Strong understanding of AI/ML applications in systems and software', 'Excellent problem-solving and communication skills', 'Experience with data visualization tools (e.g., Tableau, PowerBI)']","['Design and implement data science frameworks across multi-cloud environments', 'Develop machine learning models for data analysis and automation, including building RAG models for AWS Bedrock', 'Automate analytic solutions and build scalable analytics capabilities', 'Collaborate with the Mission team to gather requirements across various teams', 'Assess and implement new technologies and tools to enhance data capabilities', 'Support data webforms (SQL databases) and processes for API connections, including drag-and-drop data functionality', 'Lead complex data science projects from conception to implementation', 'Develop real-time data processing solutions and data solutions at scale', 'Integrate AI/ML with applications and systems', 'Mentor junior data scientists and contribute to the overall growth of the data science team', 'Communicate findings and recommendations to both technical and non-technical stakeholders']",True,['Retrieval-Augmented Generation'],Retrieval-Augmented Generation: Develop machine learning models including building Retrieval-Augmented Generation (RAG) models for AWS Bedrock to enhance analytic capabilities.,"['Machine Learning', 'Multi-Cloud Environments', 'SQL and NoSQL Databases', 'Big Data Platforms', 'Data Visualization Tools', 'Programming Languages']","Machine Learning: Develop machine learning models for data analysis and automation; expertise in machine learning techniques and statistical analysis; strong understanding of AI/ML applications in systems and software; integrate AI/ML with applications and systems.; Multi-Cloud Environments: Design and implement data science frameworks across multi-cloud environments; cloud computing expertise across AWS, Azure, and other platforms.; SQL and NoSQL Databases: Support data webforms using SQL databases and processes for API connections; proficiency in SQL and NoSQL databases.; Big Data Platforms: Experience with big data platforms such as Hadoop, Spark, and Kafka; develop real-time data processing solutions and data solutions at scale.; Data Visualization Tools: Experience with data visualization tools such as Tableau and PowerBI to communicate findings and recommendations to stakeholders.; Programming Languages: Strong programming skills in Python, SCALA, and/or UNIX shell scripting used to develop data science solutions and automation."
lREO_Gvf-mqPGqOtAAAAAA==,Data Scientist - 3313719 Jobs,"Computer Technologies Consultants (CTC) is seeking a Data Scientist to support the Defense Intelligence Agency (DIA) in Washington, DC.

With offices in Washington DC and San Diego, CA, CTC is a leading technology company providing lifecycle IT, data analytics, cloud managed hosting services, agile software development, DevOps, Test Automation, Cyber Security, and infrastructure solutions. Additionally, we provide Professional Talent Acquisition Services as we proudly support the unique needs of U.S. Defense, Intelligence, and Federal Civilian agencies as well as Fortune 1000 companies.

Got the Government Contractor Blues? Looking for a company that cares and goes beyond just filling another contract billet? Well look no further! Experience this family-oriented company who takes pride in you and will help you grow where your passions lie. Holding many Defense & Federal government contracts around the globe, with our client you have the opportunity to take on new and evolving challenges, aim beyond what you think you are capable of and work in collaborative, dynamic, and high-tempo environments. Our clients' employees are their most valued asset and they invest in their people because they are in it for the long term. They are committed to your success and well-being and offer competitive benefits packages, salaries, bonus/award programs, and a high potential for professional growth and job opportunities world-wide.

Why Should You Be Interested ?
• Direct hire full-time position
• Competitive base salary and comprehensive benefits
• Mid-size company with room for growth

Position Title : Data Scientist

Position Location : This position is full time, on-site in the National Capital Region

Daily Responsibilities:
• Oversee data normalization, building tables, moving data, writing data scripts, installation, configuration, and data integration.
• Responsibility for discovery, service mapping, configuration management, and event management using MID Servers and best practices.
• Maintain and update the data dictionary, metadata, and SOPs for data-related tasks, ensuring compliance with DIA security and configuration standards.
• Collaborate with platform teams to design scalable, efficient data architectures that enable dashboarding, KPI reporting, and Configuration Management Database (CMDB) health monitoring.
• Participate in data validation, DR/COOP testing, platform upgrades, and ensure data integrity across environments (dev, test, prod).
• Monitor data pipelines for errors or anomalies and propose continuous improvements.
• Ensure all activities align with ATO, NIST 800-53, and DoDIIS data handling guidance.

Required Years of Experience (min) :
• Five (5) years of experience in ServiceNow or a related field.

Required Degree/Certifications :
• Bachelor's degree in Computer Science, Statistics, Mathematics, a related field, or equivalent related professional experience.
• ServiceNow Certified Implementation Specialist (CIS) for Discovery or Service Mapping (required).

Required Experience & Expertise in the following areas :
• Hands-on experience with data scripting, ETL, and data integration tools in enterprise environments.
• Strong understanding of ServiceNow Discovery, Service Mapping, CMDB, and Event Management.
• Proven experience in data modeling, normalization, and database design.
• Familiarity with scripting languages such as JavaScript, Python, or PowerShell.
• Knowledge of IT infrastructure, systems management, and service dependency mapping.
• Ability to troubleshoot and resolve data-related issues quickly and efficiently.
• Strong analytical and problem-solving skills, with the ability to communicate technical findings to non-technical audiences.

Required Clearance :
• Must be eligible for a TS/SCI clearance with CI polygraph (active clearance preferred)

Pay Information

Full-Time Salary Range: TBD

Please note: This range is based on our market pay structures. However, individual salaries are determined by a variety of factors including, but not limited to: business considerations, local market conditions, and internal equity, as well as candidate qualifications, such as skills, education, and experience.

Computer Technologies Consultants, Inc. is an Equal Opportunity Employer that provides employment opportunities for all qualified applicants without regard to race, color, religion, gender identity and/or expression, sexual orientation, age, mental or sensory differing abilities, protected veteran status, sex, national origin, or any other characteristic protected by applicable law. Computer Technologies Consultants, Inc. is devoted to diversity, equity, and inclusion.",2025-07-24T00:00:00.000Z,2025-07-25,"['Five (5) years of experience in ServiceNow or a related field', ""Bachelor's degree in Computer Science, Statistics, Mathematics, a related field, or equivalent related professional experience"", 'ServiceNow Certified Implementation Specialist (CIS) for Discovery or Service Mapping (required)', 'Required Experience & Expertise in the following areas :', 'Hands-on experience with data scripting, ETL, and data integration tools in enterprise environments', 'Strong understanding of ServiceNow Discovery, Service Mapping, CMDB, and Event Management', 'Proven experience in data modeling, normalization, and database design', 'Familiarity with scripting languages such as JavaScript, Python, or PowerShell', 'Knowledge of IT infrastructure, systems management, and service dependency mapping', 'Ability to troubleshoot and resolve data-related issues quickly and efficiently', 'Strong analytical and problem-solving skills, with the ability to communicate technical findings to non-technical audiences']","['Position Location : This position is full time, on-site in the National Capital Region', 'Oversee data normalization, building tables, moving data, writing data scripts, installation, configuration, and data integration', 'Responsibility for discovery, service mapping, configuration management, and event management using MID Servers and best practices', 'Maintain and update the data dictionary, metadata, and SOPs for data-related tasks, ensuring compliance with DIA security and configuration standards', 'Collaborate with platform teams to design scalable, efficient data architectures that enable dashboarding, KPI reporting, and Configuration Management Database (CMDB) health monitoring', 'Participate in data validation, DR/COOP testing, platform upgrades, and ensure data integrity across environments (dev, test, prod)', 'Monitor data pipelines for errors or anomalies and propose continuous improvements', 'Ensure all activities align with ATO, NIST 800-53, and DoDIIS data handling guidance']",True,[],,"['Data Normalization', 'Data Scripting', 'ETL (Extract, Transform, Load)', 'Data Integration', 'ServiceNow Discovery', 'Service Mapping', 'Configuration Management Database (CMDB)', 'Event Management', 'Data Dictionary and Metadata Management', 'Data Architecture Design', 'Data Validation and Integrity', 'Data Pipelines Monitoring', 'Data Modeling and Database Design', 'Scripting Languages', 'IT Infrastructure and Systems Management']","Data Normalization: Responsible for overseeing data normalization processes including building tables and moving data to ensure consistent and clean data structures.; Data Scripting: Writing data scripts to support data integration, transformation, and automation within enterprise environments.; ETL (Extract, Transform, Load): Hands-on experience with ETL processes and tools to extract, transform, and load data efficiently in enterprise settings.; Data Integration: Managing data integration tasks including installation, configuration, and ensuring seamless data flow across systems.; ServiceNow Discovery: Utilizing ServiceNow Discovery tools to identify and map IT infrastructure components and services.; Service Mapping: Implementing service mapping to visualize and manage dependencies between IT services and infrastructure.; Configuration Management Database (CMDB): Designing and maintaining the CMDB to support configuration management and health monitoring of IT assets.; Event Management: Using event management practices to monitor and respond to IT events and incidents effectively.; Data Dictionary and Metadata Management: Maintaining and updating the data dictionary and metadata to ensure data governance and compliance with security standards.; Data Architecture Design: Collaborating with platform teams to design scalable and efficient data architectures that support dashboarding and KPI reporting.; Data Validation and Integrity: Participating in data validation, disaster recovery (DR) and continuity of operations (COOP) testing, and ensuring data integrity across development, testing, and production environments.; Data Pipelines Monitoring: Monitoring data pipelines for errors or anomalies and proposing continuous improvements to enhance data reliability.; Data Modeling and Database Design: Proven experience in data modeling, normalization, and designing databases to support enterprise data needs.; Scripting Languages: Familiarity with scripting languages such as JavaScript, Python, and PowerShell to automate and support data-related tasks.; IT Infrastructure and Systems Management: Knowledge of IT infrastructure, systems management, and service dependency mapping to support data and service management."
jP9DTA35CxtBFLhCAAAAAA==,Data Scientist Jobs,"Job Type

Full-time

Description

Data Scientist

Primary Location: Washington D.C. Metropolitan Area

Clearance: Top Secret

Must be a US Citizen

This position is contingent on contract award.

Job Summary

Obsidian Solutions Group (OSG) is seeking an Exploitation Specialist / Analytic Methodologist to join the Team!

Supporting National Geospatial-Intelligence Agency (NGA) providing and sustaining support that promotes mission excellence through applied modernized analytic techniques, data sciences, modeling, and automation that optimized service performance and innovation.

Specific Responsibilities

· Develop methods for querying, visualizing, aggregating, correlating, and analyzing big data across intelligence disciplines

· Optimize existing databases to speed up the query, input, export, and visualization of data.

· Work with teams in NGA Analysis Operations (AO) Regional, Functional and Agency/CCMD Liaison Offices (collectively referred to as ""AO Offices"") to develop strategies for exposing new datasets and create migration plans for legacy datasets.

· Build custom solutions (tools, processes, etc.) to automate or assist analytic endeavors as submitted by applicable AO Office leadership and analytic units.

· Write scripts in Visual Basic, R, Python or other software for statistical models using large datasets to extract patterns, relationships, and anticipatory behaviors that are repeatable, efficient, hypothesis testing, and knowledge capture.

· Use mathematical concepts and techniques to solve complex GEOINT analysis problem sets; understand concepts associated with structured data and relational databases

· Use tools, such as Arc GIS, Excel, SPSS, SAS, Matlab, R, or other statistical packages, to analyze and visualize operational data; visualize data both temporally and spatially

Requirements

· Possess a Bachelor's Degree or higher in math or a science related field or possess at least 7 years of relevant experience in lieu of a Bachelor's Degree.

· Experience applying multidisciplinary mathematical and statistical models via programming language to large datasets to extract patterns, relationships and anticipatory behavioral likelihoods that may not be apparent using traditional single discipline means

· Experience in developing tradecraft techniques and training solutions for discovery, preparation, manipulation and normalization of big data so that methods are repeatable and can be explained to analysts

· Experience using mathematical concepts and techniques to solve complex GEOINT analysis problem sets; understand concepts associated with structured data and relational databases

· Experience understanding and explaining the relationship between the data collected for a real world problem and the required structure of a relational database to help solve that problem

· Experience conceptualizing the relationship between a database structure and the requirements for analyzing and visualizing those data both temporally and spatially

· Experience writing scripts in Visual Basic, R, Python, Java, Javascript, C++ or other software for modeling processes, with a focus on repeatability, efficiency, knowledge capture, and hypothesis testing

· Experience using tools, such as ArcGIS, Excel, Python, SPSS, R, or other statistical packages, to analyze and visualize data; visualize data both temporally and spatially to assist in data integrity checks, ask the next question, and display analytical assessments

· Experience maintaining, moving and manipulating data between applications, using appropriate software and/or Extract-Transform-Load (ELT) procedures: Microsoft EXCEL spreadsheets, ACCESS database management system and/or ORACLE, Postgresql, or SQL Server and importing and cleaning analyst-provided datasets (Excel, geospatial data, etc.)

· Experience using statistical software (SPSS, SAS, Matlab etc.), desktop software (MS Office and Access), and the Windows operating environment. Of importance is software packages used for advanced statistical analysis of operational data

· Experience using GOTS data and analytics capabilities (MIST, INTELBOOK, LINX and WATCHBOX)

· Knowledge of intelligence operations and GEOINT phenomenology.

· Data Visualization Experience which may include Matrix Analytics, Network Analytics, Graphing Data.

· Knowledge and experience using 1) ABI tools and tradecraft to include MIST, 2) SOM tools and SOM-C, GOWK, CEDALLION, and ATLAS, and 3) OBP tools.

Physical Requirements and Work Environment

Normal Office environment

Travel

Occasional Long Distance

Company Description

Obsidian Solutions Group LLC (OSG) is a fast-growing professional services firm based in Fredericksburg, VA. We create value for our customers by delivering technology-enabled & mission-oriented technical solutions that solve complex problems, protecting people, information, and assets. Our core capabilities are in providing Enterprise IT, Intelligence Analysis, Production & Development and Knowledge-Based Professional Services Solutions that enable the customer's mission. Obsidian Solutions Group LLC is a certified 8(a), service-disabled, veteran-owned small business.

A career at Obsidian Solutions Group means you can put your expertise, credentials, and talents to great use working with customers in the DOD and Intelligence Community, while enjoying the excitement of working in a fast-growing organization committed to making a difference for our customers and in our community. Contribute independently and collaboratively alongside our amazing team of doers and thinkers. Obsidian Solutions Group is small enough to offer a family atmosphere yet large enough to deliver a highly competitive compensation package. We hire and retain the best in the industry, offering exceptional benefits that protect the well-being of our employees, their spouses and domestic partners, and their families.

Our corporate philosophy is centered on hiring and retaining employees with the requisite skills, professional experience, personal commitment, and ethical standards necessary to foster a culture of operational excellence necessary to surpass our customer's expectations.

Disclaimer

The above information on this description has been designed to indicate the general nature and level of work performed by employees within this classification. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities, and qualifications required of employees assigned to this job.

Obsidian Solutions Group is an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex (including pregnancy and gender identity), national origin, political affiliation, sexual orientation, marital status, disability, genetic information, age, membership in an employee organization, parental status, protected veteran status, and any other non-merit factor, or any other characteristic protected by law.",2025-07-25T00:00:00.000Z,2025-07-25,"['Must be a US Citizen', ""Possess a Bachelor's Degree or higher in math or a science related field or possess at least 7 years of relevant experience in lieu of a Bachelor's Degree"", 'Experience applying multidisciplinary mathematical and statistical models via programming language to large datasets to extract patterns, relationships and anticipatory behavioral likelihoods that may not be apparent using traditional single discipline means', 'Experience in developing tradecraft techniques and training solutions for discovery, preparation, manipulation and normalization of big data so that methods are repeatable and can be explained to analysts', 'Experience using mathematical concepts and techniques to solve complex GEOINT analysis problem sets; understand concepts associated with structured data and relational databases', 'Experience understanding and explaining the relationship between the data collected for a real world problem and the required structure of a relational database to help solve that problem', 'Experience conceptualizing the relationship between a database structure and the requirements for analyzing and visualizing those data both temporally and spatially', 'Experience writing scripts in Visual Basic, R, Python, Java, Javascript, C++ or other software for modeling processes, with a focus on repeatability, efficiency, knowledge capture, and hypothesis testing', 'Experience using tools, such as ArcGIS, Excel, Python, SPSS, R, or other statistical packages, to analyze and visualize data; visualize data both temporally and spatially to assist in data integrity checks, ask the next question, and display analytical assessments', 'Experience maintaining, moving and manipulating data between applications, using appropriate software and/or Extract-Transform-Load (ELT) procedures: Microsoft EXCEL spreadsheets, ACCESS database management system and/or ORACLE, Postgresql, or SQL Server and importing and cleaning analyst-provided datasets (Excel, geospatial data, etc.)', 'Experience using statistical software (SPSS, SAS, Matlab etc.), desktop software (MS Office and Access), and the Windows operating environment', 'Of importance is software packages used for advanced statistical analysis of operational data', 'Experience using GOTS data and analytics capabilities (MIST, INTELBOOK, LINX and WATCHBOX)', 'Knowledge of intelligence operations and GEOINT phenomenology', 'Data Visualization Experience which may include Matrix Analytics, Network Analytics, Graphing Data', 'Knowledge and experience using 1) ABI tools and tradecraft to include MIST, 2) SOM tools and SOM-C, GOWK, CEDALLION, and ATLAS, and 3) OBP tools', 'Physical Requirements and Work Environment']","['Supporting National Geospatial-Intelligence Agency (NGA) providing and sustaining support that promotes mission excellence through applied modernized analytic techniques, data sciences, modeling, and automation that optimized service performance and innovation', 'Develop methods for querying, visualizing, aggregating, correlating, and analyzing big data across intelligence disciplines', 'Optimize existing databases to speed up the query, input, export, and visualization of data', 'Work with teams in NGA Analysis Operations (AO) Regional, Functional and Agency/CCMD Liaison Offices (collectively referred to as ""AO Offices"") to develop strategies for exposing new datasets and create migration plans for legacy datasets', 'Build custom solutions (tools, processes, etc.)', 'to automate or assist analytic endeavors as submitted by applicable AO Office leadership and analytic units', 'Write scripts in Visual Basic, R, Python or other software for statistical models using large datasets to extract patterns, relationships, and anticipatory behaviors that are repeatable, efficient, hypothesis testing, and knowledge capture', 'Use mathematical concepts and techniques to solve complex GEOINT analysis problem sets; understand concepts associated with structured data and relational databases', 'Use tools, such as Arc GIS, Excel, SPSS, SAS, Matlab, R, or other statistical packages, to analyze and visualize operational data; visualize data both temporally and spatially']",True,[],,"['Big Data Analytics', 'Statistical Modeling', 'Mathematical and Statistical Techniques', 'Data Visualization', 'Data Engineering and ETL', 'Relational Databases', 'Programming Languages for Data Science', 'Advanced Statistical Software', 'Geospatial Intelligence (GEOINT) Analysis', 'Government Off-The-Shelf (GOTS) Analytics Tools', 'Data Visualization Techniques', 'Analytic Tradecraft Tools']","Big Data Analytics: Develop methods for querying, visualizing, aggregating, correlating, and analyzing large datasets across intelligence disciplines to extract patterns and anticipatory behaviors.; Statistical Modeling: Write scripts in Visual Basic, R, Python, and other languages to build statistical models that are repeatable, efficient, support hypothesis testing, and enable knowledge capture from large datasets.; Mathematical and Statistical Techniques: Apply multidisciplinary mathematical and statistical models and concepts to solve complex GEOINT analysis problems and extract meaningful insights from structured data and relational databases.; Data Visualization: Use tools such as ArcGIS, Excel, SPSS, SAS, Matlab, and R to visualize operational data both temporally and spatially, assisting in data integrity checks and analytical assessments.; Data Engineering and ETL: Maintain, move, and manipulate data between applications using software and Extract-Transform-Load (ETL) procedures involving Microsoft Excel, Access, Oracle, PostgreSQL, and SQL Server, including importing and cleaning analyst-provided datasets.; Relational Databases: Understand and explain the relationship between real-world data collection and the required structure of relational databases to support analysis and visualization.; Programming Languages for Data Science: Use programming languages such as Visual Basic, R, Python, Java, JavaScript, and C++ to develop custom analytic tools, automate processes, and support modeling efforts.; Advanced Statistical Software: Utilize statistical software packages including SPSS, SAS, Matlab, and R for advanced statistical analysis of operational data.; Geospatial Intelligence (GEOINT) Analysis: Apply knowledge of intelligence operations and GEOINT phenomenology to analyze geospatial data and support mission objectives.; Government Off-The-Shelf (GOTS) Analytics Tools: Use specialized GOTS data and analytics capabilities such as MIST, INTELBOOK, LINX, and WATCHBOX to support intelligence analysis.; Data Visualization Techniques: Employ matrix analytics, network analytics, and graphing data techniques to enhance data visualization and interpretation.; Analytic Tradecraft Tools: Leverage ABI tools and tradecraft including MIST, SOM tools and SOM-C, GOWK, CEDALLION, ATLAS, and OBP tools to support analytic processes and intelligence workflows."
jC4mf5O0NpszvA_FAAAAAA==,Data Scientist-RS3 Prog and Data Analytics Jobs,"Description

Position Title : Data Scientist

Location : Arlington, VA (Remote)

Clearance Level : Secret

Responsibilities will include, but are not limited to :
• Serve as a primary facilitator for preparation, execution and follow up for all Planning, Programming, and Budgeting Committee - Guard (PPBC-G) forums (General Officer / Strategic Level forums), to include Resourcing Council of Colonels (RCoC), Resource Integration Steering Committee (RISC). Coordinates across Army National Guard Bureau staffs to develop topics, products, and presentations for submission to the PPBC-G process.
• Support the design, development, and execution of all data analytic efforts led by the GS-13 Data Scientist as directed by the DAG-R Division Chief/Deputy Division Chief in support of the Chief Financial Officer's analytic agenda.
• Provide expertise on ARNG Roles, Missions, Authorities and Army strategic guidance and key planning efforts such as The Army Plan (TAP), Total Army Analysis (TAA), the Army Equipment Modernization Strategy (AEMS), and the Long-Range Investment Requirements Analysis (LIRA).
• Develop and enhance websites, applications, and secure access to databases based upon requirements for analytic efforts as approved by the COR. Customers include the CFO, ARNG G-8, DAG-R, ARNG Directorate Office of Primary Responsibility (OPR) for program portfolio's, and National-level Program Managers (NPMs).

Qualifications

Required qualifications
• Bachelor's Degree in related field of study or equivalent experience.
• Minimum of four years of experience, two within the DoD working with big-data systems and developing production-level data models .
• Possess skills and expertise in machine learning tools to select features, create, and optimize classifiers.
• Possess demonstrable collegiate-level writing skills, demonstrated familiarity with the U.S. Army organization and regulations, and strong organization and communication skills.
• Demonstrate practical experience substantiating equivalent skills such as Structured Query Language, Microsoft Excel, R or Python statistical programming, Data Visualization, and Presentation Skills.
• Prior knowledge of Power BI, Tableau, and Advana data science is preferred",2025-07-25T13:00:00.000Z,2025-07-25,"[""Bachelor's Degree in related field of study or equivalent experience"", 'Minimum of four years of experience, two within the DoD working with big-data systems and developing production-level data models ', 'Possess skills and expertise in machine learning tools to select features, create, and optimize classifiers', 'Possess demonstrable collegiate-level writing skills, demonstrated familiarity with the U.S. Army organization and regulations, and strong organization and communication skills', 'Demonstrate practical experience substantiating equivalent skills such as Structured Query Language, Microsoft Excel, R or Python statistical programming, Data Visualization, and Presentation Skills']","['Serve as a primary facilitator for preparation, execution and follow up for all Planning, Programming, and Budgeting Committee - Guard (PPBC-G) forums (General Officer / Strategic Level forums), to include Resourcing Council of Colonels (RCoC), Resource Integration Steering Committee (RISC)', 'Coordinates across Army National Guard Bureau staffs to develop topics, products, and presentations for submission to the PPBC-G process', ""Support the design, development, and execution of all data analytic efforts led by the GS-13 Data Scientist as directed by the DAG-R Division Chief/Deputy Division Chief in support of the Chief Financial Officer's analytic agenda"", 'Provide expertise on ARNG Roles, Missions, Authorities and Army strategic guidance and key planning efforts such as The Army Plan (TAP), Total Army Analysis (TAA), the Army Equipment Modernization Strategy (AEMS), and the Long-Range Investment Requirements Analysis (LIRA)', 'Develop and enhance websites, applications, and secure access to databases based upon requirements for analytic efforts as approved by the COR', ""Customers include the CFO, ARNG G-8, DAG-R, ARNG Directorate Office of Primary Responsibility (OPR) for program portfolio's, and National-level Program Managers (NPMs)""]",True,[],,"['Machine Learning', 'Big Data Systems', 'Structured Query Language (SQL)', 'Python Statistical Programming', 'R Statistical Programming', 'Data Visualization', 'Microsoft Excel', 'Power BI', 'Tableau', 'Advana Data Science']","Machine Learning: The job requires skills and expertise in machine learning tools to select features, create, and optimize classifiers for production-level data models.; Big Data Systems: Experience working with big-data systems within the Department of Defense is required for developing production-level data models.; Structured Query Language (SQL): Practical experience with SQL is necessary to support data analytic efforts and database access.; Python Statistical Programming: Experience with Python for statistical programming is required to develop and execute data analytic efforts.; R Statistical Programming: Experience with R for statistical programming is required to develop and execute data analytic efforts.; Data Visualization: The role involves data visualization skills to support analytic efforts and presentation of data insights.; Microsoft Excel: Proficiency in Microsoft Excel is required to support data analysis and presentation tasks.; Power BI: Prior knowledge of Power BI is preferred for creating business intelligence dashboards and visualizations.; Tableau: Prior knowledge of Tableau is preferred for creating business intelligence dashboards and visualizations.; Advana Data Science: Familiarity with Advana data science platform is preferred to support analytic efforts within the Army National Guard."
q6-tTQUn2Sr0Hg9vAAAAAA==,Data Scientist Jobs,"Title
Data Scientist
Full-Time/Part-Time Full-Time Description
Cyber Intelligence Alliance (CIA) Joint Venture (JV) is seeking a Data Scientist (contingent upon award) to support federal client in serving as a primary facilitator for preparation, execution and follow up for all Planning, Programming, and Budgeting Committee (PPBC-G) forms. Supports analytic efforts of the client and validates accuracy and appropriate analysis for presentation in forums. Provides primary oversight and tracking of issues/topics for development, staffing in the PPBC-G. Prefer some working knowledge of Power BI and/or Tableau.
• Candidate shall possess skills and expertise in machine learning tools to select features, create, and optimize classifiers.
• Candidate shall possess demonstrable collegiate-level writing skills, demonstrated familiarity with the U.S. Army organization and regulations, and strong organization and communication skills.
• Candidate shall have the ability to communicate complex technical findings to a variety of audiences.
• Candidate should have the ability to demonstrate practical experience substantiating equivalent skills such as Structured Query Language, Microsoft Excel, R or Python statistical programming, Data Visualization, and Presentation Skills.
Requirements for this position shall include:
• Bachelor's degree or higher in related field of study or equivalent experience
• Minimum of four (4) years of experience, two within DoD, working with big-data systems and developing production-level data models
• Secret Security Clearance Required
• Prior knowledge of Power BI, Tableau, and Advana data science is preferred.
About the Organization Established in 2008, RiVidium, Inc. (dba TripleCyber) is a VA-Verified SDVOSB and an SBA-Certified 8(a) company. To prepare our clients for the future, RiVidium has balanced all parts of our organization to attract the finest employees in order to 'Strive to be the missing element defining tomorrow's technology'. RiVidium keeps pace and surpasses its competitors by meeting challenges of advancements in Logistics, Human Capital, Cyber, Intelligence & Technology. EOE Statement We are an equal employment opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status or any other characteristic protected by law. If you need a reasonable accommodation for any part of the employment process, please contact Human Resources (HR) at hr@rividium.com.
This position is currently accepting applications.",2025-07-25T00:00:00.000Z,2025-07-25,"['Prefer some working knowledge of Power BI and/or Tableau', 'Candidate shall possess skills and expertise in machine learning tools to select features, create, and optimize classifiers', 'Candidate shall possess demonstrable collegiate-level writing skills, demonstrated familiarity with the U.S. Army organization and regulations, and strong organization and communication skills', 'Candidate shall have the ability to communicate complex technical findings to a variety of audiences', 'Candidate should have the ability to demonstrate practical experience substantiating equivalent skills such as Structured Query Language, Microsoft Excel, R or Python statistical programming, Data Visualization, and Presentation Skills', ""Bachelor's degree or higher in related field of study or equivalent experience"", 'Minimum of four (4) years of experience, two within DoD, working with big-data systems and developing production-level data models', 'Secret Security Clearance Required', 'About the Organization Established in 2008, RiVidium, Inc']","['Cyber Intelligence Alliance (CIA) Joint Venture (JV) is seeking a Data Scientist (contingent upon award) to support federal client in serving as a primary facilitator for preparation, execution and follow up for all Planning, Programming, and Budgeting Committee (PPBC-G) forms', 'Supports analytic efforts of the client and validates accuracy and appropriate analysis for presentation in forums', 'Provides primary oversight and tracking of issues/topics for development, staffing in the PPBC-G']",True,[],,"['Machine Learning', 'Feature Selection', 'Classification Models', 'SQL', 'Python Statistical Programming', 'R Statistical Programming', 'Data Visualization', 'Power BI', 'Tableau', 'Big Data Systems', 'Data Models']","Machine Learning: The candidate is expected to have skills and expertise in machine learning tools to select features, create, and optimize classifiers for analytic efforts supporting the client.; Feature Selection: The role involves using machine learning tools specifically to select features as part of building and optimizing classifiers.; Classification Models: The job requires creating and optimizing classifiers, indicating experience with classification models in machine learning.; SQL: The candidate should demonstrate practical experience with Structured Query Language for data querying and manipulation.; Python Statistical Programming: Experience with Python for statistical programming is required to support data analysis and model development.; R Statistical Programming: Experience with R for statistical programming is required to support data analysis and model development.; Data Visualization: The candidate should have skills in data visualization, including practical experience with tools like Power BI and Tableau, to present analytic results effectively.; Power BI: Preferred working knowledge of Power BI is mentioned for data visualization and presentation of analytic findings.; Tableau: Preferred working knowledge of Tableau is mentioned for data visualization and presentation of analytic findings.; Big Data Systems: The candidate must have experience working with big-data systems and developing production-level data models, indicating handling large-scale data environments.; Data Models: Developing production-level data models is a key responsibility, supporting analytic efforts and data-driven decision making."
dLAcy4VGzii_2vfPAAAAAA==,"Data Scientist - Tysons Corner, VA - Top Secret Clearance Jobs","Data Scientist needed for an opportunity with SOC's client to work in Tysons Corner, Virginia.

Active Top Secret Clearance is required!

Responsibilities
• Collaborate with data and subject matter experts from Customer and its customer teams to seek, understand, validate, interpret, and correctly use data and business insights
• MLOps, Model Engineering, Training on time series data.
• After few weeks training on Customer's AI platform, develop AI-based applications using Customer's platform for operational cloud-deployed and secure lab deployed AI-based applications.
• Develop candidate models that are promoted to active models when their performance meets threshold.
• Train, validate and deploy machine learning pipelines
• Test, troubleshoot, and enhance customer AI-based applications based on feedback.
• Manage individual project deliverables
• Identify application performance bottlenecks and implement optimizations
• Write application specifications and documentation
• Articulate methodologies, experiments, and findings clearly in actionable way.
• Work in a fast-paced environment.
• This is NOT a data analytics role using Tableau or PowerBI.
• This is NOT an ETL & SQL role.
• This is NOT a R&D role prototyping at low TRL.
Qualifications
• Bachelor's degree in a Science, Technology, Engineering or Mathematics (STEM), or comparable area of study. No experience in lieu of.
• 5+ years of Data Science development experience using Python
• Proficiency in data science, machine learning, and analytics, including statistical data analysis, model and feature evaluations.
• Strong proficiency in numpy & pandas.
• Demonstrated skills with Jupyter Notebook or comparable environments
• Practical experience in solving complex problems in an applied environment, and proficiency in critical thinking.
• Candidates require a TS to start. TS/SCI with Polygraph preferred
PREFERRED Qualifications
• Degree in Data Science, Machine Learning, Computer Science, Engineering, Statistics, or equivalent fields
• Strong mathematical background (linear algebra, calculus, probability & statistics)
• Experience with machine learning model training and analysis through open-source frameworks (Pytorch, Tensorflow, Sklearn)
• Experience crafting, conducting, analyzing, and interpreting experiments and investigations.
• Experience with modern software development tools and practices (Git, pull requests)
• Experience analyzing model performance with relevant metrics and optimizing.
• Familiarity with AI agent frameworks
• Ability to drive a project and work both independently and in a team
• Smart, motivated, can-do attitude, and seeks to make a difference
• Excellent English communication and collaboration skills, particularly in multidisciplinary teams with data scientists, software engineers, product owners, & solution architects.
Employment Pre-requisites
The following requirements must be met to be eligible for this position: Successful completion of a background investigation, and d rug urinalysis.
SOC, a Day & Zimmermann company, is an Equal Opportunity Employer,EOE AA M/F/Vet/Disability.

#INDSOC

Estimated Min Rate: $56.00
Estimated Max Rate: $80.00",2025-07-25T01:00:00.000Z,2025-07-25,"['Active Top Secret Clearance is required!', ""Bachelor's degree in a Science, Technology, Engineering or Mathematics (STEM), or comparable area of study"", 'No experience in lieu of', '5+ years of Data Science development experience using Python', 'Proficiency in data science, machine learning, and analytics, including statistical data analysis, model and feature evaluations', 'Strong proficiency in numpy & pandas', 'Demonstrated skills with Jupyter Notebook or comparable environments', 'Practical experience in solving complex problems in an applied environment, and proficiency in critical thinking', 'Candidates require a TS to start', 'The following requirements must be met to be eligible for this position: Successful completion of a background investigation, and d rug urinalysis']","['Collaborate with data and subject matter experts from Customer and its customer teams to seek, understand, validate, interpret, and correctly use data and business insights', 'MLOps, Model Engineering, Training on time series data', ""After few weeks training on Customer's AI platform, develop AI-based applications using Customer's platform for operational cloud-deployed and secure lab deployed AI-based applications"", 'Develop candidate models that are promoted to active models when their performance meets threshold', 'Train, validate and deploy machine learning pipelines', 'Test, troubleshoot, and enhance customer AI-based applications based on feedback', 'Manage individual project deliverables', 'Identify application performance bottlenecks and implement optimizations', 'Write application specifications and documentation', 'Articulate methodologies, experiments, and findings clearly in actionable way', 'Work in a fast-paced environment', 'This is NOT a data analytics role using Tableau or PowerBI', 'This is NOT an ETL & SQL role', 'This is NOT a R&D role prototyping at low TRL']",True,"['AI Platforms', 'AI-Based Applications', 'AI Agent Frameworks']","AI Platforms: The job involves developing AI-based applications using the customer's AI platform for operational cloud and secure lab deployments.; AI-Based Applications: Responsibilities include developing, testing, troubleshooting, and enhancing AI-based applications based on feedback.; AI Agent Frameworks: Familiarity with AI agent frameworks is preferred, indicating involvement with autonomous or intelligent agent systems within AI applications.","['Time Series Models', 'MLOps', 'Machine Learning Pipelines', 'Python', 'Numpy and Pandas', 'Jupyter Notebook', 'Statistical Data Analysis', 'Open-Source Machine Learning Frameworks']","Time Series Models: The role involves training on time series data and developing models that analyze temporal data patterns.; MLOps: Responsibilities include managing machine learning pipelines, training, validating, deploying models, and optimizing application performance.; Machine Learning Pipelines: The job requires training, validating, and deploying machine learning pipelines to develop candidate models that meet performance thresholds.; Python: The candidate must have 5+ years of experience in data science development using Python, including proficiency with numpy and pandas libraries.; Numpy and Pandas: Strong proficiency in numpy and pandas is required for data manipulation and analysis tasks.; Jupyter Notebook: Experience with Jupyter Notebook or comparable environments is necessary for developing and documenting data science workflows.; Statistical Data Analysis: The role requires proficiency in statistical data analysis, model evaluation, and feature evaluation to interpret and validate data insights.; Open-Source Machine Learning Frameworks: Experience with frameworks such as PyTorch, TensorFlow, and scikit-learn is preferred for model training and analysis."
vmRyubn28ldCTWSXAAAAAA==,Data Scientist Development Program (DSDP) - Entry to Mid Level ( Jobs,"Duties
Help

Data science at the National Security Agency (NSA) is a multi-disciplinary field that uses elements of mathematics, statistics, computer science, and application-specific knowledge to gather, make, and communicate principled conclusions from data. Data Science is a broad field and a team effort, spanning all the expertise needed to derive value from data. It encompasses AI Engineering, Data Engineering, ML Ops Engineering, and Human Perception and Cognition Engineering in addition to the traditional applications of data science.

Data science is present in every aspect of the mission. NSA Data Scientists tackle challenging real-world problems leveraging big data, high-performance computing, machine learning, and a breadth of other methodologies. We are looking for critical thinkers, problem solvers, and motivated individuals who are enthusiastic about data and believe that answers to hard questions lie in the yet-to-be-told story of diverse, complicated data sets. You will employ your mathematical science, computer science, and quantitative analysis skills to develop solutions to complex data problems and take full advantage of NSA's capabilities to tackle the highest priority foreign intelligence and cybersecurity challenges.

As a Data Scientist, your responsibilities may include:
- Exploratory data analysis and exploratory model-fitting to reveal data features of interest
- Machine-learned predictive modeling
- Identifying and analyzing anomalous data (including metadata)
- Lead or contribute to cross-functional teams to develop and implement Al (including generative AI) that can help solve some of our most challenging problems.
- Apply modern engineering techniques to develop decision support software prototypes.
- Propose and execute novel, cutting-edge research in Al-enhanced decision systems.
- Designing and developing analytics and techniques for analysis
- Analyzing data using mathematical and statistical methods
- Implement ML pipeline and workflows
- Leverage skills in modern data architecture, cloud engineering, data transformation, and management of structured and unstructured data sources.
- Build continuous integration and delivery pipelines for ML applications.
- Construct usable data sets from multiple sources to meet customer needs
- Developing conceptual design and models to address mission requirements
- Developing qualitative and quantitative methods for characterizing datasets in various states.
- Performing analytic modeling, scripting, and/or programming
- Working collaboratively and iteratively throughout the data-science lifecycle
- Communicate with a team of data scientists, data engineers, AI engineers, ML-Ops engineers, and stakeholders.
- Evaluating, documenting, and communicating research processes, analyses, and results to customers, peers, and leadership
- Creating interpretable visualizations.
- Work with mission owners to design, develop, and deploy new architectures for ML and automation applications such as ELT functions, HPC/compute infrastructure, AWS/Azure solutions, database solutions, and optimization of DevOps procedures.

Requirements
Help
Conditions of employment
• Employment is contingent upon successful completion of a security background investigation and polygraph.
Qualifications

The qualifications listed are the minimum acceptable to be considered for the position.

Applicants who meet minimum qualifications may be asked to complete the Data Science Examination (DSE) evaluating their knowledge of statistics, mathematics, and computer science topics that pertain to data science work. Passing this examination is a requirement in order to be considered for selection into a data scientist position.

Degree must be in Mathematics, Applied Mathematics, Statistics, Applied Statistics, Machine Learning, Data Science, Operations Research, or Computer Science. A degree in a related field (e.g., Computer Information Systems, Engineering), a degree in the physical/hard sciences (e.g. physics, chemistry, biology, astronomy), or other science disciplines (i.e., behavioral, social, library, and life) may be considered if it includes a concentration of coursework (typically 5 or more courses) in advanced mathematics (typically 200 level or higher; such as calculus, differential equations, discrete mathematics, linear algebra, and calculus based statistics) and/or computer science (e.g., algorithms, programming, data structures, data mining, artificial intelligence). College-level Algebra or other math courses intended to meet a basic college level requirement, or upper level math courses designated as elementary or basic do not count.

Note: Degrees in related fields will be considered if accompanied by a Certificate in Data Science from an accredited college/university.

ENTRY/DEVELOPMENTAL
Entry is with a Bachelor's degree and no experience. An Associate's degree plus 2 years of relevant experience may be considered for individuals with in-depth experience that is clearly related to the position. Relevant experience must be in one or more of the following: designing/implementing machine learning, data mining, advanced analytical algorithms, programming, data science, advanced statistical analysis, artificial intelligence, computational science, software engineering, or data engineering.

FULL PERFORMANCE
Entry is with a Bachelor's degree plus 3 years of relevant experience or a Master's degree plus 1 year of relevant experience or a Doctoral degree and no experience. An Associate's degree plus 5 years of relevant experience may be considered for individuals with in-depth experience that is clearly related to the position. Relevant experience must be in two or more of the following: designing/implementing machine learning, data mining, advanced analytical algorithms, programming, data science, advanced statistical analysis, artificial intelligence, computational science, software engineering, or data engineering.

Education

Degree must be in Mathematics, Applied Mathematics, Statistics, Applied Statistics, Machine Learning, Data Science, Operations Research, or Computer Science. A degree in a related field (e.g., Computer Information Systems, Engineering), a degree in the physical/hard sciences (e.g. physics, chemistry, biology, astronomy), or other science disciplines (i.e., behavioral, social, library, and life) may be considered if it includes a concentration of coursework (typically 5 or more courses) in advanced mathematics (typically 200 level or higher; such as calculus, differential equations, discrete mathematics, linear algebra, and calculus based statistics) and/or computer science (e.g., algorithms, programming, data structures, data mining, artificial intelligence). College-level Algebra or other math courses intended to meet a basic college level requirement, or upper level math courses designated as elementary or basic do not count.

Note: Degrees in related fields will be considered if accompanied by a Certificate in Data Science from an accredited college/university.

Additional information

Pay: Salary offers are based on candidates' education level and years of experience relevant to the position and also take into account information provided by the hiring manager/organization regarding the work level for the position.

Salary Range: $86,498 - $151,570 (Entry/Developmental, Full Performance)
Salary range varies by location, work level, and relevant experience to the position.

Training will be provided based on the selectee's needs and experience.

Benefits:
NSA offers a comprehensive benefits package. Work Schedule: This is a full-time position, Monday - Friday, with basic 8hr/day work requirement between 6:00 a.m. and 6:00 p.m. (flexible).",2025-07-21T00:00:00.000Z,2025-07-25,"['Employment is contingent upon successful completion of a security background investigation and polygraph', 'The qualifications listed are the minimum acceptable to be considered for the position', 'Applicants who meet minimum qualifications may be asked to complete the Data Science Examination (DSE) evaluating their knowledge of statistics, mathematics, and computer science topics that pertain to data science work', 'Passing this examination is a requirement in order to be considered for selection into a data scientist position', 'Degree must be in Mathematics, Applied Mathematics, Statistics, Applied Statistics, Machine Learning, Data Science, Operations Research, or Computer Science', 'A degree in a related field (e.g., Computer Information Systems, Engineering), a degree in the physical/hard sciences (e.g. physics, chemistry, biology, astronomy), or other science disciplines (i.e., behavioral, social, library, and life) may be considered if it includes a concentration of coursework (typically 5 or more courses) in advanced mathematics (typically 200 level or higher; such as calculus, differential equations, discrete mathematics, linear algebra, and calculus based statistics) and/or computer science (e.g., algorithms, programming, data structures, data mining, artificial intelligence)', 'College-level Algebra or other math courses intended to meet a basic college level requirement, or upper level math courses designated as elementary or basic do not count', 'Note: Degrees in related fields will be considered if accompanied by a Certificate in Data Science from an accredited college/university', ""Entry is with a Bachelor's degree and no experience"", ""An Associate's degree plus 2 years of relevant experience may be considered for individuals with in-depth experience that is clearly related to the position"", 'Relevant experience must be in one or more of the following: designing/implementing machine learning, data mining, advanced analytical algorithms, programming, data science, advanced statistical analysis, artificial intelligence, computational science, software engineering, or data engineering', ""Entry is with a Bachelor's degree plus 3 years of relevant experience or a Master's degree plus 1 year of relevant experience or a Doctoral degree and no experience"", ""An Associate's degree plus 5 years of relevant experience may be considered for individuals with in-depth experience that is clearly related to the position"", 'Relevant experience must be in two or more of the following: designing/implementing machine learning, data mining, advanced analytical algorithms, programming, data science, advanced statistical analysis, artificial intelligence, computational science, software engineering, or data engineering', 'Degree must be in Mathematics, Applied Mathematics, Statistics, Applied Statistics, Machine Learning, Data Science, Operations Research, or Computer Science', 'A degree in a related field (e.g., Computer Information Systems, Engineering), a degree in the physical/hard sciences (e.g. physics, chemistry, biology, astronomy), or other science disciplines (i.e., behavioral, social, library, and life) may be considered if it includes a concentration of coursework (typically 5 or more courses) in advanced mathematics (typically 200 level or higher; such as calculus, differential equations, discrete mathematics, linear algebra, and calculus based statistics) and/or computer science (e.g., algorithms, programming, data structures, data mining, artificial intelligence)', 'College-level Algebra or other math courses intended to meet a basic college level requirement, or upper level math courses designated as elementary or basic do not count', 'Note: Degrees in related fields will be considered if accompanied by a Certificate in Data Science from an accredited college/university', ""Training will be provided based on the selectee's needs and experience""]","['It encompasses AI Engineering, Data Engineering, ML Ops Engineering, and Human Perception and Cognition Engineering in addition to the traditional applications of data science', ""You will employ your mathematical science, computer science, and quantitative analysis skills to develop solutions to complex data problems and take full advantage of NSA's capabilities to tackle the highest priority foreign intelligence and cybersecurity challenges"", 'Exploratory data analysis and exploratory model-fitting to reveal data features of interest', 'Machine-learned predictive modeling', 'Identifying and analyzing anomalous data (including metadata)', 'Lead or contribute to cross-functional teams to develop and implement Al (including generative AI) that can help solve some of our most challenging problems', 'Apply modern engineering techniques to develop decision support software prototypes', 'Propose and execute novel, cutting-edge research in Al-enhanced decision systems', 'Designing and developing analytics and techniques for analysis', 'Analyzing data using mathematical and statistical methods', 'Implement ML pipeline and workflows', 'Leverage skills in modern data architecture, cloud engineering, data transformation, and management of structured and unstructured data sources', 'Build continuous integration and delivery pipelines for ML applications', 'Construct usable data sets from multiple sources to meet customer needs', 'Developing conceptual design and models to address mission requirements', 'Developing qualitative and quantitative methods for characterizing datasets in various states', 'Performing analytic modeling, scripting, and/or programming', 'Working collaboratively and iteratively throughout the data-science lifecycle', 'Communicate with a team of data scientists, data engineers, AI engineers, ML-Ops engineers, and stakeholders', 'Evaluating, documenting, and communicating research processes, analyses, and results to customers, peers, and leadership', 'Creating interpretable visualizations', 'Work with mission owners to design, develop, and deploy new architectures for ML and automation applications such as ELT functions, HPC/compute infrastructure, AWS/Azure solutions, database solutions, and optimization of DevOps procedures']",True,"['Generative AI', 'AI-Enhanced Decision Systems', 'AI Engineering']",Generative AI: Leading or contributing to teams developing and implementing generative AI solutions to address challenging problems.; AI-Enhanced Decision Systems: Proposing and executing novel research in AI-enhanced decision support systems to improve mission outcomes.; AI Engineering: Engaging in AI engineering practices as part of the multidisciplinary data science team to develop AI-driven solutions.,"['Exploratory Data Analysis', 'Machine-learned Predictive Modeling', 'Anomaly Detection', 'Mathematical and Statistical Methods', 'ML Pipelines and Workflows', 'Data Architecture and Cloud Engineering', 'Continuous Integration and Delivery for ML', 'Data Integration and ETL (Extract, Transform, Load)', 'Analytic Modeling and Programming', 'Data Visualization', 'Advanced Mathematics and Computer Science', 'Data Mining and Advanced Analytical Algorithms', 'Data Science Lifecycle Collaboration', 'High-Performance Computing (HPC)']","Exploratory Data Analysis: Used to reveal data features of interest through initial investigation and model-fitting.; Machine-learned Predictive Modeling: Developing predictive models using machine learning techniques to solve complex data problems.; Anomaly Detection: Identifying and analyzing anomalous data, including metadata, to detect irregularities.; Mathematical and Statistical Methods: Applying mathematical science, statistics, and quantitative analysis to analyze data and develop solutions.; ML Pipelines and Workflows: Implementing machine learning pipelines and workflows to operationalize models and data processes.; Data Architecture and Cloud Engineering: Leveraging modern data architecture and cloud platforms such as AWS and Azure for data transformation and management of structured and unstructured data.; Continuous Integration and Delivery for ML: Building CI/CD pipelines specifically for machine learning applications to enable automated deployment and updates.; Data Integration and ETL (Extract, Transform, Load): Constructing usable datasets from multiple sources and developing ELT functions to meet customer needs.; Analytic Modeling and Programming: Performing analytic modeling, scripting, and programming to develop data-driven solutions.; Data Visualization: Creating interpretable visualizations to communicate data insights effectively to stakeholders.; Advanced Mathematics and Computer Science: Utilizing advanced coursework in calculus, differential equations, linear algebra, algorithms, programming, data structures, and data mining as foundational knowledge for data science tasks.; Data Mining and Advanced Analytical Algorithms: Designing and implementing data mining techniques and advanced analytical algorithms to extract insights from data.; Data Science Lifecycle Collaboration: Working collaboratively and iteratively throughout the data science lifecycle with cross-functional teams including data scientists, data engineers, and ML-Ops engineers.; High-Performance Computing (HPC): Utilizing HPC infrastructure to support compute-intensive data science and machine learning workloads."
3BV0mxleNgf3IRb0AAAAAA==,Data Scientist- TS Clearance Jobs,"This position requires an active Top Secret Clearance. Candidates who do not hold this clearance are not eligible for hire.

Solidus is searching for a Data Scientist. This position is on- site at Tyson's, VA..

Day in the life:
• MLOps, Model Engineering, Training on time series data
• After few weeks training on Customer's AI platform, develop AI-based applications using Customer's platform for operational cloud-deployed and secure lab deployed AI-based applications
• Develop candidate models that are promoted to active models when their performance meets threshold
• Train, validate and deploy machine learning pipelines
• Test, troubleshoot, and enhance customer AI-based applications based on feedback
• Manage individual project deliverables
• Identify application performance bottlenecks and implement optimizations
• Write application specifications and documentation
• Articulate methodologies, experiments, and findings clearly in actionable way
• Work in a fast-paced environment
Required Qualifications:
• US Citizen with an active Top Secret Clearance
• Undergo a comprehensive background investigation
• Bachelor's degree in a Science, Technology, Engineering or Mathematics (STEM), or comparable area of study. No experience in lieu of
• 5+ years of Data Science development experience using Python
• Proficiency in data science, machine learning, and analytics, including statistical data analysis, model and feature evaluations
• Strong proficiency in numpy & pandas
• Demonstrated skills with Jupyter Notebook or comparable environments
• Practical experience in solving complex problems in an applied environment, and proficiency in critical thinking

Important Note:
• This is NOT a data analytics role using Tableau or PowerBI.
• This is NOT an ETL & SQL role.

• This is NOT a R&D role prototyping at low TRL.

Preferred Qualifications:
• Degree in Data Science, Machine Learning, Computer Science, Engineering, Statistics, or equivalent fields
• Strong mathematical background (linear algebra, calculus, probability & statistics)
• Experience with machine learning model training and analysis through open-source frameworks (Pytorch, Tensorflow, Sklearn)
• Experience crafting, conducting, analyzing, and interpreting experiments and investigations.
• Experience with modern software development tools and practices (Git, pull requests)
• Experience analyzing model performance with relevant metrics and optimizing.
• Familiarity with AI agent frameworks
• Ability to drive a project and work both independently and in a team
• Smart, motivated, can do attitude, and seeks to make a difference
• Excellent communication and collaboration skills, particularly in multidisciplinary teams with data scientists, software engineers, product owners, & solution architects.
• TS/SCI with Polygraph preferred

What we will bring:
Solidus offers you an exciting opportunity to tackle the nation's greatest challenges applying innovation and expertise to produce cutting-edge results that have a long-lasting impact. We offer outstanding benefits, including comprehensive health, vision, and dental insurance, generous PTO, and much more! Apply today to learn why Solidus has a 4.9/5 Star rating on Glassdoor!

Benefit selection, customer contractual specifications, relevant work experience, skills, competencies, certifications, and clearance status will influence the final salary.
Full benefits: $98,000 to $153,000 annually
Reduced benefits (no medical, dental, vision): Up to $165,000 annually

Req ID: 4959

Solidus is an Equal Opportunity Employer and provides equal employment opportunities regarding all terms and conditions of employment to all employees and qualified applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. The Company will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application and interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request an accommodation.

Federal Job Notices for Job Applicants

Please Note: Solidus does not accept applications from agencies, 3rd party vendors, or applications with incomplete information.",2025-07-25T00:00:00.000Z,2025-07-25,"['US Citizen with an active Top Secret Clearance', 'Undergo a comprehensive background investigation', ""Bachelor's degree in a Science, Technology, Engineering or Mathematics (STEM), or comparable area of study"", 'No experience in lieu of', '5+ years of Data Science development experience using Python', 'Proficiency in data science, machine learning, and analytics, including statistical data analysis, model and feature evaluations', 'Strong proficiency in numpy & pandas', 'Demonstrated skills with Jupyter Notebook or comparable environments', 'Practical experience in solving complex problems in an applied environment, and proficiency in critical thinking', 'This is NOT a data analytics role using Tableau or PowerBI', 'This is NOT an ETL & SQL role', 'This is NOT a R&D role prototyping at low TRL']","['MLOps, Model Engineering, Training on time series data', ""After few weeks training on Customer's AI platform, develop AI-based applications using Customer's platform for operational cloud-deployed and secure lab deployed AI-based applications"", 'Develop candidate models that are promoted to active models when their performance meets threshold', 'Train, validate and deploy machine learning pipelines', 'Test, troubleshoot, and enhance customer AI-based applications based on feedback', 'Manage individual project deliverables', 'Identify application performance bottlenecks and implement optimizations', 'Write application specifications and documentation', 'Articulate methodologies, experiments, and findings clearly in actionable way', 'Work in a fast-paced environment']",True,"['AI Platforms', 'AI Agent Frameworks', 'Deep Learning Frameworks']","AI Platforms: Developing AI-based applications using a customer-specific AI platform for operational deployment in cloud and secure lab environments.; AI Agent Frameworks: Familiarity with frameworks that support AI agents, indicating involvement with AI-native systems or architectures beyond traditional machine learning.; Deep Learning Frameworks: Experience with open-source deep learning frameworks such as PyTorch and TensorFlow for model training and analysis.","['MLOps', 'Time Series Modeling', 'Machine Learning Model Training', 'Python Data Science Libraries', 'Jupyter Notebook', 'Statistical Data Analysis', 'Machine Learning Pipelines', 'Model Performance Optimization']","MLOps: Managing machine learning pipelines including training, validation, deployment, and operationalization of models on cloud and secure lab environments.; Time Series Modeling: Training and engineering models specifically on time series data as part of the machine learning workflow.; Machine Learning Model Training: Developing candidate models, training them, evaluating performance, and promoting models to active status when performance thresholds are met.; Python Data Science Libraries: Using Python libraries such as numpy and pandas for data manipulation and analysis in data science development.; Jupyter Notebook: Utilizing Jupyter Notebook or comparable interactive environments for developing and documenting data science workflows.; Statistical Data Analysis: Applying statistical methods for data analysis, model evaluation, and feature evaluation within machine learning projects.; Machine Learning Pipelines: Building, training, validating, deploying, and troubleshooting end-to-end machine learning pipelines.; Model Performance Optimization: Analyzing model performance metrics and implementing optimizations to improve application performance and model accuracy."
hjhpBIewfePGk7gFAAAAAA==,"Part time - Principal Data Scientist at Davita Inc. Mc Lean, VA","Part time - Principal Data Scientist job at Davita Inc.. Mc Lean, VA.

Overview

Principal Data Scientist

Data Scientist - Community Impact and Investment Team

Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making.

As a Data Scientist at Capital One, you'll be part of a team that's leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and reduce stress in their financial lives.

Team Description
The Community Impact and Investment team develops tools and insights to support our philanthropic investment and product decisions with data-driven understanding of the communities we serve. In addition to internal decision-making, we conduct research on community impact topics that often lead to externally published articles. Our team is constantly exploring creative approaches using secondary data sources to generate meaningful insights on relevant community impact issues.

Responsibilities
Partner with a cross-functional team of data scientists, software engineers, and business leaders to develop insights that drive community investments and financial well-being.
Leverage a broad stack of technologies—Python, R, Conda, AWS, H2O, Spark, and more—to collect, clean, and analyze data from diverse sources.
Develop and validate causal inference models to assess the social impact of internal community initiatives and relevant public programs.
Solve data challenges creatively by sourcing and integrating alternative datasets, including government reports, survey data, and financial transaction data.
Translate complex findings into clear, actionable recommendations for internal stakeholders and external partners.

The Ideal Candidate is:
Mission-Driven: Passionate about leveraging data to make a positive social impact and believe in using insights to drive better decision-making.
Innovative: Stay on top of the latest research in causal inference, machine learning, and data collection methodologies—and love applying them to real-world problems.
Creative: Thrive in ambiguity, enjoy tackling undefined problems, and love finding novel data sources to enrich analysis.
Statistically-Minded: Experience with causal inference methods (RCTs, regression discontinuity, propensity score matching, difference-in-differences) and interpreting results from statistical models.
Technical: Proficient in R and Python, comfortable working with large-scale datasets in cloud environments like AWS.
Data Guru: Skilled in retrieving, combining, and analyzing structured and unstructured data from various sources.

Basic Qualifications:
Bachelor's Degree plus 5 years of experience in data analytics, or Master's Degree plus 3 years, or PhD in a quantitative field.
At least 1 year of experience with open-source programming languages for large-scale data analysis.
At least 1 year of experience with machine learning.
At least 1 year of experience with research or data analysis.
At least 1 year of experience with relational databases.

Preferred Qualifications:
Master's Degree in STEM field plus 3 years of experience in data analytics, or PhD in STEM.
At least 1 year of experience working with AWS.
At least 3 years of experience in R, Python, or Scala.
At least 3 years of experience with machine learning.
At least 3 years of experience with SQL.

Salary and Benefits
The minimum and maximum full-time annual salaries for this role are listed below, by location. Salaries for part-time roles will be prorated based on hours worked.
McLean, VA (Hybrid): $158,600 - $181,000
Chicago, IL (Hybrid): $153,900 - $188,500
Other locations will have different pay ranges. This role is eligible for performance-based incentives, including bonuses and long-term incentives.
Capital One offers comprehensive benefits supporting total well-being. Learn more at the Capital One Careers website.
Additional Information This role is open for applications for at least 5 business days. No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion. For accommodations during the application process, contact Recruiting at 1-800-304-9102 or RecruitingAccommodation@capitalone.com. For technical support, email Careers@capitalone.com.

#J-18808-Ljbffr Davita Inc.",2025-07-16T00:00:00.000Z,2025-07-25,"['Mission-Driven: Passionate about leveraging data to make a positive social impact and believe in using insights to drive better decision-making', 'Innovative: Stay on top of the latest research in causal inference, machine learning, and data collection methodologies—and love applying them to real-world problems', 'Statistically-Minded: Experience with causal inference methods (RCTs, regression discontinuity, propensity score matching, difference-in-differences) and interpreting results from statistical models', 'Technical: Proficient in R and Python, comfortable working with large-scale datasets in cloud environments like AWS', 'Data Guru: Skilled in retrieving, combining, and analyzing structured and unstructured data from various sources', ""Bachelor's Degree plus 5 years of experience in data analytics, or Master's Degree plus 3 years, or PhD in a quantitative field"", 'At least 1 year of experience with open-source programming languages for large-scale data analysis', 'At least 1 year of experience with machine learning', 'At least 1 year of experience with research or data analysis', 'At least 1 year of experience with relational databases', ""Master's Degree in STEM field plus 3 years of experience in data analytics, or PhD in STEM"", 'At least 1 year of experience working with AWS', 'At least 3 years of experience in R, Python, or Scala', 'At least 3 years of experience with machine learning', 'At least 3 years of experience with SQL']","['Partner with a cross-functional team of data scientists, software engineers, and business leaders to develop insights that drive community investments and financial well-being', 'Leverage a broad stack of technologies—Python, R, Conda, AWS, H2O, Spark, and more—to collect, clean, and analyze data from diverse sources', 'Develop and validate causal inference models to assess the social impact of internal community initiatives and relevant public programs', 'Solve data challenges creatively by sourcing and integrating alternative datasets, including government reports, survey data, and financial transaction data', 'Translate complex findings into clear, actionable recommendations for internal stakeholders and external partners', 'Creative: Thrive in ambiguity, enjoy tackling undefined problems, and love finding novel data sources to enrich analysis']",True,[],,"['Causal Inference Methods', 'Python', 'R', 'SQL', 'Machine Learning', 'Data Integration', 'Statistical Modeling', 'AWS Cloud Environment', 'H2O', 'Spark', 'Conda']","Causal Inference Methods: Used to develop and validate models assessing the social impact of community initiatives and public programs, including techniques such as randomized controlled trials (RCTs), regression discontinuity, propensity score matching, and difference-in-differences.; Python: Utilized as a primary programming language for collecting, cleaning, and analyzing large-scale datasets from diverse sources in cloud environments.; R: Used alongside Python for data analysis, statistical modeling, and working with large-scale datasets in cloud environments.; SQL: Applied for querying and managing relational databases to retrieve and combine structured data for analysis.; Machine Learning: Employed to develop predictive models and analyze data, with experience required for applying machine learning techniques to real-world problems.; Data Integration: Involves sourcing and combining alternative datasets such as government reports, survey data, and financial transaction data to enrich analysis and solve data challenges creatively.; Statistical Modeling: Used to interpret results from causal inference methods and generate actionable insights for decision-making.; AWS Cloud Environment: Provides the cloud infrastructure to handle large-scale data storage, processing, and analysis tasks.; H2O: Part of the technology stack leveraged for scalable machine learning and data analysis.; Spark: Used for big data processing and analytics to handle large datasets efficiently.; Conda: Utilized as an environment and package management system to support data science workflows in Python and R."
jnQ35lpZQpqxX-EJAAAAAA==,Data Scientist Jobs,"Paradyme, a CATHEXIS Company is hiring a Data Scientist /ML Engineer to support mission critical programs.

Responsibilities:

The Data Scientist /ML Engineer will work directly with data scientists, software engineers, and subject matter experts in the definition of new analytics capabilities able to provide our federal customers with the information they need to make proper decisions and enable their digital transformation. Duties include:

- Research, design, implement, and deploy Machine Learning algorithms for enterprise applications.

- Assist and enable federal customers to build their own applications.

- Contribute to the design and implementation of new features.

Qualifications:

- Master's degree in Computer Science, Electrical Engineering, Statistics, or equivalent fields or Bachelor's degree in Computer Science, Electrical Engineering, Statistics, or equivalent fields with one year of relevant work experience.

- Excellent programming skills in Python.

- Applied Machine Learning experience (regression and classification, supervised, and unsupervised learning).

- Strong mathematical background (linear algebra, calculus, probability, and statistics).

- Experience with scalable ML (MapReduce, streaming).

- Ability to drive a project and work both independently and in a team.

- Smart, motivated, can-do attitude, and seeks to make a difference.

- Excellent verbal and written communication.

- Ability to obtain a U.S. security clearance preferred.

Nice to Have:

- MS or PhD in Computer Science, Electrical Engineering, Statistics, or equivalent fields.

- Real passion for developing team-oriented solutions to complex engineering problems.

- Thrive in an autonomous, empowering and exciting environment.

- Great verbal and written communication skills to collaborate multi-functionally and improve scalability.

- Interest in committing to a fun, friendly, expansive, and intellectually stimulating environment.

- Hands-on experience deploying and operating applications using IaaS and PaaS on major cloud providers, such as Amazon AWS, Microsoft Azure, or Google Cloud Services.

- Experience with deep learning, natural language processing, computer vision, or reinforcement learning.

- Conveys highly technical concepts and information in written form to technical and non-technical audiences.

- The ability to work on multiple concurrent projects is essential. Strong self -motivation and the ability to work with minimal supervision.

- Must be a team-oriented individual, energetic, result & delivery oriented, with a keen interest on quality and the ability to meet deadlines.

- Ability to work in an agile environment",2025-07-24T00:00:00.000Z,2025-07-25,"[""Master's degree in Computer Science, Electrical Engineering, Statistics, or equivalent fields or Bachelor's degree in Computer Science, Electrical Engineering, Statistics, or equivalent fields with one year of relevant work experience"", 'Excellent programming skills in Python', 'Applied Machine Learning experience (regression and classification, supervised, and unsupervised learning)', 'Strong mathematical background (linear algebra, calculus, probability, and statistics)', 'Experience with scalable ML (MapReduce, streaming)', 'Ability to drive a project and work both independently and in a team', 'Smart, motivated, can-do attitude, and seeks to make a difference', 'Excellent verbal and written communication', 'MS or PhD in Computer Science, Electrical Engineering, Statistics, or equivalent fields', 'Real passion for developing team-oriented solutions to complex engineering problems', 'Thrive in an autonomous, empowering and exciting environment', 'Great verbal and written communication skills to collaborate multi-functionally and improve scalability', 'Interest in committing to a fun, friendly, expansive, and intellectually stimulating environment', 'Hands-on experience deploying and operating applications using IaaS and PaaS on major cloud providers, such as Amazon AWS, Microsoft Azure, or Google Cloud Services', 'Experience with deep learning, natural language processing, computer vision, or reinforcement learning', 'Conveys highly technical concepts and information in written form to technical and non-technical audiences', 'The ability to work on multiple concurrent projects is essential', 'Strong self -motivation and the ability to work with minimal supervision', 'Must be a team-oriented individual, energetic, result & delivery oriented, with a keen interest on quality and the ability to meet deadlines', 'Ability to work in an agile environment']","['The Data Scientist /ML Engineer will work directly with data scientists, software engineers, and subject matter experts in the definition of new analytics capabilities able to provide our federal customers with the information they need to make proper decisions and enable their digital transformation', 'Research, design, implement, and deploy Machine Learning algorithms for enterprise applications', 'Assist and enable federal customers to build their own applications', 'Contribute to the design and implementation of new features']",True,"['Deep Learning', 'Natural Language Processing', 'Computer Vision', 'Reinforcement Learning']","Deep Learning: Experience with deep learning techniques is desirable, indicating the use of neural networks for complex data modeling tasks.; Natural Language Processing: Knowledge of natural language processing is preferred, suggesting involvement with text data and language understanding models.; Computer Vision: Experience with computer vision is a plus, implying work with image or video data using AI techniques.; Reinforcement Learning: Familiarity with reinforcement learning is mentioned as a nice-to-have skill, indicating potential work with AI models that learn via interaction with environments.","['Machine Learning', 'Python Programming', 'Mathematics for Data Science', 'Scalable Machine Learning', 'Data Analytics Capabilities', 'Cloud Computing for Data Applications']","Machine Learning: The job involves researching, designing, implementing, and deploying machine learning algorithms for enterprise applications, including regression and classification models, supervised and unsupervised learning methods.; Python Programming: Excellent programming skills in Python are required to develop and deploy machine learning and data analytics solutions.; Mathematics for Data Science: A strong mathematical background in linear algebra, calculus, probability, and statistics is essential to support the development and understanding of machine learning models.; Scalable Machine Learning: Experience with scalable machine learning techniques such as MapReduce and streaming is needed to handle large-scale data processing and model deployment.; Data Analytics Capabilities: The role includes defining new analytics capabilities to provide federal customers with actionable information for decision-making and digital transformation.; Cloud Computing for Data Applications: Hands-on experience deploying and operating applications using Infrastructure as a Service (IaaS) and Platform as a Service (PaaS) on major cloud providers like Amazon AWS, Microsoft Azure, or Google Cloud Services is considered a valuable skill."
KoxF5LmD7llmq8RcAAAAAA==,Data Scientist - TS/SCI w/Poly Jobs,"The Data Scientist will deploy, fine-tune, and monitor production machine learning models in a production environment. Additionally, they will provide support in the areas of data extraction, transformation and load (ETL), data mapping, analytics, operations, databases, and maintenance of data and associated systems. As a member of the team, candidate will work in a multi-tasking, quick-paced, dynamic, process-improvement environment that requires experience with the principles of data science, data modeling, data mapping, data testing, data quality, and documentation preparation. This is a mission focused role requiring experience with deploying models in a production environment against real-time collection.

HOW A DATA SCIENTIST WILL MAKE AN IMPACT:
• Create and maintain custody of production machine learning models across a variety of tasks, including but not limited to audio extraction, object recognition, Natural Language Processing (NLP), and other generic classification tasks
• Optimize existing machine learning services to better utilize current GPU capabilities and assist with road mapping future GPU requirements
• Deploy machine learning models against streaming data, designed to provide near-real time analytics to augment decision making
• Improve data architecture decisions with data engineers to better stage data for continuous training models in production
• Provide support in the areas of data extraction, transformation and load (ETL), data mapping, analytics, operations, databases, and maintenance of data and associated systems

REQUIRED TECHNICAL SKILLS:
• Demonstrated experience with the following: Python, Cuda, Kubernetes, CI/CD. Apache Kafka, REST architecture, Open-AI, LLMs, NLP, YOLO/Object Recognition, Whisper/Audio processing
• Demonstrated experience translating data insights into tools or analytic capabilities that inform operational decisions and/or improve processes
• Demonstrated experience with relational databases (SQL, Oracle) and NoSQL databases (Elasticsearch, Neo4J, Redis)
• Demonstrated experience with GPU processing
• Demonstrated experience applying machine learning methodologies to build high-quality prediction models
• Familiar with servers operating systems; Windows, Linux, Distributed Computing, Blade Centers, and cloud infrastructure
• Familiar with database methodologies
• Familiar with Source code management and integration (ex - GitHub/GitLab, Jenkins, RunDeck)
• Familiar with Data Science frameworks such as Keras, Tensorflow, or Theano
• Ability to work well in a fast-paced, constantly evolving work environment with a focus on continual process improvement and a proactive approach to problem solving

WHAT YOU'LL NEED TO SUCCEED:
• The position requires an active TS/SCI with Polygraph security clearance
• The position requires fifteen (15+) years of related data science/statistical experience and three (3+) years of software engineering or data engineering experience
• The position requires Bachelor's or Technology degree in Engineering or a related specialized area/field, OR equivalent four (4) additional years job-related experience
• Excellent organizational, coordination, interpersonal and team building skills
• The position is on customer site

GDIT IS YOUR PLACE:
• 401K with company match
• Comprehensive health and wellness packages
• Internal mobility team dedicated to helping you own your career
• Professional growth opportunities including paid education and certifications
• Cutting-edge technology you can learn from
• Rest and recharge with paid vacation and holidays

#OpportunityOwned

#GDITCareers

#WeAreGDIT

#JET

#GDITEnhanced2025

Work Requirements",2025-07-25T17:00:00.000Z,2025-07-25,"['Demonstrated experience with the following: Python, Cuda, Kubernetes, CI/CD', 'Apache Kafka, REST architecture, Open-AI, LLMs, NLP, YOLO/Object Recognition, Whisper/Audio processing', 'Demonstrated experience translating data insights into tools or analytic capabilities that inform operational decisions and/or improve processes', 'Demonstrated experience with relational databases (SQL, Oracle) and NoSQL databases (Elasticsearch, Neo4J, Redis)', 'Demonstrated experience with GPU processing', 'Demonstrated experience applying machine learning methodologies to build high-quality prediction models', 'Familiar with servers operating systems; Windows, Linux, Distributed Computing, Blade Centers, and cloud infrastructure', 'Familiar with database methodologies', 'Familiar with Source code management and integration (ex - GitHub/GitLab, Jenkins, RunDeck)', 'Familiar with Data Science frameworks such as Keras, Tensorflow, or Theano', 'Ability to work well in a fast-paced, constantly evolving work environment with a focus on continual process improvement and a proactive approach to problem solving', 'The position requires an active TS/SCI with Polygraph security clearance', 'The position requires fifteen (15+) years of related data science/statistical experience and three (3+) years of software engineering or data engineering experience', ""The position requires Bachelor's or Technology degree in Engineering or a related specialized area/field, OR equivalent four (4) additional years job-related experience"", 'Excellent organizational, coordination, interpersonal and team building skills', 'The position is on customer site']","['The Data Scientist will deploy, fine-tune, and monitor production machine learning models in a production environment', 'Additionally, they will provide support in the areas of data extraction, transformation and load (ETL), data mapping, analytics, operations, databases, and maintenance of data and associated systems', 'As a member of the team, candidate will work in a multi-tasking, quick-paced, dynamic, process-improvement environment that requires experience with the principles of data science, data modeling, data mapping, data testing, data quality, and documentation preparation', 'This is a mission focused role requiring experience with deploying models in a production environment against real-time collection', 'Create and maintain custody of production machine learning models across a variety of tasks, including but not limited to audio extraction, object recognition, Natural Language Processing (NLP), and other generic classification tasks', 'Optimize existing machine learning services to better utilize current GPU capabilities and assist with road mapping future GPU requirements', 'Deploy machine learning models against streaming data, designed to provide near-real time analytics to augment decision making', 'Improve data architecture decisions with data engineers to better stage data for continuous training models in production', 'Provide support in the areas of data extraction, transformation and load (ETL), data mapping, analytics, operations, databases, and maintenance of data and associated systems']",True,"['Large Language Models', 'Natural Language Processing', 'Generative AI Frameworks', 'Computer Vision Models', 'Audio Processing Models', 'CUDA and GPU-Accelerated AI', 'Kubernetes for AI Deployment']",Large Language Models: Experience deploying and fine-tuning large language models (LLMs) and applying NLP techniques in production environments.; Natural Language Processing: Use of NLP techniques as part of machine learning tasks including audio extraction and classification.; Generative AI Frameworks: Familiarity with OpenAI technologies and frameworks related to generative AI.; Computer Vision Models: Experience with object recognition models such as YOLO for image and video analysis.; Audio Processing Models: Use of audio processing models such as Whisper for extracting and analyzing audio data.; CUDA and GPU-Accelerated AI: Utilize CUDA for GPU-accelerated processing to optimize machine learning and AI model performance.; Kubernetes for AI Deployment: Use Kubernetes for container orchestration to deploy and manage AI and machine learning models in production.,"['Machine Learning Models', 'Data Extraction, Transformation, and Load (ETL)', 'Data Mapping', 'Data Analytics', 'Relational and NoSQL Databases', 'GPU Processing', 'Data Science Frameworks', 'Data Modeling and Data Quality', 'Streaming Data Analytics', 'Source Code Management and CI/CD', 'Distributed Computing and Cloud Infrastructure', 'Data Operations and Maintenance']","Machine Learning Models: Deploy, fine-tune, monitor, and optimize production machine learning models for tasks such as audio extraction, object recognition, NLP, and classification, including applying machine learning methodologies to build high-quality prediction models.; Data Extraction, Transformation, and Load (ETL): Provide support in data extraction, transformation, and load processes to maintain and operate data and associated systems.; Data Mapping: Experience with data mapping to support data quality, testing, and documentation preparation in a dynamic, process-improvement environment.; Data Analytics: Translate data insights into tools or analytic capabilities that inform operational decisions and improve processes, including providing near-real time analytics from streaming data to augment decision making.; Relational and NoSQL Databases: Demonstrated experience with relational databases such as SQL and Oracle, and NoSQL databases including Elasticsearch, Neo4J, and Redis.; GPU Processing: Optimize machine learning services to better utilize GPU capabilities and assist with planning future GPU requirements.; Data Science Frameworks: Familiarity with data science frameworks such as Keras, TensorFlow, and Theano for building and deploying models.; Data Modeling and Data Quality: Apply principles of data science including data modeling, data testing, and ensuring data quality in production environments.; Streaming Data Analytics: Deploy machine learning models against streaming data to provide near-real time analytics for decision support.; Source Code Management and CI/CD: Familiarity with source code management and integration tools such as GitHub/GitLab, Jenkins, and RunDeck, and continuous integration/continuous deployment (CI/CD) pipelines.; Distributed Computing and Cloud Infrastructure: Experience with server operating systems (Windows, Linux), distributed computing environments, blade centers, and cloud infrastructure.; Data Operations and Maintenance: Support operations, maintenance, and management of data and associated systems in a production environment."
qysGugpRKcn6GQU8AAAAAA==,Data Analyst Jobs,"Title
Data Analyst
Full-Time/Part-Time Full-Time Description
Cyber Intelligence Alliance (CIA) Joint Venture (JV) is seeking a Data Analyst (contingent upon award) to support federal client in supporting analysis of military operational data to identify trends, patterns and anomalies that can inform strategic decision-making. Activities and support includes preprocessing large datasets related to Army operations, logistics, personnel and intelligence for analysis. Tasks include conducting statistical analysis and data modeling to assess combat effectiveness, force readiness, and mission performance as well as developing dashboards and reports to visualize key performance indicators and metrics for leadership. Candidate will utilize machine learning algorithms for predictive modeling in areas such as threat assessment and risk analysis.
• Candidate shall possess skills and expertise in machine learning tools to select features, create, and optimize classifiers.
• Candidate shall possess demonstrable collegiate-level writing skills, demonstrated familiarity with the U.S. Army organization and regulations, and strong organization and communication skills.
• Candidate shall have the ability to communicate complex technical findings to a variety of audiences.
• Candidate shall possess demonstrate practical experience substantiating equivalent skills such as Structured Query Language, Microsoft Excel, R or Python statistical programming, Data Visualization, and Presentation Skills.
Requirements for this position shall include:
• Bachelor's degree or higher in a related field of study or equivalent experience
• Minimum of three (3) years of experience, one within DoD, working with big-data systems and developing production-level data models
• Secret Security Clearance Required
• Prior knowledge of Power BI, Tableau and Advana data science is preferred.
About the Organization Established in 2008, RiVidium, Inc. (dba TripleCyber) is a VA-Verified SDVOSB and an SBA-Certified 8(a) company. To prepare our clients for the future, RiVidium has balanced all parts of our organization to attract the finest employees in order to 'Strive to be the missing element defining tomorrow's technology'. RiVidium keeps pace and surpasses its competitors by meeting challenges of advancements in Logistics, Human Capital, Cyber, Intelligence & Technology. EOE Statement We are an equal employment opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status or any other characteristic protected by law. If you need a reasonable accommodation for any part of the employment process, please contact Human Resources (HR) at hr@rividium.com.
This position is currently accepting applications.",2025-07-25T00:00:00.000Z,2025-07-25,"['Candidate shall possess skills and expertise in machine learning tools to select features, create, and optimize classifiers', 'Candidate shall possess demonstrable collegiate-level writing skills, demonstrated familiarity with the U.S. Army organization and regulations, and strong organization and communication skills', 'Candidate shall have the ability to communicate complex technical findings to a variety of audiences', 'Candidate shall possess demonstrate practical experience substantiating equivalent skills such as Structured Query Language, Microsoft Excel, R or Python statistical programming, Data Visualization, and Presentation Skills', ""Bachelor's degree or higher in a related field of study or equivalent experience"", 'Minimum of three (3) years of experience, one within DoD, working with big-data systems and developing production-level data models', 'Secret Security Clearance Required', 'About the Organization Established in 2008, RiVidium, Inc']","['Activities and support includes preprocessing large datasets related to Army operations, logistics, personnel and intelligence for analysis', 'Tasks include conducting statistical analysis and data modeling to assess combat effectiveness, force readiness, and mission performance as well as developing dashboards and reports to visualize key performance indicators and metrics for leadership', 'Candidate will utilize machine learning algorithms for predictive modeling in areas such as threat assessment and risk analysis']",True,[],,"['Machine Learning', 'Statistical Analysis', 'Data Modeling', 'Data Preprocessing', 'SQL', 'Python', 'R', 'Data Visualization', 'Power BI', 'Tableau', 'Big Data Systems']","Machine Learning: Used for predictive modeling in threat assessment and risk analysis, including feature selection, classifier creation, and optimization.; Statistical Analysis: Conducted to assess combat effectiveness, force readiness, and mission performance.; Data Modeling: Developed production-level data models to analyze military operational data and support strategic decision-making.; Data Preprocessing: Involves preprocessing large datasets related to Army operations, logistics, personnel, and intelligence for analysis.; SQL: Used as a practical skill for data querying and manipulation.; Python: Utilized for statistical programming and data analysis.; R: Used for statistical programming and data analysis.; Data Visualization: Developing dashboards and reports to visualize key performance indicators and metrics for leadership.; Power BI: Preferred tool for creating data visualizations and dashboards.; Tableau: Preferred tool for creating data visualizations and dashboards.; Big Data Systems: Experience working with large-scale data systems within the Department of Defense context."
xeT0sK51fE3pdAz4AAAAAA==,Data Scientist :::: Video / F2F (maybe) Prefer face to face ::: Local in MD,"Data Scientist

Columbia, MD

12+ Months

Technical Skills & Qualifications:
• Bachelor s or Master s degree in Data Science, Statistics, Computer Science, Transportation Engineering, or a related quantitative field.
• 3-5 years of experience working as a data scientist or data analyst, preferably in a transit, transportation, or public sector environment.
• Strong proficiency in Python or R for data analysis, statistical modeling, and machine learning.
• Experience with SQL for database querying, manipulation, and data extraction.
• Familiarity with transit data standards such as GTFS, AVL/CAD, APC (Automated Passenger Counters), and AVA systems.
• Experience with data visualization tools such as Power BI, or equivalent.",2025-07-02T00:00:00.000Z,2025-07-25,"['12+ Months', 'Bachelor s or Master s degree in Data Science, Statistics, Computer Science, Transportation Engineering, or a related quantitative field', '3-5 years of experience working as a data scientist or data analyst, preferably in a transit, transportation, or public sector environment', 'Strong proficiency in Python or R for data analysis, statistical modeling, and machine learning', 'Experience with SQL for database querying, manipulation, and data extraction', 'Familiarity with transit data standards such as GTFS, AVL/CAD, APC (Automated Passenger Counters), and AVA systems', 'Experience with data visualization tools such as Power BI, or equivalent']",,True,[],,"['Python', 'R', 'SQL', 'Statistical Modeling', 'Machine Learning', 'Data Visualization Tools', 'Transit Data Standards']","Python: Used for data analysis, statistical modeling, and machine learning tasks relevant to the transit and transportation domain.; R: Applied for data analysis, statistical modeling, and machine learning in the context of transit and transportation data.; SQL: Utilized for database querying, data manipulation, and extraction of transit-related data.; Statistical Modeling: Employed to analyze transit and transportation data for insights and predictive purposes.; Machine Learning: Used to develop predictive models and analyze transit data within the public sector environment.; Data Visualization Tools: Experience with Power BI or equivalent tools to create visual representations of transit and transportation data.; Transit Data Standards: Familiarity with GTFS, AVL/CAD, APC (Automated Passenger Counters), and AVA systems to handle and interpret transit-specific datasets."
4WuacWaNPYl9yRqIAAAAAA==,"Data Scientist - Computer Vision, WWPS ProServe Jobs","DESCRIPTION

The Amazon Web Services (AWS) US Federal Professional Services team is looking for a passionate and talented Computer Vision Data Scientist who will collaborate with other scientists and engineers to develop computer vision and remote sensing capabilities to address customer use-cases at enterprise scale. If you are excited to work with massive amounts of data and computer vision models to solve real world challenges, this is the position for you! We work directly with public sector entities, medical centers, and non-profits to achieve their mission goals through the adoption of Machine Learning (ML) methods. We apply computer vision to numerous imagery and sensor types, such as satellite imagery, medical imaging, aerial video, synthetic aperture radar, X-Ray, and more! Amazon has been investing in Machine Learning for decades, and by joining AWS you'll join a community of scientists and engineers developing leading edge solutions for enterprise-scale data science applications.

In this customer facing position, you will architect and implement innovative, AWS Cloud-native ML solutions, providing direct and immediate impact for your customers. You will take the lead in planning, designing, and running experiments, researching new algorithms, and will work closely with talented data scientists and engineers to put algorithms and models into practice to help solve our customers' most challenging problems. You will also guide teams in the development of new solutions and aid customers in adopting AWS ML capabilities.

This position may involve local travel up to 25%.

This position requires that the candidate selected must currently possess and maintain an active TS/SCI security clearance. The position further requires that, after start, the selected candidate have the ability to obtain and maintain an active TS/SCI security clearance with polygraph or commensurate clearance for each government agency for which they perform AWS work.

Key job responsibilities
As an experienced technology professional, you will be responsible for:
- Engage directly with customers to understand their business problems and aid them in implementing their ML solutions.
- Deliver Machine Learning projects from beginning to end. This includes understanding the business need, planning the project, aggregating & exploring data, building & validating predictive models, and deploying completed ML capabilities on the AWS Cloud to deliver business impact for the customer.
- Use Deep Learning frameworks like PyTorch and Tensorflow to help our customers build computer vision models.
- Work on TB scale datasets, creating scalable, robust and accurate computer vision systems in versatile application fields.
- Work with other Professional Services Data Scientists and Machine Learning Engineers to help our customers operationalize ML capabilities
- Collaborate with Cloud Architects to build secure, robust, and easy-to-deploy cloud-native machine learning solutions.
- Work closely with customer account teams, scientific research teams and product engineering teams to optimize model implementations and deploy internal algorithms for your customers.
- Assist customers with Machine Learning Operations (MLOps) workflows such as model deployment, retraining, testing, and performance monitoring.
- Experience applying best practices from core Software Development activities to Machine Learning (deployability, unit testing, well structured extensible software, etc.)

About the team
Diverse Experiences - AWS values diverse experiences. Even if you do not meet all of the preferred qualifications and skills listed in the job below, we encourage candidates to apply. If your career is just starting, hasn't followed a traditional path, or includes alternative experiences, don't let it stop you from applying.

Why AWS? - Amazon Web Services (AWS) is the world's most comprehensive and broadly adopted cloud platform. We pioneered cloud computing and never stopped innovating - that's why customers from the most successful startups to Global 500 companies trust our robust suite of products and services to power their businesses.

Inclusive Team Culture - Here at AWS, it's in our nature to learn and be curious. Our employee-led affinity groups foster a culture of inclusion that empower us to be proud of our differences. Ongoing events and learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (diversity) conferences, inspire us to never stop embracing our uniqueness.

Mentorship & Career Growth - We're continuously raising our performance bar as we strive to become Earth's Best Employer. That's why you'll find endless knowledge-sharing, mentorship and other career-advancing resources here to help you develop into a better-rounded professional.

Work/Life Balance - We value work-life harmony. Achieving success at work should never come at the expense of sacrifices at home, which is why we strive for flexibility as part of our working culture. When we feel supported in the workplace and at home, there's nothing we can't achieve in the cloud.

BASIC QUALIFICATIONS

- Bachelor's degree in Computer Science, Engineering, related field, or equivalent experience
- 3+ years of data scientist experience, data querying languages (e.g. SQL), scripting languages (e.g. Python) or statistical/mathematical software (e.g. R, SAS, Matlab, etc.) experience
- 3+ years of machine learning/statistical modeling data analysis tools and techniques, and parameters that affect their performance experience
- Experience applying theoretical models in an applied environment
- Current, active US Government Security Clearance of TS/SCI or above

PREFERRED QUALIFICATIONS

- 3+ years of experience handling terabyte-scale datasets
- AWS Certifications, for example AWS Solution Architect Associate/Professional, ML Specialty, or Developer Associate
- Experience working with at least one of the following industry standard formats in an imagery domain: Satellite Imagery (NITF, GeoTIFF, SICD, etc.), Motion Imagery (commercial and USG FMV specs), or medical imagery (e.g. DICOM)
- Hands-on experience with state-of-the-art object detection approaches
- Experience managing multiple AWS and ML Environments through Infrastructure as code (Cloudformation, Cloud Development Kit, Terraform, Pulumi, etc.)
- Experience containerizing/deploying computer vision models, specifically neural networks, into production environments

Amazon is an equal opportunity employer and does not discriminate on the basis of protected veteran status, disability, or other legally protected status.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you're applying in isn't listed, please contact your Recruiting Partner.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $125,500/year in our lowest geographic market up to $212,800/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits . This position will remain posted until filled. Applicants should apply via our internal or external career site.",2025-07-20T00:00:00.000Z,2025-07-25,"['This position requires that the candidate selected must currently possess and maintain an active TS/SCI security clearance', 'The position further requires that, after start, the selected candidate have the ability to obtain and maintain an active TS/SCI security clearance with polygraph or commensurate clearance for each government agency for which they perform AWS work', ""Bachelor's degree in Computer Science, Engineering, related field, or equivalent experience"", '3+ years of data scientist experience, data querying languages (e.g. SQL), scripting languages (e.g. Python) or statistical/mathematical software (e.g. R, SAS, Matlab, etc.) experience', '3+ years of machine learning/statistical modeling data analysis tools and techniques, and parameters that affect their performance experience', 'Experience applying theoretical models in an applied environment', 'Current, active US Government Security Clearance of TS/SCI or above', 'Experience managing multiple AWS and ML Environments through Infrastructure as code (Cloudformation, Cloud Development Kit, Terraform, Pulumi, etc.)', 'Experience containerizing/deploying computer vision models, specifically neural networks, into production environments']","[""You will take the lead in planning, designing, and running experiments, researching new algorithms, and will work closely with talented data scientists and engineers to put algorithms and models into practice to help solve our customers' most challenging problems"", 'You will also guide teams in the development of new solutions and aid customers in adopting AWS ML capabilities', 'This position may involve local travel up to 25%', 'Engage directly with customers to understand their business problems and aid them in implementing their ML solutions', 'Deliver Machine Learning projects from beginning to end', 'This includes understanding the business need, planning the project, aggregating & exploring data, building & validating predictive models, and deploying completed ML capabilities on the AWS Cloud to deliver business impact for the customer', 'Use Deep Learning frameworks like PyTorch and Tensorflow to help our customers build computer vision models', 'Work on TB scale datasets, creating scalable, robust and accurate computer vision systems in versatile application fields', 'Work with other Professional Services Data Scientists and Machine Learning Engineers to help our customers operationalize ML capabilities', 'Collaborate with Cloud Architects to build secure, robust, and easy-to-deploy cloud-native machine learning solutions', 'Work closely with customer account teams, scientific research teams and product engineering teams to optimize model implementations and deploy internal algorithms for your customers', 'Assist customers with Machine Learning Operations (MLOps) workflows such as model deployment, retraining, testing, and performance monitoring', 'Experience applying best practices from core Software Development activities to Machine Learning (deployability, unit testing, well structured extensible software, etc.)', 'Hands-on experience with state-of-the-art object detection approaches']",True,['Deep Learning'],Deep Learning: Use deep learning frameworks like PyTorch and TensorFlow specifically to build and optimize neural network-based computer vision models for customers.,"['Machine Learning', 'Computer Vision', 'Deep Learning Frameworks', 'Large-scale Data Handling', 'Data Querying and Scripting Languages', 'Statistical Modeling and Machine Learning Techniques', 'Model Experimentation and Algorithm Research', 'MLOps', 'Cloud-native Machine Learning Solutions', 'Infrastructure as Code', 'Model Containerization and Deployment', 'Object Detection']","Machine Learning: Deliver end-to-end machine learning projects including data aggregation, exploration, predictive model building, validation, and deployment on AWS Cloud to create business impact for customers.; Computer Vision: Develop and deploy computer vision models applied to various imagery and sensor types such as satellite imagery, medical imaging, aerial video, synthetic aperture radar, and X-Ray to solve real-world challenges.; Deep Learning Frameworks: Use PyTorch and TensorFlow frameworks to build and optimize computer vision models for customers.; Large-scale Data Handling: Work with terabyte-scale datasets to create scalable, robust, and accurate computer vision systems across diverse application fields.; Data Querying and Scripting Languages: Utilize data querying languages like SQL and scripting languages such as Python, as well as statistical/mathematical software like R, SAS, or Matlab for data analysis and modeling.; Statistical Modeling and Machine Learning Techniques: Apply machine learning and statistical modeling tools and techniques, including understanding parameters that affect model performance, to develop predictive models.; Model Experimentation and Algorithm Research: Lead planning, designing, and running experiments and researching new algorithms to improve model performance and solve customer problems.; MLOps: Assist customers with machine learning operations workflows including model deployment, retraining, testing, and performance monitoring to operationalize ML capabilities.; Cloud-native Machine Learning Solutions: Architect and implement secure, robust, and easy-to-deploy machine learning solutions on AWS Cloud, collaborating with cloud architects and engineering teams.; Infrastructure as Code: Manage multiple AWS and machine learning environments using infrastructure as code tools such as CloudFormation, Cloud Development Kit, Terraform, and Pulumi.; Model Containerization and Deployment: Containerize and deploy computer vision models, specifically neural networks, into production environments to ensure scalability and reliability.; Object Detection: Hands-on experience with state-of-the-art object detection approaches applied within computer vision projects."
XBzYIxr04OGMaO3bAAAAAA==,Data Engineer,"Description

About Us:

eSimplicity is modern digital services company that work across government, partnering with our clients to improve the lives and ensure the security of all Americans—from soldiers and veteran to kids and the elderly, and defend national interests on the battlefield. Our engineers, designers and strategist cut through complexity to create intuitive products and services that equip Federal agencies with solutions to courageously transform today for a better tomorrow for all Americans.

This position is contingent upon award.

Role Overview:

We are seeking a highly skilled Data Engineer III to help evaluate and design robust data integration solutions for large-scale, disparate datasets spanning multiple platforms and infrastructure types, including cloud-based and potentially undefined or evolving environments. This role is critical in identifying optimal data ingestion, normalization, and transformation strategies while collaborating with cross-functional teams to ensure data accessibility, reliability, and security across systems.

Responsibilities:
• Assess, design, and implement solutions for integrating large-scale datasets from disparate systems, including unknown or undefined data environments.
• Collaborate with end users and data stakeholders to understand requirements and educate them on Spark-based processing in Databricks, using SQL, Python, and/or R.
• Partner with data engineers and data scientists to extract and transform data from external sources using APIs, Kafka, or Kinesis, and build automated, resilient data pipelines.
• Write comprehensive unit, integration, and functional tests for critical data workflows.
• Create and deliver clear, concise technical presentations and documentation to both technical and non-technical audiences.
• Stay informed on the latest cloud technologies, data integration patterns, and industry best practices to drive innovation and process improvements.
• Manage deliverables and project timelines, ensuring high-quality outcomes.
• Provide timely updates to leadership and contribute to planning and prioritization discussions.

Required Qualifications:
• All candidates must pass public trust clearance through the U.S. Federal Government. This requires candidates to either be U.S. citizens or pass clearance through the Foreign National Government System which will require that candidates have lived within the United States for at least 3 out of the previous 5 years, have a valid and non-expired passport from their country of birth and appropriate VISA/work permit documentation.
• Bachelor’s degree in Computer Science, Software Engineering, Data Science, Statistics, or related technical field.
• 10+ years of experience in software/data engineering, including data pipelines, data modeling, data integration, and data management.
• Expertise in data lakes, data warehouses, data meshes, data modeling and data schemas (star, snowflake…).
• Strong expertise in SQL, Python, and/or R, with applied experience in Apache Spark and large-scale processing using PySpark or Sparklyr.
• Experience with Databricks in a production environment.
• Strong experience with AWS cloud-native data services, including S3, Glue, Athena, and Lambda.
• Strong proficiency with GitHub and GitHub Actions, including test-driven development.
• Proven ability to work with incomplete or ambiguous data infrastructure and design integration strategies.
• Excellent analytical, organizational, and problem-solving skills.
• Strong communication skills, with the ability to translate complex concepts across technical and business teams.
• Proven experience working with petabyte-level data systems.

Requirements

Desired Qualifications:
• Experience working with healthcare data, especially CMS (Centers for Medicare & Medicaid Services) datasets.
• CMS and Healthcare Expertise: In-depth knowledge of CMS regulations and experience with complex healthcare projects; in particular, data infrastructure related projects or similar.
• Demonstrated success providing support within the CMS OIT environment, ensuring alignment with organizational goals and technical standards.
• Demonstrated experience and familiarity with CMS OIT data systems (e.g. IDR-C, CCW, EDM, etc.)
• Experience with cloud platform services: AWS and Azure.
• Experience with streaming data (Kafka, Kinesis, Pub/Sub).
• Familiarity with data governance, metadata management, and data quality practices.

Working Environment:
eSimplicity supports a hybrid work environment operating within the Eastern time zone so we can work with and respond to our government clients. Expected hours are 9:00 AM to 5:00 PM Eastern unless otherwise directed by your manager.

Occasional travel for training and project meetings. It is estimated to be less than 25% per year.

Benefits:
We offer highly competitive salaries and full healthcare benefits.

Equal Employment Opportunity:
eSimplicity is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, religion, color, national origin, gender, age, status as a protected veteran, sexual orientation, gender identity, or status as a qualified individual with a disability.",2025-07-23T00:00:00.000Z,2025-07-25,"['All candidates must pass public trust clearance through the U.S. Federal Government', 'This requires candidates to either be U.S. citizens or pass clearance through the Foreign National Government System which will require that candidates have lived within the United States for at least 3 out of the previous 5 years, have a valid and non-expired passport from their country of birth and appropriate VISA/work permit documentation', 'Bachelor’s degree in Computer Science, Software Engineering, Data Science, Statistics, or related technical field', '10+ years of experience in software/data engineering, including data pipelines, data modeling, data integration, and data management', 'Expertise in data lakes, data warehouses, data meshes, data modeling and data schemas (star, snowflake…)', 'Strong expertise in SQL, Python, and/or R, with applied experience in Apache Spark and large-scale processing using PySpark or Sparklyr', 'Experience with Databricks in a production environment', 'Strong experience with AWS cloud-native data services, including S3, Glue, Athena, and Lambda', 'Strong proficiency with GitHub and GitHub Actions, including test-driven development', 'Proven ability to work with incomplete or ambiguous data infrastructure and design integration strategies', 'Excellent analytical, organizational, and problem-solving skills', 'Strong communication skills, with the ability to translate complex concepts across technical and business teams', 'Proven experience working with petabyte-level data systems', 'IDR-C, CCW, EDM, etc.)', 'Experience with cloud platform services: AWS and Azure', 'Experience with streaming data (Kafka, Kinesis, Pub/Sub)', 'Familiarity with data governance, metadata management, and data quality practices', 'It is estimated to be less than 25% per year']","['We are seeking a highly skilled Data Engineer III to help evaluate and design robust data integration solutions for large-scale, disparate datasets spanning multiple platforms and infrastructure types, including cloud-based and potentially undefined or evolving environments', 'This role is critical in identifying optimal data ingestion, normalization, and transformation strategies while collaborating with cross-functional teams to ensure data accessibility, reliability, and security across systems', 'Assess, design, and implement solutions for integrating large-scale datasets from disparate systems, including unknown or undefined data environments', 'Collaborate with end users and data stakeholders to understand requirements and educate them on Spark-based processing in Databricks, using SQL, Python, and/or R', 'Partner with data engineers and data scientists to extract and transform data from external sources using APIs, Kafka, or Kinesis, and build automated, resilient data pipelines', 'Write comprehensive unit, integration, and functional tests for critical data workflows', 'Create and deliver clear, concise technical presentations and documentation to both technical and non-technical audiences', 'Stay informed on the latest cloud technologies, data integration patterns, and industry best practices to drive innovation and process improvements', 'Manage deliverables and project timelines, ensuring high-quality outcomes', 'Provide timely updates to leadership and contribute to planning and prioritization discussions', 'Expected hours are 9:00 AM to 5:00 PM Eastern unless otherwise directed by your manager', 'Occasional travel for training and project meetings']",False,,,,
sddKJVxz0FQ33rHEAAAAAA==,Geospatial Data Scientist / Machine Learning Engineer (TS cleara Jobs,"Figure Eight Federal (F8F): Leading the Future of AI Training Data

Figure Eight Federal (F8F) provides accurate and reliable human annotated datasets that fuel AI and machine learning for some of the world's biggest brands. With more than 25 years of industry knowledge, F8F's technology powers many of the AI interactions we experience every day. Our solutions and expertise empower our clients to achieve their AI goals and make a significant impact in their industry.

We are seeking an exceptional Geospatial Data Scientist (GDS) to join our team at the cutting edge of data focused geospatial analytics. This role sits at the critical intersection of remote sensing, computer vision, machine learning, and data science. The ideal candidate will possess advanced knowledge of raster-level geospatial data, comprehensive understanding of collection metadata, and expertise in various sensing phenomenologies including Electro-Optical (EO), Infrared (IR), and Synthetic Aperture Radar (SAR). This position is pivotal in bridging the gap between geospatial data expertise and machine learning applications.

Responsibilities:
• Analyze and process complex geospatial datasets from multiple sensing modalities (EO, IR, SAR)
• Evaluate dataset quality, coverage, and metadata to determine suitability for ML applications
• Develop and implement innovative data preparation strategies for geospatial machine learning
• Design and execute validation methods for geospatial data quality assurance
• Develop automated processes for geospatial data integration and harmonization
• Generate comprehensive documentation of data characteristics, limitations, and potential biases
• Stay current with emerging trends and technologies in remote sensing and geospatial data science
• Provide technical consultation on remote sensing capabilities and limitations for project planning
• Other duties as assigned

Qualifications:
• Bachelor's degree in Remote Sensing, GIS, Computer Science, Geospatial Science, Data Science, or related field (additional years of experience may be substituted for degree)
• 3+ years of experience working with remote sensing data in analytical applications
• Demonstrable knowledge of EO, IR, and/or SAR sensing phenomenologies and their unique characteristics
• Strong programming skills in Python or R, with experience using geospatial libraries (e.g., GDAL, GeoPandas)
• Working knowledge of computer vision techniques applied to satellite/aerial imagery
• Proficiency with geospatial metadata standards and their importance in analysis
• Experience evaluating dataset suitability for ML training and deployment
• Experience with containerization (Docker) and workflow automation for geospatial pipelines
• Strong ability to visualize data for consumption by both technical and non-technical audiences
• Active Top Secret security clearance

Preferred Qualifications:
• Master's degree in Remote Sensing, Computer Science, Geospatial Science, Data Science, or related field
• Experience with machine learning frameworks (TensorFlow, PyTorch) and their application to geospatial data
• Experience with GIS tools such as QGIS, ArcGIS, etc.
• Knowledge of deep learning architectures specifically designed for remote sensing data
• Familiarity with hyperspectral and LiDAR data processing
• Experience with time-series analysis of satellite imagery
• Understanding of uncertainty quantification in geospatial data and propagation into ML models
• Experience with cloud-based geospatial computing (AWS, Google Earth Engine, Microsoft Planetary Computer)",2025-07-25T01:00:00.000Z,2025-07-25,"['The ideal candidate will possess advanced knowledge of raster-level geospatial data, comprehensive understanding of collection metadata, and expertise in various sensing phenomenologies including Electro-Optical (EO), Infrared (IR), and Synthetic Aperture Radar (SAR)', 'This position is pivotal in bridging the gap between geospatial data expertise and machine learning applications', ""Bachelor's degree in Remote Sensing, GIS, Computer Science, Geospatial Science, Data Science, or related field (additional years of experience may be substituted for degree)"", '3+ years of experience working with remote sensing data in analytical applications', 'Demonstrable knowledge of EO, IR, and/or SAR sensing phenomenologies and their unique characteristics', 'Strong programming skills in Python or R, with experience using geospatial libraries (e.g., GDAL, GeoPandas)', 'Working knowledge of computer vision techniques applied to satellite/aerial imagery', 'Proficiency with geospatial metadata standards and their importance in analysis', 'Experience evaluating dataset suitability for ML training and deployment', 'Experience with containerization (Docker) and workflow automation for geospatial pipelines', 'Strong ability to visualize data for consumption by both technical and non-technical audiences', 'Active Top Secret security clearance']","['This role sits at the critical intersection of remote sensing, computer vision, machine learning, and data science', 'Analyze and process complex geospatial datasets from multiple sensing modalities (EO, IR, SAR)', 'Evaluate dataset quality, coverage, and metadata to determine suitability for ML applications', 'Develop and implement innovative data preparation strategies for geospatial machine learning', 'Design and execute validation methods for geospatial data quality assurance', 'Develop automated processes for geospatial data integration and harmonization', 'Generate comprehensive documentation of data characteristics, limitations, and potential biases', 'Stay current with emerging trends and technologies in remote sensing and geospatial data science', 'Provide technical consultation on remote sensing capabilities and limitations for project planning', 'Other duties as assigned']",True,['Deep Learning'],"Deep Learning: Using deep learning frameworks like TensorFlow and PyTorch to develop models specifically applied to geospatial data, including architectures designed for remote sensing.","['Geospatial Data Analysis', 'Remote Sensing Data', 'Machine Learning', 'Computer Vision', 'Data Preparation and Validation', 'Data Integration and Harmonization', 'Geospatial Metadata Standards', 'Programming with Geospatial Libraries', 'Data Visualization', 'Containerization and Workflow Automation', 'Time-Series Analysis', 'Deep Learning for Remote Sensing', 'Cloud-Based Geospatial Computing']","Geospatial Data Analysis: Analyzing and processing complex geospatial datasets from multiple sensing modalities such as Electro-Optical (EO), Infrared (IR), and Synthetic Aperture Radar (SAR) to support machine learning applications.; Remote Sensing Data: Working with raster-level geospatial data and understanding collection metadata and sensing phenomenologies to evaluate dataset quality, coverage, and suitability for ML training and deployment.; Machine Learning: Applying machine learning techniques to geospatial data, including developing data preparation strategies and evaluating datasets for ML applications.; Computer Vision: Using computer vision techniques specifically applied to satellite and aerial imagery to extract meaningful features for analysis and ML.; Data Preparation and Validation: Designing and implementing innovative data preparation strategies and validation methods to ensure geospatial data quality and suitability for machine learning.; Data Integration and Harmonization: Developing automated processes for integrating and harmonizing geospatial data from multiple sources.; Geospatial Metadata Standards: Proficiency with geospatial metadata standards to ensure accurate analysis and documentation of data characteristics, limitations, and biases.; Programming with Geospatial Libraries: Strong programming skills in Python or R using geospatial libraries such as GDAL and GeoPandas to manipulate and analyze geospatial data.; Data Visualization: Visualizing geospatial data effectively for both technical and non-technical audiences to communicate insights and findings.; Containerization and Workflow Automation: Experience with containerization technologies like Docker and workflow automation to streamline geospatial data pipelines.; Time-Series Analysis: Analyzing time-series satellite imagery data to extract temporal patterns and trends relevant to geospatial applications.; Deep Learning for Remote Sensing: Applying deep learning architectures designed for remote sensing data to enhance analysis and predictive modeling.; Cloud-Based Geospatial Computing: Utilizing cloud platforms such as AWS, Google Earth Engine, and Microsoft Planetary Computer for scalable geospatial data processing and analysis."
sAtX1osX8LlDyT1_AAAAAA==,Data Scientist 3,"Are you VIGILANT about your career? RealmOne definitely is!

RealmOne was built on the principle that people matter first and foremost. We believe in providing a strong work/life balance by investing in our employees and encouraging professional and personal growth. We do this by offering exceptional benefits, flexible schedules, and the tools necessary to achieve success through paid training, mentoring, and the opportunity to work alongside top-notch security professionals.

Join us on this journey as we execute this new mission-critical contract providing Cybersecurity Expertise and Risk Management!

Your effort and expertise are crucial to the success and execution of this impactful mission that is critical in ensuring mission success through Data Scientists, Cryptologic Computer Scientists, Cryptanalytic Computer Scientists, Cryptologic Cyber Planners, Intrusion Analysts, Protocol Analysts, Signals Analysts and Reverse Engineers by improving, protecting, and defending our Nation's Security.

Job Description:

We are seeking a Data Scientist proficient in Python and experienced in automating workflows, data manipulation, and visualization using Jupyter Notebooks. This role involves leveraging Python expertise to streamline processes and create insightful visualizations for data-driven decision-making.

The Level 3 Data Scientist shall possess the following capabilities:
• Foundations: (Mathematical, Computational, Statistical)
• Data Processing: (Data management and curation, data description and visualization, workflow and reproducibility)
• Modeling, Inference, and Prediction: (Data modeling and assessment, domain-specific considerations)
• Devise strategies for extracting meaning and value from large datasets. Make and communicate principled conclusions from data using elements of mathematics, statistics, computer science, and application specific knowledge. Through analytic modeling, statistical analysis, programming, and/or another appropriate scientific method, develop and implement qualitative and quantitative methods for characterizing, exploring, and assessing large datasets in various states of organization, cleanliness, and structure that account for the unique features and limitations inherent in DOD data holdings. Translate practical mission needs and analytic questions related to large datasets into technical requirements and, conversely, assist others with drawing appropriate conclusions from the analysis of such data. Effectively communicate complex technical information to non-technical audiences. Make informed recommendations regarding competing technical solutions by maintaining awareness of the constantly shifting DOD collection, processing, storage and analytic capabilities and limitations.

Qualifications:
• Bachelor's Degree with 10 years of relevant experience
• Associates degree with 12 years of relevant experience
• Bachelor'sDegree must be in Mathematics, Applied Mathematics Statistics, Applied Statistics, Machine learning, Data Science, Operations Research, or Computer Science or a degree in a related field (Computer Information Systems, Engineering), a degree in the physical/hard sciences (e.g. physics, chemistry, biology, astronomy), or other science disciplines with a substantial computational component (i.e. behavioral, social, or life) may be considered if it included a concentration of coursework (5 or more courses) in advanced Mathematics (typically 300 level or higher, such as linear algebra, probability and statistics, machine learning) and/or computer science (e.g. algorithms, programming, , data structures, data mining, artificial intelligence). College-level requirement, or upper-level math courses designated as elementary or basic do not count. Note: A broader range of degrees will be considered if accompanied by a Certificate in Data Science from an accredited college/university.
• Relevant experience must be in designing/implementing machine learning, data science, advanced analytical algorithms, programming (skill in at least one high-level language (e.g. Python)), statistical analysis (e.g. variability, sampling error, inference, hypothesis testing, EDA, application of linear models), data management (e.g. data cleaning and transformation), data mining, data modeling and assessment, artificial intelligence, and/or software engineering. Experience in more than one area is strongly preferred.

Position requires active Security Clearance with appropriate Polygraph",2025-06-26T00:00:00.000Z,2025-07-25,"['We are seeking a Data Scientist proficient in Python and experienced in automating workflows, data manipulation, and visualization using Jupyter Notebooks', 'Foundations: (Mathematical, Computational, Statistical)', 'Data Processing: (Data management and curation, data description and visualization, workflow and reproducibility)', 'Modeling, Inference, and Prediction: (Data modeling and assessment, domain-specific considerations)', 'Devise strategies for extracting meaning and value from large datasets', ""Bachelor's Degree with 10 years of relevant experience"", 'Associates degree with 12 years of relevant experience', ""Bachelor'sDegree must be in Mathematics, Applied Mathematics Statistics, Applied Statistics, Machine learning, Data Science, Operations Research, or Computer Science or a degree in a related field (Computer Information Systems, Engineering), a degree in the physical/hard sciences (e.g. physics, chemistry, biology, astronomy), or other science disciplines with a substantial computational component (i.e. behavioral, social, or life) may be considered if it included a concentration of coursework (5 or more courses) in advanced Mathematics (typically 300 level or higher, such as linear algebra, probability and statistics, machine learning) and/or computer science (e.g. algorithms, programming, , data structures, data mining, artificial intelligence)"", 'College-level requirement, or upper-level math courses designated as elementary or basic do not count', 'Note: A broader range of degrees will be considered if accompanied by a Certificate in Data Science from an accredited college/university', 'Relevant experience must be in designing/implementing machine learning, data science, advanced analytical algorithms, programming (skill in at least one high-level language (e.g. Python)), statistical analysis (e.g. variability, sampling error, inference, hypothesis testing, EDA, application of linear models), data management (e.g. data cleaning and transformation), data mining, data modeling and assessment, artificial intelligence, and/or software engineering', 'Position requires active Security Clearance with appropriate Polygraph']","['This role involves leveraging Python expertise to streamline processes and create insightful visualizations for data-driven decision-making', 'Make and communicate principled conclusions from data using elements of mathematics, statistics, computer science, and application specific knowledge', 'Through analytic modeling, statistical analysis, programming, and/or another appropriate scientific method, develop and implement qualitative and quantitative methods for characterizing, exploring, and assessing large datasets in various states of organization, cleanliness, and structure that account for the unique features and limitations inherent in DOD data holdings', 'Translate practical mission needs and analytic questions related to large datasets into technical requirements and, conversely, assist others with drawing appropriate conclusions from the analysis of such data', 'Effectively communicate complex technical information to non-technical audiences', 'Make informed recommendations regarding competing technical solutions by maintaining awareness of the constantly shifting DOD collection, processing, storage and analytic capabilities and limitations']",True,[],,"['Python', 'Jupyter Notebooks', 'Mathematics', 'Statistics', 'Data Management', 'Data Visualization', 'Data Modeling and Assessment', 'Machine Learning', 'Advanced Analytical Algorithms', 'Programming', 'Data Mining', 'Exploratory Data Analysis (EDA)', 'Statistical Inference']","Python: Used to automate workflows, manipulate data, and create visualizations to support data-driven decision-making.; Jupyter Notebooks: Utilized as an environment for data manipulation, workflow automation, and visualization development.; Mathematics: Foundational knowledge applied to extract meaning and value from large datasets and support analytic modeling and statistical analysis.; Statistics: Used for statistical analysis including variability, sampling error, inference, hypothesis testing, exploratory data analysis, and application of linear models to characterize and assess data.; Data Management: Involves data curation, cleaning, transformation, and handling datasets in various states of organization and cleanliness, particularly within DOD data holdings.; Data Visualization: Creating insightful visualizations to communicate complex data-driven conclusions effectively to both technical and non-technical audiences.; Data Modeling and Assessment: Developing and implementing qualitative and quantitative methods for modeling, inference, and prediction tailored to domain-specific considerations.; Machine Learning: Designing and implementing machine learning algorithms and advanced analytical methods to analyze and extract insights from data.; Advanced Analytical Algorithms: Applying sophisticated algorithms for data analysis, modeling, and prediction within the context of large and complex datasets.; Programming: Skill in at least one high-level programming language (e.g., Python) to support data science tasks including automation, analysis, and modeling.; Data Mining: Extracting patterns and knowledge from large datasets to support mission-critical analytic needs.; Exploratory Data Analysis (EDA): Performing initial investigations on data to discover patterns, spot anomalies, and test hypotheses.; Statistical Inference: Drawing principled conclusions from data using statistical methods to support decision-making."
NHWgeUB0JB527teXAAAAAA==,Senior Data Analyst Jobs,"Responsibilities

Noblis ESI is seeking an experienced Senior Data Analyst to support our Intelligence Community program in Bethesda, Maryland.

Responsibilities Include:
• Enterprise Architecture: Contribute to the design and evolution of our client's enterprise cloud and data architecture, ensuring interoperability, security, and alignment with business goals. Foster a culture of innovation and continuous improvement.
• Strategic Thinking: Develop data strategies that consider long-term implications, anticipating future needs and trends. Decompose complex problems and develop an analytic approach.
• Collaboration: Collaborate with multiple stakeholders to drive data integration initiatives and foster a data-driven culture.
• Compliance: Analyze current practices to ensure compliance with relevant regulations.
• Data Integrity: Analyze the current data structure, tagging, and quality standards to discover and address anomalies.
• Responsibilities will span multiple areas, including strategic planning, data security, data compliance, and data integrity to enhance our customer's data ecosystem.

Required Qualifications
• Active TS/SCI with Counterintelligence (CI) Polygraph.
• Bachelors degree and 5 to 8 years of prior relevant experience OR Masters degree with 3 to 6 years of prior relevant experience.
• Proven experience as a Data Scientist, with a focus on complex data environments.
• Experience with data science tools and languages, such as Python, R, and Scala, in various data science environments.
• Experience with data visualization tools (e.g., Tableau, MS PowerBI) to deliver data analysis solutions and visualizations.
• Proficiency in data manipulation and analysis.
• US Citizenship is required.

Desired Qualifications
• Doctorate degree in technical domain.
• Five or more years of experience working with or in the Intelligence Community (IC).
• Cloud-based data science experience.
• Experience producing executive-level products.
• Excellent communication skills, with the ability to translate technical insights into actionable recommendations and present them orally or in writing.
• Passion for staying up to date with industry trends and advancements.

Overview

Noblis and our wholly owned subsidiaries, Noblis ESI , and Noblis MSD tackle the nation's toughest problems and apply advanced solutions to our clients' most critical missions. We bring the best of scientific thought, management, and engineering expertise together in an environment of independence and objectivity to deliver enduring impact on federal missions. Noblis works with a wide range of government clients in the defense, intelligence and federal civil sectors. Learn more at Noblis -About Us

Why work at a Noblis company?

Our employees find greater meaning in their work and balance the other things in life that matter to them. Our people are our greatest asset. They are exceptionally skilled, knowledgeable, team-oriented, and mission-driven individuals who want to do work that matters and benefits the public. Noblis has won numerous workplace awards . Noblis maintains a drug-free workplace.
• Remote/hybrid status is subject to change based on Noblis and/or government requirements

Commitment to Non-Discrimination

All qualified applicants will receive consideration for employment without regard to race, color, ethnicity, sex, age, national origin, religion, physical or mental disability, pregnancy/childbirth and related medical conditions, veteran or military status, or any other characteristics protected by applicable federal, state, or local law.

If reasonable accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment, please contact us .

EEO is the Law | E-Verify | Right to Work

Total Rewards

At Noblis we recognize and reward your contributions, provide you with growth opportunities, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, and work-life programs. Our award programs acknowledge employees for exceptional performance and superior demonstration of our service standards. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in our benefit programs. Other offerings may be provided for employees not within this category. We encourage you to learn more about our total benefits by visiting the Benefits page on our Careers site.

Compensation at Noblis is determined by various factors, including but not limited to, the combination of education, certifications, knowledge, skills, competencies, and experience, internal and external equity, location, clearance level, as well as contract-specific affordability, organizational requirements and applicable employment laws. The projected compensation range for this position is based on full time status. For part time or on-call staff, compensation is proportionately adjusted based on hours worked. While monetary compensation is important, it's just one component of Noblis' total compensation package.

Posted Salary Range

USD $117,800.00 - USD $184,100.00 /Yr.",2025-07-25T13:00:00.000Z,2025-07-25,"['Active TS/SCI with Counterintelligence (CI) Polygraph', 'Bachelors degree and 5 to 8 years of prior relevant experience OR Masters degree with 3 to 6 years of prior relevant experience', 'Proven experience as a Data Scientist, with a focus on complex data environments', 'Experience with data science tools and languages, such as Python, R, and Scala, in various data science environments', 'Experience with data visualization tools (e.g., Tableau, MS PowerBI) to deliver data analysis solutions and visualizations', 'Proficiency in data manipulation and analysis', 'US Citizenship is required', 'Remote/hybrid status is subject to change based on Noblis and/or government requirements', 'All qualified applicants will receive consideration for employment without regard to race, color, ethnicity, sex, age, national origin, religion, physical or mental disability, pregnancy/childbirth and related medical conditions, veteran or military status, or any other characteristics protected by applicable federal, state, or local law']","['Noblis ESI is seeking an experienced Senior Data Analyst to support our Intelligence Community program in Bethesda, Maryland', ""Enterprise Architecture: Contribute to the design and evolution of our client's enterprise cloud and data architecture, ensuring interoperability, security, and alignment with business goals"", 'Foster a culture of innovation and continuous improvement', 'Strategic Thinking: Develop data strategies that consider long-term implications, anticipating future needs and trends', 'Decompose complex problems and develop an analytic approach', 'Collaboration: Collaborate with multiple stakeholders to drive data integration initiatives and foster a data-driven culture', 'Compliance: Analyze current practices to ensure compliance with relevant regulations', 'Data Integrity: Analyze the current data structure, tagging, and quality standards to discover and address anomalies', ""Responsibilities will span multiple areas, including strategic planning, data security, data compliance, and data integrity to enhance our customer's data ecosystem""]",True,[],,"['Python', 'R', 'Scala', 'Tableau', 'Microsoft Power BI', 'Data manipulation and analysis', 'Enterprise cloud and data architecture', 'Data strategy development', 'Data integration', 'Data compliance and security', 'Data integrity and quality assurance']","Python: Used as a data science tool and programming language for data manipulation and analysis in various data science environments.; R: Used as a data science tool and programming language for data manipulation and analysis in various data science environments.; Scala: Used as a data science tool and programming language for data manipulation and analysis in various data science environments.; Tableau: Employed as a data visualization tool to deliver data analysis solutions and visualizations.; Microsoft Power BI: Used as a data visualization tool to deliver data analysis solutions and visualizations.; Data manipulation and analysis: Core proficiency required to analyze and work with data effectively in support of the Intelligence Community program.; Enterprise cloud and data architecture: Involves contributing to the design and evolution of the client's enterprise cloud and data architecture to ensure interoperability, security, and alignment with business goals.; Data strategy development: Developing data strategies that consider long-term implications, anticipate future needs and trends, and decompose complex problems into analytic approaches.; Data integration: Collaborating with multiple stakeholders to drive data integration initiatives and foster a data-driven culture.; Data compliance and security: Analyzing current practices to ensure compliance with relevant regulations and enhancing data security within the customer's data ecosystem.; Data integrity and quality assurance: Analyzing current data structure, tagging, and quality standards to discover and address anomalies, ensuring data integrity."
-_klp8UWVhrJmWAwAAAAAA==,ME00432-Data Scientist 4 Jobs,"Momentum Engineering, Inc., a Woman-Owned Small Business (WOSB), fosters an employee-centric culture. Our strength lies in our people. With a high percentage of employees holding advanced degrees in engineering, computer science, and related disciplines, we bring deep technical expertise to every mission. Our team includes professionals with security clearances and full-scope polygraphs, ensuring trusted, secure support for the most sensitive national security initiatives. Additionally, our workforce is equipped with industry-leading certifications, demonstrating a commitment to continuous learning and excellence. Most importantly, our exceptional employee retention rate reflects a culture of professional growth, mission focus, and dedication-ensuring long-term stability and expertise for our customers' critical needs.

Job Summary
• The ideal candidate will be involved in full spectrum analytic technical support to mission operations and the intelligence lifecycle: requirements collection and refinement, translating user requirements into technical requirements, environment configuration, exploratory data analysis, model development, selection, and evaluation, identifying insights from analytic products and then communicating those results to a nontechnical audience
• Candidate will work with cross-functional teams to identify relevant and permissible data sources, access available infrastructure, and to develop analytic products tailored to mission user requirements

Primary Responsibilities
• Establish advanced analysis and data visualization methodologies, models, and tools to derive intelligence outcomes and impacts
• Design and deliver infographics across a range of media platforms
• Identify and process raw data, trends, analysis, and assessments in order to aggregate disparate information, leveraging both analytic and visualization tools
• Leverage knowledge of databases and methodologies to determine appropriate sources, determine indicators and relationships, and generate intelligence support packages
• Provide tailored communications to innovation stakeholders in meetings, demos, and other customer engagements, as well as support analytic innovation, development, and data analytics activities to customers and stakeholders
• Brief customers on assessments and prepare briefings based on finished analysis, including preparing daily briefings for senior policy and operational decision makers
• Develop machine learning models with attention to model accuracy
• Draft technical methodologies and participate in architectural reviews
• Document processes and solutions that serve as communication findings for both technical and non-technical stakeholder

Required Qualifications
• Must have active Top Secret/SCI clearance
• Bachelor's degree or equivalent practical experience
• 4 - 6+ years of experience in computer science, data science, and data analytics
• Experience executing data science methods using Python libraries for Data Cleaning/Wrangling, Exploratory Data Analysis (EDA), Statistical Analysis, Data Visualization
• Strong proficiency in programming languages such as Python
• Agile development experience along with related technologies (e.g., Jira)
• Strong communication and interpersonal skills

Desired Qualifications
• Familiarity and experience with the Intelligence Community (IC), and the intel cycle
• Familiarity and experience with the Department of Homeland Security (DHS)
• Ability, openness, and eagerness to learn

Exempt hourly position. 11 paid holidays, minimum of 3 weeks PTO, company sponsored group medical plan, company paid dental, vision, life insurance, and STD/LTD plans. Salary is dependent upon the candidate's experience and qualifications.",2025-07-19T00:00:00.000Z,2025-07-25,"['Must have active Top Secret/SCI clearance', ""Bachelor's degree or equivalent practical experience"", '4 - 6+ years of experience in computer science, data science, and data analytics', 'Experience executing data science methods using Python libraries for Data Cleaning/Wrangling, Exploratory Data Analysis (EDA), Statistical Analysis, Data Visualization', 'Strong proficiency in programming languages such as Python', 'Agile development experience along with related technologies (e.g., Jira)', 'Strong communication and interpersonal skills']","['The ideal candidate will be involved in full spectrum analytic technical support to mission operations and the intelligence lifecycle: requirements collection and refinement, translating user requirements into technical requirements, environment configuration, exploratory data analysis, model development, selection, and evaluation, identifying insights from analytic products and then communicating those results to a nontechnical audience', 'Candidate will work with cross-functional teams to identify relevant and permissible data sources, access available infrastructure, and to develop analytic products tailored to mission user requirements', 'Establish advanced analysis and data visualization methodologies, models, and tools to derive intelligence outcomes and impacts', 'Design and deliver infographics across a range of media platforms', 'Identify and process raw data, trends, analysis, and assessments in order to aggregate disparate information, leveraging both analytic and visualization tools', 'Leverage knowledge of databases and methodologies to determine appropriate sources, determine indicators and relationships, and generate intelligence support packages', 'Provide tailored communications to innovation stakeholders in meetings, demos, and other customer engagements, as well as support analytic innovation, development, and data analytics activities to customers and stakeholders', 'Brief customers on assessments and prepare briefings based on finished analysis, including preparing daily briefings for senior policy and operational decision makers', 'Develop machine learning models with attention to model accuracy', 'Draft technical methodologies and participate in architectural reviews', 'Document processes and solutions that serve as communication findings for both technical and non-technical stakeholder']",True,[],,"['Exploratory Data Analysis', 'Data Cleaning/Wrangling', 'Statistical Analysis', 'Data Visualization', 'Machine Learning Models', 'Python Programming', 'Databases and Data Sources', 'Agile Development']","Exploratory Data Analysis: Used to analyze and summarize data sets to identify patterns and insights relevant to mission operations and intelligence lifecycle.; Data Cleaning/Wrangling: Applied using Python libraries to prepare raw data for analysis by handling inconsistencies and formatting issues.; Statistical Analysis: Performed to evaluate data trends and support intelligence assessments and model evaluation.; Data Visualization: Established advanced methodologies and designed infographics across media platforms to communicate analytic results and intelligence outcomes effectively.; Machine Learning Models: Developed with attention to model accuracy to support analytic products tailored to mission user requirements.; Python Programming: Used extensively for data science methods including data cleaning, exploratory data analysis, statistical analysis, and visualization.; Databases and Data Sources: Leveraged knowledge of databases and methodologies to identify appropriate data sources, determine indicators and relationships, and generate intelligence support packages.; Agile Development: Utilized agile methodologies and related tools such as Jira to support iterative development and delivery of analytic products."
9-w0Jz3GtdfwWvO4AAAAAA==,Data Scientist Jobs,"NewGen Technologies is seeking a versatile Data Scientist with a TS/SCI and poly to join a high paced team working on cutting-edge AI/ML and networking technology. As the Data Scientist will be part of a small agile team building a big data pipeline, AI/ML-based analytics capabilities, and user interfaces for government customers. This project includes highly innovative work focused on leveraging AI/ML to discover patterns and develop insights across multiple networks and devices to include IoT and 5G. Work is conducted in conjunction with world-renowned scientist and engineers at IBM Research. The team is fast-paced, collaborative, and cohesive, and depends on team members to communicate openly and to design solutions and deliver quality models on a regular, aggressive clip.

You will have the opportunity to choose W2 (with or without benefits) or 1099 employment options.

Required:
• Demonstrated experience with Python, Jupyter
• demonstrated experience with Machine Learning, including model development, evaluation and optimization using tools and packages such as: sklearn, NumPy, PyTorch, or TensorFlow
• Exposure to/understanding of network data analysis (IP traffic)using Bro/Zeek, TShark/PyShark, or other network analysis tools
Desired:
• Demonstrated experience with one or more of the following: Spark, MLFlow, Docker, AWS, Linux/CentOS, bash scripting.
• Demonstrated experience with Agile software development, Scrum, Git/GitHub and software development lifecycle (SDLC).
• Bachelor's degree in computer science, engineering, or related technical field.
Technical and Professional Expertise:
• Ability to apply, evaluate, and modify machine learning algorithms against various data sources and use cases
• Design and develop methods, processes, and systems to consolidate and analyze structured and unstructured, diverse sources including big data sources.
• Concentrate on the AI discipline of Machine Learning - in data, pattern identification and analysis. As such will be evaluate capabilities and analysis in Natural Language Processing, Machine Learning, predictive modeling, statistical analysis and hypothesis testing
• Develops and uses advanced software programs, algorithms, query techniques, model complex business problems, and automated processes to cleanse, integrate, and evaluate datasets.
About Us:
NewGen is a technology consulting services company solving some of the public and private sectors' toughest challenges across Enterprise Management, Cyber Security and DevOps. We know that to find and hire the best fit, we must offer interesting work at the best rate possible. By partnering with us, you will find opportunities that leverage and grow your technical abilities and offer you the flexibility you require. Join our talent network today. #CJ",2025-07-25T14:00:00.000Z,2025-07-25,"['Demonstrated experience with Python, Jupyter', 'demonstrated experience with Machine Learning, including model development, evaluation and optimization using tools and packages such as: sklearn, NumPy, PyTorch, or TensorFlow', 'Exposure to/understanding of network data analysis (IP traffic)using Bro/Zeek, TShark/PyShark, or other network analysis tools', 'Ability to apply, evaluate, and modify machine learning algorithms against various data sources and use cases', 'Concentrate on the AI discipline of Machine Learning - in data, pattern identification and analysis', 'Develops and uses advanced software programs, algorithms, query techniques, model complex business problems, and automated processes to cleanse, integrate, and evaluate datasets']","['As the Data Scientist will be part of a small agile team building a big data pipeline, AI/ML-based analytics capabilities, and user interfaces for government customers', 'This project includes highly innovative work focused on leveraging AI/ML to discover patterns and develop insights across multiple networks and devices to include IoT and 5G', 'Design and develop methods, processes, and systems to consolidate and analyze structured and unstructured, diverse sources including big data sources', 'As such will be evaluate capabilities and analysis in Natural Language Processing, Machine Learning, predictive modeling, statistical analysis and hypothesis testing']",True,[],,"['Python', 'Jupyter', 'Machine Learning', 'scikit-learn', 'NumPy', 'PyTorch', 'TensorFlow', 'Network Data Analysis', 'Big Data Pipelines', 'Predictive Modeling', 'Statistical Analysis', 'Natural Language Processing', 'Data Cleansing and Integration', 'Agile Software Development', 'Spark', 'MLflow', 'Docker', 'AWS', 'Linux/CentOS', 'Bash Scripting', 'Git/GitHub']","Python: Used as a primary programming language for data analysis, model development, and building data pipelines.; Jupyter: Utilized as an interactive environment for developing, documenting, and running data science experiments and models.; Machine Learning: Applied for model development, evaluation, optimization, pattern identification, predictive modeling, and statistical analysis across diverse data sources.; scikit-learn: Used as a tool for developing, evaluating, and optimizing machine learning models.; NumPy: Employed for numerical computing and data manipulation as part of the machine learning and data analysis workflow.; PyTorch: Used for machine learning model development and evaluation, including neural network implementations.; TensorFlow: Utilized for machine learning model development and evaluation, including neural network implementations.; Network Data Analysis: Involves analyzing IP traffic data using tools like Bro/Zeek and TShark/PyShark to extract insights from network data.; Big Data Pipelines: Designing and building scalable data pipelines to consolidate and analyze structured and unstructured big data sources.; Predictive Modeling: Developing models to forecast outcomes and identify patterns within diverse datasets.; Statistical Analysis: Applying statistical methods including hypothesis testing to analyze data and validate models.; Natural Language Processing: Evaluating capabilities and analysis techniques related to processing and understanding text data.; Data Cleansing and Integration: Automating processes to clean, integrate, and prepare datasets for analysis and modeling.; Agile Software Development: Working within agile teams using Scrum methodologies to develop data science solutions iteratively.; Spark: Used for distributed data processing and building scalable data pipelines.; MLflow: Employed for managing the machine learning lifecycle including experiment tracking and model deployment.; Docker: Utilized to containerize applications and machine learning models for consistent deployment.; AWS: Used as a cloud platform to host data pipelines, storage, and machine learning workloads.; Linux/CentOS: Operating system environment for development, deployment, and running data science tools and pipelines.; Bash Scripting: Used to automate workflows and manage data processing tasks in the development environment.; Git/GitHub: Version control tools used to manage codebase and collaborate on software development lifecycle."
YdYVExrltznEb7kIAAAAAA==,"Principal Data Scientist, AI Foundations at Capital One Mc Lean, VA","Principal Data Scientist, AI Foundations job at Capital One. Mc Lean, VA.

Principal Data Scientist, AI Foundations
Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making.

As a Data Scientist at Capital One, you’ll be part of a team that’s leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives.
Team Description
AI Foundations Specialist Models Data Science team builds and ships state of the art scalable architecture, AI/ML solutions for Capital One’s award-winning mobile app. We partner with product, tech and design teams to deliver app features that delight customers with dynamic and personalized experiences, enable them to chat with Capital One’s digital assistant Eno, or search for useful contents. You will be the driving force to experiment, innovate and create next generation experiences powered by the latest emerging generative AI technologies.
In this role, you will:
Partner with a cross-functional team of data scientists, software engineers, machine learning engineers and product managers to deliver AI powered products that change how customers interact with their money.
Leverage a broad stack of technologies — Pytorch, AWS Ultraclusters, Hugging Face, LangChain, Lightning, VectorDBs, and more — to reveal the insights hidden within huge volumes of numeric and textual data.
Be the expert in Natural Language Processing (NLP) to harness the power of Large Language Models (LLMs), adapt and finetune them for customer facing applications and features.
Build machine learning and NLP models through all phases of development, from design through training, evaluation, and validation; partnering with engineering teams to operationalize them in scalable and resilient production systems that serve 80+ million customers.
Flex your interpersonal skills to translate the complexity of your work into tangible business goals.
The Ideal Candidate is:
Customer first. You love the process of analyzing and creating, but also share our passion to do the right thing. You know at the end of the day it’s about making the right decision for our customers.
Innovative. You continually research and evaluate emerging technologies. You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them.
Creative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You’re not afraid to share a new idea.
A leader. You challenge conventional thinking and work with stakeholders to identify and improve the status quo. You're passionate about talent development for your own team and beyond.
Technical. You’re comfortable with advanced ML and DL technologies including language models and are passionate about developing further. You have hands-on experience working with LLMs and solutions using open-source tools and cloud computing platforms.
Influential. You are passionate about AI/ML and can bring along a cross functional team in breakthrough innovations. You communicate clearly and effectively to share your findings with non-technical audiences.
You are experienced in training language models or large computer vision models as well as have expertise in one or more key subdomains such as: training optimization, self-supervised learning, explainability, RLHF.
You have an engineering mindset as shown by a track record of delivering models at scale both in training data and inference volumes. You have experience in delivering libraries, platforms, or solution level code to existing products.
Basic Qualifications:
Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:
A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 5 years of experience performing data analytics
A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 3 years of experience performing data analytics
A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field)
Preferred Qualifications:
Master’s Degree in “STEM” field (Science, Technology, Engineering, or Mathematics), or PhD in “STEM” field (Science, Technology, Engineering, or Mathematics)
Experience working with AWS
At least 3 years’ experience in Python, Scala, or R
At least 3 years’ experience with machine learning
At least 3 years’ experience with SQL
Capital One will consider sponsoring a new qualified applicant for employment authorization for this position.
The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.
McLean, VA: $158,600 - $181,000 for Princ Associate, Data Science
New York, NY: $173,000 - $197,400 for Princ Associate, Data Science
San Jose, CA: $173,000 - $197,400 for Princ Associate, Data Science
Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate’s offer letter.
This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.
Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website . Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.
This role is expected to accept applications for a minimum of 5 business days. No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

#J-18808-Ljbffr Capital One",2025-07-03T00:00:00.000Z,2025-07-25,"['You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them', 'You thrive on bringing definition to big, undefined problems', 'You love asking questions and pushing hard to find answers', 'You challenge conventional thinking and work with stakeholders to identify and improve the status quo', ""You're passionate about talent development for your own team and beyond"", 'You’re comfortable with advanced ML and DL technologies including language models and are passionate about developing further', 'You have hands-on experience working with LLMs and solutions using open-source tools and cloud computing platforms', 'Influential', 'You are passionate about AI/ML and can bring along a cross functional team in breakthrough innovations', 'You communicate clearly and effectively to share your findings with non-technical audiences', 'You are experienced in training language models or large computer vision models as well as have expertise in one or more key subdomains such as: training optimization, self-supervised learning, explainability, RLHF', 'You have an engineering mindset as shown by a track record of delivering models at scale both in training data and inference volumes', 'You have experience in delivering libraries, platforms, or solution level code to existing products', 'Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:', ""A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 5 years of experience performing data analytics"", ""A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 3 years of experience performing data analytics"", 'A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field)', 'Master’s Degree in “STEM” field (Science, Technology, Engineering, or Mathematics), or PhD in “STEM” field (Science, Technology, Engineering, or Mathematics)', 'Experience working with AWS', 'At least 3 years’ experience in Python, Scala, or R', 'At least 3 years’ experience with machine learning', 'At least 3 years’ experience with SQL']","['You will be the driving force to experiment, innovate and create next generation experiences powered by the latest emerging generative AI technologies', 'Partner with a cross-functional team of data scientists, software engineers, machine learning engineers and product managers to deliver AI powered products that change how customers interact with their money', 'Leverage a broad stack of technologies — Pytorch, AWS Ultraclusters, Hugging Face, LangChain, Lightning, VectorDBs, and more — to reveal the insights hidden within huge volumes of numeric and textual data', 'Be the expert in Natural Language Processing (NLP) to harness the power of Large Language Models (LLMs), adapt and finetune them for customer facing applications and features', 'Build machine learning and NLP models through all phases of development, from design through training, evaluation, and validation; partnering with engineering teams to operationalize them in scalable and resilient production systems that serve 80+ million customers', 'Flex your interpersonal skills to translate the complexity of your work into tangible business goals', 'You continually research and evaluate emerging technologies']",True,"['Large Language Models', 'Generative AI', 'PyTorch', 'Hugging Face', 'LangChain', 'Lightning', 'Vector Databases', 'Self-Supervised Learning', 'Reinforcement Learning from Human Feedback', 'Explainability']","Large Language Models: The job requires hands-on experience working with LLMs, including adapting, fine-tuning, and operationalizing them for customer-facing AI-powered products.; Generative AI: The role involves experimenting, innovating, and creating next-generation experiences powered by the latest emerging generative AI technologies.; PyTorch: PyTorch is used as part of the technology stack for building and training deep learning models, including language models.; Hugging Face: Hugging Face tools and libraries are leveraged to work with transformer models and facilitate NLP and generative AI development.; LangChain: LangChain is used to build AI-powered applications, particularly those involving language models and chaining multiple AI components.; Lightning: Lightning is used to streamline and scale deep learning model training and deployment.; Vector Databases: Vector databases are utilized to manage and search large volumes of numeric and textual data, supporting AI applications such as similarity search and embeddings.; Self-Supervised Learning: Expertise in self-supervised learning is required as a key subdomain for training language or vision models.; Reinforcement Learning from Human Feedback: Experience with RLHF is needed for improving model behavior and alignment in AI systems.; Explainability: Knowledge of explainability techniques is important for interpreting and validating AI and machine learning models.","['Machine Learning', 'Natural Language Processing', 'Python', 'Scala', 'R', 'SQL', 'AWS']","Machine Learning: The role involves building machine learning models through all phases of development, including design, training, evaluation, and validation, and operationalizing them in scalable production systems serving millions of customers.; Natural Language Processing: Expertise in NLP is required to harness Large Language Models, adapt and fine-tune them for customer-facing applications and features.; Python: Experience with Python is required for developing machine learning and data science solutions.; Scala: Experience with Scala is required for developing machine learning and data science solutions.; R: Experience with R is required for developing machine learning and data science solutions.; SQL: Experience with SQL is required for data analytics and managing relational databases.; AWS: Experience working with AWS cloud computing platform is required, including leveraging AWS Ultraclusters for scalable computing."
bOjFjfYsAwA58iRxAAAAAA==,Data Scientist Jobs,"Overview

DATA SCIENTIST (ARDAP):

Bowhead is seeking a Data Scientist for the upcomming Army Data and Analytics Platform (ARDAP) effort located at Fort Belvoir, VA. This is a fast paced job managing subject matter experts and IT professionals advising executive level personnel on financial, technical, and other high-level policy areas.

Responsibilities
• Lead development and implementation of analytics solutions to solve business problems and optimize mission execution.
• Define and develop techniques to integrate, consolidate, and structure data for analytical use.
• Research, analyze, and document technical approaches for desired outcomes.
• Provide guidance in applying appropriate algorithms, solutions, and data science techniques.
• Develop and implement a set of techniques or analytics applications to transform massive-scale data into actionable and meaningful information.
• Lead development, testing, and demonstration of analytics products.
• Design scalable algorithms utilizing large amounts of data and apply data mining, cluster analysis, statistical models, visualization, and machine learning to power data driven products and tools and provide useful insights.
• Enable automation of queries and build tools. Design and develop piping and processing of massive data streams to facilitate analysis.
• Develop graphical analysis to analyze and interpret data, update existing programs to reflect new business rules or policy changes, and develop customizable reports.
• Write scripts to integrate data, conduct exploratory data analysis to discover patterns, and apply machine learning to train predictive models.
• Have experience formulating recommendations and briefings and easily communicate complex ideas to high-level commanders/executives.
• Have experience serving as a data scientist on complex technology implementations, and experience in large data environments with an understanding of scaling algorithms between differing environments.

Qualifications
• MA/MS in Computer Science, Engineering, Mathematics, or related discipline or Equivalent
• Ten (10+) years of experience with programming languages such as Python and R; and querying languages such as SQL required
• Intermediate to advanced level skills in Microsoft Office software suite - Word, Excel, Outlook, PowerPoint
• Ability to communicate effectively with all levels of employees and outside contacts
• Strong interpersonal skills and good judgment with the ability to work alone or as part of a team

Physical Demands:
• Must be able to lift up to 25 pounds
• Must be able to stand and walk for prolonged amounts of time
• Must be able to twist, bend and squat periodically

SECURITY CLEARANCE REQUIREMENTS: Must currently hold a security clearance at the Secret level. US Citizenship is a requirement for Secret clearance at this location.

#LI-KC1",2025-07-25T01:00:00.000Z,2025-07-25,"['Have experience formulating recommendations and briefings and easily communicate complex ideas to high-level commanders/executives', 'Have experience serving as a data scientist on complex technology implementations, and experience in large data environments with an understanding of scaling algorithms between differing environments', 'MA/MS in Computer Science, Engineering, Mathematics, or related discipline or Equivalent', 'Ten (10+) years of experience with programming languages such as Python and R; and querying languages such as SQL required', 'Intermediate to advanced level skills in Microsoft Office software suite - Word, Excel, Outlook, PowerPoint', 'Ability to communicate effectively with all levels of employees and outside contacts', 'Strong interpersonal skills and good judgment with the ability to work alone or as part of a team', 'Must be able to lift up to 25 pounds', 'Must be able to stand and walk for prolonged amounts of time', 'Must be able to twist, bend and squat periodically', 'SECURITY CLEARANCE REQUIREMENTS: Must currently hold a security clearance at the Secret level', 'US Citizenship is a requirement for Secret clearance at this location']","['This is a fast paced job managing subject matter experts and IT professionals advising executive level personnel on financial, technical, and other high-level policy areas', 'Lead development and implementation of analytics solutions to solve business problems and optimize mission execution', 'Define and develop techniques to integrate, consolidate, and structure data for analytical use', 'Research, analyze, and document technical approaches for desired outcomes', 'Provide guidance in applying appropriate algorithms, solutions, and data science techniques', 'Develop and implement a set of techniques or analytics applications to transform massive-scale data into actionable and meaningful information', 'Lead development, testing, and demonstration of analytics products', 'Design scalable algorithms utilizing large amounts of data and apply data mining, cluster analysis, statistical models, visualization, and machine learning to power data driven products and tools and provide useful insights', 'Enable automation of queries and build tools', 'Design and develop piping and processing of massive data streams to facilitate analysis', 'Develop graphical analysis to analyze and interpret data, update existing programs to reflect new business rules or policy changes, and develop customizable reports', 'Write scripts to integrate data, conduct exploratory data analysis to discover patterns, and apply machine learning to train predictive models']",True,[],,"['Python', 'R', 'SQL', 'Machine Learning', 'Data Mining', 'Cluster Analysis', 'Statistical Models', 'Data Visualization', 'Data Integration', 'Exploratory Data Analysis', 'Data Pipelines']","Python: Used as a primary programming language for data science tasks including scripting, data integration, and model development.; R: Used as a primary programming language for statistical analysis and data science tasks.; SQL: Used for querying and managing data within large data environments.; Machine Learning: Applied to train predictive models and power data-driven products and tools.; Data Mining: Used to extract patterns and insights from large datasets to support analytics solutions.; Cluster Analysis: Applied as a statistical technique to group data points for analysis and insight generation.; Statistical Models: Designed and utilized to analyze data and support decision-making processes.; Data Visualization: Developed graphical analyses to interpret data and communicate insights effectively.; Data Integration: Involves scripting and techniques to consolidate and structure data for analytical use.; Exploratory Data Analysis: Conducted to discover patterns and inform the development of predictive models.; Data Pipelines: Designed and developed to process massive data streams and facilitate analysis."
W2DDfF5JErG6iCPKAAAAAA==,Data Scientist Jobs,"Title: Data Scientist
Location: Reston, Virginia
• Clearance: *Active TS/SCI w/ Polygraph needed to apply *

Company Overview:

Cornerstone Defense, in partnership with our military, intelligence, and civil government customers, supports U.S. operations worldwide through the use of many different types of intelligence, satellite, and cyber technologies. Cornerstone's Intelligence Sector provides solutions to the United States Government for information collection, operations, exploitation and dissemination, and research activities. Our Team specializes in software development, cloud architecture, systems and network engineering, systems integration, agile management, as well as targeting operations and intelligence analysis. Our support to our mission customers includes cyber network operations, exploitation and defense, signals intelligence, human intelligence, and critical missions and networks.

Job Description
Seeking a Data Scientist responsible for working closely with Client's Customer Engagement project teams to provide the customer with business analysis expertise, dashboard design in a tactical capacity, evaluate internal and external client requirements, and implement effective solutions in a timely manner.
The selected candidate will leverage their analytical skills and expertise in predictive analytics to extract insights from complex datasets and drive data-driven decision-making within our client's user community. They will collaborate closely with cross-functional teams to develop predictive models, uncover actionable insights, and solve challenging business problems.
Job Requirements:
• Must have an Active TS/SCI with polygraph ONLY all others need not apply.
• Analyze large, complex datasets to identify trends, patterns, and relationships.
• Conduct exploratory data analysis (EDA) to gain insights and formulate hypotheses.
• Utilize statistical methods and data visualization techniques to communicate findings effectively.
• Ability to consolidate, interpret, and present data in reports/dashboards for Executives, Team Leads, and Individual End Users focused on Acquisition and Financial Information.
• An analytical mindset that allows you to look at the data available and drive into meaningful insights for the end user(s).
• Ability to produce reports and dashboards using Microsoft Power BI, SSRS, and other data tools.
• Experience using SQL to create queries and general knowledge of SQL database structure/relational databases
• Ability to define and document customer business processes and report/dashboard content needs, including business process diagrams, data maps, and data modeling.
• Consult with project team members and customer stakeholders to identify, define, and document business needs and objectives, current reporting capabilities, and challenges related to the business functions, such as those supporting the Federal Acquisition Lifecycle.
• Collaborate with the Client project manager, technical analysts, and customer end-users in the analysis, design, configuration, testing, and maintenance of the Business Intelligence module of Client's AEON Business Process Management Platform to ensure desired operational performance and capabilities.
• Design and conduct experiments to test hypotheses and validate model assumptions.
• Implement A/B testing frameworks to evaluate the impact of changes and interventions.
• Analyze experimental results and provide recommendations for further optimization.
• Track and document changes for functional and business specifications; write detailed, universally understood procedures for testing use cases, knowledge capture, and training purposes.
• Achieve proficiency in all significant Client Reporting/Analytic products, including the AEON software suite, through internal staffing training, self-guided tutorials, and daily exposure to individual product feature sets.
• Provide support for various meetings, demonstrations, and program activities related to Business Intelligence.
• Test reports/dashboard projects following business and functional design following best practices for quality assurance.
• Record and track defects uncovered during test execution and assist in defect resolution (troubleshooting and researching).
• Comprehension of change management processes.
• Other duties as assigned.
Required Experience.
• 3+ years prior data scientist experience.
• Proven experience in data science, machine learning, or predictive analytics roles.
• Proficiency in programming languages commonly used in data science (e.g., SQL, Python, R, etc.).
• Ability to work in a team-oriented environment for a matrixed organization.
• Strong knowledge and experience with data reporting tools, including Microsoft PowerBI, SSRS, Tableau, etc.
• Strong knowledge of productivity tools like Microsoft Office (Word, Excel, Outlook).
• Experience with Agile and SCRUM processes and methodologies.
• Knowledge of software development life cycle (SDLC) practices, principles, and techniques as they apply to the Agile development process.
• Excellent verbal and written communication skills, proven ability to listen and relate to customers.
• Ability to effectively collaborate with internal and external customers.
• Demonstrated analytical and problem-solving capabilities.
• Proven ability to communicate technical details to a non-technical audience.
• Excellent organizational and time management skills.
• Strong team player who is always willing to help other team members.
Desired Experience :
• Bachelor's degree or relevant experience.
• Knowledge of SQL Databases and Query Creation
• Knowledge of the Federal Acquisition Lifecycle or commercial contracting.
• Knowledge of Federal financial systems or commercial accounting.
• Ability to develop and deploy predictive models using machine learning algorithms, optimize model performance, and evaluate model accuracy
• Experience with Federal government contracting and/or program office organization's business processes.",2025-07-25T13:00:00.000Z,2025-07-25,"['Must have an Active TS/SCI with polygraph ONLY all others need not apply', 'Ability to consolidate, interpret, and present data in reports/dashboards for Executives, Team Leads, and Individual End Users focused on Acquisition and Financial Information', 'An analytical mindset that allows you to look at the data available and drive into meaningful insights for the end user(s)', 'Ability to produce reports and dashboards using Microsoft Power BI, SSRS, and other data tools', 'Experience using SQL to create queries and general knowledge of SQL database structure/relational databases', 'Ability to define and document customer business processes and report/dashboard content needs, including business process diagrams, data maps, and data modeling', '3+ years prior data scientist experience', 'Proven experience in data science, machine learning, or predictive analytics roles', 'Proficiency in programming languages commonly used in data science (e.g., SQL, Python, R, etc.)', 'Ability to work in a team-oriented environment for a matrixed organization', 'Strong knowledge and experience with data reporting tools, including Microsoft PowerBI, SSRS, Tableau, etc', 'Strong knowledge of productivity tools like Microsoft Office (Word, Excel, Outlook)', 'Experience with Agile and SCRUM processes and methodologies', 'Knowledge of software development life cycle (SDLC) practices, principles, and techniques as they apply to the Agile development process', 'Excellent verbal and written communication skills, proven ability to listen and relate to customers', 'Ability to effectively collaborate with internal and external customers', 'Demonstrated analytical and problem-solving capabilities', 'Proven ability to communicate technical details to a non-technical audience', 'Excellent organizational and time management skills', 'Strong team player who is always willing to help other team members']","[""Seeking a Data Scientist responsible for working closely with Client's Customer Engagement project teams to provide the customer with business analysis expertise, dashboard design in a tactical capacity, evaluate internal and external client requirements, and implement effective solutions in a timely manner"", ""The selected candidate will leverage their analytical skills and expertise in predictive analytics to extract insights from complex datasets and drive data-driven decision-making within our client's user community"", 'They will collaborate closely with cross-functional teams to develop predictive models, uncover actionable insights, and solve challenging business problems', 'Analyze large, complex datasets to identify trends, patterns, and relationships', 'Conduct exploratory data analysis (EDA) to gain insights and formulate hypotheses', 'Utilize statistical methods and data visualization techniques to communicate findings effectively', 'Consult with project team members and customer stakeholders to identify, define, and document business needs and objectives, current reporting capabilities, and challenges related to the business functions, such as those supporting the Federal Acquisition Lifecycle', ""Collaborate with the Client project manager, technical analysts, and customer end-users in the analysis, design, configuration, testing, and maintenance of the Business Intelligence module of Client's AEON Business Process Management Platform to ensure desired operational performance and capabilities"", 'Design and conduct experiments to test hypotheses and validate model assumptions', 'Implement A/B testing frameworks to evaluate the impact of changes and interventions', 'Analyze experimental results and provide recommendations for further optimization', 'Track and document changes for functional and business specifications; write detailed, universally understood procedures for testing use cases, knowledge capture, and training purposes', 'Achieve proficiency in all significant Client Reporting/Analytic products, including the AEON software suite, through internal staffing training, self-guided tutorials, and daily exposure to individual product feature sets', 'Provide support for various meetings, demonstrations, and program activities related to Business Intelligence', 'Test reports/dashboard projects following business and functional design following best practices for quality assurance', 'Record and track defects uncovered during test execution and assist in defect resolution (troubleshooting and researching)', 'Comprehension of change management processes', 'Other duties as assigned']",True,[],,"['Predictive Analytics', 'Exploratory Data Analysis', 'Statistical Methods', 'A/B Testing', 'SQL', 'Data Visualization Tools', 'Business Intelligence', 'Data Modeling', 'Machine Learning', 'Programming Languages for Data Science', 'Agile and SCRUM Methodologies']","Predictive Analytics: Used to extract insights from complex datasets and drive data-driven decision-making within the client's user community.; Exploratory Data Analysis: Conducted to gain insights and formulate hypotheses from large, complex datasets.; Statistical Methods: Utilized to analyze data and communicate findings effectively through data visualization techniques.; A/B Testing: Implemented frameworks to evaluate the impact of changes and interventions, analyze experimental results, and provide recommendations for optimization.; SQL: Used to create queries and understand relational database structures for data extraction and analysis.; Data Visualization Tools: Includes Microsoft Power BI, SSRS, Tableau, and AEON Business Process Management Platform used to produce reports and dashboards for various stakeholders.; Business Intelligence: Involves analysis, design, configuration, testing, and maintenance of BI modules to ensure operational performance and capabilities.; Data Modeling: Defining and documenting customer business processes, report/dashboard content needs, business process diagrams, and data maps.; Machine Learning: Developing and deploying predictive models using machine learning algorithms, optimizing model performance, and evaluating model accuracy.; Programming Languages for Data Science: Proficiency in SQL, Python, and R used for data analysis, model development, and querying.; Agile and SCRUM Methodologies: Applied in the software development lifecycle to manage projects and collaborate effectively in a team-oriented environment."
yUD93sAbedo_NTVWAAAAAA==,Data Scientist (Senior) Jobs,"Data Scientist (Senior)

Location: Springfield, VA

TS/SCI REQUIRED

Position Responsibilities:
• Support NSG strategies through the creation of automated collection models, dynamic analytic models, workflow automations, and any other automation processes and products as assigned.
• Refine, enhance and improve the operational performance of any automated solution through the evaluation of performance data, regular customer interaction, and a standardized maintenance cycle.
• Apply data science and visual programming tradecraft to support and streamline analysis tasks as identified by stakeholders and the Government.
• Enhance technical solutions to problems related to IC intelligence integration, automated collections, tipping and cueing, information sharing, and visualization.
• Conduct extensive collections and analytic modeling, data processing,

Required Skills. Proficiency in common geospatial software applications and tools, such as visual programming (JEMA, FADE/MIST, ECO/ETAS), Python, SQL, Git, GIMS, AWS Sagemaker, AWS Cloud, ESRI ArcGIS, statistics (descriptive, Bayesian), Markov-Chain modelling, TensorFlow, Linear Algebra, R, SAS, NLP.",2025-07-25T01:00:00.000Z,2025-07-25,"['Proficiency in common geospatial software applications and tools, such as visual programming (JEMA, FADE/MIST, ECO/ETAS), Python, SQL, Git, GIMS, AWS Sagemaker, AWS Cloud, ESRI ArcGIS, statistics (descriptive, Bayesian), Markov-Chain modelling, TensorFlow, Linear Algebra, R, SAS, NLP']","['Support NSG strategies through the creation of automated collection models, dynamic analytic models, workflow automations, and any other automation processes and products as assigned', 'Refine, enhance and improve the operational performance of any automated solution through the evaluation of performance data, regular customer interaction, and a standardized maintenance cycle', 'Apply data science and visual programming tradecraft to support and streamline analysis tasks as identified by stakeholders and the Government', 'Enhance technical solutions to problems related to IC intelligence integration, automated collections, tipping and cueing, information sharing, and visualization', 'Conduct extensive collections and analytic modeling, data processing,']",True,"['TensorFlow', 'Natural Language Processing (NLP)']","TensorFlow: Used specifically as a deep learning framework to build and deploy neural network models supporting analytic tasks in intelligence workflows.; Natural Language Processing (NLP): Applied in the context of AI to process and analyze textual data for intelligence purposes, enhancing information extraction and understanding.","['Automated Collection Models', 'Dynamic Analytic Models', 'Workflow Automations', 'Visual Programming', 'Geospatial Software Applications', 'Python', 'SQL', 'Git', 'AWS Sagemaker', 'AWS Cloud', 'Statistics (Descriptive, Bayesian)', 'Markov-Chain Modelling', 'TensorFlow', 'Linear Algebra', 'R', 'SAS', 'Natural Language Processing (NLP)']","Automated Collection Models: Used to support NSG strategies by creating automated models for data collection and analysis to streamline intelligence workflows.; Dynamic Analytic Models: Developed to enhance operational performance and support intelligence analysis through adaptable and evolving data models.; Workflow Automations: Implemented to automate repetitive analysis tasks and improve efficiency in data processing and intelligence operations.; Visual Programming: Applied to support and streamline analysis tasks using tools such as JEMA, FADE/MIST, and ECO/ETAS for geospatial and intelligence data processing.; Geospatial Software Applications: Utilized tools like ESRI ArcGIS and GIMS to analyze and visualize geospatial intelligence data relevant to operational needs.; Python: Used for scripting, data processing, and building analytic models within the intelligence and geospatial context.; SQL: Employed for querying and managing structured data to support analytic modeling and data processing tasks.; Git: Used for version control and collaboration in developing data science and automation solutions.; AWS Sagemaker: Leveraged as a cloud-based platform to build, train, and deploy machine learning models supporting intelligence workflows.; AWS Cloud: Used to host and manage data science and analytic solutions in a scalable and secure cloud environment.; Statistics (Descriptive, Bayesian): Applied to analyze data distributions, inferential statistics, and probabilistic modeling to support analytic decision-making.; Markov-Chain Modelling: Used to model stochastic processes and predict sequences relevant to intelligence data analysis.; TensorFlow: Utilized as a framework for building and deploying machine learning models, including neural networks, to support analytic tasks.; Linear Algebra: Applied as a mathematical foundation for modeling and computations in data science and machine learning workflows.; R: Used for statistical analysis, data visualization, and building analytic models in support of intelligence operations.; SAS: Employed for advanced statistical analysis and data management within analytic modeling tasks.; Natural Language Processing (NLP): Applied to analyze and extract insights from textual intelligence data to support information sharing and decision-making."
Z2Vx-hBADY9ZO7y6AAAAAA==,"Senior Manager, Data Science - Model Risk Office","Senior Manager, Data Science - Model Risk Office
Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making.
As a Data Scientist at Capital One, you'll be part of a team that's leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives.
In Capital One's Model Risk Office, we defend the company against model failures and find new ways of making better decisions with models. We use our statistics, software engineering, and business expertise to drive the best outcomes in both Risk Management and the Enterprise. We understand that we can't prepare for tomorrow by focusing on today, so we invest in the future: investing in new skills, building better tools, and maintaining a network of trusted partners. We learn from past mistakes and develop increasingly powerful techniques to avoid their repetition.
In this role, you will:
• Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love
• Distill the details of complex interconnected modeling systems to influence senior business leaders on model strategy, business use, and risks
• Assess, challenge, and at times defend state-of-the-art decision-making systems to internal and regulatory partners
• Shape our practice of building machine learning models, from design through training, evaluation, validation, and implementation
• Oversee development of benchmark and challenger models to stress test critical modeling decisions

The Ideal Candidate is:
• Innovative. You continually research and evaluate emerging technologies. You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them.
• Creative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You're not afraid to share a new idea.
• Technical. You're comfortable with open-source languages and are passionate about developing further. You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms.
• Statistically-minded. You've built models, validated them, and backtested them. You know how to interpret a confusion matrix or a ROC curve. You have experience with clustering, classification, sentiment analysis, time series, and deep learning.

Basic Qualifications:
• Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:
• A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 7 years of experience performing data analytics
• A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 5 years of experience performing data analytics
• A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 2 years of experience performing data analytics
• At least 2 years of experience leveraging open source programming languages for large scale data analysis
• At least 2 years of experience working with machine learning
• At least 2 years of experience utilizing relational databases

Preferred Qualifications:
• PhD in ""STEM"" field (Science, Technology, Engineering, or Mathematics) plus 4 years of experience in data analytics
• At least 5 years of experience in Python, Scala, or R for large scale data analysis
• At least 5 years of experience with machine learning
• At least 1 year of experience working with AWS
• At least 1 year of experience managing people

Capital One will consider sponsoring a new qualified applicant for employment authorization for this position.
The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.
Chicago, IL: $204,900 - $233,800 for Sr Mgr, Data Science
McLean, VA: $225,400 - $257,200 for Sr Mgr, Data Science
Plano, TX: $204,900 - $233,800 for Sr Mgr, Data Science
Richmond, VA: $204,900 - $233,800 for Sr Mgr, Data Science
Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate's offer letter.
This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.
Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website . Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.
This role is expected to accept applications for a minimum of 5 business days.
No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City's Fair Chance Act; Philadelphia's Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.
If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com . All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.
For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com
Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.
Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",2025-07-18T00:00:00.000Z,2025-07-25,"['You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them', 'You thrive on bringing definition to big, undefined problems', 'You love asking questions and pushing hard to find answers', ""You're comfortable with open-source languages and are passionate about developing further"", 'You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms', 'Statistically-minded', 'You know how to interpret a confusion matrix or a ROC curve', 'You have experience with clustering, classification, sentiment analysis, time series, and deep learning', 'Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:', ""A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 7 years of experience performing data analytics"", ""A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 5 years of experience performing data analytics"", 'A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 2 years of experience performing data analytics', 'At least 2 years of experience leveraging open source programming languages for large scale data analysis', 'At least 2 years of experience working with machine learning', 'At least 2 years of experience utilizing relational databases']","['Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love', 'Distill the details of complex interconnected modeling systems to influence senior business leaders on model strategy, business use, and risks', 'Assess, challenge, and at times defend state-of-the-art decision-making systems to internal and regulatory partners', 'Shape our practice of building machine learning models, from design through training, evaluation, validation, and implementation', 'Oversee development of benchmark and challenger models to stress test critical modeling decisions', 'You continually research and evaluate emerging technologies', ""You've built models, validated them, and backtested them""]",True,[],,"['Statistical Modeling', 'Relational Databases', 'Machine Learning', 'Model Validation and Backtesting', 'Classification', 'Clustering', 'Sentiment Analysis', 'Time Series Analysis', 'Deep Learning', 'Open-Source Programming Languages', 'Cloud Computing Platforms', 'Confusion Matrix and ROC Curve Interpretation']","Statistical Modeling: Used to personalize credit card offers and drive data-driven decision-making in financial services.; Relational Databases: Utilized for managing and querying large-scale customer data to support analytics and model development.; Machine Learning: Applied in building, training, evaluating, validating, and implementing predictive models to improve decision-making and manage model risk.; Model Validation and Backtesting: Performed to assess model performance, ensure reliability, and defend models to internal and regulatory stakeholders.; Classification: Used as a modeling technique to categorize data, relevant for tasks such as risk assessment and customer segmentation.; Clustering: Employed to identify natural groupings in data, supporting exploratory data analysis and model development.; Sentiment Analysis: Applied to analyze textual data for understanding customer opinions or behaviors.; Time Series Analysis: Used to model and forecast data points collected or sequenced over time, relevant for financial and risk modeling.; Deep Learning: Implemented as part of advanced modeling techniques to capture complex patterns in data.; Open-Source Programming Languages: Languages such as Python, Scala, and R are used for large-scale data analysis and developing data science solutions.; Cloud Computing Platforms: Leveraged to support scalable data processing and model deployment environments.; Confusion Matrix and ROC Curve Interpretation: Techniques used to evaluate classification model performance and inform decision-making."
vELC56-lhnBwwds7AAAAAA==,Research Data Scientist,"APPLICATION INSTRUCTIONS:
• CURRENT PENN STATE EMPLOYEE (faculty, staff, technical service, or student), please login to Workday to complete the internal application process. Please do not apply here, apply internally through Workday.
• CURRENT PENN STATE STUDENT (not employed previously at the university) and seeking employment with Penn State, please login to Workday to complete the student application process. Please do not apply here, apply internally through Workday.
• If you are NOT a current employee or student, please click ""Apply"" and complete the application process for external applicants.

Approval of remote and hybrid work is not guaranteed regardless of work location. For additional information on remote work at Penn State, see Notice to Out of State Applicants.

This position is funded for 12 months; continuation past 12 months will be based on university need, performance, and/or availability of funding.

POSITION SPECIFICS

The Department of Biobehavioral Health in the College of Health and Human Development is seeking a Research Data Scientist. Under the direction of Dr. Idan Shalev, this position will work on federally funded projects and lead the development and execution of computational workflows to analyze longitudinal multi-omic data. This position will support the integration, quality control, and statistical analysis of transcriptomic, metabolomic, and epigenetic datasets across time, ensure methodological rigor in testing study hypotheses, and contribute to the generation of reproducible, high-quality research outputs.

What You'll Do:
• Develop and implement statistical models and data workflows for analysis of transcriptomic, metabolomic, and epigenetic data across three longitudinal timepoints.
• Conduct data integration and harmonization across multi-omic platforms, ensuring alignment with study protocols and cohort structures.
• Perform quality control and preprocessing of raw omics datasets, including normalization, batch correction, and outlier detection, generating usable datasets for future analyses.
• Generate publication-ready data visualizations and summary outputs for internal reporting, scientific publications, and grant progress updates.
• Contribute to manuscripts and conference abstracts by preparing methods and results sections in collaboration with the study team.
• Support onboarding and training of student researchers in computational methods and data management procedures.
• Document analytical pipelines and code to ensure reproducibility and adherence to open science best practices.

Skills You Have:
• Proficiency in statistical analysis and modeling, including longitudinal data analysis and mixed-effects models.
• Experience with multi-omic data analysis, including transcriptomic, metabolomic, and epigenetic datasets.
• Skill in data preprocessing, including normalization, batch correction, and outlier detection.
• Experience with data integration and harmonization across platforms and timepoints.
• Proficiency in programming languages commonly used in data science, such as R or Python.
• Ability to create publication-ready visualizations and summary outputs for diverse audiences.
• Experience contributing to scientific manuscripts and conference presentations, especially methods and results sections.
• Knowledge of reproducible research practices, including workflow documentation and version control (e.g., Git).
• Familiarity with research design and methodology, particularly in child development, maltreatment, or early life adversity.
• Strong problem-solving skills and ability to work independently within established research goals.
• Effective written and verbal communication skills for technical and collaborative work.
• Ability to train and support junior team members, including onboarding and mentoring student researchers.
• Experience working in interdisciplinary research teams.

Desired Qualifications:
• 1+ years of post-baccalaureate experience in statistical programming, bioinformatics, or data science, preferably in a research or academic setting.
• Demonstrated experience working with high-dimensional biological data such as transcriptomics, metabolomics, or epigenetics.
• Familiarity with longitudinal data analysis and reproducible research practices is expected.
• Experience working with data related to child development, child maltreatment, or early life adversity is strongly preferred.

Schedule:

This position is located on-site at the Pennsylvania State University in University Park, PA. Questions related to flexible work should be directed to the hiring manager during the interview process.

MINIMUM EDUCATION, WORK EXPERIENCE & REQUIRED CERTIFICATIONS
Bachelor's Degree1+ years of relevant experience; or an equivalent combination of education and experience acceptedRequired Certifications:None

Application Instructions

To apply, submit a cover letter, resume, and the contact information for three professional references. Review of applications will begin immediately and continue until the position is filled.

BACKGROUND CHECKS/CLEARANCES
Employment with the University will require successful completion of background check(s) in accordance with University policies.

Penn State does not sponsor or take over sponsorship of a staff employment Visa. Applicants must be authorized to work in the U.S.

SALARY & BENEFITS
The salary range for this position, including all possible grades, is $61,800.00 - $89,600.00.

Salary Structure - Information on Penn State's salary structure

Penn State provides a competitive benefits package for full-time employees designed to support both personal and professional well-being. In addition to comprehensive medical, dental, and vision coverage, employees enjoy robust retirement plans and substantial paid time off which includes holidays, vacation and sick time. One of the standout benefits is the generous 75% tuition discount, available to employees as well as eligible spouses and children. For more detailed information, please visit our Benefits Page.

CAMPUS SECURITY CRIME STATISTICS

Pursuant to the Jeanne Clery Disclosure of Campus Security Policy and Campus Crime Statistics Act and the Pennsylvania Act of 1988, Penn State publishes a combined Annual Security and Annual Fire Safety Report (ASR). The ASR includes crime statistics and institutional policies concerning campus security, such as those concerning alcohol and drug use, crime prevention, the reporting of crimes, sexual assault, and other matters. The ASR is available for review here.

EEO IS THE LAW

Penn State is an equal opportunity employer and is committed to providing employment opportunities to all qualified applicants without regard to race, color, religion, age, sex, sexual orientation, gender identity, national origin, disability or protected veteran status. If you are unable to use our online application process due to an impairment or disability, please contact .

The Pennsylvania State University is committed to and accountable for advancing equity, respect, and belonging. We embrace individual uniqueness, as well as a culture of belonging that supports equity initiatives, leverages the educational and institutional benefits of inclusion in society, and provides opportunities for engagement intended to help all members of the community thrive. We value belonging as a core strength and an essential element of the university's teaching, research, and service mission.

Federal Contractors Labor Law Poster

PA State Labor Law Poster

Penn State Policies

Copyright Information

Hotlines",2025-07-19T00:00:00.000Z,2025-07-25,"['This position is funded for 12 months; continuation past 12 months will be based on university need, performance, and/or availability of funding', 'Proficiency in statistical analysis and modeling, including longitudinal data analysis and mixed-effects models', 'Experience with multi-omic data analysis, including transcriptomic, metabolomic, and epigenetic datasets', 'Skill in data preprocessing, including normalization, batch correction, and outlier detection', 'Experience with data integration and harmonization across platforms and timepoints', 'Proficiency in programming languages commonly used in data science, such as R or Python', 'Ability to create publication-ready visualizations and summary outputs for diverse audiences', 'Experience contributing to scientific manuscripts and conference presentations, especially methods and results sections', 'Knowledge of reproducible research practices, including workflow documentation and version control (e.g., Git)', 'Familiarity with research design and methodology, particularly in child development, maltreatment, or early life adversity', 'Strong problem-solving skills and ability to work independently within established research goals', 'Effective written and verbal communication skills for technical and collaborative work', 'Ability to train and support junior team members, including onboarding and mentoring student researchers', 'Experience working in interdisciplinary research teams', 'Questions related to flexible work should be directed to the hiring manager during the interview process', 'MINIMUM EDUCATION, WORK EXPERIENCE & REQUIRED CERTIFICATIONS', ""Bachelor's Degree1+ years of relevant experience; or an equivalent combination of education and experience accepted"", 'Required Certifications:None', 'Employment with the University will require successful completion of background check(s) in accordance with University policies', 'Applicants must be authorized to work in the U.S']","['Under the direction of Dr. Idan Shalev, this position will work on federally funded projects and lead the development and execution of computational workflows to analyze longitudinal multi-omic data', 'This position will support the integration, quality control, and statistical analysis of transcriptomic, metabolomic, and epigenetic datasets across time, ensure methodological rigor in testing study hypotheses, and contribute to the generation of reproducible, high-quality research outputs', 'Develop and implement statistical models and data workflows for analysis of transcriptomic, metabolomic, and epigenetic data across three longitudinal timepoints', 'Conduct data integration and harmonization across multi-omic platforms, ensuring alignment with study protocols and cohort structures', 'Perform quality control and preprocessing of raw omics datasets, including normalization, batch correction, and outlier detection, generating usable datasets for future analyses', 'Generate publication-ready data visualizations and summary outputs for internal reporting, scientific publications, and grant progress updates', 'Contribute to manuscripts and conference abstracts by preparing methods and results sections in collaboration with the study team', 'Support onboarding and training of student researchers in computational methods and data management procedures', 'Document analytical pipelines and code to ensure reproducibility and adherence to open science best practices']",True,[],,"['Longitudinal Data Analysis', 'Mixed-Effects Models', 'Multi-Omic Data Analysis', 'Data Preprocessing', 'Data Integration and Harmonization', 'Statistical Modeling', 'Data Visualization', 'Reproducible Research Practices', 'Programming Languages for Data Science']","Longitudinal Data Analysis: Used to develop and implement statistical models analyzing transcriptomic, metabolomic, and epigenetic data across multiple timepoints in longitudinal studies.; Mixed-Effects Models: Applied as part of statistical modeling techniques to analyze longitudinal multi-omic datasets, accounting for both fixed and random effects.; Multi-Omic Data Analysis: Involves integration, quality control, and statistical analysis of transcriptomic, metabolomic, and epigenetic datasets across timepoints to support study hypotheses.; Data Preprocessing: Includes normalization, batch correction, and outlier detection performed on raw omics datasets to generate usable data for downstream analyses.; Data Integration and Harmonization: Conducted across multiple omic platforms and longitudinal timepoints to ensure alignment with study protocols and cohort structures.; Statistical Modeling: Development and implementation of models to analyze complex biological data, ensuring methodological rigor in hypothesis testing.; Data Visualization: Creation of publication-ready visualizations and summary outputs for internal reporting, scientific publications, and grant progress updates.; Reproducible Research Practices: Documentation of analytical pipelines and code, including workflow documentation and version control (e.g., Git), to ensure reproducibility and adherence to open science best practices.; Programming Languages for Data Science: Proficiency in R and Python used for statistical analysis, data preprocessing, and workflow development in multi-omic research."
F595o4pTxLpOHPEbAAAAAA==,Data Scientist - Senior Jobs,"Job Description

Why Choose Royce Geo, A GRVTY Company

We're not your typical government contracting company, nor do we want to be. At Royce Geo, A GRVTY Company, we live for building durable and long-lasting relationships with our clients, providing exceptional service with a CAN'T QUIT / WON'T QUIT attitude. We are creating a culture of winning, optimism, FUN, and caring for the person next to you. If you want to work in a real team environment and share the wealth and satisfaction of providing real value to your customer, then this company may be just for you.

Royce Geo, A GRVTY Company, prides ourselves in our values-first approach. Our values of Accountability, Attitude, Communication, Innovation, and Leadership are integrated into how we approach problems, guide our interactions with others, and create the framework for our culture. We recognize and reward our team members that champion these attributes.

We offer a competitive benefit package that is designed to attract and retain exceptional talent. We take care of our team members from multiple facets including health, financial, and well-being programs:
• Robust health plan including medical, dental, and vision
• Health Savings Account with company contribution
• Annual Paid Time Off and Paid Holidays
• Paid Parental Leave
• 401k with generous company match
• Training and Development Opportunities
• Award Programs
• Variety of Company Sponsored Events
• **Requires an active TS/SCI Security Clearance****

Position Summary:

We are looking for a Senior Data Scientist, with experience processing and analyzing large datasets, who will use their technical knowledge, experience, and customer-centric focus to create and deliver world-class analytic processes, scripting solutions, and data modeling content. This is a mission-driven opportunity to support the DoD and Intelligence Community.

The Data Scientist will coordinate with our clients to understand questions and issues involving the client's datasets, then determine the best method and approach to create data-driven solutions within program guidelines. This position will be relied upon as a Subject Matter Expert (SME), and be expected to lead/assist in the development of automated processes, architect data science solutions, automated workflows, conduct analysis, use available tools to analyze data, remain adaptable to mission requirements, and identify patterns to help solve some of the complex problems that face the DoD and Intelligence Community (IC).

Responsibilities
• Work with large structured / unstructured data in a modeling and analytical environment to define and create streamline processes in the evaluation of unique datasets and solve challenging intelligence issues
• Lead and participate in the design of solutions and refinement of pre-existing processes
• Work with Customer Stakeholders, Program Managers, and Product Owners to translate road map features into components/tasks, estimate timelines, identify resources, suggest solutions, and recognize possible risks
• Use exploratory data analysis techniques to identify meaningful relationships, patterns, or trends from complex data
• Combine applied mathematics, programming skills, analytical techniques, and data to provide impactful insights for decision makers
• Research and implement optimization models, strategies, and methods to inform data management activities and analysis
• Apply big data analytic tools to large, diverse sets of data to deliver impactful insights and assessments
• Conduct peer reviews to improve quality of workflows, procedures, and methodologies
• Help build high-performing teams; mentor team members providing development opportunities to increase their technical skills and knowledge

Required Qualifications:
• Active TS/SCI Clearance with ability to obtain a CI Poly
• 10+ years of relevant experience. (A combination of years of experience & professional certifications/trainings can be used in lieu of years of experience)
• Experience supporting IC operations
• Possess expert level knowledge to manipulate and analyze structured/ unstructured data
• Demonstrated experience in data mining and developing/maintaining/manipulating databases
• Demonstrated experience in identifying potential systems enhancements, new capabilities, concept demonstrators, and capability business cases
• Demonstrated experience using GOTS data processing and analytics capabilities to modernize analytic methodologies
• Demonstrated experience using COTS statistical software (Map Large, Tableau, MatLab) for advanced statistical analysis of operational tools and data visualization which enables large datasets to be interrogated and allows for patterns, relationships, and anticipatory behavioral likelihoods that may not be apparent using traditional single discipline means
• Knowledge of advanced analytic methodologies, and experience in implementing and executing those methodologies to enable customer satisfaction
• Demonstrated experience in directing activities of highly skilled technical and analytical teams responsible for developing solutions to highly complex analytical/intelligence problems
• Experienced in conducting multi-INT and technology specific research to support mission operations
• Possess effective communications skills; capable of providing highlydetailed information in an easy-to-understand format

Desired Qualifications:
• Possess Master's degree in Data Scienceor related technical field
• Experience developing and working with Artificial Intelligence and Machine Learning (AI/ML)
• Demonstrated experience of advanced programming techniques, using one or more of the following: HTML 5/Javascript, ArcObjects, Python, Model Builder, Oracle, SQL, GIScience, GeospatiavAnalysis, Statistics, ArcGIS Desktop, ArcGIS Server, Arc SDE, ArcIMS.
• Experience using NET, Python, C++, and/or JAVA programming for web interface development and geodatabase development.
• Experience building and maintaining databases of GEOINT, SIGINT, or OSINT data related to the area of interest needs.
• Data Visualization Experience which may include Matrix Analytics, Network Analytics, Graphing Data that assist the analytical workforce in generating common operational pictures depicting fused intelligence and information to support informal assessments and finished products

EEO Statement

Royce Geo, A GRVTY Company, is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran and will not be discriminated against on the basis of disability.

Anyone requiring reasonable accommodations should email recruiting@grvty.com or call 703-544-7930 with requested details. A member of the HR team will respond to your request within 2 business days.

Know Your Rights: Workplace Discrimination is Illegal (eeoc.gov)

Datascientist2025

About Royce Geo

Established in 2015, Royce Geo has quickly evolved into a well-rounded, diverse, small business tackling some of the most complex issues for our Defense and Intelligence Community clients. We are an award-winning small business firm, providing vital support to our mission partners across four core areas: Geospatial Information Technology, Data Analytics, Intelligence, and Training.

Our team members are highly skilled subject matter experts, who listen and partner with our clients to accomplish the mission. We own the problem and find the solution while upholding the highest standards-to exceed expectations. We take risks and challenge the status quo to deliver innovative and cutting-edge solutions.

Our employee-centric company culture is everything. Even while we grow, our small company mentality continues to exist. We demand inspiration from our leadership, and accountability from all so that we can influence others through our actions. This is Royce Geo.",2025-07-25T00:00:00.000Z,2025-07-25,"['**Requires an active TS/SCI Security Clearance****', 'We are looking for a Senior Data Scientist, with experience processing and analyzing large datasets, who will use their technical knowledge, experience, and customer-centric focus to create and deliver world-class analytic processes, scripting solutions, and data modeling content', 'Active TS/SCI Clearance with ability to obtain a CI Poly', '10+ years of relevant experience', '(A combination of years of experience & professional certifications/trainings can be used in lieu of years of experience)', 'Experience supporting IC operations', 'Possess expert level knowledge to manipulate and analyze structured/ unstructured data', 'Demonstrated experience in data mining and developing/maintaining/manipulating databases', 'Demonstrated experience in identifying potential systems enhancements, new capabilities, concept demonstrators, and capability business cases', 'Demonstrated experience using GOTS data processing and analytics capabilities to modernize analytic methodologies', 'Demonstrated experience using COTS statistical software (Map Large, Tableau, MatLab) for advanced statistical analysis of operational tools and data visualization which enables large datasets to be interrogated and allows for patterns, relationships, and anticipatory behavioral likelihoods that may not be apparent using traditional single discipline means', 'Knowledge of advanced analytic methodologies, and experience in implementing and executing those methodologies to enable customer satisfaction', 'Demonstrated experience in directing activities of highly skilled technical and analytical teams responsible for developing solutions to highly complex analytical/intelligence problems', 'Experienced in conducting multi-INT and technology specific research to support mission operations', 'Possess effective communications skills; capable of providing highlydetailed information in an easy-to-understand format']","[""The Data Scientist will coordinate with our clients to understand questions and issues involving the client's datasets, then determine the best method and approach to create data-driven solutions within program guidelines"", 'This position will be relied upon as a Subject Matter Expert (SME), and be expected to lead/assist in the development of automated processes, architect data science solutions, automated workflows, conduct analysis, use available tools to analyze data, remain adaptable to mission requirements, and identify patterns to help solve some of the complex problems that face the DoD and Intelligence Community (IC)', 'Work with large structured / unstructured data in a modeling and analytical environment to define and create streamline processes in the evaluation of unique datasets and solve challenging intelligence issues', 'Lead and participate in the design of solutions and refinement of pre-existing processes', 'Work with Customer Stakeholders, Program Managers, and Product Owners to translate road map features into components/tasks, estimate timelines, identify resources, suggest solutions, and recognize possible risks', 'Use exploratory data analysis techniques to identify meaningful relationships, patterns, or trends from complex data', 'Combine applied mathematics, programming skills, analytical techniques, and data to provide impactful insights for decision makers', 'Research and implement optimization models, strategies, and methods to inform data management activities and analysis', 'Apply big data analytic tools to large, diverse sets of data to deliver impactful insights and assessments', 'Conduct peer reviews to improve quality of workflows, procedures, and methodologies', 'Help build high-performing teams; mentor team members providing development opportunities to increase their technical skills and knowledge']",True,['Artificial Intelligence and Machine Learning'],Artificial Intelligence and Machine Learning: Experience developing and working with AI/ML technologies to enhance data science solutions and support mission requirements within the Intelligence Community.,"['Data Mining', 'Data Modeling', 'Exploratory Data Analysis', 'Optimization Models', 'Big Data Analytics', 'Advanced Statistical Analysis', 'Data Visualization', 'Database Development and Maintenance', 'Programming Languages for Data Science', 'Geospatial Analysis and GIS Tools', 'Applied Mathematics and Analytical Techniques', 'Data Pipelines and Automated Workflows']","Data Mining: Used to extract and analyze patterns from large structured and unstructured datasets to support intelligence and operational decision-making.; Data Modeling: Creating data models and scripting solutions to represent and analyze complex datasets for the DoD and Intelligence Community.; Exploratory Data Analysis: Applying techniques to identify meaningful relationships, patterns, or trends from complex data to inform decision makers.; Optimization Models: Researching and implementing optimization strategies and methods to improve data management and analytical processes.; Big Data Analytics: Applying big data analytic tools to large, diverse datasets to deliver impactful insights and assessments relevant to mission operations.; Advanced Statistical Analysis: Using commercial off-the-shelf (COTS) statistical software such as Map Large, Tableau, and MatLab for advanced analysis and data visualization to interrogate large datasets and identify patterns and behavioral likelihoods.; Data Visualization: Creating visual representations of data including matrix analytics, network analytics, and graphing to support analytical workforce and intelligence assessments.; Database Development and Maintenance: Developing, maintaining, and manipulating databases, including geodatabases related to GEOINT, SIGINT, or OSINT data to support area of interest needs.; Programming Languages for Data Science: Using programming languages such as Python, SQL, C++, Java, HTML5, and JavaScript for data processing, web interface development, and geospatial analysis.; Geospatial Analysis and GIS Tools: Applying GIScience and geospatial analysis techniques using tools like ArcGIS Desktop, ArcGIS Server, Arc SDE, ArcIMS, ArcObjects, and Model Builder to analyze geospatial intelligence data.; Applied Mathematics and Analytical Techniques: Combining applied mathematics with programming and analytical methods to provide impactful insights for decision makers.; Data Pipelines and Automated Workflows: Leading and assisting in the development of automated processes and workflows to streamline data science solutions and analytical methodologies."
JIwW_VAAwcd4PSYNAAAAAA==,Data Analyst Jobs,"Overview

We are looking for a Data Analyst to work with our team and our clients to architect and develop data models, data warehouses, lakes, and lakehouses, data governance, services, and pipelines. We are looking for more than just a ""Data Analyst"", but a technologist with excellent communication and customer service skills and a passion for data and problem solving.

Contributions
• Work on migration of data environments with performance and reliability
• Assess, understand, and document data sources
• Address technical inquiries concerning customization, integration, enterprise architecture and general feature / functionality of data products
• Experience working with database / data warehouse solutions in cloud (Preferably GCP. Alternatively Azure, AWS)
• Key must have skill sets - data modeling, data understanding
• You will be part of our Data Exploitation Practice!

Qualifications
• Ability to hold a position of public trust with the US government.
• Bachelor's degree in computer science, information systems, engineering, business, or a scientific or technical discipline
• 0-2 years of experience with data model and date warehouse design, including schema design and entity relationship diagrams
• 0-2 years of experience collaborating with management, personas, and engineers to support data quality efforts
• Experience with large-scale data migration
• Experience designing storage and retrieval solutions for both structured and unstructured data, in support of data science pipelines
• Experience designing data platforms for user consumption
• Experience supporting the development of related data artifacts
• Data Dictionary
• Entity Relationship Diagrams
• Data Flow Diagram
• Data Quality Plan
• Data Management Plan
• Data Asset Catalog
• Experience with relational SQL and NoSQL databases
• Familiarity with cloud technology, using AWS, Azure, or GCP. Knowledge of managed service offerings (e.g. AWS EC2, EMR, RDS, Redshift)
• Experience developing specifications for modern large-scale data repositories including development of specifications for cloud-based database solutions
• Familiarity with FIPS 140-2 compliant encryption to both stored data and data in motion
• Understand customer requirements and prioritize for maximum customer / user experience
• Experience working with software and data science teams to operationalize information
• Experience collaborating with staff, IT customers, and other technical and non-technical staff and contractors at all levels
• Experience working in an agile environment
• Experience working with BigQuery and Looker

About steampunk

Steampunk relies on several factors to determine salary, including but not limited to geographic location, contractual requirements, education, knowledge, skills, competencies, and experience. The projected compensation range for this position is $50,000 to $115,000. The estimate displayed represents a typical annual salary range for this position. Annual salary is just one aspect of Steampunk's total compensation package for employees. Learn more about additional Steampunk benefits here.

Identity Statement

As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud.

Steampunk is a Change Agent in the Federal contracting industry, bringing new thinking to clients in the Homeland, Federal Civilian, Health and DoD sectors. Through our Human-Centered delivery methodology, we are fundamentally changing the expectations our Federal clients have for true shared accountability in solving their toughest mission challenges. As an employee owned company, we focus on investing in our employees to enable them to do the greatest work of their careers - and rewarding them for outstanding contributions to our growth. If you want to learn more about our story, visit http://www.steampunk.com .

We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law. Steampunk participates in the E-Verify program.",2025-07-25T00:00:00.000Z,2025-07-25,"['We are looking for more than just a ""Data Analyst"", but a technologist with excellent communication and customer service skills and a passion for data and problem solving', 'Experience working with database / data warehouse solutions in cloud (Preferably GCP', 'Alternatively Azure, AWS)', 'Key must have skill sets - data modeling, data understanding', 'Ability to hold a position of public trust with the US government', ""Bachelor's degree in computer science, information systems, engineering, business, or a scientific or technical discipline"", '0-2 years of experience with data model and date warehouse design, including schema design and entity relationship diagrams', '0-2 years of experience collaborating with management, personas, and engineers to support data quality efforts', 'Experience with large-scale data migration', 'Experience designing storage and retrieval solutions for both structured and unstructured data, in support of data science pipelines', 'Experience designing data platforms for user consumption', 'Experience supporting the development of related data artifacts', 'Data Dictionary', 'Entity Relationship Diagrams', 'Data Flow Diagram', 'Data Quality Plan', 'Data Management Plan', 'Data Asset Catalog', 'Experience with relational SQL and NoSQL databases', 'Familiarity with cloud technology, using AWS, Azure, or GCP', 'Knowledge of managed service offerings (e.g', 'AWS EC2, EMR, RDS, Redshift)', 'Experience developing specifications for modern large-scale data repositories including development of specifications for cloud-based database solutions', 'Familiarity with FIPS 140-2 compliant encryption to both stored data and data in motion', 'Understand customer requirements and prioritize for maximum customer / user experience', 'Experience working with software and data science teams to operationalize information', 'Experience collaborating with staff, IT customers, and other technical and non-technical staff and contractors at all levels', 'Experience working in an agile environment', 'Experience working with BigQuery and Looker']","['We are looking for a Data Analyst to work with our team and our clients to architect and develop data models, data warehouses, lakes, and lakehouses, data governance, services, and pipelines', 'Work on migration of data environments with performance and reliability', 'Assess, understand, and document data sources', 'Address technical inquiries concerning customization, integration, enterprise architecture and general feature / functionality of data products', 'You will be part of our Data Exploitation Practice!']",True,[],,"['Data Modeling', 'Data Warehouses and Lakes', 'Data Governance', 'Data Pipelines', 'Data Migration', 'Data Quality Management', 'Data Artifacts', 'Relational SQL and NoSQL Databases', 'Cloud Data Platforms', 'Data Security and Encryption', 'Data Science Pipelines', 'Business Intelligence Tools', 'Agile Methodology']","Data Modeling: Involves architecting and developing data models, including schema design and entity relationship diagrams, to support data warehouses, lakes, and lakehouses.; Data Warehouses and Lakes: Designing and developing large-scale data repositories such as data warehouses, lakes, and lakehouses for structured and unstructured data storage and retrieval.; Data Governance: Implementing data governance practices to ensure data quality, security, and compliance within data platforms and pipelines.; Data Pipelines: Developing and maintaining data pipelines to support data migration, integration, and operationalization of data for analytics and data science teams.; Data Migration: Managing large-scale migration of data environments with a focus on performance and reliability.; Data Quality Management: Collaborating with management and engineers to support data quality efforts, including development of data quality plans and data management plans.; Data Artifacts: Supporting the development of data artifacts such as data dictionaries, data asset catalogs, and data flow diagrams to document and manage data assets.; Relational SQL and NoSQL Databases: Experience working with both relational SQL and NoSQL databases to design storage and retrieval solutions for diverse data types.; Cloud Data Platforms: Designing and developing cloud-based data platforms using managed services from AWS, Azure, or GCP, including services like AWS EC2, EMR, RDS, Redshift, and Google BigQuery.; Data Security and Encryption: Applying FIPS 140-2 compliant encryption standards to protect data at rest and in motion within data platforms.; Data Science Pipelines: Designing storage and retrieval solutions that support data science pipelines and operationalization of information.; Business Intelligence Tools: Experience working with BI tools such as Looker to enable user consumption and visualization of data.; Agile Methodology: Working in an agile environment to collaborate effectively with technical and non-technical stakeholders at all levels."
FSq23doT5Q3_l8m3AAAAAA==,Senior Data Scientist  Marketing Mix Modeling (MMM),"Job Title: Senior Data Scientist Marketing Mix Modeling (MMM)

Type: Contract
Work Hours: Must work in PST time zone
Location: Remote (Canada)

Role Overview

We are hiring two Senior Data Scientists with strong hands-on experience in Marketing Mix Modeling (MMM). The ideal candidate will have deep statistical expertise, solid Python and SQL skills, and the ability to translate modeling insights into business strategy. Experience working with large-scale retail or CPG marketing data is preferred.

Key Responsibilities
• Build, validate, and interpret MMM models to quantify channel effectiveness
• Develop actionable insights and present optimization recommendations to stakeholders
• Integrate internal and external data sources into unified MMM datasets
• Use Python for modeling and SQL for data extraction and transformation
• Collaborate closely with marketing, finance, and analytics teams

Required Qualifications
• 5 7+ years of experience in data science or marketing analytics
• Minimum 2 years of deep, hands-on MMM experience (Bayesian or Frequentist preferred)
• Proficient in Python (pandas, statsmodels, PyMC3 or similar)
• Strong SQL skills for querying and transforming large datasets
• Excellent communication and visualization skills to explain technical insights to business users
• Retail/media/CPG experience highly desirable",2025-07-09T00:00:00.000Z,2025-07-25,"['The ideal candidate will have deep statistical expertise, solid Python and SQL skills, and the ability to translate modeling insights into business strategy', '5 7+ years of experience in data science or marketing analytics', 'Proficient in Python (pandas, statsmodels, PyMC3 or similar)', 'Strong SQL skills for querying and transforming large datasets', 'Excellent communication and visualization skills to explain technical insights to business users']","['Work Hours: Must work in PST time zone', 'Build, validate, and interpret MMM models to quantify channel effectiveness', 'Develop actionable insights and present optimization recommendations to stakeholders', 'Integrate internal and external data sources into unified MMM datasets', 'Use Python for modeling and SQL for data extraction and transformation', 'Collaborate closely with marketing, finance, and analytics teams']",True,[],,"['Marketing Mix Modeling', 'Bayesian Modeling', 'Frequentist Modeling', 'Python', 'SQL', 'Data Integration', 'Data Visualization']","Marketing Mix Modeling: Build, validate, and interpret Marketing Mix Models to quantify channel effectiveness and integrate internal and external data sources into unified datasets for analysis.; Bayesian Modeling: Apply Bayesian statistical methods in Marketing Mix Modeling to enhance model accuracy and inference.; Frequentist Modeling: Use Frequentist statistical approaches in Marketing Mix Modeling for model development and validation.; Python: Utilize Python programming language, including libraries such as pandas, statsmodels, and PyMC3, for data manipulation, statistical modeling, and analysis.; SQL: Employ SQL skills for querying, extracting, and transforming large datasets to support modeling and analysis.; Data Integration: Combine internal and external data sources into unified datasets to support comprehensive Marketing Mix Modeling.; Data Visualization: Create visualizations to communicate technical insights and optimization recommendations effectively to business stakeholders."
qpj3zaGyt6CCKKexAAAAAA==,"Director, Data Scientist – Apollo/Card Data","Director, Data Scientist - Apollo/Card Data Join to apply for the Director, Data Scientist - Apollo/Card Data role at Capital One Director, Data Scientist - Apollo/Card Data Join to apply for the Director, Data Scientist - Apollo/Card Data role at Capital One Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making. As a Data Scientist at Capital One, you’ll be part of a team that’s leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives. Team Description Apollo (part of Card DMDC) is Capital One’s one stop shop for authoritative, 360 degree information on US businesses. We are on a mission to build a market leading, business critical Business Data Product and Platform that gives our customers a competitive advantage through information. Our customers rely on Apollo’s data and capabilities to market, sell, verify, underwrite, serve, and protect business customers, often in real-time intelligent ways. Business data is a complex, multi-billion dollar problem that is poorly served by legacy providers. We are tackling this critical opportunity by acquiring and processing massive amounts of data, leveraging cutting-edge ML/AI to resolve identity and predict valuable features and architecting interfaces that allow our users to seamlessly integrate Apollo into their workflows Data Science is at the heart of Apollo and this role will have an opportunity to shape the next generation of capabilities. Role Description In this role, you will: Lead a team of data scientists and collaborate with machine learning engineers, data engineers, business analysts and product managers to deliver product(s) customers love. Lead machine learning and data science technical direction and execution (operations, governance, processes and practice) working closely with product management to craft a roadmap and success criterion. Lean on your deep technical background in graph-based machine learning, deep learning, software engineering and algorithm development to organize, grow and manage the ML/AI capabilities for the product. Flex your interpersonal skills to translate the complexity of your work into tangible business goals The Ideal Candidate is: Technical Innovator. You have a strong background in ML/AI and engineering practices with experience in Entity Resolution, Information Retrieval, Graph-based ML, LLM/Embeddings or Deep Learning. You have hands-on experience developing effective data science solutions, while pushing the envelope with state-of-the-art techniques. Customer-back. Product mindset. You are deeply curious about customer needs and bring a product mindset to drive business results, integrating ML/AI design, engineering and execution. You identify high-leverage efforts and the necessary trade-offs to shape a roadmap that balances transformative innovation with time-to-value and pragmatism. Empathetic People Leader. You establish a culture of inclusiveness, cooperation and candor. You’re passionate about talent development, provide frequent actionable feedback to team members, and promote innovation Strategic Thinker and Communicator. You love asking questions and pushing hard for answers. You challenge conventional thinking and work with stakeholders to identify and improve the status quo by bringing clarity to big, undefined problems.You set the team vision, and inspire your team and peers to execute towards it. Basic Qualifications: Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date : A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 9 years of experience performing data analytics A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 7 years of experience performing data analytics A PHD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 4 years of experience performing data analytics At least 4 years of experience leveraging open source programming languages for large scale data analysis At least 4 years of experience working with machine learning At least 4 years of experience utilizing relational databases Preferred Qualifications: PhD in “STEM” field (Science, Technology, Engineering, or Mathematics) plus 5 years of experience in data analytics At least 1 year of experience working with AWS At least 3 year of experience managing people At least 5 years of experience in Python, Scala, or R for large scale data analysis At least 5 years of experience with machine learning Capital One will consider sponsoring a new qualified applicant for employment authorization for this position. The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. McLean, VA: $263,900 - $301,200 for Dir, Data Science New York, NY: $287,800 - $328,500 for Dir, Data Science Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate’s offer letter. This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan. Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. This role is expected to accept applications for a minimum of 5 business days. No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC). Seniority level Seniority level Director Employment type Employment type Full-time Job function Job function Other Referrals increase your chances of interviewing at Capital One by 2x Get notified about new Director jobs in New York, NY . New York, NY $120,000.00-$170,000.00 3 weeks ago New York, NY $130,000.00-$160,000.00 1 month ago New York, NY $132,000.00-$152,000.00 2 weeks ago Brooklyn, NY $150,000.00-$180,000.00 1 week ago New York City Metropolitan Area $175,000.00-$200,000.00 1 week ago New York, NY $138,500.00-$200,800.00 1 week ago New York, NY $170,000.00-$190,000.00 4 days ago Fairfield, NJ $150,000.00-$170,000.00 2 weeks ago Marketing Director/Director of Commercial Brand Strategy Brooklyn, NY $150,000.00-$175,000.00 7 hours ago New York City Metropolitan Area $200,400.00-$333,960.00 2 days ago Manhattan, NY $149,133.00-$195,000.00 3 days ago New York, NY $130,000.00-$200,000.00 1 month ago New York, NY $189,600.00-$260,700.00 1 week ago New York, NY $173,432.42-$204,968.58 1 week ago New York, NY $200,000.00-$240,000.00 1 month ago New York, NY $189,600.00-$260,700.00 1 week ago New York, NY $170,000.00-$190,000.00 3 weeks ago New York, NY $160,000.00-$175,000.00 4 days ago General Manager / Center Director / Fitness Director / Personal East Rutherford, NJ $14,400.00-$90,000.00 1 month ago New York, NY $350,000.00-$385,000.00 1 week ago Director of Brand Marketing - Color & Conservation New York, NY $165,000.00-$180,000.00 4 days ago New York, NY $120,000.00-$220,000.00 1 year ago New York City Metropolitan Area $110,000.00-$115,000.00 1 week ago New York, NY $110,000.00-$130,000.00 6 days ago New York City Metropolitan Area $208,920.00-$348,000.00 2 weeks ago New York, NY $147,000.00-$205,000.00 2 weeks ago We’re unlocking community knowledge in a new way. Experts add insights directly into each article, started with the help of AI. #J-18808-Ljbffr",2025-07-16T00:00:00.000Z,2025-07-25,,,True,"['Large Language Models', 'Embeddings']",Large Language Models: Experience with LLMs and embeddings is required to enhance ML/AI capabilities and support advanced AI-driven features in the Apollo product.; Embeddings: Used in conjunction with LLMs to improve entity resolution and information retrieval within the AI/ML framework.,"['Statistical Modeling', 'Relational Databases', 'Machine Learning', 'Graph-based Machine Learning', 'Deep Learning', 'Algorithm Development', 'Data Analytics', 'Open Source Programming Languages', 'Entity Resolution', 'Information Retrieval', 'Data Science Solutions', 'Data Pipelines']","Statistical Modeling: Used to personalize credit card offers and drive data-driven decision-making at scale across billions of customer records.; Relational Databases: Utilized for managing and querying structured business data critical to the Apollo platform.; Machine Learning: Applied to resolve identity, predict valuable features, and build business data products that provide competitive advantages.; Graph-based Machine Learning: A core technical area leveraged for entity resolution and information retrieval within the Apollo product.; Deep Learning: Used alongside graph-based ML and algorithm development to advance ML/AI capabilities for business data products.; Algorithm Development: Involved in creating advanced algorithms to support ML/AI solutions and product features.; Data Analytics: Performed extensively by the candidate, including large scale data analysis using open source programming languages.; Open Source Programming Languages: Used for large scale data analysis, including Python, Scala, or R.; Entity Resolution: A key ML/AI technique applied to identify and link business entities accurately within large datasets.; Information Retrieval: Employed to enhance data access and usability in the Apollo platform.; Data Science Solutions: Developed to push the envelope with state-of-the-art techniques and deliver impactful business results.; Data Pipelines: Architected to acquire and process massive amounts of business data efficiently for real-time intelligent applications."
rb-LZhza9xIgTYTaAAAAAA==,"Senior Data Scientist, AI Foundations","Senior Data Scientist, AI Foundations

Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making.

As a Data Scientist at Capital One, you’ll be part of a team that’s leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives.

Team Description

AI Foundations Specialist Models Data Science team builds and ships state of the art scalable architecture, AI/ML solutions for Capital One’s award-winning mobile app. We partner with product, tech and design teams to deliver app features that delight customers with dynamic and personalized experiences, enable them to chat with Capital One’s digital assistant Eno, or search for useful contents. You will be the driving force to experiment, innovate and create next generation experiences powered by the latest emerging generative AI technologies.

In this role, you will:
• Partner with a cross-functional team of data scientists, software engineers, machine learning engineers and product managers to deliver AI powered products that change how customers interact with their money.
• Leverage a broad stack of technologies — Pytorch, AWS Ultraclusters, Hugging Face, LangChain, Lightning, VectorDBs, and more — to reveal the insights hidden within huge volumes of numeric and textual data.
• Be the expert in Natural Language Processing (NLP) to harness the power of Large Language Models (LLMs), adapt and finetune them for customer facing applications and features.
• Build machine learning and NLP models through all phases of development, from design through training, evaluation, and validation; partnering with engineering teams to operationalize them in scalable and resilient production systems that serve 80+ million customers.
• Flex your interpersonal skills to translate the complexity of your work into tangible business goals.

The Ideal Candidate is:
• Customer first. You love the process of analyzing and creating, but also share our passion to do the right thing. You know at the end of the day it’s about making the right decision for our customers.
• Innovative. You continually research and evaluate emerging technologies. You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them.
• Creative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You’re not afraid to share a new idea.
• A leader. You challenge conventional thinking and work with stakeholders to identify and improve the status quo. You're passionate about talent development for your own team and beyond.
• Technical. You’re comfortable with advanced ML and DL technologies including language models and are passionate about developing further. You have hands-on experience working with LLMs and solutions using open-source tools and cloud computing platforms.
• Influential. You are passionate about AI/ML and can bring along a cross functional team in breakthrough innovations. You communicate clearly and effectively to share your findings with non-technical audiences.
• You are experienced in training language models or large computer vision models as well as have expertise in one or more key subdomains such as: training optimization, self-supervised learning, explainability, RLHF.
• You have an engineering mindset as shown by a track record of delivering models at scale both in training data and inference volumes. You have experience in delivering libraries, platforms, or solution level code to existing products.

Basic Qualifications:
• Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:
• A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 2 years of experience performing data analytics
• A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration

Preferred Qualifications:
• Master’s Degree in “STEM” field (Science, Technology, Engineering, or Mathematics), or PhD in “STEM” field (Science, Technology, Engineering, or Mathematics)
• Experience working with AWS
• At least 2 years’ experience in Python, Scala, or R
• At least 2 years’ experience with machine learning
• At least 2 years’ experience with SQL

Capital One will consider sponsoring a new qualified applicant for employment authorization for this position.

The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.

New York, NY: $145,100 - $165,600 for Sr Assoc, Data Science

San Jose, CA: $145,100 - $165,600 for Sr Assoc, Data Science

Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate’s offer letter.

This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.

Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.

This role is expected to accept applications for a minimum of 5 business days.

No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",2025-07-20T00:00:00.000Z,2025-07-25,"['Customer first', 'You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them', 'You thrive on bringing definition to big, undefined problems', 'You love asking questions and pushing hard to find answers', ""You're passionate about talent development for your own team and beyond"", 'Technical', 'You’re comfortable with advanced ML and DL technologies including language models and are passionate about developing further', 'You have hands-on experience working with LLMs and solutions using open-source tools and cloud computing platforms', 'Influential', 'You are passionate about AI/ML and can bring along a cross functional team in breakthrough innovations', 'You communicate clearly and effectively to share your findings with non-technical audiences', 'You are experienced in training language models or large computer vision models as well as have expertise in one or more key subdomains such as: training optimization, self-supervised learning, explainability, RLHF', 'You have an engineering mindset as shown by a track record of delivering models at scale both in training data and inference volumes', 'You have experience in delivering libraries, platforms, or solution level code to existing products', 'Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:', ""A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 2 years of experience performing data analytics"", ""A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration""]","['You will be the driving force to experiment, innovate and create next generation experiences powered by the latest emerging generative AI technologies', 'Partner with a cross-functional team of data scientists, software engineers, machine learning engineers and product managers to deliver AI powered products that change how customers interact with their money', 'Leverage a broad stack of technologies — Pytorch, AWS Ultraclusters, Hugging Face, LangChain, Lightning, VectorDBs, and more — to reveal the insights hidden within huge volumes of numeric and textual data', 'Be the expert in Natural Language Processing (NLP) to harness the power of Large Language Models (LLMs), adapt and finetune them for customer facing applications and features', 'Build machine learning and NLP models through all phases of development, from design through training, evaluation, and validation; partnering with engineering teams to operationalize them in scalable and resilient production systems that serve 80+ million customers', 'Flex your interpersonal skills to translate the complexity of your work into tangible business goals', 'You continually research and evaluate emerging technologies', 'You challenge conventional thinking and work with stakeholders to identify and improve the status quo']",True,"['Large Language Models', 'Generative AI', 'PyTorch', 'Hugging Face', 'LangChain', 'Lightning', 'Vector Databases', 'Training Optimization', 'Self-Supervised Learning', 'Explainability', 'Reinforcement Learning from Human Feedback', 'AI Model Engineering and Deployment']","Large Language Models: Expertise required to adapt, fine-tune, and deploy LLMs for customer-facing applications, enabling dynamic and personalized user experiences.; Generative AI: Used to create next-generation experiences powered by emerging generative AI technologies integrated into products like digital assistants.; PyTorch: Deep learning framework used for training and fine-tuning neural network models including large language models.; Hugging Face: Open-source platform and library used for working with transformer models and managing LLMs.; LangChain: Framework used to build applications powered by language models, facilitating integration and orchestration of LLMs.; Lightning: Deep learning framework used to streamline training and deployment of neural network models.; Vector Databases: Used to store and query vector embeddings for efficient retrieval in AI applications involving LLMs.; Training Optimization: Expertise in improving the efficiency and effectiveness of training large AI models.; Self-Supervised Learning: Applied as a key subdomain technique for training large models without extensive labeled data.; Explainability: Used to interpret and communicate the behavior and decisions of AI models to stakeholders.; Reinforcement Learning from Human Feedback: Applied to improve AI model performance by incorporating human feedback during training.; AI Model Engineering and Deployment: Involves delivering libraries, platforms, or solution-level code to production systems, ensuring scalability and resilience for AI models.","['Machine Learning', 'Natural Language Processing', 'Data Analytics', 'SQL', 'Python', 'Scala', 'R', 'AWS']","Machine Learning: Used to build predictive models and NLP models through all phases of development including design, training, evaluation, and validation; operationalized in scalable production systems serving millions of customers.; Natural Language Processing: Applied to harness the power of large language models for customer-facing applications, including adaptation and fine-tuning to improve user experience.; Data Analytics: Performed on large volumes of numeric and textual data to reveal insights that inform business decisions and product features.; SQL: Used as a fundamental skill for querying and managing relational databases as part of data analytics and model development.; Python: Programming language used for data science, machine learning, and model development tasks.; Scala: Programming language experience preferred for data processing and analytics.; R: Programming language experience preferred for statistical analysis and data science.; AWS: Cloud computing platform used to support scalable machine learning and data processing workloads."
VzvO9O1Z2iE_TicQAAAAAA==,Data Scientist (Mid-Level) Jobs,"TITLE: Data Scientist (Mid-Level)

LOCATION: Marine Corps Intelligence Activity, Quantico VA

OVERVIEW: The Data Scientist (Mid-Level) will develop and implement data science solutions to support MCIA's intelligence analysis and production mission. The data scientist will apply expertise in machine learning, data mining, and predictive modeling to extract insights from large, complex datasets and enable data-driven decision-making.

RESPONSIBILITIES:
• Collaborate with analysts, collectors, and stakeholders to identify and prioritize data science requirements
• Perform data wrangling, data cleaning, and feature engineering to prepare data for analysis
• Design, train, and evaluate machine learning models for pattern recognition, anomaly detection, and prediction
• Conduct exploratory data analysis and statistical modeling to uncover trends, patterns, and relationships
• Develop data visualizations, dashboards, and reports to communicate insights to technical and non-technical audiences
• Implement data science pipelines and workflows to automate and scale analytic processes
• Stay current on emerging data science tools, techniques, and best practices relevant to MCIA mission

REQUIREMENTS:
• Bachelor's degree or equivalent experience in data science, computer science, applied mathematics, or related field
• Minimum 3 years of experience developing and implementing data science solutions in DoD/IC or similar environment
• Proficiency in data science programming languages (Python, R) and libraries (scikit-learn, pandas, TensorFlow)
• Experience with data manipulation, feature selection, model training/evaluation, and results interpretation
• Knowledge of statistics, probability, machine learning algorithms, and data visualization techniques
• Familiarity with big data processing tools (Hadoop, Spark) and cloud computing platforms (AWS, Azure)
• Active Top Secret/SCI security clearance

Excellent problem-solving, communication, and collaboration skills to work effectively in a multidisciplinary team

About Streamline

Streamline is a professional and technical solutions company focused on the U.S. Defense, Intelligence, and Special Operations communities. Our talented team of analyst, engineers, and military professionals support our clients most demanding missions. We offer an unmatched opportunity to grow and learn in an exciting and entrepreneurial environment. Highly motivated individuals will find a culture that values their individual input and compensates them well for their efforts.

Streamline provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.",2025-07-25T11:00:00.000Z,2025-07-25,"[""Bachelor's degree or equivalent experience in data science, computer science, applied mathematics, or related field"", 'Minimum 3 years of experience developing and implementing data science solutions in DoD/IC or similar environment', 'Proficiency in data science programming languages (Python, R) and libraries (scikit-learn, pandas, TensorFlow)', 'Experience with data manipulation, feature selection, model training/evaluation, and results interpretation', 'Knowledge of statistics, probability, machine learning algorithms, and data visualization techniques', 'Familiarity with big data processing tools (Hadoop, Spark) and cloud computing platforms (AWS, Azure)', 'Active Top Secret/SCI security clearance', 'Excellent problem-solving, communication, and collaboration skills to work effectively in a multidisciplinary team']","[""OVERVIEW: The Data Scientist (Mid-Level) will develop and implement data science solutions to support MCIA's intelligence analysis and production mission"", 'The data scientist will apply expertise in machine learning, data mining, and predictive modeling to extract insights from large, complex datasets and enable data-driven decision-making', 'Collaborate with analysts, collectors, and stakeholders to identify and prioritize data science requirements', 'Perform data wrangling, data cleaning, and feature engineering to prepare data for analysis', 'Design, train, and evaluate machine learning models for pattern recognition, anomaly detection, and prediction', 'Conduct exploratory data analysis and statistical modeling to uncover trends, patterns, and relationships', 'Develop data visualizations, dashboards, and reports to communicate insights to technical and non-technical audiences', 'Implement data science pipelines and workflows to automate and scale analytic processes', 'Stay current on emerging data science tools, techniques, and best practices relevant to MCIA mission']",True,['TensorFlow'],TensorFlow: Apply TensorFlow specifically for neural network-based model development within the data science workflow.,"['Machine Learning', 'Data Wrangling and Cleaning', 'Feature Engineering', 'Exploratory Data Analysis and Statistical Modeling', 'Data Visualization and Dashboards', 'Data Science Pipelines and Workflows', 'Programming Languages and Libraries', 'Big Data Processing Tools', 'Cloud Computing Platforms']","Machine Learning: Design, train, and evaluate models for pattern recognition, anomaly detection, and prediction to extract insights from large, complex datasets and enable data-driven decision-making.; Data Wrangling and Cleaning: Perform data wrangling, data cleaning, and feature engineering to prepare data for analysis.; Feature Engineering: Create and select features to improve model performance as part of data preparation.; Exploratory Data Analysis and Statistical Modeling: Conduct exploratory data analysis and statistical modeling to uncover trends, patterns, and relationships in data.; Data Visualization and Dashboards: Develop data visualizations, dashboards, and reports to communicate insights to both technical and non-technical audiences.; Data Science Pipelines and Workflows: Implement pipelines and workflows to automate and scale analytic processes.; Programming Languages and Libraries: Use Python and R programming languages along with libraries such as scikit-learn, pandas, and TensorFlow for data manipulation, model training, and evaluation.; Big Data Processing Tools: Utilize big data tools like Hadoop and Spark to handle large datasets.; Cloud Computing Platforms: Leverage cloud platforms such as AWS and Azure to support data science solutions."
Luhjoi_lXJPh7xdSAAAAAA==,Data Scientist (TS/SCI + Poly) Jobs,"Description

The DarkStar Group, a GRVTY Company is seeking a Data Scientist with a TS/SCI + Poly clearance (applicable to this customer) to join one of our top projects in Chantilly, VA. Below is an overview of the project, as well as information on our company, our benefits, and our $25,000 referral program.

THE PROJECT

The DarkStar Group's team is charged with taking commercial and academic innovation high-side, in domains of Artificial Intelligence / Machine Learning (AI / ML) such as Computer Vision (Image and Video Processing), Natural Language Processing (NLP), and Audio Modeling. We also bring the best ideas, tools, and approaches in technology infrastructure (AWS, DevOps, etc.) to the IC. The tech stack used is extremely broad - anything cutting edge in the commercial market, the open source community, or the academic research community is likely involved: and if something isn't being looked at yet, you can make that happen.

This effort supports ALL missions of the Intelligence Community, including cyber-related data science missions. A seamless group of contractor and customer personnel work to create innovations that supply customer groups with the data sets, models, algorithms, software, and infrastructure they need to increase their mission success. Management is hands off, gives the team the freedom to explore new approaches, and markets the best ideas and results to all the other IC customers.

This project regularly needs various types of people - Data Scientists, Data / ETL Engineers, Analytic Software Engineers, Full Stack Developers, UI/UX Developers, and AWS/DevOps experts. We're particularly interested in people with any of the following experience:
• developing AI / ML models (neural networks, tree based algorithms, etc.);
• conducting data analysis in the fields of Computer Vision, NLP, or audio signal processing;
• doing data ingest and ETL into sponsor environments; or
• building data-analytic software systems.

Work on this program takes place throughout the Reston/Herndon/Chantilly, VA area (we cannot support remote work) and requires a TS/SCI + Poly clearance (acceptable to this customer).

The Role
• The data scientist will be working with several different types of cyber SME's to build a tool to help end users sift through data and find important information. We are looking for someone with great data science skills but also experience with adjacent skills i.e. data engineering (they might need to help with parsing raw data, etc.).

Required Skills
• Diverse data science skills (NLP, entity extraction, utilizing generative AI)
• Strong python programmer
• Data engineering experience
• Strong communication skills
• Must be able to comprehend requirements and effectively execute tasks accordingly
• Experience working with cyber data
About The DarkStar Group
Our Company

The DarkStar Group is a small business that solves BIG problems. We're one of the Inc. 5000 fastest-growing private companies in the US, and our engineers and scientists support the most critical national security missions in Virginia, Maryland, and elsewhere. Data Science, Software Engineering, Cloud/AWS Infrastructure, and Cyber/CNO are our core areas of expertise. We offer interesting and important work, job security, some of the best and most flexible benefits you'll find in the IC, and salaries so strong that they'll likely surprise you.

Our Benefits

The DarkStar Group offers exceptional compensation and benefits:
• very strong salaries;
• 100% company-paid medical, dental, and vision premiums for you and all dependents;
• the ability to get increased salary if you don't need medical/dental/vision;
• 100% company-paid disability and life insurance benefits;
• a generously-funded HSA;
• an 8% 401(k) contribution;
• 31 days of PTO/holidays to start (more with tenure);
• the ability to flex time across pay periods without using your PTO;
• a generous training budget;
• $25,000 employee referral bonuses;
• business development / growth incentives; and
• top notch company swag.
• * We have a huge growth opportunity, so we are offering up to a $25,000 reward for anyone new you refer whom we hire. **

The DarkStar Group, A GRVTY Company, is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran and will not be discriminated against on the basis of disability.

Anyone requiring reasonable accommodations should email ds_recruiting@grvty.comor call 703-544-7930 with requested details. A member of the HR team will respond to your request within 2 business days.

Know Your Rights: Workplace Discrimination is Illegal",2025-07-23T00:00:00.000Z,2025-07-25,"['developing AI / ML models (neural networks, tree based algorithms, etc.);', 'Work on this program takes place throughout the Reston/Herndon/Chantilly, VA area (we cannot support remote work) and requires a TS/SCI + Poly clearance (acceptable to this customer)', 'We are looking for someone with great data science skills but also experience with adjacent skills i.e. data engineering (they might need to help with parsing raw data, etc.)', 'Diverse data science skills (NLP, entity extraction, utilizing generative AI)', 'Strong python programmer', 'Data engineering experience', 'Strong communication skills', 'Must be able to comprehend requirements and effectively execute tasks accordingly', 'Experience working with cyber data']","[""The tech stack used is extremely broad - anything cutting edge in the commercial market, the open source community, or the academic research community is likely involved: and if something isn't being looked at yet, you can make that happen"", 'This effort supports ALL missions of the Intelligence Community, including cyber-related data science missions', 'This project regularly needs various types of people - Data Scientists, Data / ETL Engineers, Analytic Software Engineers, Full Stack Developers, UI/UX Developers, and AWS/DevOps experts', 'conducting data analysis in the fields of Computer Vision, NLP, or audio signal processing;', 'doing data ingest and ETL into sponsor environments; or', 'building data-analytic software systems', ""The data scientist will be working with several different types of cyber SME's to build a tool to help end users sift through data and find important information""]",True,"['Generative AI', 'Neural Networks']","Generative AI: Utilized within the project for advanced data science tasks, including NLP and entity extraction, to enhance analytic capabilities.; Neural Networks: Developed as part of AI/ML models to support computer vision, NLP, and audio modeling applications in intelligence community missions.","['Data Engineering', 'Natural Language Processing', 'Computer Vision', 'Audio Signal Processing', 'Machine Learning Models', 'Python Programming']","Data Engineering: Involves parsing raw data and performing data ingest and ETL into sponsor environments to support data science workflows and analytic software systems.; Natural Language Processing: Applied as part of diverse data science skills to analyze text data, including entity extraction, within cyber-related data science missions.; Computer Vision: Used for image and video processing as part of data analysis tasks in the project.; Audio Signal Processing: Conducting data analysis on audio data as part of the data scientist's responsibilities.; Machine Learning Models: Developing AI/ML models including neural networks and tree-based algorithms to support mission success in intelligence community projects.; Python Programming: Strong Python programming skills are required to implement data science and data engineering tasks."
zJn4GywD96dEf-_xAAAAAA==,"Senior Data Scientist, AI Foundations","Senior Data Scientist, AI Foundations

Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making.

As a Data Scientist at Capital One, you’ll be part of a team that’s leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives.

Team Description

AI Foundations Specialist Models Data Science team builds and ships state of the art scalable architecture, AI/ML solutions for Capital One’s award-winning mobile app. We partner with product, tech and design teams to deliver app features that delight customers with dynamic and personalized experiences, enable them to chat with Capital One’s digital assistant Eno, or search for useful contents. You will be the driving force to experiment, innovate and create next generation experiences powered by the latest emerging generative AI technologies.

In this role, you will:
• Partner with a cross-functional team of data scientists, software engineers, machine learning engineers and product managers to deliver AI powered products that change how customers interact with their money.
• Leverage a broad stack of technologies — Pytorch, AWS Ultraclusters, Hugging Face, LangChain, Lightning, VectorDBs, and more — to reveal the insights hidden within huge volumes of numeric and textual data.
• Be the expert in Natural Language Processing (NLP) to harness the power of Large Language Models (LLMs), adapt and finetune them for customer facing applications and features.
• Build machine learning and NLP models through all phases of development, from design through training, evaluation, and validation; partnering with engineering teams to operationalize them in scalable and resilient production systems that serve 80+ million customers.
• Flex your interpersonal skills to translate the complexity of your work into tangible business goals.

The Ideal Candidate is:
• Customer first. You love the process of analyzing and creating, but also share our passion to do the right thing. You know at the end of the day it’s about making the right decision for our customers.
• Innovative. You continually research and evaluate emerging technologies. You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them.
• Creative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You’re not afraid to share a new idea.
• A leader. You challenge conventional thinking and work with stakeholders to identify and improve the status quo. You're passionate about talent development for your own team and beyond.
• Technical. You’re comfortable with advanced ML and DL technologies including language models and are passionate about developing further. You have hands-on experience working with LLMs and solutions using open-source tools and cloud computing platforms.
• Influential. You are passionate about AI/ML and can bring along a cross functional team in breakthrough innovations. You communicate clearly and effectively to share your findings with non-technical audiences.
• You are experienced in training language models or large computer vision models as well as have expertise in one or more key subdomains such as: training optimization, self-supervised learning, explainability, RLHF.
• You have an engineering mindset as shown by a track record of delivering models at scale both in training data and inference volumes. You have experience in delivering libraries, platforms, or solution level code to existing products.

Basic Qualifications:
• Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:
• A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 2 years of experience performing data analytics
• A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration

Preferred Qualifications:
• Master’s Degree in “STEM” field (Science, Technology, Engineering, or Mathematics), or PhD in “STEM” field (Science, Technology, Engineering, or Mathematics)
• Experience working with AWS
• At least 2 years’ experience in Python, Scala, or R
• At least 2 years’ experience with machine learning
• At least 2 years’ experience with SQL

Capital One will consider sponsoring a new qualified applicant for employment authorization for this position.

The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.

New York, NY: $145,100 - $165,600 for Sr Assoc, Data Science

San Jose, CA: $145,100 - $165,600 for Sr Assoc, Data Science

Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate’s offer letter.

This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.

Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.

This role is expected to accept applications for a minimum of 5 business days.

No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",2025-07-20T00:00:00.000Z,2025-07-25,"['Customer first', 'You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them', 'You thrive on bringing definition to big, undefined problems', 'You love asking questions and pushing hard to find answers', ""You're passionate about talent development for your own team and beyond"", 'Technical', 'You’re comfortable with advanced ML and DL technologies including language models and are passionate about developing further', 'You have hands-on experience working with LLMs and solutions using open-source tools and cloud computing platforms', 'Influential', 'You are passionate about AI/ML and can bring along a cross functional team in breakthrough innovations', 'You communicate clearly and effectively to share your findings with non-technical audiences', 'You are experienced in training language models or large computer vision models as well as have expertise in one or more key subdomains such as: training optimization, self-supervised learning, explainability, RLHF', 'You have an engineering mindset as shown by a track record of delivering models at scale both in training data and inference volumes', 'You have experience in delivering libraries, platforms, or solution level code to existing products', 'Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:', ""A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 2 years of experience performing data analytics"", ""A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration""]","['You will be the driving force to experiment, innovate and create next generation experiences powered by the latest emerging generative AI technologies', 'Partner with a cross-functional team of data scientists, software engineers, machine learning engineers and product managers to deliver AI powered products that change how customers interact with their money', 'Leverage a broad stack of technologies — Pytorch, AWS Ultraclusters, Hugging Face, LangChain, Lightning, VectorDBs, and more — to reveal the insights hidden within huge volumes of numeric and textual data', 'Be the expert in Natural Language Processing (NLP) to harness the power of Large Language Models (LLMs), adapt and finetune them for customer facing applications and features', 'Build machine learning and NLP models through all phases of development, from design through training, evaluation, and validation; partnering with engineering teams to operationalize them in scalable and resilient production systems that serve 80+ million customers', 'Flex your interpersonal skills to translate the complexity of your work into tangible business goals', 'You continually research and evaluate emerging technologies', 'You challenge conventional thinking and work with stakeholders to identify and improve the status quo']",True,"['Large Language Models', 'Generative AI', 'PyTorch', 'Hugging Face', 'LangChain', 'Lightning', 'Vector Databases', 'Training Optimization', 'Self-Supervised Learning', 'Explainability', 'Reinforcement Learning from Human Feedback']","Large Language Models: Expertise required in adapting, fine-tuning, and training LLMs for customer-facing AI applications.; Generative AI: Driving force to experiment and innovate with emerging generative AI technologies to create next-generation customer experiences.; PyTorch: Used as a deep learning framework to build and train neural network models including LLMs.; Hugging Face: Utilized as an open-source platform and library for working with transformer models and LLMs.; LangChain: Employed to build AI applications that integrate LLMs with external data sources and workflows.; Lightning: Used as a framework to simplify and scale deep learning model training and deployment.; Vector Databases: Used to store and query vector embeddings for efficient retrieval in AI applications involving LLMs.; Training Optimization: Expertise in improving the efficiency and effectiveness of training large language and computer vision models.; Self-Supervised Learning: Applied as a key subdomain technique for training models without extensive labeled data.; Explainability: Focus on making AI model decisions interpretable and understandable for stakeholders.; Reinforcement Learning from Human Feedback: Used to improve model behavior and alignment by incorporating human feedback during training.","['Machine Learning', 'Natural Language Processing', 'Data Analytics', 'SQL', 'Python', 'Scala', 'R', 'AWS']","Machine Learning: Used to build predictive models and NLP models through all phases of development including design, training, evaluation, and validation; operationalized in scalable production systems serving millions of customers.; Natural Language Processing: Applied to harness the power of large language models for customer-facing applications, including adaptation and fine-tuning of models.; Data Analytics: Experience performing data analytics is required, involving analysis of numeric and textual data to reveal insights.; SQL: Used for querying and managing relational databases as part of data analytics and model development.; Python: Programming language used for machine learning, data analytics, and model development.; Scala: Programming language experience preferred for data science and machine learning tasks.; R: Programming language experience preferred for statistical analysis and data science.; AWS: Cloud computing platform used to support scalable machine learning and data processing workloads."
SWC1sPoUrYiHb9W8AAAAAA==,ME00383-Data Scientist 3 Jobs,"Momentum Engineering, Inc., a Woman-Owned Small Business (WOSB), fosters an employee-centric culture. Our strength lies in our people. With a high percentage of employees holding advanced degrees in engineering, computer science, and related disciplines, we bring deep technical expertise to every mission. Our team includes professionals with security clearances and full-scope polygraphs, ensuring trusted, secure support for the most sensitive national security initiatives. Additionally, our workforce is equipped with industry-leading certifications, demonstrating a commitment to continuous learning and excellence. Most importantly, our exceptional employee retention rate reflects a culture of professional growth, mission focus, and dedication-ensuring long-term stability and expertise for our customers' critical needs.

Job Summary
• Seeking a highly motivated and detail-oriented Data Scientist to provide Cyber Tradecraft support
• The ideal candidate will have strong analytical and statistical skills, a deep understanding of machine learning and data modeling, and the ability to extract meaningful insights from complex data sets to support business objectives

Primary Responsibilities
• Perform anomaly detection
• Design, develop, and implement statistical models and machine learning algorithms
• Analyze large structured and unstructured datasets from various sources to uncover trends and patterns
• Communicate findings clearly through dashboards, visualizations, and reports
• Collaborate with stakeholders across engineering, product, and business teams to translate data into actionable insights

Required Qualifications
• Must have active Top Secret/SCI with NSA FSP
• Master's degree with 6 years of relevant experience, Bachelor's Degree with 8 years of relevant experience, or Associates degree with 10 years of in-depth relevant experience that is clearly related to the position
• Proficiency in programming languages such as Python
• Experience with customer tools and dataflow

Desired Qualifications
• Experience with data redundancy and optimization

Exempt hourly position. 11 paid holidays, minimum of 3 weeks PTO, company sponsored group medical plan, company paid dental, vision, life insurance, and STD/LTD plans. Salary is dependent upon the candidate's experience and qualifications.

The pay range for this role is:

130,000 - 175,000 USD per year ( Ft. Meade MD )",2025-07-25T14:00:00.000Z,2025-07-25,"['Seeking a highly motivated and detail-oriented Data Scientist to provide Cyber Tradecraft support', 'The ideal candidate will have strong analytical and statistical skills, a deep understanding of machine learning and data modeling, and the ability to extract meaningful insights from complex data sets to support business objectives', 'Must have active Top Secret/SCI with NSA FSP', ""Master's degree with 6 years of relevant experience, Bachelor's Degree with 8 years of relevant experience, or Associates degree with 10 years of in-depth relevant experience that is clearly related to the position"", 'Proficiency in programming languages such as Python', 'Experience with customer tools and dataflow']","['Perform anomaly detection', 'Design, develop, and implement statistical models and machine learning algorithms', 'Analyze large structured and unstructured datasets from various sources to uncover trends and patterns', 'Communicate findings clearly through dashboards, visualizations, and reports', 'Collaborate with stakeholders across engineering, product, and business teams to translate data into actionable insights']",True,[],,"['Anomaly Detection', 'Statistical Models', 'Machine Learning Algorithms', 'Data Analysis of Structured and Unstructured Data', 'Data Visualization and Dashboards', 'Python Programming']","Anomaly Detection: Used to identify unusual patterns or outliers in data to support cyber tradecraft and security objectives.; Statistical Models: Designed, developed, and implemented to analyze data and extract meaningful insights relevant to business and security goals.; Machine Learning Algorithms: Applied to model complex data relationships and support predictive analytics within cyber tradecraft contexts.; Data Analysis of Structured and Unstructured Data: Analyzed large datasets from various sources to uncover trends and patterns that inform decision-making and operational strategies.; Data Visualization and Dashboards: Communicated analytical findings clearly through visual tools and reports to stakeholders across engineering, product, and business teams.; Python Programming: Used as a primary programming language to develop data models, perform analysis, and implement machine learning algorithms."
XmlF2hnsr8waRqdGAAAAAA==,"Principal Data Scientist, AI Foundations","Principal Data Scientist, AI Foundations

Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making.

As a Data Scientist at Capital One, you’ll be part of a team that’s leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives.

Team Description

AI Foundations Specialist Models Data Science team builds and ships state of the art scalable architecture, AI/ML solutions for Capital One’s award-winning mobile app. We partner with product, tech and design teams to deliver app features that delight customers with dynamic and personalized experiences, enable them to chat with Capital One’s digital assistant Eno, or search for useful contents. You will be the driving force to experiment, innovate and create next generation experiences powered by the latest emerging generative AI technologies.

In this role, you will:
• Partner with a cross-functional team of data scientists, software engineers, machine learning engineers and product managers to deliver AI powered products that change how customers interact with their money.
• Leverage a broad stack of technologies — Pytorch, AWS Ultraclusters, Hugging Face, LangChain, Lightning, VectorDBs, and more — to reveal the insights hidden within huge volumes of numeric and textual data.
• Be the expert in Natural Language Processing (NLP) to harness the power of Large Language Models (LLMs), adapt and finetune them for customer facing applications and features.
• Build machine learning and NLP models through all phases of development, from design through training, evaluation, and validation; partnering with engineering teams to operationalize them in scalable and resilient production systems that serve 80+ million customers.
• Flex your interpersonal skills to translate the complexity of your work into tangible business goals.

The Ideal Candidate is:
• Customer first. You love the process of analyzing and creating, but also share our passion to do the right thing. You know at the end of the day it’s about making the right decision for our customers.
• Innovative. You continually research and evaluate emerging technologies. You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them.
• Creative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You’re not afraid to share a new idea.
• A leader. You challenge conventional thinking and work with stakeholders to identify and improve the status quo. You're passionate about talent development for your own team and beyond.
• Technical. You’re comfortable with advanced ML and DL technologies including language models and are passionate about developing further. You have hands-on experience working with LLMs and solutions using open-source tools and cloud computing platforms.
• Influential. You are passionate about AI/ML and can bring along a cross functional team in breakthrough innovations. You communicate clearly and effectively to share your findings with non-technical audiences.
• You are experienced in training language models or large computer vision models as well as have expertise in one or more key subdomains such as: training optimization, self-supervised learning, explainability, RLHF.
• You have an engineering mindset as shown by a track record of delivering models at scale both in training data and inference volumes. You have experience in delivering libraries, platforms, or solution level code to existing products.

Basic Qualifications:
• Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:
• A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 5 years of experience performing data analytics
• A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 3 years of experience performing data analytics
• A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field)

Preferred Qualifications:
• Master’s Degree in “STEM” field (Science, Technology, Engineering, or Mathematics), or PhD in “STEM” field (Science, Technology, Engineering, or Mathematics)
• Experience working with AWS
• At least 3 years’ experience in Python, Scala, or R
• At least 3 years’ experience with machine learning
• At least 3 years’ experience with SQL

Capital One will consider sponsoring a new qualified applicant for employment authorization for this position.

The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.

McLean, VA: $158,600 - $181,000 for Princ Associate, Data Science

New York, NY: $173,000 - $197,400 for Princ Associate, Data Science

San Jose, CA: $173,000 - $197,400 for Princ Associate, Data Science

Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate’s offer letter.

This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.

Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.

This role is expected to accept applications for a minimum of 5 business days.

No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",2025-07-20T00:00:00.000Z,2025-07-25,"['Customer first', 'You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them', 'You thrive on bringing definition to big, undefined problems', 'You love asking questions and pushing hard to find answers', ""You're passionate about talent development for your own team and beyond"", 'Technical', 'You’re comfortable with advanced ML and DL technologies including language models and are passionate about developing further', 'You have hands-on experience working with LLMs and solutions using open-source tools and cloud computing platforms', 'Influential', 'You are passionate about AI/ML and can bring along a cross functional team in breakthrough innovations', 'You communicate clearly and effectively to share your findings with non-technical audiences', 'You are experienced in training language models or large computer vision models as well as have expertise in one or more key subdomains such as: training optimization, self-supervised learning, explainability, RLHF', 'You have an engineering mindset as shown by a track record of delivering models at scale both in training data and inference volumes', 'You have experience in delivering libraries, platforms, or solution level code to existing products', 'Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:', ""A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 5 years of experience performing data analytics"", ""A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 3 years of experience performing data analytics"", 'A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field)']","['You will be the driving force to experiment, innovate and create next generation experiences powered by the latest emerging generative AI technologies', 'Partner with a cross-functional team of data scientists, software engineers, machine learning engineers and product managers to deliver AI powered products that change how customers interact with their money', 'Leverage a broad stack of technologies — Pytorch, AWS Ultraclusters, Hugging Face, LangChain, Lightning, VectorDBs, and more — to reveal the insights hidden within huge volumes of numeric and textual data', 'Be the expert in Natural Language Processing (NLP) to harness the power of Large Language Models (LLMs), adapt and finetune them for customer facing applications and features', 'Build machine learning and NLP models through all phases of development, from design through training, evaluation, and validation; partnering with engineering teams to operationalize them in scalable and resilient production systems that serve 80+ million customers', 'Flex your interpersonal skills to translate the complexity of your work into tangible business goals', 'You continually research and evaluate emerging technologies', 'You challenge conventional thinking and work with stakeholders to identify and improve the status quo']",True,"['Large Language Models (LLMs)', 'Generative AI', 'PyTorch', 'Hugging Face', 'LangChain', 'Lightning', 'Vector Databases', 'Training Optimization', 'Self-Supervised Learning', 'Explainability', 'Reinforcement Learning from Human Feedback (RLHF)', 'Deep Learning']",Large Language Models (LLMs): Harnessed and fine-tuned to build customer-facing AI applications such as digital assistants and personalized experiences.; Generative AI: Used to create next-generation customer experiences powered by emerging AI technologies.; PyTorch: Utilized as a deep learning framework to develop and train neural network models including LLMs.; Hugging Face: Employed as an open-source platform and library for working with transformer models and LLMs.; LangChain: Used to build AI applications that integrate LLMs with external data sources and workflows.; Lightning: Applied as a framework to streamline deep learning model training and deployment.; Vector Databases: Used to store and retrieve high-dimensional embeddings for AI applications such as semantic search and recommendation.; Training Optimization: Expertise in improving efficiency and effectiveness of training large AI models.; Self-Supervised Learning: Applied as a technique to train models using unlabeled data to improve performance.; Explainability: Used to interpret and understand AI model decisions to ensure transparency and trust.; Reinforcement Learning from Human Feedback (RLHF): Applied to fine-tune AI models by incorporating human feedback to improve alignment and performance.; Deep Learning: Used to develop advanced neural network models including language and computer vision models at scale.,"['Statistical Modeling', 'Relational Databases', 'Machine Learning', 'Natural Language Processing (NLP)', 'Python', 'Scala', 'R', 'SQL', 'Data Analytics', 'Machine Learning Model Development Lifecycle']","Statistical Modeling: Used to personalize credit card offers and drive data-driven decision-making at scale.; Relational Databases: Employed historically and currently to manage and query large volumes of structured data.; Machine Learning: Applied to build predictive models and AI-powered products that improve customer financial interactions.; Natural Language Processing (NLP): Used to develop and fine-tune models for customer-facing applications, enabling features like digital assistants and content search.; Python: A primary programming language used for data analytics and machine learning model development.; Scala: Used as a programming language for data analytics and model development.; R: Used as a programming language for data analytics and statistical modeling.; SQL: Used for querying and managing data within relational databases.; Data Analytics: Performed to analyze large datasets and extract actionable insights to support business decisions.; Machine Learning Model Development Lifecycle: Involves design, training, evaluation, validation, and operationalization of models in production systems serving millions of customers."
DDlYUr7BgyKaoURDAAAAAA==,Data Scientist 2 - 24016 Jobs,"Requisition Number: 24016

Required Travel: 11 - 25%

Employment Type: Full Time/Salaried/Exempt

Anticipated Salary Range: $79,534.00 - $110,000.00

Security Clearance: Ability to Obtain

Level of Experience: Mid

This opportunity resides with Global Security (GS). Mission Technologies' Global Security (GS) group comprises live, virtual, constructive (LVC) solutions; fleet sustainment; nuclear and environmental; and Australia business.

As a trusted partner to our military customers, HII designs, develops and operates the largest LVC enterprise that prepares warfighters for cross-domain battle. With advanced technologies to enable mission readiness, HII understands that preparation requires full coordination-not readiness in piece-parts.

For more than 40 years, the U.S. Navy has entrusted HII to maintain and modernize the vast majority of its fleet. With a holistic approach to life-cycle maritime defense systems-from small watercraft to submarines, surface combatants and aircraft carriers-HII ensures a high state of readiness.

HII supports the Department of Energy's national security mission through the management and operation of its sites, as well as the safe cleanup of legacy waste across the country. HII meets clients' toughest nuclear and environmental challenges.

Meet HII's Mission Technologies Division
Our team of more than 7,000 professionals worldwide delivers all-domain expertise and advanced technologies in service of mission partners across the globe. Mission Technologies is leading the next evolution of national defense - the data evolution - by accelerating a breadth of national security solutions for government and commercial customers. Our capabilities range from C5ISR, AI and Big Data, cyber operations and synthetic training environments to fleet sustainment, environmental remediation and the largest family of unmanned underwater vehicles in every class. Find the role that's right for you. Apply today. We look forward to meeting you.

To learn more about Mission Technologies, click here for a short video: https://vimeo.com/732533072

Job Description

HII Mission Technologies is seeking a Data Scientist 2 to support the Joint Training Synthetic Environment (JTSE) Joint Staff J7(JS J-7) contract at our Suffolk, VA Joint Staff Complex. This position is eligible for a hybrid work schedule.

Essential Job Responsibilities
• Designs, develops, and implements statistical and analytical methods.
• Examines processes and systems to consolidate and analyze diverse data sets including structured, semi-structured and unstructured.
• Develops and sources software programs, algorithms, dashboards, information tools, and queries to collect, clean, model, integrate and evaluate datasets.
• Documents workflows and processes employed to improve knowledge across the Data Science and Engineering team.
• Employs statistical concepts, linguistics and programming skills to develop related techniques and methods for analysis.
• Keeps abreast of new analytic methodologies and technologies.
• Collaborates with functional business units to drive solutions and directions, and interprets and presents findings to enable business decisions.

Minimum Qualifications
• 2 years relevant experience with Bachelors in related field; 0 years experience with Masters in related field; or High School Diploma or equivalent and 6 years relevant experience.
• Must have the ability to obtain, and be able to maintain, an active TS/SCI clearance.
• Excellent written and verbal communication skills.
• Ability to work both in a team and individually.
• Solid organizational skills, including attention to detail.
• Self-motivated and driven desire to succeed with minimal direction.

Preferred Requirements
• An active TS/SCI security clearance.
• Experience with the configuration and use of Superset in connecting to data sources and creating dashboards.
• Prior use of Talend and Qlik toolsets.
• Development and use of Apache Spark.
• Experience with developing data analytics and processing pipeline applications with Python.

HII is more than a job - it's an opportunity to build a new future. We offer competitive benefits such as best-in-class medical, dental and vision plan choices; wellness resources; employee assistance programs; Savings Plan Options (401(k)); financial planning tools, life insurance; employee discounts; paid holidays and paid time off; tuition reimbursement; as well as early childhood and post-secondary education scholarships. Bonus/other non-recurrent compensation is occasionally offered for qualified positions, and if applicable to this role will be addressed by the recruiter at the screening phase of application.

The listed salary range for this role is intended as a good faith estimate based on the role's location, expectations, and responsibilities. When extending an offer, HII's Mission Technologies division takes a variety of factors into consideration which include, but are not limited to, the role's function and a candidate's education or training, work experience, and key skills.

Why HII
We build the world's most powerful, survivable naval ships and defense technology solutions that safeguard our seas, sky, land, space and cyber. Our workforce includes skilled tradespeople; artificial intelligence, machine learning (AI/ML) experts; engineers; technologists; scientists; logistics experts; and business administration professionals.

Recognized as one of America's top large company employers, we are a values and ethics driven organization that puts people's safety and well-being first. Regardless of your role or where you serve, at HII, you'll find a supportive and welcoming environment, competitive benefits, and valuable educational and training programs for continual career growth at every stage of your career.

Together we are working to ensure a future where everyone can be free and thrive.
All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, physical or mental disability, age, or veteran status or any other basis protected by federal, state, or local law.

Do You Need Assistance?
If you need a reasonable accommodation for any part of the employment process, please send an e-mail to buildyourcareer@hii-co.com and let us know the nature of your request and your contact information. Reasonable accommodations are considered on a case-by-case basis. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this email address. Additionally, you may also call 1-844-849-8463 for assistance. Press #3 for HII Mission Technologies.",2025-07-24T00:00:00.000Z,2025-07-25,"['Security Clearance: Ability to Obtain', '2 years relevant experience with Bachelors in related field; 0 years experience with Masters in related field; or High School Diploma or equivalent and 6 years relevant experience', 'Must have the ability to obtain, and be able to maintain, an active TS/SCI clearance', 'Excellent written and verbal communication skills', 'Ability to work both in a team and individually', 'Solid organizational skills, including attention to detail', 'Self-motivated and driven desire to succeed with minimal direction']","['Required Travel: 11 - 25%', 'With advanced technologies to enable mission readiness, HII understands that preparation requires full coordination-not readiness in piece-parts', 'For more than 40 years, the U.S. Navy has entrusted HII to maintain and modernize the vast majority of its fleet', 'With a holistic approach to life-cycle maritime defense systems-from small watercraft to submarines, surface combatants and aircraft carriers-HII ensures a high state of readiness', 'Designs, develops, and implements statistical and analytical methods', 'Examines processes and systems to consolidate and analyze diverse data sets including structured, semi-structured and unstructured', 'Develops and sources software programs, algorithms, dashboards, information tools, and queries to collect, clean, model, integrate and evaluate datasets', 'Documents workflows and processes employed to improve knowledge across the Data Science and Engineering team', 'Employs statistical concepts, linguistics and programming skills to develop related techniques and methods for analysis', 'Keeps abreast of new analytic methodologies and technologies', 'Collaborates with functional business units to drive solutions and directions, and interprets and presents findings to enable business decisions']",True,[],,"['Statistical and Analytical Methods', 'Data Integration and Processing', 'Dashboards and BI Tools', 'Data Pipelines and Big Data Processing', 'Programming for Data Science', 'Workflow Documentation']","Statistical and Analytical Methods: Designs, develops, and implements statistical and analytical methods to analyze data and support decision-making processes.; Data Integration and Processing: Examines processes and systems to consolidate and analyze diverse data sets including structured, semi-structured, and unstructured data, and develops software programs, algorithms, and queries to collect, clean, model, integrate, and evaluate datasets.; Dashboards and BI Tools: Develops dashboards and information tools using BI tools such as Superset and Qlik to visualize data and support business decisions.; Data Pipelines and Big Data Processing: Experience with developing data analytics and processing pipeline applications using Apache Spark and Python to handle large-scale data processing.; Programming for Data Science: Employs programming skills, particularly in Python, to develop techniques and methods for data analysis and pipeline development.; Workflow Documentation: Documents workflows and processes to improve knowledge sharing across the Data Science and Engineering team."
mM64TjTRCvQvPUz3AAAAAA==,Cyber Data Science Engineer Jobs,"The Cyber Data Science Engineer provides support to the customer in the area of Cyber Security. Daily Tasks include, but are not limited to:

The Cyber Systems Engineer provides SETA support to the customer in the area of Cyber Security Operations. Daily tasks include, but are not limited to:
• Compile's information to develop the weekly, monthly, and annual customer ""Cyber Snapshot."" Reporting metrics on cases and incidents that have happened over the period as well as items of interest on Cyber Security that would be of interest to senior management.
• Verifies/validates systems with specific emphasis on network operations and cyber warfare tactics, techniques, and procedures focused on the threat to information networks.
• Assesses security performance using evaluation criteria and technical performance measures.
• Prepares assessments and cyber threat profiles of current and planned products based on sophisticated testing, research, and
• Participates in design reviews of components (hardware and software) to ensure applicability to the current system and traceability of requirements.
• Develops and maintains analytical procedures to meet changing requirements
• Produces high-quality papers, presentations, recommendations, and findings for senior US government intelligence and operations officials.
• Provide identification and classification of system and network vulnerabilities, providing mitigation and remediation recommendations.
• Analyzes policies and procedures against Federal laws and regulations and provides recommendations for closing gaps.
• Develops strategies to comply with privacy and risk management requirements.
• Prepare threat analysis reports.
• Create Indications of Compromise for new and existing malware.
• Participate in Cyber Defense Working Groups, forums, and IPTS. Provide cyber defense guidance.

Qualifications:

Required:
• Current U.S. Government Top Secret clearance with SCI eligibility.
• Favorably adjudicated Polygraph.
• Bachelor of Science Degree in Science, Technology, Engineering or Mathematics (STEM) or an advanced IA certification.
• DoD 8570 certification in IAT or IAM.
• Experience in security systems engineering involving various computer hardware and software operation systems and application solutions in both stand-alone and LAN/WAN configurations Experience with security features and/or vulnerability of various operating systems as defined by NIST, DISA (STIGs), and USCYBERCOM.
• Experience with networks and systems security administration, operation systems security configuration and account management best practices.
• Solid understanding of network intrusion detection methods and techniques.

Desired:
• Experience with SIEM technology and applications such as ArcSight or Splunk.
• Experience with FireEye or experience with an equivalent ""endpoint agent"" application Experience in responding to detected security incidents.
• Experience implementing RMF Process and NIST 800-53 technical controls, as well as developing and maintaining associated certification and accreditation documentation.
• Self-starter requiring limited direction and supervision.
• Experience working in a Network Security Operations Center.
• An understanding of satellite communication networks Experience briefing senior customer personnel.
• Ability to organize and prioritize numerous customer requests in a fast pace deadline driven environment.
• Familiarity with Amazon Web Services (AWS).
• Familiarity with customer's IA processes.
• Experience supporting IC or DoD in the Cyber Security Domain.Cyber Data",2025-07-25T00:00:00.000Z,2025-07-25,"['Current U.S. Government Top Secret clearance with SCI eligibility', 'Favorably adjudicated Polygraph', 'Bachelor of Science Degree in Science, Technology, Engineering or Mathematics (STEM) or an advanced IA certification', 'DoD 8570 certification in IAT or IAM', 'Experience in security systems engineering involving various computer hardware and software operation systems and application solutions in both stand-alone and LAN/WAN configurations Experience with security features and/or vulnerability of various operating systems as defined by NIST, DISA (STIGs), and USCYBERCOM', 'Experience with networks and systems security administration, operation systems security configuration and account management best practices', 'Solid understanding of network intrusion detection methods and techniques']","['The Cyber Data Science Engineer provides support to the customer in the area of Cyber Security', 'The Cyber Systems Engineer provides SETA support to the customer in the area of Cyber Security Operations', 'Compile\'s information to develop the weekly, monthly, and annual customer ""Cyber Snapshot."" Reporting metrics on cases and incidents that have happened over the period as well as items of interest on Cyber Security that would be of interest to senior management', 'Verifies/validates systems with specific emphasis on network operations and cyber warfare tactics, techniques, and procedures focused on the threat to information networks', 'Assesses security performance using evaluation criteria and technical performance measures', 'Prepares assessments and cyber threat profiles of current and planned products based on sophisticated testing, research, and', 'Participates in design reviews of components (hardware and software) to ensure applicability to the current system and traceability of requirements', 'Develops and maintains analytical procedures to meet changing requirements', 'Produces high-quality papers, presentations, recommendations, and findings for senior US government intelligence and operations officials', 'Provide identification and classification of system and network vulnerabilities, providing mitigation and remediation recommendations', 'Analyzes policies and procedures against Federal laws and regulations and provides recommendations for closing gaps', 'Develops strategies to comply with privacy and risk management requirements', 'Prepare threat analysis reports', 'Create Indications of Compromise for new and existing malware', 'Participate in Cyber Defense Working Groups, forums, and IPTS', 'Provide cyber defense guidance']",False,,,,
3pUDR8Cr6LAiuPx6AAAAAA==,Software Engineer/Data Scientist Jobs,"Software Engineer/Data Scientist

Active Top Secret (TS/SCI) clearance with polygraph is required.

YOE Requirement: 8 yrs., B.S. in a technical discipline or 4 additional yrs. in place of B.S.

Description: As a data scientist specializing in graph analysis and algorithms, you will join a collaborative team building an entirely new graph analysis platform that, for the first time, will allow our mission customers to visualize, analyze, and traverse their expansive and complex mission data in graph format and in near-real-time. Your responsibilities will center around enhancing our graph data capabilities—designing, modeling, and optimizing complex graph structures and crafting performant database queries. While familiarity with Neo4j and its query language, Cypher, is beneficial, we welcome candidates with broader graph analysis experience who are eager to deepen their expertise. You may also develop and maintain data parsers using Python to support our ingestion pipelines and maintain comprehensive documentation of data models. Finally, you will work directly with mission analysts and operators to listen to their needs and address them through novel data models and graphing solutions.

Responsibilities:

• Develop and refine graph data models to accommodate new data sources and fulfill customer-driven feature requests.

• Design and optimize graph queries, with an expectation to learn and utilize Cypher for Neo4j.

• Build and maintain data parsers in Python, ensuring reliable data ingestion.

• Validate and analyze mission data to confirm accuracy, integrity, and optimal performance.

• Collaborate closely with analysts to understand and translate analytical requirements into practical graph-based solutions.

• Work alongside software developers to integrate efficient queries and data parsers into robust software components.

• Maintain clear, comprehensive documentation of graph schemas, data models, and related processes using tools such as Confluence.

• Engage directly with customers to understand operational challenges and propose effective technical solutions.

Skill Requirements:

• Experience or interest in graph databases, such as Neo4j, with a willingness to learn specific tools like Cypher.

• Strong Python programming skills, specifically for writing and maintaining data parsing scripts.

• Proven ability to translate customer requirements into implementable data-driven solutions.

• Excellent communication and interpersonal skills for effective collaboration with diverse stakeholders.

• Strong analytical thinking and problem-solving abilities.

• Solid understanding of measuring analytic performance - what queries run slow, what run fast.

• Strong communication skills (you talk to developers, you talk to senior leadership, you talk to users, etc).

• Experience with Angular, React, or Vue.

Nice to Haves:

• Previous experience with Neo4j or other graph databases.

• Knowledge of TCP/IP networking concepts.

• Understanding graph theory and algorithms.

• Familiarity with real-time data processing or streaming analytics.

• Experience with containerization technologies (Docker, Kubernetes).

• Understanding of ETL processes for large, complex datasets.

• Familiarity with SIGINT collection and analysis systems or similar mission environments.

• Knowledge of HTML, CSS, Sass, NPM, and using REST APIs.

• Experience developing single-page web apps.

• Familiarity with Git and Gitlab CI/CD.

Benefits:

• 12% Retirement Contribution (6% Employer Contribution + 6% Employer Match)

• 200 hours per annum of Paid Time Off (PTO) prorated to start date (PTO can be earned & negotiated)

• Straight Time can be earned on top of your Salary after meeting your required billable hours

• Flexible work hours

• 40 hours of New Parent Leave

• Medical, dental, & vision insurance for individuals and families (salaries can be negotiated for those who waive medical benefits)

• Life, AD&D, Short-Term Disability, & Long-Term Disability Insurance

• Bonuses for high performers, year-end, and referrals

• $5,000 Professional Development Allowance

• 40 hours of Training

• $5,250 Education Reimbursement

Salary range: $135,000 - $200,000

Disclaimer: Salary for this position, along with additional compensation options, will be determined on an individual basis following the interview process, considering various factors such as years of experience, skills, education/certifications, contract specifications, market conditions, etc.",2025-07-25T13:00:00.000Z,2025-07-25,"['Active Top Secret (TS/SCI) clearance with polygraph is required', 'YOE Requirement: 8 yrs., B.S. in a technical discipline or 4 additional yrs. in place of B.S', 'Experience or interest in graph databases, such as Neo4j, with a willingness to learn specific tools like Cypher', 'Strong Python programming skills, specifically for writing and maintaining data parsing scripts', 'Proven ability to translate customer requirements into implementable data-driven solutions', 'Excellent communication and interpersonal skills for effective collaboration with diverse stakeholders', 'Strong analytical thinking and problem-solving abilities', 'Solid understanding of measuring analytic performance - what queries run slow, what run fast', 'Strong communication skills (you talk to developers, you talk to senior leadership, you talk to users, etc)', 'Experience with Angular, React, or Vue', 'Previous experience with Neo4j or other graph databases', 'Knowledge of TCP/IP networking concepts', 'Understanding graph theory and algorithms', 'Familiarity with real-time data processing or streaming analytics', 'Experience with containerization technologies (Docker, Kubernetes)', 'Understanding of ETL processes for large, complex datasets', 'Familiarity with SIGINT collection and analysis systems or similar mission environments', 'Knowledge of HTML, CSS, Sass, NPM, and using REST APIs', 'Experience developing single-page web apps', 'Familiarity with Git and Gitlab CI/CD']","['Description: As a data scientist specializing in graph analysis and algorithms, you will join a collaborative team building an entirely new graph analysis platform that, for the first time, will allow our mission customers to visualize, analyze, and traverse their expansive and complex mission data in graph format and in near-real-time', 'Your responsibilities will center around enhancing our graph data capabilities—designing, modeling, and optimizing complex graph structures and crafting performant database queries', 'While familiarity with Neo4j and its query language, Cypher, is beneficial, we welcome candidates with broader graph analysis experience who are eager to deepen their expertise', 'You may also develop and maintain data parsers using Python to support our ingestion pipelines and maintain comprehensive documentation of data models', 'Finally, you will work directly with mission analysts and operators to listen to their needs and address them through novel data models and graphing solutions', 'Develop and refine graph data models to accommodate new data sources and fulfill customer-driven feature requests', 'Design and optimize graph queries, with an expectation to learn and utilize Cypher for Neo4j', 'Build and maintain data parsers in Python, ensuring reliable data ingestion', 'Validate and analyze mission data to confirm accuracy, integrity, and optimal performance', 'Collaborate closely with analysts to understand and translate analytical requirements into practical graph-based solutions', 'Work alongside software developers to integrate efficient queries and data parsers into robust software components', 'Maintain clear, comprehensive documentation of graph schemas, data models, and related processes using tools such as Confluence', 'Engage directly with customers to understand operational challenges and propose effective technical solutions']",True,[],,"['Graph Databases', 'Graph Theory and Algorithms', 'Python Data Parsers', 'Data Modeling', 'Data Query Optimization', 'Real-Time Data Processing', 'ETL Processes', 'Analytic Performance Measurement', 'Data Documentation', 'SQL-like Query Languages']","Graph Databases: The job involves designing, modeling, and optimizing complex graph data structures and queries to support mission data analysis and visualization in graph format, with specific mention of Neo4j and its query language Cypher.; Graph Theory and Algorithms: Understanding and applying graph theory and algorithms is important for developing and refining graph data models and optimizing graph queries to meet customer-driven feature requests.; Python Data Parsers: Developing and maintaining data parsers using Python is required to support reliable data ingestion pipelines and ensure data accuracy and integrity.; Data Modeling: Creating and refining data models, particularly graph data models, to accommodate new data sources and fulfill analytical and operational requirements.; Data Query Optimization: Designing and optimizing database queries, especially graph queries, to ensure performant data retrieval and analysis.; Real-Time Data Processing: Familiarity with real-time data processing or streaming analytics is desirable to support near-real-time analysis and traversal of mission data.; ETL Processes: Understanding ETL (Extract, Transform, Load) processes for handling large, complex datasets is beneficial for managing data ingestion and preparation.; Analytic Performance Measurement: Measuring and analyzing query performance to identify slow and fast-running queries, ensuring optimal system efficiency.; Data Documentation: Maintaining comprehensive documentation of graph schemas, data models, and related processes using tools such as Confluence to support collaboration and knowledge sharing.; SQL-like Query Languages: Using Cypher, a query language for graph databases, to write and optimize queries for data retrieval and analysis."
ThZVOMyrozHI7hKEAAAAAA==,Command and Control Data Scientist Jobs,"Overview

UIC Bowhead is seeking a mission-focused, policy-savvy C2 Data Scientist to support the Program Manager for Marine Air-Ground Task Force Command and Control (PM MAGTF C2) within a military acquisition program office. This role bridges traditional data science with strategic-level advisory functions. The successful candidate will operate at the intersection of data science, enterprise portfolio management, and tactical command and control (C2) systems. This position will directly contribute to shaping emerging DoD, Joint, and USMC data-centric policies and tactics, techniques, and procedures (TTPs), while ensuring that advanced analytics and AI/ML solutions align with both enterprise and operational warfighter needs.

Responsibilities

• Coordinate PM MAGTF C2's participation in developing DoD, Joint, and Marine Corps data strategies and TTPs related to integrated C2, mission command, Zero Trust, and data governance.
• Contribute to cross-functional working groups, shaping policy and strategy for data-centric operations at both tactical and enterprise levels.
• Perform and/or assess statistical and exploratory data analysis (EDA) on portfolio-level data to inform executive decisions and SAFe-aligned strategy execution.
• Drive the design and implementation of predictive models and machine learning techniques tailored for DDIL environments and tactical decision-making contexts.
• Develop and/or support the creation of dashboards and visualizations that support Lean Portfolio Management (LPM), strategic portfolio reviews, and operational alignment.
• Lead the development and coordination of PM MAGTF C2's data governance plan and tagging guidance, ensuring alignment with enterprise and mission needs.
• Drive the implementation of enterprise level data policies into the PM MAGTF C2 data strategy.
• Assess and recommend emerging data science, AI/ML tools, and architectures for integration into composable, tactical decision support platforms.
• Author and deliver technical reports and white papers on analytics strategies, governance frameworks, and model integration to support portfolio objectives.

Qualifications
• Master's degree in Data Science, Statistics, Systems Engineering, Computer Science, or a related field.
• 5+ years of experience applying data science in a defense, intelligence, or C2 domain.
• Familiarity with military acquisition processes and the DoD Data Strategy, including metadata standards, and AI/ML integration.
• Strong communication and collaboration skills to support policy development, stakeholder engagement, and cross-functional coordination.
• Strong understanding of the data science domain including trends, technologies, and toolsets.
• Proficiency in data platforms such as SQL and no SQL databases, big data, distributed data processing.
• Proficiency in Python, R, SQL, or other relevant data analysis languages.

Preferred:
• Active Top Secret DoD Secret clearance.
• Prior military service or experience supporting military C2 or tactical systems.
• Experience designing models for DDIL environments and edge computing.
• Exposure to tactical data mesh/data fabrics.
• Experience using JIRA, Confluence, and Agile frameworks

SECURITY CLEARANCE REQUIRED: Must currently hold a Secret security clearance. US Citizenship is required.

Physical Demands:
• Must be able to lift up to 25 pounds
• Must be able to stand and walk for prolonged amounts of time
• Must be able to twist, bend and squat periodically

#LI-DNI

MN1",2025-07-19T00:00:00.000Z,2025-07-25,"[""Master's degree in Data Science, Statistics, Systems Engineering, Computer Science, or a related field"", '5+ years of experience applying data science in a defense, intelligence, or C2 domain', 'Familiarity with military acquisition processes and the DoD Data Strategy, including metadata standards, and AI/ML integration', 'Strong communication and collaboration skills to support policy development, stakeholder engagement, and cross-functional coordination', 'Strong understanding of the data science domain including trends, technologies, and toolsets', 'Proficiency in data platforms such as SQL and no SQL databases, big data, distributed data processing', 'Proficiency in Python, R, SQL, or other relevant data analysis languages', 'SECURITY CLEARANCE REQUIRED: Must currently hold a Secret security clearance', 'US Citizenship is required', 'Must be able to lift up to 25 pounds', 'Must be able to stand and walk for prolonged amounts of time', 'Must be able to twist, bend and squat periodically']","['UIC Bowhead is seeking a mission-focused, policy-savvy C2 Data Scientist to support the Program Manager for Marine Air-Ground Task Force Command and Control (PM MAGTF C2) within a military acquisition program office', 'This role bridges traditional data science with strategic-level advisory functions', 'The successful candidate will operate at the intersection of data science, enterprise portfolio management, and tactical command and control (C2) systems', 'This position will directly contribute to shaping emerging DoD, Joint, and USMC data-centric policies and tactics, techniques, and procedures (TTPs), while ensuring that advanced analytics and AI/ML solutions align with both enterprise and operational warfighter needs', ""Coordinate PM MAGTF C2's participation in developing DoD, Joint, and Marine Corps data strategies and TTPs related to integrated C2, mission command, Zero Trust, and data governance"", 'Contribute to cross-functional working groups, shaping policy and strategy for data-centric operations at both tactical and enterprise levels', 'Perform and/or assess statistical and exploratory data analysis (EDA) on portfolio-level data to inform executive decisions and SAFe-aligned strategy execution', 'Drive the design and implementation of predictive models and machine learning techniques tailored for DDIL environments and tactical decision-making contexts', 'Develop and/or support the creation of dashboards and visualizations that support Lean Portfolio Management (LPM), strategic portfolio reviews, and operational alignment', ""Lead the development and coordination of PM MAGTF C2's data governance plan and tagging guidance, ensuring alignment with enterprise and mission needs"", 'Drive the implementation of enterprise level data policies into the PM MAGTF C2 data strategy', 'Assess and recommend emerging data science, AI/ML tools, and architectures for integration into composable, tactical decision support platforms', 'Author and deliver technical reports and white papers on analytics strategies, governance frameworks, and model integration to support portfolio objectives']",True,['AI/ML Integration'],"AI/ML Integration: Ensure that advanced analytics and AI/ML solutions align with both enterprise and operational warfighter needs; assess and recommend emerging AI/ML tools and architectures for integration into composable, tactical decision support platforms.","['Exploratory Data Analysis', 'Predictive Modeling', 'Machine Learning', 'Dashboards and Data Visualization', 'Data Governance', 'SQL and NoSQL Databases', 'Python and R Programming']","Exploratory Data Analysis: Perform and/or assess statistical and exploratory data analysis (EDA) on portfolio-level data to inform executive decisions and SAFe-aligned strategy execution.; Predictive Modeling: Drive the design and implementation of predictive models tailored for DDIL environments and tactical decision-making contexts.; Machine Learning: Drive the design and implementation of machine learning techniques tailored for DDIL environments and tactical decision-making contexts; assess and recommend AI/ML tools and architectures for integration into tactical decision support platforms.; Dashboards and Data Visualization: Develop and/or support the creation of dashboards and visualizations that support Lean Portfolio Management, strategic portfolio reviews, and operational alignment.; Data Governance: Lead the development and coordination of data governance plans and tagging guidance to ensure alignment with enterprise and mission needs; drive the implementation of enterprise-level data policies into the data strategy.; SQL and NoSQL Databases: Proficiency in data platforms such as SQL and NoSQL databases, big data, and distributed data processing.; Python and R Programming: Proficiency in Python, R, SQL, or other relevant data analysis languages used for data science and analytics tasks."
Kivyrc7fiUv35ibSAAAAAA==,Cyber Data Science Engineer Jobs,"Program Description:

The program provides Systems Engineering and Technical Assistance (SETA) core and non-core support in the areas of Cyber Security and Management to improve the Information Assurance (IA) posture of a National customer. The contracts Core Capabilities are: IA Management, Federal Information Security Management Act (FISMA) coordination and reporting, Risk Management Framework (RMF) application, IA compliance measurements and metrics, Assessment and Authorization (A&A), Vulnerability Management, and Cyber Defense support.

Position Description:

The Cyber Data Science Engineer provides support to the customer in the area of Cyber Security. Daily Tasks include, but are not limited to:
• Utilize analytical, statistical, and programming skills to collect, analyze, and interpret large cybersecurity data sets
• Develop data-driven solutions
• Analyze data sets found in the customer's vulnerability scanning, authorization, and configuration management tools
• Import and transform data into usable sets for analysis tools used by the customer (e.g., Tableau)
• Provide analysis and graphical presentations of collected metrics for IA compliance status reporting
• Support legacy visualization and situational awareness tools based on Microsoft Excel
• Collaborate with the Heat Map team to investigate options to simplify and automate the current Heat Map

Job Requirements

Required:
• Current U.S. Government Top Secret clearance with SCI eligibility.
• Favorably adjudicated Polygraph.
• Bachelor of Science Degree in Science, Technology, Engineering or Mathematics (STEM) or an advanced IA certification (i.e., CISSP or CASP)
• DoD 8570 certification in IAT or IAM
• Deep understanding of statistics and analysis
• Skilled in artificial intelligence and machine learning (e.g., SageMaker)
• Ability to code in multiple languages, including Python
• Knowledge of databases, data structures, and data architectures
• Excellent communications skills - both verbal and non-verbal
• Office Automation Skills - MS Office, MS Project, Visio
• Self-starter requiring limited direction and supervision
• Strong attention to detail
• Ability to work in a team environment
• Experience with data visualization tools (e.g. Tableau, Infogram, Chartbloks)
• Experience with data transformation (structured data format/schema transformation) using common programming tools (e.g., Python, JSON, etc.)
• Experience applying statistical analysis to large data sets

Desired:
• Experience briefing senior customer personnel
• Experience with Tableau administration
• Ability to organize and prioritize numerous customer requests in a fast pace deadline driven environment
• Familiarity with Amazon Web Services (AWS)
• Familiarity with customer's IA processes
• Experience with ServiceNow and Splunk
• Experience supporting IC or DoD in the Cyber Security Domain
• Familiarity with the RMF process
• Experience with Relational Database Management System (RDMS)
• Experience with Apache Hadoop and the Hadoop Distributed File System
• Experience with Amazon Elastic MapReduce (EMR) and SageMaker
• Experience with Machine Learning or Artificial Intelligence

Travel

Security Clearance

Top Secret/SCI/CI Poly",2025-07-25T00:00:00.000Z,2025-07-25,"['Current U.S. Government Top Secret clearance with SCI eligibility', 'Favorably adjudicated Polygraph', 'Bachelor of Science Degree in Science, Technology, Engineering or Mathematics (STEM) or an advanced IA certification (i.e., CISSP or CASP)', 'DoD 8570 certification in IAT or IAM', 'Deep understanding of statistics and analysis', 'Skilled in artificial intelligence and machine learning (e.g., SageMaker)', 'Ability to code in multiple languages, including Python', 'Knowledge of databases, data structures, and data architectures', 'Excellent communications skills - both verbal and non-verbal', 'Office Automation Skills - MS Office, MS Project, Visio', 'Self-starter requiring limited direction and supervision', 'Strong attention to detail', 'Ability to work in a team environment', 'Experience with data visualization tools (e.g', 'Tableau, Infogram, Chartbloks)', 'Experience with data transformation (structured data format/schema transformation) using common programming tools (e.g., Python, JSON, etc.)', 'Experience applying statistical analysis to large data sets']","['The program provides Systems Engineering and Technical Assistance (SETA) core and non-core support in the areas of Cyber Security and Management to improve the Information Assurance (IA) posture of a National customer', 'The Cyber Data Science Engineer provides support to the customer in the area of Cyber Security', 'Utilize analytical, statistical, and programming skills to collect, analyze, and interpret large cybersecurity data sets', 'Develop data-driven solutions', ""Analyze data sets found in the customer's vulnerability scanning, authorization, and configuration management tools"", 'Import and transform data into usable sets for analysis tools used by the customer (e.g., Tableau)', 'Provide analysis and graphical presentations of collected metrics for IA compliance status reporting', 'Support legacy visualization and situational awareness tools based on Microsoft Excel', 'Collaborate with the Heat Map team to investigate options to simplify and automate the current Heat Map']",True,['Amazon SageMaker'],Amazon SageMaker: Used as a platform for developing and deploying machine learning and artificial intelligence models to support cybersecurity data analysis and solutions.,"['Statistical Analysis', 'Data Visualization Tools', 'Data Transformation', 'Python Programming', 'Databases and Data Architectures', 'Machine Learning', 'Relational Database Management Systems (RDBMS)', 'Big Data Technologies']","Statistical Analysis: Used to analyze large cybersecurity data sets and apply statistical methods to interpret data for Information Assurance compliance and vulnerability management.; Data Visualization Tools: Experience with tools such as Tableau, Infogram, Chartbloks, and Microsoft Excel to create graphical presentations and support situational awareness and compliance status reporting.; Data Transformation: Transforming structured data formats and schemas using programming tools like Python and JSON to prepare data for analysis and visualization.; Python Programming: Used for coding, data transformation, and analysis tasks related to cybersecurity data sets.; Databases and Data Architectures: Knowledge of databases, data structures, and architectures to manage and analyze cybersecurity-related data.; Machine Learning: Applied to develop data-driven solutions and analyze cybersecurity data, including experience with AWS SageMaker.; Relational Database Management Systems (RDBMS): Experience managing and querying relational databases relevant to cybersecurity data.; Big Data Technologies: Experience with Apache Hadoop, Hadoop Distributed File System, and Amazon Elastic MapReduce (EMR) to handle large-scale cybersecurity data processing."
z1zA2HhCf8D6og4gAAAAAA==,"Senior Data Scientist, NLP","Senior Data Scientist - NLP

Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making.

As a Data Scientist at Capital One, you’ll be part of a team that’s leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives.

Team Description

AI Foundations Specialist Models Data Science team builds and ships state of the art scalable architecture, AI/ML solutions for Capital One’s award-winning mobile app. We partner with product, tech and design teams to deliver app features that delight customers with dynamic and personalized experiences, enable them to chat with Capital One’s digital assistant Eno, or search for useful contents. You will be the driving force to experiment, innovate and create next generation experiences powered by the latest emerging generative AI technologies.

In this role, you will:
• Partner with a cross-functional team of data scientists, software engineers, machine learning engineers and product managers to deliver AI powered products that change how customers interact with their money.
• Leverage a broad stack of technologies — Pytorch, AWS Ultraclusters, Hugging Face, LangChain, Lightning, VectorDBs, and more — to reveal the insights hidden within huge volumes of numeric and textual data.
• Be the expert in Natural Language Processing (NLP) to harness the power of Large Language Models (LLMs), adapt and finetune them for customer facing applications and features.
• Build machine learning and NLP models through all phases of development, from design through training, evaluation, and validation; partnering with engineering teams to operationalize them in scalable and resilient production systems that serve 80+ million customers.
• Flex your interpersonal skills to translate the complexity of your work into tangible business goals.

The Ideal Candidate is:
• Customer first. You love the process of analyzing and creating, but also share our passion to do the right thing. You know at the end of the day it’s about making the right decision for our customers.
• Innovative. You continually research and evaluate emerging technologies. You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them.
• Creative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You’re not afraid to share a new idea.
• A leader. You challenge conventional thinking and work with stakeholders to identify and improve the status quo. You're passionate about talent development for your own team and beyond.
• Technical. You’re comfortable with advanced ML and DL technologies including language models and are passionate about developing further. You have hands-on experience working with LLMs and solutions using open-source tools and cloud computing platforms.
• Influential. You are passionate about AI/ML and can bring along a cross functional team in breakthrough innovations. You communicate clearly and effectively to share your findings with non-technical audiences.
• You are experienced in training language models or large computer vision models as well as have expertise in one or more key subdomains such as: training optimization, self-supervised learning, explainability, RLHF.
• You have an engineering mindset as shown by a track record of delivering models at scale both in training data and inference volumes. You have experience in delivering libraries, platforms, or solution level code to existing products.

Basic Qualifications:
• Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:
• A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 2 years of experience performing data analytics
• A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration

Preferred Qualifications:
• Master’s Degree in “STEM” field (Science, Technology, Engineering, or Mathematics), or PhD in “STEM” field (Science, Technology, Engineering, or Mathematics)
• Experience working with AWS
• At least 2 years’ experience in Python, Scala, or R
• At least 2 years’ experience with machine learning
• At least 2 years’ experience with SQL

Capital One will consider sponsoring a new qualified applicant for employment authorization for this position.

The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.
McLean, VA: $133,000 - $151,800 for Sr Assoc, Data ScienceNew York, NY: $145,100 - $165,600 for Sr Assoc, Data ScienceSan Jose, CA: $145,100 - $165,600 for Sr Assoc, Data Science

Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate’s offer letter.
This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.

Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at theCapital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.
This role is expected to accept applications for a minimum of 5 business days.No agencies please. Capital One is an equal opportunity employer (EOE, including disability/vet) committed to non-discrimination in compliance with applicable federal, state, and local laws. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",2025-07-03T00:00:00.000Z,2025-07-25,"['Customer first', 'You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them', 'You thrive on bringing definition to big, undefined problems', 'You love asking questions and pushing hard to find answers', 'You challenge conventional thinking and work with stakeholders to identify and improve the status quo', ""You're passionate about talent development for your own team and beyond"", 'Technical', 'You’re comfortable with advanced ML and DL technologies including language models and are passionate about developing further', 'You have hands-on experience working with LLMs and solutions using open-source tools and cloud computing platforms', 'Influential', 'You are passionate about AI/ML and can bring along a cross functional team in breakthrough innovations', 'You communicate clearly and effectively to share your findings with non-technical audiences', 'You are experienced in training language models or large computer vision models as well as have expertise in one or more key subdomains such as: training optimization, self-supervised learning, explainability, RLHF', 'You have an engineering mindset as shown by a track record of delivering models at scale both in training data and inference volumes', 'You have experience in delivering libraries, platforms, or solution level code to existing products', 'Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:', ""A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 2 years of experience performing data analytics"", ""A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration""]","['You will be the driving force to experiment, innovate and create next generation experiences powered by the latest emerging generative AI technologies', 'Partner with a cross-functional team of data scientists, software engineers, machine learning engineers and product managers to deliver AI powered products that change how customers interact with their money', 'Leverage a broad stack of technologies — Pytorch, AWS Ultraclusters, Hugging Face, LangChain, Lightning, VectorDBs, and more — to reveal the insights hidden within huge volumes of numeric and textual data', 'Be the expert in Natural Language Processing (NLP) to harness the power of Large Language Models (LLMs), adapt and finetune them for customer facing applications and features', 'Build machine learning and NLP models through all phases of development, from design through training, evaluation, and validation; partnering with engineering teams to operationalize them in scalable and resilient production systems that serve 80+ million customers', 'Flex your interpersonal skills to translate the complexity of your work into tangible business goals', 'You continually research and evaluate emerging technologies']",True,"['Large Language Models', 'Generative AI', 'PyTorch', 'Hugging Face', 'LangChain', 'Vector Databases', 'Lightning', 'Reinforcement Learning from Human Feedback', 'Self-Supervised Learning', 'Explainability']","Large Language Models: Central to the role for adapting, fine-tuning, and deploying customer-facing AI applications, enabling advanced natural language understanding and generation capabilities.; Generative AI: Employed to create next-generation customer experiences powered by emerging AI technologies, including dynamic and personalized interactions within the mobile app.; PyTorch: Used as a deep learning framework to develop and train neural network models, particularly large language models and other AI solutions.; Hugging Face: Leveraged as an open-source platform and library for accessing, fine-tuning, and deploying transformer-based models and other state-of-the-art AI technologies.; LangChain: Utilized to build AI-powered applications that integrate language models with external data sources and workflows, enhancing the capabilities of AI products.; Vector Databases: Used to store and retrieve high-dimensional vector embeddings generated by AI models, supporting efficient similarity search and retrieval in AI applications.; Lightning: Applied as a framework to streamline and scale deep learning model training and deployment, improving efficiency in AI model development.; Reinforcement Learning from Human Feedback: Implemented as a key subdomain expertise to optimize training of language models, enhancing model performance and alignment with user expectations.; Self-Supervised Learning: Used as an advanced training technique to improve model learning from unlabeled data, contributing to the development of robust AI models.; Explainability: Incorporated to provide transparency and interpretability of AI model decisions, ensuring trust and understanding in AI-powered products.","['Natural Language Processing', 'Machine Learning', 'Data Analytics', 'SQL', 'Python']","Natural Language Processing: Used as a core expertise area to build and adapt models for customer-facing applications, leveraging textual data to create personalized and dynamic user experiences.; Machine Learning: Applied to build models through all phases of development including design, training, evaluation, and validation, and to operationalize scalable production systems serving millions of customers.; Data Analytics: Involves analyzing large volumes of numeric and textual data to reveal insights that inform product features and customer interactions.; SQL: Used as a data querying tool to support data analytics and model development processes.; Python: Utilized as a primary programming language for data science, machine learning, and model development tasks."
VdFYXEyTnfhyWtOLAAAAAA==,Junior Data Engineer - 1129-P Jobs,"Location: Reston, VA

Clearance Requirement: TS w/ SCI Eligibility

Job Description and Responsibilities:

Come join the future of data-driven decision making! At Data Machines we leverage data analytics, DevSecOps, machine intelligence, and data science to engineer solutions for our Federal government, defense, and commercial sponsors to solve real-world, critical mission problems.

Data Machines is looking for a motivated and detail-oriented Junior Data Engineer to join our growing Data Engineering team. This is an exciting opportunity for someone early in their career to gain hands-on experience with modern data technologies, contribute to the development of data pipelines, and help drive data-driven decision-making across the organization. This position is full-time on site in Reston, VA.

Key Responsibilities:
• Assist in the design, development, and maintenance of scalable data pipelines and ETL processes
• Work with structured and unstructured data from various sources to ingest, clean, transform, and store in appropriate formats
• Support the creation and optimization of data models in data warehouses (e.g., Postgres)
• Monitor data pipeline performance and troubleshoot issues as needed
• Collaborate with data analysts, data scientists, and software engineers to understand data needs
• Ensure data quality, integrity, and consistency across all data systems
• Maintain documentation for data processes and pipelines
• Learn and adapt to new tools, technologies, and best practices in data engineering

Minimum Qualifications:
• Active TS Clearance with SCI Eligibility
• Bachelor's degree in Computer Science, Engineering, Information Systems, or a related field
• Proficiency in SQL and at least one programming language (e.g., Python)
• Familiarity with relational databases and data warehousing concepts
• Understanding of ETL concepts and tools
• Exposure to workflow orchestration tools like Apache Airflow, NiFi and Kafka
• Strong analytical and problem-solving skills
• Excellent communication and teamwork abilities
• Eagerness to learn and grow in a fast-paced environment
• Experience in Jupyter Notebooks, PostgreSQL.
• Experience with version control systems (e.g., Git)

Desired Qualifications:
• Knowledge of data lake technologies and big data tools (e.g., Spark)
• Familiarity with containerization tools like Docker",2025-07-25T01:00:00.000Z,2025-07-25,"['Active TS Clearance with SCI Eligibility', ""Bachelor's degree in Computer Science, Engineering, Information Systems, or a related field"", 'Proficiency in SQL and at least one programming language (e.g., Python)', 'Familiarity with relational databases and data warehousing concepts', 'Understanding of ETL concepts and tools', 'Exposure to workflow orchestration tools like Apache Airflow, NiFi and Kafka', 'Strong analytical and problem-solving skills', 'Excellent communication and teamwork abilities', 'Eagerness to learn and grow in a fast-paced environment', 'Experience in Jupyter Notebooks, PostgreSQL', 'Experience with version control systems (e.g., Git)']","['Assist in the design, development, and maintenance of scalable data pipelines and ETL processes', 'Work with structured and unstructured data from various sources to ingest, clean, transform, and store in appropriate formats', 'Support the creation and optimization of data models in data warehouses (e.g., Postgres)', 'Monitor data pipeline performance and troubleshoot issues as needed', 'Collaborate with data analysts, data scientists, and software engineers to understand data needs', 'Ensure data quality, integrity, and consistency across all data systems', 'Maintain documentation for data processes and pipelines', 'Learn and adapt to new tools, technologies, and best practices in data engineering']",False,,,,
7lTh6mDn6ETjNrFtAAAAAA==,Data Science SME Instructor Jobs,"Responsibilities:
• Provide training support to ensure operations personnel receive the necessary systems knowledge required to advance their knowledge and comprehension of Data Science and Advanced Data Analytics capabilities/tradecraft, either directly or with the assistance of Data Scientist or Domain Experts
• Provide insight into current/future course needs/development across the wide spectrum of Data Science and Advanced Data Analytics tradecraft.
• Perform the majority of course development, instruct high-level specialized courses, and identify/incorporate new data science/analytics techniques into course materials and offerings
• Provide mission areas with direct mentoring to assist customers with implementation of newly acquired/learned skills

Required Skills:
• Must be a U.S. Citizen
• Active TS/SCI clearance and polygraph required
• Preferred: Experience instructing NCU courses/NCU Adjunct Certified
• Minimum of four (4) years' experience performing data-analysis on massive amounts of collected information in order to pinpoint unique insight and intelligence opportunities within the data
• Must have experience with scripting/data analytics (Python, Perl, Bash, etc.)
• Must be highly proficient within at least two of the following skill areas:
• Mathematics/Statistics
• Computer Science
• Scripting
• Cloud Computing
• Data Mining, Metadata Analysis or Machine Learning
• Artificial Intelligence
• Data Visualization or Data Automation.
• Must have familiarity with relational capabilities integration, a wide variety of tools and tradecraft, as well as automation of analytic processes
• Must be an expert in understanding ""Big Data Analytics"" from the perspective of data management, data preparation, data governance and analytic development and production
• Must have in-depth experience with at least two of the following advanced scripting languages and tools; Python, R, SQL, Lucene, Jupyter, Pig, Scala, ELK Stack, Splunk, PowerBI, or Jupyter Notebooks

Compensation Range: $186,000 - $245,000

_____________________________________________________________________________________________________

Compensation ranges encompass a total compensation package and are a general guideline only and not intended as a guaranteed and/or implied final compensation or salary for this job opening. Determination of official compensation or salary relies on several different factors including, but not limited to: level of position, complexity of job responsibilities, geographic location, candidate's scope of relevant work experience, educational background, certifications, contract-specific affordability, organizational requirements and alignment with local market data.

Our compensation includes other indirect financial components designed to support employees' total well-being, which should be considered when evaluating our competitive benefits package. These monetary benefits include medical insurance, life insurance, disability, paid time off, maternity/paternity leave, 401(k) company match, training/education reimbursements and other work/life programs.

_____________________________________________________________________________________________________

IntelliGenesis is committed to providing equal opportunity to all employees and applicants for employment. The Company is an Equal Opportunity Employer (EOE), and as such, does not tolerate discrimination, retaliation, or harassment of its employees or applicants based upon race, color, religion, gender, sexual orientation, national origin, age, genetic information, disability, or any other protected characteristic under local, state, or federal law in any employment practice. Such employment practices include, but are not limited to: hiring, promotion, demotion, transfer, recruitment, or recruitment advertising, selection, disciplinary action layoff, termination, rates of pay, or other forms of compensation and selection of training.

IntelliGenesis is committed to the fair and equal employment of individuals with disabilities. It is the Company's policy to reasonably accommodate qualified individuals with disabilities unless the accommodation would impose an undue hardship on the organization. In accordance with the Americans with Disabilities Act (ADA) as amended, reasonable accommodations will be provided to qualified individuals with disabilities, when such accommodations are necessary, to enable them to perform the essential functions of their jobs or to enjoy the equal benefits and privileges of employment. This policy applies to all applicants for employment and all employees.",2025-07-22T00:00:00.000Z,2025-07-25,"['Must be a U.S. Citizen', 'Active TS/SCI clearance and polygraph required', ""Minimum of four (4) years' experience performing data-analysis on massive amounts of collected information in order to pinpoint unique insight and intelligence opportunities within the data"", 'Must have experience with scripting/data analytics (Python, Perl, Bash, etc.)', 'Must be highly proficient within at least two of the following skill areas:', 'Mathematics/Statistics', 'Computer Science', 'Scripting', 'Cloud Computing', 'Data Mining, Metadata Analysis or Machine Learning', 'Artificial Intelligence', 'Data Visualization or Data Automation', 'Must have familiarity with relational capabilities integration, a wide variety of tools and tradecraft, as well as automation of analytic processes', 'Must be an expert in understanding ""Big Data Analytics"" from the perspective of data management, data preparation, data governance and analytic development and production', 'Must have in-depth experience with at least two of the following advanced scripting languages and tools; Python, R, SQL, Lucene, Jupyter, Pig, Scala, ELK Stack, Splunk, PowerBI, or Jupyter Notebooks']","['Provide training support to ensure operations personnel receive the necessary systems knowledge required to advance their knowledge and comprehension of Data Science and Advanced Data Analytics capabilities/tradecraft, either directly or with the assistance of Data Scientist or Domain Experts', 'Provide insight into current/future course needs/development across the wide spectrum of Data Science and Advanced Data Analytics tradecraft', 'Perform the majority of course development, instruct high-level specialized courses, and identify/incorporate new data science/analytics techniques into course materials and offerings', 'Provide mission areas with direct mentoring to assist customers with implementation of newly acquired/learned skills']",True,['Artificial Intelligence'],Artificial Intelligence: Understanding and applying artificial intelligence concepts as part of the data science and analytics capabilities taught and mentored in the role.,"['Data Analysis', 'Scripting Languages', 'Mathematics and Statistics', 'Data Mining and Metadata Analysis', 'Machine Learning', 'Artificial Intelligence', 'Data Visualization and Automation', 'Big Data Analytics', 'Relational Capabilities Integration', 'Tools and Frameworks']","Data Analysis: Performing data analysis on massive amounts of collected information to pinpoint unique insights and intelligence opportunities within the data.; Scripting Languages: Experience with scripting and data analytics using languages such as Python, Perl, Bash, R, SQL, Scala, and Pig to automate analytic processes and support data science tasks.; Mathematics and Statistics: Proficiency in mathematics and statistics as foundational skills for data science and analytics.; Data Mining and Metadata Analysis: Applying data mining and metadata analysis techniques to extract meaningful patterns and insights from large datasets.; Machine Learning: Utilizing machine learning methods as part of advanced data analytics capabilities and tradecraft.; Artificial Intelligence: Knowledge and application of artificial intelligence concepts within data science and analytics contexts.; Data Visualization and Automation: Using data visualization tools and data automation techniques to present data insights and streamline analytic workflows.; Big Data Analytics: Expertise in big data analytics focusing on data management, data preparation, data governance, and analytic development and production.; Relational Capabilities Integration: Familiarity with integrating relational capabilities and a wide variety of tools and tradecraft to support analytic processes.; Tools and Frameworks: In-depth experience with advanced tools such as Lucene, Jupyter Notebooks, ELK Stack, Splunk, and PowerBI to support data science and analytics activities."
NZfkLG0Jg-Da5b3wAAAAAA==,DATA POLICY ANALYST - VIRGINIA -URGENT Jobs,"Job Number: 169

Job Category: GovTech

Job Title: DATA POLICY ANALYST - VIRGINIA -URGENT

Job Type: Full-time

Clearance Level: TS/SCI with POLY

Work Arrangement: On-site

Job Location: Tysons VA

Background
• Document data dictionaries and curation processes to deploy consistent understanding of data across Sponsor internal stakeholders and external product consumers
• Support Sponsor technical engagements with LNI Executive Agent, including communication of priorities for LNI technical development
• Enhance data quality models to address advanced data curation needs (e.g., classification analysis) and to integrate IC mission data to key parameters (e.g., NIPF, National Intelligence Program (NIP)
• Contribute to development of tools to automate data collection and enhance the data collection process
• Support Sponsor technical engagements with IC elements on data definition and quality issues, including bilateral conversations and IC-wide forums

Requirements
• Bachelor's degree in a relevant field (Business Information Systems, Library Science) or equivalent relevant experience
• 3+ years of experience developing data standards and/or operating data governance efforts within and across IC elements
• 3+ years of experience evaluating and monitoring data quality using database tools and data visualization techniques
• Demonstrated knowledge of IC reporting data standards and formats and knowledge of software tools for data governance and specification (e.g., Collibra)

Preferred
• Experience developing data standards and/or interfaces documentation as implemented in an international, IC or US Government specification",2025-07-25T11:00:00.000Z,2025-07-25,"[""Bachelor's degree in a relevant field (Business Information Systems, Library Science) or equivalent relevant experience"", '3+ years of experience developing data standards and/or operating data governance efforts within and across IC elements', '3+ years of experience evaluating and monitoring data quality using database tools and data visualization techniques', 'Demonstrated knowledge of IC reporting data standards and formats and knowledge of software tools for data governance and specification (e.g., Collibra)']","['Document data dictionaries and curation processes to deploy consistent understanding of data across Sponsor internal stakeholders and external product consumers', 'Support Sponsor technical engagements with LNI Executive Agent, including communication of priorities for LNI technical development', 'Enhance data quality models to address advanced data curation needs (e.g., classification analysis) and to integrate IC mission data to key parameters (e.g., NIPF, National Intelligence Program (NIP)', 'Contribute to development of tools to automate data collection and enhance the data collection process', 'Support Sponsor technical engagements with IC elements on data definition and quality issues, including bilateral conversations and IC-wide forums']",False,,,,
H9PUzNh9aNkfnKxvAAAAAA==,Senior AI/ML Cybersecurity Data Scientist Jobs,"Senior AI/ML Cybersecurity Data Scientist

Job Category: Science

Time Type: Full time

Minimum Clearance Required to Start: TS/SCI with Polygraph

Employee Type: Regular

Percentage of Travel Required: None

Type of Travel: None
• * *

The Opportunity:

CACI is seeking a Senior AI/ML Cybersecurity Data Scientist to be at the forefront of developing and securing cutting-edge machine learning solutions. This unique role combines advanced data science expertise with a focus on AI/ML security and compliance. You will have the opportunity to shape the future of secure AI systems, working on groundbreaking projects that require both analytical prowess and a deep understanding of cybersecurity frameworks. Join us in this exciting role where you will leverage your data science expertise to drive innovation while ensuring the security and compliance of critical AI/ML systems. Your work will directly impact the development of secure, cutting-edge machine learning solutions in high-stakes environments.

Responsibilities:
• Develop and implement machine learning, data mining, and graph-based algorithms for complex datasets
• Prototype and evaluate algorithms, selecting optimal models based on performance metrics • Generate insightful reports and visualizations to communicate data-driven insights
• Collaborate with subject matter experts to automate manual data analysis processes
• Secure and obtain authorization for AI/ML systems under the Risk Management Framework (RMF)
• Write and maintain System Security Plans (SSPs) for AI/ML projects
• Conduct risk assessments and ensure compliance of AI/ML systems
• Define security and performance requirements for AI/ML tools
• Manage secure deployment and configuration of AI/ML services
• Perform security reviews for AI/ML requests and implementations

Qualifications:

Required:
• Active TS/SCI w/ Polygraph
• Bachelor's degree in a quantitative discipline (e.g., statistics, mathematics, operations research, engineering, or computer science)
• 10+ years of experience analyzing datasets and developing analytics
• 10+ years of experience programming with data analysis software (e.g., R, Python, SAS, or MATLAB)
• Experience with AI/ML RMF SSP authorization
• Expertise in AI/ML services contracts and configurations
• Proficiency in conducting AI/ML request security reviews

Desired:
• Master's degree or PhD in a relevant field (can substitute for years of experience)
• Experience in software development and cloud environments
• Strong background in cybersecurity principles and practices
• Excellent communication skills to convey complex technical concepts
• Ability to work effectively in cross-functional teams
• Passion for staying current with the latest AI/ML and security trends

-
________________________________________________________________________________________

What You Can Expect:

A culture of integrity.

At CACI, we place character and innovation at the center of everything we do. As a valued team member, you'll be part of a high-performing group dedicated to our customer's missions and driven by a higher purpose - to ensure the safety of our nation.

An environment of trust.

CACI values the unique contributions that every employee brings to our company and our customers - every day. You'll have the autonomy to take the time you need through a unique flexible time off benefit and have access to robust learning resources to make your ambitions a reality.

A focus on continuous growth.

Together, we will advance our nation's most critical missions, build on our lengthy track record of business success, and find opportunities to break new ground - in your career and in our legacy.

Your potential is limitless. So is ours.

Learn more about CACI here.

________________________________________________________________________________________

Pay Range: There are a host of factors that can influence final salary including, but not limited to, geographic location, Federal Government contract labor categories and contract wage rates, relevant prior work experience, specific skills and competencies, education, and certifications. Our employees value the flexibility at CACI that allows them to balance quality work and their personal lives. We offer competitive compensation, benefits and learning and development opportunities. Our broad and competitive mix of benefits options is designed to support and protect employees and their families. At CACI, you will receive comprehensive benefits such as; healthcare, wellness, financial, retirement, family support, continuing education, and time off benefits. Learn more here .

The proposed salary range for this position is:
$131,800 - $290,000

CACI is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, age, national origin, disability, status as a protected veteran, or any other protected characteristic.",2025-07-23T00:00:00.000Z,2025-07-25,"['Minimum Clearance Required to Start: TS/SCI with Polygraph', 'You will have the opportunity to shape the future of secure AI systems, working on groundbreaking projects that require both analytical prowess and a deep understanding of cybersecurity frameworks', 'Active TS/SCI w/ Polygraph', ""Bachelor's degree in a quantitative discipline (e.g., statistics, mathematics, operations research, engineering, or computer science)"", '10+ years of experience analyzing datasets and developing analytics', '10+ years of experience programming with data analysis software (e.g., R, Python, SAS, or MATLAB)', 'Experience with AI/ML RMF SSP authorization', 'Expertise in AI/ML services contracts and configurations', 'Proficiency in conducting AI/ML request security reviews']","['Your work will directly impact the development of secure, cutting-edge machine learning solutions in high-stakes environments', 'Develop and implement machine learning, data mining, and graph-based algorithms for complex datasets', 'Prototype and evaluate algorithms, selecting optimal models based on performance metrics', 'Generate insightful reports and visualizations to communicate data-driven insights', 'Collaborate with subject matter experts to automate manual data analysis processes', 'Secure and obtain authorization for AI/ML systems under the Risk Management Framework (RMF)', 'Write and maintain System Security Plans (SSPs) for AI/ML projects', 'Conduct risk assessments and ensure compliance of AI/ML systems', 'Define security and performance requirements for AI/ML tools', 'Manage secure deployment and configuration of AI/ML services', 'Perform security reviews for AI/ML requests and implementations']",True,['AI/ML Security and Compliance'],"AI/ML Security and Compliance: Focus on securing AI/ML systems by obtaining authorization under the Risk Management Framework (RMF), writing and maintaining System Security Plans (SSPs), conducting risk assessments, ensuring compliance, defining security and performance requirements, managing secure deployment and configuration, and performing security reviews for AI/ML services and requests.","['Machine Learning', 'Data Mining', 'Graph-Based Algorithms', 'Data Analysis Software', 'Data Visualization', 'Automation of Data Analysis']","Machine Learning: Develop and implement machine learning algorithms for complex datasets and prototype and evaluate models based on performance metrics to support secure AI/ML solutions in cybersecurity contexts.; Data Mining: Apply data mining techniques to extract meaningful patterns from complex datasets as part of developing secure machine learning solutions.; Graph-Based Algorithms: Develop and implement graph-based algorithms to analyze complex datasets relevant to cybersecurity data science tasks.; Data Analysis Software: Utilize programming languages and tools such as R, Python, SAS, and MATLAB for data analysis and developing analytics in cybersecurity data science.; Data Visualization: Generate insightful reports and visualizations to communicate data-driven insights effectively within cybersecurity and AI/ML projects.; Automation of Data Analysis: Collaborate with subject matter experts to automate manual data analysis processes to improve efficiency in cybersecurity data workflows."
rr9tGrODdjuX6FdeAAAAAA==,Data Scientist III Jobs,"Overview

Falconwood is a woman-owned, veteran-owned company providing consultation and programmatic support to Department of Defense Information Technology (IT) initiatives and programs. We provide expert advice and consultation on a diverse range of IT subjects, focusing on acquisition, policy, cybersecurity, engineering, and process development.

The Data Scientist III will be responsible for leading advanced analytics and data science initiatives in support of the Commander, Naval Information Forces (NAVIFOR) N6 Directorate, with a focus on strategic data enablement across the Navy Information Warfare enterprise.

Responsibilities

This position provides oversight and direction for the implementation of data strategies, frameworks, and predictive analytics. The candidate will align data solutions with mission goals, lead cross-functional teams, and guide the adoption of enterprise-wide data governance, visualization, and analysis tools. This position is a hybrid role based in Suffolk, VA, with limited travel anticipated.

Responsibilities
• Lead the strategic development and execution of data science and analytics initiatives supporting NAVIFOR's Command Data Office (CDO)
• Oversee the implementation of the NAVIFOR CDO Data and Analytics Capability Maturity Implementation Plan (I-Plan)
• Apply advanced data science techniques including machine learning, AI, and statistical modeling to develop mission-aligned insights
• Coordinate enterprise data governance and strategy across diverse stakeholder groups
• Provide subject matter expertise in designing and optimizing Extract, Transform, Load (ETL) pipelines and data architecture
• Supervise and mentor junior data scientists, analysts, and engineers in best practices and methodologies
• Develop performance metrics, dashboards, and process improvement strategies using NPIER/DMAIC
• Author and present detailed white papers, briefs, and reports to Flag/SES-level stakeholders

Qualifications

Education: Master's degree in Analytics, Statistics, Computer Science, Information Systems, Engineering, Mathematics, or a related discipline

Experience: Minimum of 7 years of demonstrated experience in data strategy, data science, governance, and advanced analytics, preferably supporting DoD or Navy enterprise environments

Clearance: Active Secret Clearance required

Technical Skills:
• Expertise in statistical analysis, AI/ML frameworks, and advanced analytics tools
• Familiarity with data governance, Navy data strategies, and enterprise analytics
• Experience with Navy cloud platforms, data engineering tools, and collaboration tools such as Power BI, Jupyter, Confluence, and Jama

The candidate must:
• Be capable of performing effectively individually and as part of a team
• Have effective critical thinking and problem-solving skills
• Be self-motivated and able to successfully deliver with minimal supervision
• Be proficient in Microsoft Office Suite

Pay Range

Base pay is $135,000-$145,000, subject to skill level, qualifications, and location.

Benefits Highlights:

401k, Tuition Reimbursement, Health/Dental/Vision Insurance, PTO, Federal Holidays, Performance Increases, Reserve Duty Compensation and more!",2025-07-18T00:00:00.000Z,2025-07-25,"[""Education: Master's degree in Analytics, Statistics, Computer Science, Information Systems, Engineering, Mathematics, or a related discipline"", 'Experience: Minimum of 7 years of demonstrated experience in data strategy, data science, governance, and advanced analytics, preferably supporting DoD or Navy enterprise environments', 'Clearance: Active Secret Clearance required', 'Expertise in statistical analysis, AI/ML frameworks, and advanced analytics tools', 'Familiarity with data governance, Navy data strategies, and enterprise analytics', 'Experience with Navy cloud platforms, data engineering tools, and collaboration tools such as Power BI, Jupyter, Confluence, and Jama', 'Be capable of performing effectively individually and as part of a team', 'Have effective critical thinking and problem-solving skills', 'Be self-motivated and able to successfully deliver with minimal supervision', 'Be proficient in Microsoft Office Suite']","['The Data Scientist III will be responsible for leading advanced analytics and data science initiatives in support of the Commander, Naval Information Forces (NAVIFOR) N6 Directorate, with a focus on strategic data enablement across the Navy Information Warfare enterprise', 'This position provides oversight and direction for the implementation of data strategies, frameworks, and predictive analytics', 'The candidate will align data solutions with mission goals, lead cross-functional teams, and guide the adoption of enterprise-wide data governance, visualization, and analysis tools', 'This position is a hybrid role based in Suffolk, VA, with limited travel anticipated', ""Lead the strategic development and execution of data science and analytics initiatives supporting NAVIFOR's Command Data Office (CDO)"", 'Oversee the implementation of the NAVIFOR CDO Data and Analytics Capability Maturity Implementation Plan (I-Plan)', 'Apply advanced data science techniques including machine learning, AI, and statistical modeling to develop mission-aligned insights', 'Coordinate enterprise data governance and strategy across diverse stakeholder groups', 'Provide subject matter expertise in designing and optimizing Extract, Transform, Load (ETL) pipelines and data architecture', 'Supervise and mentor junior data scientists, analysts, and engineers in best practices and methodologies', 'Develop performance metrics, dashboards, and process improvement strategies using NPIER/DMAIC', 'Author and present detailed white papers, briefs, and reports to Flag/SES-level stakeholders']",True,['Artificial Intelligence'],Artificial Intelligence: Apply AI frameworks as part of advanced data science techniques to develop mission-aligned insights.,"['Machine Learning', 'Statistical Modeling', 'Data Governance', 'Extract, Transform, Load (ETL) Pipelines', 'Data Strategy', 'Data Visualization and Dashboards', 'Advanced Analytics', 'Data Engineering Tools', 'Power BI', 'Jupyter', 'NPIER/DMAIC']","Machine Learning: Apply advanced data science techniques including machine learning to develop mission-aligned insights.; Statistical Modeling: Use statistical modeling as part of advanced data science techniques to generate insights aligned with mission goals.; Data Governance: Coordinate enterprise data governance and strategy across diverse stakeholder groups and guide the adoption of enterprise-wide data governance tools.; Extract, Transform, Load (ETL) Pipelines: Provide subject matter expertise in designing and optimizing ETL pipelines and data architecture.; Data Strategy: Lead the strategic development and execution of data science and analytics initiatives and oversee the implementation of data strategies and frameworks.; Data Visualization and Dashboards: Guide the adoption of enterprise-wide visualization and analysis tools and develop performance metrics and dashboards.; Advanced Analytics: Lead advanced analytics initiatives and apply advanced analytics tools to support mission goals.; Data Engineering Tools: Experience with data engineering tools to support data architecture and pipeline optimization.; Power BI: Use Power BI as a collaboration and visualization tool within the enterprise analytics environment.; Jupyter: Utilize Jupyter notebooks as part of data science and analytics workflows.; NPIER/DMAIC: Develop performance metrics and process improvement strategies using NPIER/DMAIC methodologies."
ipKOsWNirrArF9ziAAAAAA==,"Data Scientist, Mid Jobs","Job Number: R0222267

Data Scientist, Mid

The Opportunity:

Are you excited at the prospect of unlocking the secrets held by a data set? Are you fascinated by the possibilities presented by the IoT, machine learning, and artifi cia l intelligence advances? In an increasingly connected world, massive amounts of structured and unstructured data open-up new opportunities. As a data scientist, you can turn these complex data sets into useful information to solve global challenges. Across private and public sectors from fraud detection to cancer research, to national intelligence, you know the answers are in the data.

We have an opportunity for you to use your leadership and analytical skills to improve a client's data science capability. You'll work closely with your client to understand their questions and needs, and then dig into their data-rich environment to find the pieces of their information puzzle. You'll mentor teammates and use the right combination of tools and frameworks to turn that set of disparate data points into objective answers to help leadership make informed decisions. You'll provide your customer with a deep understanding of their data, what it all means, and how they can use it. Join us as we use data science for good in building this capability.

Join us. The world can't wait.

You Have:
• 3+ years of experience with programming in R, Python, or Java
• Experience with business analytics, including dashboarding in Power BI or Tableau, business process analysis, and defining and capturing metrics
• Experience with data engineering, including ETL and querying APIs
• Experience with VBA
• Ability to communicate and collaborate with senior DoD leadership
• Ability to experiment and solve complex open-ended client challenges
• TS / SCI clearance
• Bachelor's degree

Nice If You Have:
• Experience with foundational military intelligence or DoD intelligence processes
• Knowledge of Intelligence Community ( IC ) systems, policies , platforms, data types, and challenges
• TS/SCI clearance with a polygraph

Clearance:

Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information ; TS/SCI clearance is required.

Compensation

At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen's benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.

Salary at Booz Allen is determined by various factors, including but not limited to location, the individual's particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $77,500.00 to $176,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen's total compensation package for employees. This posting will close within 90 days from the Posting Date.

Identity Statement

As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud.

Work Model

Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.
• If this position is listed as remote or hybrid, you'll periodically work from a Booz Allen or client site facility.
• If this position is listed as onsite, you'll work with colleagues and clients in person, as needed for the specific role.

Commitment to Non-Discrimination

All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law.",2025-07-22T00:00:00.000Z,2025-07-25,"['3+ years of experience with programming in R, Python, or Java', 'Experience with business analytics, including dashboarding in Power BI or Tableau, business process analysis, and defining and capturing metrics', 'Experience with data engineering, including ETL and querying APIs', 'Experience with VBA', 'Ability to communicate and collaborate with senior DoD leadership', 'Ability to experiment and solve complex open-ended client challenges', 'TS / SCI clearance', ""Bachelor's degree"", 'Experience with foundational military intelligence or DoD intelligence processes', 'Knowledge of Intelligence Community ( IC ) systems, policies , platforms, data types, and challenges', 'TS/SCI clearance with a polygraph', 'Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information ; TS/SCI clearance is required']","[""We have an opportunity for you to use your leadership and analytical skills to improve a client's data science capability"", ""You'll work closely with your client to understand their questions and needs, and then dig into their data-rich environment to find the pieces of their information puzzle"", ""You'll mentor teammates and use the right combination of tools and frameworks to turn that set of disparate data points into objective answers to help leadership make informed decisions"", ""You'll provide your customer with a deep understanding of their data, what it all means, and how they can use it"", ""If this position is listed as remote or hybrid, you'll periodically work from a Booz Allen or client site facility"", ""If this position is listed as onsite, you'll work with colleagues and clients in person, as needed for the specific role""]",True,[],,"['R programming', 'Python programming', 'Java programming', 'Business analytics', 'Power BI', 'Tableau', 'Data engineering', 'ETL', 'API querying', 'VBA']","R programming: Used for programming and data analysis tasks as part of the data scientist role.; Python programming: Used for programming and data analysis tasks as part of the data scientist role.; Java programming: Used for programming and data analysis tasks as part of the data scientist role.; Business analytics: Involves dashboarding with tools like Power BI or Tableau, business process analysis, and defining and capturing metrics to support decision-making.; Power BI: Used for creating business intelligence dashboards to visualize and analyze data.; Tableau: Used for creating business intelligence dashboards to visualize and analyze data.; Data engineering: Includes ETL (Extract, Transform, Load) processes and querying APIs to manage and prepare data for analysis.; ETL: Part of data engineering responsibilities involving extracting, transforming, and loading data for analysis.; API querying: Used to retrieve data from external or internal sources as part of data engineering tasks.; VBA: Used for automation and scripting within data-related workflows."
_CsHNij4e3_2ocvEAAAAAA==,Mid Data Scientist Jobs,"Prescient Edge is seeking a Mid. Data Scientist to support a federal government client.

Benefits:

At Prescient Edge, we believe that acting with integrity and serving our employees is the key to everyone's success. To that end, we provide employees with a best-in-class benefits package that includes:
• A competitive salary with performance bonus opportunities.
• Comprehensive healthcare benefits, including medical, vision, dental, and orthodontia coverage.
• A substantial retirement plan with no vesting schedule.
• Career development opportunities, including on-the-job training, tuition reimbursement, and networking.
• A positive work environment where employees are respected, supported, and engaged.

Job Requirements

Experience:
• 3+ years of experience in one or more of the following: Business Analysis, Army Special Operations, Intelligence and/or Information Management/ Knowledge Management.
• 3+ years of Experience supporting the United States Military, preferably SOF elements.
• Certification or 2+ years of experience with a diverse set of analytical tools and suites to include Tableau and Alteryx and familiarity with Python, R, MATLAB or other coding platforms.

Education:
• BA/BS from an accredited institution, or former Officer, NCO or Warrant Officer with Military Experience or Intelligence/Knowledge Management background.

Security Clearance:
• Current DOD TS/SCI security clearance.

Location:
• Fort Bragg, NC.

Prescient Edge is a Veteran-Owned Small Business (VOSB) founded as a counterintelligence (CI) and Human Intelligence (HUMINT) company in 2008. We are a global operations and solutions integrator delivering full-spectrum intelligence analysis support, training, security, and RD&E support solutions to the Department of Defense and throughout the intelligence community. Prescient Edge is an Equal Opportunity Employer (EEO). All applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, or any other characteristic that is protected by law. We strive to foster equity and inclusion throughout our organization because we believe that diversity of thought is critical for creating a safe and engaging work environment while also enabling the organization's success.",2025-07-25T02:00:00.000Z,2025-07-25,"['3+ years of experience in one or more of the following: Business Analysis, Army Special Operations, Intelligence and/or Information Management/ Knowledge Management', '3+ years of Experience supporting the United States Military, preferably SOF elements', 'Certification or 2+ years of experience with a diverse set of analytical tools and suites to include Tableau and Alteryx and familiarity with Python, R, MATLAB or other coding platforms', 'BA/BS from an accredited institution, or former Officer, NCO or Warrant Officer with Military Experience or Intelligence/Knowledge Management background', 'Current DOD TS/SCI security clearance']",,True,[],,"['Tableau', 'Alteryx', 'Python', 'R', 'MATLAB']","Tableau: Used as an analytical tool for data visualization and business intelligence to support data analysis tasks.; Alteryx: Utilized as a data analytics platform to prepare, blend, and analyze data for intelligence and business analysis purposes.; Python: Familiarity with Python is required for coding and data analysis tasks within the role.; R: Knowledge of R is expected for statistical analysis and data manipulation.; MATLAB: Experience with MATLAB is relevant for numerical computing and data analysis in the context of intelligence and knowledge management."
HUITRzw7krG6o6tIAAAAAA==,Data Scientist (5010) Jobs,"GVI Inc., subsidiary of Three Saints Bay, LLC, and a Federal Government Contractor industry leader, is seeking a Data Scientist in Philadelphia, PA.

Position Requirement:
• Target Education: Bachelors degree in engineering or business from an accredited college or university.
• Target Experience: Five (5) years of experience in transforming raw data into meaningful insights through advanced data programming, statistical analysis, and visualization tools. This individual should demonstrate strong analytical skills, proficiency in scripting languages such as Python or R, and expertise in SQL for data extraction and integration. Key abilities include applying data mining, modeling, and machine learning techniques to analyze large datasets, as well as creating dynamic reports, dashboards, and visualizations.
• U.S. Citizen

Position is located in Philadelphia, PA.

VEVRAA Federal Contractor

Three Saints Bay, LLC and its subsidiaries offer a team-oriented working environment and the opportunity to work with exceptional, dedicated industry professionals. We offer our employees a comprehensive benefits package and the opportunity to take part in exciting projects with government and commercial clients, both domestic and international.

We are an Equal Opportunity Employer. We invite resumes from all interested parties without regard to race, color, sex, sexual preference, religion, creed, national origin, age, genetic information, marital or veteran status, disability, or any other category protected by federal, state, or local law.",2025-07-18T00:00:00.000Z,2025-07-25,"['Target Education: Bachelors degree in engineering or business from an accredited college or university', 'Target Experience: Five (5) years of experience in transforming raw data into meaningful insights through advanced data programming, statistical analysis, and visualization tools', 'This individual should demonstrate strong analytical skills, proficiency in scripting languages such as Python or R, and expertise in SQL for data extraction and integration', 'Key abilities include applying data mining, modeling, and machine learning techniques to analyze large datasets, as well as creating dynamic reports, dashboards, and visualizations', 'U.S. Citizen']",,True,[],,"['Python', 'R', 'SQL', 'Data Mining', 'Statistical Analysis', 'Machine Learning', 'Data Visualization', 'Data Modeling']","Python: Used as a scripting language for advanced data programming and analysis.; R: Used as a scripting language for advanced data programming and statistical analysis.; SQL: Used for data extraction and integration from large datasets.; Data Mining: Applied to analyze large datasets and extract meaningful insights.; Statistical Analysis: Used to transform raw data into meaningful insights through advanced analysis techniques.; Machine Learning: Applied to analyze large datasets and build predictive or analytical models.; Data Visualization: Creating dynamic reports, dashboards, and visualizations to communicate insights.; Data Modeling: Used to represent and analyze data structures and relationships within large datasets."
6rFMigrlJs0dAy89AAAAAA==,ML/Data Science Software Engineer (Onsite) Jobs,"Date Posted:
2025-07-18
Country:
United States of America
Location:
PA602: 302 Science Park Road, Bldg 5C 302 Science Park Road Building 5C, State College, PA, 16803-2214 USA
Position Role Type:
Onsite
U.S. Citizen, U.S. Person, or Immigration Status Requirements:
Active and transferable U.S. government issued security clearance is required prior to start date. U.S. citizenship is required, as only U.S. citizens are eligible for a security clearance
Security Clearance:
TS/SCI without Polygraph

At Raytheon, the foundation of everything we do is rooted in our values and a higher calling - to help our nation and allies defend freedoms and deter aggression. We bring the strength of more than 100 years of experience and renowned engineering expertise to meet the needs of today's mission and stay ahead of tomorrow's threat. Our team solves tough, meaningful problems that create a safer, more secure world.

In the ML/Data Science Software Engineering role, you will design, develop, and test AI/ML, Java and Python code in a Linux, Agile, DevOps environment. We are at the forefront of aerospace and defense technology. Our Satellite Ground Systems Team plays a pivotal role in ensuring communication, surveillance, and defense capabilities through cutting-edge satellite systems. We invite you to be part of a team that pushes the boundaries of what's possible. Due to the security clearance requirement, this is an onsite position in our State College, PA office.

What You Will Do
• Design, develop, and maintain advanced software applications for our Satellite Ground Systems.
• Collaborate closely with systems engineers, hardware designers, and other software engineers to deliver reliable and high-performance software solutions.
• Design, implement, and test AI, ML, Java and Python based applications and software components for satellite ground systems.
• Work in parallel with legacy platform teams to eventually migrate workloads onto your pipelines.
• Collaborate with cross-functional teams to define software requirements and specifications.
• Work with previously written code and make modifications as necessary.
• Ensure software performance, reliability, and scalability.
• Participate in software design reviews, code reviews, and system integration activities.
• Contribute to the completion of program and project milestones under the specific guidance of their immediate supervisor.
• Follow established Software processes and procedures, development, documentation and maintenance/management of operations concepts, requirements (system, element, segment level), external and internal interfaces, and other software engineering work products/artifacts.

Qualifications You Must Have
• Active and transferable U.S. government issued TS/SCI security clearance is required prior to start date. U.S. citizenship is required, as only U.S. citizens are eligible for a security clearance.
• Typically requires a degree in Science, Technology, Engineering or Mathematics (STEM) and two (2) years of Software Engineering experience.
• Experience in object-oriented software design and development using Java or Python in a Linux environment.
• Experience with unit testing tools (e.g., JUnit).
• Experience in Machine Learning and Data Science.
• Experience working with large datasets and performing data analysis.

Qualifications We Prefer
• Strong analytical skills and proactive problem-solving abilities, with a deep understanding of AI/ML technologies, cloud architecture, and enterprise software.
• Security+ certification.
• Experience with Git, Jenkins, Docker, Kubernetes.
• Experience with the Atlassian Tool Suite (e.g. JIRA, Confluence, BitBucket).
• Experience with cloud computing platform (e.g. AWS or Azure).
• Experience with satellite communication systems and protocols is highly preferred.
• Familiarity with secure coding practices, especially in a defense or aerospace setting.

What We Offer
• Whether you're just starting out on your career journey or are an experienced professional, we offer a total rewards package that goes above and beyond with compensation; healthcare, wellness, retirement, and work/life benefits; career development and recognition programs. Some of the benefits we offer include parental (including paternal) leave, flexible work schedules, achievement awards, educational assistance, and child/adult backup care.
• Relocation Eligibility - Relocation assistance is available.

Learn More & Apply Now!
• Please consider the following role type definition as you apply for this role. Onsite: Employees who are working in Onsite roles will work primarily onsite. This includes all production and maintenance employees, as they are essential to the development of our products.
• This position requires a security clearance. DCSA Consolidated Adjudication Services (DCSA) , an agency of the Department of Defense, handles and adjudicates the security clearance process. More information about Security Clearances can be found on the US Department of State government website here: https://www.state.gov/m/ds/clearances/c10978.htm
• State College, PA: https://careers.rtx.com/global/en/raytheon-state-college,-pa-location
• We Are RTX

#LI-Onsite

#LI-HS30

The salary range for this role is 66,000 USD - 130,000 USD. The salary range provided is a good faith estimate representative of all experience levels. RTX considers several factors when extending an offer, including but not limited to, the role, function and associated responsibilities, a candidate's work experience, location, education/training, and key skills.

Hired applicants may be eligible for benefits, including but not limited to, medical, dental, vision, life insurance, short-term disability, long-term disability, 401(k) match, flexible spending accounts, flexible work schedules, employee assistance program, Employee Scholar Program, parental leave, paid time off, and holidays. Specific benefits are dependent upon the specific business unit as well as whether or not the position is covered by a collective-bargaining agreement.

Hired applicants may be eligible for annual short-term and/or long-term incentive compensation programs depending on the level of the position and whether or not it is covered by a collective-bargaining agreement. Payments under these annual programs are not guaranteed and are dependent upon a variety of factors including, but not limited to, individual performance, business unit performance, and/or the company's performance.

This role is a U.S.-based role. If the successful candidate resides in a U.S. territory, the appropriate pay structure and benefits will apply.

RTX anticipates the application window closing approximately 40 days from the date the notice was posted. However, factors such as candidate flow and business necessity may require RTX to shorten or extend the application window.

RTX is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or veteran status, or any other applicable state or federal protected class. RTX provides affirmative action in employment for qualified Individuals with a Disability and Protected Veterans in compliance with Section 503 of the Rehabilitation Act and the Vietnam Era Veterans' Readjustment Assistance Act.

Privacy Policy and Terms:

Click on this link to read the Policy and Terms",2025-07-21T00:00:00.000Z,2025-07-25,"['Active and transferable U.S. government issued security clearance is required prior to start date', 'U.S. citizenship is required, as only U.S. citizens are eligible for a security clearance', 'TS/SCI without Polygraph', 'Active and transferable U.S. government issued TS/SCI security clearance is required prior to start date', 'U.S. citizenship is required, as only U.S. citizens are eligible for a security clearance', 'Typically requires a degree in Science, Technology, Engineering or Mathematics (STEM) and two (2) years of Software Engineering experience', 'Experience in object-oriented software design and development using Java or Python in a Linux environment', 'Experience with unit testing tools (e.g., JUnit)', 'Experience in Machine Learning and Data Science', 'Experience working with large datasets and performing data analysis', 'Qualifications We Prefer', 'Strong analytical skills and proactive problem-solving abilities, with a deep understanding of AI/ML technologies, cloud architecture, and enterprise software', 'Security+ certification', 'Experience with Git, Jenkins, Docker, Kubernetes', 'Experience with the Atlassian Tool Suite (e.g', 'JIRA, Confluence, BitBucket)', 'Experience with cloud computing platform (e.g', 'AWS or Azure)', 'Familiarity with secure coding practices, especially in a defense or aerospace setting']","['Design, develop, and maintain advanced software applications for our Satellite Ground Systems', 'Collaborate closely with systems engineers, hardware designers, and other software engineers to deliver reliable and high-performance software solutions', 'Design, implement, and test AI, ML, Java and Python based applications and software components for satellite ground systems', 'Work in parallel with legacy platform teams to eventually migrate workloads onto your pipelines', 'Collaborate with cross-functional teams to define software requirements and specifications', 'Work with previously written code and make modifications as necessary', 'Ensure software performance, reliability, and scalability', 'Participate in software design reviews, code reviews, and system integration activities', 'Contribute to the completion of program and project milestones under the specific guidance of their immediate supervisor', 'Follow established Software processes and procedures, development, documentation and maintenance/management of operations concepts, requirements (system, element, segment level), external and internal interfaces, and other software engineering work products/artifacts', 'Onsite: Employees who are working in Onsite roles will work primarily onsite', 'This includes all production and maintenance employees, as they are essential to the development of our products', 'This position requires a security clearance']",True,['Artificial Intelligence'],"Artificial Intelligence: The job involves designing, implementing, and testing AI applications as part of software components for satellite ground systems, requiring a deep understanding of AI technologies.","['Machine Learning', 'Data Analysis', 'Python', 'Java', 'Unit Testing (JUnit)', 'Data Pipelines', 'Cloud Computing Platforms', 'DevOps Tools', 'Agile Software Development', 'Software Performance and Scalability', 'Secure Coding Practices']","Machine Learning: The role involves designing, implementing, and testing machine learning applications and software components for satellite ground systems, requiring experience in machine learning and data science.; Data Analysis: The job requires working with large datasets and performing data analysis to support software development and system performance.; Python: Python is used for software design, development, and testing of AI and ML applications in a Linux environment.; Java: Java is used for object-oriented software design and development, including AI and ML based applications for satellite ground systems.; Unit Testing (JUnit): Experience with unit testing tools such as JUnit is required to ensure software quality and reliability.; Data Pipelines: The role includes migrating workloads onto new pipelines and maintaining data processing workflows for satellite ground systems.; Cloud Computing Platforms: Experience with cloud platforms like AWS or Azure is preferred to support cloud architecture and enterprise software solutions.; DevOps Tools: Familiarity with DevOps tools such as Git, Jenkins, Docker, and Kubernetes is preferred to support software development and deployment processes.; Agile Software Development: The position operates within an Agile development environment, emphasizing iterative software design and collaboration.; Software Performance and Scalability: Ensuring software performance, reliability, and scalability is a key responsibility in developing advanced applications for satellite systems.; Secure Coding Practices: Familiarity with secure coding practices is important, especially given the defense and aerospace context of the software development."
JOSWFIuClsstn5gSAAAAAA==,Data Scientist - TS/SCI with Polygraph,"A career as a Data Scientist at GDIT means being a critical part of successful data outcomes. Here, your work can accelerate solutions for our clients while you accelerate your career. Own the opportunity to build your skills as you provide our clients with the data they need to turn insights and ideas into action.

At GDIT, people are our differentiator. As a Data Scientist supporting our client in Reston, you will help ensure today is safe and tomorrow is smarter. Our work depends on Data Scientist joining our team.

WHAT YOU’LL NEED TO SUCCEED:
• Education: Bachelor’s degree in Computer Science, Engineering, or a related technical discipline, or the equivalent combination of education, technical certifications or training, or work experience.
• Experience: 20+ years
• Technical skills:
• Demonstrated experience in software development using JAVA and python languages.
• Demonstrated experience in DevSecOps activities for large environments.
• Demonstrated experience in identifying and documenting technical risks.
• Demonstrated experience in managing large operational environment account management.
• Demonstrated experience using JIRA, Confluence, and GIT as part of an agile development environment.
• Demonstrated experience working with container orchestration technologies such as Kubernetes.
• Demonstrated experience and understanding of IT Service Management and common SLA measurements.
• Demonstrated experience performing security administration activities such as LDAP.
• Demonstrated experience creating and maintaining operating processes and procedures.
• Demonstrated experience resolving routine to highly complex inquiries.
• Demonstrated expertise with MS Outlook, Office, and working knowledge of standard operating tools and applications.
• Demonstrated experience providing high level customer service supporting users, managers, and staff.
• Demonstrated experience communicating complex technical material and translating into non-technical terms for broad audience
• Security clearance level: TS/SCI with Polygraph
• Desired skills and experience:
• Demonstrated knowledge of help desk processes and procedures.
• Demonstrated knowledge of tracking tools and governance processes.
• Demonstrated expertise in analytic and critical thinking.
• Demonstrated expertise in managing difficult situations with diplomacy, patience, and flexibility.
• Certifications such as:
• Certified Kubernetes Application Developer
• Microsoft Certified Solutions Developer
• AWS Certified Solutions Architect
• AWS Machine Learning Certification(s)
• Agile certification
• Security+
• GIAC Security Essentials Certification (GSEC)
• Location: Reston, VA (On Customer Site)
• US Citizenship required

GDIT IS YOUR PLACE:
• 401K with company match
• Comprehensive health and wellness packages
• Internal mobility team dedicated to helping you own your career
• Professional growth opportunities including paid education and certifications
• Cutting-edge technology you can learn from
• Rest and recharge with paid vacation and holidays

#OpportunityOwned
#GDITCareers
#WeAreGDIT
#JET
#GDITEnhanced2025",2025-07-23T00:00:00.000Z,2025-07-25,"['Education: Bachelor’s degree in Computer Science, Engineering, or a related technical discipline, or the equivalent combination of education, technical certifications or training, or work experience', 'Experience: 20+ years', 'Demonstrated experience in software development using JAVA and python languages', 'Demonstrated experience in DevSecOps activities for large environments', 'Demonstrated experience in identifying and documenting technical risks', 'Demonstrated experience in managing large operational environment account management', 'Demonstrated experience using JIRA, Confluence, and GIT as part of an agile development environment', 'Demonstrated experience working with container orchestration technologies such as Kubernetes', 'Demonstrated experience and understanding of IT Service Management and common SLA measurements', 'Demonstrated experience performing security administration activities such as LDAP', 'Demonstrated experience creating and maintaining operating processes and procedures', 'Demonstrated experience resolving routine to highly complex inquiries', 'Demonstrated expertise with MS Outlook, Office, and working knowledge of standard operating tools and applications', 'Demonstrated experience providing high level customer service supporting users, managers, and staff', 'Demonstrated experience communicating complex technical material and translating into non-technical terms for broad audience', 'Security clearance level: TS/SCI with Polygraph', 'Demonstrated knowledge of help desk processes and procedures', 'Demonstrated knowledge of tracking tools and governance processes', 'Demonstrated expertise in analytic and critical thinking', 'Demonstrated expertise in managing difficult situations with diplomacy, patience, and flexibility', 'Certifications such as:', 'Certified Kubernetes Application Developer', 'Microsoft Certified Solutions Developer', 'AWS Certified Solutions Architect', 'AWS Machine Learning Certification(s)', 'Agile certification', 'Security+', 'GIAC Security Essentials Certification (GSEC)', 'Location: Reston, VA (On Customer Site)', 'US Citizenship required']",,False,,,,
HWijnsTESQt6covJAAAAAA==,Experienced Data Scientist - Fully Cleared,"Make an Impact Where It Matters Most

At Intelliforce, we’re redefining the boundaries of data-driven intelligence by building tools that empower mission partners to act with clarity and speed. As a Data Scientist specializing in graph analytics, you’ll be part of a transformative effort to revolutionize how analysts visualize, explore, and understand complex relationships in real-time mission data. Your work will directly influence how raw data becomes actionable intelligence—supporting the most critical national security operations.

Here’s What Your Day-to-Day Might Include
• Designing and optimizing graph data structures that adapt to dynamic mission needs
• Crafting scalable and performant queries for graph databases, with a focus on Neo4j and Cypher
• Writing and maintaining Python-based data parsers to support ingestion and streaming workflows
• Validating large datasets to ensure integrity, accuracy, and performance under operational constraints
• Translating analyst needs into graph-based technical solutions, collaborating closely with mission users
• Working with developers to integrate queries and ingestion logic into production systems
• Documenting data models, schemas, and pipelines using tools like Confluence
• Engaging directly with end users and mission stakeholders to understand pain points and recommend solutions

Minimum Qualifications
• Clearance: TS/SCI with Full Scope Polygraph
• Citizenship: U.S. Citizen
• Education & Experience:
• Bachelor’s degree in a technical field + 8 years of relevant experience
• OR 12 years of relevant experience in lieu of a degree

Required Skills
• Familiarity with graph databases (e.g., Neo4j) and an interest in mastering Cypher
• Strong Python development skills, particularly for parser creation and data manipulation
• Ability to analyze, model, and manipulate complex data structures
• Experience collaborating with both technical and non-technical stakeholders
• Solid communication skills and a user-focused mindset

Desired Qualifications
• Hands-on experience with Neo4j and the Cypher query language
• Understanding of graph theory and graph-specific algorithms
• Background in real-time data processing, ETL pipelines, or streaming architectures
• Familiarity with TCP/IP networking concepts
• Exposure to containerization tools like Docker and Kubernetes
• Experience working within SIGINT, cyber, or other mission-focused data environments

Compensation Range: $138,000.00 - $182,000.00
• The salary range provided reflects an estimate based on current market trends and may be adjusted based on factors such as the candidate's experience, skills, and qualifications. The final offer will be tailored after a thorough evaluation of the candidate’s background and suitability for the role. Please note that this range is intended as a guideline and is subject to flexibility

Why Intelliforce? Because you matter—your work, your growth, and your well-being.

At Intelliforce, we don’t just push the boundaries of technology—we partner with some of the most mission-driven teams in defense and beyond to solve challenges that truly matter. As a Systems Engineer here, you won’t just contribute to projects—you’ll help shape outcomes that make a real-world impact.

We also know that great work starts with a great environment. That’s why we invest in you:
• Ample PTO to rest and recharge—plus all federal holidays and your birthday off, just because.
• Multiple medical plan options, including ones with zero deductible or premium for employees.
• Generous 401(k) with immediate vesting—because your future matters now.
• Exciting bonus opportunities, from profit sharing to quarterly awards and President’s Club recognition.
• A culture of collaboration, connection, and fun, with regular team activities that go beyond the work.

Ready to grow with purpose?

At Intelliforce, your career will flourish in a place where innovation thrives and people come first. Join us—and let’s build something meaningful together. You can reach us at careers@intelliforce-itsg.com or schedule a call with our Director of Recruitment, just visit this link to view their calendar: https://calendly.com/amwolfe-intelliforce-itsg/30min .

Equal Opportunity Matters

Intelliforce-IT Solutions Group, LLC is proud to be an Equal Opportunity/Affirmative Action Employer. U.S. Citizenship is required for most positions.

Need accommodations during the application process? We’re happy to help. Reach out to us at Recruiting@intelliforce-itsg.com with your specific request.

Powered by JazzHR

nqqsNiJzj6",2025-07-23T00:00:00.000Z,2025-07-25,"['Clearance: TS/SCI with Full Scope Polygraph', 'Citizenship: U.S. Citizen', 'Bachelor’s degree in a technical field + 8 years of relevant experience', 'OR 12 years of relevant experience in lieu of a degree', 'Familiarity with graph databases (e.g., Neo4j) and an interest in mastering Cypher', 'Strong Python development skills, particularly for parser creation and data manipulation', 'Ability to analyze, model, and manipulate complex data structures', 'Experience collaborating with both technical and non-technical stakeholders', 'Solid communication skills and a user-focused mindset', 'U.S. Citizenship is required for most positions']","['As a Data Scientist specializing in graph analytics, you’ll be part of a transformative effort to revolutionize how analysts visualize, explore, and understand complex relationships in real-time mission data', 'Your work will directly influence how raw data becomes actionable intelligence—supporting the most critical national security operations', 'Designing and optimizing graph data structures that adapt to dynamic mission needs', 'Crafting scalable and performant queries for graph databases, with a focus on Neo4j and Cypher', 'Writing and maintaining Python-based data parsers to support ingestion and streaming workflows', 'Validating large datasets to ensure integrity, accuracy, and performance under operational constraints', 'Translating analyst needs into graph-based technical solutions, collaborating closely with mission users', 'Working with developers to integrate queries and ingestion logic into production systems', 'Documenting data models, schemas, and pipelines using tools like Confluence', 'Engaging directly with end users and mission stakeholders to understand pain points and recommend solutions']",True,[],,"['Graph Databases', 'Cypher Query Language', 'Python', 'Data Validation', 'Data Modeling', 'Data Pipelines', 'Graph Theory and Algorithms', 'ETL Pipelines and Real-Time Data Processing', 'Collaboration with Stakeholders', 'Documentation Tools']","Graph Databases: Used for designing and optimizing graph data structures and crafting scalable queries to explore and understand complex relationships in real-time mission data, specifically with Neo4j and Cypher.; Cypher Query Language: Employed to write performant queries for graph databases, enabling efficient data retrieval and manipulation tailored to dynamic mission needs.; Python: Utilized for developing data parsers that support data ingestion and streaming workflows, as well as for data manipulation and validation of large datasets to ensure integrity and accuracy.; Data Validation: Performed to ensure the integrity, accuracy, and performance of large datasets under operational constraints in mission-critical environments.; Data Modeling: Involves translating analyst needs into graph-based technical solutions and documenting data models, schemas, and pipelines to support mission objectives.; Data Pipelines: Includes ingestion and streaming workflows supported by Python parsers and integration of queries and ingestion logic into production systems.; Graph Theory and Algorithms: Applied to understand and manipulate complex data structures within graph databases to support mission analysis and intelligence.; ETL Pipelines and Real-Time Data Processing: Experience with building and maintaining pipelines that process data in real-time or batch modes to support mission-focused data environments.; Collaboration with Stakeholders: Engaging with both technical and non-technical users to understand pain points and recommend data-driven solutions.; Documentation Tools: Using tools like Confluence to document data models, schemas, and pipelines for clarity and knowledge sharing."
nY38LhTzSZJlXiKJAAAAAA==,"Principal Associate, Data Scientist - Data Scientist - Application Fraud Team","Principal Associate, Data Scientist - Data Scientist - Application Fraud Team

Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making.

As a Data Scientist at Capital One, you’ll be part of a team that’s leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives.

Team Description:

The Application Fraud data science team builds the machine learning models that help protect our customers and Capital One against fraudsters. We prevent fraud at the application stage using real-time models. We care deeply about doing things the right way, automating, and innovating to improve the customer experience and prevent fraud.

Role Description

In this role, you will:
• Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love
• Leverage a broad stack of technologies — Python, Conda, AWS, H2O, Spark, and more — to reveal the insights hidden within huge volumes of numeric and textual data
• Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation
• Flex your interpersonal skills to translate the complexity of your work into tangible business goals

The Ideal Candidate is:
• Customer first. You love the process of analyzing and creating, but also share our passion to do the right thing. You know at the end of the day it’s about making the right decision for our customers.
• Innovative. You continually research and evaluate emerging technologies. You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them.
• Creative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You’re not afraid to share a new idea.
• A leader. You challenge conventional thinking and work with stakeholders to identify and improve the status quo. You're passionate about talent development for your own team and beyond.
• Technical. You’re comfortable with open-source languages and are passionate about developing further. You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms.
• Statistically-minded. You’ve built models, validated them, and backtested them. You know how to interpret a confusion matrix or a ROC curve. You have experience with clustering, classification, sentiment analysis, time series, and deep learning.
• A data guru. “Big data” doesn’t faze you. You have the skills to retrieve, combine, and analyze data from a variety of sources and structures. You know understanding the data is often the key to great data science.

Basic Qualifications:
• Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:
• A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 5 years of experience performing data analytics
• A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 3 years of experience performing data analytics
• A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field)

Preferred Qualifications:
• Master’s Degree in “STEM” field (Science, Technology, Engineering, or Mathematics) plus 3 years of experience in data analytics, or PhD in “STEM” field (Science, Technology, Engineering, or Mathematics)
• At least 1 year of experience working with AWS
• At least 3 years’ experience in Python, Scala, or R
• At least 3 years’ experience with machine learning
• At least 3 years’ experience with SQL

Capital One will consider sponsoring a new qualified applicant for employment authorization for this position.

The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.

Chicago, IL: $144,200 - $164,600 for Princ Associate, Data Science

McLean, VA: $158,600 - $181,000 for Princ Associate, Data Science

New York, NY: $173,000 - $197,400 for Princ Associate, Data Science

Richmond, VA: $144,200 - $164,600 for Princ Associate, Data Science

Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate’s offer letter.

This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.

Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.

This role is expected to accept applications for a minimum of 5 business days.

No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",,2025-07-25,"['Customer first', 'You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them', 'You thrive on bringing definition to big, undefined problems', 'You love asking questions and pushing hard to find answers', ""You're passionate about talent development for your own team and beyond"", 'Technical', 'You’re comfortable with open-source languages and are passionate about developing further', 'You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms', 'Statistically-minded', 'You know how to interpret a confusion matrix or a ROC curve', 'You have experience with clustering, classification, sentiment analysis, time series, and deep learning', 'A data guru', 'You have the skills to retrieve, combine, and analyze data from a variety of sources and structures', 'You know understanding the data is often the key to great data science', 'Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:', ""A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 5 years of experience performing data analytics"", ""A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 3 years of experience performing data analytics"", 'A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field)']","['Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love', 'Leverage a broad stack of technologies — Python, Conda, AWS, H2O, Spark, and more — to reveal the insights hidden within huge volumes of numeric and textual data', 'Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation', 'Flex your interpersonal skills to translate the complexity of your work into tangible business goals', 'You continually research and evaluate emerging technologies', 'You challenge conventional thinking and work with stakeholders to identify and improve the status quo', 'You’ve built models, validated them, and backtested them']",True,[],,"['Machine Learning Models', 'Statistical Modeling', 'Classification', 'Clustering', 'Sentiment Analysis', 'Time Series Analysis', 'Deep Learning', 'Confusion Matrix and ROC Curve Interpretation', 'Python', 'Conda', 'AWS', 'H2O', 'Spark', 'SQL', 'Data Retrieval and Integration']","Machine Learning Models: Build machine learning models through all phases of development, including design, training, evaluation, validation, and implementation to prevent fraud at the application stage.; Statistical Modeling: Use statistical modeling techniques to analyze data and personalize credit card offers, as well as to detect and prevent application fraud.; Classification: Apply classification methods as part of building models to identify fraudulent applications.; Clustering: Utilize clustering techniques to analyze data patterns relevant to fraud detection.; Sentiment Analysis: Experience with sentiment analysis as part of data science methods applied in the role.; Time Series Analysis: Use time series methods to analyze data trends and patterns relevant to fraud detection and prevention.; Deep Learning: Apply deep learning techniques as part of the data science toolkit for fraud detection and model building.; Confusion Matrix and ROC Curve Interpretation: Interpret confusion matrices and ROC curves to validate and evaluate the performance of fraud detection models.; Python: Use Python programming language as a primary tool for data analysis, model development, and implementation.; Conda: Leverage Conda for managing Python environments and dependencies in data science workflows.; AWS: Utilize AWS cloud computing platform to handle large-scale data processing and model deployment.; H2O: Use H2O machine learning platform to build and deploy scalable machine learning models.; Spark: Employ Apache Spark for big data processing and analytics on large volumes of numeric and textual data.; SQL: Use SQL to retrieve, combine, and analyze data from various structured data sources.; Data Retrieval and Integration: Retrieve, combine, and analyze data from a variety of sources and structures to support data science solutions."
GpF-f0pzvTLkJcBFAAAAAA==,Principal Data Scientist*,"Description

Leidos has a new and exciting opportunity for a Data Scientist in our National Security Sector's (NSS) Cyber & Analytics Business Area (CABA). Our talented team is at the forefront in Security Engineering, Computer Network Operations (CNO), Mission Software, Analytical Methods and Modeling, Signals Intelligence (SIGINT), and Cryptographic Key Management. At Leidos, we offer competitive benefits, including Paid Time Off, 11 paid Holidays, 401K with a 6% company match and immediate vesting, Flexible Schedules, Discounted Stock Purchase Plans, Technical Upskilling, Education and Training Support, Parental Paid Leave, and much more. Join us and make a difference in National Security!

Job Description

Design and develop methods, processes, and systems to extract raw data from Splunk and create reports and dashboards for data usage auditing. This role is primarily focused on Splunk SPL queries, reports, and dashboards with the need for additional processing and augmentation in Python. Strong interpersonal skills are needed as this role is customer facing.

Primary Responsibilities
• Create innovative solutions to meet the technical needs of customers.
• Work with data science teammates and the customer to create or refine recurring reports and ad-hoc reports.
• Development documentation.
• Conduct experimentation in various data science techniques, as well as developing, executing, and maintaining scripts and prototypes to analyze, interpret, visualize, and gain knowledge from numerous data sets individually or in combination to meet customer requirements.
• Proactively coordinate with customers, Scrum PMs, and cross-functional areas to communicate project statuses and initiatives.
• Analyze data to effectively coordinate, innovate, and implement process improvements to include current and new Splunk and Python reports and scripts.
• Communicate key project data to teammates to foster team cohesion and effectiveness and apply best practices and standard operating procedures.

Basic Qualifications
• 7+ years of expert knowledge in Splunk SPL and Splunk Enterprise systems.
• 5+ years of experience with Python, R, VBA or another object-oriented programming language.
• Experience using the statistical computer language Python to manipulate data and draw insights from large data sets.
• Extensive knowledge in one or more data science libraries, such as NumPy, Pandas, OpenPyXL, etc.
• Experience negotiating solutions to complex technical challenges and developing courses of action to resolve those challenges with predictable outcomes.
• Experience leading high-visibility projects that have organization-wide impact.
• Experience working collaboratively with developers and other data scientists.
• Must possess a Bachelor’s degree with 12+ years of relevant experience or a Master’s degree with 6+ years of relevant experience.
• Must have a TS/SCI with polygraph.

Preferred Qualifications
• 2+ years of experience with Visual Basic for Applications
• 5+ years of experience with SQL queries
• 5+ years of experience with MS Access
• Experience with MySQL
• Experience with SharePoint on-prem
• Experience with PowerShell
• Experience with Tableau

At Leidos, the opportunities are boundless. We challenge our staff with interesting assignments that allow them to thrive professionally and personally. For us, helping you grow your career is good business. We look forward to learning more about you – apply today.

CABARESTON

Original Posting:
May 27, 2025

For U.S. Positions: While subject to change based on business needs, Leidos reasonably anticipates that this job requisition will remain open for at least 3 days with an anticipated close date of no earlier than 3 days after the original posting date as listed above.

Pay Range:
Pay Range $126,100.00 - $227,950.00

The Leidos pay range for this job level is a general guideline only and not a guarantee of compensation or salary. Additional factors considered in extending an offer include (but are not limited to) responsibilities of the job, education, experience, knowledge, skills, and abilities, as well as internal equity, alignment with market data, applicable bargaining agreement (if any), or other law.",,2025-07-25,"['7+ years of expert knowledge in Splunk SPL and Splunk Enterprise systems', '5+ years of experience with Python, R, VBA or another object-oriented programming language', 'Experience using the statistical computer language Python to manipulate data and draw insights from large data sets', 'Extensive knowledge in one or more data science libraries, such as NumPy, Pandas, OpenPyXL, etc', 'Experience negotiating solutions to complex technical challenges and developing courses of action to resolve those challenges with predictable outcomes', 'Experience leading high-visibility projects that have organization-wide impact', 'Experience working collaboratively with developers and other data scientists', 'Must possess a Bachelor’s degree with 12+ years of relevant experience or a Master’s degree with 6+ years of relevant experience', 'Must have a TS/SCI with polygraph']","['Design and develop methods, processes, and systems to extract raw data from Splunk and create reports and dashboards for data usage auditing', 'This role is primarily focused on Splunk SPL queries, reports, and dashboards with the need for additional processing and augmentation in Python', 'Strong interpersonal skills are needed as this role is customer facing', 'Create innovative solutions to meet the technical needs of customers', 'Work with data science teammates and the customer to create or refine recurring reports and ad-hoc reports', 'Development documentation', 'Conduct experimentation in various data science techniques, as well as developing, executing, and maintaining scripts and prototypes to analyze, interpret, visualize, and gain knowledge from numerous data sets individually or in combination to meet customer requirements', 'Proactively coordinate with customers, Scrum PMs, and cross-functional areas to communicate project statuses and initiatives', 'Analyze data to effectively coordinate, innovate, and implement process improvements to include current and new Splunk and Python reports and scripts', 'Communicate key project data to teammates to foster team cohesion and effectiveness and apply best practices and standard operating procedures']",True,[],,"['Splunk SPL', 'Python', 'Data Science Techniques', 'NumPy', 'Pandas', 'OpenPyXL', 'SQL', 'MySQL', 'MS Access', 'Visual Basic for Applications (VBA)', 'PowerShell', 'Tableau']","Splunk SPL: Used to extract raw data and create reports and dashboards for data usage auditing, focusing on queries, reports, and dashboards within Splunk Enterprise systems.; Python: Applied for additional processing and augmentation of data extracted from Splunk, as well as for developing, executing, and maintaining scripts and prototypes to analyze, interpret, visualize, and gain insights from large data sets.; Data Science Techniques: Experimented with various data science methods to analyze and interpret data, supporting the creation and refinement of recurring and ad-hoc reports to meet customer requirements.; NumPy: Utilized as a data science library in Python to manipulate and analyze numerical data within large data sets.; Pandas: Used as a data science library in Python for data manipulation and analysis to support reporting and data interpretation tasks.; OpenPyXL: Employed as a Python library to work with Excel files, facilitating data processing and reporting.; SQL: Used for querying databases such as MySQL and MS Access to support data extraction and reporting needs.; MySQL: Referenced as a database system for which SQL queries are written to extract and manage data.; MS Access: Used as a database platform with SQL querying capabilities to support data management and reporting.; Visual Basic for Applications (VBA): Applied for automation and scripting within Microsoft Office environments to support data processing and reporting tasks.; PowerShell: Used for scripting and automation to support data processing and system management tasks.; Tableau: Utilized as a business intelligence tool to create dashboards and visualizations for data reporting and analysis."
9jT5m8Bkw1Y_0r9gAAAAAA==,DS2 Data Scientist (Full-time & USD salary),", a US company headquartered in Los Angeles, is looking for remote Data Scientists to join and help work on machine learning problems (in the field of NLP) for unstructured data, large enterprise users, and to improve the suite of products that we offer. The ideal candidate should be helpful, responsive, dependable, and comfortable working remotely within a small team with tight deadlines. We value people who thrive working collaboratively in a distributed team and who are enthusiastic about the potential of machine learning.

Your primary responsibility is to independently identify and deliver business insights from very diverse data types and sources. Deliver production-ready code, CSVs, and compelling narrative visualizations.

Salary: $30,000 to $45,000 (in USD) depending on experience

Timezone: PST
Responsibilities
• Own and deliver projects starting with very diverse data and business targets
• Contribute to general features for the internal product library while delivering for specific clients
• Own report delivery for clients, and contribute to library documentation
• Explore and present datasets and narrative visualizations
• Build linguistic and statistical general models
• Translate business problems into specifications for computational tasks like classification or ranking

Requirements
• 2+ years writing queries in SQL or running models in Python/Jupyter
• 2+ years doing statistical analysis
• Write and speak clearly, communicate em-pathetically
• Highest standard of excellence for your work
• Impeccable attention to detail: spotting typos in variables, syntax errors in text and gremlins in data
• Ability to define evidence-based, quantifiable solutions to open-ended business problems
Bonus Points
• Familiar with a range of NLP techniques or computational linguistics
• Fluent data storyteller
• Github: pull, push, merge, PR, cherry-picking, issue tracking
• Regular Expressions
• PostgreSQL 12+
• An example where we can see your writing style (in English), ideally data-related

Benefits
• Paid Time Off
• Work From Home
• Training & Development
We are…

IV.AI is the world's leading language processing AI platform. We have grown fast, but aim to retain our scrappy nature that enabled us to build big AI models that outperform the industry standards. There are many companies right now that talk about the potential impact of AI while we hustle hard and have actually proven the benefits repeatedly.
Helpful

We help people become smarter by using AI or data generated by AI models - the increased human intelligence is driven via a polished AI product that makes sense of noisy social media data, documents, web data, podcasts, internal or external communications. IV.AI takes problems that were previously too complex to manage because of the scope of the research and tracking needed to solve them and makes them easy to solve via high-quality data, easy to use tools and experienced, helpful teams.
Inclusive

Our inclusive culture values people regardless of their background, education or upbringing. In order to train machines to act appropriately, we need builders and contributors who are representative of the entire population. AI is only as good as the teams working on it and the training they receive. AI is incredibly powerful and human bias in the training process can be equally harmful to the world if the technology is not being managed by teams of people who are diverse and considerate.
Hardworking

In just 5 years IV.AI has built a scalable platform with 100s of AI solutions for Fortune 500 companies including Sony, Walmart, Toyota, Netflix, Time Warner, Fox, Capital One, Estée Lauder, to name a few.
Professional

Being professional and respectful of clients and coworkers is of the utmost importance. We work with blue-chip clients and with very sensitive data that requires care and diligence via our focussed security systems and protocols.
Collaborative

Our employees are constantly problem-solving and assessing their own output to maximise delivery. It’s important that our team is always looking for the best way of addressing problems so we can manage customer expectations.

, a US company headquartered in Los Angeles, is looking for remote Data Scientists to join and help work on machine learning problems (in the field of NLP) for unstructured data, large enterprise users, and to improve the suite of products that we offer. The ideal candidate should be helpful, responsive, dependable, and comfortable working remotely within a small team with tight deadlines. We value people who thrive working collaboratively in a distributed team and who are enthusiastic about the potential of machine learning.

Your primary responsibility is to independently identify and deliver business insights from very diverse data types and sources. Deliver production-ready code, CSVs, and compelling narrative visualizations.

Salary: $30,000 to $45,000 (in USD) depending on experience

Timezone: PST
Responsibilities
• Own and deliver projects starting with very diverse data and business targets
• Contribute to general features for the internal product library while delivering for specific clients
• Own report delivery for clients, and contribute to library documentation
• Explore and present datasets and narrative visualizations
• Build linguistic and statistical general models
• Translate business problems into specifications for computational tasks like classification or ranking

Requirements
• 2+ years writing queries in SQL or running models in Python/Jupyter
• 2+ years doing statistical analysis
• Write and speak clearly, communicate em-pathetically
• Highest standard of excellence for your work
• Impeccable attention to detail: spotting typos in variables, syntax errors in text and gremlins in data
• Ability to define evidence-based, quantifiable solutions to open-ended business problems
Bonus Points
• Familiar with a range of NLP techniques or computational linguistics
• Fluent data storyteller
• Github: pull, push, merge, PR, cherry-picking, issue tracking
• Regular Expressions
• PostgreSQL 12+
• An example where we can see your writing style (in English), ideally data-related

Benefits
• Paid Time Off
• Work From Home
• Training & Development
We are…

IV.AI is the world's leading language processing AI platform. We have grown fast, but aim to retain our scrappy nature that enabled us to build big AI models that outperform the industry standards. There are many companies right now that talk about the potential impact of AI while we hustle hard and have actually proven the benefits repeatedly.
Helpful

We help people become smarter by using AI or data generated by AI models - the increased human intelligence is driven via a polished AI product that makes sense of noisy social media data, documents, web data, podcasts, internal or external communications. IV.AI takes problems that were previously too complex to manage because of the scope of the research and tracking needed to solve them and makes them easy to solve via high-quality data, easy to use tools and experienced, helpful teams.
Inclusive

Our inclusive culture values people regardless of their background, education or upbringing. In order to train machines to act appropriately, we need builders and contributors who are representative of the entire population. AI is only as good as the teams working on it and the training they receive. AI is incredibly powerful and human bias in the training process can be equally harmful to the world if the technology is not being managed by teams of people who are diverse and considerate.
Hardworking

In just 5 years IV.AI has built a scalable platform with 100s of AI solutions for Fortune 500 companies including Sony, Walmart, Toyota, Netflix, Time Warner, Fox, Capital One, Estée Lauder, to name a few.
Professional

Being professional and respectful of clients and coworkers is of the utmost importance. We work with blue-chip clients and with very sensitive data that requires care and diligence via our focussed security systems and protocols.
Collaborative

Our employees are constantly problem-solving and assessing their own output to maximise delivery. It’s important that our team is always looking for the best way of addressing problems so we can manage customer expectations.",2025-07-25T14:00:00.000Z,2025-07-25,"['The ideal candidate should be helpful, responsive, dependable, and comfortable working remotely within a small team with tight deadlines', 'We value people who thrive working collaboratively in a distributed team and who are enthusiastic about the potential of machine learning', '2+ years writing queries in SQL or running models in Python/Jupyter', '2+ years doing statistical analysis', 'Write and speak clearly, communicate em-pathetically', 'Highest standard of excellence for your work', 'Impeccable attention to detail: spotting typos in variables, syntax errors in text and gremlins in data', 'Ability to define evidence-based, quantifiable solutions to open-ended business problems', 'Familiar with a range of NLP techniques or computational linguistics', 'Fluent data storyteller', 'Github: pull, push, merge, PR, cherry-picking, issue tracking', 'Regular Expressions', 'PostgreSQL 12+', 'An example where we can see your writing style (in English), ideally data-related', 'Being professional and respectful of clients and coworkers is of the utmost importance', 'The ideal candidate should be helpful, responsive, dependable, and comfortable working remotely within a small team with tight deadlines', 'We value people who thrive working collaboratively in a distributed team and who are enthusiastic about the potential of machine learning', '2+ years writing queries in SQL or running models in Python/Jupyter', '2+ years doing statistical analysis', 'Write and speak clearly, communicate em-pathetically', 'Highest standard of excellence for your work', 'Impeccable attention to detail: spotting typos in variables, syntax errors in text and gremlins in data', 'Ability to define evidence-based, quantifiable solutions to open-ended business problems', 'Familiar with a range of NLP techniques or computational linguistics', 'Fluent data storyteller', 'Github: pull, push, merge, PR, cherry-picking, issue tracking', 'Regular Expressions', 'PostgreSQL 12+', 'An example where we can see your writing style (in English), ideally data-related', 'Being professional and respectful of clients and coworkers is of the utmost importance']","['Your primary responsibility is to independently identify and deliver business insights from very diverse data types and sources', 'Deliver production-ready code, CSVs, and compelling narrative visualizations', 'Own and deliver projects starting with very diverse data and business targets', 'Contribute to general features for the internal product library while delivering for specific clients', 'Own report delivery for clients, and contribute to library documentation', 'Explore and present datasets and narrative visualizations', 'Build linguistic and statistical general models', 'Translate business problems into specifications for computational tasks like classification or ranking', 'We work with blue-chip clients and with very sensitive data that requires care and diligence via our focussed security systems and protocols', 'Your primary responsibility is to independently identify and deliver business insights from very diverse data types and sources', 'Deliver production-ready code, CSVs, and compelling narrative visualizations', 'Own and deliver projects starting with very diverse data and business targets', 'Contribute to general features for the internal product library while delivering for specific clients', 'Own report delivery for clients, and contribute to library documentation', 'Explore and present datasets and narrative visualizations', 'Build linguistic and statistical general models', 'Translate business problems into specifications for computational tasks like classification or ranking']",True,['Machine Learning'],"Machine Learning: Applied to solve problems in the field of NLP for unstructured data, improve product suites, and develop models that support business insights and client solutions.","['SQL', 'Python', 'Statistical Analysis', 'Narrative Visualization', 'Classification', 'Ranking Models', 'Natural Language Processing (NLP) Techniques', 'PostgreSQL', 'Regular Expressions']","SQL: Used for writing queries to extract and manipulate data from databases, essential for working with diverse data sources in the job.; Python: Used for running models and writing production-ready code, including statistical analysis and data processing in Jupyter notebooks.; Statistical Analysis: Applied to analyze data, build general statistical models, and derive evidence-based, quantifiable solutions to business problems.; Narrative Visualization: Creating compelling visual presentations of data to communicate insights effectively to clients and stakeholders.; Classification: Translating business problems into computational tasks involving classification to solve specific client needs.; Ranking Models: Developing models that order or prioritize items, used to address business targets and computational tasks.; Natural Language Processing (NLP) Techniques: Familiarity with a range of NLP methods or computational linguistics to work on unstructured text data and linguistic models.; PostgreSQL: Using PostgreSQL 12+ as a database system for managing and querying structured data.; Regular Expressions: Utilized for pattern matching and text processing tasks within data cleaning or feature extraction workflows."
Z0h5S9trofVXMJTUAAAAAA==,"Business Data Scientist, Sales Insights","The application window will be open until at least July 31, 2025. This opportunity will remain online based on business needs which may be before or after the specified date.

This role may also be located in our Playa Vista, CA campus.

Applicants in the County of Los Angeles: Qualified applications with arrest or conviction records will be considered for employment in accordance with the Los Angeles County Fair Chance Ordinance for Employers and the California Fair Chance Act.

Note: By applying to this position you will have an opportunity to share your preferred working location from the following: New York, NY, USA; Chicago, IL, USA; Mountain View, CA, USA; San Bruno, CA, USA; San Francisco, CA, USA; Sunnyvale, CA, USA; Boulder, CO, USA; Los Angeles, CA, USA; Atlanta, GA, USA.Minimum qualifications:
• Master's degree in a quantitative discipline such as Statistics, Engineering, Sciences, or equivalent practical experience.
• 4 years of experience using analytics to solve product or business problems, coding (e.g., Python, R, SQL), querying databases or statistical analysis.

Preferred qualifications:
• 6 years of experience using analytics to solve product or business problems, coding (e.g., Python, R, SQL), querying databases or statistical analysis.
• Experience with causal inference techniques, including incrementality measurement, observational studies, quasi-experimental designs (e.g., Difference-in-Differences).
• Experience with A/B testing design, implementation, and analysis.

About the jobGoogle's leadership team hand-picks thorny business challenges, and members of BizOps work in small teams to find solutions. As part of this team you fully immerse yourself in data collection, draw insight from analysis, and then zoom out to develop compelling, synthesized recommendations. Taking strategy one step further, you also persuasively communicate your recommendations to senior-level executives, roll-up your sleeves to help drive implementation and check back-in to see the impact of your recommendations.

As a Business Data Scientist on this team, you will be a builder who will be responsible for designing, developing, and implementing advanced models and in-depth analysis to solve business problems. You will leverage various datasets including business behavior, product journeys, business tooling and training interventions to uncover actionable insights. Your work will directly contribute to understanding the drivers of business outcomes, identifying opportunities to increase business and efficiency, and ultimately demonstrating the incremental value and Return on Investment (ROI) of various business and activation levers. You will collaborate closely with data engineers, other analysts, and business stakeholders, translating findings into clear, impactful recommendations.

The US base salary range for this full-time position is $166,000-$244,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.

Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google .

Responsibilities
• Design, build, validate, and deploy statistical techniques (e.g., predictive models, causal inference models, segmentation models) to address key business questions across business activities and activation insights.
• Conduct data analysis to identify operational insights, transforming raw data into clear, actionable business recommendations.
• Design, develop and launch reporting/dashboard solutions to enable stakeholder teams to independently and consistently track and manage key metrics.
• Act as a thought partner to business stakeholders, understanding their issues, translating business questions into well-defined problems, and communicating methodologies and findings clearly and concisely to non-technical audiences to deliver informed decision-making.

Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .",2025-07-25T10:00:00.000Z,2025-07-25,"[""Master's degree in a quantitative discipline such as Statistics, Engineering, Sciences, or equivalent practical experience"", '4 years of experience using analytics to solve product or business problems, coding (e.g., Python, R, SQL), querying databases or statistical analysis']","['As part of this team you fully immerse yourself in data collection, draw insight from analysis, and then zoom out to develop compelling, synthesized recommendations', 'Taking strategy one step further, you also persuasively communicate your recommendations to senior-level executives, roll-up your sleeves to help drive implementation and check back-in to see the impact of your recommendations', 'As a Business Data Scientist on this team, you will be a builder who will be responsible for designing, developing, and implementing advanced models and in-depth analysis to solve business problems', 'You will leverage various datasets including business behavior, product journeys, business tooling and training interventions to uncover actionable insights', 'Your work will directly contribute to understanding the drivers of business outcomes, identifying opportunities to increase business and efficiency, and ultimately demonstrating the incremental value and Return on Investment (ROI) of various business and activation levers', 'You will collaborate closely with data engineers, other analysts, and business stakeholders, translating findings into clear, impactful recommendations', 'Design, build, validate, and deploy statistical techniques (e.g., predictive models, causal inference models, segmentation models) to address key business questions across business activities and activation insights', 'Conduct data analysis to identify operational insights, transforming raw data into clear, actionable business recommendations', 'Design, develop and launch reporting/dashboard solutions to enable stakeholder teams to independently and consistently track and manage key metrics', 'Act as a thought partner to business stakeholders, understanding their issues, translating business questions into well-defined problems, and communicating methodologies and findings clearly and concisely to non-technical audiences to deliver informed decision-making']",True,[],,"['Causal Inference', 'A/B Testing', 'Predictive Modeling', 'Segmentation Models', 'Statistical Analysis', 'Data Analysis', 'Data Collection', 'Reporting and Dashboards', 'SQL', 'Python', 'R']","Causal Inference: Used to measure incrementality and analyze observational studies and quasi-experimental designs such as Difference-in-Differences to understand drivers of business outcomes and demonstrate incremental value and ROI.; A/B Testing: Design, implementation, and analysis of controlled experiments to evaluate business and product changes and their impact on key metrics.; Predictive Modeling: Designing, building, validating, and deploying statistical models to address key business questions and forecast outcomes.; Segmentation Models: Developing models to segment data for deeper insights into business activities and activation levers.; Statistical Analysis: Applying statistical techniques to analyze data, identify operational insights, and transform raw data into actionable business recommendations.; Data Analysis: Conducting in-depth analysis of various datasets including business behavior, product journeys, and training interventions to uncover actionable insights and support decision-making.; Data Collection: Immersing in gathering and preparing data from multiple sources to enable comprehensive analysis and model development.; Reporting and Dashboards: Designing, developing, and launching reporting and dashboard solutions to enable stakeholders to independently track and manage key business metrics consistently.; SQL: Querying databases to extract and manipulate data for analysis and model building.; Python: Using Python programming for coding analytics solutions, statistical modeling, and data manipulation.; R: Utilizing R programming language for statistical analysis and modeling to solve business problems."
MRajmPeaHnLmvVeKAAAAAA==,Data Scientist 5,"Job Description
As a Lead Data Scientist, you'll shape next-gen AI capabilities for Clinical Data Exchange (CDeX)-where payers and providers collaborate seamlessly. You'll build models that power prior authorization, risk adjustment, claims adjudication, and more-making data work smarter across the healthcare ecosystem. You'll also help reduce the administrative burden on clinicians, using AI to automate documentation, extract insights, and deliver real-time intelligence when it matters most. From classical ML to generative models, you'll lead with purpose designing scalable, responsible AI for real-world impact.
Responsibilities
growth and leadership. Responsibilities
- Partner with Product Managers to turn ambitious product visions
into AI-powered solutions that reshape healthcare operations and
experiences.
- Collaborate closely with Clinical Terminologists to ensure models are
clinically sound and aligned with evolving healthcare standards and
vocabularies.
- Work hand-in-hand with UI Engineers and ML Engineers to bring AI
models to life in intuitive, responsive, and scalable products.
- Lead the full lifecycle of AI development-from ideation and research
to deployment and monitoring.
- Apply the latest advancements in machine learning, deep learning,
and generative AI to deliver innovation at scale.
- Architect high-quality, production-ready AI pipelines, ensuring
robustness, accuracy, and compliance with healthcare regulations.
- Develop clean, scalable code and drive best practices across the AI
engineering stack.
- Mentor and inspire a team of data scientists, fostering technical
growth and leadership.
- Contribute to planning, reviews, and retrospectives-driving
continuous improvement and cross-team alignment.
Anticipate and navigate technical and organizational risks to ensure
project success and sustained impact.
Qualifications and Experience
- Proven experience architecting and deploying scalable AI solutions
in production, with measurable impact across complex, real-world
healthcare or enterprise systems.
- Deep technical fluency in machine learning and deep learning
architectures, including Transformers and other neural network
frameworks-plus the intuition to choose the right tool for the right
problem.
- Hands-on expertise in Large Language Models (LLMs) and
generative AI, with experience in advanced prompt engineering,
instruction fine-tuning, and parameter-efficient tuning techniques.
- Proficiency in Python is a must, with experience applying it to build
and deploy AI/ML models and develop robust, scalable solutions.
- Strong foundation in clinical data, with the ability to extract meaning
from structured and unstructured sources and align with
interoperability standards such as FHIR, C-CDA, or HL7.
- Experience building models that support healthcare-critical
processes like prior authorization, risk adjustment, clinical
summarization, or claims adjudication is a major advantage.
- Experience in building a wide range of AI models-including
classical ML models, semantic search, and information retrieval
systems-to power intelligent, high-precision workflows.
- Familiarity with AI evaluation strategies, including data labeling,
annotation workflows, human-in-the-loop review, and longitudinal
model monitoring in high-stakes environments.
- A natural drive to stay ahead of the curve, with the curiosity to
explore cutting-edge research and the discipline to translate it into
resilient, production-ready systems.
- A track record of technical leadership, including mentoring junior
and senior scientists, championing innovation, and cultivating an
environment of curiosity and excellence.
- Bonus: a strong portfolio of patents, publications, or open source
contributions, reflecting thought leadership and a commitment to
pushing the field forward.
Preferred Qualifications:
- Strong understanding of the healthcare ecosystem and proven
experience delivering AI-driven solutions tailored to healthcare
applications, transforming patient care and operational efficiency.
- Familiarity with the latest advancements in Natural Language
Processing (NLP) and Generative AI, empowering you to create
advanced AI systems that interpret, generate, and interact with
complex healthcare data.
- Proven ability to design, deploy, and scale these solutions on cloud
platforms, with preference for OCI (Oracle Cloud Infrastructure),
though experience with AWS and Azure is also highly valued.
Education
- A PhD in Computer Science, Mathematics, Statistics, Physics, Linguistics, or a related discipline, with a deep dive into Machine Learning and Deep Learning through your dissertation or final project, coupled with 12+ years of hands-on experience, is highly valued-but not a dealbreaker, OR A master's or bachelor's degree in a relevant field, paired with 12+ years of practical, impactful experience in the field, will also make you a strong contender.
you a strong contender
Disclaimer:
Certain US customer or client-facing roles may be required to comply with applicable requirements, such as immunization and occupational health mandates.
Range and benefit information provided in this posting are specific to the stated locations only
US: Hiring Range in USD from: $109,200 to $223,400 per annum. May be eligible for bonus and equity.
Oracle maintains broad salary ranges for its roles in order to account for variations in knowledge, skills, experience, market conditions and locations, as well as reflect Oracle's differing products, industries and lines of business.
Candidates are typically placed into the range based on the preceding factors as well as internal peer equity.
Oracle US offers a comprehensive benefits package which includes the following:
- Medical, dental, and vision insurance, including expert medical opinion
- Short term disability and long term disability
- Life insurance and AD&D
- Supplemental life insurance (Employee/Spouse/Child)
- Health care and dependent care Flexible Spending Accounts
- Pre-tax commuter and parking benefits
- 401(k) Savings and Investment Plan with company match
- Paid time off: Flexible Vacation is provided to all eligible employees assigned to a salaried (non-overtime eligible) position. Accrued Vacation is provided to all other employees eligible for vacation benefits. For employees working at least 35 hours per week, the vacation accrual rate is 13 days annually for the first three years of employment and 18 days annually for subsequent years of employment. Vacation accrual is prorated for employees working between 20 and 34 hours per week. Employees working fewer than 20 hours per week are not eligible for vacation.
- 11 paid holidays
- Paid sick leave: 72 hours of paid sick leave upon date of hire. Refreshes each calendar year. Unused balance will carry over each year up to a maximum cap of 112 hours.
- Paid parental leave
- Adoption assistance
- Employee Stock Purchase Plan
- Financial planning and group legal
- Voluntary benefits including auto, homeowner and pet insurance
The role will generally accept applications for at least three calendar days from the posting date or as long as the job remains posted.
Career Level - IC4
About Us
As a world leader in cloud solutions, Oracle uses tomorrow's technology to tackle today's challenges. We've partnered with industry-leaders in almost every sector-and continue to thrive after 40+ years of change by operating with integrity.
We know that true innovation starts when everyone is empowered to contribute. That's why we're committed to growing an inclusive workforce that promotes opportunities for all.
Oracle careers open the door to global opportunities where work-life balance flourishes. We offer competitive benefits based on parity and consistency and support our people with flexible medical, life insurance, and retirement options. We also encourage employees to give back to their communities through our volunteer programs.
We're committed to including people with disabilities at all stages of the employment process. If you require accessibility assistance or accommodation for a disability at any point, let us know by emailing accommodation-request_mb@oracle.com or by calling +1 888 404 2494 in the United States.
Oracle is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability and protected veterans' status, or any other characteristic protected by law. Oracle will consider for employment qualified applicants with arrest and conviction records pursuant to applicable law.",2025-07-23T00:00:00.000Z,2025-07-25,"['Qualifications and Experience', 'Proven experience architecting and deploying scalable AI solutions', 'in production, with measurable impact across complex, real-world', 'Deep technical fluency in machine learning and deep learning', 'Hands-on expertise in Large Language Models (LLMs) and', 'generative AI, with experience in advanced prompt engineering,', 'Proficiency in Python is a must, with experience applying it to build', 'processes like prior authorization, risk adjustment, clinical', 'summarization, or claims adjudication is a major advantage', 'Experience in building a wide range of AI models-including', 'classical ML models, semantic search, and information retrieval', 'systems-to power intelligent, high-precision workflows', 'Familiarity with AI evaluation strategies, including data labeling,', 'A natural drive to stay ahead of the curve, with the curiosity to', 'explore cutting-edge research and the discipline to translate it into', 'Bonus: a strong portfolio of patents, publications, or open source', 'contributions, reflecting thought leadership and a commitment to', 'pushing the field forward', 'experience delivering AI-driven solutions tailored to healthcare', 'applications, transforming patient care and operational efficiency', 'Familiarity with the latest advancements in Natural Language', 'complex healthcare data', 'Proven ability to design, deploy, and scale these solutions on cloud', 'platforms, with preference for OCI (Oracle Cloud Infrastructure),', 'though experience with AWS and Azure is also highly valued', ""A PhD in Computer Science, Mathematics, Statistics, Physics, Linguistics, or a related discipline, with a deep dive into Machine Learning and Deep Learning through your dissertation or final project, coupled with 12+ years of hands-on experience, is highly valued-but not a dealbreaker, OR A master's or bachelor's degree in a relevant field, paired with 12+ years of practical, impactful experience in the field, will also make you a strong contender"", 'Certain US customer or client-facing roles may be required to comply with applicable requirements, such as immunization and occupational health mandates']","[""You'll build models that power prior authorization, risk adjustment, claims adjudication, and more-making data work smarter across the healthcare ecosystem"", ""You'll also help reduce the administrative burden on clinicians, using AI to automate documentation, extract insights, and deliver real-time intelligence when it matters most"", ""From classical ML to generative models, you'll lead with purpose designing scalable, responsible AI for real-world impact"", 'Partner with Product Managers to turn ambitious product visions', 'into AI-powered solutions that reshape healthcare operations and', 'Collaborate closely with Clinical Terminologists to ensure models are', 'clinically sound and aligned with evolving healthcare standards and', 'vocabularies', 'Work hand-in-hand with UI Engineers and ML Engineers to bring AI', 'models to life in intuitive, responsive, and scalable products', 'Lead the full lifecycle of AI development-from ideation and research', 'to deployment and monitoring', 'Apply the latest advancements in machine learning, deep learning,', 'and generative AI to deliver innovation at scale', 'Architect high-quality, production-ready AI pipelines, ensuring', 'robustness, accuracy, and compliance with healthcare regulations', 'Develop clean, scalable code and drive best practices across the AI', 'engineering stack', 'Mentor and inspire a team of data scientists, fostering technical', 'growth and leadership', 'Contribute to planning, reviews, and retrospectives-driving', 'continuous improvement and cross-team alignment', 'Anticipate and navigate technical and organizational risks to ensure', 'project success and sustained impact', 'architectures, including Transformers and other neural network', 'instruction fine-tuning, and parameter-efficient tuning techniques', 'and deploy AI/ML models and develop robust, scalable solutions', 'Strong foundation in clinical data, with the ability to extract meaning', 'from structured and unstructured sources and align with', 'interoperability standards such as FHIR, C-CDA, or HL7', 'Experience building models that support healthcare-critical', 'annotation workflows, human-in-the-loop review, and longitudinal', 'model monitoring in high-stakes environments', 'resilient, production-ready systems', 'A track record of technical leadership, including mentoring junior', 'Processing (NLP) and Generative AI, empowering you to create', 'advanced AI systems that interpret, generate, and interact with']",True,"['Generative AI', 'Large Language Models', 'Transformers', 'Prompt Engineering']","Generative AI: The role involves applying generative AI models to automate clinical documentation, extract insights, and deliver real-time intelligence, driving innovation at scale in healthcare operations.; Large Language Models: Hands-on expertise with Large Language Models (LLMs) is required, including advanced prompt engineering, instruction fine-tuning, and parameter-efficient tuning techniques to build scalable AI solutions.; Transformers: Experience with Transformer architectures is necessary for developing deep learning models that support complex healthcare AI applications.; Prompt Engineering: The job includes advanced prompt engineering to optimize interactions with generative AI models and LLMs for healthcare-specific tasks.","['Machine Learning', 'Deep Learning', 'Python', 'Clinical Data Standards', 'Semantic Search and Information Retrieval', 'AI Evaluation Strategies']","Machine Learning: The job involves applying classical machine learning models to build predictive and analytical solutions that power healthcare processes such as prior authorization, risk adjustment, and claims adjudication.; Deep Learning: The role requires deep technical fluency in deep learning architectures, including neural networks and Transformers, to develop advanced models for healthcare applications.; Python: Proficiency in Python is essential for building, deploying, and scaling AI and machine learning models, as well as developing clean, scalable code across the AI engineering stack.; Clinical Data Standards: The job requires working with clinical data aligned to interoperability standards such as FHIR, C-CDA, and HL7 to extract meaningful insights from structured and unstructured healthcare data.; Semantic Search and Information Retrieval: Experience building AI models that include semantic search and information retrieval systems to enable intelligent, high-precision workflows in healthcare.; AI Evaluation Strategies: Familiarity with AI evaluation methods such as data labeling, annotation workflows, human-in-the-loop review, and longitudinal model monitoring in high-stakes healthcare environments is required."
qtg_xAHD7eRVhbCoAAAAAA==,"Manager, Data Scientist - Shopping Growth (Remote-Eligible)","Manager, Data Scientist - Shopping Growth (Remote-Eligible)

Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making.

As a Data Scientist at Capital One, you’ll be part of a team that’s leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives.

Team Description:

The Shopping Growth team is on a mission to bring our product to millions of new customers and help them unlock savings while also driving great value for our merchant partners. This is an opportunity to join that team’s mission and help supercharge progress through machine learning and advanced analytics.

Role Description:

In this role, you will:
• Be at the center of driving business decisions through leveraging vast datasets to understand customer value at various parts of the customer lifecycle to unlock game changing growth for an already rapidly growing business
• Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation
• Leverage a broad stack of technologies — Python, Conda, AWS, H2O, Spark, and more — to reveal the insights hidden within huge volumes of numeric and textual data
• Flex your interpersonal skills to translate the complexity of your work into tangible business goals

The Ideal Candidate is:
• Results Focused. You understand where the leverage is and desire making an impact to the business’ bottom line through driving high-quality work from start to finish efficiently
• A leader. You challenge conventional thinking and work with stakeholders to identify and improve the status quo. You’re passionate about talent development for your own team and beyond.
• Technical. You’re comfortable with open-source languages and are passionate about developing further. You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms.
• Statistically-minded. You’ve built models, validated them, and backtested them. You know how to interpret a confusion matrix or a ROC curve. You have experience with clustering, classification, sentiment analysis, time series, and deep learning.

Basic Qualifications:
• Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:
• A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 6 years of experience performing data analytics
• A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 4 years of experience performing data analytics
• A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 1 year of experience performing data analytics
• At least 1 year of experience leveraging open source programming languages for large scale data analysis
• At least 1 year of experience working with machine learning
• At least 1 year of experience utilizing relational databases

Preferred Qualifications:
• PhD in “STEM” field (Science, Technology, Engineering, or Mathematics) plus 3 years of experience in data analytics
• At least 1 year of experience working with AWS
• At least 4 years’ experience in Python, Scala, or R for large scale data analysis
• At least 4 years’ experience with machine learning
• At least 4 years’ experience with SQL

Capital One will consider sponsoring a new qualified applicant for employment authorization for this position.

Capital One is open to hiring a Remote Employee for this opportunity

The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.

Remote (Regardless of Location): $175,800 - $200,700 for Mgr, Data Science

McLean, VA: $193,400 - $220,700 for Mgr, Data Science

Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate’s offer letter.

This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.

Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.

This role is expected to accept applications for a minimum of 5 business days.

No agencies please. Capital One is an equal opportunity employer (EOE, including disability/vet) committed to non-discrimination in compliance with applicable federal, state, and local laws. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",,2025-07-25,"['You understand where the leverage is and desire making an impact to the business’ bottom line through driving high-quality work from start to finish efficiently', 'You’re passionate about talent development for your own team and beyond', 'Technical', 'You’re comfortable with open-source languages and are passionate about developing further', 'You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms', 'Statistically-minded', 'You know how to interpret a confusion matrix or a ROC curve', 'You have experience with clustering, classification, sentiment analysis, time series, and deep learning', 'Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:', ""A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 6 years of experience performing data analytics"", ""A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 4 years of experience performing data analytics"", 'A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 1 year of experience performing data analytics', 'At least 1 year of experience leveraging open source programming languages for large scale data analysis', 'At least 1 year of experience working with machine learning', 'At least 1 year of experience utilizing relational databases']","['This is an opportunity to join that team’s mission and help supercharge progress through machine learning and advanced analytics', 'Be at the center of driving business decisions through leveraging vast datasets to understand customer value at various parts of the customer lifecycle to unlock game changing growth for an already rapidly growing business', 'Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation', 'Leverage a broad stack of technologies — Python, Conda, AWS, H2O, Spark, and more — to reveal the insights hidden within huge volumes of numeric and textual data', 'Flex your interpersonal skills to translate the complexity of your work into tangible business goals', 'You challenge conventional thinking and work with stakeholders to identify and improve the status quo', 'You’ve built models, validated them, and backtested them']",True,[],,"['Machine Learning', 'Statistical Modeling', 'Clustering', 'Classification', 'Sentiment Analysis', 'Time Series Analysis', 'Deep Learning', 'Python', 'Conda', 'AWS', 'H2O', 'Spark', 'Relational Databases', 'Open Source Programming Languages', 'Model Validation and Backtesting']","Machine Learning: Build machine learning models through all phases of development, including design, training, evaluation, validation, and implementation to drive business growth and insights.; Statistical Modeling: Use statistical modeling techniques to personalize credit card offers and analyze customer data for business decision-making.; Clustering: Apply clustering methods to segment data and understand customer groups as part of data analysis and model building.; Classification: Develop classification models and interpret performance metrics such as confusion matrices and ROC curves to evaluate model effectiveness.; Sentiment Analysis: Perform sentiment analysis on textual data to extract insights relevant to customer behavior and business decisions.; Time Series Analysis: Utilize time series methods to analyze data trends over time as part of predictive modeling and analytics.; Deep Learning: Experience with deep learning techniques as part of advanced analytics and model development.; Python: Use Python programming language extensively for large scale data analysis and building data science solutions.; Conda: Leverage Conda as a package and environment management system to support data science workflows.; AWS: Utilize Amazon Web Services cloud computing platform to handle large datasets and support machine learning model deployment.; H2O: Employ H2O open-source machine learning platform to build and deploy scalable machine learning models.; Spark: Use Apache Spark for distributed data processing and large scale data analytics.; Relational Databases: Work with relational databases to manage and query structured data as part of data analytics.; Open Source Programming Languages: Leverage open source languages such as Python, Scala, or R for large scale data analysis and data science solution development.; Model Validation and Backtesting: Validate and backtest models to ensure accuracy and reliability before deployment."
8xLzY6gxrhSrqLmpAAAAAA==,Data Scientist (Hybrid/U.S. Citizens Only),"Task Force Talent is seeking data scientists for a very well-funded Series C company working on insider threat and supply chain security problems. Target salary range is 150k to 200k+, plus equity, depending on experience level and location.

Please note that although this is a data science position, the company is looking for skill sets much closer to software engineering. This is NOT a role focused on just on statistical analysis or building dashboards. Candidates will have to pass technical interviews similar to software engineering interviews.

The company is profitable and growing fast with approximately 150+ employees. Positions are available in Tysons Corner, VA, and Salt Lake City, UT, with a hybrid (typically 3 days/week in the office) schedule; however, those hours are flexible to accommodate family/childcare and traffic as the goal of in-office hours is to know your team better.

Benefits
• Company Equity Options and 401(k) Plan
• Unlimited PTO and Wellness Reimbursement
• U.S. Holidays
• Paid Parental Leave
• Comprehensive Insurance (Medical, Dental, and Vision)

This company is completely private sector, no security clearance required; however, employment is open to U.S. citizens only at this time.

____________________________________________________________________________________________________________________________________________

Qualifications
• MUST be a U.S. citizen (no permanent residents, no visa sponsorship); while no clearance is required, candidates must be clearance-eligible.
• AT LEAST 3+ years (ideally 5+ to be most competitive) of experience in data science and/or analytics
• MS or BS in an engineering (preferred) or quantitative field (Science, Economics, Statistics) with a background in programming.
• Strong proficiency in Python, SQL, R or comparable languages
• Experience with large-scale data analysis and statistical modeling
• Ability to transform complex data into actionable insights
• Strong project management and prioritization skills
• Experience with Elasticsearch preferred
• Proven ability to work independently and as part of a team
• Strong communication skills for technical and non-technical audiences

BONUS: Foreign language fluency, particularly languages associated with threat actors.

____________________________________________________________________________________________________________________________________________

Interview Process

This company typically has a phone screen, followed by a coding exercise, and then several in-person interviews. They usually move fast -- introduction to offer within two to three weeks.

About Us

Task Force Talent is a specialized recruiting firm for science, engineering, and security careers. Our clients include seed to Series C startups working on AI, cybersecurity, quantum computing, and other novel technologies. We also work with small to medium-sized government contractors, and we help leading venture capital firms find talent for their portfolio companies. We have hundreds of jobs available and consider all applicants for all roles, now and in the future. Our goal is to find the best fit for you!

____________________________________________________________________________________________________________________________________________

Not your dream job, but perfect for a friend? You can submit a referral and get a check for $2000 or more: https://www.taskforcetalent.com/referral/ (Terms and conditions apply.)

If you don't see the perfect fit, simply use our general application at: https://taskforcetalent.breezy.hr/p/5bbc3c44433e-single-application-for-all-jobs-general",,2025-07-25,"['Candidates will have to pass technical interviews similar to software engineering interviews', 'MUST be a U.S. citizen (no permanent residents, no visa sponsorship); while no clearance is required, candidates must be clearance-eligible', 'AT LEAST 3+ years (ideally 5+ to be most competitive) of experience in data science and/or analytics', 'Strong proficiency in Python, SQL, R or comparable languages', 'Experience with large-scale data analysis and statistical modeling', 'Ability to transform complex data into actionable insights', 'Strong project management and prioritization skills', 'Proven ability to work independently and as part of a team', 'Strong communication skills for technical and non-technical audiences', 'BONUS: Foreign language fluency, particularly languages associated with threat actors']",,True,[],,"['Python', 'SQL', 'R', 'Large-scale data analysis', 'Statistical modeling', 'Transforming complex data into actionable insights', 'Elasticsearch']",Python: Required proficiency in Python programming language for data science tasks.; SQL: Required proficiency in SQL for querying and managing large-scale data.; R: Required proficiency in R programming language or comparable languages for statistical analysis.; Large-scale data analysis: Experience with analyzing large datasets to extract meaningful insights.; Statistical modeling: Experience with building and applying statistical models to data for analysis and prediction.; Transforming complex data into actionable insights: Ability to interpret and convert complex data into practical recommendations or decisions.; Elasticsearch: Preferred experience with Elasticsearch for data search and analytics.
UHRE_CDzNaBk8zTgAAAAAA==,"Senior Data Scientist - Full-Time, High-Impact Role","Help us build the future of supply chain intelligence.

We're a well-funded startup backed by prominent investors, founded by serial entrepreneurs who've previously raised hundreds of millions and built category-defining companies. We're building a next-generation supply chain AI platform that will transform how global commerce operates.

We are seeking a Senior Data Scientist with deep mathematical foundations who can translate cutting-edge research into production systems that scale.

What You'll Do:
• Design and implement advanced ML models for supply chain optimization
• Apply linear programming and optimization techniques to real-world problems
• Build and deploy deep learning models at production scale
• Own the MLOps pipeline for training and serving large models
• Write production-quality code that handles billions of data points
• Collaborate with engineering to integrate models into our platform
• Research and implement state-of-the-art techniques in forecasting and optimization
• Design experiments and analyze results to drive product decisions
• Build self-improving systems that learn from user interactions

You Should Have:
• Master's degree (or PhD) in Computer Science, Mathematics, Statistics, or related field
• Strong mathematical foundations (linear algebra, optimization, probability theory)
• Deep understanding of linear programming and combinatorial optimization
• Extensive experience with deep learning frameworks (PyTorch)
• Proven track record deploying ML models to production
• MLOps experience with large-scale model training and serving
• Proficiency in Python and software engineering best practices
• Experience with distributed computing and big data technologies
• Ability to translate complex research into practical solutions

Bonus Points
• PhD in a relevant field with published research
• Experience with supply chain optimization or operations research
• Built ML infrastructure for training models with billions of parameters
• Experience with real-time ML systems and edge deployment
• Track record at successful startups or top-tier tech companies

Why Join Us?
• Work with founders who've built category leading companies before
• Backed by prominent deep tech investors — we have runway and ambition
• Solve genuinely hard problems that impact global commerce
• Own the entire ML stack with resources to build it right
• Collaborate with a world-class team of engineers
• Competitive compensation with significant equity upside
• Join at the ground floor of what will be a category-defining company

To Apply

Share a production ML system you've built that required both mathematical sophistication and engineering excellence. We're especially interested in examples involving optimization, large-scale training, or systems that improved over time. Include metrics on model performance and system scale if possible.",2025-07-25T04:00:00.000Z,2025-07-25,"[""Master's degree (or PhD) in Computer Science, Mathematics, Statistics, or related field"", 'Strong mathematical foundations (linear algebra, optimization, probability theory)', 'Deep understanding of linear programming and combinatorial optimization', 'Extensive experience with deep learning frameworks (PyTorch)', 'Proven track record deploying ML models to production', 'MLOps experience with large-scale model training and serving', 'Proficiency in Python and software engineering best practices', 'Experience with distributed computing and big data technologies', 'Ability to translate complex research into practical solutions', 'PhD in a relevant field with published research', 'Experience with supply chain optimization or operations research', 'Built ML infrastructure for training models with billions of parameters', 'Experience with real-time ML systems and edge deployment', 'Track record at successful startups or top-tier tech companies', ""Share a production ML system you've built that required both mathematical sophistication and engineering excellence"", ""We're especially interested in examples involving optimization, large-scale training, or systems that improved over time""]","['Design and implement advanced ML models for supply chain optimization', 'Apply linear programming and optimization techniques to real-world problems', 'Build and deploy deep learning models at production scale', 'Own the MLOps pipeline for training and serving large models', 'Write production-quality code that handles billions of data points', 'Collaborate with engineering to integrate models into our platform', 'Research and implement state-of-the-art techniques in forecasting and optimization', 'Design experiments and analyze results to drive product decisions', 'Build self-improving systems that learn from user interactions', 'Include metrics on model performance and system scale if possible']",True,['Deep Learning'],"Deep Learning: Build and deploy deep learning models at production scale using frameworks like PyTorch, applying neural network techniques.","['Machine Learning Models', 'Linear Programming', 'Optimization Techniques', 'Forecasting', 'MLOps', 'Distributed Computing', 'Experimental Design and Analysis', 'Self-Improving Systems', 'Deep Learning Frameworks', 'Python Programming']","Machine Learning Models: Design and implement advanced machine learning models for supply chain optimization and real-world problem solving.; Linear Programming: Apply linear programming techniques to optimize supply chain and other operational problems.; Optimization Techniques: Use optimization methods including combinatorial optimization to improve supply chain processes and model performance.; Forecasting: Research and implement state-of-the-art forecasting techniques to support product decisions.; MLOps: Own the MLOps pipeline for training and serving large-scale machine learning models, ensuring production readiness and scalability.; Distributed Computing: Leverage distributed computing and big data technologies to handle billions of data points and support large-scale model training.; Experimental Design and Analysis: Design experiments and analyze results to drive product decisions and improve system performance.; Self-Improving Systems: Build systems that learn and improve over time from user interactions.; Deep Learning Frameworks: Use deep learning frameworks such as PyTorch to build and deploy deep learning models at production scale.; Python Programming: Write production-quality Python code following software engineering best practices."
FylOg5E7_94Psyu_AAAAAA==,John Snow Labs US-Based Healthcare Data Scientist,"Company Description

John Snow Labs is an award-winning AI and NLP company, accelerating progress in data science by providing state-of-the-art software, data, and models. Founded in 2015, it helps healthcare and life science companies build, deploy, and operate AI products and services. John Snow Labs is the winner of the 2018 AI Solution Provider of the Year Award, the 2019 AI Platform of the Year Award, the 2019 International Data Science Foundation Technology award, and the 2020 AI Excellence Award.

John Snow Labs is the developer of Spark NLP - the world’s most widely used NLP library in the enterprise - and is the world’s leading provider of state-of-the-art clinical NLP software, powering some of the world’s largest healthcare & pharma companies. John Snow Labs is a global team of specialists, of which 33% hold a Ph.D. or M.D. and 75% hold at least a Master’s degree in disciplines covering data science, medicine, software engineering, pharmacy, DevOps and SecOps.

Job Description

John Snow Labs is seeking a highly skilled and motivated Data Scientist to contribute to transformative initiatives within the healthcare industry. The ideal candidate will possess a strong background in developing and optimizing machine learning models, specifically within healthcare contexts. We are looking for a results-oriented individual proficient in training and fine-tuning models, building robust, production-ready model inference pipelines, and conducting comprehensive exploratory data analysis and data enrichment.

Qualifications

Key Responsibilities:
• Train, fine tune, and enhance LLM & NLP models using the open-source Python library ecosystem. Experience with LLMs, Generative AI, and deep learning is a significant advantage.
• Build data science and data engineering pipelines specific to analyzing clinical data, such as extracting information from medical text or images, or integrating uncertain information from multiple medical data sources.
• Collaborate with our team on customer-facing projects, utilizing your expertise to create advanced machine learning, deep learning, large language models, and time series forecasting pipelines tailored to address specific business needs.
• Ensure models are validated for issues like bias, overfitting, and concept drift to ensure reliability and effectiveness.
• Engage directly with customers, requiring strong oral and written communication skills to convey complex technical concepts clearly.

Mandatory Skills:
• Proven experience in consistently delivering real-world projects covering the key responsibilities. Knowledge that is limited to an academic setting, or to using existing APIs to building applications, is not sufficient for this role.
• Hands-on experience with OMOP, FHIR, clinical terminologies, and understanding of the patient journey.
• Strong background in healthcare-related fields such as medicine, pharma, bioinformatics, or biostatistics is highly beneficial.
• A PhD in a relevant field is preferred but not required if exceptional experience is demonstrated.
• Experience with John Snow Labs’ technology stack, such as Spark NLP or the medical language models, is a plus.

What We Offer:
• A chance to work on cutting-edge problems in healthcare and life sciences, contributing to meaningful projects that impact patient outcomes.
• Long-term freelancing contracts with a commitment of at least 30 hours per week. We are seeking individuals, not agencies or teams.
• The opportunity to grow your skills and knowledge, working with a team of big data and data science experts in a supportive, collaborative environment.

To apply, please include the words 'John Snow Labs' in your cover letter and detail why you believe you are the best fit for this role. This is more than just a contract — it's a chance to make a real difference.

Additional Information

Our Commitment to You

At John Snow Labs, we believe that diversity is the catalyst of innovation. We’re committed to empowering talented people from every background and perspective to thrive.

We are an award-winning global collaborative team focused on helping our customers put artificial intelligence to good use faster. Our website includes The Story of John Snow, and our Social Impact page details how purpose and giving back is part of our DNA. More at JohnSnowLabs.com
• We are a fully virtual company, collaborating across 28 countries.
• This is a contract opportunity, not a full-time employment role.
• This role requires the availability of at least 30-40 hours per week.",,2025-07-25,"['We are looking for a results-oriented individual proficient in training and fine-tuning models, building robust, production-ready model inference pipelines, and conducting comprehensive exploratory data analysis and data enrichment', 'Experience with LLMs, Generative AI, and deep learning is a significant advantage', 'Build data science and data engineering pipelines specific to analyzing clinical data, such as extracting information from medical text or images, or integrating uncertain information from multiple medical data sources', 'Ensure models are validated for issues like bias, overfitting, and concept drift to ensure reliability and effectiveness', 'Engage directly with customers, requiring strong oral and written communication skills to convey complex technical concepts clearly', 'Proven experience in consistently delivering real-world projects covering the key responsibilities', 'Knowledge that is limited to an academic setting, or to using existing APIs to building applications, is not sufficient for this role', 'Hands-on experience with OMOP, FHIR, clinical terminologies, and understanding of the patient journey', 'Strong background in healthcare-related fields such as medicine, pharma, bioinformatics, or biostatistics is highly beneficial']","['Train, fine tune, and enhance LLM & NLP models using the open-source Python library ecosystem', 'Collaborate with our team on customer-facing projects, utilizing your expertise to create advanced machine learning, deep learning, large language models, and time series forecasting pipelines tailored to address specific business needs', 'This role requires the availability of at least 30-40 hours per week']",True,"['Large Language Models', 'Generative AI', 'Deep Learning']","Large Language Models: Train, fine-tune, and enhance large language models (LLMs) using open-source Python libraries to build advanced NLP solutions in healthcare.; Generative AI: Apply generative AI techniques and deep learning methods to improve model performance and develop innovative AI products in the healthcare domain.; Deep Learning: Utilize deep learning approaches, including neural networks, to build and optimize models for clinical data analysis and NLP tasks.","['Exploratory Data Analysis', 'Data Science Pipelines', 'Machine Learning Models', 'Time Series Forecasting', 'Clinical Data Standards', 'Spark NLP']","Exploratory Data Analysis: Conduct comprehensive exploratory data analysis and data enrichment to understand and prepare clinical data for modeling.; Data Science Pipelines: Build data science and data engineering pipelines specific to analyzing clinical data, including extracting information from medical text or images and integrating uncertain information from multiple medical data sources.; Machine Learning Models: Develop and optimize machine learning models tailored to healthcare contexts, ensuring models are validated for bias, overfitting, and concept drift to maintain reliability and effectiveness.; Time Series Forecasting: Create time series forecasting pipelines as part of advanced machine learning solutions to address specific business needs in healthcare.; Clinical Data Standards: Utilize hands-on experience with healthcare data standards such as OMOP, FHIR, and clinical terminologies to understand and analyze patient journey data.; Spark NLP: Leverage John Snow Labs’ Spark NLP library and medical language models to develop clinical NLP software solutions."
D6Y9vrIo1mX-IXCqAAAAAA==,Senior Data Scientist,"DTE is one of the nation’s largest diversified energy companies. Our electric and gas companies have fueled our customer’s homes and Michigan’s progress for more than a century. And as Michigan’s largest source of renewable energy, we’re creating a cleaner, healthier environment to power our future. We’re also serving communities beyond Michigan, where our affiliated businesses offer renewable energy, emission control technologies, and energy services to industries in 19 states.

But we’re more than a leading energy company... and working at DTE is more than just a job. At DTE, we take great care of each other and our customers, and we use our energy to be a force for growth and prosperity in our communities. When you join us, you’ll be part of a team that welcomes, recognizes, and celebrates differences and values everyone’s health, safety, and wellbeing. Are you ready to make that kind of difference? Bring your energy to DTE. Together, we can achieve great things.

Testing Required: Not Applicable

Hybrid Role: Must be able to come on-site periodically and reside a commutable distance from the assigned work location.

Emergency Response: Yes – Must be available to perform a primary assignment in support of DTE’s emergency response to storms or other events that impact service to our customers.

Job Summary

Leads large business unit or enterprise-level analytics projects with broad responsibilities for translating business requirements into analytical constructs and providing analytical insights for effective decision making. Mentors less experienced team members to run analytical experiments in a methodical manner, evaluates alternative approaches and develops predictive models to forecast business performance metrics. Communicates effectively to technical and non-technical stakeholders with strong domain expertise and business acumen. Additionally, this role requires researching and recommending new technologies and best practices within the industry to develop the organization’s analytics strategies and roadmap.

Key Accountabilities
• Leads analytics projects and collaborates with cross-functional stakeholders to complete end-to-end analyses that includes business requirements, data gathering, analysis, scaleable solutions, and presentations
• Conducts advanced statistical analysis to determine trends and significant data relationships, and proactively recommend areas of improvement.
• Develops complex data sets and predictive models to support key decisions to improve safety, employee engagement, operation efficiency, product quality, and customer satisfaction
• Prepares and delivers insightful presentations and actionable recommendations. Educates leaders and other employees on complex analytical findings in basic terms with storytelling and data visualization
• Identifies and evaluates technologies and provides strategic inputs to advance the organization’s analytics capabilities
• Implements new statistical, mathematical, machine learning, or other methodologies for modeling or analyses
• Responsible for discovering insights from Big Data to help shape or meet specific business needs and goals.
• Utilizes business expertise to translate goals into data-based deliverables, such as predictive models, pattern detection analysis or optimization algorithms
• Champions self-service reporting capability and use of Business Intelligence and statistical tools; advances the analytical capabilities of the organization
• Develops data and analytical processes based on Continuous Improvement learnings and practices

Minimum Education & Experience Requirements

This is a dual-track base requirement job; education and experience requirements can be satisfied through one of the following three options:
• Bachelor’s degree with emphasis on coursework of a quantitative nature (e.g., Statistics, Computer Science, Engineering, Mathematics, Physics, Data Science, Industrial/Organizational Psychology and Econometrics, etc.) and 6 years of experience working in a data analytical or computer programming function; or
• Master’s degree with emphasis on coursework of a quantitative nature (e.g., Statistics, Computer Science, Engineering, Mathematics, Physics, Data Science, Industrial/Organizational Psychology and Econometrics, etc.) and 4 years of experience working in a data analytical or computer programming function
• PhD degree with emphasis on coursework of a quantitative nature (e.g., Statistics, Computer Science, Engineering, Mathematics, Physics, Data Science, Industrial/Organizational Psychology and Econometrics, etc.) and 2 years of experience working in a data analytical or computer programming function

Other Qualifications

Preferred:
• PhD degree in Data Science
• Experience in quantitative analytics (e.g., data mining, regression analysis, hypothesis testing, predictive modeling and model optimization)
• Intermediate- to advanced-level knowledge and skills in data modeling, data structure, and the application of complex SQL queries with data from multiple sources, including Big Data platforms (e.g., Hadoop, AWS, Azure, Databricks)
• Experience with SAP Business Intelligence tools and SAP CRM, ISU, and BW data
• Intermediate-level or higher Continuous Improvement knowledge, skills, and certifications
• Strong written and verbal communication skills
• Strong business acumen and utility/energy industry experience

Other Requirements:
• Intermediate- to advanced-level skills and experience with data mining and statistical analysis using analytical packages / tools (e.g., R, SAS, SPSS, Stata, MATLAB, Minitab, etc.)
• Intermediate- to advanced-level skills and experience articulating business questions, pulling data from relational databases (e.g., SAP BW, ORACLE, SQL SERVER) and using advanced excel and statistical tools (e.g., Minitab, Alteryx, Advanced Excel with VBA, R, SAS, SPSS, Stata, MATLAB, etc.) and determining the appropriate analytical approach to conduct in-depth analysis to support decision making
• Intermediate- to advanced-level programming skills in SQL, C/C++/C#, Java, R, Python, PHP, ASP, or SAS
• Intermediate- to advanced-level skills in applied research design and machine learning (e.g., multivariate statistical analysis, unsupervised and supervised learning, predictive modeling, etc.)
• Self-starter and quick learner; advances self and others' knowledge and skill sets in business processes, data science, new analytical frameworks, technologies, and applications
• Strong interpersonal, analytical and problem-solving skills, including ability to communicate technical information and complex data analytics to a non-technical audience

Additional Information

Incumbents may engage in all or some combination of the activities and accountabilities, and utilize a variety of the competencies cited in this description depending upon the organization and role to which they are assigned. This description is intended to describe the general nature and level of work performed by incumbents in this job. It is not intended as an all-inclusive list of accountabilities or responsibilities, nor is it intended to limit the rights of supervisors or management representatives to assign, direct and control the work of employees under their supervision.

PRIVACY NOTICE TO CALIFORNIA JOB APPLICANTS

At DTE Energy, we are committed to providing an inclusive workplace where everyone feels welcome and a sense of belonging. We seek individuals with a heart for service, a passion to help our communities prosper, and ideas to help shape the future of energy. We are proud to be an equal opportunity, employer that considers all qualified applicants without regard to race, color, sex, sexual orientation, gender identity, age, religion, disability, national origin, citizenship, height, weight, genetic information, marital status, pregnancy, protected veteran status or any other status protected by applicable federal and/or state laws.#LI-DNP",2025-07-22T00:00:00.000Z,2025-07-25,"['Testing Required: Not Applicable', 'This is a dual-track base requirement job; education and experience requirements can be satisfied through one of the following three options:', 'Bachelor’s degree with emphasis on coursework of a quantitative nature (e.g., Statistics, Computer Science, Engineering, Mathematics, Physics, Data Science, Industrial/Organizational Psychology and Econometrics, etc.) and 6 years of experience working in a data analytical or computer programming function; or', 'Master’s degree with emphasis on coursework of a quantitative nature (e.g., Statistics, Computer Science, Engineering, Mathematics, Physics, Data Science, Industrial/Organizational Psychology and Econometrics, etc.) and 4 years of experience working in a data analytical or computer programming function', 'PhD degree with emphasis on coursework of a quantitative nature (e.g., Statistics, Computer Science, Engineering, Mathematics, Physics, Data Science, Industrial/Organizational Psychology and Econometrics, etc.) and 2 years of experience working in a data analytical or computer programming function', 'Intermediate- to advanced-level skills and experience with data mining and statistical analysis using analytical packages / tools (e.g., R, SAS, SPSS, Stata, MATLAB, Minitab, etc.)', 'Intermediate- to advanced-level skills and experience articulating business questions, pulling data from relational databases (e.g., SAP BW, ORACLE, SQL SERVER) and using advanced excel and statistical tools (e.g., Minitab, Alteryx, Advanced Excel with VBA, R, SAS, SPSS, Stata, MATLAB, etc.) and determining the appropriate analytical approach to conduct in-depth analysis to support decision making', 'Intermediate- to advanced-level programming skills in SQL, C/C++/C#, Java, R, Python, PHP, ASP, or SAS', 'Intermediate- to advanced-level skills in applied research design and machine learning (e.g., multivariate statistical analysis, unsupervised and supervised learning, predictive modeling, etc.)', ""Self-starter and quick learner; advances self and others' knowledge and skill sets in business processes, data science, new analytical frameworks, technologies, and applications"", 'Strong interpersonal, analytical and problem-solving skills, including ability to communicate technical information and complex data analytics to a non-technical audience']","['Hybrid Role: Must be able to come on-site periodically and reside a commutable distance from the assigned work location', 'Emergency Response: Yes – Must be available to perform a primary assignment in support of DTE’s emergency response to storms or other events that impact service to our customers', 'Leads large business unit or enterprise-level analytics projects with broad responsibilities for translating business requirements into analytical constructs and providing analytical insights for effective decision making', 'Mentors less experienced team members to run analytical experiments in a methodical manner, evaluates alternative approaches and develops predictive models to forecast business performance metrics', 'Communicates effectively to technical and non-technical stakeholders with strong domain expertise and business acumen', 'Additionally, this role requires researching and recommending new technologies and best practices within the industry to develop the organization’s analytics strategies and roadmap', 'Leads analytics projects and collaborates with cross-functional stakeholders to complete end-to-end analyses that includes business requirements, data gathering, analysis, scaleable solutions, and presentations', 'Conducts advanced statistical analysis to determine trends and significant data relationships, and proactively recommend areas of improvement', 'Develops complex data sets and predictive models to support key decisions to improve safety, employee engagement, operation efficiency, product quality, and customer satisfaction', 'Prepares and delivers insightful presentations and actionable recommendations', 'Educates leaders and other employees on complex analytical findings in basic terms with storytelling and data visualization', 'Identifies and evaluates technologies and provides strategic inputs to advance the organization’s analytics capabilities', 'Implements new statistical, mathematical, machine learning, or other methodologies for modeling or analyses', 'Responsible for discovering insights from Big Data to help shape or meet specific business needs and goals', 'Utilizes business expertise to translate goals into data-based deliverables, such as predictive models, pattern detection analysis or optimization algorithms', 'Champions self-service reporting capability and use of Business Intelligence and statistical tools; advances the analytical capabilities of the organization', 'Develops data and analytical processes based on Continuous Improvement learnings and practices', 'Incumbents may engage in all or some combination of the activities and accountabilities, and utilize a variety of the competencies cited in this description depending upon the organization and role to which they are assigned']",True,[],,"['Predictive Modeling', 'Statistical Analysis', 'Data Mining', 'Machine Learning', 'Data Visualization', 'SQL', 'Big Data Platforms', 'Business Intelligence Tools', 'Statistical Software Packages', 'Programming Languages', 'Continuous Improvement', 'Data Modeling']","Predictive Modeling: Develops predictive models to forecast business performance metrics and support key decisions to improve safety, employee engagement, operation efficiency, product quality, and customer satisfaction.; Statistical Analysis: Conducts advanced statistical analysis to determine trends and significant data relationships and proactively recommend areas of improvement.; Data Mining: Utilizes data mining techniques to discover insights from Big Data to help shape or meet specific business needs and goals.; Machine Learning: Implements machine learning methodologies including supervised and unsupervised learning and multivariate statistical analysis for modeling or analyses.; Data Visualization: Prepares and delivers insightful presentations and actionable recommendations, educating leaders and employees on complex analytical findings using storytelling and data visualization.; SQL: Uses advanced SQL queries to pull data from relational databases such as SAP BW, ORACLE, and SQL SERVER, working with data from multiple sources including Big Data platforms.; Big Data Platforms: Works with Big Data platforms including Hadoop, AWS, Azure, and Databricks to handle complex data sets.; Business Intelligence Tools: Champions self-service reporting capability and use of Business Intelligence tools such as SAP Business Intelligence to advance the organization's analytical capabilities.; Statistical Software Packages: Utilizes analytical packages and tools including R, SAS, SPSS, Stata, MATLAB, and Minitab for data mining and statistical analysis.; Programming Languages: Employs programming skills in SQL, C/C++/C#, Java, R, Python, PHP, ASP, or SAS to support data analytical or computer programming functions.; Continuous Improvement: Develops data and analytical processes based on Continuous Improvement learnings and practices to enhance analytics capabilities.; Data Modeling: Applies data modeling and data structure knowledge to develop complex data sets and analytical solutions."
LJAy9IiIZGK-jIXJAAAAAA==,Principal Data Scientist,"Asurion is seeking a Principal Data Scientist to join our Data Science team. An individual in this role will be designing, developing, implementing, and fine-tuning Large Language Models to build one-of-a-kind autonomous sales agents in the context of tech support. The candidate will work on the cutting-edge of LLMs as we aim to leverage them for sales where the tasks are better defined and narrow, but margin of error is very low. Leveraging AI to be offer a highly targeted and personalized sales experience while setting state-of-the-art standards for compliance and hallucinations. They should be well versed on modern massive neural language model architectures, including BERT-like and GPT/autoregressive-like LLM's, neural language generation, AI agents, few-shot multitask learning etc. The candidate should also know the limitations of LLMs and how to design solutions and services keeping those in mind. Gather and analyze large volumes of unstructured, text data, evaluates scenarios to make predictions on future outcomes and supports decision making. An ideal candidate would have excellent communication (written and oral) and presentation skills, including creating and sharing complex ideas to peers, cross-functional partners and stakeholders. The candidate will also offer technical mentorship and guidance to junior data scientists.

Role and Responsibilities:
• Utilize Natural Language Processing to analyze speech and text data, build chatbot and expert systems
• Implement existing Large Language Models such as GPT, LLaMA, etc
• Refine Large Language Models via prompt engineering, Agentic frameworks, fine-tuning, reinforcement learning, or transfer learning
• Lead and mentor a team of scientists, driving high-impact technical initiatives with broad scope and visibility
• Discover and formulate business problems and create data science solutions
• Develop prototypes for new data product ideas
• Design and deploy complex, optimized and large-scale machine learning algorithms and generative models to improve Asurion’s wireless, connected home, and appliance customers’ experiences
• Analyze and interpret the results of product experiments
• Work closely with product managers to identify and answer important product questions that help improve outcomes
• Communicate findings to product managers and development groups
• Drive the collection of new data and the refinement of existing data
• Regularly invents new and novel approaches to problems; takes initiative and breaks down barriers to solve problems; recognized within team as the source of solutions

Qualifications:
• Master's or PhD preferably in Machine Learning role with at least 4+ years hands-on ML experience
• 2+ years of experience leading a team of scientists or engineers, with a strong track record of recruiting and/or mentoring junior team members
• Specialized practical experience in Generative AI
• Expert in Natural Language Processing tasks
• Applied experience in deploying NLP based solutions, including Gen AI, at scale in a cloud environment like AWS, GCP or Azure.
• Prior experience in applying machine learning for customer experience use cases
• Comfortable manipulating and analyzing complex, high-volume, high dimensionality data from multiple sources
• Comfortable in using advanced statistical data modeling techniques and tools
• Experience using Python and working with large scale systems
• Knowledge of data processing on Hadoop programming environments (e.g. Spark/Hive)
• Familiar with optimization techniques and underlying machine learning algorithms concepts
• Solid statistical knowledge; familiarity with hypothesis testing, experimental design and time series
• Familiarity with Linux/Unix/Shell environments
• Self-driven and able to ask and tackle the most important analytical questions with a view on driving product impact
• A strong passion for empirical research and for answering hard questions with data
• Result-driven and focused self-starters, great communicators that follow through on every initiative
• Love the responsibility of being individually empowered
• Ability to communicate complex quantitative analysis in a clear, precise, and actionable manner",,2025-07-25,"[""They should be well versed on modern massive neural language model architectures, including BERT-like and GPT/autoregressive-like LLM's, neural language generation, AI agents, few-shot multitask learning etc"", 'The candidate should also know the limitations of LLMs and how to design solutions and services keeping those in mind', ""Master's or PhD preferably in Machine Learning role with at least 4+ years hands-on ML experience"", '2+ years of experience leading a team of scientists or engineers, with a strong track record of recruiting and/or mentoring junior team members', 'Specialized practical experience in Generative AI', 'Expert in Natural Language Processing tasks', 'Applied experience in deploying NLP based solutions, including Gen AI, at scale in a cloud environment like AWS, GCP or Azure', 'Prior experience in applying machine learning for customer experience use cases', 'Comfortable manipulating and analyzing complex, high-volume, high dimensionality data from multiple sources', 'Comfortable in using advanced statistical data modeling techniques and tools', 'Experience using Python and working with large scale systems', 'Knowledge of data processing on Hadoop programming environments (e.g', 'Familiar with optimization techniques and underlying machine learning algorithms concepts', 'Solid statistical knowledge; familiarity with hypothesis testing, experimental design and time series', 'Familiarity with Linux/Unix/Shell environments', 'Self-driven and able to ask and tackle the most important analytical questions with a view on driving product impact', 'A strong passion for empirical research and for answering hard questions with data', 'Result-driven and focused self-starters, great communicators that follow through on every initiative', 'Love the responsibility of being individually empowered', 'Ability to communicate complex quantitative analysis in a clear, precise, and actionable manner']","['An individual in this role will be designing, developing, implementing, and fine-tuning Large Language Models to build one-of-a-kind autonomous sales agents in the context of tech support', 'The candidate will work on the cutting-edge of LLMs as we aim to leverage them for sales where the tasks are better defined and narrow, but margin of error is very low', 'Leveraging AI to be offer a highly targeted and personalized sales experience while setting state-of-the-art standards for compliance and hallucinations', 'Gather and analyze large volumes of unstructured, text data, evaluates scenarios to make predictions on future outcomes and supports decision making', 'An ideal candidate would have excellent communication (written and oral) and presentation skills, including creating and sharing complex ideas to peers, cross-functional partners and stakeholders', 'The candidate will also offer technical mentorship and guidance to junior data scientists', 'Utilize Natural Language Processing to analyze speech and text data, build chatbot and expert systems', 'Implement existing Large Language Models such as GPT, LLaMA, etc', 'Refine Large Language Models via prompt engineering, Agentic frameworks, fine-tuning, reinforcement learning, or transfer learning', 'Lead and mentor a team of scientists, driving high-impact technical initiatives with broad scope and visibility', 'Discover and formulate business problems and create data science solutions', 'Develop prototypes for new data product ideas', 'Design and deploy complex, optimized and large-scale machine learning algorithms and generative models to improve Asurion’s wireless, connected home, and appliance customers’ experiences', 'Analyze and interpret the results of product experiments', 'Work closely with product managers to identify and answer important product questions that help improve outcomes', 'Communicate findings to product managers and development groups', 'Drive the collection of new data and the refinement of existing data', 'Regularly invents new and novel approaches to problems; takes initiative and breaks down barriers to solve problems; recognized within team as the source of solutions']",True,"['Large Language Models', 'Generative AI', 'Prompt Engineering', 'Agentic Frameworks', 'Reinforcement Learning', 'Transfer Learning', 'Neural Language Generation', 'AI Agents']","Large Language Models: Designing, developing, implementing, and fine-tuning LLMs such as GPT and LLaMA to build autonomous sales agents and deliver personalized sales experiences with low margin of error.; Generative AI: Specialized practical experience in generative AI to create novel AI-driven solutions, including neural language generation and generative models for customer experience enhancement.; Prompt Engineering: Refining large language models through prompt engineering to improve model responses and task performance.; Agentic Frameworks: Utilizing agentic frameworks to develop autonomous AI agents capable of performing complex tasks in sales and tech support contexts.; Reinforcement Learning: Applying reinforcement learning techniques to fine-tune large language models and improve their decision-making capabilities.; Transfer Learning: Using transfer learning to adapt pre-trained large language models to specific business problems and domains.; Neural Language Generation: Employing neural language generation techniques as part of large language model architectures to produce human-like text for AI agents.; AI Agents: Building autonomous AI agents leveraging large language models to perform targeted and personalized sales tasks with high accuracy.","['Natural Language Processing', 'Machine Learning', 'Statistical Modeling', 'Data Analysis', 'Python', 'Hadoop Ecosystem (Spark/Hive)', 'Optimization Techniques', 'Experimental Design and A/B Testing']","Natural Language Processing: Used to analyze speech and text data, build chatbot and expert systems, and support the development of autonomous sales agents in tech support.; Machine Learning: Designing, deploying, and fine-tuning complex, optimized, and large-scale algorithms to improve customer experiences and support predictive modeling and decision making.; Statistical Modeling: Applying advanced statistical data modeling techniques, including hypothesis testing, experimental design, and time series analysis, to analyze complex, high-volume, and high-dimensional data.; Data Analysis: Gathering and analyzing large volumes of unstructured text data to evaluate scenarios, make predictions on future outcomes, and support decision making.; Python: Used for working with large-scale systems and implementing machine learning and data science solutions.; Hadoop Ecosystem (Spark/Hive): Knowledge of data processing in Hadoop programming environments to handle large-scale data.; Optimization Techniques: Familiarity with optimization methods underlying machine learning algorithms to improve model performance and solution efficiency.; Experimental Design and A/B Testing: Analyzing and interpreting results of product experiments to inform product decisions and improvements."
JbEvU8LZ6KUYqj1uAAAAAA==,Snr Data Scientist (Manufacturing and Pricing ),"Role: Senior Data Scientist

Location: PA ? Candidate can work Remote in United States, with some needed travel

Note: The role needs strong Manufacturing / Product based industry experience. This will be a individual contributor position and will work with the top management directly in a ground up setup.

About the Role

We are seeking a highly skilled Senior Data Scientist with expertise in Pricing, FSN and point of Sales analysis for manufacturing parts for a Manufacturing Client. As an algorithm expert, you will be responsible for building and supporting predictive models that drive our pricing and FSN strategies. You will work independently and will be managing your scope of work to analyze, compile data and forecast results with predictive outcomes reporting directly to the CIO

This role requires a deep understanding of pricing experimentation, POS and manufacturing parts Supply chain process advanced modeling, and retail data analytics to uncover insights that directly impact the company?s bottom line. You will play a key role in designing, evaluating, and refining pricing strategies through data-driven approaches.

Key Responsibilities
• Develop and enhance predictive models for manufacturing parts pricing, FSN and POS.
• Analyze and interpret large, complex pricing-related datasets, applying feature engineering techniques.
• Identify opportunities to incorporate new data sources and insights for improved pricing accuracy.
• Leverage statistical and machine learning techniques to validate and refine pricing models.
• Using data analysis to identify areas for improvement in manufacturing processes, like optimizing parameters for better product quality and yield.
• Act as a strategic partner in defining pricing roadmaps and priorities in collaboration with cross-functional teams.
• Design and implement pricing evaluation frameworks to determine optimal pricing strategies.
• Monitoring quality metrics and implementing data-driven strategies to minimize defects and ensure product consistency.
• Translate complex analytical findings into actionable insights, presenting them to senior leaders and stakeholders.
• Lead end-to-end analytical projects, ensuring seamless execution from data processing to model deployment.
• Stay up to date with industry trends in pricing analytics, machine learning, and manufacturing sector developments.

Required Qualifications
• Bachelor?s or Master?s degree in a quantitative field (e.g., Data Science, Statistics, Mathematics, Economics, Computer Science) OR equivalent industry experience.
• 5+ years of experience in Manufacturing parts pricing analysis, FSN and POS data science, and statistical modeling, preferably in a manufacturing or supply chain environment. The role is seeking for a 10+ years of experience (Phd experience included)
• Proficiency in SQL, Python, R, or other data analysis and statistical programming languages.
• Strong understanding of pricing strategies, price elasticity modeling, and demand forecasting.
• Expertise in machine learning techniques (supervised/unsupervised learning, classification, regression, etc.).
• Experience with A/B testing, controlled experiments, and statistical analysis to assess pricing models' business value.
• Strong data engineering skills, including data cleaning, transformation, and feature engineering.
• Ability to communicate complex data insights to non-technical stakeholders and executives.
• Experience managing end-to-end machine learning pipelines and deploying models in production environments.
• Preferred Qualifications
• Prior experience in manufacturing, supply chain, or retail pricing analytics.
• Familiarity with big data technologies (e.g., Spark, Hadoop, Databricks).
• Experience with cloud platforms such as AWS, GCP, or Azure.
• Strong business acumen and the ability to translate data-driven insights into revenue-generating strategies.",,2025-07-25,"['Candidate can work Remote in United States, with some needed travel', 'Note: The role needs strong Manufacturing / Product based industry experience', 'Bachelor?s or Master?', 's degree in a quantitative field (e.g., Data Science, Statistics, Mathematics, Economics, Computer Science) OR equivalent industry experience', '5+ years of experience in Manufacturing parts pricing analysis, FSN and POS data science, and statistical modeling, preferably in a manufacturing or supply chain environment', 'The role is seeking for a 10+ years of experience (Phd experience included)', 'Proficiency in SQL, Python, R, or other data analysis and statistical programming languages', 'Strong understanding of pricing strategies, price elasticity modeling, and demand forecasting', 'Expertise in machine learning techniques (supervised/unsupervised learning, classification, regression, etc.)', ""Experience with A/B testing, controlled experiments, and statistical analysis to assess pricing models' business value"", 'Strong data engineering skills, including data cleaning, transformation, and feature engineering', 'Ability to communicate complex data insights to non-technical stakeholders and executives', 'Experience managing end-to-end machine learning pipelines and deploying models in production environments', 'Prior experience in manufacturing, supply chain, or retail pricing analytics', 'Familiarity with big data technologies (e.g., Spark, Hadoop, Databricks)', 'Experience with cloud platforms such as AWS, GCP, or Azure', 'Strong business acumen and the ability to translate data-driven insights into revenue-generating strategies']","['This will be a individual contributor position and will work with the top management directly in a ground up setup', 'We are seeking a highly skilled Senior Data Scientist with expertise in Pricing, FSN and point of Sales analysis for manufacturing parts for a Manufacturing Client', 'As an algorithm expert, you will be responsible for building and supporting predictive models that drive our pricing and FSN strategies', 'You will work independently and will be managing your scope of work to analyze, compile data and forecast results with predictive outcomes reporting directly to the CIO', 'This role requires a deep understanding of pricing experimentation, POS and manufacturing parts Supply chain process advanced modeling, and retail data analytics to uncover insights that directly impact the company?s bottom line', 'You will play a key role in designing, evaluating, and refining pricing strategies through data-driven approaches', 'Develop and enhance predictive models for manufacturing parts pricing, FSN and POS', 'Analyze and interpret large, complex pricing-related datasets, applying feature engineering techniques', 'Identify opportunities to incorporate new data sources and insights for improved pricing accuracy', 'Leverage statistical and machine learning techniques to validate and refine pricing models', 'Using data analysis to identify areas for improvement in manufacturing processes, like optimizing parameters for better product quality and yield', 'Act as a strategic partner in defining pricing roadmaps and priorities in collaboration with cross-functional teams', 'Design and implement pricing evaluation frameworks to determine optimal pricing strategies', 'Monitoring quality metrics and implementing data-driven strategies to minimize defects and ensure product consistency', 'Translate complex analytical findings into actionable insights, presenting them to senior leaders and stakeholders', 'Lead end-to-end analytical projects, ensuring seamless execution from data processing to model deployment', 'Stay up to date with industry trends in pricing analytics, machine learning, and manufacturing sector developments']",True,[],,"['Predictive Modeling', 'Pricing Strategies', 'Feature Engineering', 'Supervised and Unsupervised Learning', 'A/B Testing and Controlled Experiments', 'Data Engineering', 'SQL, Python, and R', 'Machine Learning Pipelines', 'Statistical Modeling', 'Manufacturing and Supply Chain Analytics', 'Big Data Technologies', 'Cloud Platforms', 'Data-Driven Decision Making']","Predictive Modeling: Building and supporting predictive models to drive pricing and FSN strategies for manufacturing parts, including forecasting results with predictive outcomes.; Pricing Strategies: Designing, evaluating, and refining pricing strategies through data-driven approaches, including price elasticity modeling and demand forecasting.; Feature Engineering: Applying feature engineering techniques to analyze and interpret large, complex pricing-related datasets for improved pricing accuracy.; Supervised and Unsupervised Learning: Leveraging machine learning techniques such as supervised and unsupervised learning, classification, and regression to validate and refine pricing models.; A/B Testing and Controlled Experiments: Using A/B testing and controlled experiments along with statistical analysis to assess the business value of pricing models.; Data Engineering: Performing data cleaning, transformation, and feature engineering to prepare data for modeling and analysis.; SQL, Python, and R: Utilizing SQL, Python, R, or other statistical programming languages for data analysis, statistical modeling, and machine learning pipeline management.; Machine Learning Pipelines: Managing end-to-end machine learning pipelines and deploying models in production environments.; Statistical Modeling: Applying statistical modeling techniques in manufacturing parts pricing analysis, FSN, and POS data science within supply chain or manufacturing contexts.; Manufacturing and Supply Chain Analytics: Analyzing manufacturing parts pricing, FSN, POS data, and supply chain processes to uncover insights that impact product quality, yield, and company revenue.; Big Data Technologies: Familiarity with big data technologies such as Spark, Hadoop, and Databricks to handle large datasets relevant to pricing and manufacturing analytics.; Cloud Platforms: Experience with cloud platforms including AWS, GCP, or Azure to support data processing, storage, and model deployment.; Data-Driven Decision Making: Translating complex analytical findings into actionable insights and collaborating with cross-functional teams to define pricing roadmaps and priorities."
EOB9dCKQUnNyaM61AAAAAA==,Data Scientist 3 - 23502,"Requisition Number: 23502

Required Travel: 0 - 10%

Employment Type: Full Time/Salaried/Exempt

Anticipated Salary Range: $99,336.00 - $132,500.00

Security Clearance: Secret

Level of Experience: Mid

This opportunity resides with Warfare Systems (WS), a business group within HII’s Mission Technologies division. Warfare Systems comprises cyber and mission IT; electronic warfare; and C5ISR systems.

HII works within our nation’s intelligence and cyber operations communities to defend our interests in cyberspace and anticipate emerging threats. Our capabilities in cybersecurity, network architecture, reverse engineering, software and hardware development uniquely enable us to support sensitive missions for the U.S. military and federal agency partners.

Meet HII’s Mission Technologies Division

Our team of more than 7,000 professionals worldwide delivers all-domain expertise and advanced technologies in service of mission partners across the globe. Mission Technologies is leading the next evolution of national defense – the data evolution - by accelerating a breadth of national security solutions for government and commercial customers. Our capabilities range from C5ISR, AI and Big Data, cyber operations and synthetic training environments to fleet sustainment, environmental remediation and the largest family of unmanned underwater vehicles in every class. Find the role that’s right for you. Apply today. We look forward to meeting you.

To learn more about Mission Technologies, click here for a short video: https://vimeo.com/732533072

Job Description

HII-Mission Technologies is currently seeking a skilled Data Scientist/Engineer to design, develop, and implement a data base architecture, tools, and techniques for management and use of extremely large data sets for use by data analyst for our DoD customer's organization. This position will be performed at the DoD customer site at Wright-Patterson Air Force Base.

#LI-HB1

Essential Job Responsibilities
• Investigate, determine, and implement suitable open-source tools for storage, managing, and use of extremely large data sets.
• Investigate, determine, and implement tools and methodologies for extracting key data points for analysis by data analyst.
• Conducts data exploration, analysis, and feature extraction techniques to incorporate into DoD customer’s organization data pipelines and workflows.
• Be part of a team responsible for creating, maintaining, and augmenting an on-premises compute environment
• Translating requirements into capabilities for technical teams
• Present status reports to key internal stakeholders
• Evaluate new tools, technologies, and processes to improve on-premises environment
• Gain familiarity of customer mission to identify and/or develop data management and workflow solutions.
• Proposes solutions and strategies to unique challenges throughout the DoD customer’s organization.
• Linux system configuration and capacity planning for large scale data analytics on-premises and cloud.
• Additional duties as assigned or required.

Minimum Qualifications
• 5 years relevant experience with Bachelor in related field; 3 years relevant experience with Masters in related field.
• Experience with defining requirements for using and maintaining open-source data analytics, data workflow, and database tools.
• Develop, implement, and maintain data analytic protocols, standards, and documentation.
• Design data models based on requirements/needs for complex analysis of data analyst
• Define requirements for vendors to implement into their proposed solutions to meet DoD customer’s organization needs and use cases.
• Experience working with multiple types of datasets and database technologies
• Experience building data pipelines from end to end
• Experience with multiple industry standard cloud and on-premise database technologies
• Experience with data exploration, analysis, and visualization tools such as Python and Matlab
• Experience and familiarity with Linux operating environment
• Experience with open-source containerization technologies and tools and how to utilize those technologies as appropriately for database technologies and analytics
• Define internal process improvements to automate repetitive tasks to minimize downtime between analysis
• Clearance: Secret clearance to start. Must be able to obtain and maintain a TS/SCI security clearance with enhanced security checks.

Physical Requirements

May require working in an office, industrial, or laboratory environment. Capable of climbing ladders and tolerating confined spaces and extreme temperature variances.

The listed salary range for this role is intended as a good faith estimate based on the role's location, expectations, and responsibilities. When extending an offer, HII's Mission Technologies division takes a variety of factors into consideration which include, but are not limited to, the role's function and a candidate's education or training, work experience, and key skills.

Together we are working to ensure a future where everyone can be free and thrive.

All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, physical or mental disability, age, or veteran status or any other basis protected by federal, state, or local law.

Do You Need Assistance?

If you need a reasonable accommodation for any part of the employment process, please send an e-mail to buildyourcareer@hii-co.com and let us know the nature of your request and your contact information. Reasonable accommodations are considered on a case-by-case basis. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this email address. Additionally, you may also call 1-844-849-8463 for assistance. Press #3 for HII Mission Technologies.",2025-06-30T00:00:00.000Z,2025-07-25,"['5 years relevant experience with Bachelor in related field; 3 years relevant experience with Masters in related field', 'Experience with defining requirements for using and maintaining open-source data analytics, data workflow, and database tools', 'Develop, implement, and maintain data analytic protocols, standards, and documentation', 'Design data models based on requirements/needs for complex analysis of data analyst', 'Define requirements for vendors to implement into their proposed solutions to meet DoD customer’s organization needs and use cases', 'Experience working with multiple types of datasets and database technologies', 'Experience building data pipelines from end to end', 'Experience with multiple industry standard cloud and on-premise database technologies', 'Experience with data exploration, analysis, and visualization tools such as Python and Matlab', 'Experience and familiarity with Linux operating environment', 'Experience with open-source containerization technologies and tools and how to utilize those technologies as appropriately for database technologies and analytics', 'Define internal process improvements to automate repetitive tasks to minimize downtime between analysis', 'Clearance: Secret clearance to start', 'Must be able to obtain and maintain a TS/SCI security clearance with enhanced security checks', 'May require working in an office, industrial, or laboratory environment', 'Capable of climbing ladders and tolerating confined spaces and extreme temperature variances']","['This position will be performed at the DoD customer site at Wright-Patterson Air Force Base', 'Investigate, determine, and implement suitable open-source tools for storage, managing, and use of extremely large data sets', 'Investigate, determine, and implement tools and methodologies for extracting key data points for analysis by data analyst', 'Conducts data exploration, analysis, and feature extraction techniques to incorporate into DoD customer’s organization data pipelines and workflows', 'Be part of a team responsible for creating, maintaining, and augmenting an on-premises compute environment', 'Translating requirements into capabilities for technical teams', 'Present status reports to key internal stakeholders', 'Evaluate new tools, technologies, and processes to improve on-premises environment', 'Gain familiarity of customer mission to identify and/or develop data management and workflow solutions', 'Proposes solutions and strategies to unique challenges throughout the DoD customer’s organization', 'Linux system configuration and capacity planning for large scale data analytics on-premises and cloud', 'Additional duties as assigned or required']",True,[],,"['Data Pipelines', 'Feature Extraction', 'Data Exploration and Analysis', 'Data Models', 'Open-Source Data Analytics Tools', 'Database Technologies', 'Data Workflow Tools', 'Python', 'MATLAB', 'Linux Operating Environment', 'Containerization Technologies', 'Data Analytic Protocols and Standards']","Data Pipelines: Responsible for building and incorporating data pipelines and workflows to manage and process extremely large data sets for analysis by data analysts within the DoD customer’s organization.; Feature Extraction: Conducts feature extraction techniques as part of data exploration and analysis to support complex data analysis needs of the DoD customer’s organization.; Data Exploration and Analysis: Performs data exploration and analysis to extract key data points and support the development of data models and analytic protocols for the DoD customer.; Data Models: Designs data models based on requirements and needs to enable complex analysis by data analysts within the DoD customer’s organization.; Open-Source Data Analytics Tools: Investigates, determines, and implements suitable open-source tools for storage, management, and analysis of extremely large data sets to support the DoD customer’s data needs.; Database Technologies: Works with multiple types of datasets and database technologies, including industry standard cloud and on-premise database systems, to support data storage and retrieval requirements.; Data Workflow Tools: Defines requirements and implements data workflow tools and methodologies to automate and streamline data management and analysis processes for the DoD customer.; Python: Uses Python as a data exploration, analysis, and visualization tool to support data analytic tasks and workflows.; MATLAB: Utilizes MATLAB for data exploration, analysis, and visualization to support complex data analytic requirements.; Linux Operating Environment: Operates within a Linux environment for system configuration, capacity planning, and supporting large scale data analytics both on-premises and in cloud environments.; Containerization Technologies: Employs open-source containerization technologies and tools to optimize database technologies and analytics workflows, enhancing deployment and scalability.; Data Analytic Protocols and Standards: Develops, implements, and maintains data analytic protocols, standards, and documentation to ensure consistency and quality in data analysis processes."
s5Fs7HUVGS5OvSfKAAAAAA==,"Senior Director, Advanced Analytics, Data Science & AI","About This Role

We are seeking a Sr Director of Advanced Analytics, Data Science & AI responsible for generating and delivering data-driven insights to support a brand, therapeutic area, or cross brand/enterprise and contribute to the development and enhancement of innovative capabilities. This role involves influencing business partners, leading the execution and interpretation of AI/ML models, framing problems, and crafting solutions, all while clearly and compellingly communicating data-driven insights.

This role is dynamic, fast-paced, highly collaborative, and covers a broad range of strategic topics that are critical to our business. To excel in this role, you must have a passion for data-driven problem solving, a strong background in data science and AI, and proven experience in leading and developing high-performing teams.

What You’ll Do:
• Provide an enterprise view of insights across Product / Brand and Therapeutic Areas (TA) on key topics like Resource Allocation, Measurement & attribution of market mix, channel optimization, digital analytics, predictive models, decision engine/next best action.
• Lead the development and implementation of data-driven solutions using advanced analytics and machine learning techniques, predictive algorithms, and AI-powered tools to extract actionable insights to drive US Commercial strategies and tactics.
• Manage and mentor a team of data scientists (internal and external) and AI experts to drive innovation and deliver high-quality results
• Influence end-to-end delivery of data science insights, from framing the business question, designing the solution, and delivering recommendations.
• Break down technical concepts into digestible insights and guide diverse stakeholders how to interpret.
• Collaborate Cross-Functionally:
• Collaborate within the insights & analytics team, coordinating efforts with the Insights & Analytics counterparts to develop and execute a comprehensive brand analytics plan.
• Deliver consolidated insights and actionable recommendations to US Commercial teams, ensuring alignment with strategic objectives and insights findings.
• Work closely with cross-functional teams to ensure seamless integration of brand analytics insights into decision-making processes and strategic initiatives.
• Define and track key performance indicators to measure the success and impact of data-driven solutions.
• Continuously evaluate and enhance existing brand /TA data science capabilities, identifying opportunities for optimization and innovation to drive greater business impact and ROI.
• Stay up to date with the latest advancements in data science and AI and apply them to improve processes and outcomes. Represent Biogen as a thought leader in data science and AI at conferences, events, and industry forums.
• Build university partnerships for driving innovation and leading-edge research technique
• Build strong relationships with key stakeholders across the enterprise, effectively communicating the value proposition of data science and fostering a culture of data-driven decision-making.
• Ensure compliance with data privacy and security regulations and maintain a high level of data integrity.
• Develop and manage budgets, resource allocation, and timelines for data science and AI projects.

Who You Are

You have a proven ability to prioritize and manage complex and innovative projects and establish vision and direction within a fast moving, challenging and energetic commercial environment. You are a highly collaborative and perceptive problem-solver with a demonstrated ability to synthesize strategic insights and drive innovation. You have exceptional and proven ability to influence, collaborate, and communicate with internal and external stakeholders at all levels.

Required Skills and Experience
• A minimum of 10 years of experience in advanced analytics in US commercial setting, previous experience in a biotech / pharmaceutical organization, or in leading global management consulting firm
• Minimum of bachelor's degree, preferably in engineering, economics, statistics, computer science, or related quantitative field
• A business leader that can contextualize the data science findings, recommendations and implications for the Business and be influential in decision making for topics like resource allocation, marketing mix optimizations and digital.
• Extensive expertise and experience with both traditional SQL and modern NoSQL data stores including SQL, and large-scale distributed systems such as Hadoop and or working in Snowflake/Databricks
• Strong experience with machine learning technology, such as: big data stack, Python, R, and visualization techniques
• Experience with pharmaceutical data sources such as IQVIA, SHS, Claims, and other syndicated resources; strong understanding of Patient/Claims data (APLD)
• Extensive experience using data science models to solve problems in a business environment setting
• Accountability for Results - focused on key strategic objectives, accountable for high standards of performance, and lead change
• Strategic Thinking & Problem Solving - Make decisions considering the long-term impact to customers, patients, employees, and the business.
• Patient & Customer Centricity - Maintain an ongoing focus on the needs of our customers and/or key stakeholders.
• Impactful Communication - Communicate with logic, clarity, and respect. Influence at all levels to achieve the best results for Biogen
• Respectful Collaboration - Seek and value others’ perspectives and strive for diverse partnerships to enhance work toward common goals.
• Empowered Development - Play an active role in professional development as a business imperative.

Job Level: Management

Additional Information

Base salary offered is determined through an analytical approach utilizing a combination of factors including, but not limited to, relevant skills & experience, job location, and internal equity.

Regular employees are eligible to receive both short term and long-term incentives, including cash bonus and equity incentive opportunities, designed to reward recent achievements and recognize your future potential based on individual, business unit and company performance.

In addition to compensation, Biogen offers a full and highly competitive range of benefits designed to support our employees’ and their families physical, financial, emotional, and social well-being; including, but not limited to:
• Medical, Dental, Vision, & Life insurances
• Fitness & Wellness programs including a fitness reimbursement
• Short- and Long-Term Disability insurance
• A minimum of 15 days of paid vacation and an additional end-of-year shutdown time off (Dec 26-Dec 31)
• Up to 12 company paid holidays + 3 paid days off for Personal Significance
• 80 hours of sick time per calendar year
• Paid Maternity and Parental Leave benefit
• 401(k) program participation with company matched contributions
• Employee stock purchase plan
• Tuition reimbursement of up to $10,000 per calendar year
• Employee Resource Groups participation

Why Biogen?

We are a global team with a commitment to excellence, and a pioneering spirit. As a mid-sized biotechnology company, we provide the stability and resources of a well-established business while fostering an environment where individual contributions make a significant impact. Our team encompasses some of the most talented and passionate achievers who have unparalleled opportunities for learning, growth, and expanding their skills. Above all, we work together to deliver life-changing medicines, with every role playing a vital part in our mission. Caring Deeply. Achieving Excellence. Changing Lives.

At Biogen, we are committed to building on our culture of inclusion and belonging that reflects the communities where we operate and the patients we serve. We know that diverse backgrounds, cultures, and perspectives make us a stronger and more innovative company, and we are focused on building teams where every employee feels empowered and inspired. Read on to learn more about our DE&I efforts.

All qualified applicants will receive consideration for employment without regard to sex, gender identity or expression, sexual orientation, marital status, race, color, national origin, ancestry, ethnicity, religion, age, veteran status, disability, genetic information or any other basis protected by federal, state or local law. Biogen is an E-Verify Employer in the United States.",2025-07-24T00:00:00.000Z,2025-07-25,"['To excel in this role, you must have a passion for data-driven problem solving, a strong background in data science and AI, and proven experience in leading and developing high-performing teams', 'You have a proven ability to prioritize and manage complex and innovative projects and establish vision and direction within a fast moving, challenging and energetic commercial environment', 'You are a highly collaborative and perceptive problem-solver with a demonstrated ability to synthesize strategic insights and drive innovation', 'You have exceptional and proven ability to influence, collaborate, and communicate with internal and external stakeholders at all levels', 'A minimum of 10 years of experience in advanced analytics in US commercial setting, previous experience in a biotech / pharmaceutical organization, or in leading global management consulting firm', ""Minimum of bachelor's degree, preferably in engineering, economics, statistics, computer science, or related quantitative field"", 'A business leader that can contextualize the data science findings, recommendations and implications for the Business and be influential in decision making for topics like resource allocation, marketing mix optimizations and digital', 'Extensive expertise and experience with both traditional SQL and modern NoSQL data stores including SQL, and large-scale distributed systems such as Hadoop and or working in Snowflake/Databricks', 'Strong experience with machine learning technology, such as: big data stack, Python, R, and visualization techniques', 'Experience with pharmaceutical data sources such as IQVIA, SHS, Claims, and other syndicated resources; strong understanding of Patient/Claims data (APLD)', 'Extensive experience using data science models to solve problems in a business environment setting', 'Accountability for Results - focused on key strategic objectives, accountable for high standards of performance, and lead change', 'Strategic Thinking & Problem Solving - Make decisions considering the long-term impact to customers, patients, employees, and the business', 'Patient & Customer Centricity - Maintain an ongoing focus on the needs of our customers and/or key stakeholders', 'Impactful Communication - Communicate with logic, clarity, and respect', 'Influence at all levels to achieve the best results for Biogen']","['We are seeking a Sr Director of Advanced Analytics, Data Science & AI responsible for generating and delivering data-driven insights to support a brand, therapeutic area, or cross brand/enterprise and contribute to the development and enhancement of innovative capabilities', 'This role involves influencing business partners, leading the execution and interpretation of AI/ML models, framing problems, and crafting solutions, all while clearly and compellingly communicating data-driven insights', 'This role is dynamic, fast-paced, highly collaborative, and covers a broad range of strategic topics that are critical to our business', 'Provide an enterprise view of insights across Product / Brand and Therapeutic Areas (TA) on key topics like Resource Allocation, Measurement & attribution of market mix, channel optimization, digital analytics, predictive models, decision engine/next best action', 'Lead the development and implementation of data-driven solutions using advanced analytics and machine learning techniques, predictive algorithms, and AI-powered tools to extract actionable insights to drive US Commercial strategies and tactics', 'Manage and mentor a team of data scientists (internal and external) and AI experts to drive innovation and deliver high-quality results', 'Influence end-to-end delivery of data science insights, from framing the business question, designing the solution, and delivering recommendations', 'Break down technical concepts into digestible insights and guide diverse stakeholders how to interpret', 'Collaborate Cross-Functionally:', 'Collaborate within the insights & analytics team, coordinating efforts with the Insights & Analytics counterparts to develop and execute a comprehensive brand analytics plan', 'Deliver consolidated insights and actionable recommendations to US Commercial teams, ensuring alignment with strategic objectives and insights findings', 'Work closely with cross-functional teams to ensure seamless integration of brand analytics insights into decision-making processes and strategic initiatives', 'Define and track key performance indicators to measure the success and impact of data-driven solutions', 'Continuously evaluate and enhance existing brand /TA data science capabilities, identifying opportunities for optimization and innovation to drive greater business impact and ROI', 'Stay up to date with the latest advancements in data science and AI and apply them to improve processes and outcomes', 'Represent Biogen as a thought leader in data science and AI at conferences, events, and industry forums', 'Build university partnerships for driving innovation and leading-edge research technique', 'Build strong relationships with key stakeholders across the enterprise, effectively communicating the value proposition of data science and fostering a culture of data-driven decision-making', 'Ensure compliance with data privacy and security regulations and maintain a high level of data integrity', 'Develop and manage budgets, resource allocation, and timelines for data science and AI projects', 'Respectful Collaboration - Seek and value others’ perspectives and strive for diverse partnerships to enhance work toward common goals', 'Empowered Development - Play an active role in professional development as a business imperative']",True,['Artificial Intelligence'],Artificial Intelligence: Led the execution and interpretation of AI models and AI-powered tools to enhance data-driven solutions and extract actionable insights for commercial strategies.,"['Advanced Analytics', 'Predictive Models', 'Machine Learning', 'SQL and NoSQL Databases', 'Big Data Stack', 'Python and R', 'Data Visualization Techniques', 'Pharmaceutical Data Sources', 'Data Science Models', 'Key Performance Indicators (KPIs)', 'Data Privacy and Security Compliance']","Advanced Analytics: Used to generate and deliver data-driven insights supporting brand, therapeutic area, or enterprise-wide decisions, including resource allocation, market mix measurement, channel optimization, and digital analytics.; Predictive Models: Developed and implemented to extract actionable insights that drive US Commercial strategies and tactics, including decision engines and next best action recommendations.; Machine Learning: Applied as part of advanced analytics techniques to develop data-driven solutions and predictive algorithms for business problem solving and innovation.; SQL and NoSQL Databases: Extensive expertise with traditional SQL and modern NoSQL data stores, including large-scale distributed systems such as Hadoop, Snowflake, and Databricks, to manage and analyze data.; Big Data Stack: Utilized alongside machine learning technologies and programming languages like Python and R to handle large-scale data processing and analytics.; Python and R: Used for machine learning, data analysis, and visualization techniques to support data science projects and deliver insights.; Data Visualization Techniques: Employed to communicate complex data science findings clearly and compellingly to diverse stakeholders.; Pharmaceutical Data Sources: Experience with IQVIA, SHS, Claims, and other syndicated resources, with a strong understanding of patient and claims data (APLD) to inform analytics and modeling.; Data Science Models: Extensively used to solve business problems in a commercial environment, supporting strategic decision-making and innovation.; Key Performance Indicators (KPIs): Defined and tracked to measure the success and impact of data-driven solutions and analytics initiatives.; Data Privacy and Security Compliance: Ensured throughout data science and AI projects to maintain high data integrity and regulatory adherence."
0X-dVx1GOIhD9Oj1AAAAAA==,Data Scientist - Technology Consulting - AI and Data - GPS - Manager - Multiple Positions - 1623873,"EY focuses on high-ethical standards and integrity among its employees and expects all candidates to demonstrate these qualities.

At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better. Join us and build an exceptional experience for yourself, and a better working world for all. The exceptional EY experience. It's yours to build.

Data Scientist, Technology Consulting, AI & Data, Government & Public Sector (Manager) (Multiple Positions) (1623873), EY Government Services LLC.

Provide a full range of consulting services to help State, Local and Education clients implement new ideas to help achieve their mission outcomes by delivering a unique perspective on how data science and analytics can transform and improve their entire organization. Apply data mining and statistical analysis techniques like hypothesis testing, segmentation, and modelling to analyze large amounts of data. Deliver the latest data science and big data technologies and practices to design, build and maintain scalable and robust solutions that unify, enrich and analyze data from multiple sources. Help clients make data-driven decisions by working with structured and unstructured data sets, building out predictive models and advise clients on data mining leading practices. Unify, enrich, and analyze client data to derive new insights and opportunities. Leverage in-house data platforms as needed and recommend and build new data platforms/solutions as required to exceed client’s requirements. Build and apply data analysis algorithms (data mining, statistics, machine learning, natural language processing, sentiment analysis, text mining, etc.) as appropriate. Communicate findings, recommendations, and opportunities to clients to improve data systems and solutions. Apply data driven approach (KPIs) in tying technology solutions to specific business outcomes. Share leading practices and insights about current industry or subject-matter topics with EY US leaders, proposal teams and clients. Manage and motivate teams with diverse skills and backgrounds.

Consistently deliver quality client services by monitoring progress. Demonstrate in-depth technical capabilities and professional knowledge. Maintain long-term client relationships and networks. Cultivate business development opportunities.

Full time employment, Monday – Friday, 40 hours per week, 8:30 am – 5:30 pm.

MINIMUM REQUIREMENTS:

Must have a Bachelor's degree in Mathematics, Information Systems, Statistics, Operations Research, Analytics, Computer Science, Engineering, Data Science, Machine Learning, or a related field, and 5 years of progressive, post-baccalaureate work experience. Alternatively, will accept a Master's degree in Mathematics, Information Systems, Statistics, Operations Research, Analytics, Computer Science, Engineering, Data Science, Machine Learning, or a related field and 4 years of work experience.

Must have 4 years of advisory and/or consulting experience.

Must have 4 years hands-on experience with one or a combination of the following: data science, big data, and/or data engineering.

Must have 3 years of experience connecting data sources and structures in one or a combination of any of the following: APIs, NoSQL, RDBMS, Hadoop, S3, SQL, Hive, Pig, and/or Blob Storage.

Must have 3 years of experience with advanced statistical modeling.

Must have 2 years of experience in at least one of the following: R, Python, Java, C#, or Scala.

Must have 2 years of experience in each of the following:- machine learning such as k-NN, naive bayes, decision trees, or SVM
- data mining and statistical tools
- pattern recognition and predictive modelling
- recommendation engines, scoring systems, A/B testing
- setting up data and experimental platforms.

Must have 2 years of hands-on experience with various big data technologies in at least one of the following ecosystems: Google, AWS, or Microsoft.

Must have 4 years of experience working with tools/libraries including with one or combination of any of the following: Python, Panda, and/or R.

Must have 2 years of experience of leading, coaching, mentoring and performance assessment of all levels of staff.

Requires domestic travel up to 30% to serve client needs.

Employer will accept any suitable combination of education, training, or experience.

Please apply on-line at ey.com/en_us/careers and click on ""Careers - Job Search”, then “Search Jobs"" (Job Number - 1623873).

What we offer

We offer a comprehensive compensation and beneﬁts package where you’ll be rewarded based on your performance and recognized for the value you bring to the business. The base salary for this job is $186,660.00 per year. In addition, our Total Rewards package includes medical and dental coverage, pension and 401(k) plans, and a wide range of paid time off options. Join us in our team-led and leader-enabled hybrid model. Our expectation is for most people in external, client serving roles to work together in person 40-60% of the time over the course of an engagement, project or year. Under our ﬂexible vacation policy, you’ll decide how much vacation time you need based on your own personal circumstances. You’ll also be granted time off for designated EY Paid Holidays, Winter/Summer breaks, Personal/Family Care, and other leaves of absence when needed to support your physical, ﬁnancial, and emotional well-being.

• Continuous learning: You’ll develop the mindset and skills to navigate whatever comes next.
• Success as defined by you: We’ll provide the tools and flexibility, so you can make a meaningful impact, your way.
• Transformative leadership: We’ll give you the insights, coaching and confidence to be the leader the world needs.
• Diverse and inclusive culture: You’ll be embraced for who you are and empowered to use your voice to help others find theirs.

EY accepts applications for this position on an on-going basis. If you can demonstrate that you meet the criteria above, please contact us as soon as possible.

The exceptional EY experience. It’s yours to build.
EY | Building a better working world

EY exists to build a better working world, helping to create long-term value for clients, people and society and build trust in the capital markets.

Enabled by data and technology, diverse EY teams in over 150 countries provide trust through assurance and help clients grow, transform and operate.

Working across assurance, consulting, law, strategy, tax and transactions, EY teams ask better questions to find new answers for the complex issues facing our world today.

For those living in California, please click here for additional information.

EY provides equal employment opportunities to applicants and employees without regard to race, color, religion, age, sex, sexual orientation, gender identity/expression, pregnancy, genetic information, national origin, protected veteran status, disability status, or any other legally protected basis, including arrest and conviction records, in accordance with applicable law. 

EY is committed to providing reasonable accommodation to qualified individuals with disabilities, including veterans with disabilities. If you have a disability and either need assistance applying online or need to request an accommodation during any part of the application process, please call 1-800-EY-HELP3, type Option 2 (HR-related inquiries) and then type Option 1 (HR Shared Services Center), which will route you to EY’s Talent Shared Services Team or email SSC Customer Support at ssc.customersupport@ey.com.

This particular position at Ernst & Young in the United States requires the qualified candidate to be a ""United States worker"" as defined by the U.S. Department of Labor regulations at 20 CFR 656.3. You can review this definition at https://www.gpo.gov/fdsys/pkg/CFR-2011-title20-vol3/pdf/CFR-2011-title20-vol3-sec656-3.pdf at the bottom of page 750. Please feel free to apply to other positions that do not require you to be a ""U.S. worker"".",2025-07-10T00:00:00.000Z,2025-07-25,"[""Must have a Bachelor's degree in Mathematics, Information Systems, Statistics, Operations Research, Analytics, Computer Science, Engineering, Data Science, Machine Learning, or a related field, and 5 years of progressive, post-baccalaureate work experience"", ""Alternatively, will accept a Master's degree in Mathematics, Information Systems, Statistics, Operations Research, Analytics, Computer Science, Engineering, Data Science, Machine Learning, or a related field and 4 years of work experience"", 'Must have 4 years of advisory and/or consulting experience', 'Must have 4 years hands-on experience with one or a combination of the following: data science, big data, and/or data engineering', 'Must have 3 years of experience connecting data sources and structures in one or a combination of any of the following: APIs, NoSQL, RDBMS, Hadoop, S3, SQL, Hive, Pig, and/or Blob Storage', 'Must have 3 years of experience with advanced statistical modeling', 'Must have 2 years of experience in at least one of the following: R, Python, Java, C#, or Scala', 'Must have 2 years of experience in each of the following:- machine learning such as k-NN, naive bayes, decision trees, or SVM', 'data mining and statistical tools', 'pattern recognition and predictive modelling', 'recommendation engines, scoring systems, A/B testing', 'setting up data and experimental platforms', 'Must have 2 years of hands-on experience with various big data technologies in at least one of the following ecosystems: Google, AWS, or Microsoft', 'Must have 4 years of experience working with tools/libraries including with one or combination of any of the following: Python, Panda, and/or R', 'Must have 2 years of experience of leading, coaching, mentoring and performance assessment of all levels of staff', 'Requires domestic travel up to 30% to serve client needs', 'Employer will accept any suitable combination of education, training, or experience', 'Success as defined by you: We’ll provide the tools and flexibility, so you can make a meaningful impact, your way', 'Transformative leadership: We’ll give you the insights, coaching and confidence to be the leader the world needs']","['Provide a full range of consulting services to help State, Local and Education clients implement new ideas to help achieve their mission outcomes by delivering a unique perspective on how data science and analytics can transform and improve their entire organization', 'Apply data mining and statistical analysis techniques like hypothesis testing, segmentation, and modelling to analyze large amounts of data', 'Deliver the latest data science and big data technologies and practices to design, build and maintain scalable and robust solutions that unify, enrich and analyze data from multiple sources', 'Help clients make data-driven decisions by working with structured and unstructured data sets, building out predictive models and advise clients on data mining leading practices', 'Unify, enrich, and analyze client data to derive new insights and opportunities', 'Leverage in-house data platforms as needed and recommend and build new data platforms/solutions as required to exceed client’s requirements', 'Build and apply data analysis algorithms (data mining, statistics, machine learning, natural language processing, sentiment analysis, text mining, etc.)', 'Communicate findings, recommendations, and opportunities to clients to improve data systems and solutions', 'Apply data driven approach (KPIs) in tying technology solutions to specific business outcomes', 'Share leading practices and insights about current industry or subject-matter topics with EY US leaders, proposal teams and clients', 'Manage and motivate teams with diverse skills and backgrounds', 'Consistently deliver quality client services by monitoring progress', 'Demonstrate in-depth technical capabilities and professional knowledge', 'Maintain long-term client relationships and networks', 'Cultivate business development opportunities', 'Full time employment, Monday – Friday, 40 hours per week, 8:30 am – 5:30 pm']",True,[],,"['Data Mining', 'Statistical Analysis', 'Machine Learning', 'Natural Language Processing', 'Predictive Modeling', 'Recommendation Engines', 'A/B Testing', 'Big Data Technologies', 'Data Engineering', 'Data Platforms', 'Programming Languages and Tools', 'Pattern Recognition', 'Data Pipelines', 'Statistical Tools']","Data Mining: Used to analyze large amounts of data and build data analysis algorithms to extract insights and patterns for client decision-making.; Statistical Analysis: Applied through techniques like hypothesis testing, segmentation, and advanced statistical modeling to analyze data and support client recommendations.; Machine Learning: Includes building predictive models using algorithms such as k-NN, naive bayes, decision trees, and SVM to support data-driven client solutions.; Natural Language Processing: Utilized for analyzing unstructured data including sentiment analysis and text mining to derive insights from client data.; Predictive Modeling: Developed to help clients make data-driven decisions by forecasting outcomes based on structured and unstructured data.; Recommendation Engines: Implemented as part of building scoring systems and predictive models to enhance client solutions.; A/B Testing: Used to evaluate and optimize experimental platforms and data-driven business outcomes for clients.; Big Data Technologies: Hands-on experience with ecosystems such as Google, AWS, or Microsoft to design, build, and maintain scalable data solutions.; Data Engineering: Involves connecting data sources and structures using APIs, NoSQL, RDBMS, Hadoop, S3, SQL, Hive, Pig, and Blob Storage to unify and enrich client data.; Data Platforms: Leveraged and recommended in-house and new data platforms/solutions to meet and exceed client requirements for data unification and analysis.; Programming Languages and Tools: Experience with Python, R, Java, C#, Scala, and libraries such as Pandas to develop data science and analytics solutions.; Pattern Recognition: Applied to identify trends and insights within client data to support predictive modeling and decision-making.; Data Pipelines: Designed and maintained scalable and robust solutions to unify, enrich, and analyze data from multiple sources.; Statistical Tools: Used for data mining, modeling, and analysis to support client consulting and advisory services."
iqNcZ9-ZrCJwa25CAAAAAA==,Data Scientist for Financial Planning & Analysis (FP&A),"Description
The Leidos Corporate Financial Planning & Analysis (FP&A) team is looking for an experienced Data Scientist with an entrepreneur's mindset to support a new team working on projects to improve our Enterprise financial analytics and forecasting. The position will collaborate with the VP of FP&A in building a Data Analytics Team within Finance. You should be strongly experienced in Python coding and visualization building skills and have knowledge of commonly used ML libraries (SciKit-learn). Data Engineering and ML Ops experience is a plus!

We are looking for someone who is intellectually adaptive, likes to collaborate, inquisitive, and capable of conducting original science.

The FP&A Data & Analytics team will collaborate closely with Leidos' AI Accelerator team which includes junior and senior research/data scientists and data engineers with expertise in information retrieval, UI development, information science, machine learning and artificial intelligence, and statistics.

The Data Scientist will be expected to build statistical models, test hypotheses, interpret, summarize, visualize, and succinctly report on data findings. The Scientist will leverage automation and machine learning to manage data, predict scenarios and make recommendations. The data scientist will partner with business and operational leaders to provide an impact by leveraging data and analytical tools, strategic thinking, and hypothesis-based analysis on machine learning (ML)-based projects. The data scientist is responsible for modeling complex business problems through statistical, algorithmic, mining, and visualization techniques. Further, they will support senior leadership by creating business insights, reports, and analyses to aid in the decision-making process.

Responsibilities:
• Translates business needs into analytics/reporting requirements to support executive decisions and workflows with required information
• Performs large-scale experimentation and builds data-driven models to answer business questions
• Proactively mines data warehouses to identify trends and patterns and generates insights for business units and senior leadership
• Performs large-scale experimentation to identify hidden relationships between variables in large datasets
• Researches and implements cutting-edge techniques and tools in machine learning/deep learning/artificial intelligence to make data analysis more efficient
• Designs and conducts data analyses with the highest standard of rigor and scientific accuracy; this includes study design, methodology, algorithms, and statistical modeling
• Analyzes data provided to identify trends, inform decisions
• Supports developmental plans based on data findings related to program, personnel, training needs
• Supports development and maintenance of primary program database and run interval reporting
• Implements appropriate modeling and data science strategies required to address customer needs
• Communicates results and methods for solutions to internal and external stakeholders
• Designs, builds, trains, and evaluates machine learning models

Basic Qualifications:
• Bachelor's degree in Computer Science, Data Science, Data Engineering or related field with 2+ years of relevant experience
• Strong experience with Python as well as fluency in multiple programming languages and statistical analysis tools such as C++, JavaScript, R, SAS, Excel, SQL, MATLAB, SPSS
• Experience /familiarity with frequentist statistics and probability including predicative modeling
• Experience with data repositories and reporting tools
• Good understanding of machine learning algorithms, tools and platforms
• Experience with AI/ML tools, such as common Python packages (e.g., scikit-learn, NumPy, Pandas) and Jupyter notebooks
• Experience with time series modeling, causal inference, or probabilistic forecasting models.
• Experience with tabular data analysis using languages such as SQL, R, and/or Python
• Experience with statistical modeling and data analysis
• Understanding of transformers and foundation models
• Self-starter with high intellectual curiosity
• Great communication skills, able to explain model results to a non-technical audience
• Proficient in data exploration techniques and tools
• Ability to work in a cross functional team as this position will be under the Finance function but have opportunity to collaborate with the AI Accelerator team
• US citizenship is required and able to obtain security clearance as needed.

Preferred Qualifications:
• Experience with data visualization libraries such as Plotly, Streamlit, and matplotlib
• Willing to learn new skills and platforms to support data analytics
• Candidates will ideally have a specialization in ML or AI
• Experience with database technologies such as SQL, NoSQL, Oracle, Hadoop, or Teradata
• Proficient in data exploration techniques and tools such as Amazon Web Services (AWS)
• Experience with MLOps tools and frameworks, such as Kubeflow, MLflow, DVC, TensorBoard
• Ability to design, build, and deploy data solutions that capture, explore, transform, and utilize data to support AI, ML, and BI
• Experience with data repositories and ETL
• Knowledge of how to design and implement high-volume data ingestion and streaming pipelines using Open Source frameworks like Apache Spark, Flink, Nifi, and Kafka on AWS Cloud
• Ability to integrate data from different sources, including databases, data warehouses, APIs, and external system

Original Posting Date: 2024-12-17While subject to change based on business needs, Leidos reasonably anticipates that this job requisition will remain open for at least 3 days with an anticipated close date of no earlier than 3 days after the original posting date as listed above.

Pay Range: Pay Range $67,600.00 - $122,200.00
The Leidos pay range for this job level is a general guideline only and not a guarantee of compensation or salary. Additional factors considered in extending an offer include (but are not limited to) responsibilities of the job, education, experience, knowledge, skills, and abilities, as well as internal equity, alignment with market data, applicable bargaining agreement (if any), or other law.
About Leidos Leidos is a Fortune 500® innovation company rapidly addressing the world's most vexing challenges in national security and health. The company's global workforce of 47,000 collaborates to create smarter technology solutions for customers in heavily regulated industries. Headquartered in Reston, Virginia, Leidos reported annual revenues of approximately $15.4 billion for the fiscal year ended December 29, 2023. For more information, visit www.Leidos.com .
Pay and Benefits Pay and benefits are fundamental to any career decision. That's why we craft compensation packages that reflect the importance of the work we do for our customers. Employment benefits include competitive compensation, Health and Wellness programs, Income Protection, Paid Leave and Retirement. More details are available here .
Securing Your Data Beware of fake employment opportunities using Leidos' name. Leidos will never ask you to provide payment-related information during any part of the employment application process (i.e., ask you for money), nor will Leidos ever advance money as part of the hiring process (i.e., send you a check or money order before doing any work). Further, Leidos will only communicate with you through emails that are generated by the Leidos.com automated system - never from free commercial services (e.g., Gmail, Yahoo, Hotmail) or via WhatsApp, Telegram, etc. If you received an email purporting to be from Leidos that asks for payment-related information or any other person a l information (e.g., about you or your previous employer), and you are concerned about its legitimacy, please make us aware immediately by emailing us at [email protected] .
If you believe you are the victim of a scam, contact your local law enforcement and report the incident to the U.S. Federal Trade Commission .
Commitment to Diversity All qualified applicants will receive consideration for employment without regard to sex, race, ethnicity, age, national origin, citizenship, religion, physical or mental disability, medical condition, genetic information, pregnancy, family structure, marital status, ancestry, domestic partner status, sexual orientation, gender identity or expression, veteran or military status, or any other basis prohibited by law. Leidos will also consider for employment qualified applicants with criminal histories consistent with relevant laws.",,2025-07-25,"['You should be strongly experienced in Python coding and visualization building skills and have knowledge of commonly used ML libraries (SciKit-learn)', 'We are looking for someone who is intellectually adaptive, likes to collaborate, inquisitive, and capable of conducting original science', ""Bachelor's degree in Computer Science, Data Science, Data Engineering or related field with 2+ years of relevant experience"", 'Strong experience with Python as well as fluency in multiple programming languages and statistical analysis tools such as C++, JavaScript, R, SAS, Excel, SQL, MATLAB, SPSS', 'Experience /familiarity with frequentist statistics and probability including predicative modeling', 'Experience with data repositories and reporting tools', 'Good understanding of machine learning algorithms, tools and platforms', 'Experience with AI/ML tools, such as common Python packages (e.g., scikit-learn, NumPy, Pandas) and Jupyter notebooks', 'Experience with time series modeling, causal inference, or probabilistic forecasting models', 'Experience with tabular data analysis using languages such as SQL, R, and/or Python', 'Experience with statistical modeling and data analysis', 'Understanding of transformers and foundation models', 'Self-starter with high intellectual curiosity', 'Great communication skills, able to explain model results to a non-technical audience', 'Proficient in data exploration techniques and tools', 'Ability to work in a cross functional team as this position will be under the Finance function but have opportunity to collaborate with the AI Accelerator team', 'US citizenship is required and able to obtain security clearance as needed', 'Original Posting Date: 2024-12-17While subject to change based on business needs, Leidos reasonably anticipates that this job requisition will remain open for at least 3 days with an anticipated close date of no earlier than 3 days after the original posting date as listed above']","['The position will collaborate with the VP of FP&A in building a Data Analytics Team within Finance', 'The Data Scientist will be expected to build statistical models, test hypotheses, interpret, summarize, visualize, and succinctly report on data findings', 'The Scientist will leverage automation and machine learning to manage data, predict scenarios and make recommendations', 'The data scientist will partner with business and operational leaders to provide an impact by leveraging data and analytical tools, strategic thinking, and hypothesis-based analysis on machine learning (ML)-based projects', 'The data scientist is responsible for modeling complex business problems through statistical, algorithmic, mining, and visualization techniques', 'Further, they will support senior leadership by creating business insights, reports, and analyses to aid in the decision-making process', 'Translates business needs into analytics/reporting requirements to support executive decisions and workflows with required information', 'Performs large-scale experimentation and builds data-driven models to answer business questions', 'Proactively mines data warehouses to identify trends and patterns and generates insights for business units and senior leadership', 'Performs large-scale experimentation to identify hidden relationships between variables in large datasets', 'Researches and implements cutting-edge techniques and tools in machine learning/deep learning/artificial intelligence to make data analysis more efficient', 'Designs and conducts data analyses with the highest standard of rigor and scientific accuracy; this includes study design, methodology, algorithms, and statistical modeling', 'Analyzes data provided to identify trends, inform decisions', 'Supports developmental plans based on data findings related to program, personnel, training needs', 'Supports development and maintenance of primary program database and run interval reporting', 'Implements appropriate modeling and data science strategies required to address customer needs', 'Communicates results and methods for solutions to internal and external stakeholders', 'Designs, builds, trains, and evaluates machine learning models']",True,"['Transformers and foundation models', 'Deep learning', 'Artificial intelligence']","Transformers and foundation models: Understanding of modern AI architectures relevant to the role, indicating exposure to advanced AI models.; Deep learning: Researching and implementing deep learning techniques to improve data analysis efficiency and model performance.; Artificial intelligence: Applying AI methods alongside machine learning to enhance data-driven decision-making and automation.","['Python', 'scikit-learn', 'Statistical modeling', 'Data visualization libraries', 'SQL', 'Pandas', 'NumPy', 'Jupyter notebooks', 'Time series modeling', 'Causal inference', 'Probabilistic forecasting models', 'Machine learning algorithms', 'Data repositories and reporting tools', 'Data exploration techniques and tools', 'Frequentist statistics and probability', 'Data engineering and ETL', 'Apache Spark, Flink, Nifi, Kafka', 'MLOps tools and frameworks', 'Tabular data analysis', 'Statistical analysis tools', 'Data pipelines', 'Data mining']","Python: Used extensively for coding, data analysis, and building visualization tools in the role.; scikit-learn: A commonly used machine learning library in Python for building and evaluating ML models.; Statistical modeling: Involves building statistical models to test hypotheses, interpret data, and support decision-making.; Data visualization libraries: Includes tools such as Plotly, Streamlit, and matplotlib used to create visual representations of data findings.; SQL: Used for querying and analyzing tabular data from databases and data warehouses.; Pandas: A Python library used for data manipulation and analysis, particularly with tabular data.; NumPy: A Python library used for numerical computing and data processing tasks.; Jupyter notebooks: An interactive environment used for developing and sharing code, data analysis, and visualizations.; Time series modeling: Applied to forecast and analyze temporal data relevant to financial planning and analysis.; Causal inference: Used to identify cause-effect relationships within data to inform business decisions.; Probabilistic forecasting models: Models that predict future outcomes with associated probabilities, supporting scenario analysis.; Machine learning algorithms: Applied to build predictive models and automate data-driven decision-making processes.; Data repositories and reporting tools: Used to store, manage, and report on large datasets to generate business insights.; Data exploration techniques and tools: Employed to investigate data characteristics, identify trends, and prepare data for modeling.; Frequentist statistics and probability: Statistical methods used for predictive modeling and hypothesis testing in the role.; Data engineering and ETL: Involves designing and maintaining data ingestion, transformation, and integration pipelines.; Apache Spark, Flink, Nifi, Kafka: Open source frameworks used for high-volume data ingestion, streaming, and processing on AWS Cloud.; MLOps tools and frameworks: Includes Kubeflow, MLflow, DVC, and TensorBoard used to manage machine learning lifecycle and model deployment.; Tabular data analysis: Analyzing structured data using SQL, R, and Python to extract insights and build models.; Statistical analysis tools: Includes C++, JavaScript, R, SAS, Excel, MATLAB, and SPSS used for various data analysis tasks.; Data pipelines: Designing and deploying data solutions to capture, transform, and utilize data for analytics and BI.; Data mining: Extracting patterns and relationships from large datasets to support business insights."
IAfRu9R8YRzc6ycbAAAAAA==,Data Science Analyst II-Geriatric and Palliative Medicine,"Description

The Data Science Analyst II collaborates with stakeholders from across the organization to develop sophisticated analytics to provide information, insights and BI (Business Intelligence) solutions that contribute to sound strategic planning, decision-making, goal setting, and effective performance measurement. The Data Science Analyst II demonstrates sound and a more advanced understanding of the healthcare domain, technical data manipulation and analytic development skills and impact the patient community of the Mount Sinai Health System.

Responsibilities
• Analyzes data requests using information technology, enrollment, claims, pharmacy, clinical, contract, medical management, financial, administrative and other corporate data from both modeled and disparate internal and external sources.
• Responsible for one or more stakeholder groups
• Takes a proactive role as liaison/analyst for internal stakeholders, understands their needs and translates them into reporting and analytic solutions.
• Effectively communicates with stakeholders and customers and ensures all requests are properly triaged, recorded and tracked.
• Adheres to corporate standards for performance metrics, data collection, data integrity, query design, and reporting format to ensure high quality, meaningful analytic output.
• Helps identify and understand data from internal and external sources for competitive, scenario and performance analyses, and financial modeling to gain member/provider insight into new and existing processes and business opportunities.
• Works closely with IT on the ongoing improvement of Mount Sinai’s integrated data warehouse, driven by strategic and business needs, and designed to ensure data and reporting consistency throughout the organization.
• Develops and maintains project work plans, including critical tasks, milestones, timelines, interdependencies and contingencies. Tracks and reports progress. Keeps stakeholders apprised of project status and implications for completion.
• Provides technical support to data analytics functions as they relate to varied business units, and technical expertise on the selection, development and implementation of various reporting and BI tools tied to business unit reporting requirements. Creates new BI reports and interactive dashboards as required.
• Prepares clear, well-organized project-specific documentation, including, at a minimum, analytic methods used, key decision points and caveats, with sufficient detail to support comprehension and replication.
• Ensures customers are adequately trained to use self-service BI tools and dashboards.
• Mentors level I Analysts, and teaches others within the organization on how to a) define meaningful process and performance measures, b) develop BI queries, and c) generate and use management reports effectively.
• Shares development and process knowledge with other analysts in order to assure redundancy and continuously builds a core of analytical strength within the organization.
• Demonstrates advanced level proficiency with the principles and methodologies of process improvement. Applies these in the execution of responsibilities in support of a process focused approach.

Qualifications
• BA or BS degree minimum, in a relevant field of study; Masters degree preferred.
• 5 years minimum in analytics development expertise, preferably in health care, or for a health provider, health plan or accountable care organization, including either:
• Working knowledge of a health care EMR such as Epic/Clarity, aCW, etc.; a payor claims system such as Facets, Amisys, etc.; or a hospital/provider system such as IDX, Soarian, etc.
• Knowledge of the New York State Medicaid and CMS Medicare regulations and related reporting requirements, such as STARS,QARR, MMCOR, MEDS, RAPS and HEDIS is a strong plus.
• Experience working in a health plan or consulting actuarial, financial reporting or medical economics departments highly valuable.
• Experience as a nurse informaticist highly valuable.
• Experience working in healthcare provider analytics related to revenue modeling, managed care contracting, population management, case management, clinical or financial decision report
• PhD, MD or DO program may be substituted for three years of experience.

, 851 - Geriatrics and Palliative Care - ISM, Icahn School of Medicine

Employer Description

Strength through Unity and Inclusion

The Mount Sinai Health System is committed to fostering an environment where everyone can contribute to excellence. We share a common dedication to delivering outstanding patient care. When you join us, you become part of Mount Sinai’s unparalleled legacy of achievement, education, and innovation as we work together to transform healthcare. We encourage all team members to actively participate in creating a culture that ensures fair access to opportunities, promotes inclusive practices, and supports the success of every individual.

At Mount Sinai, our leaders are committed to fostering a workplace where all employees feel valued, respected, and empowered to grow. We strive to create an environment where collaboration, fairness, and continuous learning drive positive change, improving the well-being of our staff, patients, and organization. Our leaders are expected to challenge outdated practices, promote a culture of respect, and work toward meaningful improvements that enhance patient care and workplace experiences. We are dedicated to building a supportive and welcoming environment where everyone has the opportunity to thrive and advance professionally. Explore this opportunity and be part of the next chapter in our history.

About the Mount Sinai Health System:

Mount Sinai Health System is one of the largest academic medical systems in the New York metro area, with more than 48,000 employees working across eight hospitals, more than 400 outpatient practices, more than 300 labs, a school of nursing, and a leading school of medicine and graduate education. Mount Sinai advances health for all people, everywhere, by taking on the most complex health care challenges of our time — discovering and applying new scientific learning and knowledge; developing safer, more effective treatments; educating the next generation of medical leaders and innovators; and supporting local communities by delivering high-quality care to all who need it. Through the integration of its hospitals, labs, and schools, Mount Sinai offers comprehensive health care solutions from birth through geriatrics, leveraging innovative approaches such as artificial intelligence and informatics while keeping patients’ medical and emotional needs at the center of all treatment. The Health System includes more than 9,000 primary and specialty care physicians; 13 joint-venture outpatient surgery centers throughout the five boroughs of New York City, Westchester, Long Island, and Florida; and more than 30 affiliated community health centers. We are consistently ranked by U.S. News & World Report's Best Hospitals, receiving high ""Honor Roll"" status, and are highly ranked: No. 1 in Geriatrics, top 5 in Cardiology/Heart Surgery, and top 20 in Diabetes/Endocrinology, Gastroenterology/GI Surgery, Neurology/Neurosurgery, Orthopedics, Pulmonology/Lung Surgery, Rehabilitation, and Urology. New York Eye and Ear Infirmary of Mount Sinai is ranked No. 12 in Ophthalmology. U.S. News & World Report’s “Best Children’s Hospitals” ranks Mount Sinai Kravis Children's Hospital among the country’s best in several pediatric specialties. The Icahn School of Medicine at Mount Sinai is ranked No. 11 nationwide in National Institutes of Health funding and in the 99th percentile in research dollars per investigator according to the Association of American Medical Colleges. Newsweek’s “The World’s Best Smart Hospitals” ranks The Mount Sinai Hospital as No. 1 in New York and in the top five globally, and Mount Sinai Morningside in the top 20 globally.

Equal Opportunity Employer

The Mount Sinai Health System is an equal opportunity employer, complying with all applicable federal civil rights laws. We do not discriminate, exclude, or treat individuals differently based on race, color, national origin, age, religion, disability, sex, sexual orientation, gender, veteran status, or any other characteristic protected by law. We are deeply committed to fostering an environment where all faculty, staff, students, trainees, patients, visitors, and the communities we serve feel respected and supported. Our goal is to create a healthcare and learning institution that actively works to remove barriers, address challenges, and promote fairness in all aspects of our organization.

Compensation

The Mount Sinai Health System (MSHS) provides salary ranges that comply with the New York City Law on Salary Transparency in Job Advertisements. The salary range for the role is $99999.98 - $121366.93 Annually. Actual salaries depend on a variety of factors, including experience, education, and operational need. The salary range or contractual rate listed does not include bonuses/incentive, differential pay or other forms of compensation or benefits.",2025-06-27T00:00:00.000Z,2025-07-25,"['5 years minimum in analytics development expertise, preferably in health care, or for a health provider, health plan or accountable care organization, including either:', 'Working knowledge of a health care EMR such as Epic/Clarity, aCW, etc.; a payor claims system such as Facets, Amisys, etc.; or a hospital/provider system such as IDX, Soarian, etc', 'Knowledge of the New York State Medicaid and CMS Medicare regulations and related reporting requirements, such as STARS,QARR, MMCOR, MEDS, RAPS and HEDIS is a strong plus', 'Experience working in a health plan or consulting actuarial, financial reporting or medical economics departments highly valuable', 'Experience as a nurse informaticist highly valuable', 'Experience working in healthcare provider analytics related to revenue modeling, managed care contracting, population management, case management, clinical or financial decision report', 'PhD, MD or DO program may be substituted for three years of experience']","['The Data Science Analyst II collaborates with stakeholders from across the organization to develop sophisticated analytics to provide information, insights and BI (Business Intelligence) solutions that contribute to sound strategic planning, decision-making, goal setting, and effective performance measurement', 'The Data Science Analyst II demonstrates sound and a more advanced understanding of the healthcare domain, technical data manipulation and analytic development skills and impact the patient community of the Mount Sinai Health System', 'Analyzes data requests using information technology, enrollment, claims, pharmacy, clinical, contract, medical management, financial, administrative and other corporate data from both modeled and disparate internal and external sources', 'Responsible for one or more stakeholder groups', 'Takes a proactive role as liaison/analyst for internal stakeholders, understands their needs and translates them into reporting and analytic solutions', 'Effectively communicates with stakeholders and customers and ensures all requests are properly triaged, recorded and tracked', 'Adheres to corporate standards for performance metrics, data collection, data integrity, query design, and reporting format to ensure high quality, meaningful analytic output', 'Helps identify and understand data from internal and external sources for competitive, scenario and performance analyses, and financial modeling to gain member/provider insight into new and existing processes and business opportunities', 'Works closely with IT on the ongoing improvement of Mount Sinai’s integrated data warehouse, driven by strategic and business needs, and designed to ensure data and reporting consistency throughout the organization', 'Develops and maintains project work plans, including critical tasks, milestones, timelines, interdependencies and contingencies', 'Tracks and reports progress', 'Keeps stakeholders apprised of project status and implications for completion', 'Provides technical support to data analytics functions as they relate to varied business units, and technical expertise on the selection, development and implementation of various reporting and BI tools tied to business unit reporting requirements', 'Creates new BI reports and interactive dashboards as required', 'Prepares clear, well-organized project-specific documentation, including, at a minimum, analytic methods used, key decision points and caveats, with sufficient detail to support comprehension and replication', 'Ensures customers are adequately trained to use self-service BI tools and dashboards', 'Mentors level I Analysts, and teaches others within the organization on how to a) define meaningful process and performance measures, b) develop BI queries, and c) generate and use management reports effectively', 'Shares development and process knowledge with other analysts in order to assure redundancy and continuously builds a core of analytical strength within the organization', 'Demonstrates advanced level proficiency with the principles and methodologies of process improvement', 'Applies these in the execution of responsibilities in support of a process focused approach']",True,[],,"['Business Intelligence (BI) Tools and Dashboards', 'Data Warehousing', 'Healthcare Data Analytics', 'Data Integrity and Query Design', 'Financial and Performance Modeling', 'Stakeholder Engagement and Analytics Translation', 'Process Improvement Methodologies', 'Healthcare Regulatory Knowledge', 'Healthcare Systems and EMR Knowledge', 'Mentoring and Training']","Business Intelligence (BI) Tools and Dashboards: Used to develop and implement reporting and BI solutions that support strategic planning, decision-making, and performance measurement; includes creating new BI reports and interactive dashboards and training users on self-service BI tools.; Data Warehousing: Involves working closely with IT to improve an integrated data warehouse to ensure data and reporting consistency across the organization, supporting analytics and reporting needs.; Healthcare Data Analytics: Analyzing diverse healthcare data sources such as enrollment, claims, pharmacy, clinical, contract, medical management, financial, administrative, and other corporate data from both modeled and disparate internal and external sources to generate insights and support business opportunities.; Data Integrity and Query Design: Adhering to corporate standards for performance metrics, data collection, data integrity, query design, and reporting format to ensure high quality and meaningful analytic output.; Financial and Performance Modeling: Conducting financial modeling and performance analyses to gain insights into member/provider processes and business opportunities within healthcare settings.; Stakeholder Engagement and Analytics Translation: Acting as a liaison to understand stakeholder needs and translate them into reporting and analytic solutions, ensuring requests are triaged, recorded, and tracked effectively.; Process Improvement Methodologies: Applying advanced principles and methodologies of process improvement to support a process-focused approach in analytics and reporting responsibilities.; Healthcare Regulatory Knowledge: Utilizing knowledge of healthcare regulations such as New York State Medicaid and CMS Medicare reporting requirements (e.g., STARS, QARR, MMCOR, MEDS, RAPS, HEDIS) to inform analytics and reporting.; Healthcare Systems and EMR Knowledge: Experience with healthcare electronic medical records (EMR) systems like Epic/Clarity, aCW, and hospital/provider systems such as IDX and Soarian, as well as payor claims systems like Facets and Amisys, to support data analytics in healthcare contexts.; Mentoring and Training: Mentoring junior analysts and teaching others how to define meaningful process and performance measures, develop BI queries, and generate and use management reports effectively."
CwULlYgvqe3eUcVtAAAAAA==,Senior Data Scientist (Data Analytics) Jobs,"Overview

We are seeking a highly skilled Senior Data Scientist with specialized expertise in Artificial Intelligence (AI) and Machine Learning (ML) to support the analysis and interpretation of large-scale datasets. This role is vital for leveraging our law enforcement client's data holdings to develop innovative insights, predictive models, and business solutions. The ideal candidate will have experience working with unstructured data, statistical modeling, and advanced data analytics to drive decision-making and enhance operational effectiveness.

Contributions
• Develop and support AI/ML models for data analysis, focusing on the accuracy, authenticity, expectancy, timeliness, relevancy, and viability of intelligence data.
• Conduct advanced data integration and statistical analysis to identify patterns, trends, and intelligence gaps.
• Innovate by deriving investigative, statistical, and predictive value from our clients extensive data sources.
• Prepare, clean, and manage big data sets, design data models, and develop robust databases to support AI-driven business solutions.
• Tackle complex technical challenges using state-of-the-art techniques and industry knowledge.
• Deploy, validate, and manage various types of data models including supervised, unsupervised, and deep learning models.
• Perform advanced mathematical and statistical modeling to organize, optimize, and predict trends from both structured and unstructured data.
• Validate and improve machine learning models with rigorous statistical techniques to ensure high accuracy and precision.
• Design and implement algorithms such as neural networks, decision trees, and surrogate models to drive AI initiatives.
• Utilize modern tools and methodologies such as Data Lakes, serverless computing (Athena/Lambda), and ETL processes to manage data storage and computational needs.
• Employ data visualization tools like Power BI, Tableau, or Qlik to translate data insights into actionable intelligence.

Qualifications

Required Qualifications:
• 4+ years of hands-on experience in AI/ML model development, including supervised and unsupervised learning, with a strong focus on Natural Language Processing (NLP) for unstructured data.
• 5+ years of proficiency in at least one analytical/statistical programming language (e.g., Python, R, Scala, Closure).
• 2+ years of experience manipulating and processing unstructured data from various platforms.
• 2+ years of experience using data visualization tools such as Power BI, Tableau, Elastic X-Pack (including Graph), or Qlik.
• Bachelor's Degree in Data Science, Computer Science, Mathematics, or a related field; a combination of education and experience may be considered. An advanced degree is desirable.
• Must be local to El, Paso TX or willing to drive on site 5 days a week.
• Applicants selected will be subject to a Government background investigation and must meet eligibility and suitability requirements.
Preferred Skills:
• Experience in client engagement and relationship building.
• Experience in team leadership and staff / team management.
• Expertise in data architecture and big data management.
• Strong problem-solving abilities with a creative approach to model optimization and algorithm development.
• Ability to work collaboratively on cross-functional teams and communicate complex technical concepts to non-technical stakeholders.

In accordance with the contractual terms and conditions set by the customer, Steampunk is required to pre-screen candidates based on customer defined criteria to determine eligibility.

About steampunk

Steampunk relies on several factors to determine salary, including but not limited to geographic location, contractual requirements, education, knowledge, skills, competencies, and experience. The projected compensation range for this position is $140,000 to $190,000. The estimate displayed represents a typical annual salary range for this position. Annual salary is just one aspect of Steampunk's total compensation package for employees. Learn more about additional Steampunk benefits here.

Identity Statement

As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud.

Steampunk is a Change Agent in the Federal contracting industry, bringing new thinking to clients in the Homeland, Federal Civilian, Health and DoD sectors. Through our Human-Centered delivery methodology, we are fundamentally changing the expectations our Federal clients have for true shared accountability in solving their toughest mission challenges. As an employee owned company, we focus on investing in our employees to enable them to do the greatest work of their careers - and rewarding them for outstanding contributions to our growth. If you want to learn more about our story, visit http://www.steampunk.com .

We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law. Steampunk participates in the E-Verify program.",2025-07-25T01:00:00.000Z,2025-07-25,"['The ideal candidate will have experience working with unstructured data, statistical modeling, and advanced data analytics to drive decision-making and enhance operational effectiveness', 'Utilize modern tools and methodologies such as Data Lakes, serverless computing (Athena/Lambda), and ETL processes to manage data storage and computational needs', '4+ years of hands-on experience in AI/ML model development, including supervised and unsupervised learning, with a strong focus on Natural Language Processing (NLP) for unstructured data', '5+ years of proficiency in at least one analytical/statistical programming language (e.g., Python, R, Scala, Closure)', '2+ years of experience manipulating and processing unstructured data from various platforms', '2+ years of experience using data visualization tools such as Power BI, Tableau, Elastic X-Pack (including Graph), or Qlik', ""Bachelor's Degree in Data Science, Computer Science, Mathematics, or a related field; a combination of education and experience may be considered"", 'Must be local to El, Paso TX or willing to drive on site 5 days a week', 'Applicants selected will be subject to a Government background investigation and must meet eligibility and suitability requirements']","[""This role is vital for leveraging our law enforcement client's data holdings to develop innovative insights, predictive models, and business solutions"", 'Develop and support AI/ML models for data analysis, focusing on the accuracy, authenticity, expectancy, timeliness, relevancy, and viability of intelligence data', 'Conduct advanced data integration and statistical analysis to identify patterns, trends, and intelligence gaps', 'Innovate by deriving investigative, statistical, and predictive value from our clients extensive data sources', 'Prepare, clean, and manage big data sets, design data models, and develop robust databases to support AI-driven business solutions', 'Tackle complex technical challenges using state-of-the-art techniques and industry knowledge', 'Deploy, validate, and manage various types of data models including supervised, unsupervised, and deep learning models', 'Perform advanced mathematical and statistical modeling to organize, optimize, and predict trends from both structured and unstructured data', 'Validate and improve machine learning models with rigorous statistical techniques to ensure high accuracy and precision', 'Design and implement algorithms such as neural networks, decision trees, and surrogate models to drive AI initiatives', 'Employ data visualization tools like Power BI, Tableau, or Qlik to translate data insights into actionable intelligence']",True,"['Natural Language Processing', 'Deep Learning']",Natural Language Processing: Focus on NLP techniques applied to unstructured data as part of AI/ML model development to extract intelligence and support law enforcement analytics.; Deep Learning: Use deep learning methods including neural networks to develop AI models that enhance predictive capabilities and investigative insights.,"['Supervised Learning', 'Unsupervised Learning', 'Deep Learning Models', 'Statistical Modeling', 'Machine Learning Model Validation', 'Neural Networks', 'Decision Trees', 'Surrogate Models', 'Natural Language Processing', 'Data Lakes', 'Serverless Computing', 'ETL Processes', 'Data Visualization Tools', 'Analytical Programming Languages', 'Big Data Management']","Supervised Learning: Develop and support AI/ML models including supervised learning to analyze intelligence data with focus on accuracy and relevancy.; Unsupervised Learning: Deploy and manage unsupervised learning models to identify patterns, trends, and intelligence gaps in large datasets.; Deep Learning Models: Deploy, validate, and manage deep learning models such as neural networks to drive AI initiatives and predictive analytics.; Statistical Modeling: Perform advanced mathematical and statistical modeling to organize, optimize, and predict trends from structured and unstructured data.; Machine Learning Model Validation: Validate and improve machine learning models using rigorous statistical techniques to ensure high accuracy and precision.; Neural Networks: Design and implement neural network algorithms as part of AI initiatives to enhance predictive modeling and data analysis.; Decision Trees: Design and implement decision tree algorithms to support AI-driven business solutions and investigative analytics.; Surrogate Models: Develop surrogate models to support complex AI and machine learning tasks within data analysis workflows.; Natural Language Processing: Apply NLP techniques focused on unstructured data to extract insights and support AI/ML model development.; Data Lakes: Utilize Data Lakes for managing large-scale data storage and integration to support AI-driven business solutions.; Serverless Computing: Employ serverless computing technologies such as Athena and Lambda to manage data storage and computational needs efficiently.; ETL Processes: Design and implement ETL processes to prepare, clean, and manage big data sets for advanced analytics and AI applications.; Data Visualization Tools: Use tools like Power BI, Tableau, Elastic X-Pack, and Qlik to translate complex data insights into actionable intelligence for stakeholders.; Analytical Programming Languages: Leverage programming languages such as Python, R, Scala, and Closure for statistical analysis, data manipulation, and model development.; Big Data Management: Expertise in data architecture and big data management to handle extensive and diverse data sources for analytics and AI."
npE7ACWV6keCaLZQAAAAAA==,Data Scientist,"We are seeking a Data Scientist for a long term contract in Tucson, AZ.

This position is ideal for a Data Scientist who is passionate about doing meaningful work—applying their skills in AI, machine learning, and image analysis to advance cancer diagnostics and digital pathology. You’ll be working with a mission-driven, highly respected healthcare company that's at the forefront of innovation in cancer technology and patient care.

Description: Data Scientist, Digital Pathology Development

Onsite – Tucson

Key Responsibilities:
• Work closely with the Tucson-based assay and algorithm development teams to ensure seamless data integration and maintain data integrity across complex digital pathology projects.
• Design, develop, and implement robust solutions to automate manual steps within the algorithm development and data management workflows, enhancing efficiency and reproducibility.
• Perform sophisticated image processing, data analysis, and predictive modeling using large-scale digital pathology datasets.
• Build, test, and deploy computational tools and algorithms, primarily using Python or similar languages, adhering to high standards of code quality, efficiency, and maintainability.
• Leverage your skills in digital pathology, machine learning (ML), artificial intelligence (AI), and GUI development to create impactful solutions and improve algorithm performance.
• Meticulously maintain the traceability and integrity of all data, including images and associated metadata, ensuring compliance with relevant standards and supporting contractual obligations.

Minimum Qualifications:
• Bachelor's degree in Computer Science, Data Science, Engineering, Statistics, or a related quantitative field with 7+ years of relevant experience.
• Proven experience developing, testing, and deploying solutions using Python or similar programming languages within a software development lifecycle.
• Solid understanding and practical experience in image analysis, machine learning/deep learning techniques, and AI concepts.
• Demonstrated ability to perform complex data modeling, processing, and analysis on large or intricate datasets.
• Experience developing graphical user interface (GUI) for technical applications or data visualization.
• Excellent analytical and problem-solving skills with meticulous attention to detail.
• Strong verbal and written communication skills, enabling effective collaboration within cross-functional teams.

Preferred Qualifications:
• Experience working within the life sciences, biotechnology, or pharmaceutical industry, particularly with digital pathology or medical imaging data.
• Familiarity with regulatory requirements and compliance standards applicable to medical devices or software as a medical device (SaMD) (e.g., FDA guidance, IVDR).
• Proficiency with cloud computing platforms (e.g., AWS, Azure, GCP) and associated services.
• Experience utilizing High-Performance Computing (HPC) environments for computationally intensive tasks.
• Knowledge of bioinformatics or molecular modeling techniques.",,2025-07-25,"[""Bachelor's degree in Computer Science, Data Science, Engineering, Statistics, or a related quantitative field with 7+ years of relevant experience"", 'Proven experience developing, testing, and deploying solutions using Python or similar programming languages within a software development lifecycle', 'Solid understanding and practical experience in image analysis, machine learning/deep learning techniques, and AI concepts', 'Demonstrated ability to perform complex data modeling, processing, and analysis on large or intricate datasets', 'Experience developing graphical user interface (GUI) for technical applications or data visualization', 'Excellent analytical and problem-solving skills with meticulous attention to detail', 'Strong verbal and written communication skills, enabling effective collaboration within cross-functional teams']","['Work closely with the Tucson-based assay and algorithm development teams to ensure seamless data integration and maintain data integrity across complex digital pathology projects', 'Design, develop, and implement robust solutions to automate manual steps within the algorithm development and data management workflows, enhancing efficiency and reproducibility', 'Perform sophisticated image processing, data analysis, and predictive modeling using large-scale digital pathology datasets', 'Build, test, and deploy computational tools and algorithms, primarily using Python or similar languages, adhering to high standards of code quality, efficiency, and maintainability', 'Leverage your skills in digital pathology, machine learning (ML), artificial intelligence (AI), and GUI development to create impactful solutions and improve algorithm performance', 'Meticulously maintain the traceability and integrity of all data, including images and associated metadata, ensuring compliance with relevant standards and supporting contractual obligations']",True,"['Artificial Intelligence', 'Deep Learning']",Artificial Intelligence: Applied alongside machine learning and deep learning techniques to enhance algorithm performance and develop impactful solutions in digital pathology.; Deep Learning: Used as part of image analysis and algorithm development to improve diagnostic accuracy and automate complex tasks in digital pathology.,"['Machine Learning', 'Image Analysis', 'Predictive Modeling', 'Python Programming', 'Data Integration and Integrity', 'Graphical User Interface (GUI) Development', 'Data Modeling and Processing', 'High-Performance Computing (HPC)', 'Cloud Computing Platforms']","Machine Learning: Used to develop and improve algorithms for digital pathology projects, including predictive modeling and data analysis on large-scale datasets.; Image Analysis: Applied to process and analyze digital pathology images to support cancer diagnostics and algorithm development.; Predictive Modeling: Performed on large-scale digital pathology datasets to build computational tools that aid in diagnostics and research.; Python Programming: Primary language used to build, test, and deploy computational tools and algorithms, ensuring code quality and maintainability.; Data Integration and Integrity: Ensuring seamless integration and maintaining the accuracy and traceability of complex digital pathology data and associated metadata.; Graphical User Interface (GUI) Development: Developed for technical applications and data visualization to improve usability and interaction with computational tools.; Data Modeling and Processing: Conducted complex data modeling and processing on large or intricate datasets to support algorithm development and analysis.; High-Performance Computing (HPC): Utilized for computationally intensive tasks related to image processing and algorithm development in digital pathology.; Cloud Computing Platforms: Experience with AWS, Azure, or GCP to support scalable computing and data storage needs for digital pathology projects."
HD_Y3R_tuV5zgVAeAAAAAA==,"Lead Data Scientist, Machine Learning Engineer 2025- US","Aimpoint Digital is a premier analytics consulting firm with a mission to drive business value for clients through expertise in data strategy, data analytics, decision sciences, and data engineering and infrastructure. This position is within our decision sciences practice which focuses on delivering solutions via machine learning and statistical modelling.

What you will do

As a part of Aimpoint Digital, you will focus on enabling clients to get the most out of their data. You will work with all levels of the client organization to build value driving solutions that extract insights and then train them on how to manage and maintain these solutions. Typical solutions will utilize machine learning, artificial intelligence, statistical analysis, automation, optimization, and/or data visualizations. As a Lead Data Scientist, you will be expected to work independently on client engagements, take part in the development of our practice, aid in business development, and contribute innovative ideas and initiatives to our company. As a Lead Data Scientist you will:
• Become a trusted advisor working with clients to design end-to-end analytical solutions
• Work independently to solve complex data science use-cases across various industries
• Design and develop feature engineering pipelines, build ML & AI infrastructure, deploy models, and orchestrate advanced analytical insights
• Write code in SQL, Python, and Spark following software engineering best practices
• Collaborate with stakeholders and customers to ensure successful project delivery

Who we are looking for

We are looking for collaborative individuals who want to drive value, work in a fast-paced environment, and solve real business problems. You are a coder who writes efficient and optimized code leveraging key Databricks features. You are a problem-solver who can deliver simple, elegant solutions as well as cutting-edge solutions that, regardless of complexity, your clients can understand, implement, and maintain. You genuinely think about the end-to-end machine learning pipeline as you generate robust solutions. You are both a teacher and a student as we enable our clients, upskill our teammates, and learn from one another. You want to drive impact for your clients and do so through thoughtfulness, prioritization, and seeing a solution through from brainstorming to deployment. In particular you have these traits:
• Degree in Computer Science, Engineering, Mathematics, or equivalent experience.
• Experience with building high quality Data Science models to solve a client's business problems
• Experience with managing stakeholders and collaborating with customers
• Strong written and verbal communication skills required
• Ability to manage an individual workstream independently
• 3+ years of experience developing and deploying ML models in any platform (Azure, AWS, GCP, Databricks etc.)
• Ability to apply data science methodologies and principles to real life projects
• Expertise in software engineering concepts and best practices
• Self-starter with excellent communication skills, able to work independently, and lead projects, initiatives, and/or people
• Willingness to travel.

Want to stand out?
• Consulting Experience
• Databricks Machine Learning Associate or Machine Learning Professional Certification.
• Familiarity with traditional machine learning tools such as Python, SKLearn, XGBoost, SparkML, etc.
• Experience with deep learning frameworks like TensorFlow or PyTorch.
• Knowledge of ML model deployment options (e.g., Azure Functions, FastAPI, Kubernetes) for real-time and batch processing.
• Experience with CI/CD pipelines (e.g., DevOps pipelines, GitHub Actions).
• Knowledge of infrastructure as code (e.g., Terraform, ARM Template, Databricks Asset Bundles).
• Understanding of advanced machine learning techniques, including graph-based processing, computer vision, natural language processing, and simulation modeling.
• Experience with generative AI and LLMs, such as LLamaIndex and LangChain
• Understanding of MLOps or LLMOps.
• Familiarity with Agile methodologies, preferably Scrum

We are actively seeking candidates for full-time, remote work within the US.",2025-07-14T00:00:00.000Z,2025-07-25,"['We are looking for collaborative individuals who want to drive value, work in a fast-paced environment, and solve real business problems', 'You are a coder who writes efficient and optimized code leveraging key Databricks features', 'You are a problem-solver who can deliver simple, elegant solutions as well as cutting-edge solutions that, regardless of complexity, your clients can understand, implement, and maintain', 'You genuinely think about the end-to-end machine learning pipeline as you generate robust solutions', 'Degree in Computer Science, Engineering, Mathematics, or equivalent experience', ""Experience with building high quality Data Science models to solve a client's business problems"", 'Experience with managing stakeholders and collaborating with customers', 'Strong written and verbal communication skills required', 'Ability to manage an individual workstream independently', '3+ years of experience developing and deploying ML models in any platform (Azure, AWS, GCP, Databricks etc.)', 'Ability to apply data science methodologies and principles to real life projects', 'Expertise in software engineering concepts and best practices', 'Self-starter with excellent communication skills, able to work independently, and lead projects, initiatives, and/or people', 'Willingness to travel', 'Consulting Experience', 'Databricks Machine Learning Associate or Machine Learning Professional Certification', 'Familiarity with traditional machine learning tools such as Python, SKLearn, XGBoost, SparkML, etc', 'Experience with deep learning frameworks like TensorFlow or PyTorch', 'Knowledge of ML model deployment options (e.g., Azure Functions, FastAPI, Kubernetes) for real-time and batch processing', 'Experience with CI/CD pipelines (e.g., DevOps pipelines, GitHub Actions)', 'Knowledge of infrastructure as code (e.g., Terraform, ARM Template, Databricks Asset Bundles)', 'Understanding of advanced machine learning techniques, including graph-based processing, computer vision, natural language processing, and simulation modeling', 'Experience with generative AI and LLMs, such as LLamaIndex and LangChain', 'Understanding of MLOps or LLMOps', 'Familiarity with Agile methodologies, preferably Scrum', 'We are actively seeking candidates for full-time, remote work within the US']","['As a part of Aimpoint Digital, you will focus on enabling clients to get the most out of their data', 'You will work with all levels of the client organization to build value driving solutions that extract insights and then train them on how to manage and maintain these solutions', 'Typical solutions will utilize machine learning, artificial intelligence, statistical analysis, automation, optimization, and/or data visualizations', 'As a Lead Data Scientist, you will be expected to work independently on client engagements, take part in the development of our practice, aid in business development, and contribute innovative ideas and initiatives to our company', 'Become a trusted advisor working with clients to design end-to-end analytical solutions', 'Work independently to solve complex data science use-cases across various industries', 'Design and develop feature engineering pipelines, build ML & AI infrastructure, deploy models, and orchestrate advanced analytical insights', 'Write code in SQL, Python, and Spark following software engineering best practices', 'Collaborate with stakeholders and customers to ensure successful project delivery', 'You are both a teacher and a student as we enable our clients, upskill our teammates, and learn from one another', 'You want to drive impact for your clients and do so through thoughtfulness, prioritization, and seeing a solution through from brainstorming to deployment']",True,"['Generative AI', 'Large Language Models (LLMs)', 'LLMOps']","Generative AI: Experience with generative AI technologies and frameworks such as LLamaIndex and LangChain to build AI-driven solutions.; Large Language Models (LLMs): Familiarity with LLMs and their application in AI infrastructure and solutions, including managing and deploying these models.; LLMOps: Understanding of operations specifically related to managing and deploying large language models and AI pipelines.","['Machine Learning', 'Statistical Analysis', 'Feature Engineering', 'Data Pipelines', 'SQL', 'Python', 'Spark', 'Scikit-learn', 'XGBoost', 'SparkML', 'Deep Learning Frameworks', 'ML Model Deployment', 'CI/CD Pipelines', 'Infrastructure as Code', 'Advanced Machine Learning Techniques', 'Data Visualization', 'MLOps']","Machine Learning: Utilized to build high quality data science models that solve client business problems and to develop and deploy ML models across various platforms such as Azure, AWS, GCP, and Databricks.; Statistical Analysis: Applied as part of delivering solutions that extract insights and support decision sciences within client engagements.; Feature Engineering: Designing and developing feature engineering pipelines to prepare data for machine learning and analytical models.; Data Pipelines: Building and orchestrating pipelines that support feature engineering and model deployment as part of end-to-end analytical solutions.; SQL: Writing code in SQL to manipulate and query data as part of data science workflows following software engineering best practices.; Python: Used for coding in data science projects, including building machine learning models and feature engineering pipelines.; Spark: Utilized for big data processing and coding within data science projects, leveraging Databricks features.; Scikit-learn: Familiarity with this traditional machine learning tool is required for building and deploying ML models.; XGBoost: Experience with this gradient boosting framework is expected for developing machine learning models.; SparkML: Used as a machine learning library within Spark for building scalable ML models.; Deep Learning Frameworks: Experience with TensorFlow and PyTorch for advanced machine learning techniques including computer vision and natural language processing.; ML Model Deployment: Knowledge of deploying ML models using options such as Azure Functions, FastAPI, and Kubernetes for real-time and batch processing.; CI/CD Pipelines: Experience with continuous integration and continuous deployment pipelines like DevOps pipelines and GitHub Actions to automate ML model deployment.; Infrastructure as Code: Knowledge of tools such as Terraform, ARM Template, and Databricks Asset Bundles to manage infrastructure supporting data science and ML workflows.; Advanced Machine Learning Techniques: Understanding of graph-based processing, computer vision, natural language processing, and simulation modeling to solve complex data science use-cases.; Data Visualization: Utilized to communicate analytical insights effectively to stakeholders and clients.; MLOps: Understanding of machine learning operations to manage the lifecycle of ML models and infrastructure."
Db5tG7QmN3FBIZ98AAAAAA==,"Data Scientist - Data and Machine Learning, WWPS ProServe","Description

Are you excited to help the healthcare and life sciences (HCLS) industry customers design, build, and implement AI algorithms, including advanced Generative AI solutions, to augment decision making while meeting the highest standards for reliability, transparency, and scalability? The Amazon Web Services (AWS) Professional Services team works directly with HCLS customers to achieve their goals through the adoption of Machine Learning (ML) and Generative AI methods. Our team collaborates across the entire AWS organization to bring access to product and service teams, to get the right solution delivered and drive feature innovation based on customer needs.

At AWS, we're hiring experienced data scientists with a background in both traditional and generative AI who can help our customers understand the opportunities their HCLS data presents, and build solutions that earn the customer trust needed for deployment to production systems.

In this role, you will work closely with customers to deeply understand their data challenges and requirements, and design tailored solutions that best fit their use cases. You should have broad experience building models using all kinds of HCLS data sources, and building data-intensive applications at scale. You should possess excellent business acumen and communication skills to collaborate effectively with stakeholders, develop key business questions, and translate requirements into actionable solutions. You will provide guidance and support to other engineers, sharing industry best practices and driving innovation in the field of data science and AI.

This position requires that the candidate selected be a US Citizen.

Key job responsibilities

As An Data Scientist, You Will
• Collaborate with AI/ML scientists and architects to research, design, develop, and evaluate AI algorithms to address real-world challenges
• Interact with customers directly to understand the business problem, help and aid them in implementation of AI solutions, deliver briefing and deep dive sessions to customers and guide customer on adoption patterns and paths to production.
• Create and deliver best practice recommendations, tutorials, blog posts, sample code, and presentations adapted to technical, business, and executive stakeholder
• Provide customer and market feedback to Product and Engineering teams to help define product direction

About The Team

Diverse Experiences: AWS values diverse experiences. Even if you do not meet all of the preferred qualifications and skills listed in the job below, we encourage candidates to apply. If your career is just starting, hasn’t followed a traditional path, or includes alternative experiences, don’t let it stop you from applying.

Why AWS? Amazon Web Services (AWS) is the world’s most comprehensive and broadly adopted cloud platform. We pioneered cloud computing and never stopped innovating — that’s why customers from the most successful startups to Global 500 companies trust our robust suite of products and services to power their businesses.

Inclusive Team Culture - Here at AWS, it’s in our nature to learn and be curious. Our employee-led affinity groups foster a culture of inclusion that empower us to be proud of our differences. Ongoing events and learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (diversity) conferences, inspire us to never stop embracing our uniqueness.

Mentorship & Career Growth - We’re continuously raising our performance bar as we strive to become Earth’s Best Employer. That’s why you’ll find endless knowledge-sharing, mentorship and other career-advancing resources here to help you develop into a better-rounded professional.

Work/Life Balance - We value work-life harmony. Achieving success at work should never come at the expense of sacrifices at home, which is why we strive for flexibility as part of our working culture. When we feel supported in the workplace and at home, there’s nothing we can’t achieve in the cloud.

Basic Qualifications
• Bachelor's degree in Computer Science, Engineering, related field, or equivalent experience
• 3+ years of experience building models for business applications
• Experience with algorithms, data structures, parsing, numerical optimization, data mining, parallel and distributed computing, high-performance computing, neural deep learning methods and/or machine learning
• Experience using Python and hands on experience building models with deep learning frameworks (i.e. Tensorflow, Keras, PyTorch, MXNet, JAX)
• Experience of working with healthcare and life sciences data (e.g. EHR, HL7/FHIR, insurance claims, genomics, medical imaging, etc)

Preferred Qualifications
• Masters or PhD Degree in computer science, engineering, mathematics, operations research, or in a highly quantitative field related to healthcare and life sciences
• Practical experience in solving complex problems using cloud computing
• Experience building applications leveraging GenAI

Amazon is an equal opportunity employer and does not discriminate on the basis of protected veteran status, disability, or other legally protected status.

Los Angeles County applicants: Job duties for this position include: work safely and cooperatively with other employees, supervisors, and staff; adhere to standards of excellence despite stressful conditions; communicate effectively and respectfully with employees, supervisors, and staff to ensure exceptional customer service; and follow all federal, state, and local laws and Company policies. Criminal history may have a direct, adverse, and negative relationship with some of the material job duties of this position. These include the duties and responsibilities listed above, as well as the abilities to adhere to company policies, exercise sound judgment, effectively manage stress and work safely and respectfully with others, exhibit trustworthiness and professionalism, and safeguard business operations and the Company’s reputation. Pursuant to the Los Angeles County Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $125,500/year in our lowest geographic market up to $212,800/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.

Company - Amazon Web Services, Inc.

Job ID: A2993489",2025-07-10T00:00:00.000Z,2025-07-25,"['You should have broad experience building models using all kinds of HCLS data sources, and building data-intensive applications at scale', 'You should possess excellent business acumen and communication skills to collaborate effectively with stakeholders, develop key business questions, and translate requirements into actionable solutions', 'This position requires that the candidate selected be a US Citizen', ""Bachelor's degree in Computer Science, Engineering, related field, or equivalent experience"", '3+ years of experience building models for business applications', 'Experience with algorithms, data structures, parsing, numerical optimization, data mining, parallel and distributed computing, high-performance computing, neural deep learning methods and/or machine learning', 'Experience using Python and hands on experience building models with deep learning frameworks (i.e', 'Tensorflow, Keras, PyTorch, MXNet, JAX)', 'Experience of working with healthcare and life sciences data (e.g', 'EHR, HL7/FHIR, insurance claims, genomics, medical imaging, etc)', 'These include the duties and responsibilities listed above, as well as the abilities to adhere to company policies, exercise sound judgment, effectively manage stress and work safely and respectfully with others, exhibit trustworthiness and professionalism, and safeguard business operations and the Company’s reputation']","['In this role, you will work closely with customers to deeply understand their data challenges and requirements, and design tailored solutions that best fit their use cases', 'You will provide guidance and support to other engineers, sharing industry best practices and driving innovation in the field of data science and AI', 'Collaborate with AI/ML scientists and architects to research, design, develop, and evaluate AI algorithms to address real-world challenges', 'Interact with customers directly to understand the business problem, help and aid them in implementation of AI solutions, deliver briefing and deep dive sessions to customers and guide customer on adoption patterns and paths to production', 'Create and deliver best practice recommendations, tutorials, blog posts, sample code, and presentations adapted to technical, business, and executive stakeholder', 'Provide customer and market feedback to Product and Engineering teams to help define product direction']",True,"['Generative AI', 'AI Algorithms']","Generative AI: Designing, building, and implementing advanced generative AI solutions to augment decision making in healthcare and life sciences, including helping customers adopt generative AI methods and build applications leveraging GenAI.; AI Algorithms: Collaborating with AI/ML scientists and architects to research, design, develop, and evaluate AI algorithms that address real-world challenges in healthcare and life sciences.","['Healthcare and Life Sciences Data', 'Machine Learning', 'Deep Learning Frameworks', 'Python Programming']","Healthcare and Life Sciences Data: Experience working with diverse healthcare and life sciences data sources such as EHR, HL7/FHIR, insurance claims, genomics, and medical imaging to build models and data-intensive applications at scale.; Machine Learning: Building models for business applications using machine learning techniques including algorithms, data structures, numerical optimization, data mining, parallel and distributed computing, and high-performance computing.; Deep Learning Frameworks: Hands-on experience building models using deep learning frameworks such as TensorFlow, Keras, PyTorch, MXNet, and JAX to develop neural deep learning methods.; Python Programming: Using Python as a primary programming language for developing machine learning and deep learning models."
h902T2VUZpEt8OGEAAAAAA==,Data Scientist - Lead,"Description:
• Analyze and interpret datasets using statistical techniques and machine learning.
• Use data science tools like Azure Databricks, Power BI, and Python.
• Prepare and deliver analysis results that communicate data insights.
• Collaborate with cross-functional teams to understand data needs.
• Build predictive models and machine-learning algorithms.
• Coach and mentor team members on data science best practices.

Requirements:
• Bachelors degree with five (5) or more years of experience in the field or in a related area.
• Masters or doctorate degree
• Expertise in Power Platform s
• Familiarity with LLM (open source or closed)
• Experience in Front end web app development ( Flaskapp , Gradio etc )
• Familiarity with RAG architecture

Benefits:",2025-07-23T00:00:00.000Z,2025-07-25,"['Bachelors degree with five (5) or more years of experience in the field or in a related area', 'Masters or doctorate degree', 'Expertise in Power Platform s', 'Familiarity with LLM (open source or closed)', 'Experience in Front end web app development ( Flaskapp , Gradio etc )', 'Familiarity with RAG architecture']","['Analyze and interpret datasets using statistical techniques and machine learning', 'Use data science tools like Azure Databricks, Power BI, and Python', 'Prepare and deliver analysis results that communicate data insights', 'Collaborate with cross-functional teams to understand data needs', 'Build predictive models and machine-learning algorithms', 'Coach and mentor team members on data science best practices']",True,"['Large Language Models', 'Retrieval-Augmented Generation', 'AI-Enabled Frontend Development']","Large Language Models: Familiarity with open source or closed LLMs is required, indicating use or integration of advanced AI language models.; Retrieval-Augmented Generation: Knowledge of RAG architecture suggests involvement with AI systems that combine retrieval of external information with generative language models.; AI-Enabled Frontend Development: Experience with frontend web app development using frameworks like Flask and Gradio, which are often used to build interfaces for AI models.","['Statistical Techniques', 'Machine Learning', 'Azure Databricks', 'Power BI', 'Python', 'Predictive Models']",Statistical Techniques: Used to analyze and interpret datasets to extract meaningful insights.; Machine Learning: Applied to build predictive models and machine-learning algorithms for data analysis.; Azure Databricks: Utilized as a data science tool for processing and analyzing large datasets.; Power BI: Used to prepare and deliver analysis results through interactive dashboards and reports.; Python: Employed as a programming language for data analysis and building machine learning models.; Predictive Models: Developed to forecast outcomes based on historical data.
dda2-nHv7bZhJWViAAAAAA==,Data Scientist 2 (Hawaii),"Prime Time Consulting provides clients with expert intelligence analysis services. Our clients include defense contractors, industrial and service corporations, and departments and agencies of the U.S. Federal Government.

Data Scientist 2

We are actively searching for Data Scientists, located in Hawaii, to support our team. We have varying levels of Data Scientist roles, depending on years of experience and education.

Job Description:
• Performs tasks associated with Big Data Platform management, utilizes skills in programming languages, develops prototype algorithms as well as algorithm refinements, and supports data visualization and analytics.

The Level 2 Data Scientist shall possess the following capabilities:

Employ some combination of the following skill areas:
• Foundations: (Mathematical, Computational, Statistical) 2. Data Processing: (Data management and curation, data description and visualization, workflow, and reproducibility)
• Modeling, Inference, and Prediction: (Data modeling and assessment, domain-specific considerations)
• Devise strategies for extracting meaning and value from large datasets. Make and communicate principled conclusions from data using elements of mathematics,
• Statistics, computer science, and application specific knowledge.
• Through analytic modeling, statistical analysis, programming, and/or another appropriate scientific method, develop and implement qualitative and quantitative methods for characterizing, exploring, and assessing large datasets in various states of organization, cleanliness, and structure that account for the unique features and limitations inherent in data holdings.
• Translate practical mission needs and analytic questions related to large datasets into technical requirements and, conversely, assist others with drawing appropriate conclusions from the analysis of such data. Effectively communicate complex technical information to non-technical audiences. Make informed recommendations regarding competing technical solutions by maintaining awareness of the constantly shifting, processing, storage and analytic capabilities and limitations.

Qualifications:
• Bachelor’s Degree with 3 years of relevant experience

OR
• Associates degree with 5 years of relevant experience
• Bachelor’s Degree must be in Mathematics, Applied Mathematics Statistics, Applied Statistics, Machine learning, Data Science, Operations Research, or Computer Science or a degree in a related field (Computer Information Systems, Engineering), a degree in the physical/hard sciences (e.g. physics, chemistry, biology, astronomy), or other science disciplines with a substantial computational component (i.e. behavioral, social, or life) may be considered if it included a concentration of coursework (5 or more courses) in advanced Mathematics (typically 300 level or higher, such as linear algebra, probability and statistics, machine learning) and/or computer science (e.g. algorithms, programming, , data structures, data mining, artificial intelligence). College-level requirements, or upper-level math courses designated as elementary or basic do not count. Note: A broader range of degrees will be considered if accompanied by a Certificate in Data Science from an accredited college/university.
• Relevant experience must be in designing/implementing machine learning, data science, advanced analytical algorithms, programming (skill in at least one high-level language (e.g., Python)), statistical analysis (e.g., variability, sampling error, inference, hypothesis testing, EDA, application of linear models), data management (e.g., data cleaning and transformation), data mining, data modeling and assessment, artificial intelligence, and/or software engineering. Experience in more than one area is strongly preferred.

Position requires active Security Clearance with appropriate Polygraph

Pay Range: $80,000-$130,000

The salary range provided in this job posting is intended to offer a general idea of the compensation for the role and is based on market research and internal benchmarks. The actual salary offered to the selected candidate will be determined based on factors such as experience, education, qualifications, and geographic location. This range is subject to change and does not constitute a guarantee of compensation. Additionally, the salary offered may be adjusted based on the candidate’s performance during the selection process and evolving business needs.

Company Perks
• 200 hours of PTO annually
• 6% 401k Contribution
• Competitive Health Care Options
• Short Term/Long Term/Life Insurance
• Annual Training Budget

We are an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, sex, age, national origin, disability, Veteran status, or any other category protected by federal, state, or local laws.",2025-06-29T00:00:00.000Z,2025-07-25,,,True,[],,"['Big Data Platform Management', 'Programming Languages', 'Data Visualization', 'Data Processing', 'Mathematical, Computational, and Statistical Foundations', 'Modeling, Inference, and Prediction', 'Analytic Modeling and Statistical Analysis', 'Data Cleaning and Transformation', 'Machine Learning', 'Statistical Analysis Techniques', 'Data Mining', 'Data Modeling and Assessment', 'Software Engineering']","Big Data Platform Management: Involves managing large-scale data platforms to support data processing and analytics tasks as part of the data scientist role.; Programming Languages: Utilized for developing prototype algorithms, algorithm refinements, and supporting data visualization and analytics.; Data Visualization: Used to represent data graphically to aid in analysis and communication of insights.; Data Processing: Includes data management, curation, description, visualization, workflow, and reproducibility to handle large datasets effectively.; Mathematical, Computational, and Statistical Foundations: Provides the theoretical basis for data modeling, inference, and prediction tasks.; Modeling, Inference, and Prediction: Involves data modeling and assessment with domain-specific considerations to extract meaningful insights from data.; Analytic Modeling and Statistical Analysis: Used to develop and implement qualitative and quantitative methods for characterizing, exploring, and assessing large datasets.; Data Cleaning and Transformation: Processes applied to prepare data for analysis by improving data quality and structure.; Machine Learning: Designing and implementing algorithms to enable predictive modeling and data-driven decision making.; Statistical Analysis Techniques: Includes variability analysis, sampling error, inference, hypothesis testing, exploratory data analysis, and application of linear models.; Data Mining: Techniques used to discover patterns and relationships in large datasets.; Data Modeling and Assessment: Creating representations of data structures and evaluating their suitability for analysis.; Software Engineering: Applying programming and development skills to build and maintain data science solutions."
BQFGF4-a8emlvysjAAAAAA==,"Data Scientist, Research, Youtube Ads, Advertiser Optimization","About the position

At Google, data drives all of our decision-making. As a Data Scientist focused on Research and Advertiser Optimization for YouTube Ads, you will play a crucial role in shaping Google's business and technical strategies by processing, analyzing, and interpreting vast data sets. Your analytical excellence and statistical methods will be essential in mining through data to identify opportunities for Google and its clients to operate more efficiently. This includes enhancing advertising efficacy, optimizing network infrastructure, and studying user behavior. In this role, you will not only analyze data but also collaborate with Engineers, Product Managers, Sales Associates, and Marketing teams to adjust Google's practices based on your findings. Identifying problems is just the beginning; you will also be responsible for devising solutions. You will evaluate and improve Google's products, working alongside a multi-disciplinary team of engineers and analysts on a wide range of challenges. This position requires a scientific approach and statistical methods to tackle product creation, development, and improvement while considering the behaviors of end users. The US base salary range for this full-time position is $127,000-$187,000, plus bonuses, equity, and benefits. The salary range reflects the minimum and maximum target salaries for the position across all US locations, with individual pay determined by work location and other factors such as job-related skills, experience, and relevant education or training. Your recruiter can provide more specific salary information during the hiring process. Google is committed to being an equal opportunity workplace and an affirmative action employer, ensuring equal employment opportunity regardless of various factors including race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements.

Responsibilities
• Manage bidding optimization to ensure exceptional advertiser experiences, while contributing to business growth.
,
• Align retrieval scores with auctions to maximize the total desired spend across all advertisers and ensure YouTube advertisers see immediate benefits from investments.
,
• Own the process of gathering, extracting, and compiling data across sources via relevant tools (e.g., SQL, R, Python).
,
• Independently format, re-structure, and/or validate data to ensure quality, and review the dataset to ensure it is ready for analysis.
,
• Use custom data infrastructure or existing data models as appropriate, using specialized knowledge.
,
• Design and evaluate models to mathematically express and solve defined problems with limited precedent.
,
• Collaborate with cross-functional stakeholders to identify and clarify business or product questions to answer.
,
• Provide feedback to translate and refine business questions into tractable analysis, evaluation metrics, or mathematical models.

Requirements
• Master's degree in Statistics, Data Science, Mathematics, Physics, Economics, Operations Research, Engineering, or a related quantitative field.
,
• 3 years of work experience using analytics to solve product or business problems, coding (e.g., Python, R, SQL), querying databases or statistical analysis, or a PhD degree.

Nice-to-haves
• 5 years of work experience using analytics to solve product or business problems, coding (e.g., Python, R, SQL), querying databases or statistical analysis, or a PhD degree.
,
• Experience and strong interest in understanding, measuring, and improving end user experience.
,
• Experience in constrained optimization theory.
,
• Knowledge of Ads systems, including auction, serving, and ads quality.

Benefits
• Health insurance
,
• Dental insurance
,
• Vision insurance
,
• 401(k) plan with company matching
,
• Paid time off
,
• Parental leave
,
• Employee stock purchase plan
,
• Tuition reimbursement
,
• Professional development opportunities
,
• Wellness programs",,2025-07-25,"[""Master's degree in Statistics, Data Science, Mathematics, Physics, Economics, Operations Research, Engineering, or a related quantitative field"", '3 years of work experience using analytics to solve product or business problems, coding (e.g., Python, R, SQL), querying databases or statistical analysis, or a PhD degree', '5 years of work experience using analytics to solve product or business problems, coding (e.g., Python, R, SQL), querying databases or statistical analysis, or a PhD degree', 'Experience and strong interest in understanding, measuring, and improving end user experience', 'Experience in constrained optimization theory', 'Knowledge of Ads systems, including auction, serving, and ads quality']","['Your analytical excellence and statistical methods will be essential in mining through data to identify opportunities for Google and its clients to operate more efficiently', 'This includes enhancing advertising efficacy, optimizing network infrastructure, and studying user behavior', ""In this role, you will not only analyze data but also collaborate with Engineers, Product Managers, Sales Associates, and Marketing teams to adjust Google's practices based on your findings"", 'Identifying problems is just the beginning; you will also be responsible for devising solutions', ""You will evaluate and improve Google's products, working alongside a multi-disciplinary team of engineers and analysts on a wide range of challenges"", 'This position requires a scientific approach and statistical methods to tackle product creation, development, and improvement while considering the behaviors of end users', 'Manage bidding optimization to ensure exceptional advertiser experiences, while contributing to business growth', 'Align retrieval scores with auctions to maximize the total desired spend across all advertisers and ensure YouTube advertisers see immediate benefits from investments', 'Own the process of gathering, extracting, and compiling data across sources via relevant tools (e.g., SQL, R, Python)', 'Independently format, re-structure, and/or validate data to ensure quality, and review the dataset to ensure it is ready for analysis', 'Use custom data infrastructure or existing data models as appropriate, using specialized knowledge', 'Design and evaluate models to mathematically express and solve defined problems with limited precedent', 'Collaborate with cross-functional stakeholders to identify and clarify business or product questions to answer', 'Provide feedback to translate and refine business questions into tractable analysis, evaluation metrics, or mathematical models']",True,[],,"['Statistical Methods', 'Bidding Optimization', 'Data Extraction and Compilation', 'Data Validation and Formatting', 'Custom Data Infrastructure and Data Models', 'Mathematical Modeling', 'Cross-functional Collaboration', 'SQL', 'Python', 'R', 'Constrained Optimization Theory', 'Ads Systems Knowledge']","Statistical Methods: Used to analyze data, identify opportunities, and tackle product creation, development, and improvement while considering end user behaviors.; Bidding Optimization: Managing bidding processes to ensure exceptional advertiser experiences and contribute to business growth.; Data Extraction and Compilation: Gathering, extracting, and compiling data across sources using tools such as SQL, R, and Python.; Data Validation and Formatting: Independently formatting, restructuring, and validating data to ensure quality and readiness for analysis.; Custom Data Infrastructure and Data Models: Using specialized knowledge to apply custom or existing data models and infrastructure for analysis.; Mathematical Modeling: Designing and evaluating models to mathematically express and solve defined problems with limited precedent.; Cross-functional Collaboration: Working with engineers, product managers, sales associates, and marketing teams to adjust practices based on data findings and clarify business or product questions.; SQL: Used for querying databases as part of data extraction and analysis.; Python: Used for coding, data extraction, and analysis tasks.; R: Used for coding, statistical analysis, and data extraction.; Constrained Optimization Theory: Applied knowledge in optimization theory relevant to improving advertiser experiences and business outcomes.; Ads Systems Knowledge: Understanding of auction, serving, and ads quality systems relevant to advertiser optimization."
wAr7PaXYId54vgswAAAAAA==,Senior Data Scientist,"Senior Data Scientist

Virta Health is pioneering a new standard of care for people to reclaim their lives. We are in the midst of a public health crisis: obesity rates are at an all-time high and over half of US adults have type 2 diabetes or prediabetes, and despite billions spent on new treatments, outcomes are largely worse. Virta reverses these diseases and delivers life-changing results by pairing individualized nutrition with ongoing care from a clinical support team. We have raised over $350 million from top-tier investors, and partner with the largest health plans, employers, and government organizations to help their employees and members restore their health and take back their lives.

Role Overview

The Advanced Analytics & AI (AAA) team is accountable for both pioneering new classes of data that power our business, and ensuring that data is powerful, clear, correct and easy to use throughout the company. The team collaborates closely with the engineering, product development, commercial, and clinical teams to transform data into actionable insights that propel Virta's mission forward.

As a Senior Data Scientist on the AAA team, you will play a crucial role in shaping our data-driven decision making processes and in driving impactful insights that advance our mission. This role offers a unique blend of hands-on coding and strategic leadership, working closely in partnership with the Product Development group that supports adoption of our member-facing products. You will get a chance to work closely with stakeholders to create impactful data-driven reports and analyses that strengthen Virta’s value proposition.

Responsibilities
• Serve as data lead for the Adoption Squad:
• Understand the product – strategy, goals, roadmap, users – deeply enough to identify high-impact, strategic opportunities and risks.
• Use data to steer conversations: bring data-driven hypotheses, challenge assumptions, frame trade-offs, prioritize strategically.
• Translate vague product hunches into sharp analytical questions, and design the right approach to answer them.
• Be the source of truth for KPIs and product metrics: help define and monitor them, and identify trends and drivers.
• Drive decision making with data: Prioritize analyses that meaningfully inform product decisions and change outcomes, reframe analysis requests that won’t do that into ones that will, and design and deliver the resulting analyses properly and rapidly.
• Lead experimentation thoughtfully: guide the team on when and when not to experiment, help enable self-serve experimentation, and focus on frequent, small experiments to speed learning.
• Identify where product strategy and ideas could be better, more easily, or more quickly implemented with the help of AI (ML or GenAI), and help enable this integration.
• Show up as a collaborative leader, not simply a service provider, and help focus work on what matters most.
• Work end-to-end to translate clinical, member, and claims data from our data warehouse into actionable recommendations: work with stakeholders to design reports and dashboards that answer real business questions, design the data flows to support these, and build the required data transformation pipelines.

Must-Haves
• Experience working at a digital health or similar startup, preferably during the growth phase, in order to function effectively in a fast-paced, rapidly changing environment.
• 7+ years of experience in a Healthcare Analytics or Data Science role, working with large datasets and conducting statistical and quantitative modeling, melding analytics with strong programming, data mining, clustering and segmentation.
• 5+ years of work experience working data science and visualization tools (SQL, R, and/or Python)
• Advanced understanding of data storage, ETL frameworks, data transformation, and validation
• Experience in building BI dashboards using tools such as Looker or Tableau
• Ability to explain technology, techniques and approaches to others

Nice-to-Haves
• Experience leading cross-functional efforts to build scalable systems and data pipelines, working with complex data structures
• Understanding of Generative AI concepts and basic usage of GenAI tools (ChatGPT, Claude, etc.)
• Experience building pipelines using dbt
• Demonstrated project management experience

90 Day Plan

Within your first 90 days at Virta, we expect you will do the following:
• Familiarize yourself with the Advanced Analytics & AI team roles and responsibilities. Get a pulse on team structure, key stakeholders, and areas for opportunity with an eye towards scalability and standardization.
• Integrate with the Adoption Squad to understand team dynamics, analyze key product features and data pipelines, and familiarize yourself with the Squad’s product roadmap
• Analyze current member journey to understand Virta’s technology ecosystem
• Meet cross-functional stakeholders to understand how their business needs align with Squad and Team goals
• Identify at least 1 area of opportunity to leverage GenAI to increase team efficiency or improve our processes
• Teach and inspire your team members through knowledge sharing, pair programming, and giving feedback during code reviews

Values-driven culture

Virta’s company values drive our culture, so you’ll do well if:
• You put people first and take care of yourself, your peers, and our patients equally
• You have a strong sense of ownership and take initiative while empowering others to do the same
• You prioritize positive impact over busy work
• You have no ego and understand that everyone has something to bring to the table regardless of experience
• You appreciate transparency and promote trust and empowerment through open access of information
• You are evidence-based and prioritize data and science over seniority or dogma
• You take risks and rapidly iterate

Is this role not quite what you're looking for? Join our Talent Community and follow us on Linkedin to stay connected!

Virta has a location based compensation structure. Starting pay will be based on a number of factors and commensurate with qualifications & experience. For this role, the compensation range is $167,249 - $216,000. Information about Virta’s benefits is on our Careers page at: https://www.virtahealth.com/careers.

As part of your duties at Virta, you may come in contact with sensitive patient information that is governed by HIPAA. Throughout your career at Virta, you will be expected to follow Virta's security and privacy procedures to ensure our patients' information remains strictly confidential. Security and privacy training will be provided.

As a remote-first company, our team is spread across various locations with office hubs in Denver and San Francisco.
Clinical roles: We currently do not hire in the following states: AK, HI, RI
Corporate roles: We currently do not hire in the following states: AK, AR, DE, HI, ME, MS, NM, OK, SD, VT, WI.

#LI-remote",2025-07-21T00:00:00.000Z,2025-07-25,"['Experience working at a digital health or similar startup, preferably during the growth phase, in order to function effectively in a fast-paced, rapidly changing environment', '7+ years of experience in a Healthcare Analytics or Data Science role, working with large datasets and conducting statistical and quantitative modeling, melding analytics with strong programming, data mining, clustering and segmentation', '5+ years of work experience working data science and visualization tools (SQL, R, and/or Python)', 'Advanced understanding of data storage, ETL frameworks, data transformation, and validation', 'Experience in building BI dashboards using tools such as Looker or Tableau', 'Ability to explain technology, techniques and approaches to others', 'Experience leading cross-functional efforts to build scalable systems and data pipelines, working with complex data structures', 'Understanding of Generative AI concepts and basic usage of GenAI tools (ChatGPT, Claude, etc.)', 'Experience building pipelines using dbt', 'Demonstrated project management experience', 'You have a strong sense of ownership and take initiative while empowering others to do the same', 'You prioritize positive impact over busy work', 'You have no ego and understand that everyone has something to bring to the table regardless of experience', 'You appreciate transparency and promote trust and empowerment through open access of information', 'You are evidence-based and prioritize data and science over seniority or dogma', 'You take risks and rapidly iterate']","['As a Senior Data Scientist on the AAA team, you will play a crucial role in shaping our data-driven decision making processes and in driving impactful insights that advance our mission', 'You will get a chance to work closely with stakeholders to create impactful data-driven reports and analyses that strengthen Virta’s value proposition', 'Serve as data lead for the Adoption Squad:', 'Understand the product – strategy, goals, roadmap, users – deeply enough to identify high-impact, strategic opportunities and risks', 'Use data to steer conversations: bring data-driven hypotheses, challenge assumptions, frame trade-offs, prioritize strategically', 'Translate vague product hunches into sharp analytical questions, and design the right approach to answer them', 'Be the source of truth for KPIs and product metrics: help define and monitor them, and identify trends and drivers', 'Drive decision making with data: Prioritize analyses that meaningfully inform product decisions and change outcomes, reframe analysis requests that won’t do that into ones that will, and design and deliver the resulting analyses properly and rapidly', 'Lead experimentation thoughtfully: guide the team on when and when not to experiment, help enable self-serve experimentation, and focus on frequent, small experiments to speed learning', 'Identify where product strategy and ideas could be better, more easily, or more quickly implemented with the help of AI (ML or GenAI), and help enable this integration', 'Show up as a collaborative leader, not simply a service provider, and help focus work on what matters most', 'Work end-to-end to translate clinical, member, and claims data from our data warehouse into actionable recommendations: work with stakeholders to design reports and dashboards that answer real business questions, design the data flows to support these, and build the required data transformation pipelines', 'Familiarize yourself with the Advanced Analytics & AI team roles and responsibilities', 'Get a pulse on team structure, key stakeholders, and areas for opportunity with an eye towards scalability and standardization', 'Integrate with the Adoption Squad to understand team dynamics, analyze key product features and data pipelines, and familiarize yourself with the Squad’s product roadmap', 'Analyze current member journey to understand Virta’s technology ecosystem', 'Meet cross-functional stakeholders to understand how their business needs align with Squad and Team goals', 'Identify at least 1 area of opportunity to leverage GenAI to increase team efficiency or improve our processes', 'Teach and inspire your team members through knowledge sharing, pair programming, and giving feedback during code reviews']",True,['Generative AI'],"Generative AI: Recognized as a potential tool to improve team efficiency and processes, with basic usage of GenAI tools like ChatGPT and Claude mentioned for integration into product strategy.","['Statistical and Quantitative Modeling', 'SQL', 'R', 'Python', 'ETL Frameworks', 'Data Transformation and Validation', 'BI Dashboards (Looker, Tableau)', 'Data Pipelines', 'Data-Driven Experimentation', 'Feature Engineering', 'Data Mining, Clustering, and Segmentation', 'dbt (Data Build Tool)']","Statistical and Quantitative Modeling: Used to analyze large healthcare datasets and conduct data mining, clustering, and segmentation to derive insights relevant to healthcare analytics.; SQL: Employed for querying and managing data within the company's data warehouse to support data transformation and analysis.; R: Utilized as a data science tool for statistical analysis and visualization in healthcare analytics.; Python: Used for programming, data analysis, and building data transformation pipelines to support data-driven decision making.; ETL Frameworks: Applied to extract, transform, and load clinical, member, and claims data from the data warehouse into usable formats for analysis and reporting.; Data Transformation and Validation: Involves designing and building data flows and pipelines to ensure data quality and readiness for analysis and reporting.; BI Dashboards (Looker, Tableau): Used to build interactive dashboards and reports that answer real business questions and monitor KPIs and product metrics.; Data Pipelines: Built and maintained to support scalable systems and complex data structures, enabling end-to-end data processing and actionable recommendations.; Data-Driven Experimentation: Leading and enabling frequent, small experiments to speed learning and inform product decisions through data analysis.; Feature Engineering: Implied through the process of translating vague product hunches into sharp analytical questions and designing approaches to answer them.; Data Mining, Clustering, and Segmentation: Used to analyze healthcare data for identifying patterns and grouping similar data points to support strategic decision making.; dbt (Data Build Tool): Used for building data transformation pipelines to support scalable and maintainable data workflows."
fC1QkJ4uJ6xxBy5dAAAAAA==,Data Science & Analytics,"At Blocksi, We Are Always Looking for New Talent

As we strive to enhance student safety and foster a secure global digital school environment, we are actively seeking driven and dedicated team players to collaborate in shaping the future of
school safety with us.

Ready for a career dive into the booming EdTech industry?

Data Science & Analytics

Key player in transforming raw data into valuable business insights, aiding data-driven decision-making. Optimize AI solutions for scalability and manage big data tools and frameworks.

Don’t see an open position? We are always looking for enthusiastic individuals to join our team, so we encourage you to submit your application

Make sure to include your resume and cover letter.",,2025-07-25,['Optimize AI solutions for scalability and manage big data tools and frameworks'],"['Key player in transforming raw data into valuable business insights, aiding data-driven decision-making']",True,['AI Solution Optimization'],AI Solution Optimization: Optimizing AI solutions for scalability to ensure efficient and effective deployment in production environments.,"['Data Analytics', 'Big Data Tools and Frameworks']",Data Analytics: Transforming raw data into valuable business insights to support data-driven decision-making.; Big Data Tools and Frameworks: Managing big data tools and frameworks to handle large-scale data processing and analysis.
cNQzFnQ5KGZiafZLAAAAAA==,"Data Scientist, Special Operations Command (Active Secret) Jobs","Rhombus Power is purposefully transforming defense and global security enterprises with Guardian, our Artificial Intelligence platform for strategic, operational, and tactical decision-making at the speed of relevance.

We provide relevant, actionable, and AI-powered insights at each step in the defense decision-making cycle. Equipped with Guardian's AI-powered tools-- from infrastructure to data to insights -- our clients are able to solve their most complex, interconnected challenges and achieve decision and operational superiority.

Come join our cross-disciplinary and world-class team that is delivering game-changing solutions to transform global security.

Learn more about Rhombus and watch a demonstration of Guardian, our AI Platform here -- https://youtube.com/watch?v=3PxY6su1Q-Q

See the following articles to learn more about what we do:

https://foreignpolicy.com/2023/06/19/ai-artificial-intelligence-national-security-foreign-policy-threats-prediction/

https://federalnewsnetwork.com/air-force/2023/12/new-decision-advantage-tool-will-change-how-air-force-makes-investment-decisions/

https://apnews.com/article/us-intelligence-services-ai-models-9471e8c5703306eb29f6c971b6923187

Job description:

As a Data Scientist at Rhombus you will work with our Product team. You will design, develop, and launch efficient and reliable data pipelines to move, analyze, and model data and to provide intuitive analytics from Rhombus’ large and complex datasets. A strong systematic mind is a priority, as well as the ability to communicate clearly in multiple technical contexts.

The ideal candidate should be passionate about finding insights in large datasets, while maintaining attention to database architecture, data reliability, efficiency, and quality. As we are continually releasing new features and products, the ability to construct elegant system-level data architecture is expected.

You will acquire, manipulate, and transform data to breathe life and meaning into arcane holdings, and use your creations to open new doors and opportunities to the customer. An innovative and inquisitive mind is required for success.

Responsibilities:

-Discover datasets that could help in solution development

-Data curation, data evaluation, and data analysis

-Design, create, and implement quantitative models

-Validation and quality assurance of data, models and results

-Deploy and implement solutions in collaboration with product team

-Interact with the product team on current and upcoming user requirements

-Responsiveness to customer feedback delivered by product team and responsiveness to customer timelines

-Systems-level approach to implementation to integrate solutions as part of a larger, interconnected project

Qualifications:

-Active Secret clearance

-A strong academic background in Statistics, Mathematics, Engineering, or similar degree is highly desired. -We prefer candidates to hold at minimum a Masters degree. We have multiple openings!

-Exceptional academic and industry experience with Python and especially with data handling libraries such as Pandas and PyArrow

-Strong background in database management solutions, familiarity with databases such as MySQL and Oracle

-Large-scale data processing and implementing batch processing pipelines in HPC or cloud architecture

-Experience with Cloud Computing environments (AWS, GCloud, Azure) is a plus

Location:

Palo Alto, CA; St. Louis, MO; Tampa, FL; San Antonio, TX; Colorado Springs, CO; Omaha, NE; Washington, D.C.

Benefits:

-Full medical, dental, vision coverage for employee and dependents

-401k matching program

-PTO and Holidays

-Bonus and other incentive programs

-Access to mental health program

-Access to Flexible Spending Accounts for Health Care, Dependent and Commuter

About Rhombus:

Rhombus Power Inc. (Rhombus) is a startup located in the heart of Silicon Valley at Stanford Research Park in Palo Alto.  We use cutting-edge cross-disciplinary approaches to solve pressing Big Data and Sensing problems in security, energy, and healthcare. Our advisory board includes two Nobel Laureates and a Draper Prize winner.

Rhombus compensates, motivates, and develops employees, who are trusted, empowered, and involved. Employees have clear roles and expectations – and their roles are flexible enough to move at the speed of innovation in order to meet and exceed client expectations. We have a unique culture of global purpose, rooted in the innovation and progress of Silicon Valley.

Rhombus knows that diversity is a condition for success. We are committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer.",2025-07-17T00:00:00.000Z,2025-07-25,"['A strong systematic mind is a priority, as well as the ability to communicate clearly in multiple technical contexts', 'The ideal candidate should be passionate about finding insights in large datasets, while maintaining attention to database architecture, data reliability, efficiency, and quality', 'An innovative and inquisitive mind is required for success', 'Active Secret clearance', 'We prefer candidates to hold at minimum a Masters degree', 'Exceptional academic and industry experience with Python and especially with data handling libraries such as Pandas and PyArrow', 'Strong background in database management solutions, familiarity with databases such as MySQL and Oracle', 'Large-scale data processing and implementing batch processing pipelines in HPC or cloud architecture']","['As a Data Scientist at Rhombus you will work with our Product team', 'You will design, develop, and launch efficient and reliable data pipelines to move, analyze, and model data and to provide intuitive analytics from Rhombus’ large and complex datasets', 'As we are continually releasing new features and products, the ability to construct elegant system-level data architecture is expected', 'You will acquire, manipulate, and transform data to breathe life and meaning into arcane holdings, and use your creations to open new doors and opportunities to the customer', 'Discover datasets that could help in solution development', 'Data curation, data evaluation, and data analysis', 'Design, create, and implement quantitative models', 'Validation and quality assurance of data, models and results', 'Deploy and implement solutions in collaboration with product team', 'Interact with the product team on current and upcoming user requirements', 'Responsiveness to customer feedback delivered by product team and responsiveness to customer timelines', 'Systems-level approach to implementation to integrate solutions as part of a larger, interconnected project']",True,[],,"['Data Pipelines', 'Data Analysis', 'Quantitative Models', 'Data Validation and Quality Assurance', 'Python Data Libraries', 'Database Management', 'Large-Scale Data Processing', 'Cloud Computing Environments']","Data Pipelines: Design, develop, and launch efficient and reliable data pipelines to move, analyze, and model data from large and complex datasets.; Data Analysis: Perform data curation, data evaluation, and data analysis to discover insights and support solution development.; Quantitative Models: Design, create, and implement quantitative models to analyze data and provide actionable insights.; Data Validation and Quality Assurance: Validate and ensure quality of data, models, and results to maintain reliability and accuracy.; Python Data Libraries: Use Python with data handling libraries such as Pandas and PyArrow for data manipulation and processing.; Database Management: Maintain strong background in database management solutions, including familiarity with MySQL and Oracle databases.; Large-Scale Data Processing: Implement batch processing pipelines for large-scale data processing in HPC or cloud architectures.; Cloud Computing Environments: Experience with cloud computing platforms such as AWS, Google Cloud, and Azure is considered a plus."
fZCgCsjP2DX7ZTUXAAAAAA==,"Sr Data Scientist in Ridgefield, CT","Hi,

Hope you are doing great.

Please go through the job description given below and if you are interested do share an updated word copy of your resume and best time to reach you over the phone.

Position: Sr Data Scientist

Locations: Ridgefield, CT

Duration: Contract

Job Description:
• Sr Data Scientist with overall 10-15 years of IT experience out of which two or more years of hands-on experience designing and deploying GenAI solutions.
• 3+ years of experience in coding Python, R and Shiny
• Develop roadmap and strategy for NLP, LLM, Gen AI model development and lifecycle implementation
• Experience in Pharmaceuticals/Life sciences is preferred",,2025-07-25,"['Sr Data Scientist with overall 10-15 years of IT experience out of which two or more years of hands-on experience designing and deploying GenAI solutions', '3+ years of experience in coding Python, R and Shiny', 'Develop roadmap and strategy for NLP, LLM, Gen AI model development and lifecycle implementation']",,True,"['Generative AI', 'Natural Language Processing', 'Large Language Models']","Generative AI: The role involves hands-on experience designing and deploying generative AI solutions, indicating development and implementation of AI models that generate content or data.; Natural Language Processing: The job requires developing roadmaps and strategies for NLP, focusing on processing and understanding human language as part of AI model development.; Large Language Models: Involves strategy and lifecycle implementation for LLMs, indicating work with advanced AI models that understand and generate human-like text.","['Python', 'R', 'Shiny']","Python: Used for coding and development in data science tasks as part of the job requirements.; R: Used for coding and development in data science tasks as part of the job requirements.; Shiny: Used for building interactive web applications in R, supporting data visualization and analytics."
TJmvQbs8fjvZtjc3AAAAAA==,Data Science Director,"Summary:

We’re looking for a seasoned analytics leader to drive data-informed decisions for Meta. You will play a critical role in helping Meta build the platforms of the future. You will partner with the product and business teams that build and grow our infrastructure for the future of Meta. You will be focused on results, be proactive, deliver rigorous analyses, and use data to drive change in products, strategies, and organizations.About the role:People leadership: You will inspire, lead and grow a world-class team.Product leadership: You will use data to shape development, quantify new opportunities, identify upcoming challenges, and ensure the products we build bring value to people, businesses, and Meta. You will help your partner teams prioritize what to build, set goals, and understand their product’s ecosystem.Analytics: You will guide teams using data and insights. You will focus on developing hypotheses and employ a broad toolkit of rigorous analytical approaches, different methodologies, frameworks, and technical approaches to test them.Communication and influence: You won’t simply present data, but tell data-driven stories. You will convince and influence your partners using clear insights and recommendations. You will build credibility through structure and clarity, and be a trusted strategic partner.

Required Skills:

Data Science Director Responsibilities:
• Inspire, lead and grow a distributed team of data scientists and data science leaders across North America
• Apply your expertise in quantitative analysis, data mining, and the presentation of data in developing data-informed strategies for growing and improving our product offerings.
• Contribute to long-term technical vision and strategy methods and metrics that will improve the quality and efficiency of our products at scale.
• Lead development and communication of product area insights and recommended action items with Meta Analytics leadership.

Minimum Qualifications:

Minimum Qualifications:
• 10+ years of work experience managing analytics teams, working collaboratively with Product and Infrastructure teams, and guiding data-influenced product and business planning, prioritization and strategy development.
• Demonstrated experience in hiring, retaining and scaling geographically dispersed, high-performing teams with a broad range of experiences, perspectives, approaches, and backgrounds
• Proven experience influencing strategy and driving change across org boundaries through clear and compelling communication of data-driven insights and analyses.
• Intellectual curiosity, drive, and decisiveness with ambiguous and complex enviornments.
• Experience working effectively with multiple stakeholders and cross-functionally.
• Effective communication skills.

Preferred Qualifications:

Preferred Qualifications:
• Experience with both product and business analytics work and demonstrated to deliver an integrated approach.

Public Compensation:

$253,000/year to $314,000/year + bonus + equity + benefits

Industry: Internet

Equal Opportunity:

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.",2025-07-02T00:00:00.000Z,2025-07-25,"['10+ years of work experience managing analytics teams, working collaboratively with Product and Infrastructure teams, and guiding data-influenced product and business planning, prioritization and strategy development', 'Demonstrated experience in hiring, retaining and scaling geographically dispersed, high-performing teams with a broad range of experiences, perspectives, approaches, and backgrounds', 'Proven experience influencing strategy and driving change across org boundaries through clear and compelling communication of data-driven insights and analyses', 'Intellectual curiosity, drive, and decisiveness with ambiguous and complex enviornments', 'Experience working effectively with multiple stakeholders and cross-functionally', 'Effective communication skills', 'Meta participates in the E-Verify program in certain locations, as required by law']","['You will play a critical role in helping Meta build the platforms of the future', 'You will partner with the product and business teams that build and grow our infrastructure for the future of Meta', 'You will be focused on results, be proactive, deliver rigorous analyses, and use data to drive change in products, strategies, and organizations', 'Product leadership: You will use data to shape development, quantify new opportunities, identify upcoming challenges, and ensure the products we build bring value to people, businesses, and Meta', 'You will help your partner teams prioritize what to build, set goals, and understand their product’s ecosystem.Analytics: You will guide teams using data and insights', 'You will focus on developing hypotheses and employ a broad toolkit of rigorous analytical approaches, different methodologies, frameworks, and technical approaches to test them', 'Communication and influence: You won’t simply present data, but tell data-driven stories', 'You will convince and influence your partners using clear insights and recommendations', 'You will build credibility through structure and clarity, and be a trusted strategic partner', 'Inspire, lead and grow a distributed team of data scientists and data science leaders across North America', 'Apply your expertise in quantitative analysis, data mining, and the presentation of data in developing data-informed strategies for growing and improving our product offerings', 'Contribute to long-term technical vision and strategy methods and metrics that will improve the quality and efficiency of our products at scale', 'Lead development and communication of product area insights and recommended action items with Meta Analytics leadership']",True,[],,"['Quantitative Analysis', 'Data Mining', 'Data-Driven Storytelling', 'Hypothesis Development and Testing', 'Product and Business Analytics', 'Team Leadership in Data Science']","Quantitative Analysis: Used to develop data-informed strategies for growing and improving product offerings by applying rigorous numerical and statistical methods.; Data Mining: Applied to extract useful patterns and insights from large datasets to inform product and business decisions.; Data-Driven Storytelling: Involves presenting data insights in a compelling narrative form to influence partners and drive strategic decisions.; Hypothesis Development and Testing: Focuses on formulating hypotheses and employing a broad toolkit of analytical methodologies and frameworks to rigorously test them.; Product and Business Analytics: Used to shape product development, quantify new opportunities, identify challenges, and ensure products deliver value to users and the business.; Team Leadership in Data Science: Involves inspiring, leading, and growing distributed teams of data scientists and leaders to drive analytics initiatives and data-informed decision-making."
uodVhdEIF9g9sV9JAAAAAA==,Data Scientist,"Haystack News is the leading local & world news service on Connected TVs reaching millions of users! This is a unique opportunity to work at Haystack News, one of the fastest-growing TV startups in the world. We are already preloaded on 37% of all TVs shipped in the US!

Be part of a Silicon Valley startup and work directly with the founding team. Jumpstart your career by working with Stanford & Carnegie Mellon alumni and faculty who have already been part of other successful startups in Silicon Valley.

You should join us if you're hungry to learn how Silicon Valley startups thrive, you like to ship quickly and often, love to solve challenging problems, and like working in small teams.

See Haystack feature at Google IO: https://www.youtube.com/watch?v=-YawUi6qPck

Job functions

We are looking for an outstanding Data Scientist to join Haystack and help improve the experience of millions of users that rely on Haystack to get the news every day.

Within the team you’ll find many opportunities to work on various aspects of Data Science, Machine Learning, and Data Engineering. The job offers the opportunity of generating a major impact on the product while working with an awesome and talented team, using the latest technologies.

You will:
• Analyze large data sets to get insights using statistical analysis tools and techniques
• Build, evaluate and deploy machine learning models
• Maintain ongoing reliability, performance, and support of the data infrastructure, providing solutions based on application needs and anticipated growth.
• Work with tools to configure, monitor and orchestrate data infrastructure and pipelines.
• Run and monitor AB Tests
• Build and manage APIs

Qualifications and requirements
• Bachelor's degree in Computer Science, Statistics, Math or related field.
• 3+ years experience writing software in a professional setting
• Knowledge of AWS and Python
• Strong Math/Stats background with statistical analysis experience on big data sets
• Experience with SQL and NoSQL (e.g. MongoDb or DynamoDB)
• Big Plus: Experience with data warehouses (e.g. Snowflake, Big Query, Redshift)
• Exposure to ML/AI libraries such as sklearn, LightGBM and, XGBoost.
• Travel Visa to the US (desired)

Conditions
• Uber rides to come to the office!
• Travel to team's offsite events
• Learn about multiple technologies",,2025-07-25,"[""Bachelor's degree in Computer Science, Statistics, Math or related field"", '3+ years experience writing software in a professional setting', 'Knowledge of AWS and Python', 'Strong Math/Stats background with statistical analysis experience on big data sets', 'Experience with SQL and NoSQL (e.g. MongoDb or DynamoDB)', 'Big Plus: Experience with data warehouses (e.g. Snowflake, Big Query, Redshift)', 'Exposure to ML/AI libraries such as sklearn, LightGBM and, XGBoost']","['We are looking for an outstanding Data Scientist to join Haystack and help improve the experience of millions of users that rely on Haystack to get the news every day', 'Analyze large data sets to get insights using statistical analysis tools and techniques', 'Build, evaluate and deploy machine learning models', 'Maintain ongoing reliability, performance, and support of the data infrastructure, providing solutions based on application needs and anticipated growth', 'Work with tools to configure, monitor and orchestrate data infrastructure and pipelines', 'Run and monitor AB Tests', 'Build and manage APIs', ""Travel to team's offsite events""]",True,[],,"['Statistical Analysis', 'Machine Learning Models', 'A/B Testing', 'Data Infrastructure and Pipelines', 'SQL and NoSQL Databases', 'Data Warehouses', 'Python Programming', 'Machine Learning Libraries']","Statistical Analysis: Used to analyze large data sets to extract insights and support decision-making in the product context.; Machine Learning Models: Building, evaluating, and deploying models to improve user experience and product performance.; A/B Testing: Running and monitoring experiments to evaluate the impact of changes and optimize product features.; Data Infrastructure and Pipelines: Maintaining, configuring, monitoring, and orchestrating data infrastructure and pipelines to ensure reliability and scalability based on application needs and growth.; SQL and NoSQL Databases: Utilizing SQL and NoSQL databases such as MongoDB or DynamoDB for data storage and retrieval.; Data Warehouses: Experience with data warehouses like Snowflake, BigQuery, and Redshift to manage large-scale data storage and analytics.; Python Programming: Using Python as a primary programming language for data analysis, model development, and infrastructure tasks.; Machine Learning Libraries: Exposure to libraries such as scikit-learn, LightGBM, and XGBoost for implementing machine learning algorithms."
lNUvseFlY2wc0alQAAAAAA==,Imaging Data Scientist,"Overview

Frontier Technology Inc. (FTI) is seeking an experienced Data Scientist with a background in imaging science to support existing contracts in our Beverly, MA office. FTI’s Data, Cyber and Integrated Services (DCIS) group provides software development, data science, cyber security, and systems engineering support to FTI through a matrixed organization. The Image Science team based in Beverly, MA provides science and software development services to space-based electro-optical infrared (EOIR) sensor programs. Machine learning, AI-augmented decision support, and space wargaming are all directions of company growth, and experience or interest in these areas are desired. We have extensive experience in systems engineering, sensor requirements definition, sensor design, sensor calibration, data analysis, radiometric performance validation, physics-based and phenomenological simulation tools, and data management. Apply knowledge of statistics, machine learning, programming, data modeling, simulation, and advanced mathematics to recognize patterns, identify opportunities, pose business questions, and make valuable discoveries leading to prototype development and product improvement.

Responsibilities
• Develop algorithms associated with image processing, sensor calibration, data simulation and modeling, and software automation.
• Perform analysis of sensor data, simulated systems and algorithms.
• Work with other scientists on the team collaboratively to complete algorithm development or analysis tasks.
• Interface with software developers on the team to define software requirements and guide software implementation.
• Interface with customers to brief work and define tasking.
• Use a flexible, analytical approach to design, develop, and evaluate predictive models and advanced algorithms that lead to optimal value extraction from the data.

Education/Qualifications
• Must be a U.S. Citizen and currently have a TS clearance that will require an SCI upgrade. Current TS/SCI is preferred.
• Bachelor's or Master’s degree in Computer Science, Statistics, Mathematics, Data Science, Engineering, Astronomy, Physics, or a related technical field. Prefer PhD.
• Practical knowledge of telescopes, optical systems, and focal plane arrays, including observation planning or mission design.
• Strong technical background in astronomy or remote sensing.
• Experience with standard data analysis and reduction procedures.
• Strong foundation in mathematics. Experience with the application of statistical concepts and techniques to data preferred.
• Scientific programming competency in Python or Matlab.
• Excellent communication skills, with emphasis on the ability to communicate technical results to non-technical audiences (such as customers).
• Experience in statistical inference, machine learning for target detection and discrimination, or in AI-augmented decision support
• This position will require minimal travel and will be in our Beverly, MA office.

Optional Experience:
• Optical signatures modeling.
• Multi-scale modeling, first principles and phenomenological simulation of physical systems.
• Technical work on a sensor program.

#LI-GH1

#LI-Onsite",,2025-07-25,"['We have extensive experience in systems engineering, sensor requirements definition, sensor design, sensor calibration, data analysis, radiometric performance validation, physics-based and phenomenological simulation tools, and data management', 'Apply knowledge of statistics, machine learning, programming, data modeling, simulation, and advanced mathematics to recognize patterns, identify opportunities, pose business questions, and make valuable discoveries leading to prototype development and product improvement', 'Must be a U.S. Citizen and currently have a TS clearance that will require an SCI upgrade', 'Prefer PhD', 'Practical knowledge of telescopes, optical systems, and focal plane arrays, including observation planning or mission design', 'Strong technical background in astronomy or remote sensing', 'Experience with standard data analysis and reduction procedures', 'Strong foundation in mathematics', 'Optical signatures modeling', 'Multi-scale modeling, first principles and phenomenological simulation of physical systems', 'Technical work on a sensor program']","['Develop algorithms associated with image processing, sensor calibration, data simulation and modeling, and software automation', 'Perform analysis of sensor data, simulated systems and algorithms', 'Work with other scientists on the team collaboratively to complete algorithm development or analysis tasks', 'Interface with software developers on the team to define software requirements and guide software implementation', 'Interface with customers to brief work and define tasking', 'Use a flexible, analytical approach to design, develop, and evaluate predictive models and advanced algorithms that lead to optimal value extraction from the data']",True,['AI-augmented Decision Support'],AI-augmented Decision Support: Leverage AI techniques to enhance decision-making processes related to sensor data analysis and operational support.,"['Image Processing', 'Sensor Calibration', 'Data Simulation and Modeling', 'Statistical Inference', 'Machine Learning', 'Predictive Models and Advanced Algorithms', 'Data Analysis and Reduction Procedures', 'Programming in Python and Matlab', 'Data Modeling', 'Physics-based and Phenomenological Simulation Tools']","Image Processing: Develop algorithms related to processing images from sensors to extract meaningful information and improve data quality.; Sensor Calibration: Create and apply algorithms to calibrate sensors ensuring accurate and reliable data collection from imaging systems.; Data Simulation and Modeling: Develop and use simulation tools and models to replicate sensor data and physical systems for analysis and algorithm testing.; Statistical Inference: Apply statistical concepts and techniques to analyze sensor data and support decision-making processes.; Machine Learning: Use machine learning methods for target detection, discrimination, and predictive modeling to extract value from sensor data.; Predictive Models and Advanced Algorithms: Design, develop, and evaluate models and algorithms that predict outcomes and optimize data value extraction.; Data Analysis and Reduction Procedures: Perform standard data analysis and reduction techniques to process and interpret sensor and imaging data.; Programming in Python and Matlab: Utilize Python and Matlab programming languages for scientific computing, algorithm development, and data analysis.; Data Modeling: Apply data modeling techniques to represent and analyze sensor and imaging data effectively.; Physics-based and Phenomenological Simulation Tools: Use simulation tools based on physical principles and phenomenological models to support sensor data analysis and system understanding."
YLxEIPUAI7fhR_mYAAAAAA==,Senior AI Data Scientist,"General Information

Locations: Kirkland, Washington, United States of America
• Location: Los Angeles - Chatsworth
• Country: United States of America
• Location: Austin
• Country: United States of America
• Location: Vancouver
• Country: Canada
• Location: Toronto
• Country: Canada
• Location: Edmonton
• Country: Canada
• Location: Orlando
• Country: United States of America
• Location: Redwood City
• Country: United States of America

Role ID

209183

Worker Type

Regular Employee

Studio/Department

EA Studios - CAP Central

Work Model

Hybrid

Description & Requirements

Electronic Arts creates next-level entertainment experiences that inspire players and fans around the world. Here, everyone is part of the story. Part of a community that connects across the globe. A place where creativity thrives, new perspectives are invited, and ideas matter. A team where everyone makes play happen.

Empowering players to create is an exciting future for the gaming industry. At Electronic Arts we have many examples of players creating content, whether it be a skateboard park in Skate or fantastical mansions in the Sims 4. The future definitely has our players being more empowered to create with their imagination being the only limit.

We are looking for a Data Scientist to help shape the future of content creation and gameplay with AI. If you have the right expertise and are interested we want to hear from you!

As a Senior AI Data Scientist you will:
• Build, fine-tune and implement AI and machine learning models to solve challenging problems
• Ensure AI and machine learning production pipelines are scalable, repeatable and cloud agnostic
• Apply current and emerging techniques in deep learning, natural language processing and other machine learning areas
• Collect, clean, manage, analyze and visualize large sets of data using multiple data platforms, tools and technique
• Work in partnership with game teams to integrate AI solutions into products and services.
• Optimize and fine-tune AI models for performance and scalability. Analyze and interpret data to extract meaningful insights and improve AI models.
• Document and present findings and solutions to stakeholders.

Desired qualifications and experience:
• A minimum of 3+ years of experience in data science
• PhD or MSc in statistics, mathematics, computer science, or related field
• Strong expertise in deep learning, fluent in Python and SQL
• Expertise in automating machine learning models and building end to end products
• Experience with devops tools and principles (Git, CI/CD, Docker)
• Effective within Cloud environments (GCP, AWS)
• Understanding of containerization and orchestration technologies (Docker, Kubernetes, etc.)
• C++ and game development experience is a plus.

COMPENSATION AND BENEFITS

The ranges listed below are what EA in good faith expects to pay applicants for this role in these locations at the time of this posting. If you reside in a different location, a recruiter will advise on the applicable range and benefits. Pay offered will be determined based on a number of relevant business and candidate factors (e.g. education, qualifications, certifications, experience, skills, geographic location, or business needs).

PAY RANGES
• British Columbia (depending on location e.g. Vancouver vs. Victoria) * $96,400 - $133,900 CAD
• California (depending on location e.g. Los Angeles vs. Sacramento) * $122,300 - $170,600 USD
• Washington (depending on location e.g. Seattle vs. Spokane) * $104,000 - $174,700 USD

In the US, we offer a package of benefits including paid time off (3 weeks per year to start), 80 hours per year of sick time, 16 paid company holidays per year, 10 weeks paid time off to bond with baby, medical/dental/vision insurance, life insurance, disability insurance, and 401(k) to regular full-time employees. Certain roles may also be eligible for bonus and equity.

In British Columbia, we offer a package of benefits including vacation (3 weeks per year to start), 10 days per year of sick time, paid top-up to EI/QPIP benefits up to 100% of base salary when you welcome a new child (12 weeks for maternity, and 4 weeks for parental/adoption leave), extended health/dental/vision coverage, life insurance, disability insurance, retirement plan to regular full-time employees. Certain roles may also be eligible for bonus and equity.

About Electronic Arts

We’re proud to have an extensive portfolio of games and experiences, locations around the world, and opportunities across EA. We value adaptability, resilience, creativity, and curiosity. From leadership that brings out your potential, to creating space for learning and experimenting, we empower you to do great work and pursue opportunities for growth.

We adopt a holistic approach to our benefits programs, emphasizing physical, emotional, financial, career, and community wellness to support a balanced life. Our packages are tailored to meet local needs and may include healthcare coverage, mental well-being support, retirement savings, paid time off, family leaves, complimentary games, and more. We nurture environments where our teams can always bring their best to what they do.

Electronic Arts is an equal opportunity employer. All employment decisions are made without regard to race, color, national origin, ancestry, sex, gender, gender identity or expression, sexual orientation, age, genetic information, religion, disability, medical condition, pregnancy, marital status, family status, veteran status, or any other characteristic protected by law. We will also consider employment qualified applicants with criminal records in accordance with applicable law. EA also makes workplace accommodations for qualified individuals with disabilities as required by applicable law.",,2025-07-25,['California (depending on location e.g'],"['Build, fine-tune and implement AI and machine learning models to solve challenging problems', 'Ensure AI and machine learning production pipelines are scalable, repeatable and cloud agnostic', 'Apply current and emerging techniques in deep learning, natural language processing and other machine learning areas', 'Collect, clean, manage, analyze and visualize large sets of data using multiple data platforms, tools and technique', 'Work in partnership with game teams to integrate AI solutions into products and services', 'Optimize and fine-tune AI models for performance and scalability', 'Analyze and interpret data to extract meaningful insights and improve AI models', 'Document and present findings and solutions to stakeholders']",True,"['Deep Learning', 'Natural Language Processing', 'AI Model Fine-Tuning']",Deep Learning: Apply current and emerging deep learning techniques to develop AI models for gameplay and content creation.; Natural Language Processing: Utilize natural language processing methods as part of AI solutions integrated into gaming products and services.; AI Model Fine-Tuning: Optimize and fine-tune AI models for improved performance and scalability within production environments.,"['Machine Learning Models', 'Data Collection and Management', 'SQL', 'Python', 'Data Visualization', 'DevOps Tools and Principles', 'Cloud Environments', 'Containerization and Orchestration']","Machine Learning Models: Build, fine-tune, and implement machine learning models to solve challenging problems and improve AI models' performance and scalability.; Data Collection and Management: Collect, clean, manage, analyze, and visualize large datasets using multiple data platforms, tools, and techniques to extract meaningful insights.; SQL: Use SQL for data querying and management within cloud environments and data platforms.; Python: Utilize Python programming language for data science tasks including model development, data analysis, and automation of machine learning models.; Data Visualization: Visualize large sets of data to communicate insights and support decision-making processes.; DevOps Tools and Principles: Apply DevOps tools and principles such as Git, CI/CD pipelines, and Docker to automate machine learning model deployment and ensure scalable production pipelines.; Cloud Environments: Work effectively within cloud platforms like Google Cloud Platform (GCP) and Amazon Web Services (AWS) to deploy and manage data and machine learning workflows.; Containerization and Orchestration: Use containerization and orchestration technologies such as Docker and Kubernetes to support scalable and repeatable machine learning production pipelines."
-XlZLA8_bDy1vpVpAAAAAA==,Data Scientist II,"Overview

This position sits within our Product Development division, which develops, tests, and improves our software solutions in an innovative and collaborative environment.

ConstructConnect is looking for a full-time Data Scientist II.

The construction industry is ready for innovation. Metrics show an increase in buildings but a downturn in available labor. ConstructConnect is ready to fill this gap through a variety of artificial intelligence and machine learning approaches. Our opportunity to achieve this goal is vast and varied. We are leveraging natural language processing, object detection, image segmentation, and classifiers to name a few.

The ideal candidate for this role will have a deep interest in building models, developing training data, and researching the best algorithm to apply to a given situation. They will bring an energy for innovation and a desire to learn new techniques and tools. Come help us build the future of the pre-bid construction industry!

The Opportunity

As a Data Scientist II, you will play a crucial role in leveraging data-driven insights to guide strategic decision-making and drive business growth. You will engage in developing Machine Learning and AI solutions to complicated problems on the leading edge of construction planning technology. You will have the opportunity to design, develop and implement best-in-class solutions for our organization and our clients.

Responsibilities

What You’ll Be Doing
• Collaborate with cross-functional teams to define requirements, curate high-quality training datasets, and develop machine learning solutions for business challenges.
• Drive innovation by researching and experimenting with cutting-edge algorithms, architectures, and techniques.
• Optimize and fine-tune deep learning models to improve its performance, accuracy, and efficiency.
• Conduct thorough evaluations and assessments of models, providing recommendations for enhancements and optimizations.
• Contribute to the development of internal frameworks, and libraries to streamline ML workflows.
• Communicate research findings, insights, and recommendations effectively to both technical and non-technical stakeholders.
• Stay informed about industry trends, best practices, and emerging technologies in AI.
• Mentor and provide guidance to the team, sharing best practices.
• This job description in no way implies that the duties listed here are the only ones that team members can be required to perform

Qualifications

What Y ou Bring to the Team
• Creative problem-solver who is passionate about digging into complex problems and devising innovative approaches to reach results.
• Effective communication skills and experience distilling and presenting complex quantitative analysis into action-oriented recommendations.
• Proven experience as a Data Scientist, with a focus on computer vision, NLP, or predictive analytics.
• Solid understanding of deep learning architectures for computer vision and NLP.
• Knowledge of computer vision techniques, such as classification, object detection, and image segmentation.
• Familiarity with computer vision libraries and tools, such as OpenCV, scikit-image.
• Strong understanding of NLP methods and techniques, including text preprocessing, word embeddings, and language modeling.
• Proficiency in machine learning frameworks, such as TensorFlow, PyTorch , or scikit-learn.
• Strong programming skills in Python, with experience in data manipulation, analysis, and visualization using libraries such as Pandas, NumPy, and Matplotlib.
• Experience with cloud platforms, such as GCP, and deploying models to production environments is a plus.
• Bachelor's degree or equivalent experience in data science, Statistics, Computer Science, or a related field.

Physical Demands And Work Environment
• The physical activities of this position include frequent sitting, telephone communication, and working on a computer for extended periods. Visual acuity is required to perform activities close to the eyes.
• Team members are expected to maintain a dedicated and ergonomically appropriate remote workspace.
• Team members who live within commuting distance of one of our office locations (Greater Cincinnati/Northern Kentucky or Atlanta, Georgia) are expected to work in a hybrid capacity, with regular in-office presence as determined by the team or department.
• All team members must reside and perform their work within the United States. .

E-Verify Statement

ConstructConnect utilizes the E-Verify program with every potential new hire. This makes it possible for us to make certain that every employee who works for ConstructConnect is eligible to work in the United States. To learn more about E-Verify you can call 1-800-255-7688 or visit their website. E-Verify® is a registered trademark of the United States Department of Homeland Security.

Privacy Notice",2025-07-23T00:00:00.000Z,2025-07-25,"['Effective communication skills and experience distilling and presenting complex quantitative analysis into action-oriented recommendations', 'Proven experience as a Data Scientist, with a focus on computer vision, NLP, or predictive analytics', 'Solid understanding of deep learning architectures for computer vision and NLP', 'Knowledge of computer vision techniques, such as classification, object detection, and image segmentation', 'Familiarity with computer vision libraries and tools, such as OpenCV, scikit-image', 'Strong understanding of NLP methods and techniques, including text preprocessing, word embeddings, and language modeling', 'Proficiency in machine learning frameworks, such as TensorFlow, PyTorch , or scikit-learn', 'Strong programming skills in Python, with experience in data manipulation, analysis, and visualization using libraries such as Pandas, NumPy, and Matplotlib', ""Bachelor's degree or equivalent experience in data science, Statistics, Computer Science, or a related field"", 'Visual acuity is required to perform activities close to the eyes', 'Team members are expected to maintain a dedicated and ergonomically appropriate remote workspace', 'Team members who live within commuting distance of one of our office locations (Greater Cincinnati/Northern Kentucky or Atlanta, Georgia) are expected to work in a hybrid capacity, with regular in-office presence as determined by the team or department', 'All team members must reside and perform their work within the United States']","['The ideal candidate for this role will have a deep interest in building models, developing training data, and researching the best algorithm to apply to a given situation', 'They will bring an energy for innovation and a desire to learn new techniques and tools', 'As a Data Scientist II, you will play a crucial role in leveraging data-driven insights to guide strategic decision-making and drive business growth', 'You will engage in developing Machine Learning and AI solutions to complicated problems on the leading edge of construction planning technology', 'You will have the opportunity to design, develop and implement best-in-class solutions for our organization and our clients', 'Collaborate with cross-functional teams to define requirements, curate high-quality training datasets, and develop machine learning solutions for business challenges', 'Drive innovation by researching and experimenting with cutting-edge algorithms, architectures, and techniques', 'Optimize and fine-tune deep learning models to improve its performance, accuracy, and efficiency', 'Conduct thorough evaluations and assessments of models, providing recommendations for enhancements and optimizations', 'Contribute to the development of internal frameworks, and libraries to streamline ML workflows', 'Communicate research findings, insights, and recommendations effectively to both technical and non-technical stakeholders', 'Stay informed about industry trends, best practices, and emerging technologies in AI', 'Mentor and provide guidance to the team, sharing best practices', 'This job description in no way implies that the duties listed here are the only ones that team members can be required to perform', 'Creative problem-solver who is passionate about digging into complex problems and devising innovative approaches to reach results', 'The physical activities of this position include frequent sitting, telephone communication, and working on a computer for extended periods']",True,"['Deep Learning Frameworks', 'Natural Language Processing with Deep Learning', 'Computer Vision with Deep Learning']",Deep Learning Frameworks: Using TensorFlow and PyTorch specifically for developing and fine-tuning deep learning architectures in computer vision and NLP applications.; Natural Language Processing with Deep Learning: Applying deep learning-based NLP techniques such as language modeling and word embeddings to build AI solutions.; Computer Vision with Deep Learning: Leveraging deep learning architectures for advanced computer vision tasks including object detection and image segmentation.,"['Machine Learning', 'Deep Learning', 'Computer Vision', 'Natural Language Processing', 'Predictive Analytics', 'Training Data Development', 'Model Evaluation and Assessment', 'Data Manipulation and Analysis', 'Data Visualization', 'Python Programming', 'Machine Learning Frameworks', 'Computer Vision Libraries', 'Data Science']","Machine Learning: Developing machine learning solutions to address business challenges and drive strategic decision-making in construction planning technology.; Deep Learning: Optimizing and fine-tuning deep learning models to improve performance, accuracy, and efficiency, particularly for computer vision and NLP tasks.; Computer Vision: Applying computer vision techniques such as classification, object detection, and image segmentation to construction industry problems.; Natural Language Processing: Utilizing NLP methods including text preprocessing, word embeddings, and language modeling to build models and develop training data.; Predictive Analytics: Using predictive analytics to support data-driven insights and business growth.; Training Data Development: Curating high-quality training datasets to support machine learning and AI model development.; Model Evaluation and Assessment: Conducting thorough evaluations and assessments of models to provide recommendations for enhancements and optimizations.; Data Manipulation and Analysis: Using Python libraries such as Pandas and NumPy for data manipulation and analysis.; Data Visualization: Employing visualization tools like Matplotlib to present data insights effectively.; Python Programming: Strong programming skills in Python to support data manipulation, analysis, visualization, and model development.; Machine Learning Frameworks: Proficiency with frameworks such as scikit-learn, TensorFlow, and PyTorch for building and deploying machine learning models.; Computer Vision Libraries: Familiarity with libraries like OpenCV and scikit-image to implement computer vision techniques.; Data Science: Applying data science principles and statistical methods to solve complex problems in the construction industry."
mQpi1jdqC_qPbVz-AAAAAA==,"General / data scientist / research analyst - direct at US Department of the Air Force Agency Wide Eglin Air Force Base, FL","General / data scientist / research analyst - direct job at US Department of the Air Force Agency Wide. Eglin Air Force Base, FL.

Duties

For additional information on direct hire opportunities with the Air Force please click here .

Duties:
• Supervise government civilians within the Advanced Capabilities Flight.
• Oversee supervisory administrative aspects such as time off, travel, talent management and retention.
• Act as hiring manager for new employees and oversee on-boarding.
• Organize, train, and equip team of test engineers, scientists, aircrew, logisticians, and support personnel to accomplish flight test mission sets.
• Provide technical subject matter expertise where applicable to solve issues that arise during flight test.
• Communicate program status to squadron and group leadership. Provide early indications of concerns before they manifest as issues.
• Provide technical continuity for military and civilian workforce.

Requirements
Conditions of Employment
• U.S. Citizenship Required
• Telework may be authorized.
• If authorized, PCS will be paid IAW JTR and AF Regulations. If receiving an authorized PCS, you may be subject to completing/signing a CONUS agreement. More information on PCS requirements, may be found at:
• Security clearance requirements are based upon actual position being filled.
• Locations are not negotiable. The actual duty locations available may be located on the Air Force Civilian Service website.
• Random drug testing may be required depending upon the position being filled.
• Supervisory requirements may be required depending upon the position being filled.
• Promotion potential may be authorized depending upon position being filled.
• For additional information on direct hire opportunities with the Air Force please go to
• Full/part-time employees occupying direct childcare positions are eligible for discounts IAW DAF AFSVC/CC Memo, 30 Sep 22; first child 100% / each additional child 25%. Other assigned CYP and FCC personnel are eligible for 25% discount.
• A professional degree at the bachelor’s level from a department that administers at least one engineering degree currently accredited by the Accreditation Board of Engineering and Technology (ABET) is highly desired
• Possess a bachelor’s degree in a related technical discipline such as mathematics, computer science, one of the physical sciences or engineering.
• Work may occasionally require travel away from the normal duty station on military or commercial aircraft.
• The work requires the employee to obtain and maintain the appropriate security clearance.
• This is an acquisition position and is covered by the Acquisition Professional Development Program (APDP).
• Applicant must be capable of achieving the APDP certification.

Qualifications

For additional information on direct hire opportunities with the Air Force please click here .

In order to qualify, you must meet the specialized experience requirements described in the Office of Personnel Management (OPM) Qualification Standards for General Schedule Positions, Administrative and Management positions located here

SPECIALIZED EXPERIENCE: Applicants must have at least one (1) year of specialized experience at the next lower broadband NH-03 or equivalent to the next lower grade GS-12 thru GS-13 in the Federal Service.

Knowledge, Skills and Abilities
• Knowledge of a wide range of advanced multidisciplinary professional engineering/data science/computer science/research analysis concepts, principles, practices, standards, methods, and techniques to apply experimental theories and new developments to problems not susceptible to treatment by accepted methods, and to plan and execute specialized programs of marked difficulty, responsibility, and significance.
• Knowledge of the mission, roles, functions, organizational structure, and operation of the DoD, Air Force, and

organizations that govern, interface with, and/or influence systems acquisition, development, and/or

sustainment; and knowledge of planning, programming, and budgeting cycles, financial systems, and restrictions on expenditure of funds.
• Knowledge of and skill in evaluating state-of-the-art and advancements in theory, application, technology, and policy affecting systems being developed, and in planning, organizing, and directing the functions and staff in critical aspects of development, production, and/or support of systems, subsystems, or equipment.
• Knowledge of safety, security, personnel management, and Equal Employment Opportunity (EEO) regulations, practices, and procedures.
• Skill in establishing and maintaining effective relationships, building consensus and coalitions, negotiating, and resolving conflicts with a variety of individuals and organizations as well as communicating effectively, both orally and in writing.
• Ability to plan, organize, and direct the functions of an organization, and mentor, motivate, and appraise the staff through subordinate supervisors as well as analyze, plan, and adjust work operations of one or more organizational segments to meet program requirements and objectives within available resources.

Education

All Professional Engineering Positions, 0800

Individual Occupational Requirements

A. Degree: Engineering. To be acceptable, the program must:
(1) lead to a bachelor's degree in a school of engineering with at least one program accredited by ABET; or
(2) include differential and integral calculus and courses (more advanced than first-year physics and chemistry) in five of the following seven areas of engineering science or physics: (a) statics, dynamics; (b) strength of materials (stress-strain relationships); (c) fluid mechanics, hydraulics; (d) thermodynamics; (e) electrical fields and circuits; (f) nature and properties of materials (relating particle and aggregate structure to properties); and (g) any other comparable area of fundamental engineering science or physics, such as optics, heat transfer, soil mechanics, or electronics. OR

B. Combination of education and experience - college-level education, training, and/or technical experience that furnished (1) a thorough knowledge of the physical and mathematical sciences underlying engineering, and (2) a good understanding, both theoretical and practical, of the engineering sciences and techniques and their applications to one of the branches of engineering. The adequacy of such background must be demonstrated by one of the following: 1. Professional registration or licensure - Current registration as an Engineer Intern (EI), Engineer in Training (EIT)1 , or licensure as a Professional Engineer (PE) by any State, the District of Columbia, Guam, or Puerto Rico. Absent other means of qualifying under this standard, those applicants who achieved such registration by means other than written test (e.g., State grandfather or eminence provisions) are eligible only for positions that are within or closely related to the specialty field of their registration. For example, an applicant who attains registration through a State Board's eminence provision as a manufacturing engineer typically would be rated eligible only for manufacturing engineering positions. 2. Written Test - Evidence of having successfully passed the Fundamentals of Engineering (FE)2 examination or any other written test required for professional registration by an engineering licensure board in the various States, the District of Columbia, Guam, and Puerto Rico. 3. Specified academic courses - Successful completion of at least 60 semester hours of courses in the physical, mathematical, and engineering sciences and that included the courses specified in the basic requirements under paragraph A. The courses must be fully acceptable toward meeting the requirements of an engineering program as described in paragraph A. 4. Related curriculum - Successful completion of a curriculum leading to a bachelor's degree in an appropriate scientific field, e.g., engineering technology, physics, chemistry, architecture, computer science, mathematics, hydrology, or geology, may be accepted in lieu of a bachelor's degree in engineering, provided the applicant has had at least 1 year of professional engineering experience acquired under professional engineering supervision and guidance. Ordinarily there should be either an established plan of intensive training to develop professional engineering competence, or several years of prior professional engineering-type experience, e.g., in interdisciplinary positions. (The above examples of related curricula are not all-inclusive.) Note: An applicant who meets the basic requirements as specified in A or B above, except as noted under B.1., may qualify for positions in any branch of engineering unless selective factors indicate otherwise.
Data Science Series 1560
Qualifications Standard for Data Science Series, 1560
Basic Requirements:
• Degree: Mathematics, statistics, computer science, data science or field directly related to the position. The degree must be in a major field of study (at least at the baccalaureate level) that is appropriate for the position.

or
• Combination of education and experience: Courses equivalent to a major field of study (30 semester hours) as shown in paragraph A above, plus additional education or appropriate experience.

Operations Research Series 1515
Individual Occupational Requirements
Basic Requirements:

Degree: in operations research; or at least 24 semester hours in a combination of operations research, mathematics, probability, statistics, mathematical logic, science, or subject-matter courses requiring substantial competence in college-level mathematics or statistics. At least 3 of the 24 semester hours must have been in calculus.

Additional information

Air Force Civilian Service Employment Benefits:

Paid Time Off:
• 11 Federal Holidays off per year
• Vacation time (Annual Leave) accumulates based on length of employment. Starts at 13 days (104 hours) per year and up to 26 days (208 hours) per year
• 13 sick days per year (104 hours)

Retirement:
• Pension: Federal Employees Retirement System (FERS)
• 401K: Thrift Savings Plan (TSP) available with up to 5% agency matching

Health & Wellness:
• Various Medical, Dental & Vision packages to choose from for entire family
• Flexible Spending Account
• Federal Long Term Care Insurance, and Life & Disability Insurance

Work/Life Balance:
• Family and Medical Leave Act
• Employee Assistance Program (EAP)
• Flexible Work Arrangements (dependent on position)

Career Development:
• Tuition Assistance & Professional Development opportunities
• Career enhancement and promotion opportunities

To learn more about our benefits, please check out the AFTC Benefits Trifold at .

Federal Resume Tips:

Office of Personnel Management (OPM) Classification & Qualifications for Federal Government Employees:

To receive additional information about current and future job openings with Air Force Civilian Service, please registerat and click ""Subscribe"" in the top right corner.

Please visit the Air Force Test Center job board to view other career opportunities:

Equal Opportunity Employer. U.S. citizenship required. Must be of legal working age.

Air Force Test Center is proud to be an Equal Employment Opportunity employer, and is dedicated to advancing diversity, equity, inclusion, and accessibility. We recognize diversity encompasses many parts of one's identity including but not limited to race, color, gender (including pregnancy, childbirth, or related medical conditions), gender identity and expression, age, sexual orientation, national origin, religion, genetic information, disability status, and veteran status. AFTC encourages ALL candidates to apply as our employees' points of view are key to our success.

Disabled veteran leave is available to a Federal employee hired on/after 5 Nov 2016, who is a veteran with a service-connected disability rating of 30% or more. For more information, click here.
• Benefits

A career with the U.S. government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Opens in a new windowLearn more about federal benefits.

Review our benefits

Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time or intermittent. Contact the hiring agency for more information on the specific benefits offered.

How You Will Be Evaluated

You will be evaluated for this job based on how well you meet the qualifications above.

For additional information on direct hire opportunities with the Air Force please click here .
• Benefits

A career with the U.S. government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Opens in a new windowLearn more about federal benefits.

Review our benefits

Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time or intermittent. Contact the hiring agency for more information on the specific benefits offered.
• Required Documents

As a new or existing federal employee, you and your family may have access to a range of benefits. Your benefits depend on the type of position you have - whether you're a permanent, part-time, temporary or an intermittent employee. You may be eligible for the following benefits, however, check with your agency to make sure you're eligible under their policies.

For additional information on direct hire opportunities with the Air Force please click here .

If you are relying on your education to meet qualification requirements:

Education must be accredited by an accrediting institution recognized by the U.S. Department of Education in order for it to be credited towards qualifications. Therefore, provide only the attendance and/or degrees from schools accredited by accrediting institutions recognized by the U.S. Department of Education.

Failure to provide all of the required information as stated in this vacancy announcement may result in an ineligible rating or may affect the overall rating.
• How to Apply

Ensure you click the READ MORE below to open the frame and then CLICK APPLY NOW to complete an application and upload resume (PDF or Word Doc) and/or additional documents (Transcripts, certifications, Vet Docs (DD214), SF-50).

To receive additional information about current and future job openings with AFCS via email notification, please register at and sign up to ""Get Career Updates.""

For additional information on direct hire opportunities with the Air Force please click here .

Equal Opportunity Employer. U.S. citizenship required. Must be of legal working age.

Agency contact information

Air Force Test Center Recruitment

Email

AFTC.Enterprise.Recruiting@us.af.mil

Address

Eglin AFB
310 W Van Matre Ave
Ste 102
Eglin AFB, FL 32542
US
Next steps

For additional information on direct hire opportunities with the Air Force please click here .
• Fair and Transparent

The Federal hiring process is set up to be fair and transparent. Please read the following guidance.
• Criminal history inquiries
• Equal Employment Opportunity (EEO) Policy
• Financial suitability
• New employee probationary period
• Privacy Act
• Reasonable accommodation policy
• Selective Service
• Signature and false statements
• Social security number request

Required Documents

For additional information on direct hire opportunities with the Air Force please click here .

If you are relying on your education to meet qualification requirements:

Education must be accredited by an accrediting institution recognized by the U.S. Department of Education in order for it to be credited towards qualifications. Therefore, provide only the attendance and/or degrees from schools accredited by accrediting institutions recognized by the U.S. Department of Education.

Failure to provide all of the required information as stated in this vacancy announcement may result in an ineligible rating or may affect the overall rating.

Help This job is open to
• The public

U.S. Citizens, Nationals or those who owe allegiance to the U.S.",2025-07-08T00:00:00.000Z,2025-07-25,"['U.S. Citizenship Required', 'Security clearance requirements are based upon actual position being filled', 'Possess a bachelor’s degree in a related technical discipline such as mathematics, computer science, one of the physical sciences or engineering', 'Applicant must be capable of achieving the APDP certification', 'SPECIALIZED EXPERIENCE: Applicants must have at least one (1) year of specialized experience at the next lower broadband NH-03 or equivalent to the next lower grade GS-12 thru GS-13 in the Federal Service', 'Knowledge of a wide range of advanced multidisciplinary professional engineering/data science/computer science/research analysis concepts, principles, practices, standards, methods, and techniques to apply experimental theories and new developments to problems not susceptible to treatment by accepted methods, and to plan and execute specialized programs of marked difficulty, responsibility, and significance', 'Knowledge of the mission, roles, functions, organizational structure, and operation of the DoD, Air Force, and', 'sustainment; and knowledge of planning, programming, and budgeting cycles, financial systems, and restrictions on expenditure of funds', 'Knowledge of and skill in evaluating state-of-the-art and advancements in theory, application, technology, and policy affecting systems being developed, and in planning, organizing, and directing the functions and staff in critical aspects of development, production, and/or support of systems, subsystems, or equipment', 'Knowledge of safety, security, personnel management, and Equal Employment Opportunity (EEO) regulations, practices, and procedures', 'Degree: Engineering', ""(1) lead to a bachelor's degree in a school of engineering with at least one program accredited by ABET; or"", '(2) include differential and integral calculus and courses (more advanced than first-year physics and chemistry) in five of the following seven areas of engineering science or physics: (a) statics, dynamics; (b) strength of materials (stress-strain relationships); (c) fluid mechanics, hydraulics; (d) thermodynamics; (e) electrical fields and circuits; (f) nature and properties of materials (relating particle and aggregate structure to properties); and (g) any other comparable area of fundamental engineering science or physics, such as optics, heat transfer, soil mechanics, or electronics', 'Combination of education and experience - college-level education, training, and/or technical experience that furnished (1) a thorough knowledge of the physical and mathematical sciences underlying engineering, and (2) a good understanding, both theoretical and practical, of the engineering sciences and techniques and their applications to one of the branches of engineering', 'The adequacy of such background must be demonstrated by one of the following: 1', 'Professional registration or licensure - Current registration as an Engineer Intern (EI), Engineer in Training (EIT)1 , or licensure as a Professional Engineer (PE) by any State, the District of Columbia, Guam, or Puerto Rico', 'Absent other means of qualifying under this standard, those applicants who achieved such registration by means other than written test (e.g., State grandfather or eminence provisions) are eligible only for positions that are within or closely related to the specialty field of their registration', ""For example, an applicant who attains registration through a State Board's eminence provision as a manufacturing engineer typically would be rated eligible only for manufacturing engineering positions"", 'Written Test - Evidence of having successfully passed the Fundamentals of Engineering (FE)2 examination or any other written test required for professional registration by an engineering licensure board in the various States, the District of Columbia, Guam, and Puerto Rico', 'Specified academic courses - Successful completion of at least 60 semester hours of courses in the physical, mathematical, and engineering sciences and that included the courses specified in the basic requirements under paragraph A', 'The courses must be fully acceptable toward meeting the requirements of an engineering program as described in paragraph A', ""Related curriculum - Successful completion of a curriculum leading to a bachelor's degree in an appropriate scientific field, e.g., engineering technology, physics, chemistry, architecture, computer science, mathematics, hydrology, or geology, may be accepted in lieu of a bachelor's degree in engineering, provided the applicant has had at least 1 year of professional engineering experience acquired under professional engineering supervision and guidance"", 'Ordinarily there should be either an established plan of intensive training to develop professional engineering competence, or several years of prior professional engineering-type experience, e.g., in interdisciplinary positions. (The above examples of related curricula are not all-inclusive.)', 'Note: An applicant who meets the basic requirements as specified in A or B above, except as noted under B.1., may qualify for positions in any branch of engineering unless selective factors indicate otherwise', 'Qualifications Standard for Data Science Series, 1560', 'Degree: Mathematics, statistics, computer science, data science or field directly related to the position', 'The degree must be in a major field of study (at least at the baccalaureate level) that is appropriate for the position', 'Combination of education and experience: Courses equivalent to a major field of study (30 semester hours) as shown in paragraph A above, plus additional education or appropriate experience', 'Degree: in operations research; or at least 24 semester hours in a combination of operations research, mathematics, probability, statistics, mathematical logic, science, or subject-matter courses requiring substantial competence in college-level mathematics or statistics', 'At least 3 of the 24 semester hours must have been in calculus', 'U.S. citizenship required', 'Must be of legal working age', 'Education must be accredited by an accrediting institution recognized by the U.S', 'Department of Education in order for it to be credited towards qualifications', 'U.S. citizenship required', 'Must be of legal working age', 'Education must be accredited by an accrediting institution recognized by the U.S', 'Department of Education in order for it to be credited towards qualifications']","['Supervise government civilians within the Advanced Capabilities Flight', 'Oversee supervisory administrative aspects such as time off, travel, talent management and retention', 'Act as hiring manager for new employees and oversee on-boarding', 'Organize, train, and equip team of test engineers, scientists, aircrew, logisticians, and support personnel to accomplish flight test mission sets', 'Provide technical subject matter expertise where applicable to solve issues that arise during flight test', 'Communicate program status to squadron and group leadership', 'Provide early indications of concerns before they manifest as issues', 'Provide technical continuity for military and civilian workforce', 'Random drug testing may be required depending upon the position being filled', 'Supervisory requirements may be required depending upon the position being filled', 'Work may occasionally require travel away from the normal duty station on military or commercial aircraft', 'The work requires the employee to obtain and maintain the appropriate security clearance', 'organizations that govern, interface with, and/or influence systems acquisition, development, and/or', 'Skill in establishing and maintaining effective relationships, building consensus and coalitions, negotiating, and resolving conflicts with a variety of individuals and organizations as well as communicating effectively, both orally and in writing', 'Ability to plan, organize, and direct the functions of an organization, and mentor, motivate, and appraise the staff through subordinate supervisors as well as analyze, plan, and adjust work operations of one or more organizational segments to meet program requirements and objectives within available resources']",False,,,,
FlHGei9nG1MoCK2bAAAAAA==,"Data Scientist, Radio & Music Informatics Science Oakland, CA, United States Job","Data Scientist, Radio & Music Informatics ScienceSiriusXM and Pandora have joined together to create the leading audio entertainment company in the U.S. Together, we are uniquely positioned to lead a new era of audio entertainment by delivering the most compelling subscription and ad-supported audio experiences to millions of listeners -- in the car, at home and on the go. Our talent, content, technology and innovation continue to be at the forefront, and we want you to be a part of it!Position Summary:In this role you'll be working on a team designing, building, and testing the next innovations that will delight millions of listeners. You will have access to billions of hours of music listening history across hundreds of millions of listeners who have provided a hundred billion thumbs on their stations and playlists. And truly unique to SiriusXM + Pandora, you'll be working with extremely rich and diverse interlinked music metadata, including annotations of our expert musicologists with the Music Genome Project's 450+ musical characteristics. With these resources at your fingertips, we want your help to make sure we always pick that perfect next song for our listeners.Duties and Responsibilities:Design, build, and A/B-test improvements and innovations to SiriusXM + Pandora’s algorithmic radio, playlist, and recommendations products.Improve upon SiriusXM + Pandora’s content understanding capabilities through audio and metadata analysis.Partner closely with product, analytics, and engineering.Supervisory Responsibilities:NoneMinimum Qualifications:Masters Degree in a quantitative field (CS, EE, Statistics, Physics, Math, etc.)Preferred Qualifications:PhD Degree in a quantitative field (CS, EE, Statistics, Physics, Math, etc.) or 2+ years industry experience working as a Data Scientist.Requirements and General Skills:Experience designing and building machine learning systems or recommender systems or music information retrieval systems.Solid understanding of A/B testing concepts.Demonstrated ability to work well in a small team.Excellent communication skills with both technical and non-technical audiences.Technical Skills:Proficiency with Python, Scala, or Java.Experience with SQL (or equivalent).Experience with distributed computing systems (e.g., Spark, etc.).Familiarity with common machine learning libraries (e.g., scikit-learn, Tensorflow, etc.).Our goal at SiriusXM + Pandora is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM + Pandora is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.
#J-18808-Ljbffr",2025-07-23T00:00:00.000Z,2025-07-25,"['Partner closely with product, analytics, and engineering', 'Requirements and General Skills:Experience designing and building machine learning systems or recommender systems or music information retrieval systems', 'Solid understanding of A/B testing concepts', 'Demonstrated ability to work well in a small team', 'Excellent communication skills with both technical and non-technical audiences', 'Technical Skills:Proficiency with Python, Scala, or Java', 'Experience with SQL (or equivalent)', 'Experience with distributed computing systems (e.g., Spark, etc.).Familiarity with common machine learning libraries (e.g., scikit-learn, Tensorflow, etc.).Our goal at SiriusXM + Pandora is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation']","['You will have access to billions of hours of music listening history across hundreds of millions of listeners who have provided a hundred billion thumbs on their stations and playlists', 'Duties and Responsibilities:Design, build, and A/B-test improvements and innovations to SiriusXM + Pandora’s algorithmic radio, playlist, and recommendations products', 'Improve upon SiriusXM + Pandora’s content understanding capabilities through audio and metadata analysis']",True,['TensorFlow'],"TensorFlow: Used as a machine learning library, potentially for building neural network models related to music content analysis and recommendation, though not explicitly described as deep learning in this context.","['A/B Testing', 'Recommender Systems', 'Machine Learning Systems', 'Music Information Retrieval', 'SQL', 'Distributed Computing Systems', 'Python', 'Scala', 'Java', 'Scikit-learn']","A/B Testing: Used to design, build, and evaluate improvements and innovations to algorithmic radio, playlist, and recommendation products by comparing different versions to determine effectiveness.; Recommender Systems: Designing and building systems that suggest music content to listeners based on their listening history and preferences.; Machine Learning Systems: Developing and implementing machine learning models to support music information retrieval and recommendation tasks.; Music Information Retrieval: Analyzing audio and metadata to improve content understanding capabilities related to music characteristics and listener preferences.; SQL: Utilized for querying and managing large-scale music listening data and metadata.; Distributed Computing Systems: Experience with systems like Spark to process and analyze large volumes of music listening history and metadata efficiently.; Python: Programming language used for data analysis, machine learning model development, and building data pipelines.; Scala: Programming language used for working with distributed computing systems and data processing.; Java: Programming language used for building scalable data and machine learning systems.; Scikit-learn: A machine learning library used for building and experimenting with machine learning models related to music recommendation and analysis."
tWRA07qJ9cETDxqgAAAAAA==,Entry Level Data Scientist/ML Engineer - Remote,"The Job Market is Challenging due to almost 300,000 Tech Layoffs since October 2022 due to which thousands of laid off Techies are competing with existing Jobseekers. Entry level Job seekers struggle to get responses to their applications forget about getting client interviews. As the Saying goes ""when the Going gets tough the Tough get going” Candidates who want to make a tech career they need to differentiate themselves by ensuring they have exceptional skills and technologies to be noticed by clients.

Since 2010 Synergisticit has helped Jobseekers differentiate themselves by providing candidates the requisite skills and experience to outperform at interviews and clients. Here at SynergisticIT We just don't focus on getting you a Job we make careers.

All Positions are open for all visas and US citizens

We are matchmakers we provide clients with candidates who can perform from day 1 of starting work. In this challenging economy every client wants to save $$$'s and they want the best value for their money. Jobseekers need to self-evaluate if they have the requisite skills to meet client requirements and needs. Clients now post covid can also hire remote workers which increases even more competition for jobseekers.

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in IT Industry

We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

We also offer optionally Skill and technology enhancement programs for candidates who are either missing skills or are lacking Industry/Client experience with Projects and skills. Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. If they are qualified with enough skills and have hands on project work at clients then they should be good to be submitted to clients. Shortlisting and selection is totally based on clients discretion not ours.

please check the below links to see success outcomes of our candidates

https://www.synergisticit.com/candidate-outcomes/

We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please see us exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023

Oracle CloudWorld Event (OCW) Las Vegas 2023/ 2022 | SynergisticIT - YouTube

https://youtu.be/Rfn8Y0gnfL8?si=p2V4KFv5HukJXTrn https://youtu.be/-HkNN1ag6Zk?si=1NRfgsvL_HJMVb6Q https://www.youtube.com/watch?v=OAFOhcGy9Z8 https://www.youtube.com/watch?v=EmO7NrWHkLM https://www.youtube.com/watch?v=NVBU9RYZ6UI https://www.youtube.com/watch?v=Yy74yvjatVg

For preparing for interviews please visit https://www.synergisticit.com/interview-questions/

We are looking for the right matching candidates for our clients

Please apply via the job posting

REQUIRED SKILLS For Java /Full stack/Software Programmer
• Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
• Highly motivated, self-learner, and technically inquisitive
• Experience in programming language Java and understanding of the software development life cycle
• Project work on the skills
• Knowledge of Core Java , javascript , C++ or software programming
• Spring boot, Microservices, Docker, Jenkins and REST API's experience
• Excellent written and verbal communication skills

For data Science/Machine learning Positions
REQUIRED SKILLS
• Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
• Project work on the technologies needed
• Highly motivated, self-learner, and technically inquisitive
• Experience in programming language Java and understanding of the software development life cycle
• Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools
• Excellent written and verbal communication skills
Preferred skills: NLP, Text mining, Tableau, PowerBI, Tensorflow

If you get emails from our skill enhancement team please ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",,2025-07-25,"['Jobseekers need to self-evaluate if they have the requisite skills to meet client requirements and needs', 'Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in IT Industry', 'Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio', 'If they are qualified with enough skills and have hands on project work at clients then they should be good to be submitted to clients', 'REQUIRED SKILLS For Java /Full stack/Software Programmer', 'Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT', 'Highly motivated, self-learner, and technically inquisitive', 'Experience in programming language Java and understanding of the software development life cycle', 'Project work on the skills', 'Knowledge of Core Java , javascript , C++ or software programming', ""Spring boot, Microservices, Docker, Jenkins and REST API's experience"", 'Excellent written and verbal communication skills', 'For data Science/Machine learning Positions', 'Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT', 'Project work on the technologies needed', 'Highly motivated, self-learner, and technically inquisitive', 'Experience in programming language Java and understanding of the software development life cycle', 'Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools', 'Excellent written and verbal communication skills']",['https://youtu.be/Rfn8Y0gnfL8?si=p2V4KFv5HukJXTrn https://youtu.be/-HkNN1ag6Zk?si=1NRfgsvL_HJMVb6Q https://www.youtube.com/watch?v=OAFOhcGy9Z8 https://www.youtube.com/watch?v=EmO7NrWHkLM https://www.youtube.com/watch?v=NVBU9RYZ6UI https://www.youtube.com/watch?v=Yy74yvjatVg'],True,['TensorFlow'],"TensorFlow: TensorFlow is preferred for machine learning roles, indicating use of deep learning frameworks for building and training neural networks.","['Statistics', 'SAS', 'Python', 'Computer Vision', 'Data Visualization Tools', 'NLP', 'Machine Learning']","Statistics: Knowledge of statistics is required for data science and machine learning positions to analyze and interpret data effectively.; SAS: Experience with SAS is mentioned as a required skill for data science roles, indicating its use for statistical analysis and data management.; Python: Python programming language is required for data science and machine learning roles, supporting tasks such as data analysis, visualization, and model development.; Computer Vision: Knowledge of computer vision is preferred, suggesting involvement with image or video data processing in data science or machine learning projects.; Data Visualization Tools: Experience with data visualization tools like Tableau and PowerBI is preferred to create dashboards and visual representations of data insights.; NLP: Natural Language Processing is a preferred skill, indicating work with text mining and analysis in data science projects.; Machine Learning: Machine learning is a core skill for the data science positions, involving building predictive models and applying algorithms to data."
_5rM8LBIEtUYvKx8AAAAAA==,"Senior Data Scientist, Specialist Senior - SFL Scientific - Full-time","Senior Data Scientist, Specialist Senior - SFL Scientific

Our Deloitte Strategy & Transactions team helps guide clients through their most critical moments and transformational initiatives. From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability. Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journey-before, during, and after any major transformational projects or transactions.

SFL Scientific, a Deloitte Business, is a U.S. based, data science consulting firm specializing in building industry-specific, artificial intelligence (AI) technologies.

We are hiring a Senior Data Scientist to collaborate directly with clients to design and develop novel projects and solutions. Join a rapidly growing team of professionals working to build a world-class data science practice focused on solving complex and R&D problems.

Recruiting for this role ends on 7/31/2025.

Work You'll Do

As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services. You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions.

Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation. Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills.

+ Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production

+ Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives

+ Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization

+ Validate AI models and algorithm via code reviews, unit, and integration tests

+ Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives

+ Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives

The Team

Our Strategy offering architects bold strategies to achieve business and mission goals, enabling growth, competitive advantage, technology modernization, and continuous digital and AI transformation.

SFL Scientific, a Deloitte Business, is a data science professional services practice focused on strategy, technology, and solving business challenges with Artificial Intelligence (AI). The team has a proven track record serving large, market-leading organizations in the private and public sectors, successfully delivering high-quality, novel and complex projects, and offering deep domain and scientific capabilities. Made up of experienced AI strategists, data scientists, and AI engineers, they serve as trusted advisors to executives, helping them understand and evaluate new and essential areas for AI investment and identify unique opportunities to transform their businesses.

Qualifications:

+ Master's or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)

+ 3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)

+ 3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments

+ 3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow

+ 3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads

+ Live within commuting distance to one of Deloitte's consulting offices

+ Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve

+ Limited immigration sponsorship may be available

Preferred:

+ 2+ years of experience working in a client-facing, consulting environment

+ 2+ years of experience leading project/client engagement teams in the execution of complex AI data science solutions

+ 1+ year of experience with LLM/GenAI use cases and developing RAG solutions, tools, and services (i.e., LangChain, LangGraph, MCP, etc.)

+ 1+ year of experience with AWS Sagemaker or AWS ML Studio

Information for applicants with a need for accommodation: https://www2.deloitte.com/us/en/pages/careers/articles/join-deloitte-assistance-for-disabled-applicants.html

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $107,600 to $198,400.

You may also be eligible to participate in a discretionary annual incentive program, subject to the rules governing the program, whereby an award, if any, depends on various factors, including, without limitation, individual and organizational performance.

#MonitorDeloitte

#DeloitteJobs

#StrategyConsulting

#DeloitteStrategy

#Strategy26

#SFL26

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.

Senior Data Scientist, Specialist Senior - SFL Scientific

Our Deloitte Strategy & Transactions team helps guide clients through their most critical moments and transformational initiatives. From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability. Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journey-before, during, and after any major transformational projects or transactions.

SFL Scientific, a Deloitte Business, is a U.S. based, data science consulting firm specializing in building industry-specific, artificial intelligence (AI) technologies.

We are hiring a Senior Data Scientist to collaborate directly with clients to design and develop novel projects and solutions. Join a rapidly growing team of professionals working to build a world-class data science practice focused on solving complex and R&D problems.

Recruiting for this role ends on 7/31/2025.

Work You'll Do

As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services. You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions.

Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation. Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills.

+ Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production

+ Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives

+ Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization

+ Validate AI models and algorithm via code reviews, unit, and integration tests

+ Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives

+ Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives

The Team

Our Strategy offering architects bold strategies to achieve business and mission goals, enabling growth, competitive advantage, technology modernization, and continuous digital and AI transformation.

SFL Scientific, a Deloitte Business, is a data science professional services practice focused on strategy, technology, and solving business challenges with Artificial Intelligence (AI). The team has a proven track record serving large, market-leading organizations in the private and public sectors, successfully delivering high-quality, novel and complex projects, and offering deep domain and scientific capabilities. Made up of experienced AI strategists, data scientists, and AI engineers, they serve as trusted advisors to executives, helping them understand and evaluate new and essential areas for AI investment and identify unique opportunities to transform their businesses.

Qualifications:

+ Master's or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)

+ 3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)

+ 3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments

+ 3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow

+ 3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads

+ Live within commuting distance to one of Deloitte's consulting offices

+ Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve

+ Limited immigration sponsorship may be available

Preferred:

+ 2+ years of experience working in a client-facing, consulting environment

+ 2+ years of experience leading project/client engagement teams in the execution of complex AI data science solutions

+ 1+ year of experience with LLM/GenAI use cases and developing RAG solutions, tools, and services (i.e., LangChain, LangGraph, MCP, etc.)

+ 1+ year of experience with AWS Sagemaker or AWS ML Studio

Information for applicants with a need for accommodation: https://www2.deloitte.com/us/en/pages/careers/articles/join-deloitte-assistance-for-disabled-applicants.html

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $107,600 to $198,400.

You may also be eligible to participate in a discretionary annual incentive program, subject to the rules governing the program, whereby an award, if any, depends on various factors, including, without limitation, individual and organizational performance.

#MonitorDeloitte

#DeloitteJobs

#StrategyConsulting

#DeloitteStrategy

#Strategy26

#SFL26

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.",2025-07-24T00:00:00.000Z,2025-07-25,"[""Master's or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)"", '3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)', '3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments', '3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow', '3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads', ""Live within commuting distance to one of Deloitte's consulting offices"", 'Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve', 'Limited immigration sponsorship may be available', ""Master's or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)"", '3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)', '3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments', '3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow', '3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads', ""Live within commuting distance to one of Deloitte's consulting offices"", 'Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve', 'Limited immigration sponsorship may be available']","['From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability', 'Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journey-before, during, and after any major transformational projects or transactions', 'As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services', 'You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions', 'Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation', 'Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills', 'Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production', 'Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives', 'Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization', 'Validate AI models and algorithm via code reviews, unit, and integration tests', 'Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives', 'Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives', 'From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability', 'Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journey-before, during, and after any major transformational projects or transactions', 'As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services', 'You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions', 'Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation', 'Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills', 'Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production', 'Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives', 'Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization', 'Validate AI models and algorithm via code reviews, unit, and integration tests', 'Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives', 'Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives']",True,"['Generative AI', 'Large Language Models', 'Retrieval-Augmented Generation', 'Prompt Engineering', 'Transformers', 'PyTorch (Deep Learning)', 'AWS SageMaker', 'AI Strategy and Development']","Generative AI: The role involves working on generative AI use cases, including developing solutions and services related to large language models and generative AI technologies.; Large Language Models: Experience with LLMs is required, including developing use cases and solutions involving these models.; Retrieval-Augmented Generation: Developing RAG solutions, tools, and services is part of the job, involving integration of retrieval mechanisms with generative AI models.; Prompt Engineering: The job includes responsibilities related to designing and optimizing prompts for generative AI models to improve performance and relevance.; Transformers: Transformers are applied as part of deep learning techniques in AI/ML projects, especially related to NLP and generative AI.; PyTorch (Deep Learning): PyTorch is specifically used for implementing deep learning models, including neural networks such as CNNs, RNNs, and GANs, within AI projects.; AWS SageMaker: AWS SageMaker is used to develop, train, and deploy AI/ML models, including generative AI and LLM workloads.; AI Strategy and Development: The role includes guiding clients in AI strategy, development, and deployment of AI services to meet organizational needs and maximize business impact.","['Machine Learning', 'Deep Learning', 'Python', 'PyTorch', 'Natural Language Processing', 'Time-Series Analysis', 'Computer Vision', 'Kubernetes', 'Docker', 'TensorRT', 'RAPIDs', 'Kubeflow', 'MLflow', 'Cloud Platforms', 'Exploratory Data Analysis', 'Model Validation and Testing', 'Data Strategy']","Machine Learning: The role involves developing and deploying machine learning algorithms and models, including traditional ML techniques and model tuning and validation in production environments.; Deep Learning: The job requires applying deep learning techniques such as CNNs, RNNs, and GANs across real-world projects, including model tuning and performance validation.; Python: Python is used as a core data science language for AI/ML algorithm development and data analysis.; PyTorch: PyTorch is used as a framework for AI/ML algorithm development and deep learning model implementation.; Natural Language Processing: NLP is applied as part of data analysis tasks within AI/ML algorithm development.; Time-Series Analysis: Time-series analysis is used as a data analysis technique in AI/ML algorithm development.; Computer Vision: Computer vision techniques are applied as part of AI/ML algorithm development and data analysis.; Kubernetes: Kubernetes is used for deploying and optimizing machine learning models in production environments.; Docker: Docker is utilized for containerizing and deploying machine learning models.; TensorRT: TensorRT is employed for optimizing machine learning models for inference performance.; RAPIDs: RAPIDs is used to accelerate machine learning model deployment and optimization.; Kubeflow: Kubeflow is used to deploy and manage machine learning workflows and models.; MLflow: MLflow is used for managing the machine learning lifecycle, including experimentation, reproducibility, and deployment.; Cloud Platforms: Cloud environments such as AWS, Azure, and GCP are leveraged to deploy AI/ML workloads and support scalable model deployment.; Exploratory Data Analysis: Exploratory data analysis is performed to understand client data sets and inform model development and long-term solution design.; Model Validation and Testing: The role includes validating AI models and algorithms through code reviews, unit tests, and integration tests to ensure quality and performance.; Data Strategy: Defining data strategy is a key responsibility to align technical development with client operational requirements and business objectives."
i0Qyb4YESwPo3TNeAAAAAA==,"Research Scientist, Gemini Data","Snapshot

The Gemini Data team

We are seeking a highly motivated and talented Research Scientist to join our team to work on Gemini data. Our goal is to organize the world's information and generate and curate high-quality tokens for Gemini core model training.
About Us

Artificial Intelligence could be one of humanity's most useful inventions. At Google DeepMind, we're a team of scientists, engineers, machine learning experts and more, working together to advance the state of the art in artificial intelligence. We use our technologies for widespread public benefit and scientific discovery, and collaborate with others on critical challenges, ensuring safety and ethics are the highest priority.
The Role

We are seeking a highly motivated and talented Research Scientist to join our team to work on Gemini data.

Key responsibilities
• Research and develop methods to create diversified high-quality synthetic data, scale the creation through collaborations, evaluate & improve its effectiveness through ablation in pretraining/post-training/distillation.
• Research and develop methods to identify quality issues horizontally in the pretraining data corpus, innovate on how to fix, and evaluate & improve its effectiveness through ablation into landing.
• Stay up-to-date with the latest advancements in LLM research.
About You

In order to set you up for success as a Research Scientist at Google DeepMind, we look for the following skills and experience:

In order to set you up for success as a Research Scientist at Google DeepMind, we look for the following skills and experience:
• PhD in Computer Science or related field.
• In-depth experience and familiarity of LLM training and/or agents.
• Strong publication record in top machine learning conferences (e.g., NeurIPS, CVPR, ICML, ICLR, ICCV, ECCV).
• Solid skills & experience in software engineering for ML

In addition, the following would be an advantage:
• Excellent communication and teamwork skills
• Passion for research and a desire to make a significant impact in the pretraining data area.
• Expertise in one or more of the following areas of LLMs: Synthetic Data, Data Quality, Scaling Data

The US base salary range for this full-time position is between $166,000 - $220,000 + bonus + equity + benefits. Your recruiter can share more about the specific salary range for your targeted location during the hiring process.

At Google DeepMind, we value diversity of experience, knowledge, backgrounds and perspectives and harness these qualities to create extraordinary impact. We are committed to equal employment opportunity regardless of sex, race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, gender identity, pregnancy, or related condition (including breastfeeding) or any other basis as protected by applicable law. If you have a disability or additional need that requires accommodation, please do not hesitate to let us know.",2025-07-08T00:00:00.000Z,2025-07-25,"['PhD in Computer Science or related field', 'In-depth experience and familiarity of LLM training and/or agents', 'Strong publication record in top machine learning conferences (e.g., NeurIPS, CVPR, ICML, ICLR, ICCV, ECCV)', 'Solid skills & experience in software engineering for ML', 'Excellent communication and teamwork skills', 'Passion for research and a desire to make a significant impact in the pretraining data area', 'Expertise in one or more of the following areas of LLMs: Synthetic Data, Data Quality, Scaling Data']","['We are seeking a highly motivated and talented Research Scientist to join our team to work on Gemini data', 'Research and develop methods to create diversified high-quality synthetic data, scale the creation through collaborations, evaluate & improve its effectiveness through ablation in pretraining/post-training/distillation', 'Research and develop methods to identify quality issues horizontally in the pretraining data corpus, innovate on how to fix, and evaluate & improve its effectiveness through ablation into landing', 'Stay up-to-date with the latest advancements in LLM research']",True,"['Large Language Models', 'Ablation Studies', 'Model Distillation', 'AI Research']","Large Language Models: In-depth experience and familiarity with training and working with large language models (LLMs) and agents, including staying up-to-date with the latest advancements in LLM research.; Ablation Studies: Use of ablation techniques to evaluate and improve the effectiveness of synthetic data creation and data quality methods in pretraining, post-training, and distillation.; Model Distillation: Application of distillation techniques as part of the evaluation and improvement process for synthetic data effectiveness in model training.; AI Research: Engagement in cutting-edge AI research, demonstrated by a strong publication record in top machine learning conferences and a passion for advancing pretraining data methodologies.","['Synthetic Data', 'Data Quality', 'Pretraining Data']","Synthetic Data: Research and development of methods to create diversified high-quality synthetic data and scale its creation through collaborations, with evaluation and improvement of its effectiveness in pretraining, post-training, and distillation phases.; Data Quality: Research and development of methods to identify and fix quality issues horizontally in the pretraining data corpus, including evaluation and improvement of these methods through ablation studies.; Pretraining Data: Focus on organizing and curating high-quality tokens for core model training, with responsibilities including improving the quality and effectiveness of pretraining data."
nb_X9MFGMA5UnNR0AAAAAA==,Lead Data Scientist,"Company Overview

At Motorola Solutions, we believe that everything starts with our people. We're a global close-knit community, united by the relentless pursuit to help keep people safer everywhere. Our critical communications, video security and command center technologies support public safety agencies and enterprises alike, enabling the coordination that's critical for safer communities, safer schools, safer hospitals and safer businesses. Connect with a career that matters, and help us build a safer future.

Department OverviewThe Design & Tools (D&T) team is a strategic component of Centralized Managed Support Operations (CMSO), responsible for providing exceptional Service Design & innovative technology solutions to enable and empower MSI Centralized Managed Support Operations to meet and exceed customer's expectations. In this role, you will fit in the AI & Architecture team within D&T.
Job Description

We are looking for a Senior Data Scientist who will lead and drive the Artificial Intelligence & Analytics stream at D&T (Design and Tools). In this role, you will also serve as a subject matter expert in the AI and ML domain, and build analytical and statistical machine learning models that will drive business decisions. You will understand user requirements and translate them into AI solutions that turbocharge internal and external user experiences. Many of these AI solutions will be enabled within the core technologies used within CMSO, including Salesforce and ServiceNow. In other instances, you will also be responsible for building custom predictive and prescriptive ML models for preventative system health checks, system log analytics, automated root cause analysis etc.

Responsibilities include:
• Manage and direct processes of AI related projects
• Drive requirements for AI related projects, work with internal customers and with ServiceNow and Salesforce Product Managers for features planning, prioritization and implementation
• Understand and apply various statistical methods for data analysis, EDA, hypothesis testing, and drawing meaningful conclusions.
• Understand ML concepts and has applied one or more of Deep Learning methods, NLP, computer vision, sentiment analysis, topic modeling and graph theory in real world applications to solve business problems
• Guiding models to master the theory and application of supervised, unsupervised, and reinforcement learning algorithms for tasks like classification, regression, and clustering.
• Training ML models to effectively communicate complex data insights through clear and informative visualizations
• Instilling in models an understanding of the ethical implications of data science, including bias detection, fairness, and responsible data handling.
• Develop application-specific interfaces that leverage GenAI capabilities, LLMs and FMs to enhance the associate and customer experience.
• Design APIs for performance, real-time applications, scale, ease of use and governance automation.
• Serves as industry thought leader in data science and applies deep expertise to drive novel customer experiences
• Adaptive and the desire to learn new technologies.

Technical Experience
• Extensive knowledge in using Python libraries to perform univariate and bivariate analysis, building advanced machine learning models and data integrations with source systems and systems of record
• Experience with common data science tools such as Python, R, PyTorch, TensorFlow, Keras, NLTK, or spaCy
• Very good knowledge and experience with Databases like Postgres, Redshift, MSSQL
• Knowledge and experience in Cloud Environments (Azure, AWS, GCP)
• Experience to read data from multiple sources and cleanse, enhance and analyze the data.
• Ability to integrate data, sourcing data from several Sources including databases, files, API and Server logs.

Preferred Qualifications
• Minimum of 4+ years experience in data analytics, data mining, machine learning, and has employed predictive, prescriptive, conversational or generative AI to solve business problems
• Minimum of 4+ years experience in hands-on design, coding, development and deployment using data science tools such as Python, Tensorflow etc. to build AI solutions
• Minimum 2+ years experience leading teams to deliver solutions and results
• Deep knowledge of ML streams, e.g., natural language processing, computer vision, statistical learning theory and their application in real world situations
• Knowledge of ServiceNow and Salesforce products and features
• Experience working with one of the leading public clouds (AWS, Google, Azure)
• Excellent written and oral communication skills. Be able to work under pressure
• Ability to Multitask, Prioritize and Manage time effectively.
• Strong interpersonal skills and ability to work effectively across teams, functional groups

Target Base Salary Range for this role is $89,300 - $178,600

Consistent with Motorola Solutions values and applicable law, we provide the following information to promote pay transparency and equity. Pay within this range varies and depends on job-related knowledge, skills, and experience. The actual offer will be based on the individual candidate.

#LI-DB1

Basic Requirements
• Bachelor's degree in Data Science, Computer Science, or an IT related field
• Minimum of 4+ years experience in a Data Science related role
• Legal authorization to work in the U.S. indefinitely is required. Employer work permit sponsorship is not available for this position.

Travel RequirementsUnder 10%
Relocation ProvidedNone
Position TypeExperienced
Referral Payment PlanYes

Our U.S.Benefitsinclude:
• Incentive Bonus Plans
• Medical, Dental, Visionbenefits
• 401K
• 10 Paid Holidays
• GenerousPaidTime Off Packages
• Employee Stock Purchase Plan
• PaidParental & Family Leave
• and more!

EEO Statement

Motorola Solutions is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion or belief, sex, sexual orientation, gender identity, national origin, disability, veteran status or any other legally-protected characteristic.

We are proud of our people-first and community-focused culture, empowering every Motorolan to be their most authentic self and to do their best work to deliver on the promise of a safer world. If you'd like to join our team but feel that you don't quite meet all of the preferred skills, we'd still love to hear why you think you'd be a great addition to our team.

We're committed to providing an inclusive and accessible recruiting experience for candidates with disabilities, or other physical or mental health conditions. To request an accommodation, please complete thisReasonable Accommodations Formso we can assist you.",2025-07-08T00:00:00.000Z,2025-07-25,"['Adaptive and the desire to learn new technologies', 'Extensive knowledge in using Python libraries to perform univariate and bivariate analysis, building advanced machine learning models and data integrations with source systems and systems of record', 'Experience with common data science tools such as Python, R, PyTorch, TensorFlow, Keras, NLTK, or spaCy', 'Very good knowledge and experience with Databases like Postgres, Redshift, MSSQL', 'Knowledge and experience in Cloud Environments (Azure, AWS, GCP)', 'Experience to read data from multiple sources and cleanse, enhance and analyze the data', 'Ability to integrate data, sourcing data from several Sources including databases, files, API and Server logs', 'Minimum 2+ years experience leading teams to deliver solutions and results', 'Deep knowledge of ML streams, e.g., natural language processing, computer vision, statistical learning theory and their application in real world situations', 'Knowledge of ServiceNow and Salesforce products and features', 'Experience working with one of the leading public clouds (AWS, Google, Azure)', 'Excellent written and oral communication skills', 'Be able to work under pressure', 'Ability to Multitask, Prioritize and Manage time effectively', 'Strong interpersonal skills and ability to work effectively across teams, functional groups', ""Bachelor's degree in Data Science, Computer Science, or an IT related field"", 'Minimum of 4+ years experience in a Data Science related role', 'Legal authorization to work in the U.S. indefinitely is required', ""We're committed to providing an inclusive and accessible recruiting experience for candidates with disabilities, or other physical or mental health conditions""]","['In this role, you will fit in the AI & Architecture team within D&T', 'In this role, you will also serve as a subject matter expert in the AI and ML domain, and build analytical and statistical machine learning models that will drive business decisions', 'You will understand user requirements and translate them into AI solutions that turbocharge internal and external user experiences', 'Many of these AI solutions will be enabled within the core technologies used within CMSO, including Salesforce and ServiceNow', 'In other instances, you will also be responsible for building custom predictive and prescriptive ML models for preventative system health checks, system log analytics, automated root cause analysis etc', 'Manage and direct processes of AI related projects', 'Drive requirements for AI related projects, work with internal customers and with ServiceNow and Salesforce Product Managers for features planning, prioritization and implementation', 'Understand and apply various statistical methods for data analysis, EDA, hypothesis testing, and drawing meaningful conclusions', 'Understand ML concepts and has applied one or more of Deep Learning methods, NLP, computer vision, sentiment analysis, topic modeling and graph theory in real world applications to solve business problems', 'Guiding models to master the theory and application of supervised, unsupervised, and reinforcement learning algorithms for tasks like classification, regression, and clustering', 'Training ML models to effectively communicate complex data insights through clear and informative visualizations', 'Instilling in models an understanding of the ethical implications of data science, including bias detection, fairness, and responsible data handling', 'Develop application-specific interfaces that leverage GenAI capabilities, LLMs and FMs to enhance the associate and customer experience', 'Design APIs for performance, real-time applications, scale, ease of use and governance automation', 'Serves as industry thought leader in data science and applies deep expertise to drive novel customer experiences', 'to build AI solutions']",True,"['Generative AI', 'Large Language Models', 'Prompt Engineering', 'Deep Learning Frameworks for AI']","Generative AI: Developing application-specific interfaces leveraging generative AI capabilities to enhance associate and customer experiences.; Large Language Models: Utilizing LLMs and foundation models (FMs) as part of AI solutions to improve user interactions and business processes.; Prompt Engineering: Translating user requirements into AI solutions involving prompt design and optimization for generative AI models.; Deep Learning Frameworks for AI: Using frameworks such as TensorFlow, PyTorch, and Keras specifically for building and deploying neural network-based AI models including NLP and computer vision.","['Statistical Methods', 'Machine Learning', 'Deep Learning', 'Natural Language Processing', 'Computer Vision', 'Feature Engineering and Data Integration', 'Python and R', 'Databases', 'Cloud Environments', 'Data Visualization', 'Ethical Data Science Practices', 'ServiceNow and Salesforce Integration']","Statistical Methods: Used for data analysis, exploratory data analysis (EDA), hypothesis testing, and drawing meaningful conclusions to support business decisions.; Machine Learning: Building analytical and statistical machine learning models including supervised, unsupervised, and reinforcement learning algorithms for classification, regression, clustering, predictive and prescriptive modeling, and automated root cause analysis.; Deep Learning: Applied deep learning methods to solve business problems including model training and development using frameworks like TensorFlow, PyTorch, and Keras.; Natural Language Processing: Applied NLP techniques such as sentiment analysis, topic modeling, and graph theory in real-world applications to extract insights and solve business problems.; Computer Vision: Utilized computer vision methods as part of machine learning applications to address business challenges.; Feature Engineering and Data Integration: Experience reading data from multiple sources including databases, files, APIs, and server logs, cleansing, enhancing, and integrating data for analysis and model building.; Python and R: Extensive use of Python libraries and R for univariate and bivariate analysis, building advanced machine learning models, and data science tasks.; Databases: Experience with relational databases such as Postgres, Redshift, and MSSQL for data storage, querying, and integration.; Cloud Environments: Knowledge and experience working with cloud platforms including Azure, AWS, and Google Cloud Platform for data storage, processing, and deployment of data science solutions.; Data Visualization: Training machine learning models to communicate complex data insights through clear and informative visualizations.; Ethical Data Science Practices: Incorporating bias detection, fairness, and responsible data handling into data science models and workflows.; ServiceNow and Salesforce Integration: Enabling AI and analytics solutions within core technologies such as ServiceNow and Salesforce to enhance internal and external user experiences."
ON9FoPBRATzj3HmNAAAAAA==,Mid-Level Data Scientist / Quant - Risk & Trading,"About Sleeper

Sleeper is one of the fastest-growing sports platforms in the US. We build free‑to‑play fantasy titles and real‑money Daily Fantasy Sports (DFS) games across the NFL, NBA/WNBA, MLB, NHL, EU football, and more. Our Risk & Trading team safeguards game integrity and optimizes profitability through data‑driven pricing and exposure management.

What You'll Be Doing
• Feature engineering & model tuning - Own the pipelines that transform raw bet, player, and market data into features for our pricing and exposure models (BigQuery + SQLX, Python, Pandas).
• Predictive modeling - Train, validate, and deploy supervised and probabilistic models that forecast player performance, market volatility, and user value.
• Guardrail automation - Ship rule‑based limiters and anomaly‑detection jobs that run every few seconds, flagging and throttling outlier exposure before it becomes tail risk.
• Dashboards & alerting - Build Grafana dashboards and SQLX reports that surface live liability, promo uptake, and top‑line KPIs to trading and exec stakeholders.
• Light on‑call rotation - During peak sports windows, respond to automated alerts and, if necessary, execute a manual override (price suspension / limit change). < 2 hrs/wk on average.
• Cross‑functional collaboration - Pair with Backend & Data Engineers to productionize models, and with Product to iterate on game mechanics and promos.

Who You Are
• 3‑5 years in data science, machine learning, or quant research; comfortable owning end‑to‑end projects.
• Fluent in Python, SQL, and modern ML tooling (scikit‑learn, XGBoost, Airflow or similar).
• Familiar with sports data and the economics of fantasy / sportsbook markets; plus if you've built pricing or risk models.
• Systems thinker who anticipates failure modes and edge cases in real‑time environments.
• Willing to flex hours around major game slates; we're a remote‑first team and optimize schedules for coverage & work‑life balance.

Nice‑to‑Haves
• Experience with BigQuery, Looker, dbt, or similar analytics stacks.
• Exposure to real‑time streams (Kafka, Pub/Sub) and event‑driven architectures.
• Prior work building user‑level segmentation or LTV models.

Compensation

In the United States, the reasonable base salary range for this role is $90 000 - $175 000 USD, plus equity and benefits (medical, dental, vision, PTO, 401k). Final offers consider experience, skills, and market data.

Benefits
• Competitive salary and stock options
• Comprehensive health, dental, and vision insurance
• 401(k)
• Flexible working hours and remote-first culture
• Clear paths for career growth and leadership

What we offer

Sleeper believes in quality over quantity, and intentionally keeps our team small as a result. In past roles, we found it very hard to make a big impact when companies grow too large in size, which has a detrimental effect on the product and the impact any single individual can have. Our team includes designers, engineers, product experts, and finance & operation focused on one thing - connecting people over sports. We believe in fair and equitable pay. Certain locations in the United States require job postings to include a reasonable estimate of the base salary range and/or a general description of benefits and other compensation applicable to the role.

Competitive salary plus benefits including Medical, Dental, PTO, 401k. Please note that The salary range for this role takes into account a wide range of factors that are considered in making compensation decisions including, but not limited to, skill sets; experience and training; licensure and certifications; and other business and organizational needs. The policy of Sleeper is to provide equal employment opportunities to all applicants and employees without regard to race, color, creed, religion, sex, sexual orientation, gender identity, marital status, citizenship status, age, national origin, ancestry, disability, veteran status, or any other legally protected status and to affirmatively seek to advance the principles of equal employment opportunity. Sleeper is committed to being an Equal Opportunity Employer and offers opportunities to all job seekers, including job seekers with disabilities. If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access the Company's career webpage as a result of your disability. You may request reasonable accommodations by sending an email to jobs@sleeper.app.

Headquartered in Las Vegas, NV, Sleeper is backed by Silicon Valley's top investors, including Andreessen Horowitz, General Catalyst, and Expa.
To learn more, visit us online at: www.sleeper.com",2025-06-26T00:00:00.000Z,2025-07-25,"['3‑5 years in data science, machine learning, or quant research; comfortable owning end‑to‑end projects', 'Fluent in Python, SQL, and modern ML tooling (scikit‑learn, XGBoost, Airflow or similar)', ""Familiar with sports data and the economics of fantasy / sportsbook markets; plus if you've built pricing or risk models"", 'Experience with BigQuery, Looker, dbt, or similar analytics stacks', 'Exposure to real‑time streams (Kafka, Pub/Sub) and event‑driven architectures', 'Prior work building user‑level segmentation or LTV models']","['Our Risk & Trading team safeguards game integrity and optimizes profitability through data‑driven pricing and exposure management', 'Feature engineering & model tuning - Own the pipelines that transform raw bet, player, and market data into features for our pricing and exposure models (BigQuery + SQLX, Python, Pandas)', 'Predictive modeling - Train, validate, and deploy supervised and probabilistic models that forecast player performance, market volatility, and user value', 'Guardrail automation - Ship rule‑based limiters and anomaly‑detection jobs that run every few seconds, flagging and throttling outlier exposure before it becomes tail risk', 'Dashboards & alerting - Build Grafana dashboards and SQLX reports that surface live liability, promo uptake, and top‑line KPIs to trading and exec stakeholders', 'Light on‑call rotation - During peak sports windows, respond to automated alerts and, if necessary, execute a manual override (price suspension / limit change)', '< 2 hrs/wk on average', 'Systems thinker who anticipates failure modes and edge cases in real‑time environments', ""Willing to flex hours around major game slates; we're a remote‑first team and optimize schedules for coverage & work‑life balance""]",True,[],,"['Feature Engineering', 'Predictive Modeling', 'Anomaly Detection', 'Dashboards and Reporting', 'SQL and BigQuery', 'Python and Pandas', 'Machine Learning Tooling', 'Data Pipelines and Workflow Orchestration', 'Real-time Data Streaming', 'User Segmentation and Lifetime Value Modeling', 'Looker and dbt']","Feature Engineering: Responsible for building data pipelines that transform raw bet, player, and market data into features used for pricing and exposure models.; Predictive Modeling: Train, validate, and deploy supervised and probabilistic models to forecast player performance, market volatility, and user value.; Anomaly Detection: Develop rule-based limiters and anomaly-detection jobs that run frequently to flag and throttle outlier exposure, preventing tail risk.; Dashboards and Reporting: Build Grafana dashboards and SQLX reports to surface live liability, promotional uptake, and key performance indicators for trading and executive stakeholders.; SQL and BigQuery: Use SQLX and BigQuery for data querying and transformation within feature engineering and reporting pipelines.; Python and Pandas: Utilize Python and Pandas for data manipulation, feature engineering, and model development.; Machine Learning Tooling: Apply modern machine learning tools such as scikit-learn and XGBoost for model training and tuning.; Data Pipelines and Workflow Orchestration: Use Airflow or similar tools to manage and automate data workflows and model pipelines.; Real-time Data Streaming: Experience with real-time data streams and event-driven architectures using Kafka or Pub/Sub to support timely data processing and alerting.; User Segmentation and Lifetime Value Modeling: Build user-level segmentation and lifetime value (LTV) models to support business insights and decision-making.; Looker and dbt: Experience with analytics stacks such as Looker and dbt for data modeling, transformation, and visualization."
fqFG2JFX5aevR7w_AAAAAA==,Junior Data Scientist - Remote,"For more than 12 years Synergisticit has helped Jobseekers stand out from other Jobseekers by providing candidates the requisite skills, experience and technical competence to outperform at interviews and at clients. Here at SynergisticIT We just don't focus on getting you a tech Job we make careers.

In this market also our candidates get multiple job offers and $100k + salaries.

please check the below links to see success outcomes of our candidates .

https://www.synergisticit.com/candidate-outcomes/

https://reg.rf.oracle.com/flow/oracle/cwoh23/OCWExhibitorCatalog/page/OCWexhibitorcatalog

We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please see us exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023

All Positions are open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.

We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

https://www.youtube.com/watch?v=OFoqPTNORew

https://www.youtube.com/watch?v=-HkNN1ag6Zk

https://www.youtube.com/watch?v=OAFOhcGy9Z8

https://youtu.be/bJJl27D8bh0

We want Data Science/Machine learning/Data Analyst and Java Full stack candidates

For data Science/Machine learning Positions

REQUIRED SKILLS

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Project work on the technologies needed

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools

Excellent written and verbal communication skills

Preferred skills: NLP, Text mining, Tableau, PowerBI, Databricks, Tensorflow

REQUIRED SKILLS For Java /Full stack/Software Positions

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Project work on the skills

Knowledge of Core Java , javascript , C++ or software programming

Spring boot, Microservices, Docker, Jenkins and REST API's experience

Excellent written and verbal communication skills

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",,2025-07-25,"['Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry', 'We want Data Science/Machine learning/Data Analyst and Java Full stack candidates', 'For data Science/Machine learning Positions', 'Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT', 'Project work on the technologies needed', 'Highly motivated, self-learner, and technically inquisitive', 'Experience in programming language Java and understanding of the software development life cycle', 'Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools', 'Excellent written and verbal communication skills', 'REQUIRED SKILLS For Java /Full stack/Software Positions', 'Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT', 'Highly motivated, self-learner, and technically inquisitive', 'Experience in programming language Java and understanding of the software development life cycle', 'Project work on the skills', 'Knowledge of Core Java , javascript , C++ or software programming', ""Spring boot, Microservices, Docker, Jenkins and REST API's experience"", 'Excellent written and verbal communication skills']",,True,['TensorFlow'],"TensorFlow: TensorFlow is a preferred skill, indicating use of this deep learning framework for building and training neural network models.","['Statistics', 'SAS', 'Python', 'Data Visualization Tools', 'NLP', 'Text Mining', 'Tableau', 'Power BI', 'Databricks', 'Machine Learning', 'Computer Vision', 'Java Programming']","Statistics: Knowledge of statistics is required for data science and machine learning positions to analyze and interpret data effectively.; SAS: Experience with SAS is mentioned as a required skill, indicating its use for statistical analysis or data management in the role.; Python: Python programming is required, likely for data analysis, scripting, and implementing machine learning models.; Data Visualization Tools: Familiarity with data visualization tools is preferred, suggesting responsibilities involving creating visual representations of data insights.; NLP: Natural Language Processing is a preferred skill, indicating potential work with text mining or language data analysis.; Text Mining: Text mining is listed as a preferred skill, implying analysis and extraction of information from text data.; Tableau: Tableau is a preferred data visualization tool mentioned for creating interactive dashboards and reports.; Power BI: Power BI is another preferred business intelligence tool for data visualization and reporting.; Databricks: Databricks is preferred, indicating use of this platform for big data processing and collaborative data science workflows.; Machine Learning: Machine learning is a key focus area, with candidates expected to have knowledge or experience in this field.; Computer Vision: Computer vision knowledge is required, suggesting work involving image or video data analysis.; Java Programming: Experience in Java programming is required, relevant for software development and possibly data engineering tasks."
_Lvr-60CKa0fuda6AAAAAA==,"Principal Data Scientist - Generative AI, Machine Learning, Python, R - Remote","Job Description

Job Summary

Responsible for overseeing data science projects, managing and mentoring a team, and aligning data initiatives with business goals. Lead the development and implementation of data models, collaborate with cross-functional teams, and stay updated on industry trends. Ensure ethical data use and communicate complex technical concepts to non-technical stakeholders. Lead initiatives on model governance and model ops to align with regulatory and security requirements. This role requires technical expertise, strategic thinking, and leadership to drive data-driven decision-making within the organization and be the pioneer on generative AI healthcare solutions, aimed at revolutionizing healthcare operations as well as enhancing member experience.

Job Duties

• Research and Development: Stay current with the latest advancements in AI and machine learning and apply these insights to improve existing models and develop new methodologies.
• AI Model Deployment, Monitoring & Model Governance: Deploy AI models into production environments, monitor their performance, and adjust as necessary to maintain accuracy and effectiveness and meet all governance and regulatory requirements.
• Innovation Projects: Lead pilot projects to test and implement new AI technologies within the organization
• Data Analysis and Interpretation: Extract meaningful insights from complex datasets, identify patterns, and interpret data to inform strategic decision-making.
• Machine Learning Model Development: Design, develop, and train machine learning models using a variety of algorithms and techniques, including supervised and unsupervised learning, deep learning, and reinforcement learning.
• Agentic Workflows Implementation: Develop and implement agentic workflows that utilize AI agents for autonomous task execution, enhancing operational efficiency and decision-making capabilities.
• RAG Pattern Utilization: Employ retrieval-augmented generation patterns to improve the performance of language models, ensuring they can access and utilize external knowledge effectively to enhance their outputs.
• Model Fine-Tuning: Fine-tune pre-trained models to adapt them to specific tasks or datasets, ensuring optimal performance and relevance in various applications.
• Data Cleaning and Preprocessing: Prepare data for analysis by performing data cleaning, handling missing values, and removing outliers to ensure high-quality inputs for modeling.
• Collaboration: Work closely with cross-functional teams, including software engineers, product managers, and business analysts, to integrate AI solutions into existing systems and processes.
• Documentation and Reporting: Create comprehensive documentation of models, methodologies, and results; communicate findings clearly to non-technical stakeholders.
• Mentors, coaches, and provides guidance to newer data scientists.
• Partner closely with business and other technology teams to build ML models which helps in improving Star ratings, reduce care gap and other business objectives.
• Present complex analytical information to all level of audiences in a clear and concise manner Collaborate with analytics team, assigning and managing delivery of analytical projects as appropriate
• Perform other duties as business requirements change, looking out for data solutions and technology enabled solution opportunities and make referrals to the appropriate team members in building out payment integrity solutions.
• Use a broad range of tools and techniques to extract insights from current industry or sector trends

Job Qualifications

REQUIRED EDUCATION:

Master’s Degree in Computer Science, Data Science, Statistics, or a related field

REQUIRED EXPERIENCE/KNOWLEDGE, SKILLS & ABILITIES:

• 10+ years’ work experience as a data scientist preferably in healthcare environment but candidates with suitable experience in other industries will be considered
• Knowledge of big data technologies (e.g., Hadoop, Spark)
• Familiar with relational database concepts, and SDLC concepts
• Demonstrate critical thinking and the ability to bring order to unstructured problems
• Technical Proficiency: Strong programming skills in languages such as Python and R, and experience with machine learning frameworks like TensorFlow, Keras, or PyTorch.
• Statistical Analysis: Excellent understanding of statistical methods and machine learning algorithms, including k-NN, Naive Bayes, SVM, and neural networks.
• Experience with Agentic Workflows: Familiarity with designing and implementing agentic workflows that leverage AI agents for autonomous operations.
• RAG Techniques: Knowledge of retrieval-augmented generation techniques and their application in enhancing AI model outputs.
• Model Fine-Tuning Expertise: Proven experience in fine-tuning models for specific tasks, ensuring they meet the required performance metrics.
• Data Visualization: Proficiency in data visualization tools (e.g., Tableau, Power BI) to present complex data insights effectively.
• Database Management: Experience with SQL and NoSQL databases, data warehousing, and ETL processes.
• Problem-Solving Skills: Strong analytical and problem-solving abilities, with a focus on developing innovative solutions to complex challenges.

PREFERRED EDUCATION:

PHD or additional experience

PREFERRED EXPERIENCE:

• Experience with cloud platforms (e.g., Databricks, Snowflake, Azure AI Studio etc.) for working with AI workflows and deploying models.
• Familiarity with natural language processing (NLP) and computer vision techniques.

#PJCorp2

#LI-AC1

To all current Molina employees: If you are interested in applying for this position, please apply through the intranet job listing.

Molina Healthcare offers a competitive benefits and compensation package. Molina Healthcare is an Equal Opportunity Employer (EOE) M/F/D/V.",2025-07-11T00:00:00.000Z,2025-07-25,"['Master’s Degree in Computer Science, Data Science, Statistics, or a related field', '10+ years’ work experience as a data scientist preferably in healthcare environment but candidates with suitable experience in other industries will be considered', 'Knowledge of big data technologies (e.g., Hadoop, Spark)', 'Familiar with relational database concepts, and SDLC concepts', 'Demonstrate critical thinking and the ability to bring order to unstructured problems', 'Technical Proficiency: Strong programming skills in languages such as Python and R, and experience with machine learning frameworks like TensorFlow, Keras, or PyTorch', 'Statistical Analysis: Excellent understanding of statistical methods and machine learning algorithms, including k-NN, Naive Bayes, SVM, and neural networks', 'Experience with Agentic Workflows: Familiarity with designing and implementing agentic workflows that leverage AI agents for autonomous operations', 'RAG Techniques: Knowledge of retrieval-augmented generation techniques and their application in enhancing AI model outputs', 'Model Fine-Tuning Expertise: Proven experience in fine-tuning models for specific tasks, ensuring they meet the required performance metrics', 'Data Visualization: Proficiency in data visualization tools (e.g., Tableau, Power BI) to present complex data insights effectively', 'Database Management: Experience with SQL and NoSQL databases, data warehousing, and ETL processes', 'Problem-Solving Skills: Strong analytical and problem-solving abilities, with a focus on developing innovative solutions to complex challenges', 'PHD or additional experience']","['Responsible for overseeing data science projects, managing and mentoring a team, and aligning data initiatives with business goals', 'Lead the development and implementation of data models, collaborate with cross-functional teams, and stay updated on industry trends', 'Ensure ethical data use and communicate complex technical concepts to non-technical stakeholders', 'Lead initiatives on model governance and model ops to align with regulatory and security requirements', 'This role requires technical expertise, strategic thinking, and leadership to drive data-driven decision-making within the organization and be the pioneer on generative AI healthcare solutions, aimed at revolutionizing healthcare operations as well as enhancing member experience', 'Research and Development: Stay current with the latest advancements in AI and machine learning and apply these insights to improve existing models and develop new methodologies', 'AI Model Deployment, Monitoring & Model Governance: Deploy AI models into production environments, monitor their performance, and adjust as necessary to maintain accuracy and effectiveness and meet all governance and regulatory requirements', 'Innovation Projects: Lead pilot projects to test and implement new AI technologies within the organization', 'Data Analysis and Interpretation: Extract meaningful insights from complex datasets, identify patterns, and interpret data to inform strategic decision-making', 'Machine Learning Model Development: Design, develop, and train machine learning models using a variety of algorithms and techniques, including supervised and unsupervised learning, deep learning, and reinforcement learning', 'Agentic Workflows Implementation: Develop and implement agentic workflows that utilize AI agents for autonomous task execution, enhancing operational efficiency and decision-making capabilities', 'RAG Pattern Utilization: Employ retrieval-augmented generation patterns to improve the performance of language models, ensuring they can access and utilize external knowledge effectively to enhance their outputs', 'Model Fine-Tuning: Fine-tune pre-trained models to adapt them to specific tasks or datasets, ensuring optimal performance and relevance in various applications', 'Data Cleaning and Preprocessing: Prepare data for analysis by performing data cleaning, handling missing values, and removing outliers to ensure high-quality inputs for modeling', 'Collaboration: Work closely with cross-functional teams, including software engineers, product managers, and business analysts, to integrate AI solutions into existing systems and processes', 'Documentation and Reporting: Create comprehensive documentation of models, methodologies, and results; communicate findings clearly to non-technical stakeholders', 'Mentors, coaches, and provides guidance to newer data scientists', 'Partner closely with business and other technology teams to build ML models which helps in improving Star ratings, reduce care gap and other business objectives', 'Present complex analytical information to all level of audiences in a clear and concise manner Collaborate with analytics team, assigning and managing delivery of analytical projects as appropriate', 'Perform other duties as business requirements change, looking out for data solutions and technology enabled solution opportunities and make referrals to the appropriate team members in building out payment integrity solutions', 'Use a broad range of tools and techniques to extract insights from current industry or sector trends']",True,"['Generative AI', 'Agentic Workflows', 'Retrieval-Augmented Generation', 'Model Fine-Tuning', 'AI Model Deployment and Monitoring', 'Natural Language Processing and Computer Vision']","Generative AI: Pioneer generative AI healthcare solutions aimed at revolutionizing healthcare operations and enhancing member experience by developing and deploying advanced AI models.; Agentic Workflows: Develop and implement agentic workflows that utilize AI agents for autonomous task execution, improving operational efficiency and decision-making capabilities.; Retrieval-Augmented Generation: Employ retrieval-augmented generation techniques to enhance language model performance by enabling access to and utilization of external knowledge sources.; Model Fine-Tuning: Fine-tune pre-trained AI models to adapt them to specific healthcare tasks or datasets, ensuring optimal performance and relevance.; AI Model Deployment and Monitoring: Deploy AI models into production environments, monitor their performance continuously, and adjust as necessary to maintain accuracy, effectiveness, and compliance with governance and regulatory requirements.; Natural Language Processing and Computer Vision: Apply NLP and computer vision techniques within AI workflows to support healthcare applications and improve model capabilities.","['Machine Learning', 'Deep Learning', 'Reinforcement Learning', 'Statistical Methods', 'Data Cleaning and Preprocessing', 'Feature Engineering', 'Data Visualization', 'SQL and NoSQL Databases', 'Big Data Technologies', 'Python and R Programming', 'Machine Learning Frameworks', 'Model Governance and Model Ops']","Machine Learning: Design, develop, and train machine learning models using a variety of algorithms and techniques, including supervised and unsupervised learning, to support healthcare and business objectives.; Deep Learning: Apply deep learning techniques, including neural networks, to develop advanced predictive models and improve healthcare operations.; Reinforcement Learning: Utilize reinforcement learning methods to enhance machine learning models and support autonomous decision-making workflows.; Statistical Methods: Employ statistical analysis techniques such as k-NN, Naive Bayes, and SVM to analyze data and build predictive models.; Data Cleaning and Preprocessing: Prepare data for analysis by performing data cleaning, handling missing values, and removing outliers to ensure high-quality inputs for modeling.; Feature Engineering: Develop and implement feature engineering techniques as part of the machine learning model development process to improve model performance.; Data Visualization: Use data visualization tools like Tableau and Power BI to present complex data insights effectively to stakeholders.; SQL and NoSQL Databases: Manage and utilize SQL and NoSQL databases, data warehousing, and ETL processes to support data storage and retrieval for analytics and modeling.; Big Data Technologies: Leverage big data technologies such as Hadoop and Spark to process and analyze large healthcare datasets.; Python and R Programming: Use Python and R programming languages for data analysis, statistical modeling, and machine learning model development.; Machine Learning Frameworks: Utilize machine learning frameworks including TensorFlow, Keras, and PyTorch to build and train models.; Model Governance and Model Ops: Lead initiatives on model governance and model operations to ensure models meet regulatory and security requirements and maintain accuracy and effectiveness in production."
d96-yMLRAA3mGfySAAAAAA==,Entry Level Data Analyst/Scientist,"For more than 12 years Synergisticit has helped Jobseekers stand out from other Jobseekers by providing candidates the requisite skills, experience and technical competence to outperform at interviews and at clients. Here at SynergisticIT We just don't focus on getting you a tech Job we make careers.

In this market also our candidates get multiple job offers and $100k + salaries.

please check the below links to see success outcomes of our candidates .

https://www.synergisticit.com/candidate-outcomes/

https://reg.rf.oracle.com/flow/oracle/cwoh23/OCWExhibitorCatalog/page/OCWexhibitorcatalog

We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please see us exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023

All Positions are open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.

We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

https://www.youtube.com/watch?v=OFoqPTNORew

https://www.youtube.com/watch?v=-HkNN1ag6Zk

https://www.youtube.com/watch?v=OAFOhcGy9Z8

https://youtu.be/bJJl27D8bh0

We want Data Science/Machine learning/Data Analyst and Java Full stack candidates

For data Science/Machine learning Positions

REQUIRED SKILLS

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Project work on the technologies needed

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools

Excellent written and verbal communication skills

Preferred skills: NLP, Text mining, Tableau, PowerBI, Databricks, Tensorflow

REQUIRED SKILLS For Java /Full stack/Software Positions

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Project work on the skills

Knowledge of Core Java , javascript , C++ or software programming

Spring boot, Microservices, Docker, Jenkins and REST API's experience

Excellent written and verbal communication skills

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",,2025-07-25,"['Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry', 'We want Data Science/Machine learning/Data Analyst and Java Full stack candidates', 'For data Science/Machine learning Positions', 'Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT', 'Project work on the technologies needed', 'Highly motivated, self-learner, and technically inquisitive', 'Experience in programming language Java and understanding of the software development life cycle', 'Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools', 'Excellent written and verbal communication skills', 'REQUIRED SKILLS For Java /Full stack/Software Positions', 'Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT', 'Highly motivated, self-learner, and technically inquisitive', 'Experience in programming language Java and understanding of the software development life cycle', 'Project work on the skills', 'Knowledge of Core Java , javascript , C++ or software programming', ""Spring boot, Microservices, Docker, Jenkins and REST API's experience"", 'Excellent written and verbal communication skills']",,True,['TensorFlow'],"TensorFlow: TensorFlow is preferred as a skill, indicating use of this deep learning framework for building AI models, likely neural networks, in data science and machine learning roles.","['Statistics', 'SAS', 'Python', 'Data Visualization Tools', 'Computer Vision', 'NLP (Natural Language Processing)', 'Databricks', 'Machine Learning']","Statistics: Knowledge of statistics is required for data science and data analyst roles to analyze and interpret data effectively.; SAS: Experience with SAS is needed for statistical analysis and data management tasks in data science positions.; Python: Python programming skills are required for data manipulation, analysis, and building data science projects.; Data Visualization Tools: Familiarity with data visualization tools like Tableau and PowerBI is preferred to create dashboards and visual insights from data.; Computer Vision: Knowledge of computer vision is mentioned as a skill relevant to data science roles, indicating work with image or video data analysis.; NLP (Natural Language Processing): NLP is preferred as a skill, indicating text mining and analysis capabilities relevant to data science tasks.; Databricks: Experience with Databricks is preferred, suggesting use of this platform for big data processing and analytics.; Machine Learning: Machine learning knowledge is required for data science and machine learning engineer positions to build predictive models and algorithms."
56LS-3FzhsqSA6rWAAAAAA==,"(USA) Principal, Data Scientist","Position Summary...

What you'll do...

This is an exciting opportunity to join our Sams Club Product Operations Data Science team, where you will unlock member and associate insights for our product managers.

About the Sams Club Product Operations Data Science Team

The team focusses on measuring the impact of our strategic product initiatives and better connecting insights across our Product Organization. We want to enhance the speed and quality of planning within our top-notch product management function and what better place to do that than in an organization that is Product Led, Data Driven and Member Obsessed.

What you'll do:
• Provide a macro view of product-driven value to our Executive Team; creating and measuring metrics that matter and being able to tell a compelling story
• Give easy access to voice-of-the-member ; voice-of-the-associate to our product managers; dishing it up in a way that is easy to draw insights from.
• Focus on input/leading indicators and being able to demonstrate impact to output/lagging indicators.
• Establish connectivity of our data ; insights; taking advantage of all touch points with our members, showing how our work complements each other to help drive operational fixes, backlog advancement and more strategic product solutions.
• Identify high impact and return on investment opportunities.
• Build and fostering collaborative relationships with key partners (business leaders, UX, Engineering) by driving priorities across business pillars and role modeling transparency.

What you'll bring:
• Strong Technical Skills: Causal Analysis, Experimentation, Statistics, SQL, Python, R
• Ability to connect the dots: Be a strategic advisor to technology partners and can understand the business problem, the product-based solution and connect it to an analytic methodology.
• Great Collaborator: Work with stakeholders such as product managers, engineering, sister analytics teams, User Experience, and business teams
• Demonstrates Good Judgement: This is a senior role and will influence senior leadership. Minimum 10 years of experience in a data science role
• Strong Retail Experience is a plus: Experience in data science in supply chain, merchandising, in-club analytics, operations, and e Commerce.

The above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.

Benefits ; Perks:

Beyond great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.
Equal Opportunity Employer:

Sams Club is an Equal Opportunity Employer- By Choice. We believe we are best equipped to help our associates, customers, and the communities we serve live better when we really know them. That means understanding, respecting, and valuing unique styles, experiences, identities, abilities, ideas and opinions- while being welcoming of all people.

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

‎

‎

‎
You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.

‎

For information about PTO, see https://one.walmart.com/notices.

‎

‎
Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

‎
Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

‎

For information about benefits and eligibility, see One.Walmart.

‎
The annual salary range for this position is $143,000.00-$286,000.00

‎
Additional compensation includes annual or quarterly performance bonuses.

‎
Additional compensation for certain positions may also include:

‎

‎
- Stock

‎

‎

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 5 years' experience in an analytics related field. Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 3 years' experience in an analytics related field. Option 3: 7 years' experience in an analytics or related field

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data science, machine learning, optimization models, PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Publications or active peer reviewer in related journals or conference, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.

Primary Location...

850 Cherry Avenue, San Bruno, CA 94066-3031, United States of America",2025-07-20T00:00:00.000Z,2025-07-25,"['Strong Technical Skills: Causal Analysis, Experimentation, Statistics, SQL, Python, R', 'Ability to connect the dots: Be a strategic advisor to technology partners and can understand the business problem, the product-based solution and connect it to an analytic methodology', 'Great Collaborator: Work with stakeholders such as product managers, engineering, sister analytics teams, User Experience, and business teams', 'Demonstrates Good Judgement: This is a senior role and will influence senior leadership', 'Minimum 10 years of experience in a data science role', 'That means understanding, respecting, and valuing unique styles, experiences, identities, abilities, ideas and opinions- while being welcoming of all people', ""Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 5 years' experience in an analytics related field"", ""Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 3 years' experience in an analytics related field"", ""Option 3: 7 years' experience in an analytics or related field"", 'Data science, machine learning, optimization models, PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Publications or active peer reviewer in related journals or conference, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly', 'The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture']","['We want to enhance the speed and quality of planning within our top-notch product management function and what better place to do that than in an organization that is Product Led, Data Driven and Member Obsessed', 'Provide a macro view of product-driven value to our Executive Team; creating and measuring metrics that matter and being able to tell a compelling story', 'Give easy access to voice-of-the-member ; voice-of-the-associate to our product managers; dishing it up in a way that is easy to draw insights from', 'Focus on input/leading indicators and being able to demonstrate impact to output/lagging indicators', 'Establish connectivity of our data ; insights; taking advantage of all touch points with our members, showing how our work complements each other to help drive operational fixes, backlog advancement and more strategic product solutions', 'Identify high impact and return on investment opportunities', 'Build and fostering collaborative relationships with key partners (business leaders, UX, Engineering) by driving priorities across business pillars and role modeling transparency']",True,[],,"['Causal Analysis', 'Experimentation', 'Statistics', 'SQL', 'Python', 'R', 'Data Science', 'Machine Learning', 'Optimization Models', 'Spark', 'Scala', 'Scikit-learn', 'TensorFlow', 'Torch']","Causal Analysis: Used as a technical skill to understand cause-effect relationships in data to inform product and business decisions.; Experimentation: Applied to design and analyze experiments to measure the impact of product initiatives and validate hypotheses.; Statistics: Fundamental for analyzing data, measuring metrics, and supporting data-driven decision making in product operations.; SQL: Used to query and manage data from databases to provide insights and support analytics workflows.; Python: A programming language employed for data analysis, statistical modeling, and building data science solutions.; R: A programming language used for statistical computing and data analysis within the data science team.; Data Science: The core discipline applied to extract insights from data, measure product impact, and support strategic decision making.; Machine Learning: Mentioned as a preferred qualification, indicating use of predictive and optimization models to enhance product and business outcomes.; Optimization Models: Used to improve product and operational decisions by mathematically optimizing key metrics and processes.; Spark: Referenced as a technology for big data processing and analytics, supporting scalable data workflows.; Scala: Mentioned as a language for data engineering and analytics, often used with Spark for large-scale data processing.; Scikit-learn: An open source machine learning framework used for building predictive models and data analysis.; TensorFlow: Listed as an open source framework, likely for machine learning model development and experimentation.; Torch: Included as an open source framework, used for machine learning and statistical modeling tasks."
27OjGwBBtqXGdv6PAAAAAA==,"Data Scientist, Infrastructure Finance (Technical Leadership)","Data Scientist, Infrastructure Finance (Technical Leadership)Join to apply for the Data Scientist, Infrastructure Finance (Technical Leadership) role at MetaData Scientist, Infrastructure Finance (Technical Leadership)1 day ago Be among the first 25 applicantsJoin to apply for the Data Scientist, Infrastructure Finance (Technical Leadership) role at MetaThis range is provided by Meta. Your actual pay will be based on your skills and experience — talk with your recruiter to learn more.Base pay range$206,000.00/yr - $281,000.00/yrMeta is seeking a Data Scientist to join a newly formed team in the Finance organization that partners very closely with Product, AI, Infrastructure, Finance and other Data Science teams across the company. These teams are building some of the most cutting edge and transformative AI products in the world that are being rolled out to Meta’s 3 Billion+ users. Building these products and features requires tens of billions of dollars of capital each year over a sustained period of time. Managing and optimizing the deployment of this vast capital and the allocation of these resources requires a team that has technical expertise in AI and Infrastructure along with a solid understanding of data science, finance and operations. We are building this team in recognition of the importance of AI and Infrastructure from a product perspective as well as the need to be efficient in our approach to deploying capital and generating returns for our shareholders. This position will use data and analysis to identify and solve product development's biggest challenges and will require one to understand the technical aspects of how AI and Infrastructure are built, operated and used to serve users. This role will help establish the ROI and company-wide prioritization of such investments and work on solving some of the most important technological problems of our times and also ensure that the company makes efficient investments. As an individual contributor, you will influence product strategy and investment decisions with data, be focused on impact, and collaborate with other teams. By joining Meta, you will become part of a world-class analytics community dedicated to skill development and career growth in analytics and beyond.Data Scientist, Infrastructure Finance (Technical Leadership) Responsibilities:Work with large and complex data sets to solve a wide array of challenging problems using different analytical and statistical approachesApply technical expertise with quantitative analysis, experimentation, data mining, and the presentation of data to build and maintain end-to-end models for long range planning and strategic decisionsBuild models to compute and explain Infrastructure OPEX and CAPEX costs at the company, product and resource levelsLeverage understanding of AI and Infrastructure to develop independent point-of-view on ROI of investments in Infrastructure and allocation of Infrastructure resources to various products and software platformsIdentify and measure success infrastructure investments through goal setting, forecasting, and monitoring of key metrics to understand trendsHelp define resource allocation policies that are reasonable and actionable from a technical, operational and financial perspectiveWork with product, engineering and data science teams to do technical, operational and business impact assessments of reallocation of resources based on changing business needs, competitive landscape and product roadmapsMaintain lineage of decisions around Infrastructure investments and assumptions under which those decisions were made to drive accountability for outcomes across the companyDefine, understand, and test opportunities and levers to improve our models, and drive roadmaps through your insights and recommendationsPartner with Product, Engineering, and cross-functional teams to inform, influence, support, and execute product strategy and investment decisionsMinimum Qualifications:Bachelor's degree in a directly related field, or equivalent practical experienceA minimum of 12 years of work experience in analytics (minimum of 8 years with a Ph.D.)Bachelor's degree in Mathematics, Statistics, a relevant technical field, or equivalent practical experienceExperience with data querying languages (e.g., SQL), scripting languages (e.g., Python), and/or statistical/mathematical software (e.g., R)Preferred Qualifications:Master's or Ph.D. degree in a quantitative fieldExperience working in a data science role at a hyperscaler, public cloud, and/or a customer of a public cloud companyExperience partnering cross-functionally with a wide range of teams, deal with ambiguity and present technical content in an easy to understand manner to technical and non-technical teamsCuriosity about the inter-relationship between business outcomes and technology investments and experience translating this to practical models for decision makingAbout Meta:Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.$206,000/year to $281,000/year + bonus + equity + benefitsIndividual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.Seniority levelSeniority levelNot ApplicableEmployment typeEmployment typeFull-timeJob functionJob functionEngineering and Information TechnologyIndustriesTechnology, Information and InternetReferrals increase your chances of interviewing at Meta by 2xGet notified about new Data Scientist jobs in Menlo Park, CA.AI Machine Learning Engineer II (Full Time) United StatesSan Jose, CA $195,800.00-$195,800.00 2 weeks agoSan Jose, CA $123,500.00-$212,850.00 3 weeks agoRedwood City, CA $80,000.00-$120,000.00 15 hours agoData Scientist, Generative AI & LLM AgentsSan Bruno, CA $119,000.00-$169,000.00 2 days agoMountain View, CA $132,000.00-$189,000.00 21 hours agoRedwood City, CA $123,000.00-$185,000.00 6 months agoSunnyvale, CA $114,000.00-$171,000.00 3 days agoSan Jose, CA $123,500.00-$212,850.00 17 hours agoSunnyvale, CA $46.63-$134,000.00 3 days agoMountain View, CA $136,301.00-$172,486.00 1 day agoSan Jose, CA $123,500.00-$212,850.00 2 weeks agoFremont, CA $145,000.00-$204,000.00 3 days agoApplied Scientist / Machine Learning Engineer, Software Engineer (Machine Learning)San Jose, CA $123,500.00-$212,850.00 2 weeks agoSan Jose, CA $123,500.00-$212,850.00 1 week agoWe’re unlocking community knowledge in a new way. Experts add insights directly into each article, started with the help of AI.
#J-18808-Ljbffr",,2025-07-25,,,True,['Artificial Intelligence'],"Artificial Intelligence: Understanding and leveraging AI technologies to develop independent perspectives on the return on investment of infrastructure and resource allocation, and to influence product strategy and investment decisions.","['Data querying languages', 'Scripting languages', 'Statistical/mathematical software', 'Quantitative analysis', 'Experimentation', 'Data mining', 'End-to-end modeling', 'Forecasting', 'Resource allocation modeling']","Data querying languages: Used to extract and manipulate large and complex data sets to solve challenging problems and support decision making in infrastructure finance.; Scripting languages: Applied for quantitative analysis, experimentation, data mining, and building end-to-end models for long range planning and strategic decisions.; Statistical/mathematical software: Utilized to perform quantitative analysis and build models that compute and explain infrastructure operational and capital expenditures at various levels.; Quantitative analysis: Employed to analyze data and build models that support infrastructure investment decisions and resource allocation.; Experimentation: Used to test and validate models and assumptions related to infrastructure investments and resource allocation policies.; Data mining: Applied to discover patterns and insights from large data sets to inform infrastructure finance decisions.; End-to-end modeling: Building and maintaining comprehensive models for long range planning and strategic decision making in infrastructure finance.; Forecasting: Used to predict trends and measure success of infrastructure investments through goal setting and monitoring key metrics.; Resource allocation modeling: Developing models and policies to allocate infrastructure resources efficiently across products and platforms based on technical, operational, and financial perspectives."
cr3DQwZIyk28A0G7AAAAAA==,"Data Scientist Boston, Massachusetts, United States Boston, Massachusetts","Join Axon and be a Force for Good.

At Axon, we’re on a mission to Protect Life. We’re explorers, pursuing society’s most critical safety and justice issues with our ecosystem of devices and cloud software. Like our products, we work better together. We connect with candor and care, seeking out diverse perspectives from our customers, communities and each other.

Life at Axon is fast-paced, challenging and meaningful. Here, you’ll take ownership and drive real change. Constantly grow as you work hard for a mission that matters at a company where you matter.
Your Impact

Real-Time Operations (RTO) is a critical and fast-growing business line at Axon, focused on transforming public safety. Our vision is to become the world’s leading platform for real-time operations—connecting first responders, dispatchers, and supervisors through cutting-edge technology.

In today’s dynamic environments, public safety professionals need real-time situational awareness to act decisively and protect lives. Axon is leading this transformation with products like Axon Fusus, which aggregate livestreams from body-worn cameras, drones, CCTV, and IoT devices into a unified “single pane of glass.” This platform helps public safety teams focus on what matters most—prioritizing vital information while minimizing operational noise.

This is not a vision of the future—it’s happening now. Our team’s mission is to enhance decision-making and situational awareness for public safety professionals when it matters most. We’re building the infrastructure for the future of safe cities, with a relentless focus on saving lives and supporting those who serve.

What You’ll Do

Location: This role does require you to be based within commutable distance to one of our main R&D US Based Hubs (Scottsdale, AZ OR Boston, MA, OR Seattle, WA, OR Atlanta, GA); flexibility to be remote
Reports to:Sr Director of Product
Direct Reports: N/A
• Lead high-impact, cross-functional data initiatives from ideation through execution, collaborating with senior stakeholders across Sales, Operations, and Product to solve complex business challenges and improve customer outcomes.
• Define and operationalize key metrics in partnership with Product and Engineering to measure business performance and enhance the customer experience.
• Uncover insights using descriptive, inferential, and predictive statistical techniques; communicate findings clearly and drive action through data.
• Design and maintain scalable, transparent ETL/ELT pipelines in collaboration with Product Analytics and Data Engineering.
• Develop and own DBT models and curated BI layers that empower product managers and stakeholders to self-serve with confidence.
• Champion data governance, ensuring consistency, discoverability, and alignment with Axon’s enterprise data standards.
• Serve as a strategic thought partner to senior product leadership, surfacing insights and identifying opportunities for data-driven innovation and product development.
What You Bring
• 5+ years of experience in data science, analytics engineering, business intelligence, or related technical fields.
• Advanced proficiency in SQL and programming languages such as Python, R, or Spark for data manipulation and analysis.
• Expertise with modern data stacks including DBT, Airflow (or similar orchestration tools), Snowflake, and data observability tools like Great Expectations.
• Experience designing, building, and maintaining scalable ETL/ELT pipelines in cloud environments such as AWS or Azure.
• Strong data modeling skills with an emphasis on building analytics layers that serve product and business stakeholders.
• Proven ability to communicate complex analyses and insights to both technical and non-technical audiences.
• Demonstrated success visualizing and presenting data using BI tools like Sigma, Tableau, or Power BI.
• Strong attention to detail and comfort navigating ambiguity in complex datasets.
• Collaborative, optimistic, and self-directed mindset.
• A drive to continually learn and master new technologies and techniques.
Benefits that Benefit You
• Competitive salary and 401k with employer match
• Discretionary paid time off
• Paid parental leave for all
• Fitness Programs
• Emotional & Mental Wellness support
• And yes, we have snacks in our offices

Benefits listed herein may vary depending on the nature of your employment and the location where you work.

The Pay: Axon is a total compensation company, meaning compensation is made up of base pay, bonus, and stock awards. The starting base pay for this role is between USD 123,750 in the lowest geographic market and USD 198,000 in the highest geographic market. The actual base pay is dependent upon many factors, such as: level, function, training, transferable skills, work experience, business needs, geographic market, and often a combination of all these factors. Our benefits offer an array of options to help support you physically, financially and emotionally through the big milestones and in your everyday life. To see more details on our benefits offerings please visit www.axon.com/careers/benefits.

Don’t meet every single requirement? That's ok. At Axon, we Aim Far. We think big with a long-term view because we want to reinvent the world to be a safer, better place. We are also committed to building diverse teams that reflect the communities we serve.

Studies have shown that women and people of color are less likely to apply to jobs unless they check every box in the job description. If you’re excited about this role and our mission to Protect Life but your experience doesn’t align perfectly with every qualification listed here, we encourage you to apply anyways. You may be just the right candidate for this or other roles.

The above job description is not intended as, nor should it be construed as, exhaustive of all duties, responsibilities, skills, efforts, or working conditions associated with this job. The job description may change or be supplemented at any time in accordance with business needs and conditions.

Some roles may also require legal eligibility to work in a firearms environment.

Axon’s mission is to Protect Life and is committed to the well-being and safety of its employees as well as Axon’s impact on the environment. All Axon employees must be aware of and committed to the appropriate environmental, health, and safety regulations, policies, and procedures. Axon employees are empowered to report safety concerns as they arise and activities potentially impacting the environment.

We are an equal opportunity employer that promotes justice, advances equity, values diversity and fosters inclusion. We’re committed to hiring the best talent — regardless of race, creed, color, ancestry, religion, sex (including pregnancy), national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, genetic information, veteran status, or any other characteristic protected by applicable laws, regulations and ordinances — and empowering all of our employees so they can do their best work. If you have a disability or special need that requires assistance or accommodation during the application or the recruiting process, please emailrecruitingops@axon.com . Please note that this email address is for accommodation purposes only. Axon will not respond to inquiries for other purposes.
#J-18808-Ljbffr",2025-07-18T00:00:00.000Z,2025-07-25,"['5+ years of experience in data science, analytics engineering, business intelligence, or related technical fields', 'Advanced proficiency in SQL and programming languages such as Python, R, or Spark for data manipulation and analysis', 'Expertise with modern data stacks including DBT, Airflow (or similar orchestration tools), Snowflake, and data observability tools like Great Expectations', 'Experience designing, building, and maintaining scalable ETL/ELT pipelines in cloud environments such as AWS or Azure', 'Strong data modeling skills with an emphasis on building analytics layers that serve product and business stakeholders', 'Proven ability to communicate complex analyses and insights to both technical and non-technical audiences', 'Demonstrated success visualizing and presenting data using BI tools like Sigma, Tableau, or Power BI', 'Strong attention to detail and comfort navigating ambiguity in complex datasets', 'Collaborative, optimistic, and self-directed mindset', 'A drive to continually learn and master new technologies and techniques', 'Some roles may also require legal eligibility to work in a firearms environment']","['Location: This role does require you to be based within commutable distance to one of our main R&D US Based Hubs (Scottsdale, AZ OR Boston, MA, OR Seattle, WA, OR Atlanta, GA); flexibility to be remote', 'Lead high-impact, cross-functional data initiatives from ideation through execution, collaborating with senior stakeholders across Sales, Operations, and Product to solve complex business challenges and improve customer outcomes', 'Define and operationalize key metrics in partnership with Product and Engineering to measure business performance and enhance the customer experience', 'Uncover insights using descriptive, inferential, and predictive statistical techniques; communicate findings clearly and drive action through data', 'Design and maintain scalable, transparent ETL/ELT pipelines in collaboration with Product Analytics and Data Engineering', 'Develop and own DBT models and curated BI layers that empower product managers and stakeholders to self-serve with confidence', 'Champion data governance, ensuring consistency, discoverability, and alignment with Axon’s enterprise data standards', 'Serve as a strategic thought partner to senior product leadership, surfacing insights and identifying opportunities for data-driven innovation and product development']",True,[],,"['SQL', 'Python', 'R', 'Spark', 'DBT', 'Airflow', 'Snowflake', 'Great Expectations', 'ETL/ELT pipelines', 'Data modeling', 'Descriptive, inferential, and predictive statistical techniques', 'Business Intelligence (BI) tools', 'Data governance']","SQL: Used for advanced data manipulation and analysis to support data science and analytics engineering tasks.; Python: Programming language utilized for data manipulation, analysis, and building scalable ETL/ELT pipelines.; R: Programming language employed for data manipulation and statistical analysis.; Spark: Used as a programming framework for large-scale data processing and analysis.; DBT: Used to develop and maintain data models and curated BI layers that empower product managers and stakeholders to self-serve with confidence.; Airflow: Orchestration tool used to design, build, and maintain scalable ETL/ELT pipelines in cloud environments.; Snowflake: Cloud data platform used to support scalable data storage and processing for analytics and data science.; Great Expectations: Data observability tool used to ensure data quality, consistency, and alignment with enterprise data standards.; ETL/ELT pipelines: Designed and maintained to enable scalable, transparent data processing workflows in collaboration with Product Analytics and Data Engineering teams.; Data modeling: Strong skills emphasized for building analytics layers that serve product and business stakeholders effectively.; Descriptive, inferential, and predictive statistical techniques: Applied to uncover insights from data, communicate findings clearly, and drive action through data.; Business Intelligence (BI) tools: Tools such as Sigma, Tableau, and Power BI are used to visualize and present data to both technical and non-technical audiences.; Data governance: Championed to ensure data consistency, discoverability, and alignment with enterprise data standards."
Xg80OBTFD7IoJL0sAAAAAA==,"Data Scientist, USAFSAM/OET, DR-1560-02","Job Overview

The United States Air Force School of Aerospace Medicine (USAFSAM) seeks to fill the mid-level, DR-02 position of Data Scientist within the Occupational & Environmental Health (OE) Department, Technical Operations Division, to serve as the primary Data Scientist.

This job announcement will be accepting candidate submissions until 7 Nov 24.

Position duties include, but are not limited to:
• Principal responsibilities is to develop/modify new methods, approaches, or scientific knowledge to solve challenges.
• Must apply knowledge of science/technology to analyze and resolve multifaceted issues/problems with minimal guidance and consult appropriately to develop objectives, priorities, and deadlines.
• The incumbent must plan and carry out work that is well aligned with organizational goals.
• Must present complex information, concepts, and ideas in a clear, concise, well-organized, and timely manner.
• Must demonstrate effective speaking skills for advanced briefings, tailoring presentations to facilitate understanding.
• Identifies and advocates for resources necessary to support and contribute to mission requirements.
• Demonstrates knowledge of corporate processes by effective application of resources.
• Incumbent will engage others in using resources more efficiently and suggest innovative ideas to optimize available resources.
• Implements the development and transition/transfer of technology solutions, within or beyond your own organization, based upon awareness of customer requirements.
• Evaluates and incorporates appropriate outside technology to support research and development.
• Work collaboratively with others in a dynamic environment, demonstrating respect for other people and alternative viewpoints.

Telework

Yes, this position is eligible for situational telework; as determined by agency policy
Remote Work (CONUS)

No, this position is not approved for remote work.
Required Qualifications
• US Citizenship
• Must be able to obtain and maintain a Secret security clearance.
• Males must be registered for Selective Service, see www.sss.gov
• As a minimum, possess a B.S. degree in mathematics, statistics, computer science, data science or field directly related to the position or a combination of education and experience with courses equivalent to a major field of study (30 semester hours) in mathematics, statistics, computer science, data science or field directly related to the position, plus additional education or appropriate experience.
• Must have at least one year of specialized experience at the DR-01/GS-11 or equivalent grade level. Specialized experience is experience providing the capacity and skills for working independently, leading collaborative events, working in teams and using these approaches to find and solve complex problems.

Desired Qualifications
• Possess an M.S. degree in data analytics, biostatistics, bioinformatics, business intelligence, epidemiology, statistics, computer science, or a related science or engineering field that emphasizes data processing, graphical data presentation, and programming.
• Demonstrate at least 3 years of experience analyzing and processing data sets using Python / Pandas, R, SQL, or related programming software.
• Demonstrate at least 3 years of experience developing advanced data visualizations with tools such as Tableau, Tableau Server, Tableau Desktop, Tableau Prep Builder, Pythong / Matplotlib, or Power BI.
• Demonstrate a minimum of 3 years experience using Microsoft Office software programs including Word, Outlook, PowerPoint, Access, Excel, Visio, or SharePoint.
• Demonstrate at least 5 years of experience applying data processing and visual analytics tools and techniques to medical (clinical) or Occupational and Environmental Health data sets.
• Demonstrate at least 5 years of experience supporting the Air Force or DoD in a medical/clinical, Public Health, or OEH-related field in a government civilian or military capacity.
• Demonstrate experience using SQL for ETL (extract, transform, and load) tools and business intelligence (BI) reporting, data mining, and analytics tools across cloud-based data warehouses, operational databases and data lakes, as well as API-brokered data.
• Demonstrate experience with Software as a Service (SaaS) / Cloud-based platforms such as AWS Redshift (Dbvisualizer) or Databricks (Redash)
• Able to work independently without extensive supervision.
• Able to manage projects to ensure all phases are completed expertly and in a timely manner.
• Have the ability to utilize their knowledge, skills, and abilities (KSA) for guiding, training, and assisting other team members.
• Able to exercise independent judgment.

(Requisition 68672)

Series

1560",,2025-07-25,"['US Citizenship', 'Must be able to obtain and maintain a Secret security clearance', 'Males must be registered for Selective Service, see www.sss.gov', 'As a minimum, possess a B.S. degree in mathematics, statistics, computer science, data science or field directly related to the position or a combination of education and experience with courses equivalent to a major field of study (30 semester hours) in mathematics, statistics, computer science, data science or field directly related to the position, plus additional education or appropriate experience', 'Must have at least one year of specialized experience at the DR-01/GS-11 or equivalent grade level', 'Specialized experience is experience providing the capacity and skills for working independently, leading collaborative events, working in teams and using these approaches to find and solve complex problems']","['Principal responsibilities is to develop/modify new methods, approaches, or scientific knowledge to solve challenges', 'Must apply knowledge of science/technology to analyze and resolve multifaceted issues/problems with minimal guidance and consult appropriately to develop objectives, priorities, and deadlines', 'The incumbent must plan and carry out work that is well aligned with organizational goals', 'Must present complex information, concepts, and ideas in a clear, concise, well-organized, and timely manner', 'Must demonstrate effective speaking skills for advanced briefings, tailoring presentations to facilitate understanding', 'Identifies and advocates for resources necessary to support and contribute to mission requirements', 'Demonstrates knowledge of corporate processes by effective application of resources', 'Incumbent will engage others in using resources more efficiently and suggest innovative ideas to optimize available resources', 'Implements the development and transition/transfer of technology solutions, within or beyond your own organization, based upon awareness of customer requirements', 'Evaluates and incorporates appropriate outside technology to support research and development', 'Work collaboratively with others in a dynamic environment, demonstrating respect for other people and alternative viewpoints']",True,[],,"['Python', 'Pandas', 'R', 'SQL', 'Tableau', 'Power BI', 'Matplotlib', 'Microsoft Office Suite', 'AWS Redshift', 'Databricks']","Python: Used for analyzing and processing data sets, including with libraries such as Pandas and Matplotlib for data manipulation and advanced data visualization.; Pandas: A Python library utilized for data analysis and processing of datasets relevant to the job.; R: Used for analyzing and processing data sets as part of the data science toolkit.; SQL: Applied for ETL (extract, transform, and load) processes, business intelligence reporting, data mining, and analytics across cloud-based data warehouses, operational databases, data lakes, and API-brokered data.; Tableau: Used to develop advanced data visualizations, including Tableau Server, Tableau Desktop, and Tableau Prep Builder.; Power BI: Employed for creating advanced data visualizations and business intelligence reporting.; Matplotlib: A Python library used for creating advanced data visualizations.; Microsoft Office Suite: Includes Word, Outlook, PowerPoint, Access, Excel, Visio, and SharePoint, used for documentation, presentations, and data management.; AWS Redshift: A cloud-based data warehousing platform used for managing and querying large datasets as part of SaaS/cloud platforms.; Databricks: A cloud-based platform used for data analytics and visualization, including tools like Redash."
j9BM52GxZAd3Ib5jAAAAAA==,"Manager, Data Science (Non-Financial Risk)","KPMG Advisory practice is currently our fastest growing practice. We are seeing tremendous client demand, and looking forward we do not anticipate that slowing down. In this ever-changing market environment, our professionals must be adaptable and thrive in a collaborative, team-driven culture. At KPMG, our people are our number one priority. With a wealth of learning and career development opportunities, a world-class training facility and leading market tools, we make sure our people continue to grow both professionally and personally. If you're looking for a firm with a strong team connection where you can be your whole self, have an impact, advance your skills, deepen your experiences, and have the flexibility and access to constantly find new areas of inspiration and expand your capabilities, then consider a career in Advisory.

KPMG is currently seeking a Manager, NFR Data Science in Non-Financial Risk for our Consulting practice.

Responsibilities:
• Serve as the technical lead on projects to design and develop advanced AI/ML solutions to meet clients' unique requirements, including participation in internal and external discussions to gather business use case requirements, provide advanced analytics and data science expertise and solution options for business problems
• Engineer solutions using natural language processing and machine learning techniques to solve critical problems and improve processes for clients across capital markets and financial services businesses, including trade surveillance, electronic communications surveillance, payments fraud detection, third-party risk management and other operational risk categories
• Utilize machine learning, natural language, and statistical analysis methods, such as sentiment analysis, topic modeling, time-series analysis, regression, classification, statistical inference, and validation methods to review financial services client risks
• Perform explanatory data analyses, generate and test working hypotheses; prepare and analyze historical data and identify patterns to develop innovative solutions to financial services operational risk and regulatory compliance programs
• Lead technical teams, mentor junior data scientists, and grow data science expertise within the broader team, including offshore; collaborate with diverse, cross-functional teams to accurately identify and prioritize requirements, ensuring that AI/ML solutions meet the needs and expectations of various stakeholders
• Present to key stakeholders, such as approach, data requirements, interim findings, and final solution architecture and infrastructure

Qualifications:
• Minimum six years of recent professional experience working in advanced analytics and data science; minimum two years of recent experience managing teams and delivering complex and critical projects
• Bachelor's degree from an accredited college/university in a relevant STEM field such as data science, computer science, engineering, mathematics, physics and other related fields
• Extensive experience in AI/ML algorithm development and data analysis including at least one of the following: NLP, time-series analysis, predictive modeling; experience with scripting, data structures and algorithms and ability to work with large amounts of data
• Experience in a statistical programming language (for example, R or Python) and related data science / machine learning packages (for example, Pandas, Scikit-learn, Pytorch, Transformers)
• Excellent communication, written, presentation, and problem-solving skills
• Previous technical client service experience preferred
• Ability to travel as required (based on location and clients served)

KPMG complies with all local/state regulations regarding displaying salary ranges. If required, the ranges displayed below or via the URL below are specifically for those potential hires who will work in the location(s) listed. Any offered salary is determined based on relevant factors such as applicant's skills, job responsibilities, prior relevant experience, certain degrees and certifications and market considerations. In addition, the firm is proud to offer a comprehensive, competitive benefits package, with options designed to help you make the best decisions for yourself, your family, and your lifestyle. Available benefits are based on eligibility. Our Total Rewards package includes a variety of medical and dental plans, vision coverage, disability and life insurance, 401(k) plans, and a robust suite of personal well-being benefits to support your mental health. Depending on job classification, standard work hours, and years of service, KPMG provides Personal Time Off per fiscal year. Additionally, each year the firm publishes a calendar of holidays to be observed during the year and provides two firmwide breaks each year where employees will not be required to use Personal Time Off; one is at year end and the other is around the July 4th holiday. Additional details about our benefits can be found towards the bottom of our KPMG US Careers site at “Benefits & How We Work”.

Follow this link to obtain salary ranges by city outside of CA:

https://kpmg.com/us/en/how-we-work/pay-transparency.html/?id=M116_3_25

KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package. KPMG is an equal opportunity employer. KPMG complies with all applicable federal, state and local laws regarding recruitment and hiring. All qualified applicants are considered for employment without regard to race, color, religion, age, sex, sexual orientation, gender identity, national origin, citizenship status, disability, protected veteran status, or any other category protected by applicable federal, state or local laws. The attached link contains further information regarding the firm's compliance with federal, state and local recruitment and hiring laws. No phone calls or agencies please.

KPMG does not currently require partners or employees to be fully vaccinated or test negative for COVID-19 in order to go to KPMG offices, client sites or KPMG events, except when mandated by federal, state or local law. In some circumstances, clients also may require proof of vaccination or testing (e.g., to go to the client site).

KPMG recruits on a rolling basis. Candidates are considered as they apply, until the opportunity is filled. Candidates are encouraged to apply expeditiously to any role(s) for which they are qualified that is also of interest to them.

Los Angeles County applicants: Material job duties for this position are listed above. Criminal history may have a direct, adverse, and negative relationship with some of the material job duties of this position. These include the duties and responsibilities listed above, as well as the abilities to adhere to company policies, exercise sound judgment, effectively manage stress and work safely and respectfully with others, exhibit trustworthiness, and safeguard business operations and company reputation. Pursuant to the California Fair Chance Act, Los Angeles County Fair Chance Ordinance for Employers, Fair Chance Initiative for Hiring Ordinance, and San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.",2025-06-30T00:00:00.000Z,2025-07-25,"['Minimum six years of recent professional experience working in advanced analytics and data science; minimum two years of recent experience managing teams and delivering complex and critical projects', ""Bachelor's degree from an accredited college/university in a relevant STEM field such as data science, computer science, engineering, mathematics, physics and other related fields"", 'Extensive experience in AI/ML algorithm development and data analysis including at least one of the following: NLP, time-series analysis, predictive modeling; experience with scripting, data structures and algorithms and ability to work with large amounts of data', 'Experience in a statistical programming language (for example, R or Python) and related data science / machine learning packages (for example, Pandas, Scikit-learn, Pytorch, Transformers)', 'Excellent communication, written, presentation, and problem-solving skills', 'Ability to travel as required (based on location and clients served)', 'These include the duties and responsibilities listed above, as well as the abilities to adhere to company policies, exercise sound judgment, effectively manage stress and work safely and respectfully with others, exhibit trustworthiness, and safeguard business operations and company reputation']","[""Serve as the technical lead on projects to design and develop advanced AI/ML solutions to meet clients' unique requirements, including participation in internal and external discussions to gather business use case requirements, provide advanced analytics and data science expertise and solution options for business problems"", 'Engineer solutions using natural language processing and machine learning techniques to solve critical problems and improve processes for clients across capital markets and financial services businesses, including trade surveillance, electronic communications surveillance, payments fraud detection, third-party risk management and other operational risk categories', 'Utilize machine learning, natural language, and statistical analysis methods, such as sentiment analysis, topic modeling, time-series analysis, regression, classification, statistical inference, and validation methods to review financial services client risks', 'Perform explanatory data analyses, generate and test working hypotheses; prepare and analyze historical data and identify patterns to develop innovative solutions to financial services operational risk and regulatory compliance programs', 'Lead technical teams, mentor junior data scientists, and grow data science expertise within the broader team, including offshore; collaborate with diverse, cross-functional teams to accurately identify and prioritize requirements, ensuring that AI/ML solutions meet the needs and expectations of various stakeholders', 'Present to key stakeholders, such as approach, data requirements, interim findings, and final solution architecture and infrastructure', 'In some circumstances, clients also may require proof of vaccination or testing (e.g., to go to the client site)']",True,"['Transformers', 'PyTorch']","Transformers: Used as part of natural language processing solutions to address client problems in financial services, including surveillance and fraud detection.; PyTorch: Employed as a deep learning framework to develop AI/ML models, including those involving natural language processing techniques.","['Machine Learning', 'Natural Language Processing', 'Time-Series Analysis', 'Sentiment Analysis', 'Topic Modeling', 'Statistical Inference', 'Regression', 'Classification', 'Explanatory Data Analysis', 'Data Science Packages', 'Statistical Programming Languages']","Machine Learning: Used to develop advanced AI/ML solutions and apply techniques such as regression, classification, and predictive modeling to solve business problems and review financial services client risks.; Natural Language Processing: Applied to engineer solutions for trade surveillance, electronic communications surveillance, payments fraud detection, and third-party risk management in financial services.; Time-Series Analysis: Utilized as a statistical method to analyze financial services client risks and develop innovative solutions for operational risk and regulatory compliance.; Sentiment Analysis: Used as a natural language processing technique to assess financial services client risks.; Topic Modeling: Employed as a natural language processing method to analyze and interpret textual data related to financial services risks.; Statistical Inference: Applied to validate models and analyze data patterns in financial services operational risk and compliance programs.; Regression: Used as a statistical method for predictive modeling and risk analysis in financial services.; Classification: Applied as a machine learning technique to categorize and assess financial services client risks.; Explanatory Data Analysis: Performed to generate and test hypotheses, analyze historical data, and identify patterns for developing risk and compliance solutions.; Data Science Packages: Experience with tools such as Pandas and Scikit-learn for data manipulation and machine learning model development.; Statistical Programming Languages: Proficiency in languages like Python and R used for scripting, data analysis, and implementing machine learning algorithms."
N-Sh8FpaBR1RMO4lAAAAAA==,"Lead Data Science Engineer, Sportsbook","We’re defining what it means to build and deliver the most extraordinary sports and entertainment experiences. Our global team is trailblazing new markets, developing cutting-edge products, and shaping the future of responsible gaming.

Here, “impossible” isn’t part of our vocabulary. You’ll face some of the toughest but most rewarding challenges of your career. They’re worth it. Channeling your inner grit will accelerate your growth, help us win as a team, and create unforgettable moments for our customers.
The Crown Is Yours

We are looking for a Lead Data Science Engineer to join our Sportsbook Reinvestment team, where we focus on understanding and optimizing how players engage with our Online Sportsbook products over time. As a Lead Data Science Engineer, you will be responsible for building advanced models and algorithms, analyzing large-scale behavioral datasets, and driving measurable impact through experimentation and productionized solutions.

What you'll do as a Lead Data Science Engineer
• Lead end-to-end modeling projects to improve customer engagement and retention, from ideation to production deployment.
• Build, test, and optimize machine learning models to forecast user behavior, personalize promotions, and enhance Sportsbook product engagement.
• Partner with engineers, analysts, product managers, and marketers to translate insights into scalable solutions embedded within customer-facing systems.
• Mentor junior data scientists and share modeling and engineering best practices across the team.
• Clearly communicate findings and the impact of your models to stakeholders to influence product and marketing strategy.

What you'll bring
• Proven experience applying machine learning and statistical modeling to solve real-world business problems, ideally in marketing or customer lifecycle contexts.
• Experience leading and coaching other data scientists
• Strong proficiency in Python (or R) and experience working with large datasets using SQL and distributed computing platforms.
• Ability to structure and execute data science projects and deliver business value through production-ready models.
• Excellent communication and collaboration skills to work effectively across technical and non-technical teams.
• A Bachelor’s degree in a relevant field such as Computer Science, Statistics, Mathematics, or a related discipline.

Join Our Team

We’re a publicly traded (NASDAQ: DKNG) technology company headquartered in Boston. As a regulated gaming company, you may be required to obtain a gaming license issued by the appropriate state agency as a condition of employment. Don’t worry, we’ll guide you through the process if this is relevant to your role.
The US base salary range for this full-time position is 140,800.00 USD - 176,000.00 USD, plus bonus, equity, and benefits as applicable. Our ranges are determined by role, level, and location. The compensation information displayed on each job posting reflects the range for new hire pay rates for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific pay range and how that was determined during the hiring process. It is unlawful in Massachusetts to require or administer a lie detector test as a condition of employment or continued employment. An employer who violates this law shall be subject to criminal penalties and civil liability.",2025-07-17T00:00:00.000Z,2025-07-25,"['Proven experience applying machine learning and statistical modeling to solve real-world business problems, ideally in marketing or customer lifecycle contexts', 'Experience leading and coaching other data scientists', 'Strong proficiency in Python (or R) and experience working with large datasets using SQL and distributed computing platforms', 'Ability to structure and execute data science projects and deliver business value through production-ready models', 'Excellent communication and collaboration skills to work effectively across technical and non-technical teams', 'A Bachelor’s degree in a relevant field such as Computer Science, Statistics, Mathematics, or a related discipline']","['As a Lead Data Science Engineer, you will be responsible for building advanced models and algorithms, analyzing large-scale behavioral datasets, and driving measurable impact through experimentation and productionized solutions', ""What you'll do as a Lead Data Science Engineer"", 'Lead end-to-end modeling projects to improve customer engagement and retention, from ideation to production deployment', 'Build, test, and optimize machine learning models to forecast user behavior, personalize promotions, and enhance Sportsbook product engagement', 'Partner with engineers, analysts, product managers, and marketers to translate insights into scalable solutions embedded within customer-facing systems', 'Mentor junior data scientists and share modeling and engineering best practices across the team', 'Clearly communicate findings and the impact of your models to stakeholders to influence product and marketing strategy']",True,[],,"['Machine Learning Models', 'Statistical Modeling', 'Behavioral Data Analysis', 'Production-Ready Models', 'SQL and Distributed Computing', 'Python (or R)', 'Experimentation and Impact Measurement', 'End-to-End Modeling Projects']","Machine Learning Models: Build, test, and optimize models to forecast user behavior, personalize promotions, and enhance product engagement in the Sportsbook context.; Statistical Modeling: Apply statistical modeling techniques to solve real-world business problems related to marketing and customer lifecycle.; Behavioral Data Analysis: Analyze large-scale behavioral datasets to understand and optimize player engagement with online Sportsbook products over time.; Production-Ready Models: Structure and execute data science projects to deliver business value through models that are deployed in production environments.; SQL and Distributed Computing: Use SQL and distributed computing platforms to work with large datasets efficiently.; Python (or R): Utilize Python or R programming languages for data analysis, modeling, and building machine learning solutions.; Experimentation and Impact Measurement: Drive measurable impact through experimentation and productionized solutions to improve customer engagement and retention.; End-to-End Modeling Projects: Lead projects from ideation through production deployment to improve customer engagement and retention."
4Pz9OfKNaMqqstSAAAAAAA==,Data Scientist,"Job Description:

Some things you can expect to do:
• Analyze structured and unstructured project data (e.g., scheduling information, safety reports, IoT sensor data) to identify trends, risks, and operational opportunities.
• Assist in the development, training, and validation of predictive models that support safety forecasting, scheduling optimization, and project risk analysis.
• Support data preparation, feature engineering, and the evaluation of model performance using tools such as pandas, scikit-learn, or XGBoost.
• Help translate machine learning outputs into actionable insights for construction and safety teams.
• Assist in the integration of predictive analytics into dashboards and field tools used by project managers and jobsite personnel.
• Collaborate with stakeholders to ensure analytics align with operational realities and business priorities.
• Work closely with the Lead Data Scientist to refine approaches, troubleshoot issues, and enhance modeling workflows.
• Participate in agile development practices and contribute to cross-functional analytics sprints.
• Communicate results and recommendations clearly to both technical and non-technical audiences, gaining exposure to real-time decision-making in the field.

To be successful in this role you must have:
• Bachelor's degree in Data Science, Statistics, Engineering, Computer Science, or a related field.
• 1-2 years of professional or academic experience applying data science methods to real-world problems.
• Proficiency in Python and SQL, with familiarity using tools such as pandas, scikit-learn, matplotlib, or XGBoost.
• Ability to work independently in a field-based environment and communicate effectively with multidisciplinary teams.
• Strong problem-solving skills, curiosity, and eagerness to learn new technologies and business processes.
• Exposure to construction or engineering project data (e.g., schedules, jobsite safety systems, field logs).
• Familiarity with cloud data platforms such as Azure, AWS, or GCP, and experience using MLflow or Databricks.
• Interest in predictive analytics and its application to safety, planning, and operational efficiency.
• Experience working with or integrating data into enterprise systems such as Procore, Power BI, or other project management tools.

Compensation:

The base pay range is $74,100-$111,100/Annually. The salary may vary within the anticipated range based on factors such as the ultimate location of the position and the selected candidate's knowledge, skills, and abilities. Position may be eligible for additional compensation that may include commission and/or an incentive program.

Eligibility:
• Positions require verification of employment eligibility to work in the U.S.

Ryan Companies is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.

Ryan Companies is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.

Non-Solicitation Notice to Recruitment Agencies:

Ryan Companies kindly requests that recruitment agencies and third-party recruiters do not submit unsolicited resumes or candidate information to any Ryan Companies employee or office. Ryan Companies will not be responsible for any fees or expenses associated with unsolicited submissions. If recruitment services are required, we will reach out directly to agencies on our approved vendor list. We appreciate your understanding and cooperation.

Ryan Companies US, Inc. is an equal opportunity and affirmative action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected Veteran status, age, or any other characteristic protected by law.

For information about your rights under Equal Employment Opportunity, https://www.dol.gov/agencies/ofccp/posters",,2025-07-25,"[""Bachelor's degree in Data Science, Statistics, Engineering, Computer Science, or a related field"", '1-2 years of professional or academic experience applying data science methods to real-world problems', 'Proficiency in Python and SQL, with familiarity using tools such as pandas, scikit-learn, matplotlib, or XGBoost', 'Ability to work independently in a field-based environment and communicate effectively with multidisciplinary teams', 'Strong problem-solving skills, curiosity, and eagerness to learn new technologies and business processes', 'Exposure to construction or engineering project data (e.g., schedules, jobsite safety systems, field logs)', 'Familiarity with cloud data platforms such as Azure, AWS, or GCP, and experience using MLflow or Databricks', 'Interest in predictive analytics and its application to safety, planning, and operational efficiency', 'Experience working with or integrating data into enterprise systems such as Procore, Power BI, or other project management tools', 'Positions require verification of employment eligibility to work in the U.S']","['Analyze structured and unstructured project data (e.g., scheduling information, safety reports, IoT sensor data) to identify trends, risks, and operational opportunities', 'Assist in the development, training, and validation of predictive models that support safety forecasting, scheduling optimization, and project risk analysis', 'Support data preparation, feature engineering, and the evaluation of model performance using tools such as pandas, scikit-learn, or XGBoost', 'Help translate machine learning outputs into actionable insights for construction and safety teams', 'Assist in the integration of predictive analytics into dashboards and field tools used by project managers and jobsite personnel', 'Collaborate with stakeholders to ensure analytics align with operational realities and business priorities', 'Work closely with the Lead Data Scientist to refine approaches, troubleshoot issues, and enhance modeling workflows', 'Participate in agile development practices and contribute to cross-functional analytics sprints', 'Communicate results and recommendations clearly to both technical and non-technical audiences, gaining exposure to real-time decision-making in the field']",True,[],,"['Predictive Modeling', 'Data Analysis', 'Feature Engineering', 'Machine Learning', 'Model Evaluation', 'Data Integration', 'SQL', 'Python', 'Cloud Data Platforms', 'MLOps', 'Business Intelligence Tools']","Predictive Modeling: Develop, train, and validate predictive models to support safety forecasting, scheduling optimization, and project risk analysis.; Data Analysis: Analyze structured and unstructured project data such as scheduling information, safety reports, and IoT sensor data to identify trends, risks, and operational opportunities.; Feature Engineering: Support data preparation and feature engineering to improve model performance.; Machine Learning: Translate machine learning outputs into actionable insights for construction and safety teams.; Model Evaluation: Evaluate model performance using tools such as pandas, scikit-learn, or XGBoost.; Data Integration: Assist in integrating predictive analytics into dashboards and field tools used by project managers and jobsite personnel.; SQL: Use SQL for data querying and manipulation as part of data science workflows.; Python: Utilize Python programming language and libraries such as pandas, scikit-learn, matplotlib, and XGBoost for data science tasks.; Cloud Data Platforms: Familiarity with cloud platforms like Azure, AWS, or GCP to support data storage, processing, and analytics.; MLOps: Experience using MLflow or Databricks to manage machine learning workflows and model lifecycle.; Business Intelligence Tools: Experience working with or integrating data into enterprise systems such as Procore and Power BI for reporting and dashboarding."
FG8ZsaZcqiRRb7AZAAAAAA==,"Sr. Manager, Data Science & Analytics","Carrier Global Corporation, a global leader in intelligent climate and energy solutions, is committed to creating solutions that matter for people and our planet for generations to come. From the beginning, we've led in inventing new technologies and entirely new industries. Today, we continue to lead because we have a world-class, diverse workforce that puts the customer at the center of everything we do. For more information, visit corporate.carrier.com or follow Carrier on social media at @Carrier.

Role Purpose:

The successful candidate will have ownership of driving critical initiatives for analytics and data products, interfacing with our leadership team to align priorities, while providing guidance to the internal teams on analytics strategy and delivery. Additionally, the candidate will deliver end-to-end data and analytics solutions that will scale and empower our users to deliver on Carriers goals and mission.

Ideal Candidate will be within a commutable distance of Carrier's office in Palm Beach Gardens, FL or Carrier's office in Atlanta, GA.

Role Responsibilities:
• Define, develop, and maintain the product roadmap for analytics data products in alignment with business goals.
• Collaborate with stakeholders to gather requirements, define use cases, and prioritize features to maximize value.
• Act as a liaison between business and technical teams, translating business needs into technical solutions.
• Work closely with data engineers, data scientists, and BI developers to ensure accurate implementation of analytics solutions.
• Drive the integration of data analytics solutions into business processes, ensuring scalability and reliability.
• Monitor and evaluate product performance using KPIs, user feedback, and business impact metrics.
• Own the backlog for analytics and data-related products, ensuring that user stories are well-defined, prioritized, and executed efficiently.

Basic Qualifications:
• Bachelors Degree
• 7+ years of experience in analytics, data, statistics, Machine Learning, and/or AI delivery roles

Preferred Qualifications:
• Experience working with cloud-based data platforms such as AWS, Snowflake.
• Proficiency in data visualization tools (ex. Power BI) and SQL.
• Experience at large companies with complex data landscapes and scale.
• Experience delivering scalable analytics solutions, ideation through deployment.
• Experience leading teams and managing individual contributors.
• Data warehousing and data lake experience.
• Strong background in enterprise data and technology principles and best practices.

#LI-Onsite

RSRCAR

Carrier is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or veteran status, or any other applicable state or federal protected class. Carrier provides affirmative action in employment for qualified Individuals with a Disability and Protected Veterans in compliance with Section 503 of the Rehabilitation Act and the Vietnam Era Veterans' Readjustment Assistance Act.

Job Applicant's Privacy Notice:

Click on this link to read the Job Applicant's Privacy Notice",,2025-07-25,"['Bachelors Degree', '7+ years of experience in analytics, data, statistics, Machine Learning, and/or AI delivery roles', 'Power BI) and SQL', 'Experience at large companies with complex data landscapes and scale', 'Experience delivering scalable analytics solutions, ideation through deployment', 'Experience leading teams and managing individual contributors', 'Data warehousing and data lake experience', 'Strong background in enterprise data and technology principles and best practices']","['The successful candidate will have ownership of driving critical initiatives for analytics and data products, interfacing with our leadership team to align priorities, while providing guidance to the internal teams on analytics strategy and delivery', 'Additionally, the candidate will deliver end-to-end data and analytics solutions that will scale and empower our users to deliver on Carriers goals and mission', 'Define, develop, and maintain the product roadmap for analytics data products in alignment with business goals', 'Collaborate with stakeholders to gather requirements, define use cases, and prioritize features to maximize value', 'Act as a liaison between business and technical teams, translating business needs into technical solutions', 'Work closely with data engineers, data scientists, and BI developers to ensure accurate implementation of analytics solutions', 'Drive the integration of data analytics solutions into business processes, ensuring scalability and reliability', 'Monitor and evaluate product performance using KPIs, user feedback, and business impact metrics', 'Own the backlog for analytics and data-related products, ensuring that user stories are well-defined, prioritized, and executed efficiently']",True,[],,"['Machine Learning', 'SQL', 'Power BI', 'Cloud-based Data Platforms', 'Data Warehousing and Data Lakes', 'Analytics Solutions Delivery', 'Data Product Roadmap and Backlog Management', 'Collaboration with Data Engineers, Data Scientists, and BI Developers', 'KPI Monitoring and Business Impact Evaluation']","Machine Learning: The role requires experience in machine learning as part of analytics, data, and statistics delivery roles, indicating involvement in building predictive or analytical models.; SQL: Proficiency in SQL is required for querying and managing data within the analytics solutions.; Power BI: Experience with Power BI is needed for data visualization and creating dashboards to support analytics and business intelligence.; Cloud-based Data Platforms: Experience working with cloud-based data platforms such as AWS and Snowflake is preferred, supporting scalable data storage and processing.; Data Warehousing and Data Lakes: The candidate should have experience with data warehousing and data lake architectures to manage large-scale enterprise data.; Analytics Solutions Delivery: The role involves delivering scalable end-to-end analytics solutions from ideation through deployment, ensuring integration into business processes.; Data Product Roadmap and Backlog Management: Responsibilities include defining and maintaining the product roadmap for analytics data products and managing the backlog to prioritize and execute user stories efficiently.; Collaboration with Data Engineers, Data Scientists, and BI Developers: The candidate will work closely with technical teams to ensure accurate implementation of analytics solutions aligned with business needs.; KPI Monitoring and Business Impact Evaluation: The role includes monitoring product performance using KPIs, user feedback, and business impact metrics to guide analytics strategy and delivery."
WrkVYutY_Bn1TmQrAAAAAA==,"Senior Analyst, Data Science (Audience Solutions Group)","Company description

Zenith is a full-service media agency with capabilities and expertise across all channels and disciplines. Zenith is part of Publicis Media, the #1 media buying network in the Americas and #2 globally. As “The ROI Agency,” Zenith’s expertise lies in driving real, tangible business outcomes, not just media metrics, that will have a measurable effect on our clients’ business. Every investment we make has an ROI mindset—not just for our clients, but for our agency at large. We’re focused on driving the maximum value for our people, our capabilities and our media investments for some of the world’s leading brands.

Overview

Working closely with both the Planning and Analytics teams, Data Sciences designs and implements statistical models and machine learning solutions that tie our clients’ marketing to real-world business goals. We use these models to understand past performance, predict future performance, and inform and optimize future decisions. Our work brings our clients closer to their marketing, helping them understand if they are talking to the right people in the right way.

We look for prior experience in media analytics, especially digital media and audiences segmentation/modeling. We hope you have a love for numbers and know how to bring data to life through a compelling story. We’re also hoping you have at least 1-2 years of experience.

Responsibilities

You will work very closely with planning, audience strategy and analytics teams to help them solve marketing problems. They also contribute crucial intellectual capital to the data science team by sharing knowledge and designing models and Data Science solutions based on their clients’ business needs and using data to tell great stories. A Senior Analyst will also help formulate a vision for their accounts and bring that vision to life. Day-to-day responsibilities include:
• Design, estimate, tune, score and maintain advanced statistical and mathematical models (e.g. classification, numeric forecasts, customer segmentation, customer propensity, attribution, etc.).
• Produce accurate statistical analysis and ensure high quality of the data analysis produced.
• Interpret, document and present/communicate analytical results to multiple business disciplines, providing conclusions and recommendations.
• Take analytical objectives and define data requirements. Extract, clean, and transform both customer level, and aggregated data for analysis, modelling, segmentation and reporting.

Qualifications
• 1+ years of work experience in quantitative analysis with proven results in leveraging customer/transaction to address business objectives
• Bachelor’s degree in a STEM or other related field, or equivalent work experience.
• Strong knowledge of Relational Databases and SQL programming.
• Highly proficient in at least one popular programming language used for Machine Learning, such as Python or R.
• Solid understanding of mathematical modeling, probability and statistics, and the design and simulation of stochastic systems.
• Familiarity with the mathematics behind important statistical learning algorithms such as ARIMA, Linear Regression, Logistic Regression, Centroid-based and Hierarchical Clustering, Principal Component Analysis (PCA), Decision Trees/Random Forest, Bayesian Inference, Markov Chain Monte-Carlo (MCMC).
• Familiarity with common advanced marketing analytics solutions such as Customer Segmentation, Marketing Mix Modeling (MMM), Multi-touch Attribution (MTA)
• Familiarity with the capabilities and mechanics of a broad range of marketing measurements and technologies such as Ad Servers, DSP, DMPs, CRMs, and Syndicated Research strongly preferred
• Strong communication skills. Ability to speak and write professionally. Ability and comfort with presenting work by phone or within small groups.

Additional information

Our Publicis Groupe motto “Viva La Différence” means we’re better together, and we believe that our differences make us stronger. It means we honor and celebrate all identities, across all facets of intersectionality, and it underpins all that we do as an organization. We are focused on fostering belonging and creating equitable & inclusive experiences for all talent.

Publicis Groupe provides robust and inclusive benefit programs and policies to support the evolving and diverse needs of our talent and enable every person to grow and thrive. Our benefits package includes medical coverage, dental, vision, disability, 401K, as well as parental and family care leave, family forming assistance, tuition reimbursement, and flexible time off.

If you require accommodation or assistance with the application or onboarding process specifically, please contact USMSTACompliance@publicis.com. All your information will be kept confidential according to EEO guidelines.

Compensation Range: $90,000 - $95,000. This is the pay range the Company believes it will pay for this position at the time of this posting. Consistent with applicable law, compensation will be determined based on the skills, qualifications, and experience of the applicant along with the requirements of the position, and the Company reserves the right to modify this pay range at any time. Temporary roles may be eligible to participate in our freelancer/temporary employee medical plan through a third-party benefits administration system once certain criteria have been met. Temporary roles may also qualify for participation in our 401(k) plan after eligibility criteria have been met. For regular roles, the Company will offer medical coverage, dental, vision, disability, 401k, and paid time off. The Company anticipates the application deadline for this job posting will be 7/15/2025.

Veterans Encouraged to Apply

#DNI",2025-07-03T00:00:00.000Z,2025-07-25,"['We look for prior experience in media analytics, especially digital media and audiences segmentation/modeling', 'We’re also hoping you have at least 1-2 years of experience', '1+ years of work experience in quantitative analysis with proven results in leveraging customer/transaction to address business objectives', 'Bachelor’s degree in a STEM or other related field, or equivalent work experience', 'Strong knowledge of Relational Databases and SQL programming', 'Highly proficient in at least one popular programming language used for Machine Learning, such as Python or R', 'Solid understanding of mathematical modeling, probability and statistics, and the design and simulation of stochastic systems', 'Familiarity with the mathematics behind important statistical learning algorithms such as ARIMA, Linear Regression, Logistic Regression, Centroid-based and Hierarchical Clustering, Principal Component Analysis (PCA), Decision Trees/Random Forest, Bayesian Inference, Markov Chain Monte-Carlo (MCMC)', 'Familiarity with common advanced marketing analytics solutions such as Customer Segmentation, Marketing Mix Modeling (MMM), Multi-touch Attribution (MTA)', 'Strong communication skills', 'Ability to speak and write professionally', 'Ability and comfort with presenting work by phone or within small groups']","['Working closely with both the Planning and Analytics teams, Data Sciences designs and implements statistical models and machine learning solutions that tie our clients’ marketing to real-world business goals', 'You will work very closely with planning, audience strategy and analytics teams to help them solve marketing problems', 'They also contribute crucial intellectual capital to the data science team by sharing knowledge and designing models and Data Science solutions based on their clients’ business needs and using data to tell great stories', 'A Senior Analyst will also help formulate a vision for their accounts and bring that vision to life', 'Design, estimate, tune, score and maintain advanced statistical and mathematical models (e.g. classification, numeric forecasts, customer segmentation, customer propensity, attribution, etc.)', 'Produce accurate statistical analysis and ensure high quality of the data analysis produced', 'Interpret, document and present/communicate analytical results to multiple business disciplines, providing conclusions and recommendations', 'Take analytical objectives and define data requirements', 'Extract, clean, and transform both customer level, and aggregated data for analysis, modelling, segmentation and reporting']",True,[],,"['Classification Models', 'Numeric Forecasting Models', 'Customer Segmentation', 'Customer Propensity Models', 'Attribution Models', 'Statistical Analysis', 'Data Extraction, Cleaning, and Transformation', 'SQL Programming', 'Python or R Programming', 'Mathematical Modeling and Probability', 'ARIMA Models', 'Linear Regression', 'Logistic Regression', 'Centroid-based Clustering', 'Hierarchical Clustering', 'Principal Component Analysis (PCA)', 'Decision Trees and Random Forests', 'Bayesian Inference', 'Markov Chain Monte Carlo (MCMC)', 'Marketing Mix Modeling (MMM)', 'Multi-touch Attribution (MTA)', 'Media Analytics', 'Ad Servers, DSP, DMPs, CRMs, Syndicated Research']","Classification Models: Design, estimate, tune, score and maintain classification models to solve marketing problems and understand customer behavior.; Numeric Forecasting Models: Develop numeric forecasting models to predict future marketing and business performance.; Customer Segmentation: Apply customer segmentation techniques to group audiences for targeted marketing and analysis.; Customer Propensity Models: Build models to estimate customer propensity for specific behaviors or outcomes relevant to marketing goals.; Attribution Models: Design and maintain attribution models to understand the impact of marketing touchpoints on business outcomes.; Statistical Analysis: Produce accurate statistical analyses to ensure high quality data insights and support business decisions.; Data Extraction, Cleaning, and Transformation: Extract, clean, and transform customer-level and aggregated data for analysis, modeling, segmentation, and reporting.; SQL Programming: Use SQL programming to query and manage relational databases for data analysis and model development.; Python or R Programming: Utilize Python or R programming languages for machine learning and statistical modeling tasks.; Mathematical Modeling and Probability: Apply mathematical modeling, probability, and statistics principles to design and simulate stochastic systems relevant to marketing analytics.; ARIMA Models: Use ARIMA models for time-series forecasting related to marketing and business performance.; Linear Regression: Implement linear regression models to analyze relationships between variables and predict outcomes.; Logistic Regression: Apply logistic regression for classification tasks such as customer propensity and segmentation.; Centroid-based Clustering: Use centroid-based clustering methods to identify natural groupings within customer data.; Hierarchical Clustering: Apply hierarchical clustering techniques for audience segmentation and pattern discovery.; Principal Component Analysis (PCA): Use PCA for dimensionality reduction and feature extraction in marketing data analysis.; Decision Trees and Random Forests: Build decision tree and random forest models for classification and regression tasks in marketing analytics.; Bayesian Inference: Employ Bayesian inference methods to incorporate prior knowledge and uncertainty in statistical models.; Markov Chain Monte Carlo (MCMC): Use MCMC techniques for simulation and estimation in complex probabilistic models.; Marketing Mix Modeling (MMM): Apply marketing mix modeling to quantify the impact of various marketing channels on sales and ROI.; Multi-touch Attribution (MTA): Use multi-touch attribution models to assign credit to multiple marketing touchpoints influencing customer actions.; Media Analytics: Leverage media analytics expertise, especially in digital media, to analyze audience behavior and campaign effectiveness.; Ad Servers, DSP, DMPs, CRMs, Syndicated Research: Utilize data and insights from ad servers, demand-side platforms, data management platforms, customer relationship management systems, and syndicated research to inform marketing analytics."
qvzZMIg_4APWJ89BAAAAAA==,"Senior, Data Scientist","Position Summary...Design and develop scalable and efficient knowledge graph solutions to model complex relationships within our vast data sets.

Collaborate with cross-functional teams to identify and extract relevant data from various sources, ensuring data quality and integrity.

Utilize your expertise in knowledge graph construction, ontology development, and semantic reasoning to enhance data integration and analysis.

Develop algorithms and machine learning models to uncover patterns, insights, and predictive analytics within the knowledge graph.

Apply advanced statistical techniques and data visualization methods to effectively communicate complex concepts and findings to both technical and non-technical stakeholders.

Stay up-to-date with the latest advancements in knowledge graph technologies and contribute to the company's knowledge base by sharing best practices and emerging trends.

What you'll do...

Walmart employees more than 2.3 million employees worldwide, with 1.6 million associates in the U.S. Walmart hires 500,000 applicants a year to fill thousands of job profiles from engineers, designers, marketers to pilots and buyers and promotes more than 300,000 people to jobs of greater responsibility. People.AI team is responsible for developing and deploying AI/ML solutions supporting the Global People function.

About Team:
The Enterprise People Technology team supports the successful deployment and adoption of new People technology across the enterprise. As a Fortune #1 company, our work impacts millions of associates globally. We strive to continuously improve people technology and products to help managers and associates so they can focus on what matters most - supporting our customers and members. People Technology is one of the major segments of Walmart Global Techs Enterprise Business Services, which is invested in building a compact, robust organization that includes service operations and technology solutions for Finance, People, and the Associate Digital Experience.

What you'll do:
• Work in a highly collaborative environment with a multidisciplinary team.
• Work with data scientists to design, architect, and build AI/ML model and model systems.
• Work with machine learning engineers to deploy, operate, and optimize scalable solutions
• Work with product managers to design user journeys, feedback loop and analyze user telemetry.
• Create opportunities to develop yourself with an end-to-end AI/ML product experience.
• Work with a set of robust work standards to ensure we build trustworthy AI/ML solutions

What you'll bring:

Experience with statistical analysis and programming languages e.g. Python and mainstream machine learning frameworks, e.g. Tensor Flow or Py Torch.
• Expertise in building and deploying machine learning models for real-world applications.
• Experience with model evaluation, optimization, and tuning for performance improvements.
• Ability to lead end-to-end data science projects, from solution design, data collection and preprocessing to model development, validation, and deployment.
• Collaborate with domain experts to define problem statements and translate business objectives into actionable data science solutions.
• Added bonus if you have experience with Large Language Model or creation, maintenance, and utilization of knowledge graphs, working with graph databases such as Neo4j, or similar.

About Walmart Global Tech
Imagine working in an environment where one line of code can make life easier for hundreds of millions of people. Thats what we do at Walmart Global Tech. Were a team of software engineers, data scientists, cybersecurity experts and service professionals within the worlds leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.

Flexible, hybrid work:
We use a hybrid way of working that is primarily in office coupled with virtual when not onsite. Our campuses serve as a hub to enhance collaboration, bring us together for purpose and deliver on business needs. This approach helps us make quicker decisions, remove location barriers across our global team and be more flexible in our personal lives.

Benefits:
Benefits: Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.

Equal Opportunity Employer:
Walmart, Inc. is an Equal Opportunity Employer By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing unique styles, experiences, identities, ideas and opinions while being welcoming of all people.

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

‎

‎

‎
You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.

‎

For information about PTO, see https://one.walmart.com/notices.

‎

‎
Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

‎
Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

‎

For information about benefits and eligibility, see One.Walmart.

‎
The annual salary range for this position is $90,000.00-$180,000.00

‎
Additional compensation includes annual or quarterly performance bonuses.

‎
Additional compensation for certain positions may also include:

‎

‎
- Stock

‎

‎

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1- Bachelor’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years' experience in an analytics related field. Option 2- Master’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years' experience in an analytics related field. Option 3 - 5 years' experience in an analytics or related field.

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data science, machine learning, optimization models, Master’s degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.

Primary Location...

508 Sw 8Th St, Bentonville, AR 72712, United States of America",2025-07-21T00:00:00.000Z,2025-07-25,"['Experience with statistical analysis and programming languages e.g. Python and mainstream machine learning frameworks, e.g', 'Tensor Flow or Py Torch', 'Added bonus if you have experience with Large Language Model or creation, maintenance, and utilization of knowledge graphs, working with graph databases such as Neo4j, or similar', 'That means understanding, respecting and valuing unique styles, experiences, identities, ideas and opinions while being welcoming of all people', ""Option 1- Bachelor’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years' experience in an analytics related field"", ""Option 2- Master’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years' experience in an analytics related field"", ""Option 3 - 5 years' experience in an analytics or related field"", 'Data science, machine learning, optimization models, Master’s degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly', 'The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture']","['Collaborate with cross-functional teams to identify and extract relevant data from various sources, ensuring data quality and integrity', 'Utilize your expertise in knowledge graph construction, ontology development, and semantic reasoning to enhance data integration and analysis', 'Develop algorithms and machine learning models to uncover patterns, insights, and predictive analytics within the knowledge graph', 'Apply advanced statistical techniques and data visualization methods to effectively communicate complex concepts and findings to both technical and non-technical stakeholders', ""Stay up-to-date with the latest advancements in knowledge graph technologies and contribute to the company's knowledge base by sharing best practices and emerging trends"", 'Work in a highly collaborative environment with a multidisciplinary team', 'Work with data scientists to design, architect, and build AI/ML model and model systems', 'Work with machine learning engineers to deploy, operate, and optimize scalable solutions', 'Work with product managers to design user journeys, feedback loop and analyze user telemetry', 'Create opportunities to develop yourself with an end-to-end AI/ML product experience', 'Work with a set of robust work standards to ensure we build trustworthy AI/ML solutions', 'Expertise in building and deploying machine learning models for real-world applications', 'Experience with model evaluation, optimization, and tuning for performance improvements', 'Ability to lead end-to-end data science projects, from solution design, data collection and preprocessing to model development, validation, and deployment', 'Collaborate with domain experts to define problem statements and translate business objectives into actionable data science solutions']",True,['Large Language Models'],"Large Language Models: Experience with Large Language Models as an added bonus, indicating familiarity with creation, maintenance, and utilization of LLMs in AI/ML solutions.","['Knowledge Graphs', 'Statistical Analysis', 'Machine Learning Models', 'Data Integration and Extraction', 'Data Visualization', 'Python Programming', 'Machine Learning Frameworks', 'Data Science Project Lifecycle', 'Optimization Models', 'Graph Databases', 'Collaborative Data Science', 'Programming Languages for Analytics']","Knowledge Graphs: Used to model complex relationships within large data sets and enhance data integration and analysis through construction, ontology development, and semantic reasoning.; Statistical Analysis: Applied advanced statistical techniques to communicate complex concepts and findings effectively to both technical and non-technical stakeholders.; Machine Learning Models: Developed and deployed machine learning models to uncover patterns, insights, and predictive analytics within knowledge graphs and real-world applications, including model evaluation, optimization, and tuning for performance improvements.; Data Integration and Extraction: Collaborated with cross-functional teams to identify and extract relevant data from various sources while ensuring data quality and integrity.; Data Visualization: Utilized data visualization methods to effectively communicate complex concepts and findings.; Python Programming: Used Python as a primary programming language for statistical analysis and machine learning model development.; Machine Learning Frameworks: Experience with mainstream machine learning frameworks such as TensorFlow and PyTorch for building and deploying models.; Data Science Project Lifecycle: Led end-to-end data science projects including solution design, data collection, preprocessing, model development, validation, and deployment.; Optimization Models: Applied optimization models as part of data science and machine learning solutions.; Graph Databases: Worked with graph databases such as Neo4j for knowledge graph creation, maintenance, and utilization.; Collaborative Data Science: Collaborated with domain experts and multidisciplinary teams to translate business objectives into actionable data science solutions.; Programming Languages for Analytics: Proficient in programming languages including Python, Spark, Scala, and R for analytics and data science tasks."
EcS_-mF0XtNHRfx0AAAAAA==,Insight Global,"A client in the Nashville area is looking for a strong Data Scientist that is strong in data ingesting, data cleansing, feature engineering, data filtering and aggregating, statistical estimation and hypothesis testing, machine learning and iterative development and continuous production integration and deployment. They will be supporting the clients Medicaid clients, but wrangling healthcare and other client data assets. They will be analyzing them iteratively to surface complex, impactfully actionable insights.",,2025-07-25,,"['A client in the Nashville area is looking for a strong Data Scientist that is strong in data ingesting, data cleansing, feature engineering, data filtering and aggregating, statistical estimation and hypothesis testing, machine learning and iterative development and continuous production integration and deployment', 'They will be supporting the clients Medicaid clients, but wrangling healthcare and other client data assets', 'They will be analyzing them iteratively to surface complex, impactfully actionable insights']",True,[],,"['Data Ingestion', 'Data Cleansing', 'Feature Engineering', 'Data Filtering and Aggregation', 'Statistical Estimation and Hypothesis Testing', 'Machine Learning', 'Iterative Development and Continuous Production Integration and Deployment']",Data Ingestion: Responsible for acquiring and importing healthcare and other client data assets for analysis.; Data Cleansing: Involves cleaning and preparing data to ensure quality and accuracy for downstream analysis.; Feature Engineering: Creating and transforming variables from raw data to improve model performance.; Data Filtering and Aggregation: Processing data by filtering and summarizing to support analysis and insight generation.; Statistical Estimation and Hypothesis Testing: Applying statistical methods to estimate parameters and test assumptions within healthcare data.; Machine Learning: Developing predictive models and iterative development to extract actionable insights from data.; Iterative Development and Continuous Production Integration and Deployment: Engaging in repeated cycles of model development and deploying models into production environments for ongoing use.
B_2B0qIwNl6JcClEAAAAAA==,Professional Development Program (PDP) Internship - Data Science Summer 2026,"Professional Development Program (PDP) Internship - Data Science Summer 2026

The world needs solutions, and we need you! At BASF, we create chemistry through the power of connected minds. By balancing economic success with environmental protection and social responsibility, we are building a more sustainable future through chemistry. As the world’s leading chemical company, we help our customers in nearly every industry meet the current and future needs of society through science and innovation.

Join BASF for our 10 to 12-week Data Science Professional Development Program (PDP) Internship, where you'll immerse yourself in our dynamic Production, Manufacturing, Business, and Research and Development (R&D) teams. This internship offers a unique opportunity to gain hands-on experience while working on impactful projects that support our business objectives. You’ll collaborate closely with seasoned professionals, gaining insights into our data science processes and strategies.

Our internship is designed to accelerate your career growth by providing you with leadership opportunities and strategic insights critical for a successful future in data science.

We welcome applicants who are mobile-minded and open to relocation, as you may have the opportunity to be placed at any BASF site across the country. This will enhance your exposure to diverse business environments and deepen your understanding of our global operations.

Embrace this opportunity to kickstart your career at BASF, where innovation and collaboration drive our success!

Are you ready to create change?

In our Data Science program, no two days are alike. You'll engage in a dynamic environment where you'll tackle diverse challenges, collaborate with cross-functional teams, and adapt to rapidly changing situations. This role offers the opportunity to innovate and problem-solve in real-time, making every day an exciting and unique experience.

Some key areas of impact may include:
• During the PDP program, you will get the opportunity to work within various areas across the organization such as Production, Manufacturing, Business (Sales & Marketing), and Research and Development (R&D) teams.
• You will work closely with talented data scientists to gain experience with the technical and scientific aspects of plant engineering. You will work with mentors and have exposure to senior leadership through high impact initiatives.
• You will be “hands-on” and will have the opportunity to lead high value projects, to execute deliverables during all phases of an analytics project – starting from project definition to completion.
• Some of the deliverables will include the development of appropriate machine learning and optimization models, collaborating with members from other functions to gather and validate the necessary data, and presenting the project results and benefits to key stakeholders and internal clients.

Unlock Your Potential: More than Just a Job

Professional Development:

Exposure to data science applications and digital tools such as Python, R, RShinv, Dash, Flask, HTML, Git, SQL, Tableau and PowerBI, AWS, Databricks, Azure, Virtual environments and Docker containers, and many more. At the end of the internship, you will present your summer project to fellow interns, BASF employees, and senior leaders, showcasing your impact and contributions.

Mentorship

Each participant will be assigned a peer mentor for their internship. Peer mentors are full-time program participants and serve as a guide throughout the program. You will develop your expertise and the ability to network at senior levels throughout BASF and establish mentoring relationships that could span your whole career.

Networking

Interns have the opportunity to participate in Employee Resource Groups (ERGs) at their site. Successfully engaging across the business throughout your internship will expand your network, allow you to grow personally and professionally, and learn a variety of valuable skill sets. Interns will also participate in a week-long orientation during which they will have the opportunity to engage with alumni and executive leadership at our headquarters in New Jersey. Additionally, interns will collaborate with full-time P/LDP program participants to organize and participate in a community service volunteer day in celebration of National Intern Day.

Your Unique Blend: What We’re Looking For

The ideal candidate for our Professional Development Program internship at BASF is a student majoring in Data Science, Data Analytics, Applied Mathematics, Statistics, Chemical Engineering, Mechanical Engineering, or other related Engineering Majors, with a graduation date between December 2026 and July 2029.
• Candidates must have a minimum cumulative GPA of a 3.2.
• Candidates must have familiarity with tools such as Python and R programing
• Candidates must have basic knowledge of machine learning, artificial intelligence, big data, and new technologies.
• Candidates must be authorized to work in the U.S. without restrictions and be willing to relocate anywhere in the country during and after the program, as all assignments are in-person or hybrid.
• Candidates should demonstrate previous leadership experience and academic achievement, along with active participation in extracurricular activities and on-campus organizations.
• Previous internship/co-op experience is preferred.
• Candidates should have a strong interest in the manufacturing or chemical industry. Project management experience is also beneficial.

Interns will be assessed for a potential returning internship offer or full-time position in our 2-year rotational program. Mobility is crucial, with potential locations including Michigan, North Carolina, Texas, and Louisiana.

We are always working to form the best team—especially from within, with an emphasis on lifelong learning and career development!

Who We Are

BASF Corporation, headquartered in Florham Park, New Jersey, is the North American affiliate of BASF SE, Ludwigshafen, Germany. BASF has approximately 16,000 employees in North America and had sales of $19.7 billion in 2024.

At BASF, we create chemistry for a sustainable future. Our ambition: We want to be the preferred chemical company to enable our customers’ green transformation. We combine economic success with environmental protection and social responsibility. Around 112,000 employees in the BASF Group contribute to the success of our customers in nearly all sectors and almost every country in the world. Our portfolio comprises, as core businesses, the segments Chemicals, Materials, Industrial Solutions, and Nutrition & Care; our standalone businesses are bundled in the segments Surface Technologies and Agricultural Solutions.

At BASF, we are committed to creating an exceptional workplace that values diversity and prioritizes our employees' well-being and development. Our dedication has been recognized through various awards and accolades. In 2024-25, BASF received the Platinum Bell Seal for Workplace Mental Health from Mental Health America, as well as the Business Group on Health’s Best Employers: Excellence in Health & Well-being award. We were recognized by PLANSPONSOR for having a 2025 Best In Class 401(k) Plan and ranked among the Top 50 Employers by readers of Minority Engineer Magazine. Fair360 (formerly Diversity Inc) also placed us 22nd on their 2024 Top 50 Companies List. Additionally, we were named one of America's Best Large Employers and one of the World's Best Employers by Forbes and Statista. For the 11th consecutive year, we achieved a top score in the Human Rights Campaign Foundation’s Corporate Equality Index, earning the 2025 “Equality 100 Award"" as a leader in LGBTQ+ workplace inclusion.

To learn more about our programs, visit www.basf.com/universitycareers.

Privacy Statement

BASF takes security & data privacy very seriously. We will never request financial information of any kind via email, private text message or direct message on any social medial platform or job board. Furthermore, we will never send a candidate a check for equipment or request any type of payment during the job application process. If you have experienced any of the above, please contact myhr@basf.com to report fraud.

Pay Transparency

BASF is committed to pay transparency practices. The competitive Pay Range for this role is $1,907- $2,340 semi monthly. Actual pay will be determined based on education, certifications, experience, and other job-related factors permitted by law.

Equal Employment Opportunities

We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, age, citizenship, color, religion, sex, marital status, national origin, disability status, gender identity or expression, protected veteran status, or any other characteristic protected by law.

Applicants must be currently authorized to work in the United States on a full-time basis.",2025-07-22T00:00:00.000Z,2025-07-25,"['Exposure to data science applications and digital tools such as Python, R, RShinv, Dash, Flask, HTML, Git, SQL, Tableau and PowerBI, AWS, Databricks, Azure, Virtual environments and Docker containers, and many more', 'The ideal candidate for our Professional Development Program internship at BASF is a student majoring in Data Science, Data Analytics, Applied Mathematics, Statistics, Chemical Engineering, Mechanical Engineering, or other related Engineering Majors, with a graduation date between December 2026 and July 2029', 'Candidates must have a minimum cumulative GPA of a 3.2', 'Candidates must have familiarity with tools such as Python and R programing', 'Candidates must have basic knowledge of machine learning, artificial intelligence, big data, and new technologies', 'Candidates must be authorized to work in the U.S. without restrictions and be willing to relocate anywhere in the country during and after the program, as all assignments are in-person or hybrid', 'Candidates should demonstrate previous leadership experience and academic achievement, along with active participation in extracurricular activities and on-campus organizations', 'Candidates should have a strong interest in the manufacturing or chemical industry', 'Project management experience is also beneficial', 'Interns will be assessed for a potential returning internship offer or full-time position in our 2-year rotational program', 'Applicants must be currently authorized to work in the United States on a full-time basis']","['This role offers the opportunity to innovate and problem-solve in real-time, making every day an exciting and unique experience', 'During the PDP program, you will get the opportunity to work within various areas across the organization such as Production, Manufacturing, Business (Sales & Marketing), and Research and Development (R&D) teams', 'You will work closely with talented data scientists to gain experience with the technical and scientific aspects of plant engineering', 'You will work with mentors and have exposure to senior leadership through high impact initiatives', 'You will be “hands-on” and will have the opportunity to lead high value projects, to execute deliverables during all phases of an analytics project – starting from project definition to completion', 'Some of the deliverables will include the development of appropriate machine learning and optimization models, collaborating with members from other functions to gather and validate the necessary data, and presenting the project results and benefits to key stakeholders and internal clients', 'At the end of the internship, you will present your summer project to fellow interns, BASF employees, and senior leaders, showcasing your impact and contributions', 'Additionally, interns will collaborate with full-time P/LDP program participants to organize and participate in a community service volunteer day in celebration of National Intern Day']",True,[],,"['Python', 'R', 'SQL', 'Tableau', 'Power BI', 'Machine Learning', 'Optimization Models', 'Data Science', 'Big Data', 'Dash', 'Flask', 'Git', 'AWS', 'Databricks', 'Azure', 'Virtual Environments', 'Docker Containers', 'Project Management']","Python: Used as a primary programming language for data science applications and analytics projects during the internship.; R: Utilized for data analysis and statistical computing as part of the data science toolkit in the internship.; SQL: Employed for data querying and management to gather and validate necessary data for analytics projects.; Tableau: Used as a BI tool to create dashboards and visualize data insights for stakeholders.; Power BI: Applied as a business intelligence tool to develop dashboards and support data-driven decision making.; Machine Learning: Interns develop machine learning models as part of project deliverables to solve business problems and optimize processes.; Optimization Models: Built during projects to improve operational efficiency and support decision-making in production and manufacturing contexts.; Data Science: The core focus of the internship, involving hands-on experience with data analysis, modeling, and collaboration with cross-functional teams.; Big Data: Basic knowledge expected; relevant to handling large datasets and applying data science techniques in the internship.; Dash: Used as a digital tool for building interactive web applications and dashboards in data science projects.; Flask: Utilized as a web framework to develop data science applications and deploy models or dashboards.; Git: Used for version control and collaboration on code during data science projects.; AWS: Cloud platform exposure provided to support data science workflows and infrastructure needs.; Databricks: Platform exposure offered for big data processing and collaborative data science work.; Azure: Cloud service used to support data science projects and infrastructure during the internship.; Virtual Environments: Used to manage project dependencies and isolate Python environments for reproducible data science workflows.; Docker Containers: Applied to containerize applications and ensure consistent deployment of data science projects.; Project Management: Experience beneficial for leading analytics projects from definition through completion, coordinating deliverables and stakeholder communication."
LSw3Xmtkv-uhV02OAAAAAA==,Data Scientist  II  - Graph Data Platform - Client Protection,"Job Description:

At Bank of America, we are guided by a common purpose to help make financial lives better through the power of every connection. We do this by driving Responsible Growth and delivering for our clients, teammates, communities and shareholders every day.

Being a Great Place to Work is core to how we drive Responsible Growth. This includes our commitment to being an inclusive workplace, attracting and developing exceptional talent, supporting our teammates physical, emotional, and financial wellness, recognizing and rewarding performance, and how we make an impact in the communities we serve.

Bank of America is committed to an in-office culture with specific requirements for office-based attendance and which allows for an appropriate level of flexibility for our teammates and businesses based on role-specific considerations.

At Bank of America, you can build a successful career with opportunities to learn, grow, and make an impact. Join us!

Job Summary

This job is responsible for reviewing and interpretating large datasets to uncover revenue generation opportunities and ensuring the development of effective risk management strategies. Key responsibilities include working with lines of business to comprehend problems, utilizing sophisticated analytics and deploying advanced techniques to devise solutions, and presenting recommendations based on findings. Job expectations include demonstrating leadership, resilience, accountability, a disciplined approach, and a commitment to fostering responsible growth for the enterprise.

This job is responsible for supporting advanced analytics technical development and the pathway to optimality, scalability, and sustainability in close partnership with Bank of America Technology. This work closely integrates with business efforts to improve portfolio risk, profitability, performance forecasting, and operational performance for customer products and related divisions such as credit cards. Key responsibilities include applying knowledge of multiple business and technical-related topics and independently driving strategic improvements, large-scale projects, and initiatives. Job expectations include working with counterparts within the Line of Business, across the technology organization, and risk teams.

Client Protection Shared Services Advanced Analytics is looking for a seasoned and energetic data science leader to join our team as a Lead Data Scientist and help us deliver data science products to the production environment especially for scalable graph analytics. In this role, you will be expected to work on large and complex data science projects. Collaborating with internal strategy, technology, product, and policy partners to deploy advanced analytical solutions with the goal of reducing fraud losses, lowering false positive impacts, improving client experience, and ensuring the Bank minimizes its total cost of fraud.

Responsibilities:
• Enables business analytics, including data analysis, trend identification, and pattern recognition, using advanced techniques to drive decision making and collection data driven insights
• Applies agile practices for project management, solution development, deployment, and maintenance
• Develops and reviews technical documentation, capturing the business requirements, and specifications related to the developed analytical solution and implementation in production
• Manages multiple priorities and ensures quality and timeliness of work deliverables such as quantitative models, data science products, data analysis reports, or data visualizations, while exhibiting the ability to work independently and in a team environment
• Delivers presentations in an engaging and effective manner through in-person and virtual conversations that communicates technical concepts and analysis results to a diverse set of internal stakeholders, and develops professional relationships to foster collaboration on work deliverables
• Supports the identification of potential issues and development of controls
• Maintains knowledge of the latest advances in the fields of data science and artificial intelligence to support business analytics
• Manages a roadmap of data science use cases for technical development and implementation to the production environment in close partnership with Bank of America Technology
• Manages relationships with multiple technology platform and development team leaders including alignment of roadmaps, managing projects, and managing risks
• Engages business and technology senior leaders on reporting of project/deliverable statuses, opportunity identification, and planning efforts
• Oversees development, delivery and quality assurance for data science use cases delivered to the production environment and other areas of the line of business
• Performs complex analysis of financial models, market data, financial data, and portfolio trends to understand product performance and improve portfolio risk, profitability, performance forecasting, and operational performance
• Coaches and mentors peers to improve proficiency in a variety of systems and serves as a subject matter expert on multiple business and technical-related topics
• Identifies business trends based on economic and portfolio conditions and communicates findings to senior management
• Supports execution of large scale projects, such as platform conversions or new project integrations by conducting advanced reporting and drawing analytics based insights
• Link Analysis/Graph analytics to find and mitigate densely connected fraud networks
• Developing and tuning graph algorithms to maximize detection of fraud
• Assist with the generation, prioritization, and investigation of fraud rings

Required Qualifications

Minimum of 4 years of experience in data and analytics

Must have familiarity with Graph databases (e.g. TigerGraph, Neo4J) and graph query languages

Must be proficient with SQL and one of SAS, Python, or Java

Critical problem-solving skills including selection of data and deployment of solutions

Proven ability to manage projects, exercise thought leadership and work with limited direction on complex problems to achieve project goals while also leading a broader team

Excellent communication and influencing skills

Thrives in fast-paced and highly dynamic environment

Intellectual curiosity and strong urge to figure out the whys of a problem and come up with creative solutions

Expertise handling data across its lifecycle in a variety of formats and storage technologies (e.g., structured, semi-structured, unstructured; graph; hadoop; kafka)

Expertise in data analytics and technical development lifecycles including having coached junior staff

Desired Qualifications

Advanced STEM (Science, Technology, Engineering, Math) degree (Masters or PhD)

7+ years of experience; work in financial services is very helpful, with preference to fraud, credit, cybersecurity, or other heavily quantitative areas

Deep understanding of graph databases, graph algorithms, and experience developing graph schemas

Understanding of advanced machine learning methodologies including neural networks, ensemble learning like XGB, and other techniques

Proficient with H2O or similar advanced analytical tools

Experience managing multi-year roadmaps, engaging technical and non-technical stakeholders, and leading large cross-functional formal projects

Experience influencing mid to senior (executive) level leaders

Experience managing risk and issue remediation

Understanding of computer science topics like automation, code versioning, computational complexity, parallel processing, requirements gathering, testing methodologies, and development lifecycle models like Agile

Skills:
• Agile Practices
• Application Development
• DevOps Practices
• Technical Documentation
• Written Communications
• Artificial Intelligence/Machine Learning
• Business Analytics
• Data Visualization
• Presentation Skills
• Risk Management
• Adaptability
• Collaboration
• Consulting
• Networking
• Policies, Procedures, and Guidelines Management

Shift:
1st shift (United States of America)

Hours Per Week:
40

Pay Transparency details

US - IL - Chicago - 110 N Wacker Dr - Bank Of America Tower Chicago (IL4110), US - NY - New York - 1114 Avenue Of The Americas - Grace (NY1544)

Pay and benefits information

Pay range

$165,000.00 - $246,200.00 annualized salary, offers to be determined based on experience, education and skill set.

Discretionary incentive eligible

This role is eligible to participate in the annual discretionary plan. Employees are eligible for an annual discretionary award based on their overall individual performance results and behaviors, the performance and contributions of their line of business and/or group; and the overall success of the Company.

Benefits

This role is currently benefits eligible. We provide industry-leading benefits, access to paid time off, resources and support to our employees so they can make a genuine impact and contribute to the sustainable growth of our business and the communities we serve.",2025-07-07T00:00:00.000Z,2025-07-25,"['Minimum of 4 years of experience in data and analytics', 'Must have familiarity with Graph databases (e.g. TigerGraph, Neo4J) and graph query languages', 'Must be proficient with SQL and one of SAS, Python, or Java', 'Critical problem-solving skills including selection of data and deployment of solutions', 'Proven ability to manage projects, exercise thought leadership and work with limited direction on complex problems to achieve project goals while also leading a broader team', 'Excellent communication and influencing skills', 'Thrives in fast-paced and highly dynamic environment', 'Intellectual curiosity and strong urge to figure out the whys of a problem and come up with creative solutions', 'Expertise handling data across its lifecycle in a variety of formats and storage technologies (e.g., structured, semi-structured, unstructured; graph; hadoop; kafka)', 'Expertise in data analytics and technical development lifecycles including having coached junior staff', 'Advanced STEM (Science, Technology, Engineering, Math) degree (Masters or PhD)', '7+ years of experience; work in financial services is very helpful, with preference to fraud, credit, cybersecurity, or other heavily quantitative areas', 'Deep understanding of graph databases, graph algorithms, and experience developing graph schemas', 'Understanding of advanced machine learning methodologies including neural networks, ensemble learning like XGB, and other techniques', 'Proficient with H2O or similar advanced analytical tools', 'Experience managing multi-year roadmaps, engaging technical and non-technical stakeholders, and leading large cross-functional formal projects', 'Experience influencing mid to senior (executive) level leaders', 'Experience managing risk and issue remediation', 'Understanding of computer science topics like automation, code versioning, computational complexity, parallel processing, requirements gathering, testing methodologies, and development lifecycle models like Agile', 'Agile Practices', 'Application Development', 'Technical Documentation', 'Written Communications', 'Artificial Intelligence/Machine Learning', 'Business Analytics', 'Data Visualization', 'Presentation Skills', 'Risk Management', 'Adaptability', 'Collaboration', 'Consulting', 'Networking', 'Policies, Procedures, and Guidelines Management']","['This job is responsible for reviewing and interpretating large datasets to uncover revenue generation opportunities and ensuring the development of effective risk management strategies', 'Key responsibilities include working with lines of business to comprehend problems, utilizing sophisticated analytics and deploying advanced techniques to devise solutions, and presenting recommendations based on findings', 'Job expectations include demonstrating leadership, resilience, accountability, a disciplined approach, and a commitment to fostering responsible growth for the enterprise', 'This job is responsible for supporting advanced analytics technical development and the pathway to optimality, scalability, and sustainability in close partnership with Bank of America Technology', 'This work closely integrates with business efforts to improve portfolio risk, profitability, performance forecasting, and operational performance for customer products and related divisions such as credit cards', 'Key responsibilities include applying knowledge of multiple business and technical-related topics and independently driving strategic improvements, large-scale projects, and initiatives', 'Job expectations include working with counterparts within the Line of Business, across the technology organization, and risk teams', 'Client Protection Shared Services Advanced Analytics is looking for a seasoned and energetic data science leader to join our team as a Lead Data Scientist and help us deliver data science products to the production environment especially for scalable graph analytics', 'In this role, you will be expected to work on large and complex data science projects', 'Collaborating with internal strategy, technology, product, and policy partners to deploy advanced analytical solutions with the goal of reducing fraud losses, lowering false positive impacts, improving client experience, and ensuring the Bank minimizes its total cost of fraud', 'Enables business analytics, including data analysis, trend identification, and pattern recognition, using advanced techniques to drive decision making and collection data driven insights', 'Applies agile practices for project management, solution development, deployment, and maintenance', 'Develops and reviews technical documentation, capturing the business requirements, and specifications related to the developed analytical solution and implementation in production', 'Manages multiple priorities and ensures quality and timeliness of work deliverables such as quantitative models, data science products, data analysis reports, or data visualizations, while exhibiting the ability to work independently and in a team environment', 'Delivers presentations in an engaging and effective manner through in-person and virtual conversations that communicates technical concepts and analysis results to a diverse set of internal stakeholders, and develops professional relationships to foster collaboration on work deliverables', 'Supports the identification of potential issues and development of controls', 'Maintains knowledge of the latest advances in the fields of data science and artificial intelligence to support business analytics', 'Manages a roadmap of data science use cases for technical development and implementation to the production environment in close partnership with Bank of America Technology', 'Manages relationships with multiple technology platform and development team leaders including alignment of roadmaps, managing projects, and managing risks', 'Engages business and technology senior leaders on reporting of project/deliverable statuses, opportunity identification, and planning efforts', 'Oversees development, delivery and quality assurance for data science use cases delivered to the production environment and other areas of the line of business', 'Performs complex analysis of financial models, market data, financial data, and portfolio trends to understand product performance and improve portfolio risk, profitability, performance forecasting, and operational performance', 'Coaches and mentors peers to improve proficiency in a variety of systems and serves as a subject matter expert on multiple business and technical-related topics', 'Identifies business trends based on economic and portfolio conditions and communicates findings to senior management', 'Supports execution of large scale projects, such as platform conversions or new project integrations by conducting advanced reporting and drawing analytics based insights', 'Link Analysis/Graph analytics to find and mitigate densely connected fraud networks', 'Developing and tuning graph algorithms to maximize detection of fraud', 'Assist with the generation, prioritization, and investigation of fraud rings', 'DevOps Practices']",True,[],,"['Graph Databases', 'Graph Algorithms', 'SQL', 'Python', 'SAS', 'Java', 'Advanced Machine Learning Methodologies', 'XGBoost', 'H2O', 'Data Analytics', 'Business Analytics', 'Data Visualization', 'Quantitative Models', 'Data Science Products', 'Data Pipelines', 'Agile Practices', 'Link Analysis', 'Hadoop', 'Kafka']","Graph Databases: Used for managing and querying graph-structured data to support scalable graph analytics and fraud detection by analyzing densely connected fraud networks.; Graph Algorithms: Developed and tuned to maximize detection of fraud by analyzing relationships and patterns within graph data.; SQL: Proficient use required for querying structured data as part of data analysis and solution deployment.; Python: Used as a programming language for data analysis, model development, and deployment of data science solutions.; SAS: One of the programming tools used for data analysis and statistical modeling.; Java: Used as a programming language option for data science and application development.; Advanced Machine Learning Methodologies: Includes neural networks, ensemble learning such as XGBoost, and other techniques applied to improve fraud detection and risk management.; XGBoost: An ensemble learning method used for predictive modeling and improving fraud detection accuracy.; H2O: An advanced analytical tool used for building and deploying machine learning models.; Data Analytics: Involves reviewing and interpreting large datasets to uncover revenue opportunities, improve portfolio risk, profitability, and operational performance.; Business Analytics: Used to enable data-driven decision making through trend identification, pattern recognition, and advanced analytical techniques.; Data Visualization: Creating visual representations of data analysis results to communicate insights effectively to stakeholders.; Quantitative Models: Developed and delivered as part of data science products to support risk management and fraud detection.; Data Science Products: Includes models and analytical solutions developed and deployed to production environments to reduce fraud losses and improve client experience.; Data Pipelines: Implied through managing data science use cases lifecycle and deployment to production, ensuring scalability and sustainability.; Agile Practices: Applied for project management, solution development, deployment, and maintenance of data science and analytics projects.; Link Analysis: Used as a graph analytics technique to identify and mitigate fraud networks by analyzing connections between entities.; Hadoop: Referenced as part of expertise handling data across various storage technologies including big data platforms.; Kafka: Included as a data streaming technology used for handling data across its lifecycle."
1JXbwdk4P2mIYU2kAAAAAA==,CTIO-Data Scientist-Sr Associate,"At PwC, our people in data and analytics engineering focus on leveraging advanced technologies and techniques to design and develop robust data solutions for clients. They play a crucial role in transforming raw data into actionable insights, enabling informed decision-making and driving business growth. Those in data science and machine learning engineering at PwC will focus on leveraging advanced analytics and machine learning techniques to extract insights from large datasets and drive data-driven decision making. You will work on developing predictive models, conducting statistical analysis, and creating data visualisations to solve complex business problems.

Focused on relationships, you are building meaningful client connections, and learning how to manage and inspire others. Navigating increasingly complex situations, you are growing your personal brand, deepening technical expertise and awareness of your strengths. You are expected to anticipate the needs of your teams and clients, and to deliver quality. Embracing increased ambiguity, you are comfortable when the path forward isn’t clear, you ask questions, and you use these moments as opportunities to grow.

Examples of the skills, knowledge, and experiences you need to lead and deliver value at this level include but are not limited to:
• Respond effectively to the diverse perspectives, needs, and feelings of others.
• Use a broad range of tools, methodologies and techniques to generate new ideas and solve problems.
• Use critical thinking to break down complex concepts.
• Understand the broader objectives of your project or role and how your work fits into the overall strategy.
• Develop a deeper understanding of the business context and how it is changing.
• Use reflection to develop self awareness, enhance strengths and address development areas.
• Interpret data to inform insights and recommendations.
• Uphold and reinforce professional and technical standards (e.g. refer to specific PwC tax and audit guidance), the Firm's code of conduct, and independence requirements.

The Opportunity

As part of the Data Science and Machine Learning Engineering team you will design and develop AI/ML systems that transform client operations. As a Senior Associate, you will lead projects from conception to production, mentoring others while engaging clients to align technology with business objectives. This role allows you to stay at the forefront of AI advancements and contribute to innovative solutions that drive business success.

Responsibilities
• Conduct experiments to validate and refine models
• Stay abreast of advancements in AI and machine learning
• Work with diverse teams to foster innovation
• Translate technical models into scalable business solutions

What You Must Have
• Bachelor's Degree
• 3 years of experience

What Sets You Apart
• Demonstrating leadership in team environments
• Communicating technical concepts to diverse audiences
• Building and deploying machine learning systems
• Programming proficiency in Python
• Working with AI frameworks like Pytorch and Tensorflow
• Familiarity with MLOps and deployment tools
• Understanding generative AI model development
• Managing time effectively under deadlines
• Passion for continuous learning and knowledge acquisition

Learn more about how we work: https://pwc.to/how-we-work

PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.

As PwC is an equal opportunity employer, all qualified applicants will receive consideration for employment at PwC without regard to race; color; religion; national origin; sex (including pregnancy, sexual orientation, and gender identity); age; disability; genetic information (including family medical history); veteran, marital, or citizenship status; or, any other status protected by law.

For only those qualified applicants that are impacted by the Los Angeles County Fair Chance Ordinance for Employers, the Los Angeles' Fair Chance Initiative for Hiring Ordinance, the San Francisco Fair Chance Ordinance, San Diego County Fair Chance Ordinance, and the California Fair Chance Act, where applicable, arrest or conviction records will be considered for Employment in accordance with these laws. At PwC, we recognize that conviction records may have a direct, adverse, and negative relationship to responsibilities such as accessing sensitive company or customer information, handling proprietary assets, or collaborating closely with team members. We evaluate these factors thoughtfully to establish a secure and trusted workplace for all.

Applications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https://pwc.to/us-application-deadlines

The salary range for this position is: $55,000 - $187,000, plus individuals may be eligible for an annual discretionary bonus. For roles that are based in Maryland, this is the listed salary range for this position. Actual compensation within the range will be dependent upon the individual's skills, experience, qualifications and location, and applicable employment laws. PwC offers a wide range of benefits, including medical, dental, vision, 401k, holiday pay, vacation, personal and family sick leave, and more. To view our benefits at a glance, please visit the following link: https://pwc.to/benefits-at-a-glance",2025-07-23T00:00:00.000Z,2025-07-25,"[""Bachelor's Degree"", '3 years of experience', 'Demonstrating leadership in team environments', 'Communicating technical concepts to diverse audiences', 'Building and deploying machine learning systems', 'Programming proficiency in Python', 'Working with AI frameworks like Pytorch and Tensorflow', 'Familiarity with MLOps and deployment tools', 'Understanding generative AI model development', 'Managing time effectively under deadlines', 'Passion for continuous learning and knowledge acquisition']","['They play a crucial role in transforming raw data into actionable insights, enabling informed decision-making and driving business growth', 'Those in data science and machine learning engineering at PwC will focus on leveraging advanced analytics and machine learning techniques to extract insights from large datasets and drive data-driven decision making', 'You will work on developing predictive models, conducting statistical analysis, and creating data visualisations to solve complex business problems', 'Focused on relationships, you are building meaningful client connections, and learning how to manage and inspire others', 'Navigating increasingly complex situations, you are growing your personal brand, deepening technical expertise and awareness of your strengths', 'You are expected to anticipate the needs of your teams and clients, and to deliver quality', 'Respond effectively to the diverse perspectives, needs, and feelings of others', 'Use a broad range of tools, methodologies and techniques to generate new ideas and solve problems', 'Use critical thinking to break down complex concepts', 'Understand the broader objectives of your project or role and how your work fits into the overall strategy', 'Develop a deeper understanding of the business context and how it is changing', 'Use reflection to develop self awareness, enhance strengths and address development areas', 'Interpret data to inform insights and recommendations', ""Uphold and reinforce professional and technical standards (e.g. refer to specific PwC tax and audit guidance), the Firm's code of conduct, and independence requirements"", 'As part of the Data Science and Machine Learning Engineering team you will design and develop AI/ML systems that transform client operations', 'As a Senior Associate, you will lead projects from conception to production, mentoring others while engaging clients to align technology with business objectives', 'This role allows you to stay at the forefront of AI advancements and contribute to innovative solutions that drive business success', 'Conduct experiments to validate and refine models', 'Stay abreast of advancements in AI and machine learning', 'Work with diverse teams to foster innovation', 'Translate technical models into scalable business solutions']",True,"['Generative AI', 'PyTorch', 'TensorFlow']",Generative AI: Understanding generative AI model development to stay at the forefront of AI advancements and contribute to innovative solutions that drive business success.; PyTorch: Working with the PyTorch AI framework to build and deploy neural network models as part of AI/ML system development.; TensorFlow: Using the TensorFlow AI framework for developing and deploying neural network models within AI/ML systems.,"['Predictive Modeling', 'Statistical Analysis', 'Data Visualization', 'Machine Learning', 'Advanced Analytics', 'Python Programming', 'MLOps']",Predictive Modeling: Developing predictive models to solve complex business problems and drive data-driven decision making by extracting insights from large datasets.; Statistical Analysis: Conducting statistical analysis to interpret data and inform insights and recommendations for business growth.; Data Visualization: Creating data visualizations to communicate complex data insights effectively and support decision making.; Machine Learning: Building and deploying machine learning systems as part of designing AI/ML systems that transform client operations and enable scalable business solutions.; Advanced Analytics: Leveraging advanced analytics techniques to extract insights from large datasets and support informed decision making.; Python Programming: Using Python programming proficiency to develop machine learning models and data science solutions.; MLOps: Familiarity with MLOps and deployment tools to manage the lifecycle of machine learning models and ensure production readiness.
qt8_DrqpgWG4SnphAAAAAA==,"Manager, Data Scientist","About the position

Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making. As a Data Scientist at Capital One, you'll be part of a team that's leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives. Team Description- The Fraud Intelligence team builds the machine learning models that help protect our customers from fraudsters. We build, maintain, and manage models using a tech stack of Python, Spark, and Kubernetes.

Responsibilities
• Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love
,
• Leverage a broad stack of technologies - Python, Conda, AWS, H2O, Spark, and more - to reveal the insights hidden within huge volumes of numeric and textual data
,
• Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation
,
• Flex your interpersonal skills to translate the complexity of your work into tangible business goals

Requirements
• Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date: A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 6 years of experience performing data analytics
,
• A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 4 years of experience performing data analytics
,
• A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 1 year of experience performing data analytics
,
• At least 1 year of experience leveraging open source programming languages for large scale data analysis
,
• At least 1 year of experience working with machine learning
,
• At least 1 year of experience utilizing relational databases

Nice-to-haves
• PhD in 'STEM' field (Science, Technology, Engineering, or Mathematics) plus 3 years of experience in data science
,
• Master's Degree in 'STEM' field plus 5 years of experience in data science
,
• At least 1 year of experience working with AWS
,
• At least 4 years' experience in Python, Scala, or R for large scale data analysis
,
• At least 4 years' experience with machine learning
,
• At least 4 years' experience with SQL

Benefits
• Comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being
,
• Performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI)",,2025-07-25,"[""Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date: A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 6 years of experience performing data analytics"", ""A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 4 years of experience performing data analytics"", 'A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 1 year of experience performing data analytics', 'At least 1 year of experience leveraging open source programming languages for large scale data analysis', 'At least 1 year of experience working with machine learning', 'At least 1 year of experience utilizing relational databases', ""PhD in 'STEM' field (Science, Technology, Engineering, or Mathematics) plus 3 years of experience in data science"", ""Master's Degree in 'STEM' field plus 5 years of experience in data science"", 'At least 1 year of experience working with AWS', ""At least 4 years' experience in Python, Scala, or R for large scale data analysis"", ""At least 4 years' experience with machine learning"", ""At least 4 years' experience with SQL""]","['Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love', 'Leverage a broad stack of technologies - Python, Conda, AWS, H2O, Spark, and more - to reveal the insights hidden within huge volumes of numeric and textual data', 'Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation', 'Flex your interpersonal skills to translate the complexity of your work into tangible business goals']",True,[],,"['Statistical Modeling', 'Relational Databases', 'Python', 'Spark', 'Machine Learning', 'Conda', 'AWS', 'H2O', 'Scala', 'R', 'SQL']","Statistical Modeling: Used to personalize credit card offers and drive data-driven decision-making in financial services.; Relational Databases: Utilized for managing and querying structured data as part of data analytics and machine learning workflows.; Python: A primary programming language used for large scale data analysis, building machine learning models, and working with big data technologies like Spark.; Spark: Employed for processing and analyzing huge volumes of numeric and textual data at scale.; Machine Learning: Applied to build models that detect fraud and protect customers, involving all phases from design to implementation.; Conda: Used as a package and environment management system to support data science workflows.; AWS: Cloud platform leveraged to support data storage, processing, and machine learning model deployment.; H2O: A machine learning platform used to build and manage predictive models within the data science team.; Scala: A programming language used for large scale data analysis alongside Python and R.; R: A programming language used for statistical computing and large scale data analysis.; SQL: Used for querying and managing data within relational databases as part of data analytics."
X6v2WbpOkslKZsjCAAAAAA==,Data Scientist,"The advanced analytics team is seeking a Data Scientist who has strong data analytics and data science background. The individual will spend time building and maintaining advanced analytical tools and leverage analytical and critical reasoning to solve complex, multidimensional problems using quantitative information and applying statistical and machine learning techniques. Develop predictive models for customer attrition and digital marketing to support retention programs, vertical segmentation and marketing strategies. Identify, collect, and explore the right data used for predictive modeling and algorithm development. Design and develop state-of-the-art data-driven analyses using statistical & advanced analytics methodologies to solve business problems.

Heartland Payment Systems is an Equal Opportunity Employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. We do not discriminate based upon race, religion, color, national origin, sex, sexual orientation, gender identity, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.",,2025-07-25,,"['The individual will spend time building and maintaining advanced analytical tools and leverage analytical and critical reasoning to solve complex, multidimensional problems using quantitative information and applying statistical and machine learning techniques', 'Develop predictive models for customer attrition and digital marketing to support retention programs, vertical segmentation and marketing strategies', 'Identify, collect, and explore the right data used for predictive modeling and algorithm development', 'Design and develop state-of-the-art data-driven analyses using statistical & advanced analytics methodologies to solve business problems']",True,[],,"['Predictive Modeling', 'Statistical and Machine Learning Techniques', 'Data Collection and Exploration', 'Advanced Analytical Tools', 'Statistical and Advanced Analytics Methodologies']","Predictive Modeling: Develop predictive models for customer attrition and digital marketing to support retention programs, vertical segmentation, and marketing strategies.; Statistical and Machine Learning Techniques: Apply statistical and machine learning techniques to solve complex, multidimensional problems using quantitative information.; Data Collection and Exploration: Identify, collect, and explore the right data used for predictive modeling and algorithm development.; Advanced Analytical Tools: Build and maintain advanced analytical tools to support data-driven analyses and problem solving.; Statistical and Advanced Analytics Methodologies: Design and develop state-of-the-art data-driven analyses using statistical and advanced analytics methodologies to solve business problems."
_QeDs0JMADGJt1J9AAAAAA==,"Senior Machine Learning Scientist, BRAID (Foundational ML)","The Position

A healthier future. It’s what drives us to innovate. To continuously advance science and ensure everyone has access to the healthcare they need today and for generations to come. Creating a world where we all have more time with the people we love. That’s what makes us Roche.

Advances in AI, data, and computational sciences are transforming drug discovery and development. Roche’s Research and Early Development organisations at Genentech (gRED) and Pharma (pRED) have demonstrated how these technologies accelerate R&D, leveraging data and novel computational models to drive impact. Seamless data sharing and access to models across gRED and pRED are essential to maximising these opportunities. The new Computational Sciences Center of Excellence (CoE) is a strategic, unified group whose goal is to harness the transformative power of data and Artificial Intelligence (AI) to assist our scientists in both pRED and gRED to deliver more innovative and transformative medicines for patients worldwide.

The Opportunity

Genentech is seeking a highly motivated Senior AI Scientist to join the Deep Learning Theory and Algorithms (DELTA) lab within the BRAID (Biology Research | AI Development) department in Genentech Research and Early Development (gRED). Our lab is dedicated to advancing AI research to support drug discovery and target discovery efforts, with a focus on large-scale foundation models in research biology. We are committed to driving innovation through cutting-edge AI methods with real-world impact in the drug discovery field. The successful candidate will contribute to a research program focused on AI foundation models, including LLMs and agents, with the ultimate aim of accelerating the drug discovery process. They will work at the intersection of AI research and engineering challenges to build the next generation of biomedical large-scale foundation models. They will contribute to developing cutting-edge AI methods, including multimodal generative modeling, large language models, and reinforcement learning techniques. Furthermore, they will contribute to system design, scaling, and optimization across the full model-development lifecycle. The successful candidate will work in an exciting and multidisciplinary environment alongside AI scientists, ML engineers, and computational biologists.

In this role, you will:
• Drive research on novel foundation models, with a specific focus on multimodal generative models, LLMs, AI Agents, and reinforcement learning.
• Lead the design and implementation of novel, cutting-edge ML methods with applications to drug discovery and target discovery.
• Work at the intersection of deep learning and engineering challenges, focusing on system design, architectural choices, and scalability, in collaboration with the MLOps team.
• Regularly publish in top-tier ML venues (e.g., NeurIPS, ICLR, ICML, AISTATS, etc.) and scientific journals, presenting results at internal and external scientific venues, conferences, and workshops.
• Collaborate closely with interdisciplinary and cross-functional teams across gRED.

Who you are
• Educational Background: Ph.D. in Computer Science, Machine Learning, Statistics, Mathematics, Physics, or a related field.
• Excellent knowledge of the theory and practice of deep learning, as demonstrated in past projects and publication record at top-tier ML venues such as NeurIPS, ICML, ICLR, AISTATS, ACL, EMNLP, etc.
• Proven experience in developing and delivering innovative ML solutions, in particular in the following areas: large-scale representation learning, multi-modal generative modeling, reinforcement learning, large language modeling, AI agents.
• Excellent Python and PyTorch programming skills, with extensive knowledge of the best practices of software engineering, data engineering, and MLOps (e.g., familiar with code version control, high-performance compute infrastructures, and machine learning experiment monitoring workflows).
• Passionate about writing excellent software, system design, scaling, and optimization across the full model-development lifecycle.
• Excellent communication, collaboration, and problem-solving skills.

Relocation benefits are available for this job posting

The expected salary range for this position, based on the primary location of California, is $167,400 - 310,800. Actual pay will be determined based on experience, qualifications, geographic location, and other job-related factors permitted by law. A discretionary annual bonus may be available based on individual and Company performance. This position also qualifies for the benefits detailed at the link provided below.

Benefits

#ComputationCoE

#tech4lifeComputationalScience

#tech4lifeAI

Genentech is an equal opportunity employer. It is our policy and practice to employ, promote, and otherwise treat any and all employees and applicants on the basis of merit, qualifications, and competence. The company's policy prohibits unlawful discrimination, including but not limited to, discrimination on the basis of Protected Veteran status, individuals with disabilities status, and consistent with all federal, state, or local laws.

If you have a disability and need an accommodation in relation to the online application process, please contact us by completing this form Accommodations for Applicants.",2025-07-15T00:00:00.000Z,2025-07-25,"['Educational Background: Ph.D. in Computer Science, Machine Learning, Statistics, Mathematics, Physics, or a related field', 'Excellent knowledge of the theory and practice of deep learning, as demonstrated in past projects and publication record at top-tier ML venues such as NeurIPS, ICML, ICLR, AISTATS, ACL, EMNLP, etc', 'Proven experience in developing and delivering innovative ML solutions, in particular in the following areas: large-scale representation learning, multi-modal generative modeling, reinforcement learning, large language modeling, AI agents', 'Excellent Python and PyTorch programming skills, with extensive knowledge of the best practices of software engineering, data engineering, and MLOps (e.g., familiar with code version control, high-performance compute infrastructures, and machine learning experiment monitoring workflows)', 'Passionate about writing excellent software, system design, scaling, and optimization across the full model-development lifecycle', 'Excellent communication, collaboration, and problem-solving skills']","['The successful candidate will contribute to a research program focused on AI foundation models, including LLMs and agents, with the ultimate aim of accelerating the drug discovery process', 'They will work at the intersection of AI research and engineering challenges to build the next generation of biomedical large-scale foundation models', 'They will contribute to developing cutting-edge AI methods, including multimodal generative modeling, large language models, and reinforcement learning techniques', 'Furthermore, they will contribute to system design, scaling, and optimization across the full model-development lifecycle', 'The successful candidate will work in an exciting and multidisciplinary environment alongside AI scientists, ML engineers, and computational biologists', 'Drive research on novel foundation models, with a specific focus on multimodal generative models, LLMs, AI Agents, and reinforcement learning', 'Lead the design and implementation of novel, cutting-edge ML methods with applications to drug discovery and target discovery', 'Work at the intersection of deep learning and engineering challenges, focusing on system design, architectural choices, and scalability, in collaboration with the MLOps team', 'Regularly publish in top-tier ML venues (e.g., NeurIPS, ICLR, ICML, AISTATS, etc.) and scientific journals, presenting results at internal and external scientific venues, conferences, and workshops', 'Collaborate closely with interdisciplinary and cross-functional teams across gRED']",True,"['Large Language Models', 'Multimodal Generative Modeling', 'AI Agents', 'Reinforcement Learning', 'Deep Learning', 'PyTorch']","Large Language Models: The position focuses on research and development of large language models (LLMs) as foundational AI models to accelerate drug discovery processes.; Multimodal Generative Modeling: The candidate will drive research on novel foundation models with a specific focus on multimodal generative models, contributing to cutting-edge AI methods in drug discovery.; AI Agents: The role includes working on AI agents as part of foundation models, aiming to advance AI research and engineering challenges in biomedical applications.; Reinforcement Learning: The job requires expertise in reinforcement learning techniques applied to the development of novel AI methods for drug and target discovery.; Deep Learning: The candidate must have excellent knowledge of deep learning theory and practice, demonstrated through past projects and publications, and apply deep learning methods in building biomedical foundation models.; PyTorch: Proficiency in PyTorch programming is required for implementing deep learning models and system design within the full model-development lifecycle.","['Machine Learning', 'MLOps']","Machine Learning: The role involves developing and delivering innovative machine learning solutions applied to drug discovery and target discovery, including large-scale representation learning and reinforcement learning techniques.; MLOps: The candidate is expected to have extensive knowledge of MLOps best practices, including code version control, high-performance compute infrastructures, and machine learning experiment monitoring workflows, collaborating with the MLOps team on system design and scalability."
v3gSeLJdguHyvKpoAAAAAA==,Data Scientist IV,"Job Title: Senior Data Scientist – Advertising & Insights

Location: Remote (PST preferred; must have overlap with Eastern and Pacific Time Zones)

Employment Type: W2 Contract Only

Pay Rate: $61/hour

Duration: 5 Months (Strong likelihood of extension)

Work Hours: 40 hours/week

Introduction

TPG is hiring a Senior Data Scientist to join a high-impact Ads Data Science team within a fast-scaling digital media and advertising technology environment. This team is focused on optimizing the ad experience and maximizing platform performance through robust data infrastructure, experimentation, and machine learning innovation.

This role is ideal for a data scientist with a passion for solving complex ad tech challenges—ranging from auction optimization and targeting to performance measurement and anomaly detection. You’ll work with product, engineering, and business stakeholders to drive strategic improvements in ad delivery and advertiser experience.

Key Responsibilities
• Design and apply data science solutions to improve ad platform performance and advertiser outcomes
• Analyze large-scale datasets to uncover insights, trends, and strategic opportunities
• Build self-service data assets and dashboards for product and engineering teams
• Lead deep dives into topline metrics to support decision-making and guide product roadmaps
• Collaborate across functions to define product requirements and translate them into DS models
• Develop ML-based systems for anomaly detection, forecasting, and pattern recognition
• Drive continuous improvement through causal inference, A/B testing, and experimentation
• Communicate data insights and model recommendations to technical and non-technical stakeholders

Required Qualifications
• MS or PhD in Computer Science, Statistics, Mathematics, or related quantitative field
• 5+ years of experience in data science, ML, or applied analytics roles
• Strong understanding of statistical modeling, causal inference, and experimental design
• Proficiency in Python or R, with experience using libraries like scikit-learn, TensorFlow, or PyTorch
• Deep knowledge of SQL and working with relational databases

Preferred Skills
• Experience with large-scale data processing (e.g., Spark, Hadoop, Hive); BigQuery experience is a plus
• Background in digital advertising, ad tech, or real-time bidding environments
• Experience designing and analyzing online experiments (A/B testing)
• Ability to build and deploy production-level ML models

Why You’ll Want This Role
• Join a cutting-edge team focused on transforming digital ad performance with data
• Collaborate cross-functionally in a fast-paced, mission-driven environment
• Opportunity to make a tangible impact on ad strategy and product development
• Fully remote with flexible scheduling aligned to core U.S. time zones

Are you ready to drive innovation through data and help scale next-generation ad solutions?

Apply now and bring your data science expertise to a team transforming digital advertising performance.

#LI-CW1 #TECH #Remote",2025-07-17T00:00:00.000Z,2025-07-25,"['MS or PhD in Computer Science, Statistics, Mathematics, or related quantitative field', '5+ years of experience in data science, ML, or applied analytics roles', 'Strong understanding of statistical modeling, causal inference, and experimental design', 'Proficiency in Python or R, with experience using libraries like scikit-learn, TensorFlow, or PyTorch', 'Deep knowledge of SQL and working with relational databases', 'Join a cutting-edge team focused on transforming digital ad performance with data', 'Collaborate cross-functionally in a fast-paced, mission-driven environment', 'Opportunity to make a tangible impact on ad strategy and product development', 'Fully remote with flexible scheduling aligned to core U.S. time zones']","['Location: Remote (PST preferred; must have overlap with Eastern and Pacific Time Zones)', 'Work Hours: 40 hours/week', 'This role is ideal for a data scientist with a passion for solving complex ad tech challenges—ranging from auction optimization and targeting to performance measurement and anomaly detection', 'You’ll work with product, engineering, and business stakeholders to drive strategic improvements in ad delivery and advertiser experience', 'Design and apply data science solutions to improve ad platform performance and advertiser outcomes', 'Analyze large-scale datasets to uncover insights, trends, and strategic opportunities', 'Build self-service data assets and dashboards for product and engineering teams', 'Lead deep dives into topline metrics to support decision-making and guide product roadmaps', 'Collaborate across functions to define product requirements and translate them into DS models', 'Develop ML-based systems for anomaly detection, forecasting, and pattern recognition', 'Drive continuous improvement through causal inference, A/B testing, and experimentation', 'Communicate data insights and model recommendations to technical and non-technical stakeholders']",True,[],,"['Statistical Modeling', 'Causal Inference', 'A/B Testing', 'Machine Learning', 'Python', 'R', 'scikit-learn', 'TensorFlow', 'PyTorch', 'SQL', 'Relational Databases', 'Large-Scale Data Processing', 'BigQuery', 'Data Dashboards', 'Data Analysis']","Statistical Modeling: Used to design and apply data science solutions for improving ad platform performance and advertiser outcomes, including causal inference and experimental design.; Causal Inference: Applied to drive continuous improvement through understanding cause-effect relationships in ad performance and experimentation.; A/B Testing: Used for experimentation and online experiment design to measure and optimize ad delivery and advertiser experience.; Machine Learning: Develop ML-based systems for anomaly detection, forecasting, and pattern recognition to enhance ad tech solutions.; Python: Programming language used for data science tasks, including building ML models and data analysis.; R: Programming language used for statistical analysis and data science modeling.; scikit-learn: Python library utilized for building machine learning models relevant to ad tech challenges.; TensorFlow: Used as a machine learning framework to develop models for anomaly detection, forecasting, and pattern recognition.; PyTorch: Employed as a deep learning framework for building ML models in the ad tech environment.; SQL: Used for querying and managing relational databases to analyze large-scale datasets and support data infrastructure.; Relational Databases: Data storage systems accessed via SQL to handle large-scale data for analysis and model development.; Large-Scale Data Processing: Experience with tools like Spark, Hadoop, and Hive to process and analyze big data relevant to digital advertising.; BigQuery: Cloud-based data warehouse used for large-scale data analysis in ad tech environments.; Data Dashboards: Built self-service dashboards to provide product and engineering teams with insights and support decision-making.; Data Analysis: Analyzing large-scale datasets to uncover insights, trends, and strategic opportunities in digital advertising."
xFjqQDYVd1oYxSEjAAAAAA==,Data Scientist,"Tombras, a 400+ person, full-service, national advertising agency with a digital mindset, is seeking a Data Scientist.

Where you'll be working: Knoxville or Atlanta. Relocation assistance may be provided.

The analytics practice at Tombras delivers on the agency's promise of data + creativity for business results. This role will be foundational to our advanced analytics team, which will partner with our analytics, media, and data-ops teams to realize the vision of offering best in class marketing science for our clients. You'll build proprietary tooling, work on brands with household recognition, and grow the team as the agency scales.

What you will be doing:
• Lead client engagements for advanced analytics including Media Mix Modeling, Message Mix Modeling, Multi-Touch Attribution, Forecasting, and support testing, experimentation, and optimization. Your remit will be end-to-end, from selling in new work thru delivery of the results.
• Develop the framework and approach for marketing science and develop bespoke offerings.
• Employ best in class tooling to develop proprietary Martech in partnership with the Technology and Media practices.
• Identify new and innovative data sets that can be used to improve existing modeling work, or deliver net new models.
• Clearly articulate statistical results to clients, ultimately leading to continued client engagement and implementation.

What you bring:
• M.S. or Ph.D. degree in a relevant field such as Data Science, Statistics, Mathematics, Computer Science, Business Analytics, or Operations Research
• (Optional) Experience in marketing science or advertising analytics
• Mastery of advanced analytical techniques including but not limited to Multivariate/Bayesian Regression, Randomized Control Trials, Media Mix/Multi-Touch Attribution, Time-Series, Forecasting, Predictive Modeling, Discrete Choice Models
• Strong competency with python, R, SQL, and other commonly used statistical tools
• Client services mindset
• Ability to influence clients and partner agencies to act on insights
• Ability to distill complicated information into succinct graphical presentations for senior stakeholders.

Why Join Tombras Analytics?

Tombras Analytics sits at the cornerstone of Connecting Data + Creativity for Business Results and delivers Diagnostic, Descriptive, Predictive and Prescriptive Analytics across both internal teams and a diverse global, national and regional client base. We are a passionate team of 20+ professionals dedicated to pushing the boundaries of analytics to help our clients discover opportunities, capitalize on trends, create efficiencies and improve marketing and business results for maximum growth.

Why you'll want to work at Tombras:

You'll be joining one of the top independent agencies in North America. Connecting Data & Creativity for Business Results® is working for our clients and creating a flywheel affect fueling both client and agency growth. You'll be a part of a highly creative agency that has been recognized by AdAge, Adweek, Communication Arts, Fast Company, Forbes and Fortune. Tombras was recently named 2025 AdAge Agency of the year and 2024 AdAge Independent Agency of the Year.

Tombras Benefits:

Family - It comes first, on every list. Tombras has been family-run since day 1, we strive to facilitate a family-oriented environment rooted in supporting one another.

Dog-friendly offices

Unlimited PTO

Generous parental leave for primary and non-primary caregivers.

Medical (PPO or High Deductible option) for employee + dependents

401(k) Participation

Employer-paid Dental & Vision

A company culture of promotions from within and an atmosphere allowing for varied and rapid career development.

New, Modern building in Downtown Knoxville

Want more reasons to work at Tombras? Check out the latest Tombras News and Our Values.

Tombras is proud to be an equal opportunity employer dedicated to pursuing and hiring a diverse workforce.

Tombras is an E-Verify employer and participates in the E-Verify program.

This job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee. Duties, responsibilities and activities may change or new ones may be assigned at any time with or without notice. Job may require traveling overnight, driving long distances as required and sitting for extended periods of time with occasional walking and standing and occasionally lifting or carrying articles weighing less than 10 pounds.",,2025-07-25,"['M.S. or Ph.D. degree in a relevant field such as Data Science, Statistics, Mathematics, Computer Science, Business Analytics, or Operations Research', '(Optional) Experience in marketing science or advertising analytics', 'Mastery of advanced analytical techniques including but not limited to Multivariate/Bayesian Regression, Randomized Control Trials, Media Mix/Multi-Touch Attribution, Time-Series, Forecasting, Predictive Modeling, Discrete Choice Models', 'Strong competency with python, R, SQL, and other commonly used statistical tools', 'Client services mindset', 'Ability to influence clients and partner agencies to act on insights', 'Ability to distill complicated information into succinct graphical presentations for senior stakeholders', 'Job may require traveling overnight, driving long distances as required and sitting for extended periods of time with occasional walking and standing and occasionally lifting or carrying articles weighing less than 10 pounds']","[""The analytics practice at Tombras delivers on the agency's promise of data + creativity for business results"", 'This role will be foundational to our advanced analytics team, which will partner with our analytics, media, and data-ops teams to realize the vision of offering best in class marketing science for our clients', ""You'll build proprietary tooling, work on brands with household recognition, and grow the team as the agency scales"", 'Lead client engagements for advanced analytics including Media Mix Modeling, Message Mix Modeling, Multi-Touch Attribution, Forecasting, and support testing, experimentation, and optimization', 'Your remit will be end-to-end, from selling in new work thru delivery of the results', 'Develop the framework and approach for marketing science and develop bespoke offerings', 'Employ best in class tooling to develop proprietary Martech in partnership with the Technology and Media practices', 'Identify new and innovative data sets that can be used to improve existing modeling work, or deliver net new models', 'Clearly articulate statistical results to clients, ultimately leading to continued client engagement and implementation']",True,[],,"['Media Mix Modeling', 'Message Mix Modeling', 'Multi-Touch Attribution', 'Forecasting', 'Testing and Experimentation', 'Multivariate Regression', 'Bayesian Regression', 'Randomized Control Trials', 'Predictive Modeling', 'Discrete Choice Models', 'Time-Series Analysis', 'Python', 'R', 'SQL', 'Statistical Tools', 'Marketing Science', 'Proprietary Tooling Development', 'Data Set Innovation', 'Client Communication and Visualization']","Media Mix Modeling: Used to lead client engagements involving advanced analytics to understand the impact of various media channels on marketing outcomes.; Message Mix Modeling: Applied in client projects to analyze the effectiveness of different messaging strategies within marketing campaigns.; Multi-Touch Attribution: Employed to attribute credit to multiple marketing touchpoints in the customer journey for better campaign optimization.; Forecasting: Used to predict future marketing and business outcomes as part of advanced analytics deliverables.; Testing and Experimentation: Supported testing and experimentation efforts to optimize marketing strategies and validate model results.; Multivariate Regression: Mastered as an advanced analytical technique for modeling relationships between multiple variables in marketing science.; Bayesian Regression: Utilized as a statistical method to incorporate prior knowledge and uncertainty in regression modeling for marketing analytics.; Randomized Control Trials: Applied to design and analyze experiments for causal inference in marketing effectiveness studies.; Predictive Modeling: Developed predictive models to forecast marketing outcomes and support client decision-making.; Discrete Choice Models: Used to model consumer choice behavior as part of marketing science analytics.; Time-Series Analysis: Employed to analyze temporal data patterns for forecasting and understanding marketing trends.; Python: Used as a primary programming language for data analysis, statistical modeling, and building proprietary tooling.; R: Utilized for statistical computing and advanced analytics in marketing science projects.; SQL: Applied to query and manage data from databases to support analytics and modeling efforts.; Statistical Tools: Used various commonly employed statistical software and tools to perform data analysis and modeling.; Marketing Science: Developed frameworks and bespoke offerings to apply advanced analytics techniques to marketing challenges.; Proprietary Tooling Development: Built custom tools in partnership with technology and media teams to support marketing analytics and Martech solutions.; Data Set Innovation: Identified and incorporated new and innovative data sets to improve existing models or create new ones.; Client Communication and Visualization: Distilled complex statistical results into clear graphical presentations to influence clients and stakeholders."
uXHo1IJOM4IwE46KAAAAAA==,Data Scientist - SME - Clearance Required - Remote Work,"Description:
• ICF seeks an experienced Data Scientist with Subject Matter Expert (SME) - Level experience
• Lead and support the research and development of new cyber analytic capabilities
• Help the US protect and defend its networks and critical information systems
• Act as a Data Scientist SME to support a large federal cyber security analytic program
• Utilize skills to help experiment and prototype future cyber capabilities for large-scale implementation
• Create useful and actionable insight for the customer through the development of machine learning, deep learning models, and related algorithms
• Strong mathematically; can automate scoring using machine learning techniques, build recommendation systems, and select the correct data points for analysis from large data sets
• Contribute to an important project from its beginning, work with the latest and emerging technologies
• Primarily telework-based with occasional meetings at client locations or ICF facilities within the National Capital Region

Requirements:
• Active US government issued security clearance required
• US Citizenship required as part of client contract requirements
• Bachelor’s degree with 12+ year of experience or Master’s degree with 10+ years of experience in Computer Science, Statistics, Applied Mathematics, Computational Linguistics, Artificial Intelligence or related field
• 15 or more years of practical working experience in one or more of the following areas: Natural Language Processing, Machine Learning Models, Question Answering, Text Mining, Information Retrieval, Distributional Semantics, Data Science, Knowledge Engineering
• Demonstrated, advanced level experience using a variety of mathematical, statistical, data mining, and data analysis methods/tools
• 15+ years' experience in Cyber Threats, Computer Science, Statistics, Applied Mathematics, Computational Linguistics, Artificial Intelligence or related field
• Interpersonal skills and the ability to communicate effectively with various clients in order to explain and elaborate on technical details
• Experience in productization of machine learning algorithms and the ability to deliver data science components that are part of successful deliverables
• Working knowledge of general machine learning algorithms and NLP, Graph Theory, and Network Analysis
• Fluency in one or more programming languages (e.g., Python, JavaScript, R, etc.)
• Experience with statistical data analysis, experimental design, and hypotheses validation
• Experience with database querying like SQL
• Readiness to collaborate with engineering teams, product teams, and customers to develop prototypes and software products
• Practical experience with the Databricks Intelligence Platform
• CompTIA Security+ or higher certification level preferred

Benefits:
• Reasonable Accommodations are available
• We are an equal opportunity employer
• Our employees are empowered to share their expertise and collaborate with others",2025-07-16T00:00:00.000Z,2025-07-25,"['ICF seeks an experienced Data Scientist with Subject Matter Expert (SME) - Level experience', 'Active US government issued security clearance required', 'US Citizenship required as part of client contract requirements', 'Bachelor’s degree with 12+ year of experience or Master’s degree with 10+ years of experience in Computer Science, Statistics, Applied Mathematics, Computational Linguistics, Artificial Intelligence or related field', '15 or more years of practical working experience in one or more of the following areas: Natural Language Processing, Machine Learning Models, Question Answering, Text Mining, Information Retrieval, Distributional Semantics, Data Science, Knowledge Engineering', 'Demonstrated, advanced level experience using a variety of mathematical, statistical, data mining, and data analysis methods/tools', ""15+ years' experience in Cyber Threats, Computer Science, Statistics, Applied Mathematics, Computational Linguistics, Artificial Intelligence or related field"", 'Interpersonal skills and the ability to communicate effectively with various clients in order to explain and elaborate on technical details', 'Experience in productization of machine learning algorithms and the ability to deliver data science components that are part of successful deliverables', 'Working knowledge of general machine learning algorithms and NLP, Graph Theory, and Network Analysis', 'Fluency in one or more programming languages (e.g., Python, JavaScript, R, etc.)', 'Experience with statistical data analysis, experimental design, and hypotheses validation', 'Experience with database querying like SQL', 'Readiness to collaborate with engineering teams, product teams, and customers to develop prototypes and software products', 'Practical experience with the Databricks Intelligence Platform']","['Lead and support the research and development of new cyber analytic capabilities', 'Help the US protect and defend its networks and critical information systems', 'Act as a Data Scientist SME to support a large federal cyber security analytic program', 'Utilize skills to help experiment and prototype future cyber capabilities for large-scale implementation', 'Create useful and actionable insight for the customer through the development of machine learning, deep learning models, and related algorithms', 'Strong mathematically; can automate scoring using machine learning techniques, build recommendation systems, and select the correct data points for analysis from large data sets', 'Contribute to an important project from its beginning, work with the latest and emerging technologies', 'Primarily telework-based with occasional meetings at client locations or ICF facilities within the National Capital Region']",True,['Deep Learning'],Deep Learning: Develop deep learning models and related algorithms specifically to support cyber analytic capabilities and prototype future cyber capabilities for large-scale implementation.,"['Machine Learning', 'Deep Learning', 'Natural Language Processing', 'Statistical Data Analysis', 'Graph Theory and Network Analysis', 'Programming Languages', 'SQL', 'Databricks Intelligence Platform']","Machine Learning: Develop machine learning models and algorithms to create actionable insights and automate scoring for cyber analytic capabilities; includes productization and delivery of machine learning components as part of successful project deliverables.; Deep Learning: Develop deep learning models and related algorithms to support cyber analytic capabilities and prototype future cyber capabilities for large-scale implementation.; Natural Language Processing: Apply NLP techniques such as question answering, text mining, information retrieval, and distributional semantics to support cyber security analytic programs and knowledge engineering.; Statistical Data Analysis: Use statistical data analysis, experimental design, and hypothesis validation methods to analyze data and support cyber analytic research and development.; Graph Theory and Network Analysis: Utilize graph theory and network analysis methods to analyze cyber threats and support cyber security analytic programs.; Programming Languages: Use programming languages such as Python, JavaScript, and R to develop machine learning and data science solutions for cyber analytic capabilities.; SQL: Perform database querying using SQL to extract and manipulate data for analysis and model development.; Databricks Intelligence Platform: Leverage the Databricks Intelligence Platform to support data science workflows and cyber analytic capabilities development."
PB6jkB5FPMUGC660AAAAAA==,Data Scientist – Cybersecurity (BHJOB22048_730) Job at ITmPowered in Denver,"Data Scientist (AI/ML) – Medical Device Cybersecurity – ITmPowered ConsultingThe Sr. Data Scientist will apply Data Science to enterprise Medical Device Cybersecurity, Network security, Attacks & Events. Leverage big data in support of an enterprise scale Medical Device Cybersecurity program spanning Risk Management, Cyber Digital Transformation, Threat Management, Network Security, End Point Security, IT Controls, Security Operations and Identity and Data Management. Will have direct impact providing strategic insight into Medical Device cybersecurity protection and improving networking security.How you’ll make an impact:Analyze large amounts of data and develop statistical models to find patterns and solve problems that will help drive strategic business decisions.Analyze data from numerous sources (Splunk, Qualis, CMDB/Asset Inventory, CyberArk, Armis, ForeScout, Automated Patch Management systems, Threat and Vulnerability, Network Traffic, Governance and Standards data, Risk Assessment data, Security baselines, etc.)Look at cybersecurity and machine learning opportunities identifying opportunities and goals (detect threats, predict attacks, prediction, prevention, detection, response, monitoring)Design and implementation of machine learning solutions using regression, model, clustering (KNN, K-means, Bayesian, Mean-shift), statistical profiling, inference, classification, and predictive analysis.Leverage AI and Machine Learning in both supervised (classification, regression) and unsupervised scenarios (clustering, association, dimension reduction).Looking at data across Network Security, network traffic analysis, Network security scanning (Wired, Wireless, cloud), Endpoint (anti-malware), Application Security (micro firewalls, WAF, Data firewalls), User Behavior Analytics, Device behavior analytics, access management. Security of data in transit, at rest, historically.Network Protection, Network Traffic Analytics, IP Traffic, Ports, intrusion detection. Identify different classes of network attacks – scanning and spoofing. Network anomaly detection, Encrypted traffic classification, Clustering for forensic analysis. Medical Device endpoint protection.Qualifications for success:Bachelor’s Degree in Data Science, Computer Science, Information Systems, Mathematics, Statistics, Engineering or similar (Masters Preferred)Experience with a range of machine learning techniques: linear regression, classifications, random forest, clustering, supervised and unsupervised learning, graph algorithms, etc.Experience in Machine, and Deep Learning frameworks, model validation and deployment tools, data pipeline technologies, and visualization and data storytelling tools (R, Tableau, Jupyter, etc.).Advanced knowledge of statistical concepts such as regressions, time series, mixed model, Bayesian methods, clustering, classification, and graph models to analyze data and provide insights.Expertise in common data science toolkits and programming languages, including R, Python (including SciPy, NumPy, and/or PySpark) and/or Scala, Java, SQL, and shell scripting.Hands-on experience with Spark and Hadoop.Experience working with high volume data lakes, and large databases.Demonstrated experience applying data science methods to real-world data problems.Preferred Expertise:Understanding of cyber security, computer network security, security protocols, encryption, security scanning, threat and vulnerability management, Technology Risk Assessment, cybersecurity assessment, IT Controls.Logistics:Local Denver resources only. No relocation provided.Will be remote primarily but must be able to come into DTC office periodically after COVID Abates.COVID-19 – Must be fully vaccinated OR provide medical or religious exemption.W2 only – No sub vendors. Sponsorship NOT available. Must have direct contact information on resume to apply.You will need to be a US Citizen, and with the ability to obtain US Government TOP SECRET clearance, as well as successfully pass a 12 panel drug screen and 10 year background check, in order to meet eligibility requirements for access to classified information.
#J-18808-Ljbffr",2025-07-20T00:00:00.000Z,2025-07-25,"['Security of data in transit, at rest, historically', 'Experience in Machine, and Deep Learning frameworks, model validation and deployment tools, data pipeline technologies, and visualization and data storytelling tools (R, Tableau, Jupyter, etc.).Advanced knowledge of statistical concepts such as regressions, time series, mixed model, Bayesian methods, clustering, classification, and graph models to analyze data and provide insights', 'Expertise in common data science toolkits and programming languages, including R, Python (including SciPy, NumPy, and/or PySpark) and/or Scala, Java, SQL, and shell scripting.Hands-on experience with Spark and Hadoop', 'Experience working with high volume data lakes, and large databases', 'Demonstrated experience applying data science methods to real-world data problems', 'You will need to be a US Citizen, and with the ability to obtain US Government TOP SECRET clearance, as well as successfully pass a 12 panel drug screen and 10 year background check, in order to meet eligibility requirements for access to classified information']","['Leverage big data in support of an enterprise scale Medical Device Cybersecurity program spanning Risk Management, Cyber Digital Transformation, Threat Management, Network Security, End Point Security, IT Controls, Security Operations and Identity and Data Management', 'Will have direct impact providing strategic insight into Medical Device cybersecurity protection and improving networking security', 'How you’ll make an impact:Analyze large amounts of data and develop statistical models to find patterns and solve problems that will help drive strategic business decisions', 'Analyze data from numerous sources (Splunk, Qualis, CMDB/Asset Inventory, CyberArk, Armis, ForeScout, Automated Patch Management systems, Threat and Vulnerability, Network Traffic, Governance and Standards data, Risk Assessment data, Security baselines, etc.)Look at cybersecurity and machine learning opportunities identifying opportunities and goals (detect threats, predict attacks, prediction, prevention, detection, response, monitoring)Design and implementation of machine learning solutions using regression, model, clustering (KNN, K-means, Bayesian, Mean-shift), statistical profiling, inference, classification, and predictive analysis', 'Leverage AI and Machine Learning in both supervised (classification, regression) and unsupervised scenarios (clustering, association, dimension reduction)', 'Looking at data across Network Security, network traffic analysis, Network security scanning (Wired, Wireless, cloud), Endpoint (anti-malware), Application Security (micro firewalls, WAF, Data firewalls), User Behavior Analytics, Device behavior analytics, access management', 'Network Protection, Network Traffic Analytics, IP Traffic, Ports, intrusion detection', 'Identify different classes of network attacks – scanning and spoofing', 'Network anomaly detection, Encrypted traffic classification, Clustering for forensic analysis', 'Medical Device endpoint protection']",True,[],,"['Regression Models', 'Classification', 'Clustering', 'Statistical Profiling', 'Inference', 'Predictive Analysis', 'Supervised Learning', 'Unsupervised Learning', 'Feature Engineering', 'Data Pipelines', 'SQL', 'Python', 'R', 'Tableau', 'Jupyter', 'Spark', 'Hadoop', 'Bayesian Methods', 'Time Series Models', 'Graph Models', 'Random Forest', 'Machine Learning', 'Deep Learning Frameworks', 'Data Visualization', 'Data Storytelling', 'Shell Scripting']","Regression Models: Used to develop statistical models analyzing large amounts of data to find patterns and solve problems for strategic business decisions in cybersecurity.; Classification: Applied in supervised machine learning scenarios to detect threats, predict attacks, and support prevention, detection, and response in cybersecurity data.; Clustering: Used in unsupervised learning scenarios including KNN, K-means, Bayesian, and Mean-shift clustering for forensic analysis, network anomaly detection, and encrypted traffic classification.; Statistical Profiling: Implemented to analyze cybersecurity data for inference and predictive analysis to identify patterns and threats.; Inference: Used alongside statistical profiling and classification to derive insights from cybersecurity data for threat detection and prediction.; Predictive Analysis: Employed to forecast cybersecurity threats and attacks by analyzing data from multiple sources and applying machine learning models.; Supervised Learning: Leveraged for classification and regression tasks to detect and predict cybersecurity threats and attacks.; Unsupervised Learning: Used for clustering, association, and dimension reduction to analyze network traffic and detect anomalies in cybersecurity data.; Feature Engineering: Implied in the design and implementation of machine learning solutions analyzing diverse cybersecurity data sources to improve model performance.; Data Pipelines: Utilized to process and manage large volumes of cybersecurity data from various sources such as Splunk, Qualis, and network traffic systems.; SQL: Used for querying and managing large databases and data lakes containing cybersecurity and network data.; Python: Applied with libraries such as SciPy, NumPy, and PySpark for data analysis, machine learning model development, and handling big data in cybersecurity contexts.; R: Used for statistical analysis, visualization, and data storytelling in cybersecurity data science tasks.; Tableau: Employed as a visualization and data storytelling tool to communicate cybersecurity insights and model results.; Jupyter: Used as an interactive environment for developing, validating, and deploying machine learning models and data analysis workflows.; Spark: Hands-on experience with Spark is used to process and analyze high volume cybersecurity data efficiently.; Hadoop: Used to manage and analyze large-scale data lakes and big data relevant to cybersecurity analytics.; Bayesian Methods: Applied as part of advanced statistical concepts for clustering, classification, and graph models to analyze cybersecurity data.; Time Series Models: Used to analyze temporal cybersecurity data for threat detection and prediction over time.; Graph Models: Utilized to analyze relationships and patterns in cybersecurity data, such as network traffic and threat connections.; Random Forest: Used as a machine learning technique for classification and regression tasks in cybersecurity threat detection.; Machine Learning: Applied broadly to develop models for detecting, predicting, and preventing cybersecurity threats using various supervised and unsupervised techniques.; Deep Learning Frameworks: Experience with deep learning frameworks is used for model validation and deployment in cybersecurity machine learning solutions.; Data Visualization: Used to create visual representations of cybersecurity data and model outputs to support decision-making and communication.; Data Storytelling: Employed to effectively communicate insights derived from cybersecurity data analysis and machine learning models.; Shell Scripting: Used to automate data processing and management tasks within cybersecurity data pipelines."
EtmlA8aarewd1UubAAAAAA==,"Senior Data Scientist – Data and Machine Learning, WWPS ProServe","Senior Data Scientist - Data and Machine Learning, WWPS ProServe Job ID: 2953184 | Amazon Web Services, Inc. Are you excited to help the US Intelligence Community design, build, and implement AI algorithms, including advanced Generative AI solutions, to augment decision making while meeting the highest standards for reliability, transparency, and scalability? The Amazon Web Services (AWS) US Federal Professional Services team works directly with US Intelligence Community agencies and other public sector entities to achieve their mission goals through the adoption of Machine Learning (ML) and Generative AI methods. We build models for text, image, video, audio, and multi-modal use cases, leveraging both traditional ML approaches and state-of-the-art generative models including Large Language Models (LLMs), text-to-image generation, and other advanced AI capabilities to fit the mission. At AWS, we're hiring experienced data scientists with a background in both traditional and generative AI who can help our customers understand the opportunities their data presents, and build solutions that earn the customer trust needed for deployment to production systems. In this role, you will work closely with customers to deeply understand their data challenges and requirements, and design tailored solutions that best fit their use cases. You should have broad experience building models using all kinds of data sources, and building data-intensive applications at scale. You should possess excellent business acumen and communication skills to collaborate effectively with stakeholders, develop key business questions, and translate requirements into actionable solutions. You will provide guidance and support to other engineers, sharing industry best practices and driving innovation in the field of data science and AI. This position requires that the candidate selected must currently possess and maintain an active TS/SCI Security Clearance with Polygraph. The position further requires the candidate to opt into a commensurate clearance for each government agency for which they perform AWS work. Key job responsibilities As a Data Scientist, you will: Collaborate with AI/ML scientists and architects to research, design, develop, and evaluate AI algorithms to address real-world challenges. Interact with customers directly to understand the business problem, help and aid them in implementation of AI solutions, deliver briefing and deep dive sessions to customers and guide customer on adoption patterns and paths to production. Create and deliver best practice recommendations, tutorials, blog posts, sample code, and presentations adapted to technical, business, and executive stakeholders. Provide customer and market feedback to Product and Engineering teams to help define product direction. This position may require up to 25% local travel. BASIC QUALIFICATIONS Bachelor's degree in Computer Science, Engineering, related field, or equivalent experience. 5+ years of experience building models for business applications. Experience with algorithms, data structures, parsing, numerical optimization, data mining, parallel and distributed computing, high-performance computing, neural deep learning methods and/or machine learning. Experience using Python and hands-on experience building models with deep learning frameworks (i.e. Tensorflow, Keras, PyTorch, MXNet). Current, active US Government Security Clearance of TS/SCI with Polygraph. PREFERRED QUALIFICATIONS Masters or PhD Degree in computer science, engineering, mathematics, operations research, or in a highly quantitative field. Practical experience in solving complex problems in an applied environment. Hands-on experience building models with deep learning frameworks like PyTorch, Tensorflow, or JAX. Experience building applications leveraging GenAI. Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit this link for more information. Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $143,300/year in our lowest geographic market up to $247,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit this link . Posted: April 1, 2025 (Updated 14 days ago) Share this job Important FAQs for current Government employees Before proceeding, please review the following FAQs here . #J-18808-Ljbffr",2025-07-16T00:00:00.000Z,2025-07-25,"['You should have broad experience building models using all kinds of data sources, and building data-intensive applications at scale', 'You should possess excellent business acumen and communication skills to collaborate effectively with stakeholders, develop key business questions, and translate requirements into actionable solutions', 'This position requires that the candidate selected must currently possess and maintain an active TS/SCI Security Clearance with Polygraph', ""BASIC QUALIFICATIONS Bachelor's degree in Computer Science, Engineering, related field, or equivalent experience"", '5+ years of experience building models for business applications', 'Experience with algorithms, data structures, parsing, numerical optimization, data mining, parallel and distributed computing, high-performance computing, neural deep learning methods and/or machine learning', 'Experience using Python and hands-on experience building models with deep learning frameworks (i.e', 'Tensorflow, Keras, PyTorch, MXNet)', 'Current, active US Government Security Clearance of TS/SCI with Polygraph', 'Practical experience in solving complex problems in an applied environment', 'Hands-on experience building models with deep learning frameworks like PyTorch, Tensorflow, or JAX', 'Experience building applications leveraging GenAI']","['In this role, you will work closely with customers to deeply understand their data challenges and requirements, and design tailored solutions that best fit their use cases', 'You will provide guidance and support to other engineers, sharing industry best practices and driving innovation in the field of data science and AI', 'Key job responsibilities As a Data Scientist, you will: Collaborate with AI/ML scientists and architects to research, design, develop, and evaluate AI algorithms to address real-world challenges', 'Interact with customers directly to understand the business problem, help and aid them in implementation of AI solutions, deliver briefing and deep dive sessions to customers and guide customer on adoption patterns and paths to production', 'Create and deliver best practice recommendations, tutorials, blog posts, sample code, and presentations adapted to technical, business, and executive stakeholders', 'Provide customer and market feedback to Product and Engineering teams to help define product direction', 'This position may require up to 25% local travel']",True,"['Generative AI', 'Large Language Models', 'Deep Learning Frameworks for Neural Networks']","Generative AI: The role involves designing, building, and implementing advanced generative AI solutions, including text-to-image generation and multi-modal models, to augment decision making for the US Intelligence Community.; Large Language Models: Experience with Large Language Models (LLMs) is required to build state-of-the-art generative models for text and other modalities tailored to mission-specific use cases.; Deep Learning Frameworks for Neural Networks: Hands-on experience with deep learning frameworks like TensorFlow, PyTorch, and JAX is necessary specifically for building and deploying neural network models within generative AI and advanced AI algorithms.","['Machine Learning', 'Data Mining', 'Numerical Optimization', 'Algorithms and Data Structures', 'Parallel and Distributed Computing', 'High-Performance Computing', 'Python', 'Deep Learning Frameworks']","Machine Learning: The role involves building models for business applications using traditional machine learning methods to address real-world challenges and support customer needs.; Data Mining: Experience with data mining techniques is required to extract useful information from diverse data sources to build data-intensive applications at scale.; Numerical Optimization: The job requires applying numerical optimization methods as part of algorithm development and model building for business and intelligence community applications.; Algorithms and Data Structures: The position demands expertise in algorithms and data structures to efficiently process and analyze data for model development and deployment.; Parallel and Distributed Computing: Experience with parallel and distributed computing is necessary to handle high-performance computing tasks and scale data-intensive applications.; High-Performance Computing: The role includes leveraging high-performance computing resources to build and deploy complex models and data applications at scale.; Python: Hands-on experience using Python is essential for building models and implementing data science and machine learning solutions.; Deep Learning Frameworks: The job requires practical experience building models using deep learning frameworks such as TensorFlow, Keras, PyTorch, MXNet, or JAX to develop neural deep learning methods."
8LeYF2XmL_c0lKQeAAAAAA==,Data Analyst/Scientist/Engineer - Entry/Junior Level,"Since 2010 Synergisticit has helped Jobseekers differentiate themselves by providing candidates the requisite skills and experience to outperform at interviews and clients. Here at SynergisticIT We just don't focus on getting you a tech Job we make careers.
In this market also we have been able to help our candidates get multiple job offers and $100k + salaries.
please check the below links to see the success outcomes of our candidates our participation at different Tech industry events and how we are different from other organizations in helping Jobseekers secure Tech careers
https://www.synergisticit.com/candidate-outcomes/
https://reg.rf.oracle.com/flow/oracle/cwoh23/OCWExhibitorCatalog/page/OCWexhibitorcatalog
We regularly interact with the Top Tech companies to give our candidates a competitive advantage see us exhibiting at Oracle Cloud World/Oracle Java One (Las Vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023
All Positions are open for all visas and US citizens
We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like Apple, Google, Paypal, Western Union, Client, visa, Walmart lab s etc to name a few.
We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, Java full-stack developers, Python/Java developers, Data analysts/ Data Scientists, and Machine Learning engineers for full-time positions with clients.
Who Should Apply Recent Computer Science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry?
We assist in filing for STEM extension and also for H1b and Green card filing to Candidates
https://www.youtube.com/watch?v=OFoqPTNORew
https://www.youtube.com/watch?v=-HkNN1ag6Zk
https://www.youtube.com/watch?v=OAFOhcGy9Z8
https://youtu.be/bJJl27D8bh0
We are looking for the right matching candidates for our clients
REQUIRED SKILLS For Java /Full stack/Software Programmer
• Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
• Highly motivated, self-learner, and technically inquisitive
• Experience in programming language Java and understanding of the software development life cycle
• Project work on the skills
• Knowledge of Core Java , javascript, C++, or software programming
• Spring boot, Microservices, Docker, Jenkins, and REST API experience
• Excellent written and verbal communication skills
For data Science/Machine learning Positions
REQUIRED SKILLS
• Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
• Project work on the technologies needed
• Highly motivated, self-learner, and technically inquisitive
• Experience in programming language Java and understanding of the software development life cycle
• Knowledge of Statistics, SAS, Python, Computer Vision, and data visualization tools
• Excellent written and verbal communication skills

Preferred skills: NLP, Text mining, Tableau, PowerBI, SAS, Tensorflow
If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team and only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third-party or agency candidates or c2c candidates",,2025-07-25,"['REQUIRED SKILLS For Java /Full stack/Software Programmer', 'Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT', 'Highly motivated, self-learner, and technically inquisitive', 'Experience in programming language Java and understanding of the software development life cycle', 'Project work on the skills', 'Knowledge of Core Java , javascript, C++, or software programming', 'Spring boot, Microservices, Docker, Jenkins, and REST API experience', 'Excellent written and verbal communication skills', 'For data Science/Machine learning Positions', 'Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT', 'Project work on the technologies needed', 'Highly motivated, self-learner, and technically inquisitive', 'Experience in programming language Java and understanding of the software development life cycle', 'Knowledge of Statistics, SAS, Python, Computer Vision, and data visualization tools', 'Excellent written and verbal communication skills']",,True,['TensorFlow'],"TensorFlow: TensorFlow is preferred for machine learning and deep learning model development, indicating use of neural networks and AI frameworks.","['Statistics', 'SAS', 'Python', 'Computer Vision', 'Data Visualization Tools', 'NLP', 'Text Mining', 'Tableau', 'Power BI']","Statistics: Knowledge of statistics is required for data science and machine learning positions to analyze and interpret data effectively.; SAS: Experience with SAS is needed for statistical analysis and data management in data science roles.; Python: Python programming skills are required for data science and machine learning tasks, including data manipulation and analysis.; Computer Vision: Familiarity with computer vision techniques is preferred, indicating work with image or video data analysis.; Data Visualization Tools: Experience with data visualization tools is preferred to create visual representations of data insights.; NLP: Natural Language Processing skills are preferred, suggesting work with text data and language analysis.; Text Mining: Text mining skills are preferred for extracting useful information from text data.; Tableau: Experience with Tableau is preferred for building interactive business intelligence dashboards and visualizations.; Power BI: Power BI experience is preferred for creating business intelligence reports and dashboards."
bbUxVNWuJFKrOXU-AAAAAA==,"Sr. Data Science Manager, Marketing","We are Farmers!

We are… more than just your favorite commercials.  At Farmers, we strive to deliver peace of mind to our customers by providing protection and comprehensive advice and delivering in the moments of truth. That means having people who can help us meet changing customer and business needs. Farmers high-performance culture is focused on results and the people who achieve them. We hold ourselves and others accountable for sustainably growing the business and each other. We seek solutions, own our actions, and grow through discomfort. We see setbacks as opportunities while continuously asking ourselves how we impact our customers.

Farmers is an award winning, equal opportunity employer, committed to the strength of a diverse workforce. We are dedicated to supporting the well-being of our people through our extensive suite of benefits, as well as the well-being of the communities we serve through employee volunteer programs and nonprofit partnerships. Helping others in their time of need isn’t just our business – it’s our culture!  To learn more about our high-performance culture and open opportunities, check out www.Farmers.com/careers/corporate and be sure to follow us on Instagram, LinkedIn, and TikTok.

Workplace: Hybrid ( #LI-Hybrid ), Remote ( #LI-Remote )

Farmers believes in a culture of collaboration, creativity, and innovation, which thrives when we have the ability to work flexibly in a virtual setting as well as the opportunity to be together in person. Our hybrid work environment combines the best of both worlds with at least three (3) days in office and up to two (2) days virtual for employees who live within fifty (50) miles of a Farmers corporate office. Applicants beyond fifty (50) miles may still be considered.
Job Summary
• Utilizes specialized knowledge and experience to apply advanced analytics and modeling to improve business results.
• Leverages unique customer information and behavioral data to influence strategic business decisions while using complex, innovative analytics, multi-variate models, machine learning and data mining technologies.
• Assists in and leads complex, cross-functional projects operationalizing business decisions.
• Works independently receiving guidance in only the most complex situations.
• The role mentors, coaches, and trains less experienced team members and supervises direct reports who are individual contributors.

What You'll Do
• Takes ownership and executes on more complex and often vague business challenges involving data science. Succeeds in specialized projects by scoping, defining measures of success, utilizing a data science vision for project success, and exceeding on prescribed and some vague timelines. Executes and leads broad projects independently with a sense of urgency. Utilizes specialized knowledge of consumer analytics including retention models, agency economics, and leads optimization in their daily work.
• Utilizes broad knowledge of advanced programing, complex ETL and specialized modeling methods to execute projects and leads the team through examples of effective technical skills. Demonstrates clean reusable code and effective documentation, encourages others to do the same. Acts as the main contributor to multiple phases of a data science project (ideation, experiment design, EDA, feature engineering, model building, deployment, etc. ). Utilizes a strong sense of ownership and contributes to multiple tasks and deadlines simultaneously.
• Partners closely with IT, business, and data management/engineering teams to understand, utilize, and improve our data infrastructure. Advises on complex matters and serves as an objective and transparent partner to drive fact-based decision making and a measures of success culture. Provides strategic direction, project clarity and methodological consultation. Delivers results both individually and by mentoring and empowering other team members.
• Mentors and provides guidance to team members. Provides high level coaching and knowledge around technical and non-technical skills. Reviews AI/ML modeling, statistical analysis, and data analysis completed by other team members, providing coaching and feedback as needed.
• Develops presentations and presents to all groups and levels of leadership, including executives. Regularly communicates complex technical material understandable to non-technical associates.
• Manages specialized model deployments via MLOps techniques. Partners closely with analytics and IT teams to deploy models/rules in various platforms and leads testing of new solutions. Takes active role in steering MLOps environment improvements.

What You'll Bring
• Minimum seven years of work experience required in data analysis, statistical or mathematical modeling, or related.
• Marketing experience preferred; Marketing Mix Modeling experience strongly preferred (not required).

Education You'll Need
• High School Diploma or equivalent required.
• Masters degree required in data science, statistics, mathematics, business analytics or related.

Additional Qualifications
• Strong verbal communication and listening skills. Advanced storytelling skills with ability to communicate complex data insights clearly to technical and non-technical audiences.
• Demonstrated written communication skills.
• Proficient in Microsoft Office Suite.
• Develops and delivers effective presentations.
• Effectively coaches and delivers constructive feedback.
• Demonstrated problem solving skills.
• Excellent collaboration and team building skills.
• Ability to influence internal and/or external constituents.
• Seeks to acquire knowledge in area of specialty.
• Possesses flexibility to work in a fast paced, dynamic environment. Able to meet deadlines and priorities that shift with business needs. Able to simultaneously handle multiple priorities. Possesses solid project management skills.
• Demonstrated analytical skills. Possesses advanced technical aptitude.
• Advanced proficiency working on large-scale structured and unstructured multidimensional data using advanced knowledge of open-source cloud-enabled analytical programming languages. Advanced ability to consult on data extraction, data manipulation and data design for statistical, modeling and monitoring needs. Advanced knowledge of data analysis, manipulation tools (SQL, Python, SAS, R, and/or Snowflake) and cloud computing services (AWS). Advanced knowledge of data visualization tools (example, Tableau, Power BI).
• Advanced proficiency in using explanatory, diagnostic, and inferential techniques such as experimental design, hypothesis testing, clustering analysis, time series and other statistical modeling algorithms with the ability to decide the appropriate methodology for the purpose. Advanced proficiency in predictive and prescriptive modeling using advanced machine learning and deep learning techniques. Advanced in ML/AI model deployment best practices. Able to adapt quickly to new technologies. Advanced knowledge of coding standards and version control (Git). Other. Broad knowledge of data ethics and data privacy.

Benefits
• Farmers offers a competitive salary commensurate with experience, qualifications and location.
o CA Only: $134,320 - $214,390
o CO Only: $126,240 - $184,690
o HI/IL/MN/VT Only: $126,240 - $197,780
o MA Only: $126,240 - $197,780
• o MD Only: $126,240 - $197,780
o NY/DC/NJ Only: $126,240 - $214,390
o Albany County: $134,320 - $184,690
o WA Only: $126,240 - $224,750
• Bonus Opportunity (based on Company and Individual Performance)
• 401(k)
• Medical
• Dental
• Vision
• Health Savings and Flexible Spending Accounts
• Life Insurance
• Paid Time Off
• Paid Parental Leave
• Tuition Assistance
• For more information, review “What we offer” on https://www.farmers.com/careers/corporate/#offer

Job Location(s): R_US - United States, US - CA - WdlndHills-6301, US - CA - WdlndHills-6303, US - CA - Woodland Hills

Anticipated application deadline: At Farmers, the recruitment process is designed to ensure that we find the best talent to join our team. As part of this process, we typically close open positions within 8 to 21 days after posting. If you are interested in any of our open positions, we encourage you to submit your application promptly.

Farmers will consider for employment all qualified applicants, including those with criminal histories, in accordance with the Los Angeles Fair Chance Initiative for Hiring Ordinance or other applicable law. Pursuant to 18 U.S.C. Section 1033, Farmers is prohibited from employing any individual who has been convicted of any criminal felony involving dishonesty or a breach of trust without prior written consent from the state Department of Insurance.

Farmers is an Equal Opportunity Employer and does not discriminate in any employer/employee relations based on race, color, religion, gender, sexual orientation, gender expression, genetic information, national origin, age, disability, marital status, military and veteran's status, or any other basis protected by applicable discrimination laws.

Want to learn more about our culture & opportunities? Check out www.Farmers.com/careers/corporate and be sure to follow us on Instagram, LinkedIn, and TikTok.

Spokane, WA only: Residents who prefer not to provide their address click here to submit your resume via email: careers@farmers.com",2025-07-14T00:00:00.000Z,2025-07-25,"['Minimum seven years of work experience required in data analysis, statistical or mathematical modeling, or related', 'High School Diploma or equivalent required', 'Masters degree required in data science, statistics, mathematics, business analytics or related', 'Strong verbal communication and listening skills', 'Advanced storytelling skills with ability to communicate complex data insights clearly to technical and non-technical audiences', 'Demonstrated written communication skills', 'Proficient in Microsoft Office Suite', 'Develops and delivers effective presentations', 'Demonstrated problem solving skills', 'Excellent collaboration and team building skills', 'Ability to influence internal and/or external constituents', 'Seeks to acquire knowledge in area of specialty', 'Possesses flexibility to work in a fast paced, dynamic environment', 'Able to meet deadlines and priorities that shift with business needs', 'Able to simultaneously handle multiple priorities', 'Possesses solid project management skills', 'Demonstrated analytical skills', 'Possesses advanced technical aptitude', 'Advanced proficiency working on large-scale structured and unstructured multidimensional data using advanced knowledge of open-source cloud-enabled analytical programming languages', 'Advanced ability to consult on data extraction, data manipulation and data design for statistical, modeling and monitoring needs', 'Advanced knowledge of data analysis, manipulation tools (SQL, Python, SAS, R, and/or Snowflake) and cloud computing services (AWS)', 'Advanced knowledge of data visualization tools (example, Tableau, Power BI)', 'Advanced proficiency in using explanatory, diagnostic, and inferential techniques such as experimental design, hypothesis testing, clustering analysis, time series and other statistical modeling algorithms with the ability to decide the appropriate methodology for the purpose', 'Advanced proficiency in predictive and prescriptive modeling using advanced machine learning and deep learning techniques', 'Advanced in ML/AI model deployment best practices', 'Able to adapt quickly to new technologies', 'Advanced knowledge of coding standards and version control (Git)', 'Broad knowledge of data ethics and data privacy']","['That means having people who can help us meet changing customer and business needs', 'Utilizes specialized knowledge and experience to apply advanced analytics and modeling to improve business results', 'Leverages unique customer information and behavioral data to influence strategic business decisions while using complex, innovative analytics, multi-variate models, machine learning and data mining technologies', 'Assists in and leads complex, cross-functional projects operationalizing business decisions', 'Works independently receiving guidance in only the most complex situations', 'The role mentors, coaches, and trains less experienced team members and supervises direct reports who are individual contributors', 'Takes ownership and executes on more complex and often vague business challenges involving data science', 'Succeeds in specialized projects by scoping, defining measures of success, utilizing a data science vision for project success, and exceeding on prescribed and some vague timelines', 'Executes and leads broad projects independently with a sense of urgency', 'Utilizes specialized knowledge of consumer analytics including retention models, agency economics, and leads optimization in their daily work', 'Utilizes broad knowledge of advanced programing, complex ETL and specialized modeling methods to execute projects and leads the team through examples of effective technical skills', 'Demonstrates clean reusable code and effective documentation, encourages others to do the same', 'Acts as the main contributor to multiple phases of a data science project (ideation, experiment design, EDA, feature engineering, model building, deployment, etc', 'Utilizes a strong sense of ownership and contributes to multiple tasks and deadlines simultaneously', 'Partners closely with IT, business, and data management/engineering teams to understand, utilize, and improve our data infrastructure', 'Advises on complex matters and serves as an objective and transparent partner to drive fact-based decision making and a measures of success culture', 'Provides strategic direction, project clarity and methodological consultation', 'Delivers results both individually and by mentoring and empowering other team members', 'Mentors and provides guidance to team members', 'Provides high level coaching and knowledge around technical and non-technical skills', 'Reviews AI/ML modeling, statistical analysis, and data analysis completed by other team members, providing coaching and feedback as needed', 'Develops presentations and presents to all groups and levels of leadership, including executives', 'Regularly communicates complex technical material understandable to non-technical associates', 'Manages specialized model deployments via MLOps techniques', 'Partners closely with analytics and IT teams to deploy models/rules in various platforms and leads testing of new solutions', 'Takes active role in steering MLOps environment improvements', 'Effectively coaches and delivers constructive feedback']",True,['Deep Learning'],Deep Learning: Applies advanced deep learning techniques as part of predictive and prescriptive modeling to improve business outcomes and model performance.,"['Advanced Analytics', 'Behavioral Data Analysis', 'Machine Learning', 'Consumer Analytics', 'ETL (Extract, Transform, Load)', 'Data Science Project Lifecycle', 'Data Infrastructure Collaboration', 'Statistical Modeling Techniques', 'Predictive and Prescriptive Modeling', 'MLOps (Model Deployment and Operations)', 'Programming and Coding Standards', 'Data Manipulation and Extraction Tools', 'Cloud Computing Services', 'Data Visualization Tools', 'Experimental Design and Hypothesis Testing', 'Clustering Analysis', 'Time Series Modeling', 'Data Ethics and Privacy']","Advanced Analytics: Utilizes specialized knowledge and experience to apply advanced analytics and modeling to improve business results.; Behavioral Data Analysis: Leverages unique customer information and behavioral data to influence strategic business decisions using complex, innovative analytics and multi-variate models.; Machine Learning: Uses machine learning and data mining technologies to develop predictive and prescriptive models; reviews AI/ML modeling completed by team members and provides coaching and feedback.; Consumer Analytics: Utilizes specialized knowledge of consumer analytics including retention models, agency economics, and leads optimization in daily work.; ETL (Extract, Transform, Load): Applies broad knowledge of advanced programming and complex ETL processes to execute projects and lead the team through effective technical skills.; Data Science Project Lifecycle: Acts as main contributor to multiple phases of data science projects including ideation, experiment design, exploratory data analysis (EDA), feature engineering, model building, and deployment.; Data Infrastructure Collaboration: Partners closely with IT, business, and data management/engineering teams to understand, utilize, and improve data infrastructure to support fact-based decision making.; Statistical Modeling Techniques: Applies explanatory, diagnostic, and inferential techniques such as experimental design, hypothesis testing, clustering analysis, time series, and other statistical modeling algorithms to decide appropriate methodologies.; Predictive and Prescriptive Modeling: Demonstrates advanced proficiency in predictive and prescriptive modeling using advanced machine learning and deep learning techniques.; MLOps (Model Deployment and Operations): Manages specialized model deployments via MLOps techniques, partners with analytics and IT teams to deploy models/rules on various platforms, leads testing of new solutions, and actively improves the MLOps environment.; Programming and Coding Standards: Demonstrates clean reusable code, effective documentation, advanced knowledge of coding standards, and version control using Git.; Data Manipulation and Extraction Tools: Possesses advanced knowledge of data analysis and manipulation tools including SQL, Python, SAS, R, and Snowflake for statistical, modeling, and monitoring needs.; Cloud Computing Services: Utilizes cloud computing services such as AWS to work on large-scale structured and unstructured multidimensional data.; Data Visualization Tools: Uses data visualization tools like Tableau and Power BI to communicate complex data insights clearly to technical and non-technical audiences.; Experimental Design and Hypothesis Testing: Employs experimental design and hypothesis testing techniques as part of advanced statistical analysis to support data-driven decision making.; Clustering Analysis: Applies clustering analysis as part of diagnostic and inferential statistical techniques to analyze data patterns.; Time Series Modeling: Uses time series and other statistical modeling algorithms to analyze temporal data and support business decisions.; Data Ethics and Privacy: Maintains broad knowledge of data ethics and data privacy to ensure responsible handling of data in all projects."
W7z9qXFh2jQjilApAAAAAA==,"Data Scientist, Marketing & Commercial Analytics","At Zelis, we Get Stuff Done. So, let’s get to it! A Little About Us Zelis is modernizing the healthcare financial experience across payers, providers, and healthcare consumers. We serve more than 750 payers, including the top five national health plans, regional health plans, TPAs and millions of healthcare providers and consumers across our platform of solutions. Zelis sees across the system to identify, optimize, and solve problems holistically with technology built by healthcare experts – driving real, measurable results for clients. A Little About You You bring a unique blend of personality and professional expertise to your work, inspiring others with your passion and dedication. Your career is a testament to your diverse experiences, community involvement, and the valuable lessons you've learned along the way. You are more than just your resume; you are a reflection of your achievements, the knowledge you've gained, and the personal interests that shape who you are. Position Overview Zelis is seeking a Data Scientist to join our growing Analytics team supporting marketing and commercial strategy across all business units. This is a strategic, net-new role designed to expand our enterprise-wide use of data science to drive insights, accelerate growth, and optimize decision-making. You will work cross-functionally with marketing, sales, product, and client teams to unlock the value of data through advanced analytics, modeling, and impactful visual storytelling. This role is ideal for someone who is hands-on, deeply analytical, and excited by the challenge of building scalable analytics solutions that inform go-to-market strategies and campaign performance. Position Overview What You’ll Do Key Responsibilities: End-to-End Data Science Execution: Own the full analytics lifecycle—from ingesting and cleaning raw data to developing predictive models, running statistical analyses, and translating findings into actionable insights for business leaders. Cross-Functional Impact: Partner with stakeholders across marketing, sales, and product teams to uncover opportunities through segmentation, attribution, funnel optimization, and campaign performance analysis. Predictive Modeling & Segmentation: Develop customer and account-level models to predict behavior, inform targeting strategies, and personalize engagement across digital and direct channels. Advanced Visualization & Dashboarding: Build interactive dashboards (Power BI preferred) that surface insights clearly and intuitively to both technical and non-technical users. Integrate AI-based tools to accelerate insight delivery. Data Quality & Governance: Proactively identify data gaps and inconsistencies across systems (e.g., CRM, campaign tools, external sources). Work with internal partners to resolve data quality issues and improve governance standards. Innovation & Tooling: Continuously evaluate and recommend new data sources, technologies, and techniques—including generative AI applications—to improve analytical workflows and business outcomes. What You’ll Bring to Zelis Qualifications 3+ years of hands-on experience in a data science or advanced analytics role, ideally supporting marketing, sales, or commercial operations Proficiency in Python and SQL required; experience with R is a plus Strong experience using data visualization platforms such as Power BI or Tableau to develop executive-level dashboards Experience working with CRM and marketing systems such as Hubspot, Salesforce, LinkedIn Campaign Manager, or similar Demonstrated ability to drive projects independently and explain complex concepts to business stakeholders Strong understanding of data modeling, A/B testing, and predictive analytics Exceptional attention to data integrity, structure, and usability across multiple sources Experience in healthcare is preferred but not required Preferred Education Master’s degree in a quantitative field such as Statistics, Computer Science, Marketing Analytics, or Business Analytics (or equivalent real-world experience) Please note at this time we are unable to proceed with candidates who require visa sponsorship now or in the future. Location and Workplace Flexibility We have offices in Atlanta GA, Boston MA, Morristown NJ, Plano TX, St. Louis MO, St. Petersburg FL, and Hyderabad, India. We foster a hybrid and remote friendly culture, and all our employee's work locations are based on the needs of the position and determined by the Leadership team. In-office work and activities, if applicable, vary based on the work and team objectives in accordance with Company policies. Equal Employment Opportunity Zelis is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. We welcome applicants from all backgrounds and encourage you to apply even if you don’t meet 100% of the qualifications for the role. We believe in the value of diverse perspectives and experiences and are committed to building an inclusive workplace for all. Accessibility Support We are dedicated to ensuring our application process is accessible to all candidates. If you are a qualified individual with a disability or a disabled veteran and require a reasonable accommodation with any part of the application and/or interview process, please email TalentAcquisition@zelis.com. Disclaimer We are an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law. The above statements are intended to describe the general nature and level of work being performed by people assigned to this classification. They are not to be construed as an exhaustive list of all responsibilities, duties, and skills required of personnel so classified. All personnel may be required to perform duties outside of their normal responsibilities, duties, and skills from time to time. Zelis is modernizing the healthcare financial experience across payers, providers, and healthcare consumers. We serve more than 750 payers, including the top five national health plans, regional health plans, TPAs and millions of healthcare providers and consumers across our platform of solutions. Zelis sees across the system to identify, optimize, and solve problems holistically with technology built by healthcare experts – driving real, measurable results for clients.",2025-06-26T00:00:00.000Z,2025-07-25,,,True,['Generative AI'],Generative AI: Evaluate and recommend generative AI applications to improve analytical workflows and accelerate insight delivery.,"['Predictive Modeling', 'Statistical Analysis', 'Data Cleaning and Ingestion', 'Segmentation and Attribution', 'A/B Testing', 'Data Visualization and Dashboarding', 'Data Quality and Governance', 'SQL', 'Python', 'CRM and Marketing Systems']","Predictive Modeling: Develop customer and account-level models to predict behavior, inform targeting strategies, and personalize engagement across digital and direct channels.; Statistical Analysis: Run statistical analyses to translate findings into actionable insights for business leaders.; Data Cleaning and Ingestion: Own the full analytics lifecycle including ingesting and cleaning raw data to prepare it for analysis and modeling.; Segmentation and Attribution: Partner with stakeholders to uncover opportunities through segmentation, attribution, funnel optimization, and campaign performance analysis.; A/B Testing: Apply A/B testing methodologies to evaluate marketing and campaign performance.; Data Visualization and Dashboarding: Build interactive dashboards using Power BI (preferred) or Tableau to surface insights clearly and intuitively to both technical and non-technical users.; Data Quality and Governance: Identify data gaps and inconsistencies across systems such as CRM and campaign tools, and work with internal partners to resolve data quality issues and improve governance standards.; SQL: Use SQL for data querying and manipulation as part of data science and analytics workflows.; Python: Utilize Python for data science tasks including data processing, modeling, and analysis.; CRM and Marketing Systems: Work with CRM and marketing platforms such as Hubspot, Salesforce, and LinkedIn Campaign Manager to integrate and analyze marketing data."
y9FYKoONTLbfhN-DAAAAAA==,Lead Data Scientist - Full-time,"Do you have a strong background in machine learning and deep learning? Are you interested in utilizing your data science skills and working with a small team in a fast-paced environment to achieve strategic mission goals? If so, Deloitte has an exciting opportunity for you!

The Team:

The GPS GSi group at Deloitte is dedicated to driving innovation and efficiency through advanced data science and business intelligence solutions. Our team collaborates closely with Enabling Area professionals to develop and implement cutting-edge machine learning, deep learning, and generative AI initiatives. We thrive in a dynamic environment where teamwork and independent problem-solving are key to achieving our strategic mission goals. Join us to be part of a small, agile team that is at the forefront of transforming decision-making processes and delivering impactful solutions.

Recruiting for this role ends on July 31st, 2025.

What You'll Do:

As a member of our GPS GSi group, you will play a crucial role in the development and maintenance of our data science and business intelligence solutions. This role will specialize in assisting with machine learning, deep learning, and generative AI initiatives that will be utilized by Enabling Area professionals to enhance and expedite decision-making. You will provide expertise within and across business teams, demonstrate the ability to work independently, and apply problem-solving skills to resolve complex issues.

+ Lead and participate in developing data science products, transforming client needs into quantifiable solutions.

+ Independently carry out tasks, using critical thinking and problem-solving skills to devise effective solutions.

+ Design, train, and deploy machine learning and deep learning models on platforms like AWS, Databricks, and Dataiku.

+ Develop and advise on Large Language Model (LLM) solutions for enterprise-wide documentation, including RAG, CPT, and SFT.

+ Utilize MLOps pipelines, including containerization (Docker) and CI/CD, for training and deploying models.

+ Write clean, well-commented code for easy collaboration and maintain structured project documentation using GitHub and/or Jira.

Qualifications

Required skills:

+ Bachelor's Degree in Statistics, Mathematics, Computer Science, Engineering, or another analytical field.

+ 6+ years of experience in data science, with deep knowledge of Python, machine learning, deep learning, and related packages (e.g., sklearn, TensorFlow, PyTorch). Proven ability to lead data science projects from inception to deployment.

+ Strong knowledge of Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG).

+ Familiarity with AWS, Databricks, and/or Dataiku platforms.

+ Working knowledge of MLOps, including containerization (e.g., Docker).

+ Strong organizational skills, with clear project documentation and the ability to write clean code.

+ Familiarity with agile project methodology and project development lifecycle.

+ Experience with GitHub for version control.

+ Ability to manage multiple detailed tasks and responsibilities simultaneously, meeting deadlines and objectives accurately.

+ Must be legally authorized to work in the United States without employer sponsorship, now or in the future.

+ Ability to travel 10%-25%, on average, based on the work you do and the clients and industries/sectors you serve

Preferred Skills:

+ Master's Degree in Statistics, Mathematics, Computer Science, Engineering, or another analytical field, or equivalent direct work experience.

+ Significant experience with MLOps and associated serving frameworks (e.g., Flask, FastAPI) and orchestration pipelines (e.g., SageMaker Pipelines, Step Functions, Metaflow).

+ Significant experience working with open-source LLMs, including serving via TGI/vLLM and performing Continued Pre-training (CPT) and/or Supervised Fine-tuning (SFT).

+ Experience using various AWS Services (e.g., Textract, Transcribe, Lambda, etc.).

+ Proficiency in basic front-end web development (e.g., Streamlit).

+ Knowledge of Object-Oriented Programming (OOP) concepts.

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $97,600 to $179,900

You may also be eligible to participate in a discretionary annual incentive program, subject to the rules governing the program, whereby an award, if any, depends on various factors, including, without limitation, individual and organizational performance.

Information for applicants with a need for accommodation: https://www2.deloitte.com/us/en/pages/careers/articles/join-deloitte-assistance-for-disabled-applicants.html

EA_ExpHire, EA_GPS_ExpHire, #LI-JK2

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.

Do you have a strong background in machine learning and deep learning? Are you interested in utilizing your data science skills and working with a small team in a fast-paced environment to achieve strategic mission goals? If so, Deloitte has an exciting opportunity for you!

The Team:

The GPS GSi group at Deloitte is dedicated to driving innovation and efficiency through advanced data science and business intelligence solutions. Our team collaborates closely with Enabling Area professionals to develop and implement cutting-edge machine learning, deep learning, and generative AI initiatives. We thrive in a dynamic environment where teamwork and independent problem-solving are key to achieving our strategic mission goals. Join us to be part of a small, agile team that is at the forefront of transforming decision-making processes and delivering impactful solutions.

Recruiting for this role ends on July 31st, 2025.

What You'll Do:

As a member of our GPS GSi group, you will play a crucial role in the development and maintenance of our data science and business intelligence solutions. This role will specialize in assisting with machine learning, deep learning, and generative AI initiatives that will be utilized by Enabling Area professionals to enhance and expedite decision-making. You will provide expertise within and across business teams, demonstrate the ability to work independently, and apply problem-solving skills to resolve complex issues.

+ Lead and participate in developing data science products, transforming client needs into quantifiable solutions.

+ Independently carry out tasks, using critical thinking and problem-solving skills to devise effective solutions.

+ Design, train, and deploy machine learning and deep learning models on platforms like AWS, Databricks, and Dataiku.

+ Develop and advise on Large Language Model (LLM) solutions for enterprise-wide documentation, including RAG, CPT, and SFT.

+ Utilize MLOps pipelines, including containerization (Docker) and CI/CD, for training and deploying models.

+ Write clean, well-commented code for easy collaboration and maintain structured project documentation using GitHub and/or Jira.

Qualifications

Required skills:

+ Bachelor's Degree in Statistics, Mathematics, Computer Science, Engineering, or another analytical field.

+ 6+ years of experience in data science, with deep knowledge of Python, machine learning, deep learning, and related packages (e.g., sklearn, TensorFlow, PyTorch). Proven ability to lead data science projects from inception to deployment.

+ Strong knowledge of Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG).

+ Familiarity with AWS, Databricks, and/or Dataiku platforms.

+ Working knowledge of MLOps, including containerization (e.g., Docker).

+ Strong organizational skills, with clear project documentation and the ability to write clean code.

+ Familiarity with agile project methodology and project development lifecycle.

+ Experience with GitHub for version control.

+ Ability to manage multiple detailed tasks and responsibilities simultaneously, meeting deadlines and objectives accurately.

+ Must be legally authorized to work in the United States without employer sponsorship, now or in the future.

+ Ability to travel 10%-25%, on average, based on the work you do and the clients and industries/sectors you serve

Preferred Skills:

+ Master's Degree in Statistics, Mathematics, Computer Science, Engineering, or another analytical field, or equivalent direct work experience.

+ Significant experience with MLOps and associated serving frameworks (e.g., Flask, FastAPI) and orchestration pipelines (e.g., SageMaker Pipelines, Step Functions, Metaflow).

+ Significant experience working with open-source LLMs, including serving via TGI/vLLM and performing Continued Pre-training (CPT) and/or Supervised Fine-tuning (SFT).

+ Experience using various AWS Services (e.g., Textract, Transcribe, Lambda, etc.).

+ Proficiency in basic front-end web development (e.g., Streamlit).

+ Knowledge of Object-Oriented Programming (OOP) concepts.

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $97,600 to $179,900

You may also be eligible to participate in a discretionary annual incentive program, subject to the rules governing the program, whereby an award, if any, depends on various factors, including, without limitation, individual and organizational performance.

Information for applicants with a need for accommodation: https://www2.deloitte.com/us/en/pages/careers/articles/join-deloitte-assistance-for-disabled-applicants.html

EA_ExpHire, EA_GPS_ExpHire, #LI-JK2

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.",2025-07-25T08:00:00.000Z,2025-07-25,"[""Bachelor's Degree in Statistics, Mathematics, Computer Science, Engineering, or another analytical field"", '6+ years of experience in data science, with deep knowledge of Python, machine learning, deep learning, and related packages (e.g., sklearn, TensorFlow, PyTorch)', 'Proven ability to lead data science projects from inception to deployment', 'Strong knowledge of Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG)', 'Familiarity with AWS, Databricks, and/or Dataiku platforms', 'Working knowledge of MLOps, including containerization (e.g., Docker)', 'Strong organizational skills, with clear project documentation and the ability to write clean code', 'Familiarity with agile project methodology and project development lifecycle', 'Experience with GitHub for version control', 'Ability to manage multiple detailed tasks and responsibilities simultaneously, meeting deadlines and objectives accurately', 'Must be legally authorized to work in the United States without employer sponsorship, now or in the future', 'Ability to travel 10%-25%, on average, based on the work you do and the clients and industries/sectors you serve', 'All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law', 'Do you have a strong background in machine learning and deep learning?', ""Bachelor's Degree in Statistics, Mathematics, Computer Science, Engineering, or another analytical field"", '6+ years of experience in data science, with deep knowledge of Python, machine learning, deep learning, and related packages (e.g., sklearn, TensorFlow, PyTorch)', 'Proven ability to lead data science projects from inception to deployment', 'Strong knowledge of Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG)', 'Familiarity with AWS, Databricks, and/or Dataiku platforms', 'Working knowledge of MLOps, including containerization (e.g., Docker)', 'Strong organizational skills, with clear project documentation and the ability to write clean code', 'Familiarity with agile project methodology and project development lifecycle', 'Experience with GitHub for version control', 'Ability to manage multiple detailed tasks and responsibilities simultaneously, meeting deadlines and objectives accurately', 'Must be legally authorized to work in the United States without employer sponsorship, now or in the future', 'Ability to travel 10%-25%, on average, based on the work you do and the clients and industries/sectors you serve']","['As a member of our GPS GSi group, you will play a crucial role in the development and maintenance of our data science and business intelligence solutions', 'This role will specialize in assisting with machine learning, deep learning, and generative AI initiatives that will be utilized by Enabling Area professionals to enhance and expedite decision-making', 'You will provide expertise within and across business teams, demonstrate the ability to work independently, and apply problem-solving skills to resolve complex issues', 'Lead and participate in developing data science products, transforming client needs into quantifiable solutions', 'Independently carry out tasks, using critical thinking and problem-solving skills to devise effective solutions', 'Design, train, and deploy machine learning and deep learning models on platforms like AWS, Databricks, and Dataiku', 'Develop and advise on Large Language Model (LLM) solutions for enterprise-wide documentation, including RAG, CPT, and SFT', 'Utilize MLOps pipelines, including containerization (Docker) and CI/CD, for training and deploying models', 'Write clean, well-commented code for easy collaboration and maintain structured project documentation using GitHub and/or Jira', 'As a member of our GPS GSi group, you will play a crucial role in the development and maintenance of our data science and business intelligence solutions', 'This role will specialize in assisting with machine learning, deep learning, and generative AI initiatives that will be utilized by Enabling Area professionals to enhance and expedite decision-making', 'You will provide expertise within and across business teams, demonstrate the ability to work independently, and apply problem-solving skills to resolve complex issues', 'Lead and participate in developing data science products, transforming client needs into quantifiable solutions', 'Independently carry out tasks, using critical thinking and problem-solving skills to devise effective solutions', 'Design, train, and deploy machine learning and deep learning models on platforms like AWS, Databricks, and Dataiku', 'Develop and advise on Large Language Model (LLM) solutions for enterprise-wide documentation, including RAG, CPT, and SFT', 'Utilize MLOps pipelines, including containerization (Docker) and CI/CD, for training and deploying models', 'Write clean, well-commented code for easy collaboration and maintain structured project documentation using GitHub and/or Jira']",True,"['Large Language Models (LLMs)', 'Retrieval-Augmented Generation (RAG)', 'Continued Pre-training (CPT)', 'Supervised Fine-tuning (SFT)', 'Generative AI', 'MLOps for AI Models', 'Flask and FastAPI', 'SageMaker Pipelines, Step Functions, Metaflow', 'Open-source LLM Serving (TGI/vLLM)']","Large Language Models (LLMs): The position requires developing and advising on LLM solutions for enterprise-wide documentation to enhance and expedite decision-making processes.; Retrieval-Augmented Generation (RAG): RAG techniques are applied to improve LLM-based solutions by integrating external knowledge retrieval to support enterprise documentation and AI initiatives.; Continued Pre-training (CPT): CPT is used to further train open-source LLMs to adapt them to specific enterprise needs and improve performance on domain-specific tasks.; Supervised Fine-tuning (SFT): SFT is employed to fine-tune LLMs with labeled data to enhance their accuracy and relevance for enterprise applications.; Generative AI: The role involves working on generative AI initiatives that transform decision-making processes and deliver impactful AI-driven solutions.; MLOps for AI Models: MLOps pipelines are utilized specifically for training, deploying, and managing AI models such as LLMs, including containerization and CI/CD practices tailored to AI workflows.; Flask and FastAPI: These serving frameworks are used to deploy AI models and APIs as part of MLOps pipelines to enable scalable and efficient AI service delivery.; SageMaker Pipelines, Step Functions, Metaflow: Orchestration pipelines on AWS and other platforms are used to automate and manage AI model training, deployment, and lifecycle operations.; Open-source LLM Serving (TGI/vLLM): Experience with serving open-source LLMs using frameworks like Text Generation Inference (TGI) and vLLM is required to support enterprise AI applications.","['Machine Learning', 'Deep Learning', 'Python', 'scikit-learn', 'TensorFlow', 'PyTorch', 'MLOps', 'Containerization (Docker)', 'CI/CD', 'AWS', 'Databricks', 'Dataiku', 'GitHub', 'Jira', 'Agile Project Methodology', 'Business Intelligence']","Machine Learning: The role involves designing, training, and deploying machine learning models to develop data science products that transform client needs into quantifiable solutions and enhance decision-making.; Deep Learning: The job requires expertise in deep learning to build advanced models, including training and deployment on platforms like AWS, Databricks, and Dataiku, to support business intelligence and data science solutions.; Python: Python is a core programming language used extensively in the role, including working with related packages such as scikit-learn, TensorFlow, and PyTorch for machine learning and deep learning projects.; scikit-learn: Used as a key machine learning package within Python to develop and deploy machine learning models as part of data science solutions.; TensorFlow: Employed as a deep learning framework to design, train, and deploy neural network models in the data science projects.; PyTorch: Utilized as a deep learning framework for building and deploying neural network models within the data science initiatives.; MLOps: The role includes working with MLOps pipelines for training and deploying models, incorporating containerization technologies like Docker and CI/CD practices to ensure efficient model lifecycle management.; Containerization (Docker): Docker is used to containerize machine learning and deep learning models as part of MLOps pipelines to facilitate scalable and reproducible deployment.; CI/CD: Continuous Integration and Continuous Deployment pipelines are implemented to automate the training and deployment of machine learning and deep learning models.; AWS: Amazon Web Services is a key platform for deploying machine learning and deep learning models, including use of various AWS services such as Textract, Transcribe, Lambda, SageMaker Pipelines, and Step Functions.; Databricks: Databricks is used as a platform for designing, training, and deploying machine learning and deep learning models within the data science workflow.; Dataiku: Dataiku is leveraged as a platform to develop and maintain data science and business intelligence solutions, including model deployment.; GitHub: GitHub is used for version control and collaboration, ensuring clean, well-commented code and structured project documentation.; Jira: Jira is utilized for project management and maintaining structured documentation within the data science and AI projects.; Agile Project Methodology: Familiarity with agile methodologies is required to manage project development lifecycles effectively and deliver data science solutions iteratively.; Business Intelligence: The role involves developing and maintaining business intelligence solutions that support decision-making and strategic mission goals."
VPzUecK83U6OIqSGAAAAAA==,Adjunct Professor of Data Science,"Job Number: 202300030

Description

ABOUT RAMAPO COLLEGE:

Ramapo College of New Jersey (RCNJ) develops ethical leaders who serve as change agents across all sectors. The College's unique interdisciplinary academic structure, its liberal arts core, its size (approximately 5,500 students), and its setting in the foothills of the Ramapo Mountains on the New Jersey/New York border provide an optimal environment for individualized, student-centered learning and leadership development. RCNJ's designation as ""New Jersey's Public Liberal Arts College"" by the State legislature is the foundation from which the College's commitment to an accessible and transformative undergraduate and graduate education is realized.

Established in 1969, CondeNast Traveler named Ramapo one of the 50 Most Beautiful College Campuses in America. The barrier-free campus occupies 300 acres and is home to 52 bachelor's degree programs spanning the arts, business, data science, humanities, education, nursing, social work, social sciences, and the sciences. Ramapo College boasts an average student/faculty ratio of 16:1 and an average class size of 21; affording students the opportunity to develop close ties to the College's exceptional faculty. In addition, the College offers graduate programs leading to master's degrees in Accounting, Applied Mathematics, Business Administration, Contemporary Instructional Design, Computer Science, Creative Music Technology, Data Science, Educational Leadership, Nursing, Social Work, and Special Education, as well as a Doctor of Nursing Practice. Every degree program is designed and delivered through the collaborative and interdisciplinary efforts of student-centered faculty scholars and staff who are committed to serving the public good through the delivery of an academically rigorous, inclusive, and a transformative collegiate experience. Ramapo is ranked #1 among New Jersey public institutions by College Choice and is recognized as the State's top college on the list of Best Disability Schools by Great Value Colleges. Further commendations include designation as a ""Military Friendly College"" in Victory Media's Guide to Military Friendly Schools, and as a leading college by U.S. News & World Report, Kiplinger's, Princeton Review, and Money Magazine, among others.

Examples of Duties

JOB SUMMARY:

Ramapo College of New Jersey is searching for an Adjunct Professor of Data Science to teach one or two sections on an as needed basis. Courses may include Graduate Level Statistics and Probability.

Applications are being accepted by logging on to www.ramapojobs.com. Attach resume, cover letter, letter discussing teaching philosophy. All applications must be completed online. Hard copies of resumes and/or applications will not be accepted. To request accommodations, call (201) 684-7506.
Compensation:
Fall 2025/Spring 2026 Semesters- $2,100 per credit

Qualifications

REQUIREMENTS:

Masters's degree with relevant teaching experience required.

Supplemental Information

EEO Statement:

Ramapo College is an Affirmative Action/Equal Employment Opportunity Employer. Ramapo is committed to academic excellence through interdisciplinary and experiential learning and international and intercultural understanding. Ramapo is also committed to fostering a community that inspires a culture of inclusivity. Examples can be found in its mission statement, strategic plans, degree and course offerings and other programs. Ramapo's environment is welcoming, dedicated to social justice, and respectful of freedom of expression.",,2025-07-25,"['Every degree program is designed and delivered through the collaborative and interdisciplinary efforts of student-centered faculty scholars and staff who are committed to serving the public good through the delivery of an academically rigorous, inclusive, and a transformative collegiate experience', 'Courses may include Graduate Level Statistics and Probability', 'Hard copies of resumes and/or applications will not be accepted', ""Masters's degree with relevant teaching experience required""]",['Ramapo College of New Jersey is searching for an Adjunct Professor of Data Science to teach one or two sections on an as needed basis'],False,,,,
AewwRofIWcwySa44AAAAAA==,Data Scientist/Curator,"Data Curator 4 month contract assignment Cambridge, MA (onsite) Required/Most Important Skills:Mass spectrometry based proteomics data R/Python Metadata capture, versioning control and curation POSITION SUMMARY:We are looking for a data scientist/curator who will help annotate proteomics data at the MLCS. The contractor will apply proteomics related knowledge with bioinformatics skills to help curate and register high dimensional proteomics data into internal data registry. The deliverable will facilitate data processing, analysis, machine learning with high reproducibility and scalability, as well as data management and visualization.EDUCATION AND EXPERIENCE:B.S or advanced degree in Bioinformatics, Biology, Molecular Cell Biology, Biochemistry, Analytical Chemistry or related fields.TECHNICAL SKILLS REQUIREMENTS:Familiarity with mass spectrometry based proteomics data type is strongly preferred. Wet-lab experience in Biology, Biochemistry, Molecular Biology, Analytical Chemistry or related field is strongly preferred. Knowledge of relational or graph database is preferred. Experience in scripting languages like R/Python is desirable. Familiarity with workflow languages (Nextflow, CWL, etc) is desirable. Familiarity with shell scripting, cluster or cloud computing infrastructure (AWS, GCP) is desirable.System One, and its subsidiaries including Joulé, ALTA IT Services, and Mountain Ltd., are leaders in delivering outsourced services and workforce solutions across North America. We help clients get work done more efficiently and economically, without compromising quality. System One not only serves as a valued partner for our clients, but we offer eligible employees health and welfare benefits coverage options including medical, dental, vision, spending accounts, life insurance, voluntary plans, as well as participation in a 401(k) plan.System One is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, age, national origin, disability, family care or medical leave status, genetic information, veteran status, marital status, or any other characteristic protected by applicable federal, state, or local law.Ref: #568-Clinical",2025-07-22T00:00:00.000Z,2025-07-25,"['EDUCATION AND EXPERIENCE:B.S or advanced degree in Bioinformatics, Biology, Molecular Cell Biology, Biochemistry, Analytical Chemistry or related fields']","['Data Curator 4 month contract assignment Cambridge, MA (onsite) Required/Most Important Skills:Mass spectrometry based proteomics data R/Python Metadata capture, versioning control and curation POSITION SUMMARY:We are looking for a data scientist/curator who will help annotate proteomics data at the MLCS', 'The contractor will apply proteomics related knowledge with bioinformatics skills to help curate and register high dimensional proteomics data into internal data registry', 'The deliverable will facilitate data processing, analysis, machine learning with high reproducibility and scalability, as well as data management and visualization']",True,[],,"['Mass Spectrometry Proteomics Data', 'R and Python', 'Metadata Capture and Versioning Control', 'Bioinformatics', 'Data Management and Visualization', 'Machine Learning', 'Relational and Graph Databases', 'Workflow Languages (Nextflow, CWL)', 'Shell Scripting and Cloud/Cluster Computing (AWS, GCP)']","Mass Spectrometry Proteomics Data: The job involves annotating and curating high dimensional proteomics data generated from mass spectrometry to support downstream data processing and analysis.; R and Python: Scripting languages R and Python are used for data curation, processing, and analysis of proteomics datasets.; Metadata Capture and Versioning Control: Capturing metadata and maintaining version control are essential for ensuring reproducibility and traceability of proteomics data.; Bioinformatics: Applying bioinformatics knowledge to curate and register proteomics data into internal data registries.; Data Management and Visualization: The role includes managing proteomics data and creating visualizations to facilitate understanding and analysis.; Machine Learning: The curated proteomics data will be used to enable machine learning workflows with high reproducibility and scalability.; Relational and Graph Databases: Knowledge of relational or graph databases is preferred for organizing and registering proteomics data.; Workflow Languages (Nextflow, CWL): Familiarity with workflow languages like Nextflow and CWL is desirable to support scalable and reproducible data processing pipelines.; Shell Scripting and Cloud/Cluster Computing (AWS, GCP): Experience with shell scripting and cloud or cluster computing infrastructure is desirable to facilitate data processing and computational workflows."
FtbFbUPhXlyFkXaXAAAAAA==,Data Scientist,"State Farm is looking for an experienced and talented Data Scientist to join our team. We are searching for an individual who is passionate about working with and analyzing data to uncover trends and develop insights for our business. Our ideal candidate is a self-starter with a keen eye for detail and excellent problem-solving skills.Required Qualifications:• A Bachelor's degree in Computer Science, Statistics, Mathematics, or related field; advanced degree preferred• Proven experience in data analysis and data mining• Proficiency in SQL, Python, and other programming languages• Knowledge of machine learning, predictive analytics, and natural language processing• Ability to work independently and in a team setting• Ability to communicate technical concepts to non-technical audiences• Understanding of data visualization tools and techniques• Ability to work with large, complex datasets• Attention to detail and accuracy• Experience with data warehousing and big data technologies

State Farm is an Equal Opportunity Employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. We do not discriminate based upon race, religion, color, national origin, sex, sexual orientation, gender identity, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.",,2025-07-25,['Our ideal candidate is a self-starter with a keen eye for detail and excellent problem-solving skills'],,True,[],,"['SQL', 'Python', 'Machine Learning', 'Predictive Analytics', 'Natural Language Processing', 'Data Visualization Tools', 'Data Warehousing', 'Big Data Technologies']","SQL: Used for querying and managing large, complex datasets as part of data analysis and data mining tasks.; Python: Utilized as a programming language for data analysis, machine learning, and working with data mining techniques.; Machine Learning: Applied to develop predictive analytics models and uncover trends in data to generate business insights.; Predictive Analytics: Used to build models that forecast outcomes and support decision-making based on data trends.; Natural Language Processing: Employed to analyze and extract insights from text data as part of data science tasks.; Data Visualization Tools: Used to communicate technical concepts and insights effectively to non-technical audiences through visual representations.; Data Warehousing: Involved in managing and organizing large volumes of data to support analysis and mining activities.; Big Data Technologies: Applied to handle and process large, complex datasets efficiently for analysis and insight generation."
iYDM8RABtSBWYFzLAAAAAA==,Data Scientist - Top Secret with CI or FS Poly,"Overview

Paradyme, a CATHEXIS Company is a rapidly growing government technology leader that puts service first, for its customers, its team and the communities it supports. We harness DevSecOps and Agile development processes to deliver exceptional results for digital transformations. With headquarters office in Tysons Corner, VA, Our award-winning culture sets it apart through its team's deep commitment to service and collaboration with its customers, each other and the community. Learn more at www.paradyme.us .
Responsibilities

Paradyme, a CATHEXIS Company is hiring a Top Secret clearance with CI or FS Polygraph Data Scientist to support mission critical programs.

The Data Scientist will work directly with data scientists, software engineers, and subject matter experts in the definition of new analytics capabilities able to provide our federal customers with the information they need to make proper decisions and enable their digital transformation. Duties include:
• Research, design, implement, and deploy Machine Learning algorithms for enterprise applications.
• Assist and enable federal customers to build their own applications.
• Contribute to the design and implementation of new features.

Qualifications:
• Top Secret clearance with CI or FS Poly or above.
• Bachelor's degree in Computer Science, Electrical Engineering, Statistics, or equivalent fields required.
• MS or PhD in Computer Science, Electrical Engineering, Statistics, or equivalent fields preferred.
• Minimum 2 years relevant work experience preferred.
• Excellent programming skills in Python.
• Applied Machine Learning experience (regression and classification, supervised, and unsupervised learning).
• Strong mathematical background (linear algebra, calculus, probability, and statistics).
• Experience with scalable ML (MapReduce, streaming).
• Ability to drive a project and work both independently and in a team.
• Smart, motivated, can-do attitude, and seeks to make a difference.
• Excellent verbal and written communication.

Nice to Have:
• Real passion for developing team-oriented solutions to complex engineering problems.
• Thrive in an autonomous, empowering and exciting environment.
• Great verbal and written communication skills to collaborate multi-functionally and improve scalability.
• Interest in committing to a fun, friendly, expansive, and intellectually stimulating environment.
• Hands-on experience deploying and operating applications using IaaS and PaaS on major cloud providers, such as Amazon AWS, Microsoft Azure, or Google Cloud Services.
• Experience with deep learning, natural language processing, computer vision, or reinforcement learning.
• Conveys highly technical concepts and information in written form to technical and non-technical audiences.
• The ability to work on multiple concurrent projects is essential. Strong self -motivation and the ability to work with minimal supervision.
• Must be a team-oriented individual, energetic, result & delivery oriented, with a keen interest on quality and the ability to meet deadlines.
• Ability to work in an agile environment

Physical Requirements: These are the essential physical requirements needed to successfully perform the job.
• Sedentary work.
• Requires sitting up to 8 hours per day.
• May require lifting up to 5 pounds unassisted.
• Fine repetitive motor skills with hands, wrists, and fingers in coordination with eyes.
• Hearing, speaking, and vision: Adequate to perform job duties and communicate in person, via video, and telephone. Includes reading information from printed sources and computer screens.
• Other: Work may be performed in an office environment, which may involve frequent contact with staff and the public. Work may be stressful at times.

EEO Statement

Paradyme, a CATHEXIS Company is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law. If you are an individual with a disability and would like to request a reasonable accommodation as part of the employment selection process, please contact HR@paradyme.us
Employment Type: OTHER",,2025-07-25,"['Top Secret clearance with CI or FS Poly or above', ""Bachelor's degree in Computer Science, Electrical Engineering, Statistics, or equivalent fields required"", 'Excellent programming skills in Python', 'Applied Machine Learning experience (regression and classification, supervised, and unsupervised learning)', 'Strong mathematical background (linear algebra, calculus, probability, and statistics)', 'Experience with scalable ML (MapReduce, streaming)', 'Ability to drive a project and work both independently and in a team', 'Smart, motivated, can-do attitude, and seeks to make a difference', 'Excellent verbal and written communication', 'Real passion for developing team-oriented solutions to complex engineering problems', 'Thrive in an autonomous, empowering and exciting environment', 'Great verbal and written communication skills to collaborate multi-functionally and improve scalability', 'Interest in committing to a fun, friendly, expansive, and intellectually stimulating environment', 'Hands-on experience deploying and operating applications using IaaS and PaaS on major cloud providers, such as Amazon AWS, Microsoft Azure, or Google Cloud Services', 'Experience with deep learning, natural language processing, computer vision, or reinforcement learning', 'Conveys highly technical concepts and information in written form to technical and non-technical audiences', 'The ability to work on multiple concurrent projects is essential', 'Strong self -motivation and the ability to work with minimal supervision', 'Must be a team-oriented individual, energetic, result & delivery oriented, with a keen interest on quality and the ability to meet deadlines', 'Ability to work in an agile environment', 'Physical Requirements: These are the essential physical requirements needed to successfully perform the job', 'Requires sitting up to 8 hours per day', 'May require lifting up to 5 pounds unassisted', 'Fine repetitive motor skills with hands, wrists, and fingers in coordination with eyes', 'Hearing, speaking, and vision: Adequate to perform job duties and communicate in person, via video, and telephone']","['The Data Scientist will work directly with data scientists, software engineers, and subject matter experts in the definition of new analytics capabilities able to provide our federal customers with the information they need to make proper decisions and enable their digital transformation', 'Research, design, implement, and deploy Machine Learning algorithms for enterprise applications', 'Assist and enable federal customers to build their own applications', 'Contribute to the design and implementation of new features', 'Sedentary work', 'Includes reading information from printed sources and computer screens', 'Other: Work may be performed in an office environment, which may involve frequent contact with staff and the public']",True,"['Deep Learning', 'Natural Language Processing', 'Computer Vision', 'Reinforcement Learning']","Deep Learning: Experience with deep learning techniques is preferred, indicating involvement with neural network-based models for complex data tasks.; Natural Language Processing: Experience with natural language processing is desired, suggesting work with text data and language understanding models.; Computer Vision: Experience with computer vision is preferred, implying work with image or video data using AI techniques.; Reinforcement Learning: Experience with reinforcement learning is noted as a nice-to-have skill, indicating familiarity with AI methods for decision-making and autonomous systems.","['Machine Learning', 'Python', 'Mathematics for Data Science', 'Scalable Machine Learning', 'Cloud Platforms for Deployment']","Machine Learning: Research, design, implement, and deploy machine learning algorithms for enterprise applications, including regression and classification, supervised and unsupervised learning.; Python: Excellent programming skills in Python are required to develop and implement machine learning models and analytics capabilities.; Mathematics for Data Science: Strong mathematical background in linear algebra, calculus, probability, and statistics is essential to support machine learning and data analysis tasks.; Scalable Machine Learning: Experience with scalable machine learning techniques such as MapReduce and streaming to handle large datasets and enterprise-scale applications.; Cloud Platforms for Deployment: Hands-on experience deploying and operating applications using Infrastructure as a Service (IaaS) and Platform as a Service (PaaS) on major cloud providers like Amazon AWS, Microsoft Azure, or Google Cloud Services."
9rv1R7t03lIBqnisAAAAAA==,"Senior Director, Data Science - Debit Routing","Job Description Position Summary: The Senior Director of Data Science – Dynamic Routing will lead the strategy and execution of intelligent transaction routing and pricing optimization. This position will lead a team of ~15 data scientists tasked with developing and operationalizing advanced machine learning and algorithmic solutions that optimize interchange fees, enhance transaction approval rates, and drive margin expansion for the business and its merchants. As the public-facing ""face"" of our transaction routing solutions, the Senior Director will play a crucial role in client engagements, articulating complex data science concepts in an accessible manner to explain trends and actions taken in routing. This leader will collaborate closely with business leaders to tailor strategies on a customer-by-customer basis, ensuring alignment with broader business goals. This leader will work in partnership with Product and Engineering teams to craft the future state vision for transaction routing solutions, ensuring the development of innovative products that meet evolving market demands. This role requires a deep understanding of data science methodologies and the ability to translate technical insights into strategic business actions, fostering strong relationships with clients and internal stakeholders to drive success. Key Responsibilities: Strategic Leadership: Own the data science roadmap for dynamic routing and interchange optimization across U.S. domestic, cross-border payment flows, and extension of dynamic routing globally. Build and deploy ML/AI models that inform routing decisions based on issuer behavior, cost structures, geo/location, network rules and eligibility, and approval likelihood. Develop scalable, low-latency algorithms integrated into real-time payment decisioning engines. Design and validate experiments to quantify the financial impact of routing and interchange strategies (e.g., A/B tests, multi-armed bandits). Model complex cost structures (interchange, scheme fees, FX margins) to recommend optimal routing paths for each transaction. Team & Capability Development: Build, lead, and mentor a multidisciplinary team of ~15 data scientists and data analysts. Mentor junior team members on best practices in modeling, experimentation, and payments domain knowledge. Foster a culture of innovation, experimentation, and continuous learning. Cross-Functional Collaboration: Collaborate with Product and Global Network Partnership teams to align optimization strategies with commercial agreements and market coverage. Work closely with Finance, Product, and Worldpay’s Lines of Business to report on savings, approval uplift, and margin impact. Communicate complex analytical concepts to non-technical stakeholders effectively. Key Areas of Focus: Ensure models meet requirements for scalability, latency, explainability, and regulatory compliance. Work with data governance and legal teams to ensure compliance with data privacy regulations (e.g., PCI-DSS, GDPR). Optimize transaction paths across processors, networks (Visa, Mastercard, Regional Networks), and endpoints to maximize approval rates and minimize costs. Use data-driven insights to steer transactions toward more favorable interchange categories or fee structures. Model historical issuer behavior (approval decline patterns, time-of-day trends, geo-specific sensitivity). Monitor and optimize for performance, latency, and reliability across network routes. Performance Measurement: Define and track KPIs to measure the business and client impact of dynamic routing Provide regular updates to executive leadership on progress, risks, and opportunities. Qualifications: Deep experience in payments, fintech, or financial transaction optimization required. Deep understanding of global regulatory frameworks that impact transaction routing (e.g. U.S. Durbin Amendment) Excellent understanding of global interchange systems, scheme fee structures, and cross-border routing economics. Strong applied knowledge of ML/AI, optimization, and decision science techniques. Proficiency in Python, SQL, and Spark Advanced degree (PhD or Master’s) in Computer Science, Statistics, Mathematics, Engineering, or related field. 10 years of experience in data science or analytics, with at least 5 years in a leadership role. Preferred Qualifications: Experience in a merchant acquiring, PSP, or card network environment. Familiarity with tokenization, real-time payments (RTP), and authorization lifecycle. Understanding of card present vs. card-not-present dynamics, tokenization, and authorization lifecycle. Experience working within SAFe Agile product development environments. Worldpay is committed to providing its employees with an exciting career opportunity and competitive compensation. The pay range for this full-time position is $177,100.00 - $297,500.00 and reflects the minimum and maximum target for new hire salaries for this position based on the posted role, level, and location. Within the range, actual individual starting pay is determined by additional factors, including job-related skills, experience, and relevant education or training. Any changes in work location will also impact actual individual starting pay. Please consult with your recruiter about the specific salary range for your preferred location during the hiring process. The job duties outlined above may be directly, and negatively impacted by a criminal history, which could lead to the withdrawal of a conditional offer. However, all qualified candidates with arrests or convictions will still be considered. Privacy Statement Worldpay is committed to protecting the privacy and security of all personal information that we process in order to provide services to our clients. For specific information on how Worldpay protects personal information online, please see the Online Privacy Notice. EEOC Statement Worldpay is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, marital status, genetic information, national origin, disability, veteran status, and other protected characteristics. The EEO is the Law poster is available here. If you are made a conditional offer of employment and will be working in the United States, you will be required to undergo a drug test. In developing this job description care was taken to include all competencies and requirements needed to successfully perform the position. Reasonable accommodations will be provided for individuals with qualified disabilities both during the hiring process, as well as to allow the individual to perform the essential functions of the job, if hired. Sourcing Model Recruitment at Worldpay works primarily on a direct sourcing model; a relatively small portion of our hiring is through recruitment agencies. Worldpay does not accept resumes from recruitment agencies which are not on the preferred supplier list and is not responsible for any related fees for resumes submitted to job postings, our employees, or any other part of our company.",2025-06-29T00:00:00.000Z,2025-07-25,"['Qualifications: Deep experience in payments, fintech, or financial transaction optimization required', 'Deep understanding of global regulatory frameworks that impact transaction routing (e.g', 'U.S. Durbin Amendment) Excellent understanding of global interchange systems, scheme fee structures, and cross-border routing economics', 'Strong applied knowledge of ML/AI, optimization, and decision science techniques', 'Proficiency in Python, SQL, and Spark Advanced degree (PhD or Master’s) in Computer Science, Statistics, Mathematics, Engineering, or related field', '10 years of experience in data science or analytics, with at least 5 years in a leadership role', 'Familiarity with tokenization, real-time payments (RTP), and authorization lifecycle', 'Understanding of card present vs. card-not-present dynamics, tokenization, and authorization lifecycle', 'Experience working within SAFe Agile product development environments']","['Job Description Position Summary: The Senior Director of Data Science – Dynamic Routing will lead the strategy and execution of intelligent transaction routing and pricing optimization', 'This position will lead a team of ~15 data scientists tasked with developing and operationalizing advanced machine learning and algorithmic solutions that optimize interchange fees, enhance transaction approval rates, and drive margin expansion for the business and its merchants', 'As the public-facing ""face"" of our transaction routing solutions, the Senior Director will play a crucial role in client engagements, articulating complex data science concepts in an accessible manner to explain trends and actions taken in routing', 'This leader will collaborate closely with business leaders to tailor strategies on a customer-by-customer basis, ensuring alignment with broader business goals', 'This leader will work in partnership with Product and Engineering teams to craft the future state vision for transaction routing solutions, ensuring the development of innovative products that meet evolving market demands', 'This role requires a deep understanding of data science methodologies and the ability to translate technical insights into strategic business actions, fostering strong relationships with clients and internal stakeholders to drive success', 'Key Responsibilities: Strategic Leadership: Own the data science roadmap for dynamic routing and interchange optimization across U.S. domestic, cross-border payment flows, and extension of dynamic routing globally', 'Build and deploy ML/AI models that inform routing decisions based on issuer behavior, cost structures, geo/location, network rules and eligibility, and approval likelihood', 'Develop scalable, low-latency algorithms integrated into real-time payment decisioning engines', 'Design and validate experiments to quantify the financial impact of routing and interchange strategies (e.g., A/B tests, multi-armed bandits)', 'Model complex cost structures (interchange, scheme fees, FX margins) to recommend optimal routing paths for each transaction', 'Team & Capability Development: Build, lead, and mentor a multidisciplinary team of ~15 data scientists and data analysts', 'Mentor junior team members on best practices in modeling, experimentation, and payments domain knowledge', 'Foster a culture of innovation, experimentation, and continuous learning', 'Cross-Functional Collaboration: Collaborate with Product and Global Network Partnership teams to align optimization strategies with commercial agreements and market coverage', 'Work closely with Finance, Product, and Worldpay’s Lines of Business to report on savings, approval uplift, and margin impact', 'Communicate complex analytical concepts to non-technical stakeholders effectively', 'Key Areas of Focus: Ensure models meet requirements for scalability, latency, explainability, and regulatory compliance', 'Work with data governance and legal teams to ensure compliance with data privacy regulations (e.g., PCI-DSS, GDPR)', 'Optimize transaction paths across processors, networks (Visa, Mastercard, Regional Networks), and endpoints to maximize approval rates and minimize costs', 'Use data-driven insights to steer transactions toward more favorable interchange categories or fee structures', 'Model historical issuer behavior (approval decline patterns, time-of-day trends, geo-specific sensitivity)', 'Monitor and optimize for performance, latency, and reliability across network routes', 'Performance Measurement: Define and track KPIs to measure the business and client impact of dynamic routing Provide regular updates to executive leadership on progress, risks, and opportunities']",True,[],,"['Machine Learning Models', 'Optimization Algorithms', 'A/B Testing and Multi-Armed Bandits', 'Cost Structure Modeling', 'Data Science Methodologies', 'Data Pipelines and Real-Time Decisioning', 'SQL, Python, and Spark', 'Experimentation and Performance Measurement', 'Data Governance and Regulatory Compliance', 'Feature Engineering and Behavioral Modeling', 'Team Leadership in Data Science and Analytics']","Machine Learning Models: Build and deploy machine learning models that inform routing decisions based on issuer behavior, cost structures, geo/location, network rules and eligibility, and approval likelihood.; Optimization Algorithms: Develop scalable, low-latency algorithms integrated into real-time payment decisioning engines to optimize interchange fees, transaction approval rates, and margin expansion.; A/B Testing and Multi-Armed Bandits: Design and validate experiments such as A/B tests and multi-armed bandits to quantify the financial impact of routing and interchange strategies.; Cost Structure Modeling: Model complex cost structures including interchange fees, scheme fees, and foreign exchange margins to recommend optimal routing paths for each transaction.; Data Science Methodologies: Apply advanced data science methodologies to translate technical insights into strategic business actions and foster strong relationships with clients and stakeholders.; Data Pipelines and Real-Time Decisioning: Develop and operationalize data pipelines and real-time payment decisioning engines to enable dynamic routing and pricing optimization.; SQL, Python, and Spark: Utilize programming languages and frameworks such as Python, SQL, and Spark for data processing, analysis, and model development.; Experimentation and Performance Measurement: Define and track key performance indicators (KPIs) to measure the business and client impact of dynamic routing and provide regular updates to executive leadership.; Data Governance and Regulatory Compliance: Ensure models and data practices comply with data privacy regulations such as PCI-DSS and GDPR, working closely with data governance and legal teams.; Feature Engineering and Behavioral Modeling: Model historical issuer behavior including approval decline patterns, time-of-day trends, and geo-specific sensitivity to improve routing decisions.; Team Leadership in Data Science and Analytics: Build, lead, and mentor a multidisciplinary team of data scientists and analysts, promoting best practices in modeling, experimentation, and domain knowledge."
6fGpmHTcSlpADv6KAAAAAA==,"Senior Manager, Data Scientist - Parsippany, NJ (Hybrid)","Apply now »

Senior Manager, Data Scientist - Parsippany, NJ (Hybrid)

Date: Jul 15, 2025

Location:
Parsippany, United States, New Jersey, 07054

Company: Teva Pharmaceuticals

Job Id: 62440

Who we are

Together, we’re on a mission to make good health more affordable and accessible, to help millions around the world enjoy healthier lives. It’s a mission that bonds our people across nearly 60 countries and a rich, diverse variety of nationalities and backgrounds. Working here means working with the world’s leading manufacturer of generic medicines, and the proud producer of many of the products on the World Health Organization’s Essential Medicines List. Today, at least 200 million people around the world take one of our medicines every single day. An amazing number, but we’re always looking for new ways to continue making a difference, and new people to make a difference with.

The opportunity

Directly supporting the Teva’s Data Science & Analytics and Patient Services teams, the Sr Manager, Data Scientist will be responsible for creating actionable insights from data to enhance best patient experiences; for identifying and analyzing data to measure patient journeys; for building machine learning / AI models to customize patient services.

This candidate will collaborate closely with Teva’s Patient Services team in Innovative Medicines to support our world-class vision. The candidate will engage with Patient Service team to explore innovative partners, identify data needs and requirements, and evaluate partner data. The candidate will leverage data science and advanced analytics, visualization and automation to provide data-driven insights, communicate meaningful findings, and drive business results.

Location: This is a hybrid role (3 days/week in office) based in our Parsippany, NJ office.

How you’ll spend your day

All areas of responsibility listed below are essential to the satisfactory performance of this position by any incumbents with reasonable accommodation if necessary. Any non-essential functions are assumed to be included in other related duties or assignments.

The ideal candidate will closely work with the unit Leader and business partner to drive solutions that enable data-driven decision making.
• Drive business value through data science and advanced analytics
• Conduct exploratory data analysis to understand the strengths and limitations of complex data sets and identify the appropriate analytical approach
• Design and manage complex analytical projects, breaking down complex business problems into multiple independent and sequential phases of analysis
• Derive insights from data and present results to internal clients and senior management
• Engineer and prepare data from disparate systems
• Integrate and prepare large, varied datasets, design appropriate data science models and algorithms, and professionally communicate results
• Implement ML models in production and track performance
• Summarize key metrics for dashboard

Your experience and qualifications

Any equivalent combination of education, training and/or experience that fulfills the requirements of the position will be considered.

Education/Certification/Experience:
• Master’s Degree with at least 2 years of experience within a highly technical/quantitative discipline (Statistics, Computer Science, Data Science, Mathematics); PhD preferred.
• Minimum 4 years of hands-on experience in generating advanced insights and predictive capability from statistical models, including (but not limited to) multivariate linear regression, cluster algorithms, decision trees, logistic regression, Principal Component Analysis (PCA), time series, survival analysis, machine learning (supervised and unsupervised), Bayesian Methods, Neural Networks, LLM etc.
• Minimum 4 years of experience in performing data analysis and modeling using Python (NumPy, pandas, Scikit-learn, TensorFlow etc).

Skills/Knowledge/Abilities:
• Strong SQL skills for data manipulation, aggregation, and optimization. Proficiency in bringing structure to ambiguous problems and deriving insights from multiple data and information sources.
• Ability to communicate complex ideas, insights, and analytical proficiency into meaningful conclusions to internal and external stakeholders.
• Strong data curiosity, analytical skills and problem-solving abilities.
• Excellent written and verbal communication skills ability to work effectively with both technical and non-technical stakeholders.
• Understanding of the brand and generic pharmaceutical landscape and the commercial data and analytic needs.
• Strong inter-personal skills and team player.
• Ability to quickly adapt to changing priorities and generate innovative solutions in a fast-paced environment.

PHYSICAL REQUIREMENTS:

Occasional:

Sitting for extended periods of time at work station or mobile equipment.

Visual Acuity:

Perform activities such as computer work, preparing and analyzing data, and extensive reading.

Compensation Data

The annual starting salary for this position is between $138,880 - $160,000 annually. Factors which may affect starting salary within this range and level of role may include geography/market, skills, education, experience and other qualifications of the successful candidate.

Enjoy a more rewarding choice

We offer a competitive benefits package, including:
• Comprehensive Health Insurance: Medical, Dental, Vision, and Prescription coverage starting on the first day of employment, providing the employee enrolls.
• Retirement Savings: 401(k) with employer match, up to 6% and an annual 3.75% Defined Contribution to the 401k plan.
• Time Off: Paid Time Off including vacation, sick/safe time, caretaker time, 13 paid Holidays and 3 paid floating holidays.
• Life and Disability Protection: Company paid Life and Disability insurance.
• Additional benefits include, but not limited to, Employee Assistance Program, Employee Stock Purchase Plan, Tuition Assistance, Flexible Spending Accounts, Health Savings Account, Life Style Spending Account, Volunteer Time Off, Paid Parental Leave, if eligible , Family Building Benefits, Virtual Physical Therapy, Accident, Critical Illness and Hospital Indemnity Insurances, Identity Theft Protection, Legal Plan, Voluntary Life Insurance and Long Term Disability and more.

Already Working @TEVA?

If you are a current Teva employee, please apply using the internal career site available on ""Employee Central"". By doing so, your application will be treated with priority. You will also be able to see opportunities that are open exclusively to Teva employees. Use the following link to search and apply: Internal Career Site

The internal career site is available from your home network as well. If you have trouble accessing your EC account, please contact your local HR/IT partner.

Teva’s Equal Employment Opportunity Commitment

Teva Pharmaceuticals is committed to equal opportunity in employment. It is Teva's policy that equal employment opportunity be provided without regard to age, race, creed, color, religion, sex, disability, pregnancy, medical condition, genetic information, marital status, sexual orientation, gender identity or expression, ancestry, national or ethnic origin, citizenship status, military status or status as a disabled or protected veteran, or any legally recognized status entitled to protection under applicable federal, state, or local laws.

Please advise us of any accommodations needed to support you throughout the recruitment and selection process. All accommodation information provided will be treated as confidential and used only for the purpose of providing an accessible candidate experience. Request a reasonable accommodation by sending an email to disabilityassistance@tevapharm.com with the nature of your request and your contact information. Only inquiries concerning a request for a reasonable accommodation will be responded to from this email address.

Important notice to Employment Agencies - Please Read Carefully

Teva Pharmaceuticals USA does not accept unsolicited assistance from agencies for employment opportunities. All CVs / resumes submitted by search firms to any employee at our company without a valid written search agreement in place for this position will be deemed the sole property of our company. No fee will be paid in the event a candidate is hired by our company as a result of an agency referral where no pre-existing agreement is in place. Where agency agreements are in place, introductions are position specific. Please, no phone calls or emails.

Apply now »",2025-07-15T00:00:00.000Z,2025-07-25,"['Any equivalent combination of education, training and/or experience that fulfills the requirements of the position will be considered', 'Minimum 4 years of hands-on experience in generating advanced insights and predictive capability from statistical models, including (but not limited to) multivariate linear regression, cluster algorithms, decision trees, logistic regression, Principal Component Analysis (PCA), time series, survival analysis, machine learning (supervised and unsupervised), Bayesian Methods, Neural Networks, LLM etc', 'Minimum 4 years of experience in performing data analysis and modeling using Python (NumPy, pandas, Scikit-learn, TensorFlow etc)', 'Strong SQL skills for data manipulation, aggregation, and optimization', 'Proficiency in bringing structure to ambiguous problems and deriving insights from multiple data and information sources', 'Ability to communicate complex ideas, insights, and analytical proficiency into meaningful conclusions to internal and external stakeholders', 'Strong data curiosity, analytical skills and problem-solving abilities', 'Excellent written and verbal communication skills ability to work effectively with both technical and non-technical stakeholders', 'Understanding of the brand and generic pharmaceutical landscape and the commercial data and analytic needs', 'Strong inter-personal skills and team player', 'Ability to quickly adapt to changing priorities and generate innovative solutions in a fast-paced environment']","['Directly supporting the Teva’s Data Science & Analytics and Patient Services teams, the Sr Manager, Data Scientist will be responsible for creating actionable insights from data to enhance best patient experiences; for identifying and analyzing data to measure patient journeys; for building machine learning / AI models to customize patient services', 'This candidate will collaborate closely with Teva’s Patient Services team in Innovative Medicines to support our world-class vision', 'The candidate will engage with Patient Service team to explore innovative partners, identify data needs and requirements, and evaluate partner data', 'The candidate will leverage data science and advanced analytics, visualization and automation to provide data-driven insights, communicate meaningful findings, and drive business results', 'All areas of responsibility listed below are essential to the satisfactory performance of this position by any incumbents with reasonable accommodation if necessary', 'Any non-essential functions are assumed to be included in other related duties or assignments', 'The ideal candidate will closely work with the unit Leader and business partner to drive solutions that enable data-driven decision making', 'Drive business value through data science and advanced analytics', 'Conduct exploratory data analysis to understand the strengths and limitations of complex data sets and identify the appropriate analytical approach', 'Design and manage complex analytical projects, breaking down complex business problems into multiple independent and sequential phases of analysis', 'Derive insights from data and present results to internal clients and senior management', 'Engineer and prepare data from disparate systems', 'Integrate and prepare large, varied datasets, design appropriate data science models and algorithms, and professionally communicate results', 'Implement ML models in production and track performance', 'Summarize key metrics for dashboard', 'Sitting for extended periods of time at work station or mobile equipment', 'Perform activities such as computer work, preparing and analyzing data, and extensive reading']",True,"['Large Language Models (LLMs)', 'TensorFlow (Neural Network Application)']","Large Language Models (LLMs): Referenced as part of the candidate's experience in building machine learning/AI models to customize patient services, indicating involvement with modern AI techniques beyond traditional machine learning.; TensorFlow (Neural Network Application): Used specifically for implementing neural network models, indicating application of deep learning frameworks in AI model development.","['Multivariate Linear Regression', 'Cluster Algorithms', 'Decision Trees', 'Logistic Regression', 'Principal Component Analysis (PCA)', 'Time Series Analysis', 'Survival Analysis', 'Machine Learning (Supervised and Unsupervised)', 'Bayesian Methods', 'Neural Networks', 'Python (NumPy, pandas, Scikit-learn, TensorFlow)', 'SQL', 'Exploratory Data Analysis', 'Data Integration and Preparation', 'Data Visualization and Automation', 'Dashboard Metrics Summarization']","Multivariate Linear Regression: Used as a statistical model to generate advanced insights and predictive capabilities from data.; Cluster Algorithms: Applied to analyze and segment data for deriving meaningful patient journey insights.; Decision Trees: Employed as part of statistical modeling techniques to support predictive analytics and data-driven decision making.; Logistic Regression: Utilized for predictive modeling to understand and forecast patient-related outcomes.; Principal Component Analysis (PCA): Used for dimensionality reduction and feature extraction to handle complex datasets effectively.; Time Series Analysis: Applied to analyze temporal data patterns relevant to patient journeys and other time-dependent metrics.; Survival Analysis: Used to model and analyze time-to-event data, likely related to patient outcomes or treatment durations.; Machine Learning (Supervised and Unsupervised): Implemented to build predictive models and uncover patterns in patient and business data to customize patient services and drive business value.; Bayesian Methods: Used as a statistical approach to enhance predictive modeling and data analysis.; Neural Networks: Applied as part of advanced modeling techniques to improve predictive capabilities and insights from complex data.; Python (NumPy, pandas, Scikit-learn, TensorFlow): Used extensively for data analysis, modeling, and implementing machine learning models in production environments.; SQL: Utilized for data manipulation, aggregation, and optimization to prepare and engineer data from disparate systems.; Exploratory Data Analysis: Conducted to understand the strengths and limitations of complex datasets and to identify appropriate analytical approaches.; Data Integration and Preparation: Involves combining large, varied datasets and preparing them for modeling and analysis.; Data Visualization and Automation: Leveraged to communicate data-driven insights effectively and to streamline analytical workflows.; Dashboard Metrics Summarization: Summarizing key metrics for dashboards to present actionable insights to internal clients and senior management."
jlx4B7G84QjAVJjjAAAAAA==,Machine Learning Specialist (flex – hybrid),"Skip to content
• Returning Applicants
• Employee Resources
• Employee Onboarding

MENU

Machine Learning Specialist (flex – hybrid)

Work Location Los Angeles,CA Job #25844 Work Hours Monday-Friday, 8:00 AM – 5:00 PM PST Employment Type 2 – Staff- Career

Duration Indefinite Salary Range $83800-179400 Annually Posted Date July 22, 2025 Bargaining Unit 99

Apply Now

Apply as Internal/Current Employee

Back to Search Results

Refer A Friend

Provide the tools necessary to deliver cutting-edge health care and groundbreaking research. As part of our Information Technology team, you’ll ensure that our medical professionals have access to the latest breakthroughs in technology, and you’ll play a key role in protecting our global patient community.
• JOB DUTIES
• JOB QUALIFICATIONS

Description UCLA Health is seeking an innovative Machine Learning Specialist to help shape the future of healthcare through artificial intelligence. This role drives the development and validation of AI/ML models that empower data-driven decision-making across clinical, financial, and operational domains.

What You’ll Do
• Design, test, and validate AI/ML models using structured and unstructured healthcare data
• Contribute to MLOps process improvements and the adoption of robust governance policies
• Develop standards, documentation, and training materials to support enterprise-wide AI/ML efforts
• Collaborate with cross-functional teams to solve complex organizational challenges
• Translate domain knowledge into scalable technical solutions that support UCLA Health’s mission

What You Bring
• Expertise in machine learning, software engineering, and data science
• Understanding of healthcare workflows across clinical, financial, and operational domains
• Ability to communicate complex technical concepts clearly to diverse audiences
• Passion for advancing healthcare through innovation and collaboration

This flexible hybrid role allows for a blend of remote and on-site work, requiring presence on-site at least 10%, within 48 hours of being asked to come in, and as needed based on operational requirements. Please note, travel to the “home office” location is not reimbursed. Each employee will complete a FlexWork Agreement with their manager to outline expectations and ensure mutual understanding. These arrangements are periodically reviewed and may be adjusted or terminated as necessary.

Salary offers are based on a variety of factors including qualifications, experience, and internal equity. The full salary range for this position is $83,800 – $179,400 annually. The University anticipates offering a salary between the minimum and midpoint of this range.

JERRY

Your career path at UCLA Health will enable you to follow a myriad of avenues and turns. It opens up a wide variety of opportunities.

ORLANDO

There’s a togetherness and higher level of commitment to teamwork at UCLA Health. We are several groups and teams that work together with a common goal which is to improve our patients experience.

DAVID

UCLA Health walks the walk and talks the talk! It's an incredible feeling to work for an organization that always puts the patient first. I am honored to work in full alignment with the UCLA Health Mission and Vision.

GET INSPIRED by our latest happenings

Awards & recognition
• ©2025 UC Regents
• UCLA Health
• Disability Accommodation Resources
• Privacy Practices
• Recruitment Fraud Alert
• Sitemap
• Terms of Use
• EE Employer

Go to Top",2025-07-22T00:00:00.000Z,2025-07-25,"['Expertise in machine learning, software engineering, and data science', 'Understanding of healthcare workflows across clinical, financial, and operational domains', 'Ability to communicate complex technical concepts clearly to diverse audiences', 'Passion for advancing healthcare through innovation and collaboration']","['Provide the tools necessary to deliver cutting-edge health care and groundbreaking research', 'As part of our Information Technology team, you’ll ensure that our medical professionals have access to the latest breakthroughs in technology, and you’ll play a key role in protecting our global patient community', 'This role drives the development and validation of AI/ML models that empower data-driven decision-making across clinical, financial, and operational domains', 'Design, test, and validate AI/ML models using structured and unstructured healthcare data', 'Contribute to MLOps process improvements and the adoption of robust governance policies', 'Develop standards, documentation, and training materials to support enterprise-wide AI/ML efforts', 'Collaborate with cross-functional teams to solve complex organizational challenges', 'Translate domain knowledge into scalable technical solutions that support UCLA Health’s mission', 'This flexible hybrid role allows for a blend of remote and on-site work, requiring presence on-site at least 10%, within 48 hours of being asked to come in, and as needed based on operational requirements', 'Each employee will complete a FlexWork Agreement with their manager to outline expectations and ensure mutual understanding', 'These arrangements are periodically reviewed and may be adjusted or terminated as necessary']",True,['Artificial Intelligence'],Artificial Intelligence: The role focuses on developing and validating AI models that empower data-driven decision-making and advance healthcare innovation.,"['Machine Learning', 'MLOps', 'Data Science', 'Structured and Unstructured Healthcare Data']","Machine Learning: This role involves designing, testing, and validating machine learning models to support data-driven decision-making across clinical, financial, and operational healthcare domains.; MLOps: The position contributes to process improvements and the adoption of governance policies related to machine learning operations to support enterprise-wide AI/ML efforts.; Data Science: Expertise in data science is required to develop and validate AI/ML models and translate domain knowledge into scalable technical solutions for healthcare.; Structured and Unstructured Healthcare Data: The job requires working with both structured and unstructured healthcare data to develop AI/ML models that improve clinical, financial, and operational outcomes."
GLzGWz9HNOjBml78AAAAAA==,"Data Scientist, Product - Full-time","**Summary:**

Meta Platforms, Inc. (Meta), formerly known as Facebook Inc., builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps and services like Messenger, Instagram, and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. To apply, click “Apply to Job” online on this web page.
• *Required Skills:**

Data Scientist, Product Responsibilities:

1. Collect, organize, interpret, and summarize statistical data in order to contribute to the design and development of Meta products.

2. Apply your expertise in quantitative analysis, data mining, and the presentation of data to see beyond the numbers and understand how our users interact with both our consumer and business products.

3. Partner with Product and Engineering teams to solve problems and identify trends and opportunities.

4. Inform, influence, support, and execute our product decisions and product launches.

5. May be assigned projects in various areas including, but not limited to, product operations, exploratory analysis, product influence, and data infrastructure.

6. Work on problems of diverse scope where analysis of data requires evaluation of identifiable factors.

7. Demonstrate good judgment in selecting methods and techniques for obtaining solutions.

8. Telecommute from anywhere in the US permitted.
• *Minimum Qualifications:**

Minimum Qualifications:

9. Requires a PhD degree(or foreign equivalent degree) in Computer Science, Engineering, Information Systems, Analytics, Mathematics, Physics, Applied Sciences, or a related field. Requires completion of a university-level course, research project, internship, or thesis in the following:

10. 1. Machine learning techniques

11. 2. Working with large data sets and network-based data (TCP or HTTP)

12. 3. ETL (Extract, Transform, Load) processes

13. 4. Relational database (SQL or PL*SQL)

14. 5. Developing in scripting language: PHP, Python, or Perl

15. 6. Statistical analysis using R, MATLAB, Mathematica, ROOT, SPSS, SAS, or Stata

16. 7. Large scale data processing infrastructures using distributed systems (Hadoop, Hive, MapReduce, LCG, or MPI)

17. 8. Quantitative analysis techniques: clustering, regression, patterns recognition, or descriptive and inferential statistics

18. 9. Communicating and presenting results of data analyses.
• *Public Compensation:**

$216,571/year to $235,400/year + bonus + equity + benefits
• *Industry:** Internet
• *Equal Opportunity:**

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.
• *Summary:**

Meta Platforms, Inc. (Meta), formerly known as Facebook Inc., builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps and services like Messenger, Instagram, and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. To apply, click “Apply to Job” online on this web page.
• *Required Skills:**

Data Scientist, Product Responsibilities:

1. Collect, organize, interpret, and summarize statistical data in order to contribute to the design and development of Meta products.

2. Apply your expertise in quantitative analysis, data mining, and the presentation of data to see beyond the numbers and understand how our users interact with both our consumer and business products.

3. Partner with Product and Engineering teams to solve problems and identify trends and opportunities.

4. Inform, influence, support, and execute our product decisions and product launches.

5. May be assigned projects in various areas including, but not limited to, product operations, exploratory analysis, product influence, and data infrastructure.

6. Work on problems of diverse scope where analysis of data requires evaluation of identifiable factors.

7. Demonstrate good judgment in selecting methods and techniques for obtaining solutions.

8. Telecommute from anywhere in the US permitted.
• *Minimum Qualifications:**

Minimum Qualifications:

9. Requires a PhD degree(or foreign equivalent degree) in Computer Science, Engineering, Information Systems, Analytics, Mathematics, Physics, Applied Sciences, or a related field. Requires completion of a university-level course, research project, internship, or thesis in the following:

10. 1. Machine learning techniques

11. 2. Working with large data sets and network-based data (TCP or HTTP)

12. 3. ETL (Extract, Transform, Load) processes

13. 4. Relational database (SQL or PL*SQL)

14. 5. Developing in scripting language: PHP, Python, or Perl

15. 6. Statistical analysis using R, MATLAB, Mathematica, ROOT, SPSS, SAS, or Stata

16. 7. Large scale data processing infrastructures using distributed systems (Hadoop, Hive, MapReduce, LCG, or MPI)

17. 8. Quantitative analysis techniques: clustering, regression, patterns recognition, or descriptive and inferential statistics

18. 9. Communicating and presenting results of data analyses.
• *Public Compensation:**

$216,571/year to $235,400/year + bonus + equity + benefits
• *Industry:** Internet
• *Equal Opportunity:**

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.",2025-07-25T14:00:00.000Z,2025-07-25,"['Requires a PhD degree(or foreign equivalent degree) in Computer Science, Engineering, Information Systems, Analytics, Mathematics, Physics, Applied Sciences, or a related field', 'Requires completion of a university-level course, research project, internship, or thesis in the following:', 'Relational database (SQL or PL*SQL)', 'Developing in scripting language: PHP, Python, or Perl', 'Statistical analysis using R, MATLAB, Mathematica, ROOT, SPSS, SAS, or Stata', 'Large scale data processing infrastructures using distributed systems (Hadoop, Hive, MapReduce, LCG, or MPI)', 'Meta participates in the E-Verify program in certain locations, as required by law', 'Demonstrate good judgment in selecting methods and techniques for obtaining solutions', 'Telecommute from anywhere in the US permitted', 'Requires a PhD degree(or foreign equivalent degree) in Computer Science, Engineering, Information Systems, Analytics, Mathematics, Physics, Applied Sciences, or a related field', 'Requires completion of a university-level course, research project, internship, or thesis in the following:', 'Machine learning techniques', 'ETL (Extract, Transform, Load) processes', 'Relational database (SQL or PL*SQL)', 'Developing in scripting language: PHP, Python, or Perl', 'Statistical analysis using R, MATLAB, Mathematica, ROOT, SPSS, SAS, or Stata', 'Large scale data processing infrastructures using distributed systems (Hadoop, Hive, MapReduce, LCG, or MPI)', 'Meta participates in the E-Verify program in certain locations, as required by law']","['Collect, organize, interpret, and summarize statistical data in order to contribute to the design and development of Meta products', 'Apply your expertise in quantitative analysis, data mining, and the presentation of data to see beyond the numbers and understand how our users interact with both our consumer and business products', 'Partner with Product and Engineering teams to solve problems and identify trends and opportunities', 'Inform, influence, support, and execute our product decisions and product launches', 'May be assigned projects in various areas including, but not limited to, product operations, exploratory analysis, product influence, and data infrastructure', 'Work on problems of diverse scope where analysis of data requires evaluation of identifiable factors', 'Demonstrate good judgment in selecting methods and techniques for obtaining solutions', 'Telecommute from anywhere in the US permitted', 'Machine learning techniques', 'Working with large data sets and network-based data (TCP or HTTP)', 'ETL (Extract, Transform, Load) processes', 'Quantitative analysis techniques: clustering, regression, patterns recognition, or descriptive and inferential statistics', 'Communicating and presenting results of data analyses', '*Public Compensation:*', 'Collect, organize, interpret, and summarize statistical data in order to contribute to the design and development of Meta products', 'Apply your expertise in quantitative analysis, data mining, and the presentation of data to see beyond the numbers and understand how our users interact with both our consumer and business products', 'Partner with Product and Engineering teams to solve problems and identify trends and opportunities', 'Inform, influence, support, and execute our product decisions and product launches', 'May be assigned projects in various areas including, but not limited to, product operations, exploratory analysis, product influence, and data infrastructure', 'Work on problems of diverse scope where analysis of data requires evaluation of identifiable factors', 'Working with large data sets and network-based data (TCP or HTTP)', 'Quantitative analysis techniques: clustering, regression, patterns recognition, or descriptive and inferential statistics', 'Communicating and presenting results of data analyses']",True,[],,"['Machine Learning', 'Large Data Sets', 'ETL Processes', 'Relational Databases', 'Scripting Languages', 'Statistical Analysis Tools', 'Distributed Data Processing', 'Quantitative Analysis Techniques', 'Data Mining and Presentation', 'Exploratory Data Analysis']","Machine Learning: The job requires expertise in machine learning techniques to analyze data and contribute to product development.; Large Data Sets: The role involves working with large data sets and network-based data such as TCP or HTTP to extract insights.; ETL Processes: The position requires experience with Extract, Transform, Load (ETL) processes to manage and prepare data for analysis.; Relational Databases: Proficiency in relational databases using SQL or PL/SQL is necessary for querying and managing structured data.; Scripting Languages: Developing in scripting languages like PHP, Python, or Perl is required for data manipulation and automation tasks.; Statistical Analysis Tools: The job involves using statistical analysis software such as R, MATLAB, Mathematica, ROOT, SPSS, SAS, or Stata to perform quantitative analysis.; Distributed Data Processing: Experience with large scale data processing infrastructures using distributed systems like Hadoop, Hive, MapReduce, LCG, or MPI is needed to handle big data workloads.; Quantitative Analysis Techniques: The role requires applying quantitative analysis methods including clustering, regression, pattern recognition, and descriptive and inferential statistics to interpret data.; Data Mining and Presentation: The position involves data mining and presenting data insights to understand user interactions and support product decisions.; Exploratory Data Analysis: The job may include exploratory analysis to identify trends, opportunities, and factors influencing product performance."
3tuYGjYGj111rYs3AAAAAA==,Solution Data Scientist (Fraud & AML),"About Us

DataVisor is the world’s leading AI-powered Fraud and Risk Platform that delivers the best overall detection coverage in the industry. With an open SaaS platform that supports easy consolidation and enrichment of any data, DataVisor's fraud and anti-money laundering (AML) solutions scale infinitely and enable organizations to act on fast-evolving fraud and money laundering activities in real time. Its patented unsupervised machine learning technology, advanced device intelligence, powerful decision engine, and investigation tools work together to provide significant performance lift from day one. DataVisor's platform is architected to support multiple use cases across different business units flexibly, dramatically lowering total cost of ownership, compared to legacy point solutions. DataVisor is recognized as an industry leader and has been adopted by many Fortune 500 companies across the globe.

Our award-winning software platform is powered by a team of world-class experts in big data, machine learning, security, and scalable infrastructure. Our culture is open, positive, collaborative, and results-driven. Come join us!

Position Overview

The Solution Data Scientist (Fraud & AML) will be part of our Professional Service team, reporting to our Chief Solution Architect and VP Professional Services. You will lead various types of technical projects e.g. fraud attack pattern study, risk strategy development, data pipeline and platform configuration, and machine learning model evaluation. Such projects may span both pre-sales and post-sales engagements with DataVisor clients.

You will drive the internal engagement with Customer Success, ML Model, Product and Engineering teams to deliver fraud and AML solutions and custom platform configuration that bring business impacts to our clients and generate revenue for DataVisor. You are a big believer and proficient user of GenAI tools e.g. ChatGPT to perform data analysis tasks 10x more efficiently than before.

Key Responsibilities
• Business Problem Discovery: Discover and understand the client’s business logic and business problems, e.g. risk decision flows, business pain points, fraud patterns, data availability and quality, and expected business outcome.
• Data Integration and Quality Check: Lead technical discussions with clients’ risk business teams (Fraud and AML) and data team to ensure high quality and comprehensive data is provided. Own the data transfers and data quality validation.
• Risk Pattern Analyses and Strategies: Leverage your strong domain expertise and business sense to conduct data analyses, pattern analyses, suggest and create detection strategies, and perform strategy testing and iterations.
• Solution Design and Configurations: Design and configure various DataVisor solution components e.g. Rules Engine, Decision Flows, Case Management, Knowledge Graph, BI Dashboards to provide tailored results and strong business values to clients.
• ML Model Performance Analysis: Work with ML Modeling team to develop, tune, and evaluate fraud detection models (unsupervised and supervised), and conduct performance metrics analysis to guide the threshold selection and decision adoption.
• Project Management and Documentation: Manage the solution service projects with project management tools e.g. Monday.com, and own the creation and reporting of key internal and external-facing project documents as deliverables.
• Presentation and Demonstration: Present the project results and demonstrate the configured solutions to key business stakeholders.
• Experience:
• 4+ years of experience in Fraud and/or AML strategies or models
• 2+ years of experience in client-facing data analytic projects
• Technical Skills:
• Domain knowledge in Fraud and AML use cases in financial services industry
• Proficient in SQL queries with complex joining and layered logics
• Familiarity with data streaming/processing e.g. REST API, Kafka, SFTP, Hadoop
• Familiarity with Python, R, and Java is a plus
• Proficient in LLM tools e.g. ChatGPT to research new business problems
• Soft Skills:
• Excellent communication, presentation, and interpersonal skills
• Strong problem-solving mindset and results-driven mindset
• Strong mindset of documentation and automation with AI tools/agents
• Ability to work collaboratively in a face-paced, team environment and manage multiple projects simultaneously
• Education:
• Bachelor’s degree in a technical or analytical discipline e.g. Data Science, Statistics, Computer Science

Why Join Us?
• Opportunity to work on impactful projects that protect businesses from risk loss
• Collaborate with a diverse and talented team of experts in AI and machine learning
• Enjoy a flexible, supportive work environment with opportunities for professional growth
• Competitive compensation and benefits package
• Stock options, Medical insurance, 401K, PTO
#J-18808-Ljbffr",2025-07-10T00:00:00.000Z,2025-07-25,"['You are a big believer and proficient user of GenAI tools e.g. ChatGPT to perform data analysis tasks 10x more efficiently than before', '4+ years of experience in Fraud and/or AML strategies or models', '2+ years of experience in client-facing data analytic projects', 'Domain knowledge in Fraud and AML use cases in financial services industry', 'Proficient in SQL queries with complex joining and layered logics', 'Familiarity with data streaming/processing e.g. REST API, Kafka, SFTP, Hadoop', 'Proficient in LLM tools e.g. ChatGPT to research new business problems', 'Excellent communication, presentation, and interpersonal skills', 'Strong problem-solving mindset and results-driven mindset', 'Strong mindset of documentation and automation with AI tools/agents', 'Ability to work collaboratively in a face-paced, team environment and manage multiple projects simultaneously', 'Bachelor’s degree in a technical or analytical discipline e.g', 'Data Science, Statistics, Computer Science']","['The Solution Data Scientist (Fraud & AML) will be part of our Professional Service team, reporting to our Chief Solution Architect and VP Professional Services', 'You will lead various types of technical projects e.g. fraud attack pattern study, risk strategy development, data pipeline and platform configuration, and machine learning model evaluation', 'Such projects may span both pre-sales and post-sales engagements with DataVisor clients', 'You will drive the internal engagement with Customer Success, ML Model, Product and Engineering teams to deliver fraud and AML solutions and custom platform configuration that bring business impacts to our clients and generate revenue for DataVisor', 'Business Problem Discovery: Discover and understand the client’s business logic and business problems, e.g. risk decision flows, business pain points, fraud patterns, data availability and quality, and expected business outcome', 'Data Integration and Quality Check: Lead technical discussions with clients’ risk business teams (Fraud and AML) and data team to ensure high quality and comprehensive data is provided', 'Own the data transfers and data quality validation', 'Risk Pattern Analyses and Strategies: Leverage your strong domain expertise and business sense to conduct data analyses, pattern analyses, suggest and create detection strategies, and perform strategy testing and iterations', 'Solution Design and Configurations: Design and configure various DataVisor solution components e.g. Rules Engine, Decision Flows, Case Management, Knowledge Graph, BI Dashboards to provide tailored results and strong business values to clients', 'ML Model Performance Analysis: Work with ML Modeling team to develop, tune, and evaluate fraud detection models (unsupervised and supervised), and conduct performance metrics analysis to guide the threshold selection and decision adoption', 'Project Management and Documentation: Manage the solution service projects with project management tools e.g. Monday.com, and own the creation and reporting of key internal and external-facing project documents as deliverables', 'Presentation and Demonstration: Present the project results and demonstrate the configured solutions to key business stakeholders']",True,"['Generative AI Tools', 'Large Language Models (LLMs)']",Generative AI Tools: Leverage generative AI tools such as ChatGPT to perform data analysis tasks more efficiently and to research new business problems related to fraud and AML.; Large Language Models (LLMs): Utilize LLM tools like ChatGPT for researching business problems and automating documentation and analysis tasks within fraud and AML projects.,"['Fraud and AML Strategies and Models', 'Data Integration and Quality Validation', 'Risk Pattern Analysis and Detection Strategies', 'SQL', 'Data Streaming and Processing Technologies', 'Machine Learning Model Evaluation and Tuning', 'BI Dashboards and Reporting Tools', 'Data Pipelines and Platform Configuration']","Fraud and AML Strategies and Models: Develop and evaluate fraud detection and anti-money laundering models using both supervised and unsupervised machine learning techniques to identify risk patterns and improve detection accuracy.; Data Integration and Quality Validation: Lead technical discussions and manage data transfers to ensure high-quality, comprehensive data is provided for fraud and AML analysis and model development.; Risk Pattern Analysis and Detection Strategies: Conduct data and pattern analyses to suggest, create, and iteratively test fraud and AML detection strategies based on domain expertise and business needs.; SQL: Use complex SQL queries with advanced joining and layered logic to extract and manipulate data relevant to fraud and AML use cases.; Data Streaming and Processing Technologies: Utilize technologies such as REST API, Kafka, SFTP, and Hadoop for data streaming, processing, and integration within fraud and AML solutions.; Machine Learning Model Evaluation and Tuning: Collaborate with ML modeling teams to develop, tune, and evaluate fraud detection models, analyzing performance metrics to guide threshold selection and decision-making.; BI Dashboards and Reporting Tools: Design and configure business intelligence dashboards and reporting components to provide tailored insights and strong business value to clients.; Data Pipelines and Platform Configuration: Lead configuration of data pipelines and platform components to support fraud and AML detection solutions and client-specific customizations."
zQbX8Kunk1O0HLj_AAAAAA==,"Senior, Data Scientist - Military veterans preferred","Position Summary...

What you'll do...

Data Source Identification: Requires knowledge of Functional business domain and scenarios; Categories of data and where it is held; Business data requirements; Database technologies and distributed datastores (e.g. SQL, NoSQL); Data Quality; Existing business systems and processes, including the key drivers and measures of success. To support the understanding of the priority order of requirements and service level agreements. Help identify the most suitable source for data that is fit for purpose. Perform initial data quality checks on extracted data.
Data Strategy: Requires knowledge of understanding of business value and relevance of data and data enabled insights / decisions; Appropriate application and understanding of data ecosystem including Data Management, Data Quality Standards and Data Governance, Accessibility, Storage and Scalability, etc.; Understanding of the methods and applications that unlock the monetary value of data assets. To understand, articulate, and apply principles of the defined strategy to routine business problems that involve a single function.
Model Deployment and Scaling: Requires knowledge of impact of variables and features on model performance; understanding of servers, model formats to store models. To support efforts to ensure that analytical models and techniques used can be deployed into production. Support evaluation of the analytical model. Support the scalability and sustainability of analytical models.
Code Development and Testing: Requires knowledge of coding languages like SQL, Java, C++, Python and others; Testing methods such as static, dynamic, software composition analysis, manual penetration testing and others; Business, domain understanding. To write code to develop the required solution and application features by using the recommended programming language and leveraging business, technical, and data requirements. Test the code using the recommended testing approach.
Model Assessment and Validation: Requires knowledge of model fit testing, tuning, and validation techniques (e.g., Chi square, ROC curve, root mean square error etc.); Impact of variables and features on model performance To Identify the model evaluation metrics. Apply best practice techniques for model testing and tuning to assess accuracy, fit, validity, and robustness for multi-stage models and model ensembles.
Data Visualization: Requires knowledge of Visualization guidelines and best practices for complex data types; Multiple data visualization tools (for example, Python, R libraries, GGplot, Matplotlib, Ploty, Tableau, PowerBI etc.); Advanced visualization techniques/ tools; Multiple story plots and structures (OABCDE); Communication & influencing technique; Emotional intelligence. To generate appropriate graphical representations of data and model outcomes. Understand customer requirements to design appropriate data representation for multiple data sets. Work with User Experience designers and User Interface engineers as required to build front end applications. Present to and influence the team and business audience using the appropriate data visualization frameworks and conveys clear messages through business and stakeholder understanding. Customize communication style based on stakeholder under guidance, and leverages rational arguments. Guide and mentor junior associates on story types, structures, and techniques based on context.
Understanding Business Context: Requires knowledge of Industry and environmental factors; Common business vernacular; Business practices across two or more domains such as product, finance, marketing, sales, technology, business systems, and human resources and in-depth knowledge of related practices; Directly relevant business metrics and business areas. To Provide recommendations to business stakeholders to solve complex business issues. Develop business cases for projects with a projected return on investment or cost savings. Translate business requirements into projects, activities, and tasks and aligns to overall business strategy and develops domain specific artifact. Serve as an interpreter and conduit to connect business needs with tangible solutions and results. Identify and recommend relevant business insights pertaining to their area of work.
Tech. Problem Formulation: Requires knowledge of Analytics/big data analytics / automation techniques and methods; Business understanding; Precedence and use cases; Business requirements and insights. To translate/ co-own business problems within one's discipline to data related or mathematical solutions. Identify appropriate methods/tools to be leveraged to provide a solution for the problem. Share use cases and gives examples to demonstrate how the method would solve the business problem.
Analytical Modeling: Requires knowledge of feature relevance and selection; Exploratory data analysis methods and techniques; Advanced statistical methods and best-practice advanced modelling techniques (e.g., graphical models, Bayesian inference, basic level of NLP, Vision, neural networks, SVM, Random Forest etc.); Multivariate calculus; Statistical models behind standard ML models; Advanced excel techniques and Programming languages like R/Python; Basic classical optimization techniques (e.g., Newton-Rapson methods, Gradient descent); Numerical methods of optimization (e.g. Linear Programming, Integer Programming, Quadratic Programming, etc.) To select the analytical modeling technique most suitable for the structured, complex data and develops custom analytical models. Conduct exploratory data analysis activities (for example, basic statistical analysis, hypothesis testing, statistical inferences) on available data. Define and finalize features based on model responses and introduces new or revised features to enhance the analysis and outcomes. Identify the dimensions of the experiment, finalize the design, test hypotheses, and conduct the experiment. Perform trend and cluster analysis on data to answer practical business problems and provide recommendations and key insights to the business. Mentor and guide junior associates on basic modeling and analytics techniques to solve complex problems.
Demonstrates up-to-date expertise and applies this to the development, execution, and improvement of action plans by providing expert advice and guidance to others in the application of information and best practices; supporting and aligning efforts to meet customer and business needs; and building commitment for perspectives and rationales.
Provides and supports the implementation of business solutions by building relationships and partnerships with key stakeholders; identifying business needs; determining and carrying out necessary processes and practices; monitoring progress and results; recognizing and capitalizing on improvement opportunities; and adapting to competing demands, organizational changes, and new responsibilities.
Models compliance with company policies and procedures and supports company mission, values, and standards of ethics and integrity by incorporating these into the development and implementation of business plans; using the Open Door Policy; and demonstrating and assisting others with how to apply these in executing business processes and practices.

Leadership Expectations

Respect for the Individual: Demonstrates and encourages respect for all; builds a high-performing, diverse team; seeks, and embraces differences in people, cultures, ideas and experiences; creates a workplace and equitable experiences where associates feel seen, supported and connected through culture of belonging so associates thrive and perform; drives a positive associate and customer/member experience for all; identifies, attracts, and retains the best, diverse team members.

Respect for the Individual: Creates a discipline and focus around developing talent, through feedback, coaching, mentoring, and developmental opportunities; promotes an environment allowing everyone to bring their best selves to work; empowers associates and partners to act in the best interest of the customer/member and company; and regularly recognizes others’ contributions and accomplishments.

Respect for the Individual: Builds strong and trusting relationships with team members and business partners; works collaboratively and cross-functionally to achieve objectives; and communicates and listens attentively, with energy and positivity to motivate, influence, and inspire commitment and action.

Acts with Integrity: Maintains and promotes the highest standards of integrity, ethics and compliance; models the Walmart values and leads by example to foster our culture; supports Walmart’s goal of becoming a regenerative company by making a positive impact for associates, customers, members, and the world around us.

Acts with Integrity: Follows the law, our code of conduct and company policies, and sets expectations for others to do the same; promotes an environment where associates feel comfortable sharing concerns and reinforces our culture of non-retaliation; listens to concerns raised by associates. takes action and encourages others to do the same; holds self and others accountable for achieving results in a way that is consistent with our values.

Acts with Integrity: Acts as an altruistic servant leader and is consistently humble, self-aware, honest, and transparent.

Service to the Customer/Member: Delivers expected business results while putting the customer/member first and consistently applying an omni-merchant mindset and acts with an Every Day Low Cost mindset to drive value and Every Day Low Prices for customers/members.

Service to the Customer/Member: Adopts a holistic perspective that considers data, analytics, customer/member insights, and different parts of the business when making plans and shaping the team’s strategy.

Strive for Excellence: Consistently raises the bar and seeks to improve; demonstrates curiosity and a growth mindset; seeks feedback, asks thoughtful questions, fosters an environment that supports learning, innovation, and learning from mistakes, and intelligent risk-taking; and exhibits resilience in the face of setbacks.

Strive for Excellence: Seeks and implements continuous improvements and encourages the team to leverage new digital tools and ways of working.

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

?

?

?
You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.

?

For information about PTO, see .

?

?
Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

?
Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

?

For information about benefits and eligibility, see .

?
The annual salary range for this position is $90,000.00-$180,000.00

?
Additional compensation includes annual or quarterly performance bonuses.

?
Additional compensation for certain positions may also include:

?

?
- Stock

?

?

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1- Bachelor’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years' experience in an analytics related field. Option 2- Master’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years' experience in an analytics related field. Option 3 - 5 years' experience in an analytics or related field.

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data science, machine learning, optimization models, Master’s degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.

Primary Location...

805 Se Moberly Ln, Bentonville, AR 72712, United States of America",2025-07-11T00:00:00.000Z,2025-07-25,"['Data Strategy: Requires knowledge of understanding of business value and relevance of data and data enabled insights / decisions; Appropriate application and understanding of data ecosystem including Data Management, Data Quality Standards and Data Governance, Accessibility, Storage and Scalability, etc.; Understanding of the methods and applications that unlock the monetary value of data assets', 'Code Development and Testing: Requires knowledge of coding languages like SQL, Java, C++, Python and others; Testing methods such as static, dynamic, software composition analysis, manual penetration testing and others; Business, domain understanding', 'Model Assessment and Validation: Requires knowledge of model fit testing, tuning, and validation techniques (e.g., Chi square, ROC curve, root mean square error etc.); Impact of variables and features on model performance To Identify the model evaluation metrics', 'Problem Formulation: Requires knowledge of Analytics/big data analytics / automation techniques and methods; Business understanding; Precedence and use cases; Business requirements and insights', 'Analytical Modeling: Requires knowledge of feature relevance and selection; Exploratory data analysis methods and techniques; Advanced statistical methods and best-practice advanced modelling techniques (e.g., graphical models, Bayesian inference, basic level of NLP, Vision, neural networks, SVM, Random Forest etc.); Multivariate calculus; Statistical models behind standard ML models; Advanced excel techniques and Programming languages like R/Python; Basic classical optimization techniques (e.g., Newton-Rapson methods, Gradient descent); Numerical methods of optimization (e.g. Linear Programming, Integer Programming, Quadratic Programming, etc.) To select the analytical modeling technique most suitable for the structured, complex data and develops custom analytical models', 'Respect for the Individual: Demonstrates and encourages respect for all; builds a high-performing, diverse team; seeks, and embraces differences in people, cultures, ideas and experiences; creates a workplace and equitable experiences where associates feel seen, supported and connected through culture of belonging so associates thrive and perform; drives a positive associate and customer/member experience for all; identifies, attracts, and retains the best, diverse team members', ""Option 1- Bachelor’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years' experience in an analytics related field"", ""Option 2- Master’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years' experience in an analytics related field"", ""Option 3 - 5 years' experience in an analytics or related field"", 'Data science, machine learning, optimization models, Master’s degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly', 'The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture']","['Data Source Identification: Requires knowledge of Functional business domain and scenarios; Categories of data and where it is held; Business data requirements; Database technologies and distributed datastores (e.g. SQL, NoSQL); Data Quality; Existing business systems and processes, including the key drivers and measures of success', 'To support the understanding of the priority order of requirements and service level agreements', 'Help identify the most suitable source for data that is fit for purpose', 'Perform initial data quality checks on extracted data', 'To understand, articulate, and apply principles of the defined strategy to routine business problems that involve a single function', 'Model Deployment and Scaling: Requires knowledge of impact of variables and features on model performance; understanding of servers, model formats to store models', 'To support efforts to ensure that analytical models and techniques used can be deployed into production', 'Support evaluation of the analytical model', 'Support the scalability and sustainability of analytical models', 'To write code to develop the required solution and application features by using the recommended programming language and leveraging business, technical, and data requirements', 'Test the code using the recommended testing approach', 'Apply best practice techniques for model testing and tuning to assess accuracy, fit, validity, and robustness for multi-stage models and model ensembles', 'Data Visualization: Requires knowledge of Visualization guidelines and best practices for complex data types; Multiple data visualization tools (for example, Python, R libraries, GGplot, Matplotlib, Ploty, Tableau, PowerBI etc.); Advanced visualization techniques/ tools; Multiple story plots and structures (OABCDE); Communication & influencing technique; Emotional intelligence', 'To generate appropriate graphical representations of data and model outcomes', 'Understand customer requirements to design appropriate data representation for multiple data sets', 'Work with User Experience designers and User Interface engineers as required to build front end applications', 'Present to and influence the team and business audience using the appropriate data visualization frameworks and conveys clear messages through business and stakeholder understanding', 'Customize communication style based on stakeholder under guidance, and leverages rational arguments', 'Guide and mentor junior associates on story types, structures, and techniques based on context', 'Understanding Business Context: Requires knowledge of Industry and environmental factors; Common business vernacular; Business practices across two or more domains such as product, finance, marketing, sales, technology, business systems, and human resources and in-depth knowledge of related practices; Directly relevant business metrics and business areas', 'To Provide recommendations to business stakeholders to solve complex business issues', 'Develop business cases for projects with a projected return on investment or cost savings', 'Translate business requirements into projects, activities, and tasks and aligns to overall business strategy and develops domain specific artifact', 'Serve as an interpreter and conduit to connect business needs with tangible solutions and results', 'Identify and recommend relevant business insights pertaining to their area of work', ""To translate/ co-own business problems within one's discipline to data related or mathematical solutions"", 'Identify appropriate methods/tools to be leveraged to provide a solution for the problem', 'Share use cases and gives examples to demonstrate how the method would solve the business problem', 'Conduct exploratory data analysis activities (for example, basic statistical analysis, hypothesis testing, statistical inferences) on available data', 'Define and finalize features based on model responses and introduces new or revised features to enhance the analysis and outcomes', 'Identify the dimensions of the experiment, finalize the design, test hypotheses, and conduct the experiment', 'Perform trend and cluster analysis on data to answer practical business problems and provide recommendations and key insights to the business', 'Mentor and guide junior associates on basic modeling and analytics techniques to solve complex problems', 'Demonstrates up-to-date expertise and applies this to the development, execution, and improvement of action plans by providing expert advice and guidance to others in the application of information and best practices; supporting and aligning efforts to meet customer and business needs; and building commitment for perspectives and rationales', 'Provides and supports the implementation of business solutions by building relationships and partnerships with key stakeholders; identifying business needs; determining and carrying out necessary processes and practices; monitoring progress and results; recognizing and capitalizing on improvement opportunities; and adapting to competing demands, organizational changes, and new responsibilities', 'Models compliance with company policies and procedures and supports company mission, values, and standards of ethics and integrity by incorporating these into the development and implementation of business plans; using the Open Door Policy; and demonstrating and assisting others with how to apply these in executing business processes and practices', 'Respect for the Individual: Builds strong and trusting relationships with team members and business partners; works collaboratively and cross-functionally to achieve objectives; and communicates and listens attentively, with energy and positivity to motivate, influence, and inspire commitment and action', 'Acts with Integrity: Maintains and promotes the highest standards of integrity, ethics and compliance; models the Walmart values and leads by example to foster our culture; supports Walmart’s goal of becoming a regenerative company by making a positive impact for associates, customers, members, and the world around us', 'takes action and encourages others to do the same; holds self and others accountable for achieving results in a way that is consistent with our values', 'Acts with Integrity: Acts as an altruistic servant leader and is consistently humble, self-aware, honest, and transparent', 'Service to the Customer/Member: Delivers expected business results while putting the customer/member first and consistently applying an omni-merchant mindset and acts with an Every Day Low Cost mindset to drive value and Every Day Low Prices for customers/members', 'Service to the Customer/Member: Adopts a holistic perspective that considers data, analytics, customer/member insights, and different parts of the business when making plans and shaping the team’s strategy', 'Strive for Excellence: Consistently raises the bar and seeks to improve; demonstrates curiosity and a growth mindset; seeks feedback, asks thoughtful questions, fosters an environment that supports learning, innovation, and learning from mistakes, and intelligent risk-taking; and exhibits resilience in the face of setbacks']",True,[],,"['SQL', 'NoSQL', 'Data Quality', 'Data Management', 'Data Governance', 'Data Visualization', 'Python', 'R', 'Java', 'C++', 'Model Evaluation Metrics', 'Feature Engineering', 'Exploratory Data Analysis', 'Statistical Models', 'Machine Learning', 'Optimization Techniques', 'Model Deployment', 'Model Scaling', 'Code Testing', 'Big Data Analytics', 'Spark', 'Scala', 'Scikit-learn', 'TensorFlow', 'Torch', 'Data Pipelines', 'Business Intelligence Tools', 'Advanced Excel Techniques']","SQL: Used as a coding language for data extraction, querying databases, and performing initial data quality checks on extracted data.; NoSQL: Referenced as a type of distributed datastore relevant for data source identification and storage.; Data Quality: Involves performing initial data quality checks on extracted data and understanding data quality standards as part of data strategy.; Data Management: Part of the data ecosystem knowledge required to understand data governance, accessibility, storage, and scalability to unlock the monetary value of data assets.; Data Governance: Included in the data ecosystem knowledge to ensure data quality standards, accessibility, and compliance with organizational policies.; Data Visualization: Involves generating graphical representations of data and model outcomes using multiple tools and techniques to communicate insights effectively to business stakeholders.; Python: Used as a programming language for code development, testing, data visualization, and advanced analytical modeling.; R: Used for programming in advanced statistical methods, exploratory data analysis, and data visualization.; Java: Mentioned as a coding language used for developing solutions and application features.; C++: Mentioned as a coding language used for developing solutions and application features.; Model Evaluation Metrics: Includes techniques such as Chi square, ROC curve, and root mean square error used for model fit testing, tuning, and validation to assess accuracy, fit, validity, and robustness.; Feature Engineering: Involves defining and finalizing features based on model responses and introducing new or revised features to enhance analysis and outcomes.; Exploratory Data Analysis: Conducting basic statistical analysis, hypothesis testing, and statistical inferences on available data to understand data characteristics and inform modeling.; Statistical Models: Includes advanced statistical methods and best-practice modeling techniques such as graphical models and Bayesian inference used for analytical modeling.; Machine Learning: Applied through standard ML models like SVM, Random Forest, and neural networks to develop custom analytical models for structured, complex data.; Optimization Techniques: Utilizes classical optimization methods like Newton-Raphson and gradient descent, as well as numerical methods such as linear, integer, and quadratic programming for analytical modeling.; Model Deployment: Supports efforts to deploy analytical models into production, including understanding model formats and server environments.; Model Scaling: Involves supporting the scalability and sustainability of analytical models in production environments.; Code Testing: Includes static, dynamic, software composition analysis, and manual penetration testing methods to ensure code quality and security.; Big Data Analytics: Knowledge of analytics and automation techniques applied to large datasets to translate business problems into data or mathematical solutions.; Spark: Referenced as a technology for which successful completion of assessments is valued, indicating its use in data processing and analytics.; Scala: Mentioned as a language for which assessments are valued, often used with big data frameworks like Spark.; Scikit-learn: An open source framework used for machine learning model development and evaluation.; TensorFlow: Listed as an open source framework used for machine learning model development.; Torch: Included as an open source framework used for machine learning model development.; Data Pipelines: Implied through responsibilities involving data source identification, extraction, quality checks, and preparation for modeling and visualization.; Business Intelligence Tools: Includes Tableau and PowerBI used for creating dashboards and visualizations to communicate data insights to stakeholders.; Advanced Excel Techniques: Used for data analysis and modeling tasks as part of analytical modeling responsibilities."
gnaaq_1XFeoRQdOoAAAAAA==,Data Science Internship,"This is a role well suited to an ambitious professional, looking for the next step in their career. As a Data Science Intern, you will be responsible for:

Working with real data to solve real business problems

Using data science and visualization tools

Collaborating with other Data Scientists and Analysts to research new methodologies and deliver new solutions

Siemens is an Equal Opportunity Employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. We do not discriminate based upon race, religion, color, national origin, sex, sexual orientation, gender identity, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.",,2025-07-25,,"['Working with real data to solve real business problems', 'Using data science and visualization tools', 'Collaborating with other Data Scientists and Analysts to research new methodologies and deliver new solutions']",True,[],,"['Data Science', 'Data Visualization']",Data Science: The role involves applying data science techniques to analyze real data and solve business problems.; Data Visualization: The job requires using visualization tools to represent data insights effectively.
vfZjZiS8ZdRbtRuKAAAAAA==,Intern - Data Science,"About the position

RGA is a purpose-driven organization working to solve today's challenges through innovation and collaboration. A Fortune 500 Company and listed among its World's Most Admired Companies, we're the only global reinsurance company to focus primarily on life- and health-related solutions. Join our multinational team of intelligent, motivated, and collaborative people, and help us make financial protection accessible to all. The intern will develop and implement predictive modeling solutions and commercial applications for both RGA internal and external clients. The successful candidate will work on designing and developing data analytic tools to meet the needs of different business applications. Communicate and collaborate with colleagues to ensure highly efficient and innovative performance. The intern will work full time from June-August.

Responsibilities
• Assist in development of predictive modeling for applications.
,
• Create and develop data processing tools for different data sources: tables, texts and images.
,
• Perform tests and develop diagnostic methodology to ensure the accuracy and reliability of data process pipeline.
,
• Validate and clean data from multiple sources. Ensure data quality and integrity for effective modeling.
,
• Participate in research related activities.
,
• Maintain regular and predictable attendance.

Requirements

undefined

Nice-to-haves

undefined

Benefits
• Gain valuable knowledge from and experience with diverse, caring colleagues around the world.
,
• Enjoy a respectful, welcoming environment that fosters individuality and encourages pioneering thought.
,
• Join the bright and creative minds of RGA, and experience vast, endless career potential.",,2025-07-25,,"['The intern will develop and implement predictive modeling solutions and commercial applications for both RGA internal and external clients', 'The successful candidate will work on designing and developing data analytic tools to meet the needs of different business applications', 'Communicate and collaborate with colleagues to ensure highly efficient and innovative performance', 'The intern will work full time from June-August', 'Assist in development of predictive modeling for applications', 'Create and develop data processing tools for different data sources: tables, texts and images', 'Perform tests and develop diagnostic methodology to ensure the accuracy and reliability of data process pipeline', 'Validate and clean data from multiple sources', 'Ensure data quality and integrity for effective modeling', 'Participate in research related activities', 'Maintain regular and predictable attendance']",True,[],,"['Predictive Modeling', 'Data Processing Tools', 'Data Pipeline Testing and Diagnostics', 'Data Validation and Cleaning']","Predictive Modeling: Develop and implement predictive modeling solutions for internal and external business applications to support decision-making and commercial use.; Data Processing Tools: Create and develop tools to process various data types including tables, texts, and images to support analytics workflows.; Data Pipeline Testing and Diagnostics: Perform tests and develop diagnostic methodologies to ensure the accuracy and reliability of data processing pipelines.; Data Validation and Cleaning: Validate and clean data from multiple sources to ensure data quality and integrity for effective modeling."
8Upetwi2ajJ92iZ0AAAAAA==,"Senior Data Scientist, Costing","Xometry (NASDAQ: XMTR) powers the industries of today and tomorrow by connecting the people with big ideas to the manufacturers who can bring them to life. Xometry's digital marketplace gives manufacturers the critical resources they need to grow their business while also making it easy for buyers at Fortune 1000 companies to tap into global manufacturing capacity.

Xometry is adding a Sr. Data Scientist to our sourcing team. The ideal candidate will have a passion for using machine learning tools and techniques to construct, optimize, and evaluate predictive models that predict the likelihood of different business outcomes. Additionally, this person will use their knowledge of probability and statistics to make defensible statistical inferences from data.

Responsibilities:
• Use data science and machine learning principles to develop effective predictive models
• Write software to prepare, clean, and sample data for use in developing predictive models
• Use cloud resources (e.g., Amazon Web Services) to prepare and process data
• Query and extract data from databases (Snowflake)
• Use data analysis and visualization tools (examples include SQL, Python, Jupyter Notebooks, and Looker) to inform the business strategy
• Relentlessly iterate solutions within a fast-paced environment where ambiguity is the norm
• Solve challenging, uncharted problems
• Work in an environment that thrives on teamwork and continuous learning opportunities

Requirements:
• Bachelor's degree required; degree in applied math, computer science, natural sciences or engineering preferred
• M.S. or Ph.D. in a related field highly desired
• 5+ years of experience with machine learning, statistical modeling, and optimization techniques
• Fluent in Python (pandas, numpy, SciPy, and scikit-learn preferred)
• Proficient in linear algebra and statistics
• Familiar with scientific software principals, e.g. versioning systems, reproducibility
• Experience in the manufacturing industry is desired
• Must be a US Citizen or Green Card holder (ITAR)

#LI-Hybrid

Xometry is an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran, or disability status.

For US based roles: Xometry participates in E-Verify and after a job offer is accepted, will provide the federal government with your Form I-9 information to confirm that you are authorized to work in the U.S.",2025-06-26T00:00:00.000Z,2025-07-25,"['5+ years of experience with machine learning, statistical modeling, and optimization techniques', 'Proficient in linear algebra and statistics', 'Familiar with scientific software principals, e.g. versioning systems, reproducibility', 'Must be a US Citizen or Green Card holder (ITAR)']","['The ideal candidate will have a passion for using machine learning tools and techniques to construct, optimize, and evaluate predictive models that predict the likelihood of different business outcomes', 'Additionally, this person will use their knowledge of probability and statistics to make defensible statistical inferences from data', 'Use data science and machine learning principles to develop effective predictive models', 'Write software to prepare, clean, and sample data for use in developing predictive models', 'Use cloud resources (e.g., Amazon Web Services) to prepare and process data', 'Query and extract data from databases (Snowflake)', 'Use data analysis and visualization tools (examples include SQL, Python, Jupyter Notebooks, and Looker) to inform the business strategy', 'Relentlessly iterate solutions within a fast-paced environment where ambiguity is the norm', 'Solve challenging, uncharted problems', 'Work in an environment that thrives on teamwork and continuous learning opportunities']",True,[],,"['Predictive Modeling', 'Machine Learning', 'Statistical Inference', 'Data Preparation and Cleaning', 'Cloud Data Processing', 'Database Querying', 'Data Analysis and Visualization', 'Python Data Libraries', 'Linear Algebra and Statistics', 'Scientific Software Practices']","Predictive Modeling: Develop and optimize predictive models using machine learning and statistical modeling techniques to forecast business outcomes.; Machine Learning: Apply machine learning principles and tools to construct, optimize, and evaluate models that predict likelihoods of various business scenarios.; Statistical Inference: Use knowledge of probability and statistics to make defensible statistical inferences from data.; Data Preparation and Cleaning: Write software to prepare, clean, and sample data for use in developing predictive models.; Cloud Data Processing: Utilize cloud resources such as Amazon Web Services to prepare and process data.; Database Querying: Extract and query data from databases, specifically Snowflake, to support data analysis and modeling.; Data Analysis and Visualization: Use tools like SQL, Python, Jupyter Notebooks, and Looker to analyze data and create visualizations that inform business strategy.; Python Data Libraries: Employ Python libraries such as pandas, numpy, SciPy, and scikit-learn for data manipulation, scientific computing, and machine learning.; Linear Algebra and Statistics: Apply proficiency in linear algebra and statistics to support modeling and data analysis tasks.; Scientific Software Practices: Follow scientific software principles including versioning systems and reproducibility to ensure reliable and maintainable code."
Kja4P_O8wJbP0NWVAAAAAA==,Associate Data Analyst,"Responsiblities Importing data from PDH OBIA and OBIEE finalizing and reconciling reports for various geographies in Excel PPT and Smartsheets. Supporting teams across various geographies in managing schedules reports dashboards and workflows. Create graphs to compare durations between plan trending and actuals deliveries. Support in creating dashboards on early on time and delayed deliveries broken up as per geographies. Troubleshoot Smartsheet access issues. Grant and remove Smartsheet Access as per requirements. Manage data including clean up and back up.

Key Skills Statistical programming. Machine learning. Probability and statistics. Data management. Statistical visualization. Econometrics.",,2025-07-25,"['Key Skills Statistical programming', 'Machine learning', 'Probability and statistics']","['Responsiblities Importing data from PDH OBIA and OBIEE finalizing and reconciling reports for various geographies in Excel PPT and Smartsheets', 'Supporting teams across various geographies in managing schedules reports dashboards and workflows', 'Create graphs to compare durations between plan trending and actuals deliveries', 'Support in creating dashboards on early on time and delayed deliveries broken up as per geographies', 'Troubleshoot Smartsheet access issues', 'Grant and remove Smartsheet Access as per requirements', 'Manage data including clean up and back up']",True,[],,"['Data Import and Integration', 'Data Visualization and Dashboards', 'Data Management', 'Statistical Programming', 'Machine Learning', 'Probability and Statistics', 'Econometrics']","Data Import and Integration: Importing data from PDH OBIA and OBIEE systems to finalize and reconcile reports across various geographies.; Data Visualization and Dashboards: Creating graphs and dashboards to compare durations between planned, trending, and actual deliveries, and to track early, on-time, and delayed deliveries segmented by geography.; Data Management: Managing data including cleaning, backup, and troubleshooting access issues in Smartsheets, as well as granting and removing access as required.; Statistical Programming: Applying statistical programming skills to support data analysis and reporting tasks.; Machine Learning: Utilizing machine learning techniques as part of the data analysis and modeling efforts.; Probability and Statistics: Employing probability and statistical methods to analyze data and support decision-making.; Econometrics: Using econometric methods to analyze economic data and support statistical modeling."
qB4HAz9l6SsBV-KYAAAAAA==,"Staff, Data Scientist – Conversational AI - Full-time / Part-time","**Position Summary...**
• *What you'll do...**

Cortex Team is Walmarts core A.I. conversational platform, powering the vision of delivering the worlds best personal assistants to Walmarts customers, accessible via natural voice commands, text messages, rich UI interactions, and a mix of all of the above via multi-modal experiences.

We believe _conversations_ are a natural and powerful user interface for interacting with technology and enable a richer customer experiences both online and in-store. We are building and designing the next generation of Natural Language Understanding (NLU) services that other teams can easily integrate and leverage, and build rich experiences: from pure voice and text shopping assistants (Siri,Sparky (https://tech.walmart.com/content/walmart-global-tech/en\_us/blog/post/walmart-is-building-a-genai-powered-shopping-assistant.html) ), to customer care channels, to mobile apps with rich, intertwined, multi-modal interaction modes (Me@Walmart (https://apps.apple.com/us/app/me-walmart/id1459898418) ).

Interested in diving in?

We need passionate and seasoned NLP data-scientists to help us improve and evolve our capabilities, taking into account the full conversational context, multi-modal interactions, and an ever increasing list of use cases.

Come at the right time, and you will have an enormous opportunity to make a massive impact on the design, architecture, and implementation of an innovative, mission critical product, driven by data-science, used every day, by people you know, and which customers love.

As part of the emerging tech group, you will also have the additional opportunity of building demos, proof of concepts, creating white papers, writing blogs, etc.

Minimum Qualifications

+ Experience with Python; solid knowledge SQL.

+ Hands on experience with classical ML models, test/train/evaluation metrics, key parameters/techniques that affect model performance

+ Understanding of relevant statistical measures such as confidence intervals, significance of error measurements, development and evaluation data sets.

+ Familiarity and ideally experience with NLU/NLP, more recent deep ML models (e.g., Transformers, BERT, Llama, Gpts, Gemini) and safe fine-tuning of these.

+ A business analytical mind; ability to communicate with consumers of the model and present results in intuitive ways.

+ Experience analyzing data to identify patterns and conducting error/deviation analysis; passion for fixing issues in the data and finding the optimal representation.

+ Ability to take a project from scoping requirements through actual launch.

+ A continuous drive to explore, improve, enhance, automate, and optimize models and products.

+ Excellent oral and written communication skills.

+ Bachelors degree or certification in Machine Learning, Computer Science, Engineering, Mathematics, Statistics or any other related field.

Preferred Qualifications

+ Exposure to real-world, production grade agentic systems.

+ Familiarity with LLMs serving optimizations and multi-LoRa

+ Ability to develop experimental and analytic plans for data modeling processes, use of strong baselines, ability to accurately determine cause and effect relations

+ Strong attention to detail and exceptional level of organization

+ Proven ability to achieve results in a fast paced, highly collaborative, dynamic work environment

+ Hands-on expertise in many disparate technologies and the full model lifecycle, typically ranging from data pipelines, data extraction, model training, model serving, labeling tools, ML-ops, ad-hoc tooling and all points in between.

+ PhD in a relevant field (Machine Learning, Computer Science, Engineering, Mathematics, Physics, Statistics or a related field)
• *About Walmart Global Tech**

Imagine working in an environment where one line of code can make life easier for hundreds of millions of people. Thats what we do at Walmart Global Tech. Were a team of software engineers, data scientists, cybersecurity experts and service professionals within the worlds leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.
• *Flexible, hybrid work:**

We use a hybrid way of working that is primarily in office coupled with virtual when not onsite. Our campuses serve as a hub to enhance collaboration, bring us together for purpose and deliver on business needs. This approach helps us make quicker decisions, remove location barriers across our global team and be more flexible in our personal lives.
• *Benefits:**

Benefits: Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.
• *Equal Opportunity Employer:**

Walmart, Inc. is an Equal Opportunity Employer By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting, and valuing unique styles, experiences, identities, ideas and opinions while being welcoming of all people.

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

‎

‎

‎

You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.

‎

For information about PTO, see https://one.walmart.com/notices .

‎

‎

Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

‎

Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

‎

For information about benefits and eligibility, see One.Walmart (https://bit.ly/3iOOb1J) .

‎

The annual salary range for this position is $143,000.00-$286,000.00

‎

Additional compensation includes annual or quarterly performance bonuses.

‎

Additional compensation for certain positions may also include:

‎

‎

- Stock

‎

‎
• *Minimum Qualifications...**

_Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications._

Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 4 years' experience in an analytics related field. Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 2 years' experience in an analytics related field. Option 3: 6 years' experience in an analytics or related field
• *Preferred Qualifications...**

_Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications._

Data science, machine learning, optimization models, PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.
• *Primary Location...**

680 West California Avenue, Sunnyvale, CA 94086-4834, United States of America

Walmart, Inc. is an Equal Opportunity Employer- By Choice. We believe we are best equipped to help our associates, customers, and the communities we serve live better when we really know them. That means understanding, respecting, and valuing diversity- unique styles, experiences, identities, abilities, ideas and opinions- while being inclusive of all people.
• *Position Summary...**
• *What you'll do...**

Cortex Team is Walmarts core A.I. conversational platform, powering the vision of delivering the worlds best personal assistants to Walmarts customers, accessible via natural voice commands, text messages, rich UI interactions, and a mix of all of the above via multi-modal experiences.

We believe _conversations_ are a natural and powerful user interface for interacting with technology and enable a richer customer experiences both online and in-store. We are building and designing the next generation of Natural Language Understanding (NLU) services that other teams can easily integrate and leverage, and build rich experiences: from pure voice and text shopping assistants (Siri,Sparky (https://tech.walmart.com/content/walmart-global-tech/en\_us/blog/post/walmart-is-building-a-genai-powered-shopping-assistant.html) ), to customer care channels, to mobile apps with rich, intertwined, multi-modal interaction modes (Me@Walmart (https://apps.apple.com/us/app/me-walmart/id1459898418) ).

Interested in diving in?

We need passionate and seasoned NLP data-scientists to help us improve and evolve our capabilities, taking into account the full conversational context, multi-modal interactions, and an ever increasing list of use cases.

Come at the right time, and you will have an enormous opportunity to make a massive impact on the design, architecture, and implementation of an innovative, mission critical product, driven by data-science, used every day, by people you know, and which customers love.

As part of the emerging tech group, you will also have the additional opportunity of building demos, proof of concepts, creating white papers, writing blogs, etc.

Minimum Qualifications

+ Experience with Python; solid knowledge SQL.

+ Hands on experience with classical ML models, test/train/evaluation metrics, key parameters/techniques that affect model performance

+ Understanding of relevant statistical measures such as confidence intervals, significance of error measurements, development and evaluation data sets.

+ Familiarity and ideally experience with NLU/NLP, more recent deep ML models (e.g., Transformers, BERT, Llama, Gpts, Gemini) and safe fine-tuning of these.

+ A business analytical mind; ability to communicate with consumers of the model and present results in intuitive ways.

+ Experience analyzing data to identify patterns and conducting error/deviation analysis; passion for fixing issues in the data and finding the optimal representation.

+ Ability to take a project from scoping requirements through actual launch.

+ A continuous drive to explore, improve, enhance, automate, and optimize models and products.

+ Excellent oral and written communication skills.

+ Bachelors degree or certification in Machine Learning, Computer Science, Engineering, Mathematics, Statistics or any other related field.

Preferred Qualifications

+ Exposure to real-world, production grade agentic systems.

+ Familiarity with LLMs serving optimizations and multi-LoRa

+ Ability to develop experimental and analytic plans for data modeling processes, use of strong baselines, ability to accurately determine cause and effect relations

+ Strong attention to detail and exceptional level of organization

+ Proven ability to achieve results in a fast paced, highly collaborative, dynamic work environment

+ Hands-on expertise in many disparate technologies and the full model lifecycle, typically ranging from data pipelines, data extraction, model training, model serving, labeling tools, ML-ops, ad-hoc tooling and all points in between.

+ PhD in a relevant field (Machine Learning, Computer Science, Engineering, Mathematics, Physics, Statistics or a related field)
• *About Walmart Global Tech**

Imagine working in an environment where one line of code can make life easier for hundreds of millions of people. Thats what we do at Walmart Global Tech. Were a team of software engineers, data scientists, cybersecurity experts and service professionals within the worlds leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.
• *Flexible, hybrid work:**

We use a hybrid way of working that is primarily in office coupled with virtual when not onsite. Our campuses serve as a hub to enhance collaboration, bring us together for purpose and deliver on business needs. This approach helps us make quicker decisions, remove location barriers across our global team and be more flexible in our personal lives.
• *Benefits:**

Benefits: Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.
• *Equal Opportunity Employer:**

Walmart, Inc. is an Equal Opportunity Employer By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting, and valuing unique styles, experiences, identities, ideas and opinions while being welcoming of all people.

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

‎

‎

‎

You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.

‎

For information about PTO, see https://one.walmart.com/notices .

‎

‎

Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

‎

Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

‎

For information about benefits and eligibility, see One.Walmart (https://bit.ly/3iOOb1J) .

‎

The annual salary range for this position is $143,000.00-$286,000.00

‎

Additional compensation includes annual or quarterly performance bonuses.

‎

Additional compensation for certain positions may also include:

‎

‎

- Stock

‎

‎
• *Minimum Qualifications...**

_Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications._

Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 4 years' experience in an analytics related field. Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 2 years' experience in an analytics related field. Option 3: 6 years' experience in an analytics or related field
• *Preferred Qualifications...**

_Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications._

Data science, machine learning, optimization models, PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.
• *Primary Location...**

680 West California Avenue, Sunnyvale, CA 94086-4834, United States of America

Walmart, Inc. is an Equal Opportunity Employer- By Choice. We believe we are best equipped to help our associates, customers, and the communities we serve live better when we really know them. That means understanding, respecting, and valuing diversity- unique styles, experiences, identities, abilities, ideas and opinions- while being inclusive of all people.",2025-07-24T00:00:00.000Z,2025-07-25,"['Experience with Python; solid knowledge SQL', 'Hands on experience with classical ML models, test/train/evaluation metrics, key parameters/techniques that affect model performance', 'Understanding of relevant statistical measures such as confidence intervals, significance of error measurements, development and evaluation data sets', 'Familiarity and ideally experience with NLU/NLP, more recent deep ML models (e.g., Transformers, BERT, Llama, Gpts, Gemini) and safe fine-tuning of these', 'A business analytical mind; ability to communicate with consumers of the model and present results in intuitive ways', 'Experience analyzing data to identify patterns and conducting error/deviation analysis; passion for fixing issues in the data and finding the optimal representation', 'Ability to take a project from scoping requirements through actual launch', 'A continuous drive to explore, improve, enhance, automate, and optimize models and products', 'Excellent oral and written communication skills', 'Bachelors degree or certification in Machine Learning, Computer Science, Engineering, Mathematics, Statistics or any other related field', ""Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 4 years' experience in an analytics related field"", ""Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 2 years' experience in an analytics related field"", ""Option 3: 6 years' experience in an analytics or related field"", 'Data science, machine learning, optimization models, PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly', 'The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture', 'We need passionate and seasoned NLP data-scientists to help us improve and evolve our capabilities, taking into account the full conversational context, multi-modal interactions, and an ever increasing list of use cases', 'Experience with Python; solid knowledge SQL', 'Hands on experience with classical ML models, test/train/evaluation metrics, key parameters/techniques that affect model performance', 'Understanding of relevant statistical measures such as confidence intervals, significance of error measurements, development and evaluation data sets', 'Familiarity and ideally experience with NLU/NLP, more recent deep ML models (e.g., Transformers, BERT, Llama, Gpts, Gemini) and safe fine-tuning of these', 'A business analytical mind; ability to communicate with consumers of the model and present results in intuitive ways', 'Experience analyzing data to identify patterns and conducting error/deviation analysis; passion for fixing issues in the data and finding the optimal representation', 'Ability to take a project from scoping requirements through actual launch', 'A continuous drive to explore, improve, enhance, automate, and optimize models and products', 'Excellent oral and written communication skills', 'Bachelors degree or certification in Machine Learning, Computer Science, Engineering, Mathematics, Statistics or any other related field', 'That means understanding, respecting, and valuing unique styles, experiences, identities, ideas and opinions while being welcoming of all people', ""Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 4 years' experience in an analytics related field"", ""Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 2 years' experience in an analytics related field"", ""Option 3: 6 years' experience in an analytics or related field"", 'Data science, machine learning, optimization models, PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly', 'The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture']","['As part of the emerging tech group, you will also have the additional opportunity of building demos, proof of concepts, creating white papers, writing blogs, etc', 'Come at the right time, and you will have an enormous opportunity to make a massive impact on the design, architecture, and implementation of an innovative, mission critical product, driven by data-science, used every day, by people you know, and which customers love', 'As part of the emerging tech group, you will also have the additional opportunity of building demos, proof of concepts, creating white papers, writing blogs, etc']",True,"['Transformers', 'Large Language Models (LLMs)', 'Generative AI', 'Conversational AI']","Transformers: Experience with recent deep learning models based on transformer architectures such as BERT, LLaMA, GPTs, and Gemini, including safe fine-tuning of these models.; Large Language Models (LLMs): Familiarity with serving optimizations and multi-LoRa techniques for large language models used in conversational AI.; Generative AI: Involvement in building and evolving generative AI-powered conversational platforms and personal assistants.; Conversational AI: Design and implementation of AI-driven conversational platforms that support natural voice commands, text messages, and multi-modal user interactions.","['Python', 'SQL', 'Classical Machine Learning Models', 'Statistical Measures', 'Data Analysis and Pattern Recognition', 'Data Pipelines and Model Lifecycle', 'Optimization Models', 'Open Source Frameworks', 'Experimental and Analytic Planning', 'Business Analytics', 'Natural Language Understanding (NLU) and Natural Language Processing (NLP)']","Python: Required experience with Python programming language for data analysis and model development.; SQL: Solid knowledge of SQL for data extraction and querying relational databases.; Classical Machine Learning Models: Hands-on experience with traditional machine learning models including training, testing, evaluation metrics, and tuning key parameters to optimize model performance.; Statistical Measures: Understanding of statistical concepts such as confidence intervals, significance of error measurements, and the use of development and evaluation datasets.; Data Analysis and Pattern Recognition: Experience analyzing data to identify patterns, conducting error and deviation analysis, and improving data representation.; Data Pipelines and Model Lifecycle: Hands-on expertise across the full model lifecycle including data pipelines, data extraction, model training, model serving, labeling tools, ML-ops, and ad-hoc tooling.; Optimization Models: Use of optimization models as part of data science and machine learning tasks.; Open Source Frameworks: Experience using open source frameworks such as scikit-learn, TensorFlow, and PyTorch for machine learning and data science tasks.; Experimental and Analytic Planning: Ability to develop experimental and analytic plans for data modeling processes, including use of strong baselines and accurate determination of cause and effect relationships.; Business Analytics: Ability to communicate model results effectively to business stakeholders and present insights in intuitive ways.; Natural Language Understanding (NLU) and Natural Language Processing (NLP): Familiarity and experience with NLU/NLP techniques to improve conversational AI capabilities, including handling multi-modal interactions and conversational context."
otZsAj2XLUruWbW4AAAAAA==,"Intern, Data Science-Remote","Overview

Since our founding in 1924, we've cut cardiovascular disease deaths in half, but there is still so much more to do. To overcome today’s biggest health challenges and accelerate this progress, we need passionate individuals like you. Join our movement, be part of the progress, and help ensure a healthier future for all. You matter, and so does the impact you can make with us.

This internship supports the Data Science team and offers hands-on experience in data science and statistical analysis within clinical or biomedical research settings. Interns will contribute to the development of machine learning models, conduct experimental design and evaluation, and assist in summarizing results and drafting manuscripts. You will have the opportunity to work closely with staff across departments and contribute to impactful, high-quality research.

The American Heart Association’s Internship Program provides college students an opportunity for hands-on experience in various facets for individuals interested in gaining work experience with a non-profit, voluntary health organization.

The Association offers many resources to help you maintain work-life harmonization through your changing needs and life situations. To help you be successful, you will have access to Heart U, our award-winning corporate university, as well as training and support locally and through our National Center.

\#TheAHALife is more than a company culture; it is our way of life. It embodies our commitment to work-life harmonization and is guided by our core values where our employees can thrive both personally and professionally. Discover why you will Be Seen. Be Heard. Be Valued at the American Heart Association by following us on LinkedIn, Instagram, Facebook, X, and at heart.jobs.

Internship Overview:
• Time Commitment: 25 hours per week
• Internship Duration: 9/8/25-12/5/25
• Location:Remote
• Salary: $23.00 per hour

Internship Outcomes:

Individuals participating in the internship program are provided with an opportunity to:
• Gain important and practical job skills to be successful in a non-profit environment.
• Opportunity to explore a career-path with a reputable voluntary health/service organization.
• Complete an internship that enriches your academic and professional resume as well as enriching your personal life by making a difference in the lives of others.

Responsibilities

Tasks could include things like the following:
• Retrieve, process, and clean large-scale biomedical data, build high-quality datasets.
• Design and develop machine learning models for clinical or biomedical research, with a focus on Large Language Models (LLMs), medical imaging, or multimodal AI.
• Conduct experimental design and evaluation, including statistical analysis, performance assessment, error analysis, and robustness testing.
• Collaborate with cross-functional teams, including clinicians, data scientists, and engineers, to refine research questions and interpret results.
• Contribute to scientific writing, including drafting manuscripts for peer-reviewed journals and preparing materials for presentations or conferences.
• Develop interactive data visualization tools to communicate insights clearly.

Qualifications
• Currently pursuing an MS or PhD degree in Computer Science, Biomedical Informatics, Engineering, Statistics, or a related quantitative field.
• Demonstrated experience with large-scale machine learning or foundation models, including training, fine-tuning, and evaluating LLMs (e.g., GPT, BERT) or vision models (e.g., CNNs, Vision Transformers.
• Strong programming skills in Python (or R), with experience in machine learning frameworks.
• In-depth knowledge of study design, data analysis, and statistical methodologies, with prior experience working with clinical or biomedical data (e.g., EHRs, images.
• Prior authorship or co-authorship of peer-reviewed publications is strongly preferred.
• Experience with interactive visualization tools (e.g., Plotly, Dash, D3.js, or React) is a plus.
• Excellent communication skills, with the ability to present results to both technical and non-technical audiences.
• Ability to deal professionally in a corporate or non-profit environment and assume responsibility for guiding projects and programs from inception through completion.
• Ability to work in a fast-paced, dynamic environment managing multiple priorities involving multiple entities.
• Intermediate to excellent proficiency in MS Word, Excel, Outlook and PowerPoint.
• Minimum availability of 20 hrs/wk, M-F between the hours of 8:00am-5:00pm.
• Required Equipment: Reliable WiFi Connection.
• Must be legally authorized to work in the United States for any employer without sponsorship, now or in the future. For any roles working remotely, the work must also be performed inside the United States, not in a foreign country.

Compensation & Benefits

The job application window is expected to close: August 1, 2025.

The American Heart Association invests in its people. Visit Rewards & Benefits to see more details.
• Compensation and Performance – Attracting talented, committed interns means offering competitive compensation, ongoing professional development and training, and an environment in which to work and grow. And we do.
• Professional Development – You can join one of our many Employee Resource Groups (ERG) or be a mentor/mentee in our professional mentoring program. HeartU is the Association’s national online university, with more than 100,000 resources designed to meet your needs and busy schedule.
• Healthcare Benefits – You will have the opportunity to participate in our Teladoc General Medical and Behavioral Health programs. We also provide access to our Employee Assistance Program (EAP) at no cost as a confidential program designed to assist employees and family members with personal issues that affect their relationships at home or at work.

Apply Today:

So, are you ready to intern for the largest voluntary health organization dedicated to fighting heart disease, stroke, and other cardiovascular diseases?

The American Heart Association’s 2028 Goal: Building on over 100 years of trusted leadership in cardiovascular and brain health, by 2028 the AHA will drive breakthroughs and implement proven solutions in science, policy, and care for healthier people and communities. The greatest discoveries in health must reach everyone where they are.

At American Heart Association | American Stroke Association, our mission is to be a relentless force for a world of longer, healthier lives, regardless of race, ethnicity, gender, gender identity, religion, age, language, sexual orientation, national origin and physical or cognitive abilities.

This position not a match with your skills? Click here to see other opportunities.

In accordance with local and state laws where applicable, qualified applicants with arrest or conviction records will be considered for employment.

EOE/Protected Veterans/Persons with Disabilities

\#AHAWAYUP, #LI-DNP

Join our Talent Community!

Join our Talent Community to receive updates on new opportunities and future events.

Default: Location : LocationUS-TX-Dallas

Posted Date57 minutes ago(7/9/2025 9:51 AM)

Requisition ID2025-16131

Job CategoryAdministrative Support

Position TypePart Time

Overview

Since our founding in 1924, we've cut cardiovascular disease deaths in half, but there is still so much more to do. To overcome today’s biggest health challenges and accelerate this progress, we need passionate individuals like you. Join our movement, be part of the progress, and help ensure a healthier future for all. You matter, and so does the impact you can make with us.

This internship supports the Data Science team and offers hands-on experience in data science and statistical analysis within clinical or biomedical research settings. Interns will contribute to the development of machine learning models, conduct experimental design and evaluation, and assist in summarizing results and drafting manuscripts. You will have the opportunity to work closely with staff across departments and contribute to impactful, high-quality research.

The American Heart Association’s Internship Program provides college students an opportunity for hands-on experience in various facets for individuals interested in gaining work experience with a non-profit, voluntary health organization.

The Association offers many resources to help you maintain work-life harmonization through your changing needs and life situations. To help you be successful, you will have access to Heart U, our award-winning corporate university, as well as training and support locally and through our National Center.

\#TheAHALife is more than a company culture; it is our way of life. It embodies our commitment to work-life harmonization and is guided by our core values where our employees can thrive both personally and professionally. Discover why you will Be Seen. Be Heard. Be Valued at the American Heart Association by following us on LinkedIn, Instagram, Facebook, X, and at heart.jobs.

Internship Overview:
• Time Commitment: 25 hours per week
• Internship Duration: 9/8/25-12/5/25
• Location:Remote
• Salary: $23.00 per hour

Internship Outcomes:

Individuals participating in the internship program are provided with an opportunity to:
• Gain important and practical job skills to be successful in a non-profit environment.
• Opportunity to explore a career-path with a reputable voluntary health/service organization.
• Complete an internship that enriches your academic and professional resume as well as enriching your personal life by making a difference in the lives of others.

Responsibilities

Tasks could include things like the following:
• Retrieve, process, and clean large-scale biomedical data, build high-quality datasets.
• Design and develop machine learning models for clinical or biomedical research, with a focus on Large Language Models (LLMs), medical imaging, or multimodal AI.
• Conduct experimental design and evaluation, including statistical analysis, performance assessment, error analysis, and robustness testing.
• Collaborate with cross-functional teams, including clinicians, data scientists, and engineers, to refine research questions and interpret results.
• Contribute to scientific writing, including drafting manuscripts for peer-reviewed journals and preparing materials for presentations or conferences.
• Develop interactive data visualization tools to communicate insights clearly.

Qualifications
• Currently pursuing an MS or PhD degree in Computer Science, Biomedical Informatics, Engineering, Statistics, or a related quantitative field.
• Demonstrated experience with large-scale machine learning or foundation models, including training, fine-tuning, and evaluating LLMs (e.g., GPT, BERT) or vision models (e.g., CNNs, Vision Transformers.
• Strong programming skills in Python (or R), with experience in machine learning frameworks.
• In-depth knowledge of study design, data analysis, and statistical methodologies, with prior experience working with clinical or biomedical data (e.g., EHRs, images.
• Prior authorship or co-authorship of peer-reviewed publications is strongly preferred.
• Experience with interactive visualization tools (e.g., Plotly, Dash, D3.js, or React) is a plus.
• Excellent communication skills, with the ability to present results to both technical and non-technical audiences.
• Ability to deal professionally in a corporate or non-profit environment and assume responsibility for guiding projects and programs from inception through completion.
• Ability to work in a fast-paced, dynamic environment managing multiple priorities involving multiple entities.
• Intermediate to excellent proficiency in MS Word, Excel, Outlook and PowerPoint.
• Minimum availability of 20 hrs/wk, M-F between the hours of 8:00am-5:00pm.
• Required Equipment: Reliable WiFi Connection.
• Must be legally authorized to work in the United States for any employer without sponsorship, now or in the future. For any roles working remotely, the work must also be performed inside the United States, not in a foreign country.

Compensation & Benefits

The job application window is expected to close: August 1, 2025.

The American Heart Association invests in its people. Visit Rewards & Benefits to see more details.
• Compensation and Performance – Attracting talented, committed interns means offering competitive compensation, ongoing professional development and training, and an environment in which to work and grow. And we do.
• Professional Development – You can join one of our many Employee Resource Groups (ERG) or be a mentor/mentee in our professional mentoring program. HeartU is the Association’s national online university, with more than 100,000 resources designed to meet your needs and busy schedule.
• Healthcare Benefits – You will have the opportunity to participate in our Teladoc General Medical and Behavioral Health programs. We also provide access to our Employee Assistance Program (EAP) at no cost as a confidential program designed to assist employees and family members with personal issues that affect their relationships at home or at work.

Apply Today:

So, are you ready to intern for the largest voluntary health organization dedicated to fighting heart disease, stroke, and other cardiovascular diseases?

The American Heart Association’s 2028 Goal: Building on over 100 years of trusted leadership in cardiovascular and brain health, by 2028 the AHA will drive breakthroughs and implement proven solutions in science, policy, and care for healthier people and communities. The greatest discoveries in health must reach everyone where they are.

At American Heart Association | American Stroke Association, our mission is to be a relentless force for a world of longer, healthier lives, regardless of race, ethnicity, gender, gender identity, religion, age, language, sexual orientation, national origin and physical or cognitive abilities.

This position not a match with your skills? Click here to see other opportunities.

In accordance with local and state laws where applicable, qualified applicants with arrest or conviction records will be considered for employment.

EOE/Protected Veterans/Persons with Disabilities

\#AHAWAYUP, #LI-DNP

Join our Talent Community!

Join our Talent Community to receive updates on new opportunities and future events.

Default: Location : LocationUS-TX-Dallas

Posted Date57 minutes ago(7/9/2025 9:51 AM)

Requisition ID2025-16131

Job CategoryAdministrative Support

Position TypePart Time",2025-07-09T00:00:00.000Z,2025-07-25,"['Currently pursuing an MS or PhD degree in Computer Science, Biomedical Informatics, Engineering, Statistics, or a related quantitative field', 'Demonstrated experience with large-scale machine learning or foundation models, including training, fine-tuning, and evaluating LLMs (e.g., GPT, BERT) or vision models (e.g., CNNs, Vision Transformers', 'Strong programming skills in Python (or R), with experience in machine learning frameworks', 'In-depth knowledge of study design, data analysis, and statistical methodologies, with prior experience working with clinical or biomedical data (e.g., EHRs, images', 'Excellent communication skills, with the ability to present results to both technical and non-technical audiences', 'Ability to deal professionally in a corporate or non-profit environment and assume responsibility for guiding projects and programs from inception through completion', 'Ability to work in a fast-paced, dynamic environment managing multiple priorities involving multiple entities', 'Intermediate to excellent proficiency in MS Word, Excel, Outlook and PowerPoint', 'Minimum availability of 20 hrs/wk, M-F between the hours of 8:00am-5:00pm', 'Required Equipment: Reliable WiFi Connection', 'Must be legally authorized to work in the United States for any employer without sponsorship, now or in the future', 'For any roles working remotely, the work must also be performed inside the United States, not in a foreign country', 'Gain important and practical job skills to be successful in a non-profit environment', 'Opportunity to explore a career-path with a reputable voluntary health/service organization', 'Currently pursuing an MS or PhD degree in Computer Science, Biomedical Informatics, Engineering, Statistics, or a related quantitative field', 'Demonstrated experience with large-scale machine learning or foundation models, including training, fine-tuning, and evaluating LLMs (e.g., GPT, BERT) or vision models (e.g., CNNs, Vision Transformers', 'Strong programming skills in Python (or R), with experience in machine learning frameworks', 'In-depth knowledge of study design, data analysis, and statistical methodologies, with prior experience working with clinical or biomedical data (e.g., EHRs, images', 'Excellent communication skills, with the ability to present results to both technical and non-technical audiences', 'Ability to deal professionally in a corporate or non-profit environment and assume responsibility for guiding projects and programs from inception through completion', 'Ability to work in a fast-paced, dynamic environment managing multiple priorities involving multiple entities', 'Intermediate to excellent proficiency in MS Word, Excel, Outlook and PowerPoint', 'Minimum availability of 20 hrs/wk, M-F between the hours of 8:00am-5:00pm', 'Required Equipment: Reliable WiFi Connection', 'Must be legally authorized to work in the United States for any employer without sponsorship, now or in the future', 'For any roles working remotely, the work must also be performed inside the United States, not in a foreign country']","['This internship supports the Data Science team and offers hands-on experience in data science and statistical analysis within clinical or biomedical research settings', 'Interns will contribute to the development of machine learning models, conduct experimental design and evaluation, and assist in summarizing results and drafting manuscripts', 'You will have the opportunity to work closely with staff across departments and contribute to impactful, high-quality research', 'Retrieve, process, and clean large-scale biomedical data, build high-quality datasets', 'Design and develop machine learning models for clinical or biomedical research, with a focus on Large Language Models (LLMs), medical imaging, or multimodal AI', 'Conduct experimental design and evaluation, including statistical analysis, performance assessment, error analysis, and robustness testing', 'Collaborate with cross-functional teams, including clinicians, data scientists, and engineers, to refine research questions and interpret results', 'Contribute to scientific writing, including drafting manuscripts for peer-reviewed journals and preparing materials for presentations or conferences', 'Develop interactive data visualization tools to communicate insights clearly', 'This internship supports the Data Science team and offers hands-on experience in data science and statistical analysis within clinical or biomedical research settings', 'Interns will contribute to the development of machine learning models, conduct experimental design and evaluation, and assist in summarizing results and drafting manuscripts', 'You will have the opportunity to work closely with staff across departments and contribute to impactful, high-quality research', 'Retrieve, process, and clean large-scale biomedical data, build high-quality datasets', 'Design and develop machine learning models for clinical or biomedical research, with a focus on Large Language Models (LLMs), medical imaging, or multimodal AI', 'Conduct experimental design and evaluation, including statistical analysis, performance assessment, error analysis, and robustness testing', 'Collaborate with cross-functional teams, including clinicians, data scientists, and engineers, to refine research questions and interpret results', 'Contribute to scientific writing, including drafting manuscripts for peer-reviewed journals and preparing materials for presentations or conferences', 'Develop interactive data visualization tools to communicate insights clearly']",True,"['Large Language Models', 'Vision Transformers', 'Multimodal AI']","Large Language Models: Designing, training, fine-tuning, and evaluating foundation models such as GPT and BERT for clinical or biomedical research applications.; Vision Transformers: Utilizing vision transformer models as part of machine learning approaches for medical imaging and multimodal AI research.; Multimodal AI: Focusing on AI models that integrate multiple data modalities, including medical imaging and large language models, to advance clinical or biomedical research.","['Machine Learning Models', 'Statistical Analysis', 'Data Processing and Cleaning', 'Study Design', 'Programming in Python or R', 'Interactive Data Visualization Tools']","Machine Learning Models: Design and development of machine learning models for clinical or biomedical research, including training, fine-tuning, and evaluation of models such as CNNs and other vision models.; Statistical Analysis: Conducting experimental design and evaluation involving statistical methodologies, performance assessment, error analysis, and robustness testing within clinical or biomedical research.; Data Processing and Cleaning: Retrieving, processing, and cleaning large-scale biomedical data to build high-quality datasets for research purposes.; Study Design: Applying in-depth knowledge of study design to support clinical or biomedical data analysis and research.; Programming in Python or R: Utilizing strong programming skills in Python or R, including experience with machine learning frameworks, to develop and implement data science and machine learning solutions.; Interactive Data Visualization Tools: Developing interactive visualization tools using technologies such as Plotly, Dash, D3.js, or React to communicate data insights clearly."
Ehv1fZjmJt__2icEAAAAAA==,"Associate Director, Data Scientist & Data Operations (Washington) at Eisai US Washington DC","Associate Director, Data Scientist & Data Operations (Washington) job at Eisai US. Washington DC. Associate Director, Data Scientist & Data Operations

Join to apply for the Associate Director, Data Scientist & Data Operations role at Eisai US .

At Eisai, our mission is to satisfy unmet medical needs and enhance healthcare benefits for patients, families, and caregivers. We are a growing pharmaceutical company focused on neurology and oncology, emphasizing research and development. Our history includes developing innovative medicines, notably the world's most widely-used treatment for Alzheimer’s disease. As we expand, we seek motivated individuals eager to make a difference in a fast-paced environment.

Role Overview: The Data Operations Group at Eisai is seeking an Associate Director - Data Scientist/Programmer to develop AI-powered dashboards. The Data Scientist will collaborate with Data Operations and Biostatisticians to support projects at various development stages, providing actionable insights for critical business initiatives.

This position can be office-based (hybrid) in Nutley, NJ, or remote.
Responsibilities
• Data Extraction & Analysis: Manipulate complex datasets to generate reports, charts, and graphs, analyzing for outliers, root causes, and correlations. Propose solutions to optimize outcomes.
• AI-Driven Data Preparation: Utilize AI and machine learning for automated data prep, especially for dynamic visualizations in Power BI.
• Natural Language Processing & LLM: Apply LLM and NLP techniques to generate insights and infographics.
• Data Preparation for Analysis: Clean datasets, handle missing values, and remove outliers for accurate modeling.
• Insight Generation for Drug Discovery: Identify patterns to support drug discovery processes.
• Data Integration: Combine diverse data sources for comprehensive analysis.
• Model Training & Data Quality: Ensure high-quality data for predictive models.
• Communication of Findings: Present insights clearly to stakeholders.
• Team Collaboration: Work with data scientists, biostatisticians, and data standards teams.
• Data Visualization: Convey complex data through visualizations, reports, and dashboards.
Qualifications
• Master’s degree in Computer Science or related field with research experience.
• Expertise in data modeling techniques.
• Proficiency in Python or R, with strong data analysis skills.
• Experience with visualization tools like Tableau or matplotlib.
• Strong problem-solving and project management skills.
• Excellent communication skills for technical and non-technical audiences.

Salary & Benefits: The base salary range is $171,100 - $224,600, with eligibility for annual and long-term incentives. Benefits details are available on our website. Eisai is an equal opportunity employer committed to diversity and inclusion.
#J-18808-Ljbffr",2025-07-20T00:00:00.000Z,2025-07-25,"['Master’s degree in Computer Science or related field with research experience', 'Expertise in data modeling techniques', 'Proficiency in Python or R, with strong data analysis skills', 'Experience with visualization tools like Tableau or matplotlib', 'Strong problem-solving and project management skills', 'Excellent communication skills for technical and non-technical audiences']","['Role Overview: The Data Operations Group at Eisai is seeking an Associate Director - Data Scientist/Programmer to develop AI-powered dashboards', 'The Data Scientist will collaborate with Data Operations and Biostatisticians to support projects at various development stages, providing actionable insights for critical business initiatives', 'Data Extraction & Analysis: Manipulate complex datasets to generate reports, charts, and graphs, analyzing for outliers, root causes, and correlations', 'Propose solutions to optimize outcomes', 'AI-Driven Data Preparation: Utilize AI and machine learning for automated data prep, especially for dynamic visualizations in Power BI', 'Natural Language Processing & LLM: Apply LLM and NLP techniques to generate insights and infographics', 'Data Preparation for Analysis: Clean datasets, handle missing values, and remove outliers for accurate modeling', 'Insight Generation for Drug Discovery: Identify patterns to support drug discovery processes', 'Data Integration: Combine diverse data sources for comprehensive analysis', 'Model Training & Data Quality: Ensure high-quality data for predictive models', 'Communication of Findings: Present insights clearly to stakeholders', 'Team Collaboration: Work with data scientists, biostatisticians, and data standards teams', 'Data Visualization: Convey complex data through visualizations, reports, and dashboards']",True,"['Large Language Models', 'Natural Language Processing', 'AI-Driven Data Preparation']","Large Language Models: Apply LLM techniques to generate insights and infographics as part of data analysis and visualization.; Natural Language Processing: Use NLP methods in conjunction with LLMs to extract insights and support AI-powered dashboard development.; AI-Driven Data Preparation: Leverage AI and machine learning techniques to automate data preparation, particularly for dynamic visualizations in Power BI.","['Data Extraction and Analysis', 'Data Preparation', 'Data Integration', 'Data Modeling Techniques', 'Predictive Modeling', 'Insight Generation', 'Data Visualization', 'Programming with Python or R']","Data Extraction and Analysis: Manipulate complex datasets to generate reports, charts, and graphs, analyzing for outliers, root causes, and correlations to propose solutions that optimize outcomes.; Data Preparation: Clean datasets, handle missing values, and remove outliers to ensure accurate modeling and high-quality data for predictive models.; Data Integration: Combine diverse data sources to enable comprehensive analysis supporting various projects.; Data Modeling Techniques: Apply expertise in data modeling to support analysis and predictive modeling efforts.; Predictive Modeling: Ensure data quality and train models to generate actionable insights for critical business initiatives.; Insight Generation: Identify patterns in data to support drug discovery processes and provide actionable insights.; Data Visualization: Develop dashboards, reports, and visualizations using tools like Tableau and matplotlib to clearly communicate complex data.; Programming with Python or R: Utilize Python or R programming languages for data analysis and manipulation."
bP4L-99QPwarZkutAAAAAA==,"Director, Data Science - Model Risk","Director, Data Science - Model Risk

Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making.

As a Data Science Leader at Capital One, you'll be part of a team that's leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives.

In Capital One's Model Risk Office, we defend the company against model failures and find new ways of making better decisions with models. We use our statistics, software engineering, and business expertise to drive the best outcomes in both Risk Management and the Enterprise. We understand that we can't prepare for tomorrow by focusing on today, so we invest in the future: investing in new skills, building better tools, and maintaining a network of trusted partners. We learn from past mistakes, and develop increasingly powerful techniques to avoid their repetition.

In this role, you will:
• Partner with a cross-functional team of data scientists, data analysts, and business analysts to drive great decisions through modeling
• Distill the details of complex interconnected modeling systems to influence senior business leaders on model strategy, business use, and risks
• Assess, challenge, and at times defend state-of-the-art decision-making systems to internal and regulatory partners
• Shape our practice of building machine learning models, from design through training, evaluation, validation, and implementation
• Oversee development of benchmark and challenger models to stress test critical modeling decisions

The Ideal Candidate is:
• A leader. You challenge conventional thinking and work with stakeholders to identify and improve the status quo.
• Creative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You're not afraid to share a new idea.
• Technical. You're comfortable with open-source languages and are passionate about developing further. You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms.
• Statistically-minded. You've built models, validated them, and backtested them. You know how to interpret a confusion matrix or a ROC curve. You have experience with clustering, classification, sentiment analysis, time series, and deep learning.

Basic Qualifications:
• Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:
• A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 9 years of experience performing data analytics
• A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 7 years of experience performing data analytics
• A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 4 years of experience performing data analytics
• At least 4 years of experience leveraging open source programming languages for large scale data analysis
• At least 4 years of experience working with machine learning
• At least 4 years of experience utilizing relational databases

Preferred Qualifications:
• PhD in ""STEM"" field (Science, Technology, Engineering, or Mathematics) plus 5 years of experience in data analytics
• At least 5 years of experience in Python, Scala, or R for large scale data analysis
• At least 5 years of experience with machine learning
• At least 1 year of experience working with AWS

Capital One will consider sponsoring a new qualified applicant for employment authorization for this position.

The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.

Chicago, IL: $239,900 - $273,800 for Dir, Data Science

McLean, VA: $263,900 - $301,200 for Dir, Data Science

New York, NY: $287,800 - $328,500 for Dir, Data Science

Richmond, VA: $239,900 - $273,800 for Dir, Data Science

Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate's offer letter.

This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.

Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at theCapital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.

This role is expected to accept applications for a minimum of 5 business days.

No agencies please. Capital One is an equal opportunity employer (EOE, including disability/vet) committed to non-discrimination in compliance with applicable federal, state, and local laws. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City's Fair Chance Act; Philadelphia's Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",,2025-07-25,"['A leader', 'You thrive on bringing definition to big, undefined problems', 'You love asking questions and pushing hard to find answers', ""You're comfortable with open-source languages and are passionate about developing further"", 'You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms', 'Statistically-minded', 'You know how to interpret a confusion matrix or a ROC curve', 'You have experience with clustering, classification, sentiment analysis, time series, and deep learning', 'Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:', ""A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 9 years of experience performing data analytics"", ""A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 7 years of experience performing data analytics"", 'A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 4 years of experience performing data analytics', 'At least 4 years of experience leveraging open source programming languages for large scale data analysis', 'At least 4 years of experience working with machine learning', 'At least 4 years of experience utilizing relational databases']","['Partner with a cross-functional team of data scientists, data analysts, and business analysts to drive great decisions through modeling', 'Distill the details of complex interconnected modeling systems to influence senior business leaders on model strategy, business use, and risks', 'Assess, challenge, and at times defend state-of-the-art decision-making systems to internal and regulatory partners', 'Shape our practice of building machine learning models, from design through training, evaluation, validation, and implementation', 'Oversee development of benchmark and challenger models to stress test critical modeling decisions', 'You challenge conventional thinking and work with stakeholders to identify and improve the status quo', 'Creative', ""You've built models, validated them, and backtested them""]",True,[],,"['Statistical Modeling', 'Relational Databases', 'Machine Learning Models', 'Model Validation and Backtesting', 'Classification and Clustering', 'Sentiment Analysis', 'Time Series Analysis', 'Deep Learning', 'Open Source Programming Languages', 'Cloud Computing Platforms', 'Confusion Matrix and ROC Curve Interpretation', 'Benchmark and Challenger Models']","Statistical Modeling: Used to personalize credit card offers and drive data-driven decision-making in financial services.; Relational Databases: Utilized for managing and querying large-scale customer data to support analytics and modeling efforts.; Machine Learning Models: Built, trained, evaluated, validated, and implemented to improve decision-making and model risk management.; Model Validation and Backtesting: Performed to assess model performance, ensure reliability, and defend models to internal and regulatory partners.; Classification and Clustering: Applied as part of modeling techniques to segment data and predict outcomes relevant to business decisions.; Sentiment Analysis: Used as a data science technique to analyze textual data for insights relevant to model development.; Time Series Analysis: Employed to analyze temporal data patterns for forecasting and risk assessment.; Deep Learning: Experience required in applying deep learning methods as part of advanced modeling techniques.; Open Source Programming Languages: Leveraged for large-scale data analysis and development of data science solutions, including Python, Scala, and R.; Cloud Computing Platforms: Used to support scalable data science workflows and model development in a cloud environment.; Confusion Matrix and ROC Curve Interpretation: Used to evaluate classification model performance and inform decision-making.; Benchmark and Challenger Models: Developed to stress test critical modeling decisions and improve model robustness."
OyvMi6BztJoRyLuVAAAAAA==,Data Scientist - Civil Engineering,"Overview

ABOUT THE POSITION

Are you a dedicated Data Scientist looking to make a significant impact through cutting-edge technology and data-driven approaches? Join VHB's innovative Technology Enablement Team in a corporate Data Science position, where you'll work with a diverse team of experts, including engineers, scientists, planners, designers, and technologists. At VHB, we collaborate with a broad range of clients-from government agencies to private businesses in the transportation, real estate, institutional, and federal industries-working collectively to enhance communities, stimulate economic growth, and promote environmental sustainability.

In this role, your skills in data analysis and modeling will be crucial in uncovering valuable insights and providing VHB with a competitive advantage. Start a fulfilling career with VHB, where your expertise will aid in enhancing mobility, community livability, and sustainable development. Apply now and help shape the future with VHB!

Key Responsibilities
• Lead big data-related projects across multiple areas including planning, transportation safety, planning, traffic operations, and transit/rail. Develop and maintain dashboards and websites that support large databases, facilitate complex search queries, and enhance various business functions.
• Produce innovative solutions driven by exploratory data analysis from complex and high dimensional datasets that are both qualitative and quantitative across the AEC industry.
• Mines and analyzes highly complex structured/unstructured data sets using highly advanced statistical methods for use in data-driven decision making.
• Strategizes, identifies, and implements new uses for existing data sources and unique opportunities to locate and collect new data; designs, modifies, and builds new data processes, and builds large, complex data sets ensuring data integrity and statistical accuracy.
• Extracts and identifies relevant information from databases and systems.
• Recognizes patterns, identifies opportunities, poses business questions, and makes valuable discoveries leading to prototype development and product improvement.
• Employs sophisticated analytical methods, machine learning, and statistical methods to prepare data for use in predictive and prescriptive modeling. Designs, develops, tests, validates, and analyzes models and advanced algorithms that lead to optimal value extraction from the data.
• Interprets results, predicts future data trends and other data foresights, and proposes strategic business solutions.
• Writes and distributes findings. Using strong business acumen, communicates data insights, foresights, and strategic solutions to both business and IT leaders through effective data visualizations and reports to influence how the organization approaches and meets business challenges. Recommends strategic cost-effective changes to existing business practices.
• Develops and applies customized algorithms or models to key business metrics with the goal of improving operations or answering business questions. Implements automated processes for efficiently producing scale models.
• May leads a project team of less experienced data staff and GIS analysts. Directs and monitors the work of less experience staff. Provides direction and support to ensure departmental effectiveness and efficiency. Orients and trains team members. Provides input into evaluating performance. May act as a supervisor in the absence of an actual supervisor.
• Trains the data management team on new or updated procedures.
• Writes and implements quality procedures.

Skills and Attributes
• Ability to implement common data management and reporting technologies, including the basics of columnar databases, unstructured data, and data visualization in Esri products (ArcGIS Online), Power BI or other tools.
• Active listening skills with the ability to breakdown complex problems or processes to solve problems internally and externally for clients.
• Skilled in strategic thinking, problem solving and connecting disparate dots.
• Familiar with Low-Code/No-Code experience, MicrosoftPowerApps, Databricks, ElasticSearch, MongoDB, Tableau, Azure, GTFS data.
• Familiarity with database management systems, such as SQL Server or Oracle
• Exposure with project management and task management and leading portions of a project and/or budget.
• Attention to detail and ability to meet tight deadlines.
• Stays updated on new and innovative development technologies and workflow improvements.

Minimum Qualifications
• Minimum of 5+ years of experience with advanced analytics in a professional setting.
• Master's degree in Statistics, Mathematics, or equivalent discipline; or equivalent experience.
• Demonstrated experience working in Planning, Architecture, Engineering, or Construction is required with emphasis in providing services for transportation agencies and/or state and federal governments.
• Advanced knowledge of machine learning, data mining, statistical predictive modeling programming, simulation, and advanced mathematics.
• Understanding of parallelization, scalability, and complexity analysis.
• Extensive experience using many of the following technologies: Python (Pandas, NumPy, SciPy), R (tidyverse), SQL, Tableau, Power BI, advanced Microsoft Excel, machine learning, statistical analysis.
• Team oriented with ability to perform multiple tasks independently in a timely manner and collaborate effectively and positively with coworkers.
• Excellent ability to communicate effectively (both written and verbal) with all levels of Employees including non-technical staff.
• Ability to absorb new concepts quickly and a willingness to learn new skills and datasets within the AEC industry.
• Applicants must be legally authorized to work for VHB in the U.S. without employer sponsorship.

The base salary range for this position is $110,025 - 138,050 for the Washington, DC and New York location. This offer is determined based on a number of job-related factors including internal comparators, skills, education, training, credentials, experience, scope and complexity of role responsibilities and geographic location. In addition, VHB offers a holistic benefits package which can be found here.

We are VHB! We're an inspired and innovative team of engineers, scientists, planners, and designers who partner with clients in the transportation, real estate, institutional, and energy industries, as well as federal, state, and local governments. Our work helps improve mobility, enhance communities, and contribute to economic vitality. We do this while balancing development and infrastructure needs with stewardship of our environment.

Our people make us great! VHB provides a differentiating employee experience, which includes:
• Diverse and inclusive culture of collaboration and innovation
• Opportunity to work on complex, transformational projects
• Community and social responsibility as sustainable stewards
• Focus on learning, development, and career growth
• Best-in-class benefits, including flexible, hybrid workplace

We are consistently rated one of the top AEC firms to work for across our 30+ offices on the East Coast. We're growing, and we hope you'll join us!

VHB is a proud Equal Opportunity Employer. Since our founding, we have intentionally fostered a culture of inclusion and belonging, supported by deep-rooted core values, one of which is diversity. Qualified applicants will receive consideration for employment without regard to race, color, religion, gender, sex, sexual orientation, gender identity/expression, national origin, disability, protected veteran status, or other characteristics protected by law.

#LI-LO1

#LI-Hybrid
Employment Type: FULL_TIME",,2025-07-25,"['Ability to implement common data management and reporting technologies, including the basics of columnar databases, unstructured data, and data visualization in Esri products (ArcGIS Online), Power BI or other tools', 'Active listening skills with the ability to breakdown complex problems or processes to solve problems internally and externally for clients', 'Skilled in strategic thinking, problem solving and connecting disparate dots', 'Familiar with Low-Code/No-Code experience, MicrosoftPowerApps, Databricks, ElasticSearch, MongoDB, Tableau, Azure, GTFS data', 'Familiarity with database management systems, such as SQL Server or Oracle', 'Exposure with project management and task management and leading portions of a project and/or budget', 'Attention to detail and ability to meet tight deadlines', 'Stays updated on new and innovative development technologies and workflow improvements', 'Minimum of 5+ years of experience with advanced analytics in a professional setting', ""Master's degree in Statistics, Mathematics, or equivalent discipline; or equivalent experience"", 'Demonstrated experience working in Planning, Architecture, Engineering, or Construction is required with emphasis in providing services for transportation agencies and/or state and federal governments', 'Advanced knowledge of machine learning, data mining, statistical predictive modeling programming, simulation, and advanced mathematics', 'Understanding of parallelization, scalability, and complexity analysis', 'Extensive experience using many of the following technologies: Python (Pandas, NumPy, SciPy), R (tidyverse), SQL, Tableau, Power BI, advanced Microsoft Excel, machine learning, statistical analysis', 'Team oriented with ability to perform multiple tasks independently in a timely manner and collaborate effectively and positively with coworkers', 'Excellent ability to communicate effectively (both written and verbal) with all levels of Employees including non-technical staff', 'Ability to absorb new concepts quickly and a willingness to learn new skills and datasets within the AEC industry', 'Applicants must be legally authorized to work for VHB in the U.S. without employer sponsorship', 'Opportunity to work on complex, transformational projects']","['In this role, your skills in data analysis and modeling will be crucial in uncovering valuable insights and providing VHB with a competitive advantage', 'Lead big data-related projects across multiple areas including planning, transportation safety, planning, traffic operations, and transit/rail', 'Develop and maintain dashboards and websites that support large databases, facilitate complex search queries, and enhance various business functions', 'Produce innovative solutions driven by exploratory data analysis from complex and high dimensional datasets that are both qualitative and quantitative across the AEC industry', 'Mines and analyzes highly complex structured/unstructured data sets using highly advanced statistical methods for use in data-driven decision making', 'Strategizes, identifies, and implements new uses for existing data sources and unique opportunities to locate and collect new data; designs, modifies, and builds new data processes, and builds large, complex data sets ensuring data integrity and statistical accuracy', 'Extracts and identifies relevant information from databases and systems', 'Recognizes patterns, identifies opportunities, poses business questions, and makes valuable discoveries leading to prototype development and product improvement', 'Employs sophisticated analytical methods, machine learning, and statistical methods to prepare data for use in predictive and prescriptive modeling', 'Designs, develops, tests, validates, and analyzes models and advanced algorithms that lead to optimal value extraction from the data', 'Interprets results, predicts future data trends and other data foresights, and proposes strategic business solutions', 'Writes and distributes findings', 'Using strong business acumen, communicates data insights, foresights, and strategic solutions to both business and IT leaders through effective data visualizations and reports to influence how the organization approaches and meets business challenges', 'Recommends strategic cost-effective changes to existing business practices', 'Develops and applies customized algorithms or models to key business metrics with the goal of improving operations or answering business questions', 'Implements automated processes for efficiently producing scale models', 'May leads a project team of less experienced data staff and GIS analysts', 'Directs and monitors the work of less experience staff', 'Provides direction and support to ensure departmental effectiveness and efficiency', 'Orients and trains team members', 'Provides input into evaluating performance', 'May act as a supervisor in the absence of an actual supervisor', 'Trains the data management team on new or updated procedures', 'Writes and implements quality procedures', 'Community and social responsibility as sustainable stewards']",True,[],,"['Exploratory Data Analysis', 'Big Data', 'Dashboards and Data Visualization', 'Structured and Unstructured Data', 'Data Integration and Data Pipelines', 'Pattern Recognition and Business Question Formulation', 'Machine Learning', 'Predictive and Prescriptive Modeling', 'Statistical Methods and Advanced Mathematics', 'Python (Pandas, NumPy, SciPy)', 'R (tidyverse)', 'SQL and Database Management Systems', 'Low-Code/No-Code Platforms', 'Databricks', 'ElasticSearch and MongoDB', 'GTFS Data', 'Data Quality and Process Automation', 'Data Communication and Reporting']","Exploratory Data Analysis: Used to produce innovative solutions from complex and high dimensional qualitative and quantitative datasets across the AEC industry.; Big Data: Leading projects involving large datasets across planning, transportation safety, traffic operations, and transit/rail to support business functions and decision making.; Dashboards and Data Visualization: Developing and maintaining dashboards and websites that support large databases and facilitate complex search queries, using tools like Power BI, Tableau, and Esri products (ArcGIS Online) to communicate insights and influence business and IT leaders.; Structured and Unstructured Data: Mining and analyzing highly complex structured and unstructured datasets using advanced statistical methods for data-driven decision making.; Data Integration and Data Pipelines: Designing, modifying, and building new data processes and large, complex datasets ensuring data integrity and statistical accuracy, including extracting relevant information from databases and systems.; Pattern Recognition and Business Question Formulation: Recognizing patterns, identifying opportunities, posing business questions, and making discoveries that lead to prototype development and product improvement.; Machine Learning: Employing sophisticated analytical and machine learning methods to prepare data for predictive and prescriptive modeling, including designing, developing, testing, validating, and analyzing models and advanced algorithms to extract optimal value from data.; Predictive and Prescriptive Modeling: Using machine learning and statistical methods to predict future data trends and provide strategic business solutions.; Statistical Methods and Advanced Mathematics: Applying advanced statistical predictive modeling, simulation, and mathematics to analyze data and support decision making.; Python (Pandas, NumPy, SciPy): Utilizing Python libraries for data manipulation, numerical computation, and scientific computing in analytics and modeling tasks.; R (tidyverse): Using R and the tidyverse collection for data analysis and statistical modeling.; SQL and Database Management Systems: Working with SQL Server, Oracle, and other database management systems to manage and query data.; Low-Code/No-Code Platforms: Familiarity with platforms like Microsoft PowerApps to support data management and application development.; Databricks: Using Databricks for big data processing and analytics.; ElasticSearch and MongoDB: Employing ElasticSearch for search and analytics and MongoDB for handling unstructured data.; GTFS Data: Working with General Transit Feed Specification data relevant to transportation planning and analysis.; Data Quality and Process Automation: Implementing automated processes for efficient model production and writing quality procedures to ensure data and process integrity.; Data Communication and Reporting: Communicating data insights, foresights, and strategic solutions effectively to technical and non-technical stakeholders through reports and visualizations."
R2QB7JrLkZh-8nJ3AAAAAA==,"Intern, Data Science-Remote","Overview

Since our founding in 1924, we've cut cardiovascular disease deaths in half, but there is still so much more to do. To overcome today’s biggest health challenges and accelerate this progress, we need passionate individuals like you. Join our movement, be part of the progress, and help ensure a healthier future for all. You matter, and so does the impact you can make with us.

This internship supports the Data Science team and offers hands-on experience in data science and statistical analysis within clinical or biomedical research settings. Interns will contribute to the development of machine learning models, conduct experimental design and evaluation, and assist in summarizing results and drafting manuscripts. You will have the opportunity to work closely with staff across departments and contribute to impactful, high-quality research.

The American Heart Association’s Internship Program provides college students an opportunity for hands-on experience in various facets for individuals interested in gaining work experience with a non-profit, voluntary health organization.

The Association offers many resources to help you maintain work-life harmonization through your changing needs and life situations. To help you be successful, you will have access to Heart U, our award-winning corporate university, as well as training and support locally and through our National Center.

\#TheAHALife is more than a company culture; it is our way of life. It embodies our commitment to work-life harmonization and is guided by our core values where our employees can thrive both personally and professionally. Discover why you will Be Seen. Be Heard. Be Valued at the American Heart Association by following us on LinkedIn, Instagram, Facebook, X, and at heart.jobs.

Internship Overview:
• Time Commitment: 25 hours per week
• Internship Duration: 9/8/25-12/5/25
• Location:Remote
• Salary: $23.00 per hour

Internship Outcomes:

Individuals participating in the internship program are provided with an opportunity to:
• Gain important and practical job skills to be successful in a non-profit environment.
• Opportunity to explore a career-path with a reputable voluntary health/service organization.
• Complete an internship that enriches your academic and professional resume as well as enriching your personal life by making a difference in the lives of others.

Responsibilities

Tasks could include things like the following:
• Retrieve, process, and clean large-scale biomedical data, build high-quality datasets.
• Design and develop machine learning models for clinical or biomedical research, with a focus on Large Language Models (LLMs), medical imaging, or multimodal AI.
• Conduct experimental design and evaluation, including statistical analysis, performance assessment, error analysis, and robustness testing.
• Collaborate with cross-functional teams, including clinicians, data scientists, and engineers, to refine research questions and interpret results.
• Contribute to scientific writing, including drafting manuscripts for peer-reviewed journals and preparing materials for presentations or conferences.
• Develop interactive data visualization tools to communicate insights clearly.

Qualifications
• Currently pursuing an MS or PhD degree in Computer Science, Biomedical Informatics, Engineering, Statistics, or a related quantitative field.
• Demonstrated experience with large-scale machine learning or foundation models, including training, fine-tuning, and evaluating LLMs (e.g., GPT, BERT) or vision models (e.g., CNNs, Vision Transformers.
• Strong programming skills in Python (or R), with experience in machine learning frameworks.
• In-depth knowledge of study design, data analysis, and statistical methodologies, with prior experience working with clinical or biomedical data (e.g., EHRs, images.
• Prior authorship or co-authorship of peer-reviewed publications is strongly preferred.
• Experience with interactive visualization tools (e.g., Plotly, Dash, D3.js, or React) is a plus.
• Excellent communication skills, with the ability to present results to both technical and non-technical audiences.
• Ability to deal professionally in a corporate or non-profit environment and assume responsibility for guiding projects and programs from inception through completion.
• Ability to work in a fast-paced, dynamic environment managing multiple priorities involving multiple entities.
• Intermediate to excellent proficiency in MS Word, Excel, Outlook and PowerPoint.
• Minimum availability of 20 hrs/wk, M-F between the hours of 8:00am-5:00pm.
• Required Equipment: Reliable WiFi Connection.
• Must be legally authorized to work in the United States for any employer without sponsorship, now or in the future. For any roles working remotely, the work must also be performed inside the United States, not in a foreign country.

Compensation & Benefits

The job application window is expected to close: August 1, 2025.

The American Heart Association invests in its people. Visit Rewards & Benefits to see more details.
• Compensation and Performance – Attracting talented, committed interns means offering competitive compensation, ongoing professional development and training, and an environment in which to work and grow. And we do.
• Professional Development – You can join one of our many Employee Resource Groups (ERG) or be a mentor/mentee in our professional mentoring program. HeartU is the Association’s national online university, with more than 100,000 resources designed to meet your needs and busy schedule.
• Healthcare Benefits – You will have the opportunity to participate in our Teladoc General Medical and Behavioral Health programs. We also provide access to our Employee Assistance Program (EAP) at no cost as a confidential program designed to assist employees and family members with personal issues that affect their relationships at home or at work.

Apply Today:

So, are you ready to intern for the largest voluntary health organization dedicated to fighting heart disease, stroke, and other cardiovascular diseases?

The American Heart Association’s 2028 Goal: Building on over 100 years of trusted leadership in cardiovascular and brain health, by 2028 the AHA will drive breakthroughs and implement proven solutions in science, policy, and care for healthier people and communities. The greatest discoveries in health must reach everyone where they are.

At American Heart Association | American Stroke Association, our mission is to be a relentless force for a world of longer, healthier lives, regardless of race, ethnicity, gender, gender identity, religion, age, language, sexual orientation, national origin and physical or cognitive abilities.

This position not a match with your skills? Click here to see other opportunities.

In accordance with local and state laws where applicable, qualified applicants with arrest or conviction records will be considered for employment.

EOE/Protected Veterans/Persons with Disabilities

\#AHAWAYUP, #LI-DNP

Join our Talent Community!

Join our Talent Community to receive updates on new opportunities and future events.

Default: Location : LocationUS-TX-Dallas

Posted Date57 minutes ago(7/9/2025 9:51 AM)

Requisition ID2025-16131

Job CategoryAdministrative Support

Position TypePart Time

Overview

Since our founding in 1924, we've cut cardiovascular disease deaths in half, but there is still so much more to do. To overcome today’s biggest health challenges and accelerate this progress, we need passionate individuals like you. Join our movement, be part of the progress, and help ensure a healthier future for all. You matter, and so does the impact you can make with us.

This internship supports the Data Science team and offers hands-on experience in data science and statistical analysis within clinical or biomedical research settings. Interns will contribute to the development of machine learning models, conduct experimental design and evaluation, and assist in summarizing results and drafting manuscripts. You will have the opportunity to work closely with staff across departments and contribute to impactful, high-quality research.

The American Heart Association’s Internship Program provides college students an opportunity for hands-on experience in various facets for individuals interested in gaining work experience with a non-profit, voluntary health organization.

The Association offers many resources to help you maintain work-life harmonization through your changing needs and life situations. To help you be successful, you will have access to Heart U, our award-winning corporate university, as well as training and support locally and through our National Center.

\#TheAHALife is more than a company culture; it is our way of life. It embodies our commitment to work-life harmonization and is guided by our core values where our employees can thrive both personally and professionally. Discover why you will Be Seen. Be Heard. Be Valued at the American Heart Association by following us on LinkedIn, Instagram, Facebook, X, and at heart.jobs.

Internship Overview:
• Time Commitment: 25 hours per week
• Internship Duration: 9/8/25-12/5/25
• Location:Remote
• Salary: $23.00 per hour

Internship Outcomes:

Individuals participating in the internship program are provided with an opportunity to:
• Gain important and practical job skills to be successful in a non-profit environment.
• Opportunity to explore a career-path with a reputable voluntary health/service organization.
• Complete an internship that enriches your academic and professional resume as well as enriching your personal life by making a difference in the lives of others.

Responsibilities

Tasks could include things like the following:
• Retrieve, process, and clean large-scale biomedical data, build high-quality datasets.
• Design and develop machine learning models for clinical or biomedical research, with a focus on Large Language Models (LLMs), medical imaging, or multimodal AI.
• Conduct experimental design and evaluation, including statistical analysis, performance assessment, error analysis, and robustness testing.
• Collaborate with cross-functional teams, including clinicians, data scientists, and engineers, to refine research questions and interpret results.
• Contribute to scientific writing, including drafting manuscripts for peer-reviewed journals and preparing materials for presentations or conferences.
• Develop interactive data visualization tools to communicate insights clearly.

Qualifications
• Currently pursuing an MS or PhD degree in Computer Science, Biomedical Informatics, Engineering, Statistics, or a related quantitative field.
• Demonstrated experience with large-scale machine learning or foundation models, including training, fine-tuning, and evaluating LLMs (e.g., GPT, BERT) or vision models (e.g., CNNs, Vision Transformers.
• Strong programming skills in Python (or R), with experience in machine learning frameworks.
• In-depth knowledge of study design, data analysis, and statistical methodologies, with prior experience working with clinical or biomedical data (e.g., EHRs, images.
• Prior authorship or co-authorship of peer-reviewed publications is strongly preferred.
• Experience with interactive visualization tools (e.g., Plotly, Dash, D3.js, or React) is a plus.
• Excellent communication skills, with the ability to present results to both technical and non-technical audiences.
• Ability to deal professionally in a corporate or non-profit environment and assume responsibility for guiding projects and programs from inception through completion.
• Ability to work in a fast-paced, dynamic environment managing multiple priorities involving multiple entities.
• Intermediate to excellent proficiency in MS Word, Excel, Outlook and PowerPoint.
• Minimum availability of 20 hrs/wk, M-F between the hours of 8:00am-5:00pm.
• Required Equipment: Reliable WiFi Connection.
• Must be legally authorized to work in the United States for any employer without sponsorship, now or in the future. For any roles working remotely, the work must also be performed inside the United States, not in a foreign country.

Compensation & Benefits

The job application window is expected to close: August 1, 2025.

The American Heart Association invests in its people. Visit Rewards & Benefits to see more details.
• Compensation and Performance – Attracting talented, committed interns means offering competitive compensation, ongoing professional development and training, and an environment in which to work and grow. And we do.
• Professional Development – You can join one of our many Employee Resource Groups (ERG) or be a mentor/mentee in our professional mentoring program. HeartU is the Association’s national online university, with more than 100,000 resources designed to meet your needs and busy schedule.
• Healthcare Benefits – You will have the opportunity to participate in our Teladoc General Medical and Behavioral Health programs. We also provide access to our Employee Assistance Program (EAP) at no cost as a confidential program designed to assist employees and family members with personal issues that affect their relationships at home or at work.

Apply Today:

So, are you ready to intern for the largest voluntary health organization dedicated to fighting heart disease, stroke, and other cardiovascular diseases?

The American Heart Association’s 2028 Goal: Building on over 100 years of trusted leadership in cardiovascular and brain health, by 2028 the AHA will drive breakthroughs and implement proven solutions in science, policy, and care for healthier people and communities. The greatest discoveries in health must reach everyone where they are.

At American Heart Association | American Stroke Association, our mission is to be a relentless force for a world of longer, healthier lives, regardless of race, ethnicity, gender, gender identity, religion, age, language, sexual orientation, national origin and physical or cognitive abilities.

This position not a match with your skills? Click here to see other opportunities.

In accordance with local and state laws where applicable, qualified applicants with arrest or conviction records will be considered for employment.

EOE/Protected Veterans/Persons with Disabilities

\#AHAWAYUP, #LI-DNP

Join our Talent Community!

Join our Talent Community to receive updates on new opportunities and future events.

Default: Location : LocationUS-TX-Dallas

Posted Date57 minutes ago(7/9/2025 9:51 AM)

Requisition ID2025-16131

Job CategoryAdministrative Support

Position TypePart Time",2025-07-09T00:00:00.000Z,2025-07-25,"['Currently pursuing an MS or PhD degree in Computer Science, Biomedical Informatics, Engineering, Statistics, or a related quantitative field', 'Demonstrated experience with large-scale machine learning or foundation models, including training, fine-tuning, and evaluating LLMs (e.g., GPT, BERT) or vision models (e.g., CNNs, Vision Transformers', 'Strong programming skills in Python (or R), with experience in machine learning frameworks', 'In-depth knowledge of study design, data analysis, and statistical methodologies, with prior experience working with clinical or biomedical data (e.g., EHRs, images', 'Excellent communication skills, with the ability to present results to both technical and non-technical audiences', 'Ability to deal professionally in a corporate or non-profit environment and assume responsibility for guiding projects and programs from inception through completion', 'Ability to work in a fast-paced, dynamic environment managing multiple priorities involving multiple entities', 'Intermediate to excellent proficiency in MS Word, Excel, Outlook and PowerPoint', 'Minimum availability of 20 hrs/wk, M-F between the hours of 8:00am-5:00pm', 'Required Equipment: Reliable WiFi Connection', 'Must be legally authorized to work in the United States for any employer without sponsorship, now or in the future', 'For any roles working remotely, the work must also be performed inside the United States, not in a foreign country', 'Gain important and practical job skills to be successful in a non-profit environment', 'Opportunity to explore a career-path with a reputable voluntary health/service organization', 'Currently pursuing an MS or PhD degree in Computer Science, Biomedical Informatics, Engineering, Statistics, or a related quantitative field', 'Demonstrated experience with large-scale machine learning or foundation models, including training, fine-tuning, and evaluating LLMs (e.g., GPT, BERT) or vision models (e.g., CNNs, Vision Transformers', 'Strong programming skills in Python (or R), with experience in machine learning frameworks', 'In-depth knowledge of study design, data analysis, and statistical methodologies, with prior experience working with clinical or biomedical data (e.g., EHRs, images', 'Excellent communication skills, with the ability to present results to both technical and non-technical audiences', 'Ability to deal professionally in a corporate or non-profit environment and assume responsibility for guiding projects and programs from inception through completion', 'Ability to work in a fast-paced, dynamic environment managing multiple priorities involving multiple entities', 'Intermediate to excellent proficiency in MS Word, Excel, Outlook and PowerPoint', 'Minimum availability of 20 hrs/wk, M-F between the hours of 8:00am-5:00pm', 'Required Equipment: Reliable WiFi Connection', 'Must be legally authorized to work in the United States for any employer without sponsorship, now or in the future', 'For any roles working remotely, the work must also be performed inside the United States, not in a foreign country']","['This internship supports the Data Science team and offers hands-on experience in data science and statistical analysis within clinical or biomedical research settings', 'Interns will contribute to the development of machine learning models, conduct experimental design and evaluation, and assist in summarizing results and drafting manuscripts', 'You will have the opportunity to work closely with staff across departments and contribute to impactful, high-quality research', 'Retrieve, process, and clean large-scale biomedical data, build high-quality datasets', 'Design and develop machine learning models for clinical or biomedical research, with a focus on Large Language Models (LLMs), medical imaging, or multimodal AI', 'Conduct experimental design and evaluation, including statistical analysis, performance assessment, error analysis, and robustness testing', 'Collaborate with cross-functional teams, including clinicians, data scientists, and engineers, to refine research questions and interpret results', 'Contribute to scientific writing, including drafting manuscripts for peer-reviewed journals and preparing materials for presentations or conferences', 'Develop interactive data visualization tools to communicate insights clearly', 'This internship supports the Data Science team and offers hands-on experience in data science and statistical analysis within clinical or biomedical research settings', 'Interns will contribute to the development of machine learning models, conduct experimental design and evaluation, and assist in summarizing results and drafting manuscripts', 'You will have the opportunity to work closely with staff across departments and contribute to impactful, high-quality research', 'Retrieve, process, and clean large-scale biomedical data, build high-quality datasets', 'Design and develop machine learning models for clinical or biomedical research, with a focus on Large Language Models (LLMs), medical imaging, or multimodal AI', 'Conduct experimental design and evaluation, including statistical analysis, performance assessment, error analysis, and robustness testing', 'Collaborate with cross-functional teams, including clinicians, data scientists, and engineers, to refine research questions and interpret results', 'Contribute to scientific writing, including drafting manuscripts for peer-reviewed journals and preparing materials for presentations or conferences', 'Develop interactive data visualization tools to communicate insights clearly']",True,"['Large Language Models', 'Vision Transformers', 'Multimodal AI']","Large Language Models: Designing, training, fine-tuning, and evaluating foundation models such as GPT and BERT for clinical or biomedical research applications.; Vision Transformers: Applying vision transformer models as part of large-scale machine learning efforts in medical imaging and multimodal AI research.; Multimodal AI: Developing AI models that integrate multiple data modalities, including medical imaging and text, to enhance clinical or biomedical research outcomes.","['Machine Learning Models', 'Statistical Analysis', 'Data Processing and Cleaning', 'Study Design', 'Programming in Python or R', 'Interactive Data Visualization Tools']","Machine Learning Models: Design and development of machine learning models for clinical or biomedical research, including training, fine-tuning, and evaluation of models such as CNNs and other vision models.; Statistical Analysis: Conducting experimental design and evaluation involving statistical methodologies, performance assessment, error analysis, and robustness testing within clinical or biomedical research.; Data Processing and Cleaning: Retrieving, processing, and cleaning large-scale biomedical data to build high-quality datasets for research purposes.; Study Design: Applying in-depth knowledge of study design to support clinical or biomedical data analysis and research.; Programming in Python or R: Utilizing strong programming skills in Python or R, including experience with machine learning frameworks, to develop and implement data science and machine learning solutions.; Interactive Data Visualization Tools: Developing interactive visualization tools using technologies such as Plotly, Dash, D3.js, or React to communicate data insights clearly."
Y7KH4dh7O3uUnfIeAAAAAA==,Entry Level Python Programmer/Data scientist/Analyst,"Since 2010 and almost 14 years SynergisticIT has helped Jobseekers get employed in the tech Job market by providing candidates the requisite skills, experience and technical competence to outperform at interviews and at clients.
Post Covid the tech Layoffs have been massive-In 2022 there were 165,269 tech layoffs, In 2023 there were 264,220 tech layoffs and so far in 2024 there have been 126,382 tech layoffs. (Source Layoffs.fyi ) -Total layoffs as per this 555,871 tech layoffs.
Client, Dell and Cisco have announced 15,000/12,500 and 4000 tech layoffs respectively in August.
The Job market is Hyper Competitive. For 1 position 500-2000 candidates or more are applying and laid off job seekers are also competing for entry level Job positions.
Acquiring the right technology skillsets which are being demanded by clients and getting yourself in front of clients is the way to get to get Interviews and eventually a Job Offer. Survival of the Fittest is the only way to get a tech Job in this job market.
In this Layoffs fueled market also SynergisticIT's candidates are able to achieve multiple job offers and $100k + salaries once they acquire the required skills.
please check the below links to see success outcomes, salaries of our candidates .
https://www.synergisticit.com/candidate-outcomes/
https://www.synergisticit.com/roi-of-computer-science-degree-colleges-vs-synergisticit/
We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please visit the below videos exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023
https://synergisticit.wistia.com/medias/tmwjwchxz5
https://synergisticit.wistia.com/medias/n8487768di
https://synergisticit.wistia.com/medias/o5gmv7i9eu
https://synergisticit.wistia.com/medias/k6t6a1n4kb
https://synergisticit.wistia.com/medias/pgrvq4fgni
https://synergisticit.wistia.com/medias/ce4syhm853
All Positions are open for all visas and US citizens
We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.
Currently, we are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Data Engineers, Machine Learning engineers for full time positions with clients.
Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.
We want Data Science/Machine learning/Data Analyst and Java Full stack candidates
REQUIRED SKILLS For Java /Full stack/Devops Positions
Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
Knowledge of Core Java , javascript , C++ or software programming
Spring boot, Microservices, Docker, Jenkins, Github, Kubernates and REST API's experience
For data Science/Data Analyst/AI/Machine learning Positions
REQUIRED SKILLS
Associate or Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT, Statistics, Mathematics or having good logical aptitude
Knowledge of Statistics, Gen AI, LLM, Sagemaker, Python, Computer Vision, data visualization tools
Preferred skills: NLP, Text mining, Tableau, PowerBI, Databricks, Tensorflow
If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.
No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",,2025-07-25,"['Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry', 'We want Data Science/Machine learning/Data Analyst and Java Full stack candidates', 'REQUIRED SKILLS For Java /Full stack/Devops Positions', 'Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT', 'Knowledge of Core Java , javascript , C++ or software programming', ""Spring boot, Microservices, Docker, Jenkins, Github, Kubernates and REST API's experience"", 'For data Science/Data Analyst/AI/Machine learning Positions', 'Associate or Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT, Statistics, Mathematics or having good logical aptitude', 'Knowledge of Statistics, Gen AI, LLM, Sagemaker, Python, Computer Vision, data visualization tools']",,True,"['Generative AI', 'Large Language Models (LLMs)', 'Amazon SageMaker', 'Computer Vision']","Generative AI: Knowledge of Generative AI is required, highlighting the role's involvement with modern AI techniques for generating content or data.; Large Language Models (LLMs): Experience with LLMs is required, indicating work with advanced AI models for natural language understanding and generation.; Amazon SageMaker: Familiarity with Amazon SageMaker is required, showing the use of cloud-based AI/ML model development and deployment services.; Computer Vision: Knowledge of computer vision is required, indicating involvement with AI techniques for image and video analysis.","['Statistics', 'Python', 'Data Visualization Tools', 'NLP (Natural Language Processing)', 'TensorFlow']","Statistics: Knowledge of statistics is required for data science, data analyst, and machine learning positions to analyze and interpret data effectively.; Python: Python programming skills are necessary for data science, machine learning, and data analyst roles to develop data pipelines, perform analysis, and build models.; Data Visualization Tools: Experience with data visualization tools such as Tableau and PowerBI is preferred to create dashboards and visual representations of data insights.; NLP (Natural Language Processing): Preferred skill in NLP and text mining indicates the role involves processing and analyzing textual data for insights.; TensorFlow: TensorFlow is a preferred skill, indicating use in building and deploying machine learning models."
nvd4TKHvearttw2aAAAAAA==,Director Data Science,"Job Description:

Job Title

ESC D&AA Data Science Director

Collaborate with Innovative 3Mers Around the World

Choosing where to start and grow your career has a major impact on your professional and personal life, so it's equally important you know that the company that you choose to work at, and its leaders, will support and guide you. With a wide variety of people, global locations, technologies and products, 3M is a place where you can collaborate with other curious, creative 3Mers.

This position provides an opportunity to transition from other private, public, government or military experience to a 3M career.

The Impact You'll Make in this Role

As the Data Science Director for 3M's Enterprise Supply Chain (ESC) Digitization & Advanced Analytics (D&AA) team, you will have the opportunity to tap into your curiosity and collaborate with some of the most innovative people around the world. Here, you will make an impact by leading a team of data scientists to deliver global ML modeling and Gen AI solutions for 3M ESC, including projects within and among Planning, Procurement, Manufacturing and Global Logistics. The person in this role will also serve as a member of the D&AA leadership team, with the opportunity to shape 3M ESC's strategy of an agile and responsive supply chain through better, faster, and more accurate decision based on Data and AI.

Primary responsibilities include:
• Leading and mentoring a team of data scientists to develop and deploy advanced analytical solutions that enable autonomous supply chain
• Providing technical and contextual guidance to members of the data science team on their projects, establishing forums for peer-to-peer collaboration, identifying resources and removing roadblocks as they occur
• Participating in prioritization discussions, executive reviews, and program updates with functional leaders and peers on the D&AA leadership team
• Coordinating with colleagues and other teams in D&AA to manage project execution
• Articulating and executing toward a clear vision for the new technical capabilities the team needs to advance to support Supply Chain's long-term digital strategy
• Maintaining a strong network of internal and external partnerships, including with IT, Corporate Laboratories and others

Your Skills and Expertise

To set you up for success in this role from day one, 3M requires (at a minimum) the following qualifications:
• Bachelor's degree or higher (completed and verified prior to start)
• Five (5) years of experiencein manufacturing or supply chain analytics roleswith increasing responsibility in a private, public, government or military environment
• Five (5) years of program leadership
• Three (3) years of experience managing direct reports

Additional qualifications that could help you succeed even further in this role include:
• Direct experience deploying ML, Gen AI, Decision Intelligence, Graph Data Science, Optimization/Simulation, and other advanced analytics solutions at enterprise scale
• Master's Degree or higher(completed and verified prior to start) in Data Science, Statistics or other data analytics field from an accredited institution
• Demonstrated ability to coordinate and influence across organizational boundaries to deliver project deliverables and timelines
• Demonstrated ability to translate business challenges into well-defined data science technical project requirements
• Ability to work collaboratively with peers and teams to identify, consider, and then choose among candidate approaches to key projects
• Expertise in ML Ops at enterprise scale
• Experience coding in one or more of Python, R, SQL, etc.
• Experience balancing near term priorities with longer-term strategic imperatives
• Experience working with global and/or remote teams
• Demonstrated change management skills.

Work location:
• Onsite: Maplewood, MN (minimum 4 days a week onsite)

Travel:May include up to 10% (Domestic / International)

Relocation Assistance: May be Authorized

Must be legally authorized to work in country of employment without sponsorship for employment visa status (e.g., H1B status).

Supporting Your Well-being

3M offers many programs to help you live your best life - both physically and financially. To ensure competitive pay and benefits, 3M regularly benchmarks with other companies that are comparable in size and scope.

Chat with Max

For assistance with searching through our current job openings or for more information about all things 3M, visit Max, our virtual recruiting assistant on 3M.com/careers.

Applicable to US Applicants Only:The expected compensation range for this position is $228,040 - $278,715, which includes base pay plus variable incentive pay, if eligible. This range represents a good faith estimate for this position. The specific compensation offered to a candidate may vary based on factors including, but not limited to, the candidate's relevant knowledge, training, skills, work location, and/or experience. In addition, this position may be eligible for a range of benefits (e.g., Medical, Dental & Vision, Health Savings Accounts, Health Care & Dependent Care Flexible Spending Accounts, Disability Benefits, Life Insurance, Voluntary Benefits, Paid Absences and Retirement Benefits, etc.). Additional information is available at: https://www.3m.com/3M/en_US/careers-us/working-at-3m/benefits/.

Good Faith Posting Date Range 07/15/2025 To 08/14/2025 Or until filled

All US-based 3M full time employees will need to sign an employee agreement as a condition of employment with 3M. This agreement lays out key terms on using 3M Confidential Information and Trade Secrets. It also has provisions discussing conflicts of interest and how inventions are assigned. Employees that are Job Grade 7 or equivalent and above may also have obligations to not compete against 3M or solicit its employees or customers, both during their employment, and for a period after they leave 3M.

Learn more about 3M's creative solutions to the world's problems at www.3M.com or on Instagram, Facebook, and LinkedIn @3M.

Responsibilities of this position include that corporate policies, procedures and security standards are complied with while performing assigned duties.

Safety is a core value at 3M. All employees are expected to contribute to a strong EHS culture by following safety policies, identifying hazards, and engaging in continuous improvement.

Pay & Benefits Overview: https://www.3m.com/3M/en_US/careers-us/working-at-3m/benefits/

3M does not discriminate in hiring or employment on the basis of race, color, sex, national origin, religion, age, disability, veteran status, or any other characteristic protected by applicable law.

Please note: your application may not be considered if you do not provide your education and work history, either by: 1) uploading a resume, or 2) entering the information into the application fields directly.

3M Global Terms of Use and Privacy Statement

Carefully read these Terms of Use before using this website. Your access to and use of this website and application for a job at 3M are conditioned on your acceptance and compliance with these terms.

Please access the linked document by clicking here, select the country where you are applying for employment, and review. Before submitting your application, you will be asked to confirm your agreement with the terms.",2025-07-15T00:00:00.000Z,2025-07-25,"['To set you up for success in this role from day one, 3M requires (at a minimum) the following qualifications:', ""Bachelor's degree or higher (completed and verified prior to start)"", 'Five (5) years of experiencein manufacturing or supply chain analytics roleswith increasing responsibility in a private, public, government or military environment', 'Five (5) years of program leadership', 'Three (3) years of experience managing direct reports', 'Direct experience deploying ML, Gen AI, Decision Intelligence, Graph Data Science, Optimization/Simulation, and other advanced analytics solutions at enterprise scale', ""Master's Degree or higher(completed and verified prior to start) in Data Science, Statistics or other data analytics field from an accredited institution"", 'Demonstrated ability to coordinate and influence across organizational boundaries to deliver project deliverables and timelines', 'Demonstrated ability to translate business challenges into well-defined data science technical project requirements', 'Ability to work collaboratively with peers and teams to identify, consider, and then choose among candidate approaches to key projects', 'Expertise in ML Ops at enterprise scale', 'Experience coding in one or more of Python, R, SQL, etc', 'Experience balancing near term priorities with longer-term strategic imperatives', 'Experience working with global and/or remote teams', 'Demonstrated change management skills', 'Must be legally authorized to work in country of employment without sponsorship for employment visa status (e.g., H1B status)', 'Good Faith Posting Date Range 07/15/2025 To 08/14/2025 Or until filled', 'All US-based 3M full time employees will need to sign an employee agreement as a condition of employment with 3M', 'This agreement lays out key terms on using 3M Confidential Information and Trade Secrets', 'Employees that are Job Grade 7 or equivalent and above may also have obligations to not compete against 3M or solicit its employees or customers, both during their employment, and for a period after they leave 3M']","[""As the Data Science Director for 3M's Enterprise Supply Chain (ESC) Digitization & Advanced Analytics (D&AA) team, you will have the opportunity to tap into your curiosity and collaborate with some of the most innovative people around the world"", 'Here, you will make an impact by leading a team of data scientists to deliver global ML modeling and Gen AI solutions for 3M ESC, including projects within and among Planning, Procurement, Manufacturing and Global Logistics', ""The person in this role will also serve as a member of the D&AA leadership team, with the opportunity to shape 3M ESC's strategy of an agile and responsive supply chain through better, faster, and more accurate decision based on Data and AI"", 'Leading and mentoring a team of data scientists to develop and deploy advanced analytical solutions that enable autonomous supply chain', 'Providing technical and contextual guidance to members of the data science team on their projects, establishing forums for peer-to-peer collaboration, identifying resources and removing roadblocks as they occur', 'Participating in prioritization discussions, executive reviews, and program updates with functional leaders and peers on the D&AA leadership team', 'Coordinating with colleagues and other teams in D&AA to manage project execution', ""Articulating and executing toward a clear vision for the new technical capabilities the team needs to advance to support Supply Chain's long-term digital strategy"", 'Maintaining a strong network of internal and external partnerships, including with IT, Corporate Laboratories and others', 'Onsite: Maplewood, MN (minimum 4 days a week onsite)']",True,['Generative AI'],"Generative AI: Leading and delivering generative AI solutions integrated with supply chain analytics to enable better, faster, and more accurate decision making.","['Machine Learning', 'Generative AI', 'Decision Intelligence', 'Graph Data Science', 'Optimization and Simulation', 'MLOps', 'Python, R, SQL']","Machine Learning: Leading a team of data scientists to deliver global machine learning modeling solutions for supply chain projects including Planning, Procurement, Manufacturing, and Global Logistics.; Generative AI: Delivering generative AI solutions as part of advanced analytics projects to support enterprise supply chain digitization and decision making.; Decision Intelligence: Deploying decision intelligence solutions at enterprise scale to improve supply chain responsiveness and agility.; Graph Data Science: Applying graph data science techniques as part of advanced analytics solutions for supply chain optimization.; Optimization and Simulation: Utilizing optimization and simulation methods to enhance supply chain processes and support strategic decision making.; MLOps: Expertise in machine learning operations at enterprise scale to support deployment and management of ML models.; Python, R, SQL: Experience coding in Python, R, and SQL to develop and implement data science and analytics solutions."
g8X_IFaPzLpUL6I6AAAAAA==,"Manager, Data Science","The Company:

Hearts & Science has been inspired by confident marketers seeking business advantage in a world of personalized digital marketing, where CRM and addressable channels converge, and decisions must be made in real time to aggregate effective reach and deliver the right message at the right time.

Designed to inform brand strategies with real-time insights, Hearts & Science is a data-driven marketing agency with expert media planning and buying capabilities, among other services that include shopper marketing, marketing innovation and content activation.

The Data Science team is pivotal in the delivery of modern agency services. We are tightly integrated with marketing science teams to deliver on and exceed our clients' business goals.
Responsibilities

External facing responsibilities:
• Build advanced ML models to cluster and segment audiences, scale and deploy custom audiences across various platforms/ publishers
• Run descriptive and diagnostic analyses to help measure campaign performance within clean rooms and/or other analytics platforms (e.g., Google ADH, Facebook advanced analytics, Amazon Marketing Cloud, etc.)
• Adhere to set deadlines and ensure high quality work product

Internal facing responsibilities:
• Leverage technical (coding) skills to help bring about process efficiencies
• Contribute to building decks and reports that help translate analytical results to internal and client teams
• Contribute to building DS Practice knowledge repository via decks, documents and other artifacts

Required Skills
• Hands-on programming language skills (SQL, Python, R, etc)
• Intermediate exposure to machine learning techniques, causal models, etc. to support the analysis of information
• Advanced presentation and communication skills
• Some experience working with non-technical teams
• Knowledge of digital clean rooms, and their related concepts and strategy
• Certifications in any of the following: Meta (Blueprint), SQL, Python, R (online)
• Demonstrated domain knowledge of business/industry

Education and Experience
• A university degree in mathematics, computer science, statistics or related field, and 3-5 years of experience in informatics work in academia, advertising, management consulting, marketing or digital consulting
• Knowledge of agency-side execution process is desirable, but not required

#LI-CC2

This is the pay range the Company believes it will pay for this position at the time of this posting. Consistent with applicable law, compensation will be determined based on relevant experience, other job-related qualifications/skills, and geographic location (to account for comparative cost of living). The Company reserves the right to modify this pay range at any time. For this role, benefits include: health insurance, vision insurance, dental insurance, 401(k), Healthcare Flexible Spending Account, Dependent Care Flexible Spending Account, vacation days, sick days, personal days, paid parental leave, paid medical leave, and STD/LTD insurance benefits.

Compensation Range

$125,000-$130,000 USD

This role is hybrid, requiring three (3) days per week in the office. The remaining two (2) days may be worked remotely. Specific in-office days will be discussed during the interview process, with flexibility to align with team needs. Please note that the number or required in-office days may be adjusted over time, potentially increasing the number of required in-office days based on business needs.

Review Our Recruitment Privacy Notice",2025-07-20T00:00:00.000Z,2025-07-25,"['Hands-on programming language skills (SQL, Python, R, etc)', 'Intermediate exposure to machine learning techniques, causal models, etc', 'Some experience working with non-technical teams', 'Knowledge of digital clean rooms, and their related concepts and strategy', 'Certifications in any of the following: Meta (Blueprint), SQL, Python, R (online)', 'Demonstrated domain knowledge of business/industry', 'A university degree in mathematics, computer science, statistics or related field, and 3-5 years of experience in informatics work in academia, advertising, management consulting, marketing or digital consulting', 'The remaining two (2) days may be worked remotely', 'Specific in-office days will be discussed during the interview process, with flexibility to align with team needs']","['Build advanced ML models to cluster and segment audiences, scale and deploy custom audiences across various platforms/ publishers', 'Run descriptive and diagnostic analyses to help measure campaign performance within clean rooms and/or other analytics platforms (e.g., Google ADH, Facebook advanced analytics, Amazon Marketing Cloud, etc.)', 'Adhere to set deadlines and ensure high quality work product', 'Leverage technical (coding) skills to help bring about process efficiencies', 'Contribute to building decks and reports that help translate analytical results to internal and client teams', 'Contribute to building DS Practice knowledge repository via decks, documents and other artifacts', 'to support the analysis of information', 'Advanced presentation and communication skills']",True,[],,"['Machine Learning Models', 'Descriptive and Diagnostic Analytics', 'SQL', 'Python', 'R', 'Causal Models', 'Digital Clean Rooms']","Machine Learning Models: Used to cluster and segment audiences and to scale and deploy custom audiences across various platforms and publishers.; Descriptive and Diagnostic Analytics: Performed to measure campaign performance within digital clean rooms and other analytics platforms such as Google ADH, Facebook advanced analytics, and Amazon Marketing Cloud.; SQL: A programming language used hands-on for data querying and manipulation relevant to the role.; Python: A programming language used hands-on for coding tasks to support data science workflows and process efficiencies.; R: A programming language used hands-on for statistical analysis and data science tasks.; Causal Models: Applied as intermediate-level machine learning techniques to support the analysis of information and campaign performance.; Digital Clean Rooms: Knowledge of digital clean rooms and their related concepts and strategy is required to perform analytics in privacy-safe environments."
bEuejHaG2OpO7IW5AAAAAA==,Manager & Sr Data Scientist,"Who Are We?

Taking care of our customers, our communities and each other. That's the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.

Job Category

Data Science

Compensation Overview

The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards.

Salary Range$142,500.00 - $235,100.00

Target Openings

1

What Is the Opportunity?

Travelers Data Scientists are taking the organization to the next level of intelligence by using advanced statistical techniques and machine learning algorithms. As a Manager & Sr. Data Scientist, you will build sophisticated models that solve important business problems and enhance our customer experience. This may include the use of artificial intelligence techniques to analyze imagery, text, and other unstructured data. You will employ storytelling using data to communicate insights and findings to stakeholders. This role may manage others.

As a member of Loss Analytics Research team, you will lead efforts to monitor and refresh the models for one line of business, engage in finding insights, and communicate results with reserving actuaries. You will collaborate with reserving actuaries to gain insights from the output of claim level predictive models. There are opportunities to leverage Machine Learning and Artificial Intelligence techniques to improve modeling accuracy and insights, as well as opportunities to support training and skill development initiatives, including supervising of modeling academy participants.What Will You Do?
• Manage portions of business or technical projects focused on the design or development of analytical solutions.
• Share expertise with the community through discussions, presentations, or peer reviews
• Set and manage expectations with business partners for small projects, and with limited guidance, identify potential conflicts and build consensus.
• Communicate analysis, insights, and results to team, peers, and business partners, and with guidance, tailor communication to the audience.
• Be a mentor or resource for less experienced analytic talent, onboard new employees and interns, and support recruiting and talent assessment efforts.
• Support various training and skill development initiatives.
• Perform other duties as assigned.
What Will Our Ideal Candidate Have?
• Masters in STEM related field or equivalent
• 5 years of related experience
• Advanced working knowledge of modeling/research/ analytics or actuarial required
• Strong grasp of value creation and business model concepts
• Advanced knowledge of multiple statistical software programs
• Ability to develop advanced models and interpret model results
• Application of advanced statistics underlying data models
• Ability to develop emerging statistical procedures to work
• Advanced knowledge in 2-3 of the following: Regression, Classification, Machine Vision, Natural Language Processing, Deep Learning and Statistical modeling.

What is a Must Have?
• Master's degree in Statistics, Mathematics, Decision Sciences, Actuarial Science or related analytical STEM field plus three years of experience, or PhD in Statistics, Mathematics, Decision Sciences, Actuarial Science or related analytical STEM field plus zero years of experience, or any suitable and equivalent combination of education and work experience.
• Heavy concentration in mathematics, including statistics and programming, business intelligence/analytics, as well as data science tools and research using large data sets. Additional verification of specific coursework will be required.

What Is in It for You?
• Health Insurance:Employees and their eligible family members - including spouses, domestic partners, and children - are eligible for coverage from the first day of employment.
• Retirement:Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers.
• Paid Time Off:Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays.
• Wellness Program:The Travelers wellness program is comprised of tools, discounts and resources that empower you to achieve your wellness goals and caregiving needs. In addition, our mental health program provides access to free professional counseling services, health coaching and other resources to support your daily life needs.
• Volunteer Encouragement:We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice.

Employment Practices

Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences.

In accordance with local law, candidates seeking employment in Colorado are not required to disclose dates of attendance at or graduation from educational institutions.

If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you.

Travelers reserves the right to fill this position at a level above or below the level included in this posting.

To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/.",,2025-07-25,"['Masters in STEM related field or equivalent', '5 years of related experience', 'Advanced working knowledge of modeling/research/ analytics or actuarial required', 'Strong grasp of value creation and business model concepts', 'Advanced knowledge of multiple statistical software programs', 'Ability to develop advanced models and interpret model results', 'Application of advanced statistics underlying data models', 'Ability to develop emerging statistical procedures to work', 'Advanced knowledge in 2-3 of the following: Regression, Classification, Machine Vision, Natural Language Processing, Deep Learning and Statistical modeling', ""Master's degree in Statistics, Mathematics, Decision Sciences, Actuarial Science or related analytical STEM field plus three years of experience, or PhD in Statistics, Mathematics, Decision Sciences, Actuarial Science or related analytical STEM field plus zero years of experience, or any suitable and equivalent combination of education and work experience"", 'Heavy concentration in mathematics, including statistics and programming, business intelligence/analytics, as well as data science tools and research using large data sets', 'Additional verification of specific coursework will be required']","['Data Scientist, you will build sophisticated models that solve important business problems and enhance our customer experience', 'This may include the use of artificial intelligence techniques to analyze imagery, text, and other unstructured data', 'You will employ storytelling using data to communicate insights and findings to stakeholders', 'This role may manage others', 'As a member of Loss Analytics Research team, you will lead efforts to monitor and refresh the models for one line of business, engage in finding insights, and communicate results with reserving actuaries', 'You will collaborate with reserving actuaries to gain insights from the output of claim level predictive models', 'There are opportunities to leverage Machine Learning and Artificial Intelligence techniques to improve modeling accuracy and insights, as well as opportunities to support training and skill development initiatives, including supervising of modeling academy participants', 'Manage portions of business or technical projects focused on the design or development of analytical solutions', 'Share expertise with the community through discussions, presentations, or peer reviews', 'Set and manage expectations with business partners for small projects, and with limited guidance, identify potential conflicts and build consensus', 'Communicate analysis, insights, and results to team, peers, and business partners, and with guidance, tailor communication to the audience', 'Be a mentor or resource for less experienced analytic talent, onboard new employees and interns, and support recruiting and talent assessment efforts', 'Support various training and skill development initiatives', 'Perform other duties as assigned']",True,['Artificial Intelligence'],"Artificial Intelligence: Applied to analyze imagery, text, and other unstructured data to improve modeling accuracy and generate business insights, including opportunities to leverage AI techniques alongside machine learning.","['Regression', 'Classification', 'Machine Learning', 'Natural Language Processing', 'Deep Learning', 'Statistical Modeling', 'Statistical Software Programs', 'Business Intelligence and Analytics']","Regression: Used as one of the advanced statistical modeling techniques to develop sophisticated models that solve business problems and enhance customer experience.; Classification: Applied as an advanced statistical method to build predictive models within the Loss Analytics Research team and improve modeling accuracy.; Machine Learning: Leveraged to improve modeling accuracy and insights, including the development and refresh of claim level predictive models and other analytical solutions.; Natural Language Processing: Utilized as one of the advanced knowledge areas to analyze text and unstructured data for business insights and model development.; Deep Learning: Included as an advanced knowledge area potentially applied to analyze imagery and unstructured data to enhance modeling and business problem solving.; Statistical Modeling: Employed extensively to develop advanced models, interpret results, and apply emerging statistical procedures to business data.; Statistical Software Programs: Used to perform advanced modeling, research, and analytics required for developing and interpreting complex data models.; Business Intelligence and Analytics: Incorporated as part of the heavy concentration in mathematics and programming to support data science tools and research using large data sets."
94GX-3cOtn2mqtkfAAAAAA==,Junior Data Analyst/Scientist/Engineer,"For more than 12 years Synergisticit has helped Jobseekers stand out from other Jobseekers by providing candidates the requisite skills, experience and technical competence to outperform at interviews and at clients. Here at SynergisticIT We just don't focus on getting you a tech Job we make careers.

In this market also our candidates get multiple job offers and $100k + salaries.

please check the below links to see success outcomes of our candidates .

https://www.synergisticit.com/candidate-outcomes/

https://reg.rf.oracle.com/flow/oracle/cwoh23/OCWExhibitorCatalog/page/OCWexhibitorcatalog

We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please see us exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023

All Positions are open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.

We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

https://www.youtube.com/watch?v=OFoqPTNORew

https://www.youtube.com/watch?v=-HkNN1ag6Zk

https://www.youtube.com/watch?v=OAFOhcGy9Z8

https://youtu.be/bJJl27D8bh0

We want Data Science/Machine learning/Data Analyst and Java Full stack candidates

For data Science/Machine learning Positions

REQUIRED SKILLS

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Project work on the technologies needed

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools

Excellent written and verbal communication skills

Preferred skills: NLP, Text mining, Tableau, PowerBI, Databricks, Tensorflow

REQUIRED SKILLS For Java /Full stack/Software Positions

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Project work on the skills

Knowledge of Core Java , javascript , C++ or software programming

Spring boot, Microservices, Docker, Jenkins and REST API's experience

Excellent written and verbal communication skills

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",,2025-07-25,"['Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry', 'We want Data Science/Machine learning/Data Analyst and Java Full stack candidates', 'For data Science/Machine learning Positions', 'Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT', 'Project work on the technologies needed', 'Highly motivated, self-learner, and technically inquisitive', 'Experience in programming language Java and understanding of the software development life cycle', 'Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools', 'Excellent written and verbal communication skills', 'REQUIRED SKILLS For Java /Full stack/Software Positions', 'Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT', 'Highly motivated, self-learner, and technically inquisitive', 'Experience in programming language Java and understanding of the software development life cycle', 'Project work on the skills', 'Knowledge of Core Java , javascript , C++ or software programming', ""Spring boot, Microservices, Docker, Jenkins and REST API's experience"", 'Excellent written and verbal communication skills']",,True,['TensorFlow'],"TensorFlow: TensorFlow is preferred as a deep learning framework, indicating potential use in neural network-based AI projects.","['Statistics', 'SAS', 'Python', 'Data Visualization Tools', 'Computer Vision', 'NLP', 'Java', 'Software Development Life Cycle', 'Core Java', 'JavaScript', 'C++', 'Spring Boot', 'Microservices', 'Docker', 'Jenkins', 'REST APIs', 'TensorFlow', 'Project Work']","Statistics: Knowledge of statistics is required for data science and data analyst roles to analyze and interpret data effectively.; SAS: Experience with SAS is mentioned as a required skill, indicating its use for statistical analysis and data management.; Python: Python programming is required, likely for data manipulation, analysis, and building data science models.; Data Visualization Tools: Familiarity with data visualization tools such as Tableau and PowerBI is preferred to create dashboards and visual reports.; Computer Vision: Knowledge of computer vision is listed, suggesting involvement with image data processing and analysis.; NLP: Natural Language Processing is preferred, indicating work with text data and text mining techniques.; Java: Experience in Java programming is required, relevant for software development and possibly data engineering tasks.; Software Development Life Cycle: Understanding of the software development life cycle is necessary, implying involvement in end-to-end project development.; Core Java: Knowledge of Core Java is required for software programming tasks.; JavaScript: JavaScript knowledge is required, likely for front-end development or data visualization.; C++: C++ programming knowledge is mentioned as part of software programming skills.; Spring Boot: Experience with Spring Boot framework is required, indicating backend development skills.; Microservices: Experience with microservices architecture is required, relevant for building scalable applications.; Docker: Docker experience is required, indicating containerization skills for deployment and development.; Jenkins: Experience with Jenkins is required, suggesting knowledge of continuous integration and deployment pipelines.; REST APIs: Experience with REST APIs is required, indicating skills in building and consuming web services.; TensorFlow: TensorFlow is preferred, suggesting familiarity with deep learning frameworks for machine learning projects.; Project Work: Candidates are expected to have project experience on relevant technologies, demonstrating practical application of skills."
3L7SmRsLsP-eMQApAAAAAA==,"Senior, Data Scientist","Position Summary...

What you'll do...

At Sam’s Club, we are member obsessed. We work to add value to Sam’s Club membership, and we partner with suppliers to bring unique and exciting products to our members. The Sam’s Club Member Access Platform (MAP), the retail media network arm, is the nexus of the Supplier -Marketer- Merchant partnership. MAP is responsible for delivering impactful omnichannel advertising experiences to our members that are married with closed-loop measurement.

The Measurement, Insights and Data Strategy (MINDS) team is a data and analytics function supporting the MAP organization. They provide campaign performance measurement and audience insights for marketing effectiveness and optimization and lead innovation and monetization initiatives through media experimentation and data strategy. The team fuels MAP’s winning formula – easy to buy, easy to sell, easy to operate -- to drive accelerated growth for both supplier brands and Sam’s Club. Realizing the unique strength in 100% traceable member journey data, omni-channel fulfillment capabilities, and personalization capabilities with growing member reach.

We are seeking a Senior Data Scientist to join its Media Science and Experimentation team and help drive the company’s data innovation strategy. In this role, you will focus on implementing clean room technologies for closed-loop measurement, developing generative AI solutions for social listening, and advancing audience monetization through sophisticated experiments and machine learning–based targeting and measurement. You’ll collaborate with internal teams across Sales, Marketing, Operations, Product, Engineering, and Site Analytics to design and execute advanced analytics and measurement solutions. Additionally, you will work with external ad-tech and measurement partners—including Meta, Pinterest, Tradedesk, LiveRamp, Circana, and Epsilon—to explore new monetization opportunities using emerging technologies such as clean rooms, in-store beacons, and data marketplaces. This position reports to the Director of Media Science and Experimentation.

What you’ll do:
• Lead clean-room data science initiatives with Meta and Pinterest, managing end-to-end workflows such as audience joins, closed loop attribution measurement, campaign incrementality testing, and cross-channel measurements.
• Collaborate closely with cross-functional teams—including Product, Engineering, and Legal—to define scalable schema, governance protocols, and privacy-safe data-sharing pipelines that support both campaign measurement and audience activation.
• Design and implement advanced GenAI solutions for social listening, building LLM-powered systems that process and extract sentiment, intent, and brand affinity signals from comment data across influencer and social campaigns.
• Deliver actionable insights to campaign managers and advertisers by transforming unstructured social content into structured, high-signal intelligence.
• Integrate third-party data sources—including Freeosk sampling, Experian, Epsilon, and Circana panel data—to enhance targeting accuracy and segmentation depth, enabling more advanced use cases in personalization, lifecycle marketing, and high-value audience activation across media channels.
• Develop scalable audience automation and sharing frameworks by integrating clean-room capabilities with internal audience builders and external media platforms. Enable dynamic audience modeling, streamlined data activation, and seamless measurement workflows across partner ecosystems to drive campaign efficiency and personalization.
• Support go-to-market strategies by partnering with commercial and product teams on sales enablement, including the creation of training materials, case study collateral, and data-backed narratives to demonstrate value to advertisers and internal stakeholders.
• Develop new and innovative measurement solutions in Data Clean Rooms using advanced ML algorithms such as KD Tree Nearest Neighbor Synthetic control matching, propensity scores, t-test and bootstrapping tests for statistical significance calculations on partner media impressions data, demographics, and Sam’s buyer segments.
• Participate, and support analytics consultation projects by providing expert advice in experimental design, learning agenda, success metrics, and requirements for testing of new product feature roll-out, new ad partnership, new data adoption, campaign and audience test & learn.
• Manage end-to-end project execution, from planning and data collection to model prototyping and deployment, while effectively communicating with stakeholders and cross-functional partners.
• Conduct statistical power analyses using baseline metrics from historical data, expected impact from past learnings or expert opinion, and population size for qualifying audience to determine minimum sample size required to conduct a feasible test to get statistically significant results.
• Analyze experiment results using advanced statistical techniques such as normality tests, t-test for normally distributed data, non-parametric tests for non-normal data, and difference in difference regression for biased tests.

What you’ll bring:
• Proven experience as a Senior Data Scientist with a focus on marketing analytics, preferably in a retail or membership-based environment
• Statistical analysis experience, including experimental design, regression modeling, and machine learning using tools such as GCP, Adobe analytics, Python, R, Spark SQL and MLlib for custom analysis, in conjunction with SQL for data query and extraction techniques.
• Strong knowledge of statistical analysis, experimental design, regression modeling, machine learning, and data visualization techniques
• Well versed in ad-tech and mar-tech industry with extensive experience in econometric modeling, digital multi-touch attribution, experimental A/B testing, predictive modeling and able to advise when and how to best leverage those approaches.
• Excellent communication skills with the ability to translate complex findings into actionable insights for non-technical stakeholders.
• A comfort level working with ambiguity and the ability to thrive in an environment with rapid change.
• A curious and collaborative mindset that finds enjoyment working on complex problems.
• Familiarity with retail and membership concepts is a plus.
• AI/ML Engineering experience in building scalable media measurement and targeting solutions is a BIG PLUS.

Perks and Benefits

Beyond competitive pay, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more. 

At Sam's Club, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet!

‎
- Health benefits include medical, vision and dental coverage

‎
- Financial benefits include 401(k), stock purchase and company-paid life insurance

‎
- Paid time off benefits include PTO, parental leave, family care leave, bereavement, jury duty, and voting. You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.

‎

For information about PTO, see https://one.walmart.com/notices.

‎
- Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

‎
Live Better U is a company paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

‎
Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

‎

For information about benefits and eligibility, see One.Walmart.

‎
San Bruno, California US-08848:The annual salary range for this position is $117,000.00-$234,000.00

‎
Bentonville, Arkansas US-09930:The annual salary range for this position is $90,000.00-$180,000.00

‎

‎

‎

‎

‎

‎

‎

‎

‎

‎
Additional compensation includes annual or quarterly performance bonuses.

‎

‎

‎

‎

‎

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1- Bachelor’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years' experience in an analytics related field. Option 2- Master’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years' experience in an analytics related field. Option 3 - 5 years' experience in an analytics or related field.

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data science, machine learning, optimization models, Master’s degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.

Primary Location...

850 Cherry Avenue, San Bruno, CA 94066-3031, United States of America",2025-07-23T00:00:00.000Z,2025-07-25,"['Proven experience as a Senior Data Scientist with a focus on marketing analytics, preferably in a retail or membership-based environment', 'Statistical analysis experience, including experimental design, regression modeling, and machine learning using tools such as GCP, Adobe analytics, Python, R, Spark SQL and MLlib for custom analysis, in conjunction with SQL for data query and extraction techniques', 'Strong knowledge of statistical analysis, experimental design, regression modeling, machine learning, and data visualization techniques', 'Well versed in ad-tech and mar-tech industry with extensive experience in econometric modeling, digital multi-touch attribution, experimental A/B testing, predictive modeling and able to advise when and how to best leverage those approaches', 'Excellent communication skills with the ability to translate complex findings into actionable insights for non-technical stakeholders', 'A comfort level working with ambiguity and the ability to thrive in an environment with rapid change', 'A curious and collaborative mindset that finds enjoyment working on complex problems', 'AI/ML Engineering experience in building scalable media measurement and targeting solutions is a BIG PLUS', ""Option 1- Bachelor’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years' experience in an analytics related field"", ""Option 2- Master’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years' experience in an analytics related field"", ""Option 3 - 5 years' experience in an analytics or related field"", 'Data science, machine learning, optimization models, Master’s degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly', 'The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture']","['The Measurement, Insights and Data Strategy (MINDS) team is a data and analytics function supporting the MAP organization', 'In this role, you will focus on implementing clean room technologies for closed-loop measurement, developing generative AI solutions for social listening, and advancing audience monetization through sophisticated experiments and machine learning–based targeting and measurement', 'You’ll collaborate with internal teams across Sales, Marketing, Operations, Product, Engineering, and Site Analytics to design and execute advanced analytics and measurement solutions', 'Additionally, you will work with external ad-tech and measurement partners—including Meta, Pinterest, Tradedesk, LiveRamp, Circana, and Epsilon—to explore new monetization opportunities using emerging technologies such as clean rooms, in-store beacons, and data marketplaces', 'This position reports to the Director of Media Science and Experimentation', 'Lead clean-room data science initiatives with Meta and Pinterest, managing end-to-end workflows such as audience joins, closed loop attribution measurement, campaign incrementality testing, and cross-channel measurements', 'Collaborate closely with cross-functional teams—including Product, Engineering, and Legal—to define scalable schema, governance protocols, and privacy-safe data-sharing pipelines that support both campaign measurement and audience activation', 'Design and implement advanced GenAI solutions for social listening, building LLM-powered systems that process and extract sentiment, intent, and brand affinity signals from comment data across influencer and social campaigns', 'Deliver actionable insights to campaign managers and advertisers by transforming unstructured social content into structured, high-signal intelligence', 'Integrate third-party data sources—including Freeosk sampling, Experian, Epsilon, and Circana panel data—to enhance targeting accuracy and segmentation depth, enabling more advanced use cases in personalization, lifecycle marketing, and high-value audience activation across media channels', 'Develop scalable audience automation and sharing frameworks by integrating clean-room capabilities with internal audience builders and external media platforms', 'Enable dynamic audience modeling, streamlined data activation, and seamless measurement workflows across partner ecosystems to drive campaign efficiency and personalization', 'Support go-to-market strategies by partnering with commercial and product teams on sales enablement, including the creation of training materials, case study collateral, and data-backed narratives to demonstrate value to advertisers and internal stakeholders', 'Develop new and innovative measurement solutions in Data Clean Rooms using advanced ML algorithms such as KD Tree Nearest Neighbor Synthetic control matching, propensity scores, t-test and bootstrapping tests for statistical significance calculations on partner media impressions data, demographics, and Sam’s buyer segments', 'Participate, and support analytics consultation projects by providing expert advice in experimental design, learning agenda, success metrics, and requirements for testing of new product feature roll-out, new ad partnership, new data adoption, campaign and audience test & learn', 'Manage end-to-end project execution, from planning and data collection to model prototyping and deployment, while effectively communicating with stakeholders and cross-functional partners', 'Conduct statistical power analyses using baseline metrics from historical data, expected impact from past learnings or expert opinion, and population size for qualifying audience to determine minimum sample size required to conduct a feasible test to get statistically significant results', 'Analyze experiment results using advanced statistical techniques such as normality tests, t-test for normally distributed data, non-parametric tests for non-normal data, and difference in difference regression for biased tests']",True,"['Generative AI', 'Large Language Models']","Generative AI: Designing and implementing advanced generative AI solutions for social listening that leverage large language models to process and extract sentiment, intent, and brand affinity signals from unstructured social media comment data across influencer and social campaigns.; Large Language Models: Building LLM-powered systems to transform unstructured social content into structured, high-signal intelligence for actionable insights delivered to campaign managers and advertisers.","['Clean Room Technologies', 'Experimental Design', 'Statistical Analysis Techniques', 'Regression Modeling', 'Machine Learning', 'Data Visualization Techniques', 'SQL and Spark SQL', 'Python and R', 'Econometric Modeling', 'A/B Testing and Campaign Incrementality Testing', 'Predictive Modeling', 'Data Pipelines and Governance', 'Audience Modeling and Automation', 'Third-Party Data Integration', 'Power Analysis']","Clean Room Technologies: Leading initiatives involving clean-room data science to enable privacy-safe data sharing, audience joins, closed-loop attribution measurement, campaign incrementality testing, and cross-channel measurement workflows with partners like Meta and Pinterest.; Experimental Design: Providing expert advice and support on experimental design, learning agenda, success metrics, and requirements for testing new product features, ad partnerships, data adoption, and campaign audience test & learn.; Statistical Analysis Techniques: Applying advanced statistical methods including t-tests for normally distributed data, non-parametric tests for non-normal data, normality tests, difference-in-difference regression for biased tests, propensity scores, and bootstrapping tests to analyze experiment results and calculate statistical significance.; Regression Modeling: Utilizing regression models such as difference-in-difference regression to analyze biased tests and support campaign measurement and audience insights.; Machine Learning: Developing and deploying machine learning-based targeting and measurement solutions, including advanced ML algorithms like KD Tree Nearest Neighbor Synthetic control matching, and using ML frameworks such as Spark MLlib for custom analysis.; Data Visualization Techniques: Employing data visualization methods to communicate complex statistical and analytical findings effectively to stakeholders and campaign managers.; SQL and Spark SQL: Using SQL and Spark SQL for data querying, extraction, and processing to support analytics, modeling, and measurement workflows.; Python and R: Leveraging Python and R programming languages for statistical analysis, machine learning, and custom data science workflows.; Econometric Modeling: Applying econometric models for digital multi-touch attribution, marketing analytics, and campaign performance measurement.; A/B Testing and Campaign Incrementality Testing: Designing and analyzing experimental A/B tests and incrementality tests to measure campaign effectiveness and optimize marketing strategies.; Predictive Modeling: Building predictive models to enhance targeting accuracy, segmentation depth, and audience activation across media channels.; Data Pipelines and Governance: Collaborating to define scalable data schemas, governance protocols, and privacy-safe data-sharing pipelines that support campaign measurement and audience activation.; Audience Modeling and Automation: Developing scalable audience automation and sharing frameworks integrating clean-room capabilities with internal and external media platforms to enable dynamic audience modeling and streamlined data activation.; Third-Party Data Integration: Incorporating external data sources such as Freeosk sampling, Experian, Epsilon, and Circana panel data to improve targeting accuracy, segmentation, and personalization in marketing campaigns.; Power Analysis: Conducting statistical power analyses using baseline metrics, expected impact, and population size to determine minimum sample sizes for statistically significant tests."
4JMZcXuU2wbJEZJJAAAAAA==,Entry Level Developer/Coder/Programmer/Data Scientist/Analyst/Engineer,"The Job Market is Challenging due to almost 300,000 Tech Layoffs since October 2022 due to which thousands of laid off Techies are competing with existing Jobseekers. Entry level Job seekers struggle to get responses to their applications forget about getting client interviews. As the Saying goes ""when the Going gets tough the Tough get going"" Candidates who want to make a tech career they need to differentiate themselves by ensuring they have exceptional skills and technologies to be noticed by clients.

Since 2010 Synergisticit has helped Jobseekers differentiate themselves by providing candidates the requisite skills and experience to outperform at interviews and clients. Here at SynergisticIT We just don't focus on getting you a Job we make careers.

All Positions are open for all visas and US citizens

We are matchmakers we provide clients with candidates who can perform from day 1 of starting work. In this challenging economy every client wants to save $$$'s and they want the best value for their money. Jobseekers need to self-evaluate if they have the requisite skills to meet client requirements and needs. Clients now post covid can also hire remote workers which increases even more competition for jobseekers.

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, PayPal, western union, Client, visa, Walmart lab s etc. to name a few.

We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in IT Industry

We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

We also offer optionally Skill and technology enhancement programs for candidates who are either missing skills or are lacking Industry/Client experience with Projects and skills. Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. If they are qualified with enough skills and have hands on project work at clients then they should be good to be submitted to clients. Shortlisting and selection is totally based on clients discretion not ours.

please check the below links to see success outcomes of our candidates

https://www.synergisticit.com/candidate-outcomes/

We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please see us exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023

https://youtu.be/Rfn8Y0gnfL8?si=p2V4KFv5HukJXTrn

https://youtu.be/-HkNN1ag6Zk?si=1NRfgsvL_HJMVb6Q

https://www.youtube.com/watch?v=OAFOhcGy9Z8

https://www.youtube.com/watch?v=EmO7NrWHkLM

https://www.youtube.com/watch?v=NVBU9RYZ6UI

https://www.youtube.com/watch?v=Yy74yvjatVg

For preparing for interviews please visit https://www.synergisticit.com/interview-questions/

We are looking for the right matching candidates for our clients

Please apply via the job posting

REQUIRED SKILLS For Java /Full stack/Software Programmer
• Bachelor's degree or Master's degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
• Highly motivated, self-learner, and technically inquisitive
• Experience in programming language Java and understanding of the software development life cycle
• Project work on the skills
• Knowledge of Core Java, JavaScript, C++ or software programming
• Spring boot, Microservices, Docker, Jenkins and REST API's experience
• Excellent written and verbal communication skills

For data Science/Machine learning Positions

REQUIRED SKILLS
• Bachelor's degree or Master's degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
• Project work on the technologies needed
• Highly motivated, self-learner, and technically inquisitive
• Experience in programming language Java and understanding of the software development life cycle
• Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools
• Excellent written and verbal communication skills

Preferred skills: NLP, Text mining, Tableau, PowerBI, TensorFlow

If you get emails from our skill enhancement team please ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",,2025-07-25,"['Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in IT Industry', 'Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio', 'If they are qualified with enough skills and have hands on project work at clients then they should be good to be submitted to clients', 'REQUIRED SKILLS For Java /Full stack/Software Programmer', ""Bachelor's degree or Master's degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT"", 'Highly motivated, self-learner, and technically inquisitive', 'Experience in programming language Java and understanding of the software development life cycle', 'Project work on the skills', 'Knowledge of Core Java, JavaScript, C++ or software programming', ""Spring boot, Microservices, Docker, Jenkins and REST API's experience"", 'Excellent written and verbal communication skills', 'For data Science/Machine learning Positions', ""Bachelor's degree or Master's degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT"", 'Project work on the technologies needed', 'Highly motivated, self-learner, and technically inquisitive', 'Experience in programming language Java and understanding of the software development life cycle', 'Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools', 'Excellent written and verbal communication skills']",,True,['TensorFlow'],"TensorFlow: TensorFlow is a preferred skill, indicating use of deep learning frameworks for AI model development in data science and machine learning roles.","['Statistics', 'SAS', 'Python', 'Data Visualization Tools', 'Machine Learning', 'Computer Vision', 'NLP', 'Java', 'Core Java', 'JavaScript', 'C++', 'Spring Boot', 'Microservices', 'Docker', 'Jenkins', 'REST APIs', 'Project Work']","Statistics: Knowledge of statistics is required for data science and machine learning positions to analyze and interpret data effectively.; SAS: Experience with SAS is mentioned as a required skill for data science roles, indicating its use for statistical analysis and data management.; Python: Python programming language is required for data science and machine learning roles, supporting data analysis, scripting, and project work.; Data Visualization Tools: Familiarity with data visualization tools such as Tableau and PowerBI is preferred to create dashboards and visual insights from data.; Machine Learning: Machine learning knowledge is required for certain positions, including project work and understanding of related technologies.; Computer Vision: Computer vision is listed as a required skill area, indicating involvement with image or video data analysis in data science roles.; NLP: Natural Language Processing is a preferred skill, suggesting work with text mining and language data analysis.; Java: Java programming language experience is required for both software development and data science/machine learning roles.; Core Java: Knowledge of Core Java is required for software programming roles.; JavaScript: JavaScript knowledge is required for software programming and full stack development.; C++: C++ programming knowledge is required for software programming roles.; Spring Boot: Experience with Spring Boot framework is required for software development roles.; Microservices: Experience with microservices architecture is required for software development roles.; Docker: Docker experience is required for containerization in software development.; Jenkins: Jenkins experience is required for continuous integration and deployment in software development.; REST APIs: Experience with REST APIs is required for software development roles.; Project Work: Hands-on project work is emphasized as essential for candidates to demonstrate practical skills in both software development and data science/machine learning."
Q5yyelc-6pcT_Az8AAAAAA==,"Senior Data Scientist - Competitive Intelligence at Coinbase Memphis, TN","Senior Data Scientist - Competitive Intelligence job at Coinbase. Memphis, TN. Ready to be pushed beyond what you think you’re capable of?
At Coinbase, our mission is to increase economic freedom in the world. It’s a massive, ambitious opportunity that demands the best of us, every day, as we build the emerging onchain platform — and with it, the future global financial system.
To achieve our mission, we’re seeking a very specific candidate. We want someone who is passionate about our mission and who believes in the power of crypto and blockchain technology to update the financial system. We want someone who is eager to leave their mark on the world, who relishes the pressure and privilege of working with high caliber colleagues, and who actively seeks feedback to keep leveling up. We want someone who will run towards, not away from, solving the company’s hardest problems.
Our work culture is intense and isn’t for everyone. But if you want to build the future alongside others who excel in their disciplines and expect the same from you, there’s no better place to be.
While many roles at Coinbase are remote-first, we are not remote-only. In-person participation is required throughout the year. Team and company-wide offsites are held multiple times annually to foster collaboration, connection, and alignment. Attendance is expected and fully supported.Role Overview:
Data Science is a pivotal element of our operational strategy at Coinbase, influencing product, engineering, and decision-making processes. This role is integral to our senior leadership, investor relations, and peer teams– you will tackle complex, ambiguous questions that influence insights generation and decision making at the highest levels.
What You'll Be Doing:

Develop and maintain a comprehensive competitive intelligence framework to monitor industry trends and competitors' performance, products and activities
Engage with senior leadership to provide analytics and insights on business performance, competitive landscape and metric trends.
Gather, process, and analyze data from multiple sources (internal and external) to identify market trends and opportunities
Conduct exploratory data analysis (EDA) to uncover insights that explain business drivers and drive strategic decisions.
Prepare and present clear, concise readouts and dashboards for a senior-level audience, ensuring exceptional executive presence.
Develop and maintain data models and data pipelines to support data collection, analyses and reporting.

What We Look for in You:

A BA/BS or higher in a quantitative field such as Financial Engineering, Math, Statistics, Physics, or Computer Science. Preferably with ≥5+ years of relevant experience or a PhD in a quantitative field with with ≥3+ years of relevant experience
Demonstrated experience in driving impactful data science projects that tackle ambiguous problem spaces.
Ability to thrive in a fast-paced environment by effectively multitasking, prioritizing tasks, and managing competing demands
Ability to influence stakeholders by synthesizing data learnings into compelling stories.
Proven track record of effectively managing and communicating with senior leadership, including presenting complex information in a clear and concise manner
Self-starter with the determination and persistence to run through brick walls to achieve results
Professional experience using SQL and Python.
Understanding of the dynamics of working within a public company and managing sensitive stakeholder relationships.
Demonstration of our core cultural values: clear communication, positive energy, continuous learning, and efficient execution.

Disclaimer: Applying for a specific role does not guarantee consideration for that exact position. Leveling and team matching are assessed throughout the interview process.
ID: G2462Pay Transparency Notice: Depending on your work location, the target annual salary for this position can range as detailed below. Full time offers from Coinbase also include target bonus + benefits (including medical, dental, vision and 401(k)).Pay Range:$180,370—$212,200 USDPlease be advised that each candidate may submit a maximum of four applications within any 30-day period. We encourage you to carefully evaluate how your skills and interests align with Coinbase's roles before applying.
Commitment to Equal Opportunity
Coinbase is committed to diversity in its workforce and is proud to be an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, creed, gender, national origin, age, disability, veteran status, sex, gender expression or identity, sexual orientation or any other basis protected by applicable law. Coinbase will also consider for employment qualified applicants with criminal histories in a manner consistent with applicable federal, state and local law. For US applicants, you may view the Know Your Rights notice here. Additionally, Coinbase participates in the E-Verify program in certain locations, as required by law.
Coinbase is also committed to providing reasonable accommodations to individuals with disabilities. If you need a reasonable accommodation because of a disability for any part of the employment process, please contact us at accommodations[at]coinbase.com to let us know the nature of your request and your contact information. For quick access to screen reading technology compatible with this site click here to download a free compatible screen reader (free step by step tutorial can be found here).
Global Data Privacy Notice for Job Candidates and Applicants
Depending on your location, the General Data Protection Regulation (GDPR) and California Consumer Privacy Act (CCPA) may regulate the way we manage the data of job applicants. Our full notice outlining how data will be processed as part of the application procedure for applicable locations is available here. By submitting your application, you are agreeing to our use and processing of your data as required. For US applicants only, by submitting your application you are agreeing to arbitration of disputes as outlined here.",2025-06-30T00:00:00.000Z,2025-07-25,"['We want someone who is eager to leave their mark on the world, who relishes the pressure and privilege of working with high caliber colleagues, and who actively seeks feedback to keep leveling up', 'We want someone who will run towards, not away from, solving the company’s hardest problems', 'A BA/BS or higher in a quantitative field such as Financial Engineering, Math, Statistics, Physics, or Computer Science', 'Preferably with ≥5+ years of relevant experience or a PhD in a quantitative field with with ≥3+ years of relevant experience', 'Demonstrated experience in driving impactful data science projects that tackle ambiguous problem spaces', 'Ability to thrive in a fast-paced environment by effectively multitasking, prioritizing tasks, and managing competing demands', 'Ability to influence stakeholders by synthesizing data learnings into compelling stories', 'Proven track record of effectively managing and communicating with senior leadership, including presenting complex information in a clear and concise manner', 'Self-starter with the determination and persistence to run through brick walls to achieve results', 'Professional experience using SQL and Python', 'Understanding of the dynamics of working within a public company and managing sensitive stakeholder relationships']","['In-person participation is required throughout the year', 'Team and company-wide offsites are held multiple times annually to foster collaboration, connection, and alignment', 'Attendance is expected and fully supported', 'Data Science is a pivotal element of our operational strategy at Coinbase, influencing product, engineering, and decision-making processes', 'This role is integral to our senior leadership, investor relations, and peer teams– you will tackle complex, ambiguous questions that influence insights generation and decision making at the highest levels', ""Develop and maintain a comprehensive competitive intelligence framework to monitor industry trends and competitors' performance, products and activities"", 'Engage with senior leadership to provide analytics and insights on business performance, competitive landscape and metric trends', 'Gather, process, and analyze data from multiple sources (internal and external) to identify market trends and opportunities', 'Conduct exploratory data analysis (EDA) to uncover insights that explain business drivers and drive strategic decisions', 'Prepare and present clear, concise readouts and dashboards for a senior-level audience, ensuring exceptional executive presence', 'Develop and maintain data models and data pipelines to support data collection, analyses and reporting', 'Demonstration of our core cultural values: clear communication, positive energy, continuous learning, and efficient execution', 'Leveling and team matching are assessed throughout the interview process']",True,[],,"['Competitive Intelligence Framework', 'Exploratory Data Analysis', 'Data Models', 'Data Pipelines', 'SQL', 'Python', 'Analytics and Insights', 'Dashboards and Reporting']","Competitive Intelligence Framework: Develop and maintain a framework to monitor industry trends and competitors' performance, products, and activities to inform strategic decisions.; Exploratory Data Analysis: Conduct exploratory data analysis (EDA) to uncover insights that explain business drivers and support strategic decision-making.; Data Models: Develop and maintain data models to support data collection, analysis, and reporting for business insights.; Data Pipelines: Develop and maintain data pipelines to facilitate data collection, processing, and analysis from multiple internal and external sources.; SQL: Use SQL professionally to query and manage data as part of data analysis and model development.; Python: Use Python professionally for data processing, analysis, and building data science projects.; Analytics and Insights: Provide analytics and insights on business performance, competitive landscape, and metric trends to senior leadership to influence decision-making.; Dashboards and Reporting: Prepare and present clear, concise readouts and dashboards tailored for senior-level audiences to communicate complex information effectively."
XW0IRUn7bngH8eOnAAAAAA==,"Member of Technical Staff, Experimentation Data Scientist","At Microsoft, we are committed to advancing the frontiers of artificial intelligence in ways that are bold, responsible, and inclusive. Our vision is to build intelligent systems-spanning agents, applications, services, and infrastructure-that empower every person and organization on the planet to achieve more. We believe AI should be accessible to all: consumers, businesses, and developers alike.

The Microsoft AI (MAI) team is looking for an Experimentation Data Scientist to help shape the next generation of personal AI experiences through Copilot. This role involves managing and analyzing experiments to provide actionable insights that drive product improvements and user experience enhancements. Key Responsibilities: Experimentation Management: Collaborate with feature teams to design, implement, and debug experiments.

Conduct ad hoc analysis to understand metrics and user behavior changes. Statistical Analysis: Perform power analysis and experimental inference to ensure the validity and reliability of experiments. Data Analysis: Utilize SQL and Python to pull and analyze data quickly, providing insights into user behavior and experiment outcomes.

Collaboration: Work closely with partners to ensure robust telemetry and instrumentation and with feature teams to design and implement experiments. Qualifications Bachelor's Degree in Statistics, Econometrics, Computer Science, Electrical or Computer Engineering, or related field AND 6+ years related experience (e.g., statistics, predictive analytics, research) OR Master's Degree in Statistics, Econometrics, Computer Science, Electrical or Computer Engineering, or related field AND 4+ years related experience (e.g., statistics, predictive analytics, research) OR Doctorate in Statistics, Econometrics, Computer Science, Electrical or Computer Engineering, or related field AND 3+ years related experience (e.g., statistics, predictive analytics, research) OR equivalent experience. Strong background in statistics, economics, or a related field

Proficiency in SQL and Python. Experience with online A/B testing. Ability to conduct power analysis and experimental inference.

Strong problem-solving skills and attention to detail. Excellent communication and collaboration skills. Preferred Qualifications: Experience in a similar role within a data science or analytics team.

Familiarity with telemetry and instrumentation frameworks. Data Science IC5 - The typical base pay range for this role across the U.S. is USD $139,900 - $274,800 per year

There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $188,000 - $304,200 per year. Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here: https://careers.microsoft.com/us/en/us-corporate-pay Microsoft will accept applications for the role until Month Day, Year

Microsoft's mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.

#MAI Copilot",2025-07-10T00:00:00.000Z,2025-07-25,"[""Qualifications Bachelor's Degree in Statistics, Econometrics, Computer Science, Electrical or Computer Engineering, or related field AND 6+ years related experience (e.g., statistics, predictive analytics, research) OR Master's Degree in Statistics, Econometrics, Computer Science, Electrical or Computer Engineering, or related field AND 4+ years related experience (e.g., statistics, predictive analytics, research) OR Doctorate in Statistics, Econometrics, Computer Science, Electrical or Computer Engineering, or related field AND 3+ years related experience (e.g., statistics, predictive analytics, research) OR equivalent experience"", 'Strong background in statistics, economics, or a related field', 'Proficiency in SQL and Python', 'Experience with online A/B testing', 'Ability to conduct power analysis and experimental inference', 'Strong problem-solving skills and attention to detail', 'Excellent communication and collaboration skills', 'Familiarity with telemetry and instrumentation frameworks']","['This role involves managing and analyzing experiments to provide actionable insights that drive product improvements and user experience enhancements', 'Key Responsibilities: Experimentation Management: Collaborate with feature teams to design, implement, and debug experiments', 'Conduct ad hoc analysis to understand metrics and user behavior changes', 'Statistical Analysis: Perform power analysis and experimental inference to ensure the validity and reliability of experiments', 'Data Analysis: Utilize SQL and Python to pull and analyze data quickly, providing insights into user behavior and experiment outcomes', 'Collaboration: Work closely with partners to ensure robust telemetry and instrumentation and with feature teams to design and implement experiments']",True,[],,"['A/B Testing', 'Power Analysis', 'Experimental Inference', 'SQL', 'Python', 'Statistical Analysis', 'Telemetry and Instrumentation Frameworks']","A/B Testing: Used to design, implement, and analyze online experiments to evaluate product features and user experience changes.; Power Analysis: Performed to ensure the validity and reliability of experiments by determining the appropriate sample size and statistical power.; Experimental Inference: Applied to draw valid conclusions from experimentation data and assess the impact of changes on user behavior and metrics.; SQL: Utilized to extract and manipulate data efficiently for analysis of experiment outcomes and user behavior.; Python: Used for data analysis and ad hoc querying to provide actionable insights from experimentation data.; Statistical Analysis: Employed to analyze experiment data, including metrics evaluation and user behavior changes, ensuring robust conclusions.; Telemetry and Instrumentation Frameworks: Collaborated with partners to ensure robust data collection and instrumentation for accurate experiment tracking and analysis."
lmVpVHR6235f71D8AAAAAA==,Data Scientist- Minneapolis MNinnea,"Position- Data Scientist
Location- Minneapolis MN
Duration- Contract
Rate- DOE

Lead Researcher / Data Scientist
Proficiency across the entire Client pipeline is essential, coupled with a confident aptitude for evaluating outcomes and understand the business impact. As a pivotal member of a small team, you will take ownership of projects, adeptly managing and engaging stakeholders while adhering to industry best practices.

Additionally, a hunger for deeper Client/AI knowledge and a willingness to delve into the engineering and deployment facets of Client are crucial. The ability to thrive in an agile environment, fostering close collaboration with product, engineering, and UX teams, is paramount. We are particularly interested in candidates capable of swiftly validating business value and guiding projects to successful production. Prior experience in LLM is desirable. Join us in shaping the future of legal technology innovation!

As an Applied Scientist in Labs, you will be part of a global interdisciplinary team of experts. We hire specialists across a variety of AI research areas, as well as engineers, to drive the company's digital transformation. TR Labs is known for delivering innovative AI products that serve Client customers in new and exciting ways.

About The Role

As a Senior/Lead Data Scientist/Researcher, NLP you will:
• Experiment and Develop: You will drive the end-to-end model development lifecycle, championing best practices to ensure reproducible research and well-managed software delivery
• Collaborate : Working on a collaborative cross-functional team, you will share information, value diverse ideas, and partner effectively with colleagues across the globe. You will elevate and mentor teammates
• Deliver : with a sense of urgency and the desire to work in a fast-paced, dynamic environment, you will translate complex business problems into projects with clearly defined scope. Our problems are complex; our solutions are right-sized. You will be accountable for timely, well-managed deliverables
• Innovate : You will be empowered to try new approaches and learn new technologies. You will foster innovative ideas to solve real-world challenges
• Inspire : You will be a proactive communicator who is excited to share your work. You will be articulate and compelling in describing ideas to both technical and non-technical audiences. You will help lead the way in the adoption of AI across the enterprise.
Basic Qualifications
• Master or a a comparable level of experience
• At least 5 years practical, relevant experience building Client/AI systems, from ideation to production
• Solid software engineering skills for prototyping
• Professional experience as a technical leader, translating complex business problems into projects with clearly defined scope, coordinating and guiding the work of others",,2025-07-25,"['Proficiency across the entire Client pipeline is essential, coupled with a confident aptitude for evaluating outcomes and understand the business impact', 'Additionally, a hunger for deeper Client/AI knowledge and a willingness to delve into the engineering and deployment facets of Client are crucial', 'The ability to thrive in an agile environment, fostering close collaboration with product, engineering, and UX teams, is paramount', 'We are particularly interested in candidates capable of swiftly validating business value and guiding projects to successful production', 'You will be articulate and compelling in describing ideas to both technical and non-technical audiences', 'Master or a a comparable level of experience', 'At least 5 years practical, relevant experience building Client/AI systems, from ideation to production', 'Solid software engineering skills for prototyping', 'Professional experience as a technical leader, translating complex business problems into projects with clearly defined scope, coordinating and guiding the work of others']","['As a pivotal member of a small team, you will take ownership of projects, adeptly managing and engaging stakeholders while adhering to industry best practices', 'Experiment and Develop: You will drive the end-to-end model development lifecycle, championing best practices to ensure reproducible research and well-managed software delivery', 'Collaborate : Working on a collaborative cross-functional team, you will share information, value diverse ideas, and partner effectively with colleagues across the globe', 'You will elevate and mentor teammates', 'Deliver : with a sense of urgency and the desire to work in a fast-paced, dynamic environment, you will translate complex business problems into projects with clearly defined scope', 'You will be accountable for timely, well-managed deliverables', 'Innovate : You will be empowered to try new approaches and learn new technologies', 'You will foster innovative ideas to solve real-world challenges', 'Inspire : You will be a proactive communicator who is excited to share your work', 'You will help lead the way in the adoption of AI across the enterprise']",True,"['Large Language Models', 'Applied AI Research', 'AI Adoption Leadership']","Large Language Models: Prior experience in LLM is desirable, indicating involvement with large language models in AI systems.; Applied AI Research: Part of a global interdisciplinary team driving AI research and digital transformation through innovative AI products.; AI Adoption Leadership: Helping lead the adoption of AI across the enterprise by communicating AI concepts effectively to technical and non-technical audiences.","['Model Development Lifecycle', 'Stakeholder Management', 'Business Problem Translation', 'Collaboration in Cross-Functional Teams']","Model Development Lifecycle: Driving the end-to-end model development lifecycle, ensuring reproducible research and well-managed software delivery.; Stakeholder Management: Taking ownership of projects and adeptly managing and engaging stakeholders while adhering to industry best practices.; Business Problem Translation: Translating complex business problems into projects with clearly defined scope and guiding projects to successful production.; Collaboration in Cross-Functional Teams: Working collaboratively with product, engineering, UX teams, and global colleagues to share information and value diverse ideas."
2X2i3m-VlA5XoRFuAAAAAA==,"Staff, Data Scientist","Position Summary...

What you'll do...

We are looking for a computer vision scientist to solve some real retail problems/challenges. Utilize Computer Vision algorithms, Generative AI methods, deep learning architectures, VLMs and state-of-the-art techniques to build and deploy advanced retail solutions.

About Team:
At Walmart, we prioritize innovation and data security. Our team is dedicated to maintaining a secure operating environment and preserving the trust of our customers, associates, and stakeholders. We combine a range of services and expertise to prevent fraud, detect threats, and manage digital risk and access. Our focus is on mitigating attack risks, securing cloud transformation, and fostering a culture of security and reliability within our team

What you'll do:
• Design, train, and deploy deep learning models for object detection, image-based personalization, including product discovery, visual recommendations, and generative image content.
• Build and scale foundation model pipelines that leverage multimodal signals — including text, images, and customer embeddings — to power highly personalized visual experiences.
• Lead innovation efforts on image generative modeling, including diffusion models, CNNs, or text-to-image synthesis aligned with retail context.
• Implement efficient image understanding models for visual similarity, visual search, or classification across Walmart's vast product catalog.
• Design model workflow that integrates with MLOps to optimize model performance and latency, especially for customer-facing features with visual components.
• Contribute to cutting-edge research and internal knowledge by publishing work or presenting findings on vision-language models, multimodal personalization, and generative AI for e-commerce.

What you'll bring:
• MS or (preferably) PhD in Computer Science, Machine Learning, Computer Vision, Applied Mathematics, or a related technical field, with 2–4 years of industry or research experience.
• Demonstrated expertise in deep learning for computer vision, including CNNs, vision transformers (ViTs), and diffusion-based generative models.
• Experience building and deploying image generation, manipulation, or understanding systems in production — such as visual search, personalized image recommendations.
• Proficiency in Python and strong familiarity with deep learning frameworks such as PyTorch, TensorFlow, and image modeling libraries like OpenCV, torchvision, or Hugging Face.
• Familiarity with multimodal models (e.g., CLIP, BLIP, Flamingo) that combine vision and language for richer customer understanding and content personalization.
• Experience working with large-scale datasets, data pipelines, and distributed training.

About Walmart Global Tech
Imagine working in an environment where one line of code can make life easier for hundreds of millions of people. That’s what we do at Walmart Global Tech. We’re a team of software engineers, data scientists, cybersecurity expert's and service professionals within the world’s leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.

Walmart’s culture is a competitive advantage, and it’s fostered by being together. Working together in person allows us to collaborate, align quickly and innovate with greater speed. We use our campuses to create purposeful connection rooted in deepening understanding and investing in the development of our associates.
Our hubs: Walmart is a global company with offices across the United States and around the world. Our global headquarters is in Bentonville, Arkansas, with primary hubs in the San Francisco Bay area and New York/New Jersey.

Benefits:
Benefits: Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.

Equal Opportunity Employer:
Walmart, Inc. is an Equal Opportunity Employer – By Choice. We believe we are best equipped to help our associates, customers, and the communities we serve live better when we really know them. That means understanding, respecting, and valuing unique styles, experiences, identities, ideas, and opinions – while being inclusive of all people.

The above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

‎

‎

‎
You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.

‎

For information about PTO, see https://one.walmart.com/notices.

‎

‎
Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

‎
Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

‎

For information about benefits and eligibility, see One.Walmart.

‎
The annual salary range for this position is $110,000.00-$220,000.00

‎
Additional compensation includes annual or quarterly performance bonuses.

‎
Additional compensation for certain positions may also include:

‎

‎
- Stock

‎

‎

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 4 years' experience in an analytics related field. Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 2 years' experience in an analytics related field. Option 3: 6 years' experience in an analytics or related field

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data science, machine learning, optimization models, PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.

Primary Location...

805 Se Moberly Ln, Bentonville, AR 72712, United States of America",2025-07-22T00:00:00.000Z,2025-07-25,"['MS or (preferably) PhD in Computer Science, Machine Learning, Computer Vision, Applied Mathematics, or a related technical field, with 2–4 years of industry or research experience', 'Demonstrated expertise in deep learning for computer vision, including CNNs, vision transformers (ViTs), and diffusion-based generative models', 'Experience building and deploying image generation, manipulation, or understanding systems in production — such as visual search, personalized image recommendations', 'Proficiency in Python and strong familiarity with deep learning frameworks such as PyTorch, TensorFlow, and image modeling libraries like OpenCV, torchvision, or Hugging Face', 'Familiarity with multimodal models (e.g., CLIP, BLIP, Flamingo) that combine vision and language for richer customer understanding and content personalization', 'Experience working with large-scale datasets, data pipelines, and distributed training', ""Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 4 years' experience in an analytics related field"", ""Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 2 years' experience in an analytics related field"", ""Option 3: 6 years' experience in an analytics or related field"", 'Data science, machine learning, optimization models, PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly', 'The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture']","['We are looking for a computer vision scientist to solve some real retail problems/challenges', 'Utilize Computer Vision algorithms, Generative AI methods, deep learning architectures, VLMs and state-of-the-art techniques to build and deploy advanced retail solutions', 'Design, train, and deploy deep learning models for object detection, image-based personalization, including product discovery, visual recommendations, and generative image content', 'Build and scale foundation model pipelines that leverage multimodal signals — including text, images, and customer embeddings — to power highly personalized visual experiences', 'Lead innovation efforts on image generative modeling, including diffusion models, CNNs, or text-to-image synthesis aligned with retail context', ""Implement efficient image understanding models for visual similarity, visual search, or classification across Walmart's vast product catalog"", 'Design model workflow that integrates with MLOps to optimize model performance and latency, especially for customer-facing features with visual components', 'Contribute to cutting-edge research and internal knowledge by publishing work or presenting findings on vision-language models, multimodal personalization, and generative AI for e-commerce', 'That means understanding, respecting, and valuing unique styles, experiences, identities, ideas, and opinions – while being inclusive of all people']",True,"['Generative AI', 'Vision-Language Models', 'Deep Learning Frameworks for Neural Networks', 'Diffusion Models', 'Vision Transformers', 'Multimodal Foundation Models', 'MLOps for AI Models']","Generative AI: Employing generative AI methods including diffusion models and text-to-image synthesis to create advanced retail solutions such as generative image content and personalized visual recommendations.; Vision-Language Models: Using models like CLIP, BLIP, and Flamingo that integrate vision and language modalities to enhance customer understanding and content personalization in retail.; Deep Learning Frameworks for Neural Networks: Utilizing PyTorch and TensorFlow specifically for developing and deploying neural network architectures such as CNNs, vision transformers, and diffusion-based generative models.; Diffusion Models: Leading innovation in image generative modeling using diffusion-based generative models aligned with retail contexts for image generation and manipulation.; Vision Transformers: Applying vision transformer architectures (ViTs) for advanced image understanding and personalization tasks in retail.; Multimodal Foundation Models: Building and scaling pipelines that leverage multimodal signals (text, images, embeddings) to power personalized visual experiences and generative AI applications.; MLOps for AI Models: Designing model workflows integrated with MLOps to optimize performance and latency of AI models, especially for customer-facing visual features.","['Computer Vision', 'Deep Learning', 'Multimodal Models', 'Data Pipelines', 'Python', 'Machine Learning', 'Open Source Frameworks', 'Image Modeling Libraries', 'Data Science']","Computer Vision: Used to solve retail problems by applying algorithms for object detection, image-based personalization, visual similarity, visual search, and classification across a large product catalog.; Deep Learning: Designing, training, and deploying models such as CNNs and vision transformers for image understanding, personalization, and generative image content in retail applications.; Multimodal Models: Leveraging models that combine text, images, and customer embeddings to create highly personalized visual experiences and richer customer understanding.; Data Pipelines: Experience working with large-scale datasets and building scalable data pipelines to support distributed training and model deployment.; Python: Proficiency in Python programming language used for developing deep learning models and data processing.; Machine Learning: Applying machine learning techniques including optimization models and predictive analytics relevant to retail and e-commerce contexts.; Open Source Frameworks: Using frameworks such as scikit-learn, TensorFlow, and PyTorch for building and deploying machine learning and deep learning models.; Image Modeling Libraries: Utilizing libraries like OpenCV, torchvision, and Hugging Face for image processing, manipulation, and model development.; Data Science: Applying statistical and analytical methods to extract insights and build models that support retail solutions and personalization."
TlSdO-H7sbBty-NgAAAAAA==,"(USA) Senior Data Scientist, Tech","Position Summary...

What you'll do...

X4 Time Series Data Scientist – Forecasting & Generative AI

What you’ll do:

· Develop scalable time series forecasting systems leveraging global models like Temporal Fusion Transformers, N-BEATS, and PATCHTST, enabling robust forecasting across thousands of retails and e-commerce time series.

· Foundational Knowledge on advanced regression.

· Apply generative AI to synthesize time series data, enhance model training pipelines, and build intelligent NLP-based assistants for analytics enablement.

· Design and train large-scale neural networks for time series, anomaly detection, and causal inference, with deployment via automated batch pipelines using tools like Airflow or Astronomer.

· Build and maintain production-ready forecasting and LLM applications on cloud platforms (GCP or Azure), integrated with internal systems to deliver insights at scale.

· Perform Big Data processing and feature engineering using distributed compute platforms like Spark or Ray.

· Collaborate with cross-functional teams (product, engineering, business) to define objectives, formulate hypotheses, and deploy models that directly influence decision-making.

What you’ll bring:

· Strong foundation in time series forecasting, deep learning, and optimization theory, with a focus on sequence modeling and attention-based architectures.

· Experience in training and deploying transformer-based neural networks (e.g., TFT, LSTM, GPT variants) for real-world business applications.

· Proficient in Python, SQL, and hands-on with PyTorch, TensorFlow/Keras, Scikit-learn, and stats models.

· Demonstrated ability to work on GPU-based model training pipelines, and exposure to managing experimentation at scale.

Great to have:

· Hands-on experience with distributed training, multi-GPU setups, or TPU-based workflows.

· Exposure to LLM fine-tuning, retrieval-augmented generation (RAG), NLP applications.

· Familiarity with ML model monitoring, drift detection, and model retraining strategies in live systems.

· Knowledge of econometrics or domain experience in retail, demand forecasting, or e-commerce analytics.

Behavioral Qualifications:

· Self-starter with a problem-solving mindset, comfort with ambiguity, and ability to adapt quickly in a fast-paced environment.

· Strong communication skills to translate complex technical findings into actionable insights for non-technical stakeholders.

· A collaborative approach with a bias for action, ownership mindset, and a passion for learning and innovation.

About Walmart Global Tech:

Imagine working in an environment where one line of code can make life easier for hundreds of millions of people. Thats what we do at Walmart Global Tech. Were a team of software engineers, data scientists, cybersecurity experts and service professionals within the world's leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.

Flexible, hybrid work:

We use a hybrid way of working that is primarily in office coupled with virtual when not onsite. Our campuses serve as a hub to enhance collaboration, bring us together for purpose and deliver on business needs. This approach helps us make quicker decisions, remove location barriers across our global team and be more flexible in our personal lives.

Benefits:

Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.

Equal Opportunity Statement:

Walmart, Inc. is an Equal Opportunity Employer By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting, and valuing unique styles, experiences, identities, ideas and opinions while being welcoming of all people.

The above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

‎

‎

‎
You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.

‎

For information about PTO, see https://one.walmart.com/notices.

‎

‎
Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

‎
Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

‎

For information about benefits and eligibility, see One.Walmart.

‎
The annual salary range for this position is $73,000.00-$127,000.00

‎
Additional compensation includes annual or quarterly performance bonuses.

‎
Additional compensation for certain positions may also include:

‎
- Regional Pay Zone (RPZ) (based on location)

‎
- Stock

‎

‎

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1- Bachelor’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3
years' experience in an analytics related field. Option 2- Master’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science,
Information Technology, or related field and 1 years' experience in an analytics related field. Option 3 - 5 years' experience in an analytics or
related field.

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data science, machine learning, optimization models, Master’s degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch)

Primary Location...

805 Se Moberly Ln, Bentonville, AR 72712, United States of America",2025-07-21T00:00:00.000Z,2025-07-25,"['Experience in training and deploying transformer-based neural networks (e.g., TFT, LSTM, GPT variants) for real-world business applications', 'Proficient in Python, SQL, and hands-on with PyTorch, TensorFlow/Keras, Scikit-learn, and stats models', 'Demonstrated ability to work on GPU-based model training pipelines, and exposure to managing experimentation at scale', 'Hands-on experience with distributed training, multi-GPU setups, or TPU-based workflows', 'Exposure to LLM fine-tuning, retrieval-augmented generation (RAG), NLP applications', 'Familiarity with ML model monitoring, drift detection, and model retraining strategies in live systems', 'Knowledge of econometrics or domain experience in retail, demand forecasting, or e-commerce analytics', 'Self-starter with a problem-solving mindset, comfort with ambiguity, and ability to adapt quickly in a fast-paced environment', 'Strong communication skills to translate complex technical findings into actionable insights for non-technical stakeholders', 'A collaborative approach with a bias for action, ownership mindset, and a passion for learning and innovation', 'That means understanding, respecting, and valuing unique styles, experiences, identities, ideas and opinions while being welcoming of all people', 'Option 1- Bachelor’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3', ""years' experience in an analytics related field"", 'Option 2- Master’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science,', ""Information Technology, or related field and 1 years' experience in an analytics related field"", ""Option 3 - 5 years' experience in an analytics or"", 'Data science, machine learning, optimization models, Master’s degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch)']","['Develop scalable time series forecasting systems leveraging global models like Temporal Fusion Transformers, N-BEATS, and PATCHTST, enabling robust forecasting across thousands of retails and e-commerce time series', 'Foundational Knowledge on advanced regression', 'Apply generative AI to synthesize time series data, enhance model training pipelines, and build intelligent NLP-based assistants for analytics enablement', 'Design and train large-scale neural networks for time series, anomaly detection, and causal inference, with deployment via automated batch pipelines using tools like Airflow or Astronomer', 'Build and maintain production-ready forecasting and LLM applications on cloud platforms (GCP or Azure), integrated with internal systems to deliver insights at scale', 'Perform Big Data processing and feature engineering using distributed compute platforms like Spark or Ray', 'Collaborate with cross-functional teams (product, engineering, business) to define objectives, formulate hypotheses, and deploy models that directly influence decision-making', 'Strong foundation in time series forecasting, deep learning, and optimization theory, with a focus on sequence modeling and attention-based architectures']",True,"['Generative AI', 'Large Language Models', 'PyTorch', 'TensorFlow', 'LLM Fine-Tuning', 'Retrieval-Augmented Generation', 'NLP Applications', 'Transformer Neural Networks', 'ML Model Monitoring']","Generative AI: Apply generative AI techniques to synthesize time series data, enhance model training pipelines, and build intelligent NLP-based assistants for analytics enablement.; Large Language Models: Build and maintain production-ready large language model (LLM) applications integrated with internal systems to deliver scalable insights.; PyTorch: Use PyTorch for developing and training deep learning models, including transformer-based neural networks.; TensorFlow: Employ TensorFlow/Keras frameworks for designing and training deep neural networks applied to time series and NLP tasks.; LLM Fine-Tuning: Engage in fine-tuning large language models to adapt them for specific business applications and improve performance.; Retrieval-Augmented Generation: Implement retrieval-augmented generation (RAG) techniques to enhance NLP applications by integrating external knowledge retrieval with generative models.; NLP Applications: Develop NLP-based intelligent assistants and applications to support analytics and decision-making.; Transformer Neural Networks: Train and deploy transformer architectures such as GPT variants for real-world business applications involving sequence modeling and language understanding.; ML Model Monitoring: Monitor machine learning models in production for drift detection and implement retraining strategies to maintain model accuracy over time.","['Time Series Forecasting', 'Advanced Regression', 'Feature Engineering', 'Big Data Processing', 'Machine Learning', 'Neural Networks', 'Transformer Models', 'Model Deployment Pipelines', 'SQL', 'Python', 'Scikit-learn', 'Statsmodels', 'Spark', 'Ray', 'GPU-based Model Training', 'Multi-GPU and TPU Workflows', 'Econometrics', 'Optimization Theory']","Time Series Forecasting: Develop scalable forecasting systems using advanced global models to enable robust predictions across thousands of retail and e-commerce time series.; Advanced Regression: Apply foundational knowledge of advanced regression techniques to support forecasting and predictive modeling tasks.; Feature Engineering: Perform feature engineering on large datasets using distributed compute platforms like Spark and Ray to improve model performance.; Big Data Processing: Handle large-scale data processing tasks leveraging distributed computing frameworks such as Spark and Ray.; Machine Learning: Utilize machine learning methods including optimization models and sequence modeling to build predictive models and support decision-making.; Neural Networks: Design and train large-scale neural networks for time series analysis, anomaly detection, and causal inference.; Transformer Models: Train and deploy transformer-based neural networks such as Temporal Fusion Transformers (TFT) and LSTM for sequence modeling and forecasting.; Model Deployment Pipelines: Deploy models via automated batch pipelines using orchestration tools like Airflow or Astronomer to ensure production readiness.; SQL: Use SQL for data querying and manipulation as part of data processing and feature engineering workflows.; Python: Employ Python programming for data science tasks including model development, data processing, and experimentation.; Scikit-learn: Leverage scikit-learn for implementing classical machine learning algorithms and statistical modeling.; Statsmodels: Use statsmodels for statistical modeling and econometrics analysis relevant to forecasting and causal inference.; Spark: Utilize Apache Spark for distributed data processing and feature engineering on big data.; Ray: Apply Ray for distributed computing to scale data processing and model training tasks.; GPU-based Model Training: Work on GPU-accelerated pipelines to train complex models efficiently at scale.; Multi-GPU and TPU Workflows: Experience with distributed training using multi-GPU setups or TPU-based workflows to optimize model training performance.; Econometrics: Apply econometric methods and domain knowledge in retail, demand forecasting, and e-commerce analytics to improve model relevance.; Optimization Theory: Use optimization theory principles to enhance model training and forecasting accuracy."
bwefpvyZgb9Xr6OzAAAAAA==,"Principal, Data Scientist - People.AI","Position Summary...

What you'll do...

About Walmart

Walmart employs more than 2.3 million associates worldwide, with 1.6 million associates in the U.S. Each year, Walmart hires 500,000 applicants to fill thousands of job profiles from engineers, designers, and marketers to pilots and buyers. We promote over 300,000 people annually to positions of greater responsibility.

About People Technology Team

The Enterprise People Technology team supports the successful deployment and adoption of new People technology across the enterprise. As a Fortune #1 company, our work impacts millions of associates globally. We strive to continuously improve people technology and products to help managers and associates focus on what matters most - supporting our customers and members. People Technology is a significant segment of Walmart Global Tech’s Enterprise Business Services, invested in building a compact, robust organization that includes service operations and technology solutions for Finance, People, and the Associate Digital Experience.

About People.AI Team

The People.AI team is responsible for developing and deploying AI/ML solutions supporting the Walmart associates globally. In this role, you will build an LLM-powered intelligent experience within a chatbot or business application to enhance associate experience and productivity. You will design and build an intelligent conversational interface that improves communication, automates tasks, accesses data and insights, and provides personalized Q&A support to associates, ultimately creating a more efficient and engaging work environment.

What You'll Do
• Develop LLM-powered intelligent experiences that interpret and generate insights from both tabular and unstructured data.
• Build and optimize personalized Q&A systems using large language models, enabling context-aware responses tailored to user needs.
• Design and enhance conversational talent recommendation systems, combining autonomous agent architectures with personalized recommendation algorithms.
• Advance traditional recommendation systems by evolving them from simple ranked lists to multi-topic, interactive experiences that better reflect user intent.
• Construct multi-agent intelligent workflows that translate natural language inputs into complex, goal-directed task sequences.
• Collaborate within a highly cross-functional team, including data scientists, machine learning engineers, product managers, and UX designers.
• Partner with fellow data scientists to design, prototype, and iterate on AI/ML models and system architectures.
• Work closely with machine learning engineers to deploy, monitor, and optimize scalable AI/ML solutions in production environments.
• Collaborate with product managers to design intuitive user experiences, define feedback loops, and analyze user telemetry to guide product improvements.
• Engage in end-to-end AI/ML product development, from ideation to deployment, while continually expanding your technical and product skillset.
• Follow and help define robust development standards to ensure the creation of trustworthy, safe, and responsible AI systems.
• Contribute to internal and external AI/ML research through experimentation, whitepapers, and collaboration with the broader AI community.

What You'll Bring
• Proven experience deploying high-risk NLP applications in real-world, production environments—such as those involving regulatory compliance, privacy, safety, or fairness.
• Demonstrated ability to advance and implement Trustworthy AI and Responsible ML practices, working cross-functionally with engineering, legal, policy, and product stakeholders across a large enterprise.
• Track record of mentoring and coaching junior data scientists, especially in navigating ambiguous or novel problem spaces.
• Strong applied machine learning experience, with solid foundational knowledge in statistics, optimization, and deep learning—preferably gained at leading technology companies (e.g., Google, Meta, Microsoft) or AI-first startups.
• Excellent communication skills with the ability to synthesize complex technical work into accessible insights for executive briefings, research publications, and external presentations.
• Advanced proficiency in Python and common ML/DS libraries such as NumPy, pandas, scikit-learn, as well as deep learning frameworks like TensorFlow, PyTorch.
• Experience designing and deploying scalable deep learning systems, including neural network architecture optimization, model distillation, quantization, or on-device inference.
• Strong understanding of machine learning infrastructure, including experience with Kubeflow, MLflow, Airflow is a plus.
• 8+ years of industry experience, with a demonstrated ability to take ownership of complex projects and deliver impactful AI/ML solutions from concept to production.

Bonus Skills:
• Hands-on experience with Text-to-SQL or Text-to-Cypher based application, or the design of modern recommender systems.
• Experience developing or fine-tuning large language models (LLMs), including prompt engineering, retrieval-augmented generation (RAG), or open-weight model customization.
• Publication history in top-tier ML/NLP conferences such as NeurIPS, ICML, ACL, EMNLP, or ICLR

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

‎

‎

‎
You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.

‎

For information about PTO, see https://one.walmart.com/notices.

‎

‎
Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

‎
Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

‎

For information about benefits and eligibility, see One.Walmart.

‎
The annual salary range for this position is $110,000.00-$220,000.00

‎
Additional compensation includes annual or quarterly performance bonuses.

‎
Additional compensation for certain positions may also include:

‎

‎
- Stock

‎

‎

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 5 years' experience in an analytics related field. Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 3 years' experience in an analytics related field. Option 3: 7 years' experience in an analytics or related field

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data science, machine learning, optimization models, PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Publications or active peer reviewer in related journals or conference, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.

Primary Location...

2501 Se J St, Ste A, Bentonville, AR 72716-3724, United States of America",2025-07-20T00:00:00.000Z,2025-07-25,"['Proven experience deploying high-risk NLP applications in real-world, production environments—such as those involving regulatory compliance, privacy, safety, or fairness', 'Demonstrated ability to advance and implement Trustworthy AI and Responsible ML practices, working cross-functionally with engineering, legal, policy, and product stakeholders across a large enterprise', 'Track record of mentoring and coaching junior data scientists, especially in navigating ambiguous or novel problem spaces', 'Strong applied machine learning experience, with solid foundational knowledge in statistics, optimization, and deep learning—preferably gained at leading technology companies (e.g., Google, Meta, Microsoft) or AI-first startups', 'Excellent communication skills with the ability to synthesize complex technical work into accessible insights for executive briefings, research publications, and external presentations', 'Advanced proficiency in Python and common ML/DS libraries such as NumPy, pandas, scikit-learn, as well as deep learning frameworks like TensorFlow, PyTorch', 'Experience designing and deploying scalable deep learning systems, including neural network architecture optimization, model distillation, quantization, or on-device inference', '8+ years of industry experience, with a demonstrated ability to take ownership of complex projects and deliver impactful AI/ML solutions from concept to production', 'Hands-on experience with Text-to-SQL or Text-to-Cypher based application, or the design of modern recommender systems', 'Experience developing or fine-tuning large language models (LLMs), including prompt engineering, retrieval-augmented generation (RAG), or open-weight model customization', 'Publication history in top-tier ML/NLP conferences such as NeurIPS, ICML, ACL, EMNLP, or ICLR', ""Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 5 years' experience in an analytics related field"", ""Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 3 years' experience in an analytics related field"", ""Option 3: 7 years' experience in an analytics or related field"", 'Data science, machine learning, optimization models, PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Publications or active peer reviewer in related journals or conference, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly', 'The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture']","['In this role, you will build an LLM-powered intelligent experience within a chatbot or business application to enhance associate experience and productivity', 'You will design and build an intelligent conversational interface that improves communication, automates tasks, accesses data and insights, and provides personalized Q&A support to associates, ultimately creating a more efficient and engaging work environment', 'Develop LLM-powered intelligent experiences that interpret and generate insights from both tabular and unstructured data', 'Build and optimize personalized Q&A systems using large language models, enabling context-aware responses tailored to user needs', 'Design and enhance conversational talent recommendation systems, combining autonomous agent architectures with personalized recommendation algorithms', 'Advance traditional recommendation systems by evolving them from simple ranked lists to multi-topic, interactive experiences that better reflect user intent', 'Construct multi-agent intelligent workflows that translate natural language inputs into complex, goal-directed task sequences', 'Collaborate within a highly cross-functional team, including data scientists, machine learning engineers, product managers, and UX designers', 'Partner with fellow data scientists to design, prototype, and iterate on AI/ML models and system architectures', 'Work closely with machine learning engineers to deploy, monitor, and optimize scalable AI/ML solutions in production environments', 'Collaborate with product managers to design intuitive user experiences, define feedback loops, and analyze user telemetry to guide product improvements', 'Engage in end-to-end AI/ML product development, from ideation to deployment, while continually expanding your technical and product skillset', 'Follow and help define robust development standards to ensure the creation of trustworthy, safe, and responsible AI systems', 'Contribute to internal and external AI/ML research through experimentation, whitepapers, and collaboration with the broader AI community']",True,"['Large Language Models (LLMs)', 'Prompt Engineering', 'Retrieval-Augmented Generation', 'Conversational AI and Autonomous Agents', 'Trustworthy AI and Responsible ML']","Large Language Models (LLMs): The role focuses on developing and deploying LLM-powered intelligent experiences, including building personalized Q&A systems, fine-tuning LLMs, and creating conversational interfaces that enhance associate productivity and communication.; Prompt Engineering: Experience with prompt engineering is required for customizing and optimizing large language models to generate context-aware responses tailored to user needs.; Retrieval-Augmented Generation: The job involves working with retrieval-augmented generation (RAG) techniques to enhance LLM capabilities by integrating external data retrieval for improved response accuracy and relevance.; Conversational AI and Autonomous Agents: Designing conversational talent recommendation systems and constructing multi-agent intelligent workflows that translate natural language inputs into complex, goal-directed task sequences are key responsibilities, involving autonomous agent architectures.; Trustworthy AI and Responsible ML: The position requires advancing and implementing trustworthy AI and responsible machine learning practices, ensuring safety, fairness, privacy, and regulatory compliance in high-risk NLP applications deployed in production environments.","['Machine Learning', 'Deep Learning Frameworks', 'Python and ML/DS Libraries', 'Recommendation Systems', 'Data Science', 'Machine Learning Infrastructure', 'Text-to-SQL and Text-to-Cypher Applications']","Machine Learning: The role involves strong applied machine learning experience with foundational knowledge in statistics and optimization, designing and deploying scalable machine learning models, and collaborating with data scientists and machine learning engineers to develop AI/ML models and system architectures.; Deep Learning Frameworks: The job requires advanced proficiency in deep learning frameworks such as TensorFlow and PyTorch, including experience in neural network architecture optimization, model distillation, quantization, and on-device inference.; Python and ML/DS Libraries: Advanced proficiency in Python and common machine learning and data science libraries such as NumPy, pandas, and scikit-learn is essential for developing and deploying AI/ML solutions.; Recommendation Systems: Design and enhancement of conversational talent recommendation systems and modern recommender systems are part of the responsibilities, evolving traditional ranked list approaches to multi-topic, interactive experiences reflecting user intent.; Data Science: The position requires expertise in data science, including interpreting and generating insights from tabular and unstructured data, and collaborating with data scientists to prototype and iterate on models.; Machine Learning Infrastructure: Experience with machine learning infrastructure tools such as Kubeflow, MLflow, and Airflow is considered a plus for deploying, monitoring, and optimizing scalable AI/ML solutions in production environments.; Text-to-SQL and Text-to-Cypher Applications: Hands-on experience with Text-to-SQL or Text-to-Cypher based applications is valued, indicating work with translating natural language queries into database queries as part of intelligent systems."
M_ZRUaefrohfGkDxAAAAAA==,"(USA) Senior Manager, Data Science","Position Summary...

What you'll do...

Senior Manager, Data Science – Last Mile Delivery

Elevator Pitch

Lead the strategy and execution for Walmart’s core Last Mile Delivery platform algorithm. Own algorithmic decisions that directly impact customer experience, driver performance, and Walmart’s cost structure. Apply LLMs, Gen AI, and advanced ML techniques to solve high-impact logistics challenges. Act as a thought leader in a high-visibility, independent role with direct senior leadership engagement.

Key Responsibilities

- Own and lead end-to-end strategy, design, and optimization of Last Mile Delivery platform algorithms.

-Serve as the primary thought leader for algorithmic decisions affecting Last Mile logistics.

- Drive alignment with cross-functional teams including engineering, product, and business leadership. - Integrate cutting-edge technologies such as LLMs, Gen AI, and advanced ML techniques to improve routing efficiency.

- Lead large-scale data analysis to identify opportunities for operational and business improvement.

- Present complex technical insights to senior leadership in a clear, business-relevant way.

- Ensure delivery of scalable, robust, and measurable solutions that impact key business outcomes.

- Mentor and guide junior data scientists and team members.

Why Join Us

- Direct ownership of a mission-critical algorithm with national-scale impact.

- Shape the future of Walmart’s Last Mile Delivery through innovation and leadership.

- High visibility role with recognition for driving strategic business results.

Ideal Candidate Profile

- 6–8+ years of experience in data science, machine learning, and logistics or routing optimization.

- Proven leadership experience managing projects or teams in a technical environment.

- Expertise in advanced ML techniques, optimization, and cloud platforms (e.g., GCP).

- Strong business acumen combined with exceptional communication and stakeholder management skills.

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

‎

‎

‎
You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.

‎

For information about PTO, see https://one.walmart.com/notices.

‎

‎
Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

‎
Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

‎

For information about benefits and eligibility, see One.Walmart.

‎
The annual salary range for this position is $110,000.00-$220,000.00

‎
Additional compensation includes annual or quarterly performance bonuses.

‎
Additional compensation for certain positions may also include:

‎

‎
- Stock

‎

‎

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 5 years' experience in an analytics related field. Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 3 years' experience in an analytics related field. Option 3: 7 years' experience in an analytics or related field.

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data science, machine learning, optimization models, PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Supervisory experience, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.

Primary Location...

702 Sw 8Th St, Bentonville, AR 72716, United States of America",2025-07-24T00:00:00.000Z,2025-07-25,"['6–8+ years of experience in data science, machine learning, and logistics or routing optimization', 'Proven leadership experience managing projects or teams in a technical environment', 'Expertise in advanced ML techniques, optimization, and cloud platforms (e.g., GCP)', 'Strong business acumen combined with exceptional communication and stakeholder management skills', ""Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 5 years' experience in an analytics related field"", ""Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 3 years' experience in an analytics related field"", ""Option 3: 7 years' experience in an analytics or related field"", 'Data science, machine learning, optimization models, PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Supervisory experience, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly', 'The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture']","['Lead the strategy and execution for Walmart’s core Last Mile Delivery platform algorithm', 'Own algorithmic decisions that directly impact customer experience, driver performance, and Walmart’s cost structure', 'Apply LLMs, Gen AI, and advanced ML techniques to solve high-impact logistics challenges', 'Act as a thought leader in a high-visibility, independent role with direct senior leadership engagement', 'Own and lead end-to-end strategy, design, and optimization of Last Mile Delivery platform algorithms', 'Serve as the primary thought leader for algorithmic decisions affecting Last Mile logistics', 'Drive alignment with cross-functional teams including engineering, product, and business leadership. - Integrate cutting-edge technologies such as LLMs, Gen AI, and advanced ML techniques to improve routing efficiency', 'Lead large-scale data analysis to identify opportunities for operational and business improvement', 'Present complex technical insights to senior leadership in a clear, business-relevant way', 'Ensure delivery of scalable, robust, and measurable solutions that impact key business outcomes', 'Mentor and guide junior data scientists and team members']",True,"['Large Language Models', 'Generative AI', 'TensorFlow', 'PyTorch']","Large Language Models: Applied to solve logistics challenges and improve routing efficiency as part of the Last Mile Delivery platform.; Generative AI: Integrated into the Last Mile Delivery platform to enhance algorithmic decision-making and operational performance.; TensorFlow: Used as an open-source framework for developing AI models, including neural networks, within the data science team.; PyTorch: Used as an open-source framework for building and training AI models, including neural networks, in the context of advanced AI applications.","['Advanced Machine Learning Techniques', 'Optimization Models', 'Large-Scale Data Analysis', 'Python', 'Spark', 'Scala', 'R', 'Scikit-learn', 'Cloud Platforms (e.g., GCP)']","Advanced Machine Learning Techniques: Used to solve high-impact logistics challenges and improve routing efficiency within the Last Mile Delivery platform.; Optimization Models: Applied to design and optimize algorithms for Last Mile Delivery to enhance operational efficiency and cost structure.; Large-Scale Data Analysis: Conducted to identify opportunities for operational and business improvements in Last Mile Delivery.; Python: One of the programming languages assessed and used for data science and machine learning tasks.; Spark: Used as a framework for handling large-scale data processing and analytics.; Scala: Used as a programming language for data processing and analytics tasks.; R: Used for statistical analysis and data science tasks.; Scikit-learn: An open-source framework used for implementing machine learning models and algorithms.; Cloud Platforms (e.g., GCP): Utilized to deploy and manage machine learning and data science solutions at scale."
WvC-xZO3_loct8pSAAAAAA==,"Senior Data Scientist, AWS Professional Services","Description

Are you looking to work at the forefront of Machine Learning (ML) and Artificial Intelligence (AI)? Would you be excited to apply AI algorithms to solve real world problems with significant impact? The Amazon Web Services Professional Services (ProServe) team is seeking a skilled Senior Data Scientist to help customers implement AI/ML solutions and realize transformational business opportunities.

This is a team of scientists, engineers, and architects working step-by-step with customers to build bespoke solutions that harness the power of AI. The team helps customers imagine and scope the use cases that will create the greatest value for their businesses, select and train and fine-tune the right models, define paths to navigate technical or business challenges, develop scalable solutions and applications, and launch them in production. The team provides guidance and implements best practices for applying AI responsibly and cost efficiently.

You will work directly with customers and innovate in a fast-paced organization that contributes to game-changing projects and technologies. You will design and run experiments, research new algorithms, and find new ways of optimizing risk, profitability, and customer experience.

We’re looking for Senior Data Scientists capable of using AI/ML and other techniques to design, evangelize, and implement state-of-the-art solutions for never-before-solved problems.

Key job responsibilities

As an experienced Senior Data Scientist, you will be responsible for:
• Lead end-to-end AI/ML and GenAI projects, from understanding business needs to data preparation, model development, solution deployment, and post-production monitoring
• Collaborate with AI/ML scientists, engineers, and architects to research, design, develop, and evaluate AI algorithms and build ML systems and operations (MLOps) using AWS services to address real-world challenges
• Interact with customers directly to understand the business challenges, deliver briefing and deep dive sessions to customers and guide them on adoption patterns and paths to production
• Create and deliver best practice recommendations, tutorials, blog posts, publications, sample code, and presentations tailored to technical, business, and executive stakeholders
• Provide customer and market feedback to product and engineering teams to help define product direction

This is a customer-facing role with potential travel to customer sites as needed.

About The Team

ABOUT AWS:

Diverse Experiences

Amazon values diverse experiences. Even if you do not meet all of the preferred qualifications and skills listed in the job description, we encourage candidates to apply. If your career is just starting, hasn’t followed a traditional path, or includes alternative experiences, don’t let it stop you from applying.

Why AWS

Amazon Web Services (AWS) is the world’s most comprehensive and broadly adopted cloud platform. We pioneered cloud computing and never stopped innovating — that’s why customers from the most successful startups to Global 500 companies trust our robust suite of products and services to power their businesses.

Work/Life Balance

We value work-life harmony. Achieving success at work should never come at the expense of sacrifices at home, which is why we strive for flexibility as part of our working culture. When we feel supported in the workplace and at home, there’s nothing we can’t achieve in the cloud.

Inclusive Team Culture

Here at AWS, it’s in our nature to learn and be curious. Our employee-led affinity groups foster a culture of inclusion that empower us to be proud of our differences. Ongoing events and learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences, inspire us to never stop embracing our uniqueness.

Mentorship and Career Growth

We’re continuously raising our performance bar as we strive to become Earth’s Best Employer. That’s why you’ll find endless knowledge-sharing, mentorship and other career-advancing resources here to help you develop into a better-rounded professional.

Basic Qualifications
• Master's degree in computer science, machine learning, robotics, operations research, statistics, mathematics or equivalent quantitative field with 5+ years of experience; or bachelor's degree with 8+ years of experience
• 5+ years of building machine learning models for business application experience
• 3+ years of hands-on experience with training, fine-tuning, evaluating, and deploying transformer models in production
• Experience with cloud services related to machine learning (e.g., Amazon SageMaker) and generative AI applications
• Experience with technical customer-facing engagements, and strong communication skills, with attention to detail and ability to convey rigorous technical concepts and considerations to non-experts

Preferred Qualifications
• PhD in computer science, machine learning, robotics, operations research, statistics, mathematics or equivalent quantitative field
• AWS experience preferred, with proficiency in a range of AWS services (e.g., SageMaker, Bedrock, EC2, ECS, EKS, OpenSearch, VPC) and professional certifications (e.g., Solutions Architect Professional)
• 2+ years of experience with design, deployment, and evaluation of AI agents and orchestration approaches; experience with open source frameworks like LangChain, LangGraph, LlamaIndex, and/ or similar tools
• 5+ years of deep learning, computer vision, human robotic interaction, algorithms implementation experience using PyTorch or TensorFlow
• Experience in launching AI applications in production on AWS
• Experience building ML pipelines with MLOps best practices, including: data preprocessing, distributed & GPU training, model deployment, monitoring, and retraining; experience with container and CI/CD pipelines

Amazon is an equal opportunity employer and does not discriminate on the basis of protected veteran status, disability, or other legally protected status.

Los Angeles County applicants: Job duties for this position include: work safely and cooperatively with other employees, supervisors, and staff; adhere to standards of excellence despite stressful conditions; communicate effectively and respectfully with employees, supervisors, and staff to ensure exceptional customer service; and follow all federal, state, and local laws and Company policies. Criminal history may have a direct, adverse, and negative relationship with some of the material job duties of this position. These include the duties and responsibilities listed above, as well as the abilities to adhere to company policies, exercise sound judgment, effectively manage stress and work safely and respectfully with others, exhibit trustworthiness and professionalism, and safeguard business operations and the Company’s reputation. Pursuant to the Los Angeles County Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $143,300/year in our lowest geographic market up to $247,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.

Company - Amazon Web Services, Inc.

Job ID: A2999972",2025-07-18T00:00:00.000Z,2025-07-25,"[""Master's degree in computer science, machine learning, robotics, operations research, statistics, mathematics or equivalent quantitative field with 5+ years of experience; or bachelor's degree with 8+ years of experience"", '5+ years of building machine learning models for business application experience', '3+ years of hands-on experience with training, fine-tuning, evaluating, and deploying transformer models in production', 'Experience with cloud services related to machine learning (e.g., Amazon SageMaker) and generative AI applications', 'Experience with technical customer-facing engagements, and strong communication skills, with attention to detail and ability to convey rigorous technical concepts and considerations to non-experts', 'These include the duties and responsibilities listed above, as well as the abilities to adhere to company policies, exercise sound judgment, effectively manage stress and work safely and respectfully with others, exhibit trustworthiness and professionalism, and safeguard business operations and the Company’s reputation']","['The team helps customers imagine and scope the use cases that will create the greatest value for their businesses, select and train and fine-tune the right models, define paths to navigate technical or business challenges, develop scalable solutions and applications, and launch them in production', 'You will work directly with customers and innovate in a fast-paced organization that contributes to game-changing projects and technologies', 'You will design and run experiments, research new algorithms, and find new ways of optimizing risk, profitability, and customer experience', 'We’re looking for Senior Data Scientists capable of using AI/ML and other techniques to design, evangelize, and implement state-of-the-art solutions for never-before-solved problems', 'Lead end-to-end AI/ML and GenAI projects, from understanding business needs to data preparation, model development, solution deployment, and post-production monitoring', 'Collaborate with AI/ML scientists, engineers, and architects to research, design, develop, and evaluate AI algorithms and build ML systems and operations (MLOps) using AWS services to address real-world challenges', 'Interact with customers directly to understand the business challenges, deliver briefing and deep dive sessions to customers and guide them on adoption patterns and paths to production', 'Create and deliver best practice recommendations, tutorials, blog posts, publications, sample code, and presentations tailored to technical, business, and executive stakeholders', 'Provide customer and market feedback to product and engineering teams to help define product direction', 'This is a customer-facing role with potential travel to customer sites as needed']",True,"['Generative AI', 'Large Language Models (LLMs)', 'AI Model Fine-Tuning', 'AI MLOps', 'AI Agents and Orchestration']","Generative AI: Leading projects involving generative AI applications, including model selection, training, fine-tuning, and deployment to create innovative AI solutions.; Large Language Models (LLMs): Hands-on experience with training, fine-tuning, evaluating, and deploying transformer-based LLMs in production, and collaborating on AI algorithms involving LLMs.; AI Model Fine-Tuning: Fine-tuning AI models, particularly transformer-based models, to tailor them for specific business use cases and improve performance.; AI MLOps: Building and managing AI-specific ML operations pipelines that include deployment, monitoring, and retraining of AI models, especially LLMs and generative AI models, using AWS services.; AI Agents and Orchestration: Designing, deploying, and evaluating AI agents and orchestration approaches using frameworks such as LangChain, LangGraph, and LlamaIndex to build AI-native solutions.","['Machine Learning', 'Transformer Models', 'AWS Machine Learning Services', 'MLOps', 'Deep Learning Frameworks', 'AI Agents and Orchestration Frameworks']","Machine Learning: Used to build models for business applications, including training, fine-tuning, evaluating, and deploying models in production to solve real-world problems and optimize business outcomes.; Transformer Models: Experience required in training, fine-tuning, evaluating, and deploying transformer models in production environments as part of AI/ML solutions.; AWS Machine Learning Services: Utilization of AWS cloud services such as Amazon SageMaker for building, training, deploying, and managing machine learning models and pipelines.; MLOps: Building and managing ML systems and operations including data preprocessing, distributed and GPU training, model deployment, monitoring, and retraining, following best practices and using container and CI/CD pipelines.; Deep Learning Frameworks: Experience with PyTorch and TensorFlow for implementing deep learning, computer vision, and robotics algorithms.; AI Agents and Orchestration Frameworks: Design, deployment, and evaluation of AI agents and orchestration approaches using open source frameworks like LangChain, LangGraph, and LlamaIndex."
CBAdXkHc6Pv_MTV_AAAAAA==,"Data Scientist, Senior (Clearance Required) - Remote work local to DC Metro or FL","ICF International seeks an experienced Senior Data Scientist to support the research and development of new cyber analytic capabilities that will help the US protect and defend its networks and critical information systems. The successful cleared candidate will act as a Senior Data Scientist to support a large federal cyber security analytic program. Your work will contribute to the knowledge of how cyber-attacks work, how vulnerabilities are exploited, and the way hostile cyber actors operate. Utilize your skills to help experiment and prototype future cyber capabilities for implementation at large scale.

As the Senior Data Scientist, your exceptional skillset will create useful and actionable insight for the customer through the development of machine learning, deep learning models, and related algorithms. The ideal candidate is strong mathematically; can automate scoring using machine learning techniques, build recommendation systems, and select the correct data points for analysis from large data sets. You are focused on results, a self-starter, and have demonstrated success for using analytics to drive the understanding, growth, and success of the analysis. This is an opportunity to contribute to an important project from the beginning, work with the latest and emerging technologies, and all while building a great career at ICF!

This role is primarily telework-based with occasional meetings at client locations (Arlington, VA or Pensacola, FL) or ICF facilities within the National Capital Region (Washington, DC Metro Area).

What You Will Be Doing:
• Perform knowledge elicitation from customer subject matter experts and convert that to derived algorithms
• Analyze large data sets to identify actionable insights with mathematical statistical rigor
• Rigorously critique and correct intermediate results to improve the algorithmic outcomes
• Design and deploy deep learning algorithms and predictive models
• Develop custom data models and algorithms to apply to data sets
• Assess the effectiveness and accuracy of new data sources and data gathering techniques
• Develop processes and tools to monitor and analyze model performance and data accuracy
• Interpret and communicate results to non-technical customers

What You Must Have:
• Bachelor's degree with 12+ or Master's degree with 10+ years of experience in Computer Science, Statistics, Applied Mathematics, Computational Linguistics, Artificial Intelligence or related field
• 10 or more years of practical working experience in one or more of the following areas: Natural Language Processing, Machine Learning Models, Question Answering, Text Mining, Information Retrieval, Distributional Semantics, Data Science, Knowledge Engineering
• Strong experience using a variety of mathematical, statistical, data mining, and data analysis methods/tools
• Active high-level security clearance required as part of client contract requirement
• US Citizenship required as part of client contract requirements

Preferred Skills/Experience:
• Experience in Computer Science, Statistics, Applied Mathematics, Computational Linguistics, Artificial Intelligence or related field
• Interpersonal skills and the ability to communicate effectively with various clients in order to explain and elaborate on technical details
• Experience in productization of machine learning algorithms and the ability to deliver data science components that are part of successful deliverables
• Working knowledge of general machine learning algorithms and NLP, Graph Theory, and Network Analysis
• Fluency in one or more programming languages (e.g., Python, JavaScript, R, etc.)
• Experience with statistical data analysis, experimental design, and hypotheses validation
• Experience with database querying like SQL
• Readiness to collaborate with engineering teams, product teams, and customers to develop prototypes and software products
• Scaled Agile Framework (SAFe) experience
• CompTIA Security+ or higher certification level preferred

Working at ICF
ICF is a global advisory and technology services provider, but we're not your typical consultants. We combine unmatched expertise with cutting-edge technology to help clients solve their most complex challenges, navigate change, and shape the future.

We can only solve the world's toughest challenges by building a workplace that allows everyone to thrive. We are an equal opportunity employer. Together, our employees are empowered to share their expertise and collaborate with others to achieve personal and professional goals. For more information, please read our EEO policy.

Reasonable Accommodations are available, including, but not limited to, for disabled veterans, individuals with disabilities, and individuals with sincerely held religious beliefs, in all phases of the application and employment process. To request an accommodation, please email Candidateaccommodation@icf.com and we will be happy to assist. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

Read more about workplace discrimination rights or our benefit offerings which are included in the Transparency in (Benefits) Coverage Act.

Candidate AI Usage Policy

At ICF, we are committed to ensuring a fair interview process for all candidates based on their own skills and knowledge. As part of this commitment, the use of artificial intelligence (AI) tools to generate or assist with responses during interviews (whether in-person or virtual) is not permitted. This policy is in place to maintain the integrity and authenticity of the interview process.

However, we understand that some candidates may require accommodation that involves the use of AI. If such an accommodation is needed, candidates are instructed to contact us in advance at candidateaccommodation@icf.com. We are dedicated to providing the necessary support to ensure that all candidates have an equal opportunity to succeed.

Pay Range - There are multiple factors that are considered in determining final pay for a position, including, but not limited to, relevant work experience, skills, certifications and competencies that align to the specified role, geographic location, education and certifications as well as contract provisions regarding labor categories that are specific to the position.

The pay range for this position based on full-time employment is:
$118,730.00 - $201,840.00

Virginia Remote Office (VA99)",,2025-07-25,"[""Bachelor's degree with 12+ or Master's degree with 10+ years of experience in Computer Science, Statistics, Applied Mathematics, Computational Linguistics, Artificial Intelligence or related field"", '10 or more years of practical working experience in one or more of the following areas: Natural Language Processing, Machine Learning Models, Question Answering, Text Mining, Information Retrieval, Distributional Semantics, Data Science, Knowledge Engineering', 'Strong experience using a variety of mathematical, statistical, data mining, and data analysis methods/tools', 'Active high-level security clearance required as part of client contract requirement', 'US Citizenship required as part of client contract requirements']","['The successful cleared candidate will act as a Senior Data Scientist to support a large federal cyber security analytic program', 'Your work will contribute to the knowledge of how cyber-attacks work, how vulnerabilities are exploited, and the way hostile cyber actors operate', 'Utilize your skills to help experiment and prototype future cyber capabilities for implementation at large scale', 'As the Senior Data Scientist, your exceptional skillset will create useful and actionable insight for the customer through the development of machine learning, deep learning models, and related algorithms', 'The ideal candidate is strong mathematically; can automate scoring using machine learning techniques, build recommendation systems, and select the correct data points for analysis from large data sets', 'You are focused on results, a self-starter, and have demonstrated success for using analytics to drive the understanding, growth, and success of the analysis', 'This role is primarily telework-based with occasional meetings at client locations (Arlington, VA or Pensacola, FL) or ICF facilities within the National Capital Region (Washington, DC Metro Area)', 'Perform knowledge elicitation from customer subject matter experts and convert that to derived algorithms', 'Analyze large data sets to identify actionable insights with mathematical statistical rigor', 'Rigorously critique and correct intermediate results to improve the algorithmic outcomes', 'Design and deploy deep learning algorithms and predictive models', 'Develop custom data models and algorithms to apply to data sets', 'Assess the effectiveness and accuracy of new data sources and data gathering techniques', 'Develop processes and tools to monitor and analyze model performance and data accuracy', 'Interpret and communicate results to non-technical customers']",True,['Deep Learning'],Deep Learning: Design and deploy deep learning algorithms specifically to enhance cyber analytic capabilities and predictive modeling.,"['Machine Learning', 'Deep Learning', 'Natural Language Processing', 'Statistical Data Analysis', 'Data Mining', 'Predictive Modeling', 'Feature Engineering', 'Recommendation Systems', 'Knowledge Engineering', 'Experimental Design', 'SQL', 'Graph Theory and Network Analysis']","Machine Learning: Develop machine learning models to create actionable insights and automate scoring in cyber security analytics.; Deep Learning: Design and deploy deep learning algorithms and predictive models to support cyber analytic capabilities.; Natural Language Processing: Apply NLP techniques such as question answering, text mining, and information retrieval to analyze cyber security data.; Statistical Data Analysis: Use mathematical and statistical rigor to analyze large data sets and validate hypotheses.; Data Mining: Employ data mining methods to extract useful information from large and complex data sets.; Predictive Modeling: Develop predictive models to anticipate cyber threats and vulnerabilities.; Feature Engineering: Select and engineer relevant data points from large data sets for analysis and model development.; Recommendation Systems: Build recommendation systems as part of machine learning applications in cyber security.; Knowledge Engineering: Convert knowledge elicited from subject matter experts into derived algorithms for cyber analytic purposes.; Experimental Design: Apply experimental design principles to validate hypotheses and improve algorithmic outcomes.; SQL: Use database querying skills to access and manipulate data for analysis.; Graph Theory and Network Analysis: Utilize graph theory and network analysis techniques to understand relationships and structures in cyber data."
-NpPrxS4_eufwQxnAAAAAA==,"Data Scientist, Senior","Job Number: R0221171

Data Scientist, Senior

The Opportunity:

As a data scientist, you’re excited at the prospect of unlocking the secrets held by a data set, and you’re fascinated by the possibilities presented by IoT, machine learning, and artificial intelligence. In an increasingly connected world, massive amounts of structured and unstructured data open new opportunities. As a data scientist at Booz Allen, you can help turn these complex data sets into useful information to solve global challenges. Across private and public sectors—from fraud detection to cancer research to national intelligence—we need you to help find the answers in the data.

On our team, you’ll use your leadership skills and data science expertise to create real-world impact. You’ll work closely with clients to understand their questions and needs, and then dig into their data-rich environments to find the pieces of their information puzzle. You’ll guide teammates and lead the development of algorithms and systems. You’ll use the right combination of tools and frameworks to turn sets of disparate data points into objective answers to advise your clients as they make informed decisions. Ultimately, you’ll provide a deep understanding of the data, what it all means, and how it can be used.

Work with us as we use data science for good.

Join us. The world can’t wait.

You Have:  
• 5+ years of experience in applied data science or ML roles, including using Python and NLP and LLM implementation
• 5+ years of experience with data exploration, data cleaning, data analysis, data visualization, or data mining
• Experience with production-level systems, data lake environments, and streaming data, including Kafka
• Experience implementing end-to-end ML workflows from data prep to deployment and evaluation
• Ability to quickly learn infrastructure or systems concepts, including how pipelines interface with data lakes
• Ability to design, implement, and iterate on ML models for document classification, extraction, summarization, and search
• Ability to take ownership of data science workflows that interact with a production system streaming millions of documents per week
• TS/SCI clearance
• Bachelor's degree

Nice If You Have:  
• Experience in collaborating with MLOps and infrastructure engineers to ensure robust model deployment, monitoring, and retraining pipelines
• Experience supporting platform components such as documents indexing or search, GPU workloads, and distributed storage, including Cloudera
• Experience in the development of algorithms leveraging R, Python, SQL, or NoSQL
• Experience with Distributed data or computing tools, including MapReduce, Hadoop, Hive, EMR, Spark, Gurobi, or MySQL 
• Experience with visualization packages, including Plotly, Seaborn, or ggplot2

Clearance: 

Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance is required. 

Compensation

At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.

Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $99,000.00 to $225,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees. This posting will close within 90 days from the Posting Date.

Identity Statement

As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud.

Work Model

Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.
• If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility.
• If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role.

Commitment to Non-Discrimination

All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law.",2025-07-08T00:00:00.000Z,2025-07-25,"['5+ years of experience in applied data science or ML roles, including using Python and NLP and LLM implementation', '5+ years of experience with data exploration, data cleaning, data analysis, data visualization, or data mining', 'Experience with production-level systems, data lake environments, and streaming data, including Kafka', 'Experience implementing end-to-end ML workflows from data prep to deployment and evaluation', 'Ability to quickly learn infrastructure or systems concepts, including how pipelines interface with data lakes', 'Ability to design, implement, and iterate on ML models for document classification, extraction, summarization, and search', 'Ability to take ownership of data science workflows that interact with a production system streaming millions of documents per week', 'TS/SCI clearance', ""Bachelor's degree"", 'Experience in collaborating with MLOps and infrastructure engineers to ensure robust model deployment, monitoring, and retraining pipelines', 'Experience supporting platform components such as documents indexing or search, GPU workloads, and distributed storage, including Cloudera', 'Experience in the development of algorithms leveraging R, Python, SQL, or NoSQL', 'Experience with Distributed data or computing tools, including MapReduce, Hadoop, Hive, EMR, Spark, Gurobi, or MySQL\u202f', 'Experience with visualization packages, including Plotly, Seaborn, or ggplot2']","['On our team, you’ll use your leadership skills and data science expertise to create real-world impact', 'You’ll work closely with clients to understand their questions and needs, and then dig into their data-rich environments to find the pieces of their information puzzle', 'You’ll guide teammates and lead the development of algorithms and systems', 'You’ll use the right combination of tools and frameworks to turn sets of disparate data points into objective answers to advise your clients as they make informed decisions', 'Ultimately, you’ll provide a deep understanding of the data, what it all means, and how it can be used', 'If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility', 'If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role']",True,['Large Language Models'],"Large Language Models: Implemented and applied in NLP tasks such as document classification, extraction, summarization, and search, indicating use of modern AI techniques involving LLMs.","['Python', 'Natural Language Processing', 'Large Language Models', 'Data Exploration', 'Data Cleaning', 'Data Analysis', 'Data Visualization', 'Data Mining', 'Production-Level Systems', 'Data Lakes', 'Streaming Data', 'Kafka', 'Machine Learning Workflows', 'ML Models for Document Tasks', 'MLOps', 'R', 'SQL and NoSQL', 'Distributed Computing Tools', 'Visualization Packages']","Python: Used for applied data science and machine learning roles, including algorithm development and data analysis.; Natural Language Processing: Applied for document classification, extraction, summarization, and search tasks within machine learning workflows.; Large Language Models: Implemented as part of NLP and machine learning solutions to handle document-related tasks.; Data Exploration: Involves examining and understanding data sets as part of data cleaning, analysis, and mining processes.; Data Cleaning: Performed to prepare data for analysis and machine learning model development.; Data Analysis: Used to extract insights and inform decision-making from complex data sets.; Data Visualization: Utilized to communicate data insights effectively, employing tools such as Plotly, Seaborn, and ggplot2.; Data Mining: Applied to discover patterns and relationships within large data sets.; Production-Level Systems: Experience working with systems that handle real-time or large-scale data processing, including streaming data environments.; Data Lakes: Used as storage environments for large volumes of structured and unstructured data, interfacing with data pipelines.; Streaming Data: Handled data streams, including millions of documents per week, often using Kafka for ingestion and processing.; Kafka: Employed as a streaming platform to manage real-time data flows within production systems.; Machine Learning Workflows: Implemented end-to-end processes from data preparation to model deployment and evaluation.; ML Models for Document Tasks: Designed and iterated on models specifically for document classification, extraction, summarization, and search.; MLOps: Collaborated with engineers to ensure robust deployment, monitoring, and retraining of machine learning models.; R: Used for algorithm development alongside Python and SQL/NoSQL databases.; SQL and NoSQL: Applied for data querying and management in algorithm development and data processing.; Distributed Computing Tools: Experience with MapReduce, Hadoop, Hive, EMR, Spark, and Gurobi to handle large-scale data processing and optimization tasks.; Visualization Packages: Utilized Plotly, Seaborn, and ggplot2 to create visual representations of data insights."
GZLlvlCrp8E8rvQKAAAAAA==,Senior Data Scientist,"Position Summary:

As a Senior Data Scientist, you will drive the development and implementation of Machine Learning and Artificial intelligent techniques for Penske next-generation Supply Chain & Logistics products. With a robust background in data science and industry experience with machine learning, coding, and distributed computing systems such as PySpark, your role will be instrumental in establishing and advancing Penske's predictive analytics capabilities, particularly at the enterprise level.

In addition to your hands-on contributions, you will serve as a mentor to less experienced data scientists, guiding them towards professional growth and instilling a culture of best practices within the team. As a Senior Data Scientist, you will simultaneously navigate multiple projects, each of significant scale and complexity, with potential organization-wide impact. You will be expected to provide detailed analysis, formulate project approaches, and define their scope. Success in this role involves extensive cross-functional collaboration with customers, vendors, and suppliers.

Major Responsibilities:

Strategic Opportunities and Process Improvement:

• Collaborate closely with diverse stakeholders to identify and define complex business problems

• Conduct comprehensive ROI analysis to establish the feasibility of potential projects

• Contribute to building business cases for significant, enterprise-wide analytics initiatives

Data Evaluation and Analysis:

• Identify appropriate data sources to answer intricate business questions

• Extract, blend, cleanse, and organize data, leveraging automated ETL processes

• Visualize data to facilitate understanding and decision-making

• Identify and address outliers, missing or incomplete records in the data

Model Building and Implementation:

• Identify appropriate techniques and algorithms for model construction

• Develop, test, and fine-tune machine learning models

• Construct applications and embed models for enterprise-level use

Communication and Leadership:

• Actively engage in best practices discussions with team members regarding modeling activities

• Provide regular updates on project activities and results with the team

• Participate in and lead discussions about Penske's data-driven vision and strategy

• Act as a mentor for junior data scientists, fostering their growth and development

Exploring New Technologies and Industry Trends:

• Stay abreast of business trends in the logistics industry

• Evaluate new technologies and assess their potential application to our business

Qualifications for External Candidates

Qualifications:

• 6+ years of experience along with a master’s degree in Engineering, Operations Research, Statistics, Applied Math, Computer Science, or related quantitative field required

• 4+ years of experience along with a PhD in Engineering, Operations Research, Statistics, Applied Math, Computer Science, or related quantitative field preferred.

• Minimum of 4 years of experience designing and building machine learning applications using both structured and unstructured datasets.

• Demonstrated proficiency in Python, or other high-level scripting languages, with practical experience in programming.

• Extensive experience in distributed computing frameworks, such as PySpark, is required

• Proven expertise in the application of advanced Machine Learning and Deep Learning techniques in a business environment is a must.

• Solid experience with SQL.

• Ability to manage multiple complex projects simultaneously

• Experience translating complex data insights into strategic recommendations for non-technical stakeholders.

• Strong oral and written communication skills

• Strong ability to collaborate with different functional teams and stakeholders with both tech and non-tech backgrounds.

• Demonstrated ability to mentor and guide junior team members.

• Familiarity with model deployment, MLOps practices as well as exposure to containerization technologies (like Docker) and orchestration systems (like Kubernetes), will be considered a significant asset, although not strictly required.

Physical Requirements: • The physical and mental demands described here are representative of those that must be met by an associate to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. • The associate will be required to: read; communicate verbally and/or in written form; remember and analyze certain information; and remember and understand certain instructions or guidelines. • While performing the duties of this job, the associate may be required to stand, walk, and sit. The associate is frequently required to use hands to touch, handle, and feel, and to reach with hands and arms. The associate must be able to occasionally lift and/or move up to 25lbs/12kg. • Specific vision abilities required by this job include close vision, distance vision, peripheral vision, depth perception and the ability to adjust focus.

Penske is an Equal Opportunity Employer.

About Penske Logistics Penske Logistics is a wholly owned subsidiary of Penske Truck Leasing. With operations in North America, South America, Europe and Asia, Penske Logistics provides supply chain management and logistics services to leading companies around the world. Penske Logistics delivers value through its design, planning and execution in transportation, warehousing and freight management. Visit www.PenskeLogistics.com to learn more.

About Penske Truck Leasing/Transportation Solutions

Penske Truck Leasing/Transportation Solutions is a premier global transportation provider that delivers essential and innovative transportation, logistics and technology services to help companies and people move forward. With headquarters in Reading, PA, Penske and its associates are driven by a dedication to excellence and a commitment to customer success. Visit Go Penske to learn more.

Job Category: Information Technology

Job Family: Common

Address: 100 Gundy Drive

Primary Location: US-PA-Reading

Employer: Penske Truck Leasing Co., L.P.

Req ID: 2406093",2025-07-23T00:00:00.000Z,2025-07-25,"['6+ years of experience along with a master’s degree in Engineering, Operations Research, Statistics, Applied Math, Computer Science, or related quantitative field required', 'Minimum of 4 years of experience designing and building machine learning applications using both structured and unstructured datasets', 'Demonstrated proficiency in Python, or other high-level scripting languages, with practical experience in programming', 'Extensive experience in distributed computing frameworks, such as PySpark, is required', 'Proven expertise in the application of advanced Machine Learning and Deep Learning techniques in a business environment is a must', 'Solid experience with SQL', 'Ability to manage multiple complex projects simultaneously', 'Experience translating complex data insights into strategic recommendations for non-technical stakeholders', 'Strong oral and written communication skills', 'Strong ability to collaborate with different functional teams and stakeholders with both tech and non-tech backgrounds', 'Demonstrated ability to mentor and guide junior team members', 'Familiarity with model deployment, MLOps practices as well as exposure to containerization technologies (like Docker) and orchestration systems (like Kubernetes), will be considered a significant asset, although not strictly required', 'The physical and mental demands described here are representative of those that must be met by an associate to successfully perform the essential functions of this job', 'The associate will be required to: read; communicate verbally and/or in written form; remember and analyze certain information; and remember and understand certain instructions or guidelines', 'While performing the duties of this job, the associate may be required to stand, walk, and sit', 'The associate is frequently required to use hands to touch, handle, and feel, and to reach with hands and arms', 'The associate must be able to occasionally lift and/or move up to 25lbs/12kg', 'Specific vision abilities required by this job include close vision, distance vision, peripheral vision, depth perception and the ability to adjust focus']","['As a Senior Data Scientist, you will drive the development and implementation of Machine Learning and Artificial intelligent techniques for Penske next-generation Supply Chain & Logistics products', ""With a robust background in data science and industry experience with machine learning, coding, and distributed computing systems such as PySpark, your role will be instrumental in establishing and advancing Penske's predictive analytics capabilities, particularly at the enterprise level"", 'In addition to your hands-on contributions, you will serve as a mentor to less experienced data scientists, guiding them towards professional growth and instilling a culture of best practices within the team', 'As a Senior Data Scientist, you will simultaneously navigate multiple projects, each of significant scale and complexity, with potential organization-wide impact', 'You will be expected to provide detailed analysis, formulate project approaches, and define their scope', 'Success in this role involves extensive cross-functional collaboration with customers, vendors, and suppliers', 'Collaborate closely with diverse stakeholders to identify and define complex business problems', 'Conduct comprehensive ROI analysis to establish the feasibility of potential projects', 'Contribute to building business cases for significant, enterprise-wide analytics initiatives', 'Identify appropriate data sources to answer intricate business questions', 'Extract, blend, cleanse, and organize data, leveraging automated ETL processes', 'Visualize data to facilitate understanding and decision-making', 'Identify and address outliers, missing or incomplete records in the data', 'Model Building and Implementation:', 'Identify appropriate techniques and algorithms for model construction', 'Develop, test, and fine-tune machine learning models', 'Construct applications and embed models for enterprise-level use', 'Actively engage in best practices discussions with team members regarding modeling activities', 'Provide regular updates on project activities and results with the team', ""Participate in and lead discussions about Penske's data-driven vision and strategy"", 'Act as a mentor for junior data scientists, fostering their growth and development', 'Stay abreast of business trends in the logistics industry', 'Evaluate new technologies and assess their potential application to our business', 'Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions']",True,[],,"['Machine Learning', 'Deep Learning', 'Python', 'Distributed Computing with PySpark', 'SQL', 'Data Extraction, Transformation, and Loading (ETL)', 'Data Visualization', 'Data Cleaning and Preprocessing', 'Model Deployment and MLOps', 'Predictive Analytics', 'ROI Analysis', 'Mentorship and Leadership in Data Science']","Machine Learning: Develop, test, and fine-tune machine learning models for enterprise-level supply chain and logistics products; apply advanced machine learning techniques in a business environment.; Deep Learning: Apply advanced deep learning techniques as part of machine learning applications in a business context.; Python: Use Python or other high-level scripting languages for programming and model development.; Distributed Computing with PySpark: Leverage distributed computing frameworks such as PySpark to handle large-scale data processing and analytics.; SQL: Utilize SQL for data querying and management of structured data.; Data Extraction, Transformation, and Loading (ETL): Extract, blend, cleanse, and organize data using automated ETL processes to prepare data for analysis and modeling.; Data Visualization: Visualize data to facilitate understanding and support decision-making processes.; Data Cleaning and Preprocessing: Identify and address outliers, missing, or incomplete records in datasets to ensure data quality for analysis and modeling.; Model Deployment and MLOps: Familiarity with model deployment and MLOps practices, including exposure to containerization technologies like Docker and orchestration systems like Kubernetes, to support production-level model management.; Predictive Analytics: Establish and advance predictive analytics capabilities at the enterprise level to support supply chain and logistics business decisions.; ROI Analysis: Conduct comprehensive return on investment analysis to evaluate the feasibility of potential projects.; Mentorship and Leadership in Data Science: Mentor junior data scientists, guide best practices in modeling activities, and foster professional growth within the team."
mJTOv-IE2zQAxuBZAAAAAA==,Senior Data Scientist,"About the Team
Fanatics is one of the world’s most transformative companies, which over the past decade has implemented a revolutionary vertical commerce model, cutting-edge tech platform and agile supply chain to morph from a North American e-commerce vendor into a new breed of mobile-first consumer brand: part tech company, part on-demand manufacturer and part logistics expert. Fanatics’ commerce division is the world’s largest manufacturer and provider of licensed sports merchandise, and the same innovation and differentiation the company applied to the antiquated licensed apparel industry is now being optimized across the entire sports ecosystem, including physical and digital trading cards and collectibles and online sports betting and iGaming. With more choices at the fingertips of consumers than ever before, Fanatics is building the leading global digital sports platform to create interactive, lasting fan experiences which also helps partners establish better direct-to-consumer relationships in today’s highly competitive world.

Fanatics Collectibles has the combined vision and distinct strengths of both Fanatics and Topps that will improve the collector experience while maintaining vital parts of the hobby. Fanatics’ data-driven, direct-to-consumer expertise, which includes a database of more than 80 million sports fans globally, will enhance and expand Topps’ existing digital capabilities and grow the market opportunity for all participants. In addition, Topps’ world-class quality, product development, and manufacturing capabilities, along with their commitment to collectors and hobby shops, will ensure products are more readily accessible, positively impacting current and future collectors and partners.

The Role
We are looking for senior-level Data Scientists to join our Data Engineering, Science, and Analytics team. Do you thrive at applying data science to solve business problems? As a data scientist, you will have ample opportunities to apply your data science skillset to unlock vast business opportunities by extracting key insights using a wide range of data sources, advanced statistical models, and machine learning algorithms and translating results into meaningful, goal-oriented business actions. Each day, you will be presented with a variety of new challenges and interesting projects that tap your interests and strengths.

Responsibilities:

Collaborate with cross-functional partners in operations, finance, marketing, and engineering to understand business need and scope data science projects.
Wrangle, process, cleanse, verify, and enrich data from different sources used for analysis.
Help build data-informed business strategy and roadmaps.
Translate business needs into data product requirements, evaluate technologies, and identify opportunities to innovate and improve our data science capabilities.
Use creative problem-solving skills to analyze data and build statistical / machine learning models to help solve business problems from different perspectives.
Work closely with data engineers to create services that can ingest and supply data to and from both internal and external sources and ensure data quality and timeliness.
Lead the development of data visualization and dashboards to help the organization monitor performance, generate insights, and continuously improve user experience.
Establish playbooks to drive process and consistent outcomes.
Participating in the full life cycle of model development, which spans from business problem discovery, data discovery to model deployment and monitoring.

Qualifications:

Master’s or Doctoral degree in Computer Science (with a focus on Data Mining, Machine Learning), Statistics, Econometrics, Physics, or other rigorous quantitative disciplines that require processing and modeling data at a complex and large scale.
4+ years of professional experience as a data scientist.
Proficient in Python, SQL, Spark, the associated Python and Spark packages commonly used by data scientists, and Deep Learning libraries, such as PyTorch.
Proficient in wrangle and analyze data with complex relationships and time scale.
Strong understanding of and practical experience in a wide range of machine learning algorithms and statistical modeling.
Experience in using data visualization and dashboard tools.
Experience and knowledge with computer vision domain, library such as OpenCV, PIL, and modern CV architectures (CNNs, Vision Transformers, Image Gen AI etc.)
Experience in software development, system design and deployment is preferred.
Working experience in cloud-native technology.
Experience working with large structured and unstructured datasets stored in relational and NOSQL databases.
Out-of-the-box thinker and problem solver who can turn ambiguous business problems into clear data-driven solutions that deliver meaningful business impacts.
Excellent organizational skills, verbal and written communication skills, and presentation skills.

Some things you may want to know about us:

We’re a small team (growing fast!) and everyone wears lots of hats.
We’re have offices in Los Angeles and New York, and many of us are remote.
We work hard, but not all the time. We have families that we like to spend time with.

The salary range for this position is $200,000- $240,000 which represents base pay only and does not include short-term or long-term incentive compensation. When determining base pay, as part of a final compensation package, we consider several factors such as location, experience, qualifications, and training.

Ensure your Fanatics job offer is legitimate and don’t fall victim to fraud. Fanatics never seeks payment from job applicants. Feel free to ask your recruiter for a phone call or other type of communication for interview, and ensure your communication is coming from a Fanatics email address (including @collectfanatics.com). For added security, where possible, apply through our company website at www.fanaticsinc.com/careers

Fanatics is building a leading global digital sports platform. We ignite the passions of global sports fans and maximize the presence and reach for our hundreds of sports partners globally by offering products and services across Fanatics Commerce, Fanatics Collectibles, and Fanatics Betting & Gaming, allowing sports fans to Buy, Collect, and Bet. Through the Fanatics platform, sports fans can buy licensed fan gear, jerseys, lifestyle and streetwear products, headwear, and hardgoods; collect physical and digital trading cards, sports memorabilia, and other digital assets; and bet as the company builds its Sportsbook and iGaming platform. Fanatics has an established database of over 100 million global sports fans; a global partner network with approximately 900 sports properties, including major national and international professional sports leagues, players associations, teams, colleges, college conferences and retail partners, 2,500 athletes and celebrities, and 200 exclusive athletes; and over 2,000 retail locations, including its Lids retail stores. Our more than 22,000 employees are committed to relentlessly enhancing the fan experience and delighting sports fans globally.",2025-07-18T00:00:00.000Z,2025-07-25,"['Do you thrive at applying data science to solve business problems?', 'As a data scientist, you will have ample opportunities to apply your data science skillset to unlock vast business opportunities by extracting key insights using a wide range of data sources, advanced statistical models, and machine learning algorithms and translating results into meaningful, goal-oriented business actions', 'Master’s or Doctoral degree in Computer Science (with a focus on Data Mining, Machine Learning), Statistics, Econometrics, Physics, or other rigorous quantitative disciplines that require processing and modeling data at a complex and large scale', '4+ years of professional experience as a data scientist', 'Proficient in Python, SQL, Spark, the associated Python and Spark packages commonly used by data scientists, and Deep Learning libraries, such as PyTorch', 'Proficient in wrangle and analyze data with complex relationships and time scale', 'Strong understanding of and practical experience in a wide range of machine learning algorithms and statistical modeling', 'Experience in using data visualization and dashboard tools', 'Experience and knowledge with computer vision domain, library such as OpenCV, PIL, and modern CV architectures (CNNs, Vision Transformers, Image Gen AI etc.)', 'Working experience in cloud-native technology', 'Experience working with large structured and unstructured datasets stored in relational and NOSQL databases', 'Out-of-the-box thinker and problem solver who can turn ambiguous business problems into clear data-driven solutions that deliver meaningful business impacts', 'Excellent organizational skills, verbal and written communication skills, and presentation skills']","['Collaborate with cross-functional partners in operations, finance, marketing, and engineering to understand business need and scope data science projects', 'Wrangle, process, cleanse, verify, and enrich data from different sources used for analysis', 'Help build data-informed business strategy and roadmaps', 'Translate business needs into data product requirements, evaluate technologies, and identify opportunities to innovate and improve our data science capabilities', 'Use creative problem-solving skills to analyze data and build statistical / machine learning models to help solve business problems from different perspectives', 'Work closely with data engineers to create services that can ingest and supply data to and from both internal and external sources and ensure data quality and timeliness', 'Lead the development of data visualization and dashboards to help the organization monitor performance, generate insights, and continuously improve user experience', 'Establish playbooks to drive process and consistent outcomes', 'Participating in the full life cycle of model development, which spans from business problem discovery, data discovery to model deployment and monitoring']",True,"['Vision Transformers', 'Generative AI', 'PyTorch']",Vision Transformers: Utilizing Vision Transformer architectures as part of modern computer vision solutions within the data science projects.; Generative AI: Applying generative AI techniques related to image generation as part of computer vision tasks.; PyTorch: Employing PyTorch deep learning library specifically for neural network and AI model development.,"['Data Wrangling and Processing', 'Statistical Modeling', 'Machine Learning Algorithms', 'Python', 'SQL', 'Spark', 'Data Visualization and Dashboards', 'Model Development Lifecycle', 'Computer Vision', 'Deep Learning Libraries', 'Cloud-Native Technology', 'Large Structured and Unstructured Data']","Data Wrangling and Processing: Ingesting, cleansing, verifying, enriching, and processing data from multiple sources to prepare it for analysis and modeling.; Statistical Modeling: Applying advanced statistical models to extract insights and solve business problems.; Machine Learning Algorithms: Using a wide range of machine learning techniques to build predictive models that address various business challenges.; Python: Utilizing Python programming language and its associated packages commonly used by data scientists for data analysis and model development.; SQL: Querying and managing structured data stored in relational databases.; Spark: Employing Apache Spark and its Python packages for large-scale data processing and analytics.; Data Visualization and Dashboards: Developing visualizations and dashboards to monitor organizational performance, generate insights, and improve user experience.; Model Development Lifecycle: Participating in the end-to-end process of model development including business problem discovery, data exploration, model building, deployment, and monitoring.; Computer Vision: Applying computer vision techniques and libraries such as OpenCV and PIL, including modern architectures like CNNs and Vision Transformers, to analyze image data.; Deep Learning Libraries: Using deep learning frameworks such as PyTorch for building and training neural network models.; Cloud-Native Technology: Working with cloud-native platforms and technologies to support scalable data science and engineering workflows.; Large Structured and Unstructured Data: Handling and analyzing large datasets stored in both relational and NoSQL databases with complex relationships and time scales."
AN7jrONXj9RSGt1JAAAAAA==,"(USA) Senior, Data Scientist","Position Summary...

Join Walmart|VIZIO and take your career to the next level!

We are looking for a highly talented and motivated Data Scientist to help deliver strategic initiatives across the organization. We look for people who can effectively partner with Product Management, Engineering, and business leaders to deliver easy, effective, and insightful analytics. We are a growing team, focusing on challenging problems that make a difference to our business. We concentrate on high-impact, high-value development, and analysis. We are looking for someone who is versatile, methodical, excited by modern technology and enjoys focusing on tackling software challenges.

What you'll do...

About the Data Science Team:

Our Data Science team operates at the heart of VIZIO/Walmart's mission to deliver the best shopping experience to our customers. We leverage advanced analytics, machine learning, and big data to drive business insights and strategic decisions. As a Senior Data Scientist, you will play a crucial role in enhancing our data capabilities and contributing to VIZIO/Walmart’s growth and innovation.

What You’ll Do:
• Solve novel and complex business problems with high-quality, maintainable code.
• Collaborate cross-functionally with Product Managers and Engineering teams to gather requirements and develop solutions.
• Analyze high volumes of data to understand business problems and propose technical solutions.
• Develop and iterate on machine learning models, from quick prototypes to production deployment.
• Evaluate the efficacy and value of product features using data-driven insights.
• Organize and document complex technical projects.

What You’ll Bring:
• Expertise in big data analytics and automation techniques.
• Strong understanding of business contexts and the ability to translate business problems into data solutions.
• Proficiency with database technologies and distributed datastores (e.g., SQL, NoSQL).
• Experience in developing and deploying machine learning models.
• Experience writing production code in Python, fluent in PySpark
• Expertise with at least one ML framework (pytorch, tensorflow, jax)
• Experience with CI/CD frameworks

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.
‎

‎

‎
You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.
‎

For information about PTO, see https://one.walmart.com/notices.

‎

‎
Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.
‎
Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.
‎

For information about benefits and eligibility, see One.Walmart.

‎
New York, New York US-11582:The annual salary range for this position is $108,000.00-$216,000.00
‎
San Francisco, California US-11574:The annual salary range for this position is $117,000.00-$234,000.00
‎

‎

‎

‎

‎

‎

‎

‎

‎

‎
Additional compensation includes annual or quarterly performance bonuses.
‎
Additional compensation for certain positions may also include:
‎

‎
- Stock
‎

‎

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1- Bachelor’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years' experience in an analytics related field. Option 2- Master’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years' experience in an analytics related field. Option 3 - 5 years' experience in an analytics or related field.

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data science, machine learning, optimization models, Master’s degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.

Primary Location...

350 5Th Ave, New York, NY 10118-4801, United States of America",,2025-07-25,"['We look for people who can effectively partner with Product Management, Engineering, and business leaders to deliver easy, effective, and insightful analytics', 'We are looking for someone who is versatile, methodical, excited by modern technology and enjoys focusing on tackling software challenges', 'Expertise in big data analytics and automation techniques', 'Strong understanding of business contexts and the ability to translate business problems into data solutions', 'Proficiency with database technologies and distributed datastores (e.g., SQL, NoSQL)', 'Experience in developing and deploying machine learning models', 'Experience writing production code in Python, fluent in PySpark', 'Expertise with at least one ML framework (pytorch, tensorflow, jax)', 'Experience with CI/CD frameworks', ""Option 1- Bachelor’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years' experience in an analytics related field"", ""Option 2- Master’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years' experience in an analytics related field"", ""Option 3 - 5 years' experience in an analytics or related field"", 'Data science, machine learning, optimization models, Master’s degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly', 'The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture']","['Solve novel and complex business problems with high-quality, maintainable code', 'Collaborate cross-functionally with Product Managers and Engineering teams to gather requirements and develop solutions', 'Analyze high volumes of data to understand business problems and propose technical solutions', 'Develop and iterate on machine learning models, from quick prototypes to production deployment', 'Evaluate the efficacy and value of product features using data-driven insights', 'Organize and document complex technical projects']",True,"['Deep Learning Frameworks (PyTorch, TensorFlow)']","Deep Learning Frameworks (PyTorch, TensorFlow): Applied specifically for neural network-based machine learning model development and deployment within the data science team.","['Big Data Analytics', 'Machine Learning Models', 'SQL and NoSQL Databases', 'Python and PySpark', 'ML Frameworks (PyTorch, TensorFlow, JAX)', 'CI/CD Frameworks', 'Optimization Models', 'Open Source Frameworks (scikit-learn, TensorFlow, Torch)']","Big Data Analytics: Used to analyze high volumes of data to understand business problems and propose technical solutions, supporting strategic initiatives and business insights.; Machine Learning Models: Developed and iterated from prototypes to production deployment to solve complex business problems and evaluate product features.; SQL and NoSQL Databases: Proficiency required for working with database technologies and distributed datastores to support data solutions.; Python and PySpark: Used for writing production code and handling big data processing within the data science workflows.; ML Frameworks (PyTorch, TensorFlow, JAX): Expertise required in at least one machine learning framework to develop and deploy machine learning models.; CI/CD Frameworks: Experience with continuous integration and continuous deployment frameworks to support production-level code and model deployment.; Optimization Models: Applied to solve business problems and improve decision-making processes as part of data science responsibilities.; Open Source Frameworks (scikit-learn, TensorFlow, Torch): Used for building machine learning models and analytics solutions leveraging popular open source tools."
iDjdplG40ufZFVE9AAAAAA==,Senior Data Scientist,"Senior Data Scientist

Virta Health is pioneering a new standard of care for people to reclaim their lives. We are in the midst of a public health crisis: obesity rates are at an all-time high and over half of US adults have type 2 diabetes or prediabetes, and despite billions spent on new treatments, outcomes are largely worse. Virta reverses these diseases and delivers life-changing results by pairing individualized nutrition with ongoing care from a clinical support team. We have raised over $350 million from top-tier investors, and partner with the largest health plans, employers, and government organizations to help their employees and members restore their health and take back their lives.

Role Overview

The Advanced Analytics & AI (AAA) team is accountable for both pioneering new classes of data that power our business, and ensuring that data is powerful, clear, correct and easy to use throughout the company. The team collaborates closely with the engineering, product development, commercial, and clinical teams to transform data into actionable insights that propel Virta's mission forward.

As a Senior Data Scientist on the AAA team, you will play a crucial role in shaping our data-driven decision making processes and in driving impactful insights that advance our mission. This role offers a unique blend of hands-on coding and strategic leadership, working closely in partnership with the Product Development group that supports adoption of our member-facing products. You will get a chance to work closely with stakeholders to create impactful data-driven reports and analyses that strengthen Virta’s value proposition.

Responsibilities
• Serve as data lead for the Adoption Squad:
• Understand the product – strategy, goals, roadmap, users – deeply enough to identify high-impact, strategic opportunities and risks.
• Use data to steer conversations: bring data-driven hypotheses, challenge assumptions, frame trade-offs, prioritize strategically.
• Translate vague product hunches into sharp analytical questions, and design the right approach to answer them.
• Be the source of truth for KPIs and product metrics: help define and monitor them, and identify trends and drivers.
• Drive decision making with data: Prioritize analyses that meaningfully inform product decisions and change outcomes, reframe analysis requests that won’t do that into ones that will, and design and deliver the resulting analyses properly and rapidly.
• Lead experimentation thoughtfully: guide the team on when and when not to experiment, help enable self-serve experimentation, and focus on frequent, small experiments to speed learning.
• Identify where product strategy and ideas could be better, more easily, or more quickly implemented with the help of AI (ML or GenAI), and help enable this integration.
• Show up as a collaborative leader, not simply a service provider, and help focus work on what matters most.
• Work end-to-end to translate clinical, member, and claims data from our data warehouse into actionable recommendations: work with stakeholders to design reports and dashboards that answer real business questions, design the data flows to support these, and build the required data transformation pipelines.

Must-Haves
• Experience working at a digital health or similar startup, preferably during the growth phase, in order to function effectively in a fast-paced, rapidly changing environment.
• 7+ years of experience in a Healthcare Analytics or Data Science role, working with large datasets and conducting statistical and quantitative modeling, melding analytics with strong programming, data mining, clustering and segmentation.
• 5+ years of work experience working data science and visualization tools (SQL, R, and/or Python)
• Advanced understanding of data storage, ETL frameworks, data transformation, and validation
• Experience in building BI dashboards using tools such as Looker or Tableau
• Ability to explain technology, techniques and approaches to others

Nice-to-Haves
• Experience leading cross-functional efforts to build scalable systems and data pipelines, working with complex data structures
• Understanding of Generative AI concepts and basic usage of GenAI tools (ChatGPT, Claude, etc.)
• Experience building pipelines using dbt
• Demonstrated project management experience

90 Day Plan

Within your first 90 days at Virta, we expect you will do the following:
• Familiarize yourself with the Advanced Analytics & AI team roles and responsibilities. Get a pulse on team structure, key stakeholders, and areas for opportunity with an eye towards scalability and standardization.
• Integrate with the Adoption Squad to understand team dynamics, analyze key product features and data pipelines, and familiarize yourself with the Squad’s product roadmap
• Analyze current member journey to understand Virta’s technology ecosystem
• Meet cross-functional stakeholders to understand how their business needs align with Squad and Team goals
• Identify at least 1 area of opportunity to leverage GenAI to increase team efficiency or improve our processes
• Teach and inspire your team members through knowledge sharing, pair programming, and giving feedback during code reviews

Values-driven culture

Virta’s company values drive our culture, so you’ll do well if:
• You put people first and take care of yourself, your peers, and our patients equally
• You have a strong sense of ownership and take initiative while empowering others to do the same
• You prioritize positive impact over busy work
• You have no ego and understand that everyone has something to bring to the table regardless of experience
• You appreciate transparency and promote trust and empowerment through open access of information
• You are evidence-based and prioritize data and science over seniority or dogma
• You take risks and rapidly iterate

Is this role not quite what you're looking for? Join our Talent Community and follow us on Linkedin to stay connected!

Virta has a location based compensation structure. Starting pay will be based on a number of factors and commensurate with qualifications & experience. For this role, the compensation range is $167,249 - $216,000. Information about Virta’s benefits is on our Careers page at: https://www.virtahealth.com/careers.

As part of your duties at Virta, you may come in contact with sensitive patient information that is governed by HIPAA. Throughout your career at Virta, you will be expected to follow Virta's security and privacy procedures to ensure our patients' information remains strictly confidential. Security and privacy training will be provided.

As a remote-first company, our team is spread across various locations with office hubs in Denver and San Francisco.
Clinical roles: We currently do not hire in the following states: AK, HI, RI
Corporate roles: We currently do not hire in the following states: AK, AR, DE, HI, ME, MS, NM, OK, SD, VT, WI.

#LI-remote",2025-07-21T00:00:00.000Z,2025-07-25,"['Experience working at a digital health or similar startup, preferably during the growth phase, in order to function effectively in a fast-paced, rapidly changing environment', '7+ years of experience in a Healthcare Analytics or Data Science role, working with large datasets and conducting statistical and quantitative modeling, melding analytics with strong programming, data mining, clustering and segmentation', '5+ years of work experience working data science and visualization tools (SQL, R, and/or Python)', 'Advanced understanding of data storage, ETL frameworks, data transformation, and validation', 'Experience in building BI dashboards using tools such as Looker or Tableau', 'Ability to explain technology, techniques and approaches to others', 'Experience leading cross-functional efforts to build scalable systems and data pipelines, working with complex data structures', 'Understanding of Generative AI concepts and basic usage of GenAI tools (ChatGPT, Claude, etc.)', 'Experience building pipelines using dbt', 'Demonstrated project management experience', 'You have a strong sense of ownership and take initiative while empowering others to do the same', 'You prioritize positive impact over busy work', 'You have no ego and understand that everyone has something to bring to the table regardless of experience', 'You appreciate transparency and promote trust and empowerment through open access of information', 'You are evidence-based and prioritize data and science over seniority or dogma', 'You take risks and rapidly iterate']","['As a Senior Data Scientist on the AAA team, you will play a crucial role in shaping our data-driven decision making processes and in driving impactful insights that advance our mission', 'You will get a chance to work closely with stakeholders to create impactful data-driven reports and analyses that strengthen Virta’s value proposition', 'Serve as data lead for the Adoption Squad:', 'Understand the product – strategy, goals, roadmap, users – deeply enough to identify high-impact, strategic opportunities and risks', 'Use data to steer conversations: bring data-driven hypotheses, challenge assumptions, frame trade-offs, prioritize strategically', 'Translate vague product hunches into sharp analytical questions, and design the right approach to answer them', 'Be the source of truth for KPIs and product metrics: help define and monitor them, and identify trends and drivers', 'Drive decision making with data: Prioritize analyses that meaningfully inform product decisions and change outcomes, reframe analysis requests that won’t do that into ones that will, and design and deliver the resulting analyses properly and rapidly', 'Lead experimentation thoughtfully: guide the team on when and when not to experiment, help enable self-serve experimentation, and focus on frequent, small experiments to speed learning', 'Identify where product strategy and ideas could be better, more easily, or more quickly implemented with the help of AI (ML or GenAI), and help enable this integration', 'Show up as a collaborative leader, not simply a service provider, and help focus work on what matters most', 'Work end-to-end to translate clinical, member, and claims data from our data warehouse into actionable recommendations: work with stakeholders to design reports and dashboards that answer real business questions, design the data flows to support these, and build the required data transformation pipelines', 'Familiarize yourself with the Advanced Analytics & AI team roles and responsibilities', 'Get a pulse on team structure, key stakeholders, and areas for opportunity with an eye towards scalability and standardization', 'Integrate with the Adoption Squad to understand team dynamics, analyze key product features and data pipelines, and familiarize yourself with the Squad’s product roadmap', 'Analyze current member journey to understand Virta’s technology ecosystem', 'Meet cross-functional stakeholders to understand how their business needs align with Squad and Team goals', 'Identify at least 1 area of opportunity to leverage GenAI to increase team efficiency or improve our processes', 'Teach and inspire your team members through knowledge sharing, pair programming, and giving feedback during code reviews']",True,['Generative AI'],Generative AI: Understanding and basic usage of generative AI tools like ChatGPT and Claude to identify opportunities for improving team efficiency and product strategy integration.,"['Statistical and Quantitative Modeling', 'Data Mining', 'Clustering and Segmentation', 'SQL', 'R', 'Python', 'Data Storage and ETL Frameworks', 'Data Transformation and Validation', 'BI Dashboards (Looker, Tableau)', 'Data Pipelines', 'Experimentation and A/B Testing', 'dbt']","Statistical and Quantitative Modeling: Used to analyze large healthcare datasets to derive insights and support data-driven decision making in a healthcare analytics context.; Data Mining: Applied to extract patterns and segment data for clustering and segmentation tasks relevant to healthcare analytics.; Clustering and Segmentation: Techniques used to group data points for better understanding of member populations and product usage patterns.; SQL: Used as a data science tool for querying and managing large datasets from the data warehouse.; R: Utilized as a programming language for data analysis and visualization in healthcare analytics.; Python: Employed for data science tasks including data transformation, analysis, and building data pipelines.; Data Storage and ETL Frameworks: Advanced understanding required to manage data storage, perform extraction, transformation, and loading of data to ensure data quality and availability.; Data Transformation and Validation: Processes to convert raw clinical, member, and claims data into clean, usable formats and to ensure data accuracy for analysis and reporting.; BI Dashboards (Looker, Tableau): Building interactive dashboards and reports to visualize KPIs and product metrics that inform business and product decisions.; Data Pipelines: Designing and building scalable data transformation pipelines to support data flows from raw data to actionable insights.; Experimentation and A/B Testing: Leading and enabling frequent, small experiments to speed learning and inform product decisions through data-driven experimentation.; dbt: Used for building data transformation pipelines to support scalable and maintainable data workflows."
KRaSg822gWoBsIzeAAAAAA==,"(USA) Senior, Data Scientist","Position Summary...

Join Walmart|VIZIO and take your career to the next level!

We are looking for a highly talented and motivated Data Scientist to help deliver strategic initiatives across the organization. We look for people who can effectively partner with Product Management, Engineering, and business leaders to deliver easy, effective, and insightful analytics. We are a growing team, focusing on challenging problems that make a difference to our business. We concentrate on high-impact, high-value development, and analysis. We are looking for someone who is versatile, methodical, excited by modern technology and enjoys focusing on tackling software challenges.

What you'll do...

About the Data Science Team:

Our Data Science team operates at the heart of VIZIO/Walmart's mission to deliver the best shopping experience to our customers. We leverage advanced analytics, machine learning, and big data to drive business insights and strategic decisions. As a Senior Data Scientist, you will play a crucial role in enhancing our data capabilities and contributing to VIZIO/Walmart’s growth and innovation.

What You’ll Do:
• Solve novel and complex business problems with high-quality, maintainable code.
• Collaborate cross-functionally with Product Managers and Engineering teams to gather requirements and develop solutions.
• Analyze high volumes of data to understand business problems and propose technical solutions.
• Develop and iterate on machine learning models, from quick prototypes to production deployment.
• Evaluate the efficacy and value of product features using data-driven insights.
• Organize and document complex technical projects.

What You’ll Bring:
• Expertise in big data analytics and automation techniques.
• Strong understanding of business contexts and the ability to translate business problems into data solutions.
• Proficiency with database technologies and distributed datastores (e.g., SQL, NoSQL).
• Experience in developing and deploying machine learning models.
• Experience writing production code in Python, fluent in PySpark
• Expertise with at least one ML framework (pytorch, tensorflow, jax)
• Experience with CI/CD frameworks

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.
‎

‎

‎
You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.
‎

For information about PTO, see https://one.walmart.com/notices.

‎

‎
Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.
‎
Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.
‎

For information about benefits and eligibility, see One.Walmart.

‎
New York, New York US-11582:The annual salary range for this position is $108,000.00-$216,000.00
‎
San Francisco, California US-11574:The annual salary range for this position is $117,000.00-$234,000.00
‎

‎

‎

‎

‎

‎

‎

‎

‎

‎
Additional compensation includes annual or quarterly performance bonuses.
‎
Additional compensation for certain positions may also include:
‎

‎
- Stock
‎

‎

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1- Bachelor’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years' experience in an analytics related field. Option 2- Master’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years' experience in an analytics related field. Option 3 - 5 years' experience in an analytics or related field.

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data science, machine learning, optimization models, Master’s degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.

Primary Location...

350 5Th Ave, New York, NY 10118-4801, United States of America",,2025-07-25,"['We look for people who can effectively partner with Product Management, Engineering, and business leaders to deliver easy, effective, and insightful analytics', 'We are looking for someone who is versatile, methodical, excited by modern technology and enjoys focusing on tackling software challenges', 'Expertise in big data analytics and automation techniques', 'Strong understanding of business contexts and the ability to translate business problems into data solutions', 'Proficiency with database technologies and distributed datastores (e.g., SQL, NoSQL)', 'Experience in developing and deploying machine learning models', 'Experience writing production code in Python, fluent in PySpark', 'Expertise with at least one ML framework (pytorch, tensorflow, jax)', 'Experience with CI/CD frameworks', ""Option 1- Bachelor’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years' experience in an analytics related field"", ""Option 2- Master’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years' experience in an analytics related field"", ""Option 3 - 5 years' experience in an analytics or related field"", 'Data science, machine learning, optimization models, Master’s degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly', 'The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture']","['Solve novel and complex business problems with high-quality, maintainable code', 'Collaborate cross-functionally with Product Managers and Engineering teams to gather requirements and develop solutions', 'Analyze high volumes of data to understand business problems and propose technical solutions', 'Develop and iterate on machine learning models, from quick prototypes to production deployment', 'Evaluate the efficacy and value of product features using data-driven insights', 'Organize and document complex technical projects']",True,"['Deep Learning Frameworks (PyTorch, TensorFlow)']","Deep Learning Frameworks (PyTorch, TensorFlow): Applied specifically for neural network-based machine learning model development and deployment within the data science team.","['Big Data Analytics', 'Machine Learning Models', 'SQL and NoSQL Databases', 'Python and PySpark', 'ML Frameworks (PyTorch, TensorFlow, JAX)', 'CI/CD Frameworks', 'Data Science and Analytics', 'Optimization Models', 'Spark and Scala', 'Scikit-learn']","Big Data Analytics: Used to analyze high volumes of data to understand business problems and drive strategic decisions within the organization.; Machine Learning Models: Developed and iterated from prototypes to production deployment to solve complex business problems and evaluate product features.; SQL and NoSQL Databases: Proficiency required for working with database technologies and distributed datastores to support data solutions.; Python and PySpark: Used for writing production code and handling big data processing tasks within machine learning and analytics workflows.; ML Frameworks (PyTorch, TensorFlow, JAX): Expertise required to develop and deploy machine learning models using popular open-source frameworks.; CI/CD Frameworks: Experience with continuous integration and continuous deployment frameworks to support production-level machine learning model deployment and automation.; Data Science and Analytics: Applied to deliver insightful analytics, translate business problems into data solutions, and support strategic initiatives.; Optimization Models: Used as part of advanced analytics and machine learning approaches to solve business problems.; Spark and Scala: Mentioned as part of assessments and skills relevant for big data processing and analytics.; Scikit-learn: Used as an open-source framework for machine learning model development."
2gTZt9EtBBLTOfd6AAAAAA==,Senior Data Scientist,"Intuit Credit Karma is a mission-driven company, focused on championing financial progress for our more than 140 million members globally. While we're best known for pioneering free credit scores, our members turn to us for everything related to their financial goals, including identity monitoring, applying for credit cards, shopping for insurance and loans (car, home and personal) and savings accounts and checking accounts* – all for free. Credit Karma has grown significantly through the years: we now have more than 1,700 employees across our offices in Oakland, Charlotte, Culver City, San Diego, London, Bangalore, and New York City.
• Banking services provided by MVB Bank, Inc., Member FDIC

Senior Data Scientist

Credit Karma is looking for a results-oriented and strategically innovative Senior Data Scientist who is passionate about applying machine learning to solve financial challenges for millions of members. In this role, you will drive data-informed decisions and deliver AI-powered recommendations that help our members achieve their financial goals. Data Science plays a ubiquitous role in Credit Karma's product, serving as the foundation for core machine learning capabilities that drive monetization, personalization, and a value-centric experience for our members. As such, this role is highly cross-functional and requires tight partnerships with a wide range of functions - including engineering, product, marketing, finance and analytics.

We are seeking a Senior Data Scientist to drive innovation in the development and application of data science techniques that power the most relevant financial products including and actionable recommendations at Credit Karma. This role is ideal for someone who combines strong statistical and machine learning skills with business acumen and cross-functional collaboration.

What you'll do:
• Partner with colleagues throughout the organization to identify high-impact opportunities to leverage our extensive data to better serve our users
• Responsible for accelerating revenue and engagement advancement through disruptive and continuous improvements in various data science models (targeting, marketing campaigns, etc.), feature engineering including user profiles and behavior, personalization, etc.
• Participate research efforts with other team members to explore the frontiers of GenAI, Deep Learning, Recommender systems, and other areas, as they apply to Personal Finance
• Collaborate closely with partner teams to define metrics that quantify various aspects of our business, including but not limited to revenue, engagement, user experience, etc. Provide solid statistical bases in designing experiments.
• Represent Data Science in cross functional meetings and reviews. Be able to translate difficult technical subject matter to business partners
• Represent Credit Karma in external forums such as conferences and meetups, and act as an evangelist for CK team in such forums

What's great about the role:
• You will work with large scale Machine Learning Models to optimize for Personal Finance Products
• You will be part of a highly impactful team, who are working on large scale projects that directly impact the business and members
• You will experience both personal and professional growth as you encourage growth throughout the team

Minimum Basic Requirement:
• MS in Computer Science, Mathematics, Statistics, Physics or a related quantitative discipline
• 5+ years of industrial experience in Data Science, Machine Learning and related areas, ideally in hyper-growth consumer Internet scenarios
• Deep statistical understanding of data at scale
• Authoritative knowledge of Python/R and SQL
• Experience with advanced modeling techniques, such as deep neutral network, collaborative filtering, matrix factorization, time series analysis, mixed-effect models, etc

Preferred Qualifications:
• Experience with driving monetization, member engagement, longer term member value through AI
• Experience working on large scale AI systems with applications across machine learning and generative AI, AI infrastructure, data foundation, and self-serve analytics through DS methods
• Ability to balance fast paced environments at a large scale company
• Ads business and product experience

Credit Karma's mission of championing financial progress for all starts from within. That's why we implemented role-based compensation, which ensures people who are in the same role receive the same pay with variations for geographic location only. It's all part of a more comprehensive DEI strategy that helps level the playing field. The base salary range for this role is $296,068, plus equity and benefits.

Benefits at Credit Karma includes:
• Medical and Dental Coverage
• Retirement Plan
• Commuter Benefits
• Wellness perks
• Paid Time Off (Vacation, Sick, Baby Bonding, Cultural Observance, & More)
• Education Perks
• Paid Gift Week in December

Equal Employment Opportunity:

Credit Karma is proud to be an Equal Employment Opportunity Employer. We welcome all candidates without regard to race, color, religion, age, marital status, sex (including pregnancy, childbirth, or related medical condition), sexual orientation, gender identity or gender expression, national origin, veteran or military status, disability (physical or mental), genetic information or other protected characteristic. We prohibit discrimination of any kind and operate in compliance with applicable fair chance laws.

Credit Karma is also committed to a diverse and inclusive work environment because it is the right thing to do. We believe that such an environment advances long-term professional growth, creates a robust business, and supports our mission of championing financial progress for everyone. We offer generous benefits and perks with a single eye to nourishing an inclusive environment that recognizes the contributions of all and fosters diversity by supporting our internal Employee Resource Groups. We've worked hard to build an intensely collaborative and creative environment, a diverse and inclusive employee culture, and the opportunity for professional growth. As part of the Credit Karma team, your voice will be heard, your contributions will matter, and your unique background and experiences will be celebrated.

Privacy Policies:

Credit Karma is strongly committed to protecting personal data. Please take a look below to review our privacy policies:
• GDPR Privacy Policy
• U.S. Job Applicant Privacy Notice",,2025-07-25,"['Credit Karma is looking for a results-oriented and strategically innovative Senior Data Scientist who is passionate about applying machine learning to solve financial challenges for millions of members', 'We are seeking a Senior Data Scientist to drive innovation in the development and application of data science techniques that power the most relevant financial products including and actionable recommendations at Credit Karma', 'This role is ideal for someone who combines strong statistical and machine learning skills with business acumen and cross-functional collaboration', 'MS in Computer Science, Mathematics, Statistics, Physics or a related quantitative discipline', '5+ years of industrial experience in Data Science, Machine Learning and related areas, ideally in hyper-growth consumer Internet scenarios', 'Deep statistical understanding of data at scale', 'Authoritative knowledge of Python/R and SQL', 'Experience with advanced modeling techniques, such as deep neutral network, collaborative filtering, matrix factorization, time series analysis, mixed-effect models, etc']","[""Data Science plays a ubiquitous role in Credit Karma's product, serving as the foundation for core machine learning capabilities that drive monetization, personalization, and a value-centric experience for our members"", 'Partner with colleagues throughout the organization to identify high-impact opportunities to leverage our extensive data to better serve our users', 'Responsible for accelerating revenue and engagement advancement through disruptive and continuous improvements in various data science models (targeting, marketing campaigns, etc.), feature engineering including user profiles and behavior, personalization, etc', 'Participate research efforts with other team members to explore the frontiers of GenAI, Deep Learning, Recommender systems, and other areas, as they apply to Personal Finance', 'Collaborate closely with partner teams to define metrics that quantify various aspects of our business, including but not limited to revenue, engagement, user experience, etc', 'Provide solid statistical bases in designing experiments', 'Represent Data Science in cross functional meetings and reviews', 'Be able to translate difficult technical subject matter to business partners', 'Represent Credit Karma in external forums such as conferences and meetups, and act as an evangelist for CK team in such forums']",True,"['Generative AI', 'Deep Learning']","Generative AI: Explored as part of research efforts to innovate financial product recommendations and personalization at Credit Karma.; Deep Learning: Investigated and applied in the context of advancing AI capabilities for personal finance products, including recommender systems.","['Machine Learning', 'Statistical Modeling', 'Deep Neural Networks', 'Collaborative Filtering', 'Matrix Factorization', 'Time Series Analysis', 'Feature Engineering', 'Python/R', 'SQL', 'Recommender Systems', 'Data Science Techniques', 'Experiment Design and A/B Testing']","Machine Learning: Applied to solve financial challenges and drive monetization, personalization, and value-centric experiences for members at Credit Karma.; Statistical Modeling: Used to develop advanced models including mixed-effect models and to provide solid statistical bases for designing experiments and defining business metrics.; Deep Neural Networks: Employed as an advanced modeling technique to improve financial product recommendations and personalization.; Collaborative Filtering: Utilized as a modeling technique to enhance recommender systems for personal finance products.; Matrix Factorization: Applied as an advanced modeling technique to support recommendation and personalization systems.; Time Series Analysis: Used to analyze temporal data patterns relevant to financial products and user behavior.; Feature Engineering: Involves creating user profiles and behavior features to improve targeting, marketing campaigns, and personalization models.; Python/R: Authoritative programming languages used for data science and machine learning model development.; SQL: Used for querying and managing extensive data to support data-driven decision making and model development.; Recommender Systems: Developed and researched to provide actionable financial product recommendations to members.; Data Science Techniques: Applied broadly to power relevant financial products and actionable recommendations, including driving revenue and engagement improvements.; Experiment Design and A/B Testing: Used to define and quantify business metrics such as revenue, engagement, and user experience through statistically sound experiments."
JVN5an6JjGzZrIZoAAAAAA==,"Senior Data Scientist, Specialist Senior - SFL Scientific","Senior Data Scientist, Specialist Senior - SFL Scientific

Our Deloitte Strategy & Transactions team helps guide clients through their most critical moments and transformational initiatives. From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability. Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journey-before, during, and after any major transformational projects or transactions.

SFL Scientific, a Deloitte Business, is a U.S. based, data science consulting firm specializing in building industry-specific, artificial intelligence (AI) technologies.

We are hiring a Senior Data Scientist to collaborate directly with clients to design and develop novel projects and solutions. Join a rapidly growing team of professionals working to build a world-class data science practice focused on solving complex and R&D problems.

Recruiting for this role ends on 7/31/2025.

Work You'll Do

As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services. You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions.

Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation. Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills.
• Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production
• Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives
• Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization
• Validate AI models and algorithm via code reviews, unit, and integration tests
• Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives
• Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives

The Team

Our Strategy offering architects bold strategies to achieve business and mission goals, enabling growth, competitive advantage, technology modernization, and continuous digital and AI transformation.

SFL Scientific, a Deloitte Business, is a data science professional services practice focused on strategy, technology, and solving business challenges with Artificial Intelligence (AI). The team has a proven track record serving large, market-leading organizations in the private and public sectors, successfully delivering high-quality, novel and complex projects, and offering deep domain and scientific capabilities. Made up of experienced AI strategists, data scientists, and AI engineers, they serve as trusted advisors to executives, helping them understand and evaluate new and essential areas for AI investment and identify unique opportunities to transform their businesses.

Qualifications:
• Master's or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)
• 3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)
• 3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments
• 3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow
• 3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads
• Live within commuting distance to one of Deloitte's consulting offices
• Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve
• Limited immigration sponsorship may be available

Preferred:
• 2+ years of experience working in a client-facing, consulting environment
• 2+ years of experience leading project/client engagement teams in the execution of complex AI data science solutions
• 1+ year of experience with LLM/GenAI use cases and developing RAG solutions, tools, and services (i.e., LangChain, LangGraph, MCP, etc.)
• 1+ year of experience with AWS Sagemaker or AWS ML Studio

Information for applicants with a need for accommodation: https://www2.deloitte.com/us/en/pages/careers/articles/join-deloitte-assistance-for-disabled-applicants.html

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $107,600 to $198,400.

You may also be eligible to participate in a discretionary annual incentive program, subject to the rules governing the program, whereby an award, if any, depends on various factors, including, without limitation, individual and organizational performance.

#MonitorDeloitte

#DeloitteJobs

#StrategyConsulting

#DeloitteStrategy

#Strategy26

#SFL26

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.",2025-06-26T00:00:00.000Z,2025-07-25,"[""Master's or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)"", '3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)', '3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments', '3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow', '3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads', ""Live within commuting distance to one of Deloitte's consulting offices"", 'Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve', 'Limited immigration sponsorship may be available', 'Information for applicants with a need for accommodation: https://www2.deloitte.com/us/en/pages/careers/articles/join-deloitte-assistance-for-disabled-applicants.html']","['From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability', 'Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journey-before, during, and after any major transformational projects or transactions', 'As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services', 'You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions', 'Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation', 'Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills', 'Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production', 'Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives', 'Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization', 'Validate AI models and algorithm via code reviews, unit, and integration tests', 'Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives', 'Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives']",True,"['Generative AI', 'Large Language Models', 'Deep Learning Frameworks', 'AI Model Deployment and MLOps', 'AI Strategy and Consulting', 'Edge AI and Autonomous Systems', 'AI Hardware Optimization', 'Retrieval-Augmented Generation', 'Cloud AI Services']","Generative AI: Experience with LLM/GenAI use cases and developing Retrieval-Augmented Generation solutions, tools, and services such as LangChain, LangGraph, and MCP.; Large Language Models: Involves working with LLMs in use cases related to generative AI and AI service development.; Deep Learning Frameworks: Use of frameworks like PyTorch specifically for developing and deploying neural network-based AI models.; AI Model Deployment and MLOps: Deploying and optimizing AI/ML models using Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow, with a focus on AI model lifecycle management.; AI Strategy and Consulting: Guiding clients with high autonomy in AI strategy and development, including thought leadership, long-term maintenance, and aligning AI solutions with business objectives.; Edge AI and Autonomous Systems: Working on novel projects involving autonomous systems and edge AI as part of AI service development.; AI Hardware Optimization: Researching and implementing hardware optimization techniques to advance state-of-the-art AI training and solution design.; Retrieval-Augmented Generation: Developing RAG solutions and tools to enhance generative AI capabilities.; Cloud AI Services: Experience with AWS SageMaker and AWS ML Studio for deploying and managing AI/ML workloads.","['Exploratory Data Analysis', 'Machine Learning', 'Deep Learning', 'Time-Series Analysis', 'Natural Language Processing', 'Computer Vision', 'Model Validation and Testing', 'Model Deployment and Optimization', 'Cloud Computing for AI/ML', 'Data Strategy']","Exploratory Data Analysis: Used to understand client data sets and operational requirements to design long-term data science solutions.; Machine Learning: Applied in developing AI/ML solutions, including traditional ML algorithm development, model tuning, performance validation, and deployment in production environments.; Deep Learning: Utilized techniques such as CNNs, RNNs, and GANs across real-world projects, including model tuning and performance validation.; Time-Series Analysis: Applied as part of data analysis methods in AI/ML algorithm development.; Natural Language Processing: Used as a data analysis technique within AI/ML algorithm development.; Computer Vision: Employed as a data analysis method in AI/ML algorithm development.; Model Validation and Testing: Includes validating AI models and algorithms via code reviews, unit tests, and integration tests to ensure quality and performance.; Model Deployment and Optimization: Involves deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow.; Cloud Computing for AI/ML: Leveraging cloud environments such as AWS, Azure, or GCP to deploy AI/ML workloads.; Data Strategy: Defining data strategy to drive technical development and create next-generation tools, products, and AI services."
Ql269g0qeg8rzPDQAAAAAA==,Senior Data Scientist [$203K/yr] TS/SCI FS-Poly Jobs,"Candidates must already possess an active Top Secret/SCI w. Full Scope Polygraph to be considered for this position.

Apply in 60 seconds at https://apply.systolic.com

Summary:

• SYSTOLIC is seeking a Senior Data Scientist

• Building and maintaining custom data analytics to automate and scale analysis

Qualifications & Compensation:

• Associate's degree with 12 years of relevant experience

• Bachelor’s Degree with 10 years of relevant experience

• Master's degree with 8 years of relevant experience

• Doctorate with 6 years of relevant experience

• Degree must be in Mathematics, Applied Mathematics Statistics, Applied Statistics, Machine learning, Data Science, Operations Research, or Computer Science or a degree in a related field. A broader range of degrees will be considered if accompanied by a Certificate in Data Science from an accredited college/university.

• Relevant experience must be in designing/implementing machine learning, data science, advanced analytical algorithms, programming, statistical analysis (e.g. variability, sampling error, inference, hypothesis testing, EDA, application of linear models), data management, data mining, data modeling and assessment, artificial intelligence, and/or software engineering.

• Candidates who meet these requirements will receive an annual compensation of approximately [$203K/yr]

About SYSTOLIC:

SYSTOLIC is dedicated to giving our employees the best possible company experience so that they can focus on providing outstanding support to their customer’s mission. Our company is founded on integrity, enthusiasm, and a relentless commitment to supporting the Intelligence Community. You can learn more about us and submit an application at https://systolic.com.

To learn about our compensation ranges, visit our Pay Transparency page at: https://systolic.com/pay-transparency",2025-07-18T00:00:00.000Z,2025-07-25,"['Candidates must already possess an active Top Secret/SCI w', 'Full Scope Polygraph to be considered for this position', ""Associate's degree with 12 years of relevant experience"", 'Bachelor’s Degree with 10 years of relevant experience', ""Master's degree with 8 years of relevant experience"", 'Doctorate with 6 years of relevant experience', 'Degree must be in Mathematics, Applied Mathematics Statistics, Applied Statistics, Machine learning, Data Science, Operations Research, or Computer Science or a degree in a related field', 'A broader range of degrees will be considered if accompanied by a Certificate in Data Science from an accredited college/university', 'Relevant experience must be in designing/implementing machine learning, data science, advanced analytical algorithms, programming, statistical analysis (e.g. variability, sampling error, inference, hypothesis testing, EDA, application of linear models), data management, data mining, data modeling and assessment, artificial intelligence, and/or software engineering']","['SYSTOLIC is seeking a Senior Data Scientist', 'Building and maintaining custom data analytics to automate and scale analysis']",True,['Artificial Intelligence'],"Artificial Intelligence: Relevant experience includes artificial intelligence, indicating involvement with AI concepts or technologies as part of the Senior Data Scientist role.","['Machine Learning', 'Data Science', 'Statistical Analysis', 'Data Analytics', 'Data Management', 'Data Mining', 'Data Modeling and Assessment']","Machine Learning: Designing and implementing machine learning models and algorithms as part of relevant experience for the Senior Data Scientist role.; Data Science: Applying data science principles including data management, data mining, data modeling, and advanced analytical algorithms to support analysis automation and scaling.; Statistical Analysis: Utilizing statistical methods such as variability analysis, sampling error, inference, hypothesis testing, exploratory data analysis (EDA), and linear models in the context of data science tasks.; Data Analytics: Building and maintaining custom data analytics solutions to automate and scale data analysis processes.; Data Management: Handling and organizing data effectively as part of the data science and analytics responsibilities.; Data Mining: Extracting useful information and patterns from large datasets to support analytical objectives.; Data Modeling and Assessment: Creating and evaluating data models to support decision-making and analysis automation."
9URUKTsZ6I8sQh_wAAAAAA==,"(USA) Senior, Data Scientist","Position Summary...

Join Walmart|VIZIO and take your career to the next level!

We are looking for a highly talented and motivated Data Scientist to help deliver strategic initiatives across the organization. We look for people who can effectively partner with Product Management, Engineering, and business leaders to deliver easy, effective, and insightful analytics. We are a growing team, focusing on challenging problems that make a difference to our business. We concentrate on high-impact, high-value development, and analysis. We are looking for someone who is versatile, methodical, excited by modern technology and enjoys focusing on tackling software challenges.

What you'll do...

About the Data Science Team:

Our Data Science team operates at the heart of VIZIO/Walmart's mission to deliver the best shopping experience to our customers. We leverage advanced analytics, machine learning, and big data to drive business insights and strategic decisions. As a Senior Data Scientist, you will play a crucial role in enhancing our data capabilities and contributing to VIZIO/Walmart’s growth and innovation.

What You’ll Do:
• Solve novel and complex business problems with high-quality, maintainable code.
• Collaborate cross-functionally with Product Managers and Engineering teams to gather requirements and develop solutions.
• Analyze high volumes of data to understand business problems and propose technical solutions.
• Develop and iterate on machine learning models, from quick prototypes to production deployment.
• Evaluate the efficacy and value of product features using data-driven insights.
• Organize and document complex technical projects.

What You’ll Bring:
• Expertise in big data analytics and automation techniques.
• Strong understanding of business contexts and the ability to translate business problems into data solutions.
• Proficiency with database technologies and distributed datastores (e.g., SQL, NoSQL).
• Experience in developing and deploying machine learning models.
• Experience writing production code in Python, fluent in PySpark
• Expertise with at least one ML framework (pytorch, tensorflow, jax)
• Experience with CI/CD frameworks

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.
‎

‎

‎
You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.
‎

For information about PTO, see https://one.walmart.com/notices.

‎

‎
Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.
‎
Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.
‎

For information about benefits and eligibility, see One.Walmart.

‎
New York, New York US-11582:The annual salary range for this position is $108,000.00-$216,000.00
‎
San Francisco, California US-11574:The annual salary range for this position is $117,000.00-$234,000.00
‎

‎

‎

‎

‎

‎

‎

‎

‎

‎
Additional compensation includes annual or quarterly performance bonuses.
‎
Additional compensation for certain positions may also include:
‎

‎
- Stock
‎

‎

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1- Bachelor’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years' experience in an analytics related field. Option 2- Master’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years' experience in an analytics related field. Option 3 - 5 years' experience in an analytics or related field.

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data science, machine learning, optimization models, Master’s degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.

Primary Location...

350 5Th Ave, New York, NY 10118-4801, United States of America",,2025-07-25,"['We look for people who can effectively partner with Product Management, Engineering, and business leaders to deliver easy, effective, and insightful analytics', 'We are looking for someone who is versatile, methodical, excited by modern technology and enjoys focusing on tackling software challenges', 'Expertise in big data analytics and automation techniques', 'Strong understanding of business contexts and the ability to translate business problems into data solutions', 'Proficiency with database technologies and distributed datastores (e.g., SQL, NoSQL)', 'Experience in developing and deploying machine learning models', 'Experience writing production code in Python, fluent in PySpark', 'Expertise with at least one ML framework (pytorch, tensorflow, jax)', 'Experience with CI/CD frameworks', ""Option 1- Bachelor’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years' experience in an analytics related field"", ""Option 2- Master’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years' experience in an analytics related field"", ""Option 3 - 5 years' experience in an analytics or related field"", 'Data science, machine learning, optimization models, Master’s degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly', 'The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture']","['Solve novel and complex business problems with high-quality, maintainable code', 'Collaborate cross-functionally with Product Managers and Engineering teams to gather requirements and develop solutions', 'Analyze high volumes of data to understand business problems and propose technical solutions', 'Develop and iterate on machine learning models, from quick prototypes to production deployment', 'Evaluate the efficacy and value of product features using data-driven insights', 'Organize and document complex technical projects']",True,[],,"['Big Data Analytics', 'Machine Learning Models', 'SQL and NoSQL Databases', 'Python and PySpark', 'ML Frameworks (PyTorch, TensorFlow, JAX)', 'CI/CD Frameworks', 'Optimization Models', 'Open Source Frameworks (scikit-learn, TensorFlow, Torch)']","Big Data Analytics: Used to analyze high volumes of data to understand business problems and propose technical solutions, supporting strategic initiatives and business insights.; Machine Learning Models: Developed and iterated from prototypes to production deployment to solve complex business problems and evaluate product features.; SQL and NoSQL Databases: Proficiency required for working with database technologies and distributed datastores to support data solutions.; Python and PySpark: Used for writing production code and handling big data processing within the data science workflows.; ML Frameworks (PyTorch, TensorFlow, JAX): Expertise required in at least one machine learning framework to develop and deploy machine learning models.; CI/CD Frameworks: Experience with continuous integration and continuous deployment frameworks to support production code and model deployment.; Optimization Models: Applied to solve business problems and improve decision-making processes as part of data science responsibilities.; Open Source Frameworks (scikit-learn, TensorFlow, Torch): Used for building machine learning models and analytics solutions within the data science team."
0abUPN9AxuM80uqSAAAAAA==,"Senior Data Scientist, Amazon Advertising","DESCRIPTION

Amazon Advertising is one of Amazon's fastest growing and most profitable businesses, responsible for defining and delivering a collection of advertising products that drive discovery and sales. Our products and solutions are strategically important to enable our Retail and Marketplace businesses to drive long-term growth. We deliver billions of ad impressions and millions of clicks and break fresh ground in product and technical innovations every day!

As a Senior Data Scientist on this team you will:
• Lead Data Science solutions from beginning to end.
• Deliver with independence on challenging large-scale problems with complexity and ambiguity.
• Write code (Python, R, Scala, SQL, etc.) to obtain, manipulate, and analyze data.
• Build Machine Learning and statistical models to solve specific business problems.
• Retrieve, synthesize, and present critical data in a format that is immediately useful to answering specific questions or improving system performance.
• Analyze historical data to identify trends and support optimal decision making.
• Apply statistical and machine learning knowledge to specific business problems and data.
• Formalize assumptions about how our systems should work, create statistical definitions of outliers, and develop methods to systematically identify outliers. Work out why such examples are outliers and define if any actions needed.
• Given anecdotes about anomalies or generate automatic scripts to define anomalies, deep dive to explain why they happen, and identify fixes.
• Build decision-making models and propose effective solutions for the business problems you define.
• Conduct written and verbal presentations to share insights to audiences of varying levels of technical sophistication.

Why you will love this opportunity: Amazon has invested heavily in building a world-class advertising business. This team defines and delivers a collection of advertising products that drive discovery and sales. Our solutions generate billions in revenue and drive long-term growth for Amazon’s Retail and Marketplace businesses. We deliver billions of ad impressions, millions of clicks daily, and break fresh ground to create world-class products. We are a highly motivated, collaborative, and fun-loving team with an entrepreneurial spirit - with a broad mandate to experiment and innovate.

Impact and Career Growth: You will invent new experiences and influence customer-facing shopping experiences to help suppliers grow their retail business and the auction dynamics that leverage native advertising; this is your opportunity to work within the fastest-growing businesses across all of Amazon! Define a long-term science vision for our advertising business, driven from our customers' needs, translating that direction into specific plans for research and applied scientists, as well as engineering and product teams. This role combines science leadership, organizational ability, technical strength, product focus, and business understanding.

Team video ~ https://youtu.be/zD_6Lzw8raE

BASIC QUALIFICATIONS
• 5+ years of data querying languages (e.g. SQL), scripting languages (e.g. Python) or statistical/mathematical software (e.g. R, SAS, Matlab, etc.) experience
• 4+ years of data scientist experience
• Bachelor's degree
• Experience with statistical models e.g. multinomial logistic regression

PREFERRED QUALIFICATIONS
• 2+ years of data visualization using AWS QuickSight, Tableau, R Shiny, etc. experience
• Experience managing data pipelines
• Experience as a leader and mentor on a data science team

Amazon is an equal opportunity employer and does not discriminate on the basis of protected veteran status, disability, or other legally protected status.

Los Angeles County applicants: Job duties for this position include: work safely and cooperatively with other employees, supervisors, and staff; adhere to standards of excellence despite stressful conditions; communicate effectively and respectfully with employees, supervisors, and staff to ensure exceptional customer service; and follow all federal, state, and local laws and Company policies. Criminal history may have a direct, adverse, and negative relationship with some of the material job duties of this position. These include the duties and responsibilities listed above, as well as the abilities to adhere to company policies, exercise sound judgment, effectively manage stress and work safely and respectfully with others, exhibit trustworthiness and professionalism, and safeguard business operations and the Company’s reputation. Pursuant to the Los Angeles County Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $143,300/year in our lowest geographic market up to $247,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.

Job details

USA, TX, Austin

USA, WA, Seattle

USA, VA, Arlington

USA, NY, New York

USA, CA, West Hollywood

USA, CA, Los Angeles

USA, CA, Palo Alto

Machine Learning Science",2025-07-16T00:00:00.000Z,2025-07-25,"['5+ years of data querying languages (e.g. SQL), scripting languages (e.g. Python) or statistical/mathematical software (e.g. R, SAS, Matlab, etc.) experience', '4+ years of data scientist experience', ""Bachelor's degree"", 'Experience with statistical models e.g. multinomial logistic regression', 'These include the duties and responsibilities listed above, as well as the abilities to adhere to company policies, exercise sound judgment, effectively manage stress and work safely and respectfully with others, exhibit trustworthiness and professionalism, and safeguard business operations and the Company’s reputation']","['Lead Data Science solutions from beginning to end', 'Deliver with independence on challenging large-scale problems with complexity and ambiguity', 'Write code (Python, R, Scala, SQL, etc.)', 'to obtain, manipulate, and analyze data', 'Build Machine Learning and statistical models to solve specific business problems', 'Retrieve, synthesize, and present critical data in a format that is immediately useful to answering specific questions or improving system performance', 'Analyze historical data to identify trends and support optimal decision making', 'Apply statistical and machine learning knowledge to specific business problems and data', 'Formalize assumptions about how our systems should work, create statistical definitions of outliers, and develop methods to systematically identify outliers', 'Work out why such examples are outliers and define if any actions needed', 'Given anecdotes about anomalies or generate automatic scripts to define anomalies, deep dive to explain why they happen, and identify fixes', 'Build decision-making models and propose effective solutions for the business problems you define', 'Conduct written and verbal presentations to share insights to audiences of varying levels of technical sophistication', ""Define a long-term science vision for our advertising business, driven from our customers' needs, translating that direction into specific plans for research and applied scientists, as well as engineering and product teams"", 'This role combines science leadership, organizational ability, technical strength, product focus, and business understanding']",True,[],,"['SQL', 'Python', 'R', 'Scala', 'Statistical Models', 'Machine Learning', 'Data Visualization Tools', 'Data Pipelines', 'Anomaly Detection', 'Data Analysis', 'Statistical Definitions of Outliers']","SQL: Used for querying and manipulating data as part of data analysis and building data science solutions.; Python: Used for scripting to obtain, manipulate, and analyze data, and to build machine learning and statistical models.; R: Used for statistical analysis, scripting, and building machine learning and statistical models.; Scala: Used as a programming language to write code for data manipulation and analysis.; Statistical Models: Includes models such as multinomial logistic regression used to solve specific business problems and identify outliers.; Machine Learning: Applied to build predictive and decision-making models to address business problems and improve system performance.; Data Visualization Tools: Experience with tools like AWS QuickSight, Tableau, and R Shiny to visualize data and communicate insights.; Data Pipelines: Experience managing data pipelines to support data processing and analysis workflows.; Anomaly Detection: Developing methods and scripts to define, identify, and explain anomalies or outliers in data to support decision making.; Data Analysis: Analyzing historical data to identify trends and support optimal decision making.; Statistical Definitions of Outliers: Formalizing assumptions and creating statistical criteria to systematically identify outliers in data."
GswHAqACfpS8GXwSAAAAAA==,Senior Data Scientist - Full-time,"At Johnson & Johnson, we believe health is everything. Our strength in healthcare innovation empowers us to build a world where complex diseases are prevented, treated, and cured, where treatments are smarter and less invasive, and solutions are personal. Through our expertise in Innovative Medicine and MedTech, we are uniquely positioned to innovate across the full spectrum of healthcare solutions today to deliver the breakthroughs of tomorrow, and profoundly impact health for humanity. Learn more at https://www.jnj.com
• *Job Function:**

Data Analytics & Computational Sciences
• *Job Sub** **Function:**

Data Science
• *Job Category:**

Scientific/Technology
• *All Job Posting Locations:**

Titusville, New Jersey, United States of America
• *Job Description:**

We are searching for the best talent for Senior Data Scientist to be in Titusville, NJ.

Our expertise in Innovative Medicine is informed and inspired by patients, whose insights fuel our science-based advancements. Visionaries like you work on teams that save lives by developing the medicines of tomorrow.

Join us in developing treatments, finding cures, and pioneering the path from lab to life while championing patients every step of the way.

Learn more at https://www.jnj.com/innovative-medicine
• *The Commercial Data Sciences Team** is looking for an extraordinary scientist who is passionate about crafting, developing, and fielding data science solutions that drive impact for patients and for Johnson & Johnson. There are many ways to explore and analyze data, and this powers the enthusiasm and passion of data scientists at J&J as many business units are eager to use the data to build business value.
• *You will be responsible for:**

This role needs someone who stays on the cutting edge of artificial intelligence, data science, and advanced analytics research through novel project execution and development of algorithms that influence decisions at various levels in the organization, with main focus on omnichannel sales and marketing optimization, but also including distribution demands, patient/payer analytics, commercial strategy, and related commercially focused model development.

The role requires both a broad knowledge of existing AI-type algorithms and the ingenuity to invent and customize when necessary. You will lead and deliver projects and develop solutions that in turn deliver insights. You will also work closely with cross departmental teams across business and technology to understand how best to solve complex problems. You will be a member of a highly collaborative and supportive team, which is part of a broader dynamic and accomplished organization that supports multiple therapeutic areas and commercial functions.

Come join us in our mission to transform the future of health!
• *Qualifications / Requirements:**

+ Ph.D. with 2+ years of experience, or M.S. with 5+ years, B.S. with 7+ years of relevant pharma experience, with degree in Computer Sciences, Statistics, Machine Learning & Artificial Intelligence, Physics, Molecular Biology, Bioinformatics, Computational Informatics, Medical Informatics, Computational Biology or a related field.

+ Solid understanding of machine learning platforms/environments.

+ Experience with practical applications of AI-type algorithms, including machine learning techniques such as regression, decision trees, probability networks, association rules, clustering, neural networks, and/or Bayesian models.

+ Familiarity with large datasets, handling of healthcare relevant datasets and understanding of data analysis workflows.

+ Proficiency with one or more programming language such as Python or R.

+ Proficiency with SQL.

+ Experience delivering on data science projects using Machine learning and AI technologies, data mining and/or text mining.

+ Familiarity with working in a cloud-based technology stack.

+ Sophisticated communication skills and ability to translate complex methods and results to diverse audiences.

+ Strong ability to establish relationships with business partners and understand their needs.

+ Proven track record to deliver end-to-end machine learning projects from understanding business requirements, development, deployment, and management of post-launch operations

+ Experience with vendor management – ensuring timelines and expectations
• *Preferred Qualifications:**

+ Experience in the Commercial Pharmaceutical business.

+ Experience with Medical / Scientific Affairs functions, Evidence generation, Unmet Need identification

+ Experience in digital media and direct-to-consumer marketing

+ Familiarity of commercially available healthcare data sets.

+ Experience with PySpark.

+ Familiarity with usage of Generative AI for productivity improvement.

+ Familiarity with open-source and gated/paid model landscape
• *Other:**

+ This position will require up to 15% domestic travel.

Johnson & Johnson is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, national origin, disability, protected veteran status or other characteristics protected by federal, state or local law. We actively seek qualified candidates who are protected veterans and individuals with disabilities as defined under VEVRAA and Section 503 of the Rehabilitation Act.

Johnson and Johnson is committed to providing an interview process that is inclusive of our applicants’ needs. If you are an individual with a disability and would like to request an accommodation, please email the Employee Health Support Center (ra-employeehealthsup@its.jnj.com) or contact AskGS to be directed to your accommodation resource.

\#Li-Hybrid

\#JNJDataScience

\#JNJIMCommercial-DS

At Johnson & Johnson, we believe health is everything. Our strength in healthcare innovation empowers us to build a world where complex diseases are prevented, treated, and cured, where treatments are smarter and less invasive, and solutions are personal. Through our expertise in Innovative Medicine and MedTech, we are uniquely positioned to innovate across the full spectrum of healthcare solutions today to deliver the breakthroughs of tomorrow, and profoundly impact health for humanity. Learn more at https://www.jnj.com
• *Job Function:**

Data Analytics & Computational Sciences
• *Job Sub** **Function:**

Data Science
• *Job Category:**

Scientific/Technology
• *All Job Posting Locations:**

Titusville, New Jersey, United States of America
• *Job Description:**

We are searching for the best talent for Senior Data Scientist to be in Titusville, NJ.

Our expertise in Innovative Medicine is informed and inspired by patients, whose insights fuel our science-based advancements. Visionaries like you work on teams that save lives by developing the medicines of tomorrow.

Join us in developing treatments, finding cures, and pioneering the path from lab to life while championing patients every step of the way.

Learn more at https://www.jnj.com/innovative-medicine
• *The Commercial Data Sciences Team** is looking for an extraordinary scientist who is passionate about crafting, developing, and fielding data science solutions that drive impact for patients and for Johnson & Johnson. There are many ways to explore and analyze data, and this powers the enthusiasm and passion of data scientists at J&J as many business units are eager to use the data to build business value.
• *You will be responsible for:**

This role needs someone who stays on the cutting edge of artificial intelligence, data science, and advanced analytics research through novel project execution and development of algorithms that influence decisions at various levels in the organization, with main focus on omnichannel sales and marketing optimization, but also including distribution demands, patient/payer analytics, commercial strategy, and related commercially focused model development.

The role requires both a broad knowledge of existing AI-type algorithms and the ingenuity to invent and customize when necessary. You will lead and deliver projects and develop solutions that in turn deliver insights. You will also work closely with cross departmental teams across business and technology to understand how best to solve complex problems. You will be a member of a highly collaborative and supportive team, which is part of a broader dynamic and accomplished organization that supports multiple therapeutic areas and commercial functions.

Come join us in our mission to transform the future of health!
• *Qualifications / Requirements:**

+ Ph.D. with 2+ years of experience, or M.S. with 5+ years, B.S. with 7+ years of relevant pharma experience, with degree in Computer Sciences, Statistics, Machine Learning & Artificial Intelligence, Physics, Molecular Biology, Bioinformatics, Computational Informatics, Medical Informatics, Computational Biology or a related field.

+ Solid understanding of machine learning platforms/environments.

+ Experience with practical applications of AI-type algorithms, including machine learning techniques such as regression, decision trees, probability networks, association rules, clustering, neural networks, and/or Bayesian models.

+ Familiarity with large datasets, handling of healthcare relevant datasets and understanding of data analysis workflows.

+ Proficiency with one or more programming language such as Python or R.

+ Proficiency with SQL.

+ Experience delivering on data science projects using Machine learning and AI technologies, data mining and/or text mining.

+ Familiarity with working in a cloud-based technology stack.

+ Sophisticated communication skills and ability to translate complex methods and results to diverse audiences.

+ Strong ability to establish relationships with business partners and understand their needs.

+ Proven track record to deliver end-to-end machine learning projects from understanding business requirements, development, deployment, and management of post-launch operations

+ Experience with vendor management – ensuring timelines and expectations
• *Preferred Qualifications:**

+ Experience in the Commercial Pharmaceutical business.

+ Experience with Medical / Scientific Affairs functions, Evidence generation, Unmet Need identification

+ Experience in digital media and direct-to-consumer marketing

+ Familiarity of commercially available healthcare data sets.

+ Experience with PySpark.

+ Familiarity with usage of Generative AI for productivity improvement.

+ Familiarity with open-source and gated/paid model landscape
• *Other:**

+ This position will require up to 15% domestic travel.

Johnson & Johnson is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, national origin, disability, protected veteran status or other characteristics protected by federal, state or local law. We actively seek qualified candidates who are protected veterans and individuals with disabilities as defined under VEVRAA and Section 503 of the Rehabilitation Act.

Johnson and Johnson is committed to providing an interview process that is inclusive of our applicants’ needs. If you are an individual with a disability and would like to request an accommodation, please email the Employee Health Support Center (ra-employeehealthsup@its.jnj.com) or contact AskGS to be directed to your accommodation resource.

\#Li-Hybrid

\#JNJDataScience

\#JNJIMCommercial-DS",2025-07-25T14:00:00.000Z,2025-07-25,"['This role needs someone who stays on the cutting edge of artificial intelligence, data science, and advanced analytics research through novel project execution and development of algorithms that influence decisions at various levels in the organization, with main focus on omnichannel sales and marketing optimization, but also including distribution demands, patient/payer analytics, commercial strategy, and related commercially focused model development', 'The role requires both a broad knowledge of existing AI-type algorithms and the ingenuity to invent and customize when necessary', 'Ph.D. with 2+ years of experience, or M.S. with 5+ years, B.S. with 7+ years of relevant pharma experience, with degree in Computer Sciences, Statistics, Machine Learning & Artificial Intelligence, Physics, Molecular Biology, Bioinformatics, Computational Informatics, Medical Informatics, Computational Biology or a related field', 'Solid understanding of machine learning platforms/environments', 'Experience with practical applications of AI-type algorithms, including machine learning techniques such as regression, decision trees, probability networks, association rules, clustering, neural networks, and/or Bayesian models', 'Familiarity with large datasets, handling of healthcare relevant datasets and understanding of data analysis workflows', 'Proficiency with one or more programming language such as Python or R', 'Proficiency with SQL', 'Experience delivering on data science projects using Machine learning and AI technologies, data mining and/or text mining', 'Familiarity with working in a cloud-based technology stack', 'Sophisticated communication skills and ability to translate complex methods and results to diverse audiences', 'Strong ability to establish relationships with business partners and understand their needs', 'Proven track record to deliver end-to-end machine learning projects from understanding business requirements, development, deployment, and management of post-launch operations', 'Experience with vendor management – ensuring timelines and expectations', 'Experience in the Commercial Pharmaceutical business', 'Experience with Medical / Scientific Affairs functions, Evidence generation, Unmet Need identification', 'Experience in digital media and direct-to-consumer marketing', 'Familiarity of commercially available healthcare data sets', 'Experience with PySpark', 'Familiarity with usage of Generative AI for productivity improvement', 'Familiarity with open-source and gated/paid model landscape', 'This position will require up to 15% domestic travel', 'This role needs someone who stays on the cutting edge of artificial intelligence, data science, and advanced analytics research through novel project execution and development of algorithms that influence decisions at various levels in the organization, with main focus on omnichannel sales and marketing optimization, but also including distribution demands, patient/payer analytics, commercial strategy, and related commercially focused model development', 'The role requires both a broad knowledge of existing AI-type algorithms and the ingenuity to invent and customize when necessary', 'Ph.D. with 2+ years of experience, or M.S. with 5+ years, B.S. with 7+ years of relevant pharma experience, with degree in Computer Sciences, Statistics, Machine Learning & Artificial Intelligence, Physics, Molecular Biology, Bioinformatics, Computational Informatics, Medical Informatics, Computational Biology or a related field', 'Solid understanding of machine learning platforms/environments', 'Experience with practical applications of AI-type algorithms, including machine learning techniques such as regression, decision trees, probability networks, association rules, clustering, neural networks, and/or Bayesian models', 'Familiarity with large datasets, handling of healthcare relevant datasets and understanding of data analysis workflows', 'Proficiency with one or more programming language such as Python or R', 'Proficiency with SQL', 'Experience delivering on data science projects using Machine learning and AI technologies, data mining and/or text mining', 'Familiarity with working in a cloud-based technology stack', 'Sophisticated communication skills and ability to translate complex methods and results to diverse audiences', 'Strong ability to establish relationships with business partners and understand their needs', 'Proven track record to deliver end-to-end machine learning projects from understanding business requirements, development, deployment, and management of post-launch operations', 'Experience with vendor management – ensuring timelines and expectations', 'Experience in the Commercial Pharmaceutical business', 'Experience with Medical / Scientific Affairs functions, Evidence generation, Unmet Need identification', 'Experience in digital media and direct-to-consumer marketing', 'Familiarity of commercially available healthcare data sets', 'Experience with PySpark', 'Familiarity with usage of Generative AI for productivity improvement', 'Familiarity with open-source and gated/paid model landscape', 'This position will require up to 15% domestic travel']","['*You will be responsible for:*', 'You will lead and deliver projects and develop solutions that in turn deliver insights', 'You will also work closely with cross departmental teams across business and technology to understand how best to solve complex problems', 'You will be a member of a highly collaborative and supportive team, which is part of a broader dynamic and accomplished organization that supports multiple therapeutic areas and commercial functions', '*You will be responsible for:*', 'You will lead and deliver projects and develop solutions that in turn deliver insights', 'You will also work closely with cross departmental teams across business and technology to understand how best to solve complex problems', 'You will be a member of a highly collaborative and supportive team, which is part of a broader dynamic and accomplished organization that supports multiple therapeutic areas and commercial functions']",True,['Generative AI'],Generative AI: Familiarity with usage for productivity improvement and knowledge of open-source and gated/paid model landscapes relevant to enhancing data science workflows.,"['Machine Learning', 'Data Mining', 'Text Mining', 'Regression Models', 'Decision Trees', 'Probability Networks', 'Association Rules', 'Clustering', 'Neural Networks', 'Bayesian Models', 'SQL', 'Python', 'R', 'PySpark', 'Cloud-based Technology Stack']","Machine Learning: Used for developing algorithms and models such as regression, decision trees, probability networks, association rules, clustering, neural networks, and Bayesian models to influence decisions in omnichannel sales, marketing optimization, distribution demands, patient/payer analytics, and commercial strategy.; Data Mining: Applied to extract useful patterns and insights from large healthcare and commercial datasets to support business value and decision-making.; Text Mining: Utilized for analyzing textual data within healthcare and commercial contexts to derive insights and support data science projects.; Regression Models: Employed as part of machine learning techniques to model relationships in data for predictive analytics in commercial and healthcare applications.; Decision Trees: Used as a machine learning method to support classification and regression tasks within commercial strategy and patient analytics.; Probability Networks: Applied as AI-type algorithms to model probabilistic relationships in data for decision-making processes.; Association Rules: Used to discover interesting relations between variables in large datasets relevant to commercial and healthcare analytics.; Clustering: Implemented to group similar data points for segmentation and pattern recognition in sales, marketing, and patient analytics.; Neural Networks: Applied as part of machine learning techniques to model complex patterns in data for commercial and healthcare insights.; Bayesian Models: Used for probabilistic modeling and inference in healthcare and commercial data science projects.; SQL: Proficiency required for querying and managing large healthcare and commercial datasets to support data analysis workflows.; Python: Used as a primary programming language for developing data science solutions, machine learning models, and data analysis workflows.; R: Utilized as a programming language for statistical analysis and data science project development.; PySpark: Experience preferred for handling large-scale data processing and analytics in cloud-based environments.; Cloud-based Technology Stack: Familiarity required for deploying and managing data science projects and workflows in scalable cloud environments."
0taZ7SRDFhgbfrKTAAAAAA==,Senior Data Scientist,"Senior Data Scientist

Virta Health is pioneering a new standard of care for people to reclaim their lives. We are in the midst of a public health crisis: obesity rates are at an all-time high and over half of US adults have type 2 diabetes or prediabetes, and despite billions spent on new treatments, outcomes are largely worse. Virta reverses these diseases and delivers life-changing results by pairing individualized nutrition with ongoing care from a clinical support team. We have raised over $350 million from top-tier investors, and partner with the largest health plans, employers, and government organizations to help their employees and members restore their health and take back their lives.

Role Overview

The Advanced Analytics & AI (AAA) team is accountable for both pioneering new classes of data that power our business, and ensuring that data is powerful, clear, correct and easy to use throughout the company. The team collaborates closely with the engineering, product development, commercial, and clinical teams to transform data into actionable insights that propel Virta's mission forward.

As a Senior Data Scientist on the AAA team, you will play a crucial role in shaping our data-driven decision making processes and in driving impactful insights that advance our mission. This role offers a unique blend of hands-on coding and strategic leadership, working closely in partnership with the Product Development group that supports adoption of our member-facing products. You will get a chance to work closely with stakeholders to create impactful data-driven reports and analyses that strengthen Virta’s value proposition.

Responsibilities
• Serve as data lead for the Adoption Squad:
• Understand the product – strategy, goals, roadmap, users – deeply enough to identify high-impact, strategic opportunities and risks.
• Use data to steer conversations: bring data-driven hypotheses, challenge assumptions, frame trade-offs, prioritize strategically.
• Translate vague product hunches into sharp analytical questions, and design the right approach to answer them.
• Be the source of truth for KPIs and product metrics: help define and monitor them, and identify trends and drivers.
• Drive decision making with data: Prioritize analyses that meaningfully inform product decisions and change outcomes, reframe analysis requests that won’t do that into ones that will, and design and deliver the resulting analyses properly and rapidly.
• Lead experimentation thoughtfully: guide the team on when and when not to experiment, help enable self-serve experimentation, and focus on frequent, small experiments to speed learning.
• Identify where product strategy and ideas could be better, more easily, or more quickly implemented with the help of AI (ML or GenAI), and help enable this integration.
• Show up as a collaborative leader, not simply a service provider, and help focus work on what matters most.
• Work end-to-end to translate clinical, member, and claims data from our data warehouse into actionable recommendations: work with stakeholders to design reports and dashboards that answer real business questions, design the data flows to support these, and build the required data transformation pipelines.

Must-Haves
• Experience working at a digital health or similar startup, preferably during the growth phase, in order to function effectively in a fast-paced, rapidly changing environment.
• 7+ years of experience in a Healthcare Analytics or Data Science role, working with large datasets and conducting statistical and quantitative modeling, melding analytics with strong programming, data mining, clustering and segmentation.
• 5+ years of work experience working data science and visualization tools (SQL, R, and/or Python)
• Advanced understanding of data storage, ETL frameworks, data transformation, and validation
• Experience in building BI dashboards using tools such as Looker or Tableau
• Ability to explain technology, techniques and approaches to others

Nice-to-Haves
• Experience leading cross-functional efforts to build scalable systems and data pipelines, working with complex data structures
• Understanding of Generative AI concepts and basic usage of GenAI tools (ChatGPT, Claude, etc.)
• Experience building pipelines using dbt
• Demonstrated project management experience

90 Day Plan

Within your first 90 days at Virta, we expect you will do the following:
• Familiarize yourself with the Advanced Analytics & AI team roles and responsibilities. Get a pulse on team structure, key stakeholders, and areas for opportunity with an eye towards scalability and standardization.
• Integrate with the Adoption Squad to understand team dynamics, analyze key product features and data pipelines, and familiarize yourself with the Squad’s product roadmap
• Analyze current member journey to understand Virta’s technology ecosystem
• Meet cross-functional stakeholders to understand how their business needs align with Squad and Team goals
• Identify at least 1 area of opportunity to leverage GenAI to increase team efficiency or improve our processes
• Teach and inspire your team members through knowledge sharing, pair programming, and giving feedback during code reviews

Values-driven culture

Virta’s company values drive our culture, so you’ll do well if:
• You put people first and take care of yourself, your peers, and our patients equally
• You have a strong sense of ownership and take initiative while empowering others to do the same
• You prioritize positive impact over busy work
• You have no ego and understand that everyone has something to bring to the table regardless of experience
• You appreciate transparency and promote trust and empowerment through open access of information
• You are evidence-based and prioritize data and science over seniority or dogma
• You take risks and rapidly iterate

Is this role not quite what you're looking for? Join our Talent Community and follow us on Linkedin to stay connected!

Virta has a location based compensation structure. Starting pay will be based on a number of factors and commensurate with qualifications & experience. For this role, the compensation range is $167,249 - $216,000. Information about Virta’s benefits is on our Careers page at: https://www.virtahealth.com/careers.

As part of your duties at Virta, you may come in contact with sensitive patient information that is governed by HIPAA. Throughout your career at Virta, you will be expected to follow Virta's security and privacy procedures to ensure our patients' information remains strictly confidential. Security and privacy training will be provided.

As a remote-first company, our team is spread across various locations with office hubs in Denver and San Francisco.
Clinical roles: We currently do not hire in the following states: AK, HI, RI
Corporate roles: We currently do not hire in the following states: AK, AR, DE, HI, ME, MS, NM, OK, SD, VT, WI.

#LI-remote",2025-07-19T00:00:00.000Z,2025-07-25,"['Experience working at a digital health or similar startup, preferably during the growth phase, in order to function effectively in a fast-paced, rapidly changing environment', '7+ years of experience in a Healthcare Analytics or Data Science role, working with large datasets and conducting statistical and quantitative modeling, melding analytics with strong programming, data mining, clustering and segmentation', '5+ years of work experience working data science and visualization tools (SQL, R, and/or Python)', 'Advanced understanding of data storage, ETL frameworks, data transformation, and validation', 'Experience in building BI dashboards using tools such as Looker or Tableau', 'Ability to explain technology, techniques and approaches to others', 'Experience leading cross-functional efforts to build scalable systems and data pipelines, working with complex data structures', 'Understanding of Generative AI concepts and basic usage of GenAI tools (ChatGPT, Claude, etc.)', 'Experience building pipelines using dbt', 'Demonstrated project management experience', 'You have a strong sense of ownership and take initiative while empowering others to do the same', 'You prioritize positive impact over busy work', 'You have no ego and understand that everyone has something to bring to the table regardless of experience', 'You appreciate transparency and promote trust and empowerment through open access of information', 'You are evidence-based and prioritize data and science over seniority or dogma', 'You take risks and rapidly iterate']","['As a Senior Data Scientist on the AAA team, you will play a crucial role in shaping our data-driven decision making processes and in driving impactful insights that advance our mission', 'You will get a chance to work closely with stakeholders to create impactful data-driven reports and analyses that strengthen Virta’s value proposition', 'Serve as data lead for the Adoption Squad:', 'Understand the product – strategy, goals, roadmap, users – deeply enough to identify high-impact, strategic opportunities and risks', 'Use data to steer conversations: bring data-driven hypotheses, challenge assumptions, frame trade-offs, prioritize strategically', 'Translate vague product hunches into sharp analytical questions, and design the right approach to answer them', 'Be the source of truth for KPIs and product metrics: help define and monitor them, and identify trends and drivers', 'Drive decision making with data: Prioritize analyses that meaningfully inform product decisions and change outcomes, reframe analysis requests that won’t do that into ones that will, and design and deliver the resulting analyses properly and rapidly', 'Lead experimentation thoughtfully: guide the team on when and when not to experiment, help enable self-serve experimentation, and focus on frequent, small experiments to speed learning', 'Identify where product strategy and ideas could be better, more easily, or more quickly implemented with the help of AI (ML or GenAI), and help enable this integration', 'Show up as a collaborative leader, not simply a service provider, and help focus work on what matters most', 'Work end-to-end to translate clinical, member, and claims data from our data warehouse into actionable recommendations: work with stakeholders to design reports and dashboards that answer real business questions, design the data flows to support these, and build the required data transformation pipelines', 'Familiarize yourself with the Advanced Analytics & AI team roles and responsibilities', 'Get a pulse on team structure, key stakeholders, and areas for opportunity with an eye towards scalability and standardization', 'Integrate with the Adoption Squad to understand team dynamics, analyze key product features and data pipelines, and familiarize yourself with the Squad’s product roadmap', 'Analyze current member journey to understand Virta’s technology ecosystem', 'Meet cross-functional stakeholders to understand how their business needs align with Squad and Team goals', 'Identify at least 1 area of opportunity to leverage GenAI to increase team efficiency or improve our processes', 'Teach and inspire your team members through knowledge sharing, pair programming, and giving feedback during code reviews']",True,['Generative AI'],Generative AI: Understanding and basic usage of generative AI tools like ChatGPT and Claude to identify opportunities for improving team efficiency and integrating AI into product strategy.,"['Statistical and Quantitative Modeling', 'SQL', 'R', 'Python', 'ETL Frameworks', 'Data Transformation and Validation', 'BI Dashboards (Looker, Tableau)', 'Data Pipelines', 'Data-Driven Decision Making', 'Experimentation and A/B Testing', 'Data Mining, Clustering, and Segmentation', 'dbt (Data Build Tool)']","Statistical and Quantitative Modeling: Used to analyze large healthcare datasets and conduct data mining, clustering, and segmentation to derive insights relevant to healthcare analytics.; SQL: Employed for querying and managing data within the data warehouse to support data transformation and analysis.; R: Used as a data science tool for statistical analysis, modeling, and visualization in healthcare analytics.; Python: Utilized for programming, data analysis, and building data transformation pipelines in healthcare analytics.; ETL Frameworks: Applied to extract, transform, and load clinical, member, and claims data from the data warehouse into usable formats for analysis and reporting.; Data Transformation and Validation: Involves designing and building data flows and pipelines to ensure data quality and readiness for analysis and reporting.; BI Dashboards (Looker, Tableau): Used to build interactive dashboards and reports that answer real business questions and monitor KPIs and product metrics.; Data Pipelines: Built and maintained to support scalable systems and complex data structures, enabling end-to-end data processing and actionable recommendations.; Data-Driven Decision Making: Driving product and business decisions by prioritizing analyses that inform outcomes, reframing analysis requests, and delivering rapid, impactful insights.; Experimentation and A/B Testing: Leading and enabling frequent, small experiments to speed learning and guide product strategy through data-driven hypotheses and testing.; Data Mining, Clustering, and Segmentation: Techniques used to analyze healthcare data for identifying patterns, user segments, and strategic opportunities.; dbt (Data Build Tool): Used for building data transformation pipelines to support scalable and maintainable data workflows."
4xzCSCAbsA-A_pxzAAAAAA==,Sr Data Scientist,"Data Science is at the core of our business. Our Data Scientists have dedicated themselves to excellence in applied quantitative disciplines such as mathematics, statistics and physics. We are seeking Senior Data Scientists to join us in our attempt to solve the extremely challenging problem of modeling and predicting the financial markets using sophisticated machine learning techniques. If you are passionate about collaborating with a world-renowned team of Data Scientists, Engineers and Researchers Voloridge could be the home for you.

You will work alongside prominent Data Scientists, Kaggle Grandmasters and a KDD cup winner at an award-winning investment management firm managing over $8B in assets. We reward our employees with an exceptional compensation package that includes wealthy benefit plans and profit-sharing bonuses. Our office in beautiful Jupiter, Florida has water views, fully stocked kitchens with fresh fruit, snacks and salad bars, lounge and gaming areas, onsite massage rooms, free garage parking and more. We seek out only the best of the best talent to join our brilliant, collaborative, and hard-working team and boast a retention rate of 92%.

Job Responsibilities
• Building and evaluating modern numerical/modeling techniques
• Working daily with complex, large-scale datasets
• Collaborative research projects requiring deep thinking, technical skills, and ingenuity
• Keeping abreast of the latest research related to data science

Minimum Requirements
• Deep understanding of modern machine learning techniques and algorithms
• Must demonstrate exceptional aptitude in descriptive and inferential statistics
• Extremely detail-oriented and self-motivated
• Experience with time series data
• Extensive experience working with large data
• Creative thinker and self-learner, able to demonstrate extraordinary critical thinking and analytical skills
• Competent skills in programming languages such as Python, R, C/#/++
• Ability to communicate actionable results with present senior leadership
• Advanced degree in Physics, Statistics, Mathematics or other quantitative disciplines or equivalent experience
• Ability to work onsite in our Jupiter, FL office

Preferred Skills and Previous Experience
• Outstanding achievements such as Math competitions, Kaggle – Grandmaster/Master, exceptional scores on SAT/GRE/LSAT, Chess Grandmaster, etc.
• Experience with relational SQL databases

Compensation and Benefits
• Relocation assistance available for the right candidate
• Highly competitive base salary
• Profit sharing bonus
• Health, dental, vision, life, and disability insurance
• 401K

Licenses Required None required

Additional Information

Voloridge Investment Management is an SEC registered investment advisor. A private investment company founded in 2009, our mission is to deliver superior risk-adjusted returns for qualified investors, using advanced proprietary modeling technology, conservative investment tactics and sophisticated risk management. Our market neutral equities strategy takes both long and short positions in the most actively traded equities, and is designed to capture alpha while limiting exposure to directional markets risks. Our futures strategy takes both long and short positions in the most actively traded global futures and is also built to maximize alpha captured across all futures markets traded while capping exposure to any sector at a given time.

Voloridge Investment Management is an Equal Opportunity Employer. All qualified applicants are encouraged to apply and will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other legally protected characteristic or status.",,2025-07-25,"['Deep understanding of modern machine learning techniques and algorithms', 'Must demonstrate exceptional aptitude in descriptive and inferential statistics', 'Extremely detail-oriented and self-motivated', 'Experience with time series data', 'Extensive experience working with large data', 'Creative thinker and self-learner, able to demonstrate extraordinary critical thinking and analytical skills', 'Competent skills in programming languages such as Python, R, C/#/++', 'Ability to communicate actionable results with present senior leadership', 'Advanced degree in Physics, Statistics, Mathematics or other quantitative disciplines or equivalent experience', 'Ability to work onsite in our Jupiter, FL office', 'Licenses Required None required']","['Building and evaluating modern numerical/modeling techniques', 'Working daily with complex, large-scale datasets', 'Collaborative research projects requiring deep thinking, technical skills, and ingenuity', 'Keeping abreast of the latest research related to data science']",True,[],,"['Machine Learning', 'Descriptive and Inferential Statistics', 'Time Series Data', 'Large-Scale Data Handling', 'Programming Languages', 'Relational SQL Databases']","Machine Learning: The job requires a deep understanding of modern machine learning techniques and algorithms to model and predict financial markets using sophisticated methods.; Descriptive and Inferential Statistics: Exceptional aptitude in descriptive and inferential statistics is necessary to analyze and interpret complex data effectively.; Time Series Data: Experience with time series data is important for modeling and forecasting financial market behaviors over time.; Large-Scale Data Handling: The role involves working daily with complex, large-scale datasets, requiring extensive experience managing and processing big data.; Programming Languages: Competent skills in programming languages such as Python, R, C, C#, and C++ are required to implement data science models and analyses.; Relational SQL Databases: Experience with relational SQL databases is preferred for managing and querying structured data relevant to financial modeling."
BBYOQrTo6n_mgd3XAAAAAA==,"Senior Data Scientist, Specialist Senior - SFL Scientific - Full-time","Senior Data Scientist, Specialist Senior - SFL Scientific

Our Deloitte Strategy & Transactions team helps guide clients through their most critical moments and transformational initiatives. From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability. Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journey-before, during, and after any major transformational projects or transactions.

SFL Scientific, a Deloitte Business, is a U.S. based, data science consulting firm specializing in building industry-specific, artificial intelligence (AI) technologies.

We are hiring a Senior Data Scientist to collaborate directly with clients to design and develop novel projects and solutions. Join a rapidly growing team of professionals working to build a world-class data science practice focused on solving complex and R&D problems.

Recruiting for this role ends on 7/31/2025.

Work You'll Do

As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services. You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions.

Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation. Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills.

+ Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production

+ Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives

+ Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization

+ Validate AI models and algorithm via code reviews, unit, and integration tests

+ Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives

+ Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives

The Team

Our Strategy offering architects bold strategies to achieve business and mission goals, enabling growth, competitive advantage, technology modernization, and continuous digital and AI transformation.

SFL Scientific, a Deloitte Business, is a data science professional services practice focused on strategy, technology, and solving business challenges with Artificial Intelligence (AI). The team has a proven track record serving large, market-leading organizations in the private and public sectors, successfully delivering high-quality, novel and complex projects, and offering deep domain and scientific capabilities. Made up of experienced AI strategists, data scientists, and AI engineers, they serve as trusted advisors to executives, helping them understand and evaluate new and essential areas for AI investment and identify unique opportunities to transform their businesses.

Qualifications:

+ Master's or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)

+ 3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)

+ 3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments

+ 3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow

+ 3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads

+ Live within commuting distance to one of Deloitte's consulting offices

+ Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve

+ Limited immigration sponsorship may be available

Preferred:

+ 2+ years of experience working in a client-facing, consulting environment

+ 2+ years of experience leading project/client engagement teams in the execution of complex AI data science solutions

+ 1+ year of experience with LLM/GenAI use cases and developing RAG solutions, tools, and services (i.e., LangChain, LangGraph, MCP, etc.)

+ 1+ year of experience with AWS Sagemaker or AWS ML Studio

Information for applicants with a need for accommodation: https://www2.deloitte.com/us/en/pages/careers/articles/join-deloitte-assistance-for-disabled-applicants.html

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $107,600 to $198,400.

You may also be eligible to participate in a discretionary annual incentive program, subject to the rules governing the program, whereby an award, if any, depends on various factors, including, without limitation, individual and organizational performance.

#MonitorDeloitte

#DeloitteJobs

#StrategyConsulting

#DeloitteStrategy

#Strategy26

#SFL26

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.

Senior Data Scientist, Specialist Senior - SFL Scientific

Our Deloitte Strategy & Transactions team helps guide clients through their most critical moments and transformational initiatives. From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability. Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journey-before, during, and after any major transformational projects or transactions.

SFL Scientific, a Deloitte Business, is a U.S. based, data science consulting firm specializing in building industry-specific, artificial intelligence (AI) technologies.

We are hiring a Senior Data Scientist to collaborate directly with clients to design and develop novel projects and solutions. Join a rapidly growing team of professionals working to build a world-class data science practice focused on solving complex and R&D problems.

Recruiting for this role ends on 7/31/2025.

Work You'll Do

As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services. You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions.

Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation. Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills.

+ Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production

+ Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives

+ Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization

+ Validate AI models and algorithm via code reviews, unit, and integration tests

+ Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives

+ Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives

The Team

Our Strategy offering architects bold strategies to achieve business and mission goals, enabling growth, competitive advantage, technology modernization, and continuous digital and AI transformation.

SFL Scientific, a Deloitte Business, is a data science professional services practice focused on strategy, technology, and solving business challenges with Artificial Intelligence (AI). The team has a proven track record serving large, market-leading organizations in the private and public sectors, successfully delivering high-quality, novel and complex projects, and offering deep domain and scientific capabilities. Made up of experienced AI strategists, data scientists, and AI engineers, they serve as trusted advisors to executives, helping them understand and evaluate new and essential areas for AI investment and identify unique opportunities to transform their businesses.

Qualifications:

+ Master's or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)

+ 3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)

+ 3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments

+ 3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow

+ 3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads

+ Live within commuting distance to one of Deloitte's consulting offices

+ Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve

+ Limited immigration sponsorship may be available

Preferred:

+ 2+ years of experience working in a client-facing, consulting environment

+ 2+ years of experience leading project/client engagement teams in the execution of complex AI data science solutions

+ 1+ year of experience with LLM/GenAI use cases and developing RAG solutions, tools, and services (i.e., LangChain, LangGraph, MCP, etc.)

+ 1+ year of experience with AWS Sagemaker or AWS ML Studio

Information for applicants with a need for accommodation: https://www2.deloitte.com/us/en/pages/careers/articles/join-deloitte-assistance-for-disabled-applicants.html

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $107,600 to $198,400.

You may also be eligible to participate in a discretionary annual incentive program, subject to the rules governing the program, whereby an award, if any, depends on various factors, including, without limitation, individual and organizational performance.

#MonitorDeloitte

#DeloitteJobs

#StrategyConsulting

#DeloitteStrategy

#Strategy26

#SFL26

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.",2025-07-25T14:00:00.000Z,2025-07-25,"[""Master's or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)"", '3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)', '3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments', '3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow', '3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads', ""Live within commuting distance to one of Deloitte's consulting offices"", 'Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve', 'Limited immigration sponsorship may be available', ""Master's or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)"", '3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)', '3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments', '3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow', '3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads', ""Live within commuting distance to one of Deloitte's consulting offices"", 'Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve', 'Limited immigration sponsorship may be available']","['From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability', 'Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journey-before, during, and after any major transformational projects or transactions', 'As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services', 'You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions', 'Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation', 'Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills', 'Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production', 'Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives', 'Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization', 'Validate AI models and algorithm via code reviews, unit, and integration tests', 'Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives', 'Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives', 'From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability', 'Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journey-before, during, and after any major transformational projects or transactions', 'As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services', 'You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions', 'Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation', 'Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills', 'Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production', 'Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives', 'Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization', 'Validate AI models and algorithm via code reviews, unit, and integration tests', 'Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives', 'Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives']",True,"['Deep Learning', 'PyTorch', 'Generative AI', 'Large Language Models', 'Prompt Engineering', 'AI Model Deployment and MLOps', 'Cloud AI Services']","Deep Learning: The role requires applying deep learning techniques such as convolutional neural networks (CNNs), recurrent neural networks (RNNs), and generative adversarial networks (GANs) across real-world projects, including model tuning and performance validation in production.; PyTorch: PyTorch is used as a core framework for AI/ML algorithm development, particularly for deep learning model training and implementation.; Generative AI: Experience with generative AI use cases, including developing retrieval-augmented generation (RAG) solutions, tools, and services such as LangChain, LangGraph, and MCP, is preferred.; Large Language Models: The job involves working with large language models (LLMs) and generative AI technologies, including fine-tuning and deploying these models for client solutions.; Prompt Engineering: The role includes developing and implementing prompt engineering techniques as part of generative AI and LLM use cases.; AI Model Deployment and MLOps: Deploying and optimizing AI models using Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow, with a focus on managing AI/ML workloads in cloud environments, is a key responsibility.; Cloud AI Services: Experience with cloud AI services such as AWS Sagemaker and AWS ML Studio is preferred for deploying and managing AI/ML workloads.","['Machine Learning', 'Data Analysis', 'Time-Series Analysis', 'Natural Language Processing', 'Computer Vision', 'Model Validation and Testing', 'Model Deployment and Optimization', 'Cloud Computing for AI/ML', 'Data Strategy']","Machine Learning: The role involves developing AI/ML algorithms using core data science languages and frameworks, applying traditional machine learning techniques such as CNNs, RNNs, and GANs, and tuning and validating models in production environments.; Data Analysis: The job requires performing exploratory data analysis on client data sets to understand operational requirements and drive long-term solutions.; Time-Series Analysis: Experience with time-series analysis is required as part of the data analysis and AI/ML algorithm development responsibilities.; Natural Language Processing: The role includes experience with NLP as part of AI/ML algorithm development and data analysis.; Computer Vision: The job involves applying computer vision techniques as part of AI/ML algorithm development and data analysis.; Model Validation and Testing: Responsibilities include validating AI models and algorithms through code reviews, unit tests, and integration tests to ensure model performance and reliability.; Model Deployment and Optimization: The role requires deploying and optimizing machine learning models using tools such as Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow, and leveraging cloud environments like AWS, Azure, or GCP.; Cloud Computing for AI/ML: Experience in leveraging cloud platforms (AWS, Azure, GCP) to deploy AI/ML workloads is essential for delivering scalable solutions.; Data Strategy: The position involves defining data strategy to guide technical development and create next-generation tools, products, and AI services aligned with client needs."
T-qb2uw_Nq1QFMu1AAAAAA==,Senior Data Scientist,"Senior Data Scientist

Virta Health is pioneering a new standard of care for people to reclaim their lives. We are in the midst of a public health crisis: obesity rates are at an all-time high and over half of US adults have type 2 diabetes or prediabetes, and despite billions spent on new treatments, outcomes are largely worse. Virta reverses these diseases and delivers life-changing results by pairing individualized nutrition with ongoing care from a clinical support team. We have raised over $350 million from top-tier investors, and partner with the largest health plans, employers, and government organizations to help their employees and members restore their health and take back their lives.

Role Overview

The Advanced Analytics & AI (AAA) team is accountable for both pioneering new classes of data that power our business, and ensuring that data is powerful, clear, correct and easy to use throughout the company. The team collaborates closely with the engineering, product development, commercial, and clinical teams to transform data into actionable insights that propel Virta's mission forward.

As a Senior Data Scientist on the AAA team, you will play a crucial role in shaping our data-driven decision making processes and in driving impactful insights that advance our mission. This role offers a unique blend of hands-on coding and strategic leadership, working closely in partnership with the Product Development group that supports adoption of our member-facing products. You will get a chance to work closely with stakeholders to create impactful data-driven reports and analyses that strengthen Virta’s value proposition.

Responsibilities
• Serve as data lead for the Adoption Squad:
• Understand the product – strategy, goals, roadmap, users – deeply enough to identify high-impact, strategic opportunities and risks.
• Use data to steer conversations: bring data-driven hypotheses, challenge assumptions, frame trade-offs, prioritize strategically.
• Translate vague product hunches into sharp analytical questions, and design the right approach to answer them.
• Be the source of truth for KPIs and product metrics: help define and monitor them, and identify trends and drivers.
• Drive decision making with data: Prioritize analyses that meaningfully inform product decisions and change outcomes, reframe analysis requests that won’t do that into ones that will, and design and deliver the resulting analyses properly and rapidly.
• Lead experimentation thoughtfully: guide the team on when and when not to experiment, help enable self-serve experimentation, and focus on frequent, small experiments to speed learning.
• Identify where product strategy and ideas could be better, more easily, or more quickly implemented with the help of AI (ML or GenAI), and help enable this integration.
• Show up as a collaborative leader, not simply a service provider, and help focus work on what matters most.
• Work end-to-end to translate clinical, member, and claims data from our data warehouse into actionable recommendations: work with stakeholders to design reports and dashboards that answer real business questions, design the data flows to support these, and build the required data transformation pipelines.

Must-Haves
• Experience working at a digital health or similar startup, preferably during the growth phase, in order to function effectively in a fast-paced, rapidly changing environment.
• 7+ years of experience in a Healthcare Analytics or Data Science role, working with large datasets and conducting statistical and quantitative modeling, melding analytics with strong programming, data mining, clustering and segmentation.
• 5+ years of work experience working data science and visualization tools (SQL, R, and/or Python)
• Advanced understanding of data storage, ETL frameworks, data transformation, and validation
• Experience in building BI dashboards using tools such as Looker or Tableau
• Ability to explain technology, techniques and approaches to others

Nice-to-Haves
• Experience leading cross-functional efforts to build scalable systems and data pipelines, working with complex data structures
• Understanding of Generative AI concepts and basic usage of GenAI tools (ChatGPT, Claude, etc.)
• Experience building pipelines using dbt
• Demonstrated project management experience

90 Day Plan

Within your first 90 days at Virta, we expect you will do the following:
• Familiarize yourself with the Advanced Analytics & AI team roles and responsibilities. Get a pulse on team structure, key stakeholders, and areas for opportunity with an eye towards scalability and standardization.
• Integrate with the Adoption Squad to understand team dynamics, analyze key product features and data pipelines, and familiarize yourself with the Squad’s product roadmap
• Analyze current member journey to understand Virta’s technology ecosystem
• Meet cross-functional stakeholders to understand how their business needs align with Squad and Team goals
• Identify at least 1 area of opportunity to leverage GenAI to increase team efficiency or improve our processes
• Teach and inspire your team members through knowledge sharing, pair programming, and giving feedback during code reviews

Values-driven culture

Virta’s company values drive our culture, so you’ll do well if:
• You put people first and take care of yourself, your peers, and our patients equally
• You have a strong sense of ownership and take initiative while empowering others to do the same
• You prioritize positive impact over busy work
• You have no ego and understand that everyone has something to bring to the table regardless of experience
• You appreciate transparency and promote trust and empowerment through open access of information
• You are evidence-based and prioritize data and science over seniority or dogma
• You take risks and rapidly iterate

Is this role not quite what you're looking for? Join our Talent Community and follow us on Linkedin to stay connected!

Virta has a location based compensation structure. Starting pay will be based on a number of factors and commensurate with qualifications & experience. For this role, the compensation range is $167,249 - $216,000. Information about Virta’s benefits is on our Careers page at: https://www.virtahealth.com/careers.

As part of your duties at Virta, you may come in contact with sensitive patient information that is governed by HIPAA. Throughout your career at Virta, you will be expected to follow Virta's security and privacy procedures to ensure our patients' information remains strictly confidential. Security and privacy training will be provided.

As a remote-first company, our team is spread across various locations with office hubs in Denver and San Francisco.
Clinical roles: We currently do not hire in the following states: AK, HI, RI
Corporate roles: We currently do not hire in the following states: AK, AR, DE, HI, ME, MS, NM, OK, SD, VT, WI.

#LI-remote",2025-07-19T00:00:00.000Z,2025-07-25,"['Experience working at a digital health or similar startup, preferably during the growth phase, in order to function effectively in a fast-paced, rapidly changing environment', '7+ years of experience in a Healthcare Analytics or Data Science role, working with large datasets and conducting statistical and quantitative modeling, melding analytics with strong programming, data mining, clustering and segmentation', '5+ years of work experience working data science and visualization tools (SQL, R, and/or Python)', 'Advanced understanding of data storage, ETL frameworks, data transformation, and validation', 'Experience in building BI dashboards using tools such as Looker or Tableau', 'Ability to explain technology, techniques and approaches to others', 'Experience leading cross-functional efforts to build scalable systems and data pipelines, working with complex data structures', 'Understanding of Generative AI concepts and basic usage of GenAI tools (ChatGPT, Claude, etc.)', 'Experience building pipelines using dbt', 'Demonstrated project management experience', 'You have a strong sense of ownership and take initiative while empowering others to do the same', 'You prioritize positive impact over busy work', 'You have no ego and understand that everyone has something to bring to the table regardless of experience', 'You appreciate transparency and promote trust and empowerment through open access of information', 'You are evidence-based and prioritize data and science over seniority or dogma', 'You take risks and rapidly iterate']","['As a Senior Data Scientist on the AAA team, you will play a crucial role in shaping our data-driven decision making processes and in driving impactful insights that advance our mission', 'You will get a chance to work closely with stakeholders to create impactful data-driven reports and analyses that strengthen Virta’s value proposition', 'Serve as data lead for the Adoption Squad:', 'Understand the product – strategy, goals, roadmap, users – deeply enough to identify high-impact, strategic opportunities and risks', 'Use data to steer conversations: bring data-driven hypotheses, challenge assumptions, frame trade-offs, prioritize strategically', 'Translate vague product hunches into sharp analytical questions, and design the right approach to answer them', 'Be the source of truth for KPIs and product metrics: help define and monitor them, and identify trends and drivers', 'Drive decision making with data: Prioritize analyses that meaningfully inform product decisions and change outcomes, reframe analysis requests that won’t do that into ones that will, and design and deliver the resulting analyses properly and rapidly', 'Lead experimentation thoughtfully: guide the team on when and when not to experiment, help enable self-serve experimentation, and focus on frequent, small experiments to speed learning', 'Identify where product strategy and ideas could be better, more easily, or more quickly implemented with the help of AI (ML or GenAI), and help enable this integration', 'Show up as a collaborative leader, not simply a service provider, and help focus work on what matters most', 'Work end-to-end to translate clinical, member, and claims data from our data warehouse into actionable recommendations: work with stakeholders to design reports and dashboards that answer real business questions, design the data flows to support these, and build the required data transformation pipelines', 'Familiarize yourself with the Advanced Analytics & AI team roles and responsibilities', 'Get a pulse on team structure, key stakeholders, and areas for opportunity with an eye towards scalability and standardization', 'Integrate with the Adoption Squad to understand team dynamics, analyze key product features and data pipelines, and familiarize yourself with the Squad’s product roadmap', 'Analyze current member journey to understand Virta’s technology ecosystem', 'Meet cross-functional stakeholders to understand how their business needs align with Squad and Team goals', 'Identify at least 1 area of opportunity to leverage GenAI to increase team efficiency or improve our processes', 'Teach and inspire your team members through knowledge sharing, pair programming, and giving feedback during code reviews']",True,['Generative AI'],Generative AI: Understanding of generative AI concepts and basic usage of GenAI tools like ChatGPT and Claude to identify opportunities for improving team efficiency and product strategy integration.,"['Statistical and Quantitative Modeling', 'Data Mining', 'Clustering and Segmentation', 'SQL', 'R', 'Python', 'Data Storage and ETL Frameworks', 'Data Transformation and Validation', 'BI Dashboards (Looker, Tableau)', 'Data Pipelines', 'Experimentation and A/B Testing', 'KPI and Product Metrics Definition and Monitoring', 'Data-Driven Reporting and Analysis', 'dbt (Data Build Tool)']","Statistical and Quantitative Modeling: Used to analyze large healthcare datasets to derive insights and support data-driven decision making in a healthcare analytics context.; Data Mining: Applied to extract patterns and segment data for clustering and segmentation tasks relevant to healthcare analytics.; Clustering and Segmentation: Techniques used to group data points for better understanding of member populations and product usage patterns.; SQL: Used as a primary tool for querying and managing data within the company's data warehouse to support analysis and reporting.; R: Utilized for statistical analysis and data science tasks, including modeling and visualization.; Python: Employed for data science programming, including data transformation, analysis, and building data pipelines.; Data Storage and ETL Frameworks: Advanced understanding required to manage data storage, perform data extraction, transformation, and loading to ensure data quality and availability.; Data Transformation and Validation: Critical for preparing clinical, member, and claims data into actionable formats and ensuring data correctness for analysis and reporting.; BI Dashboards (Looker, Tableau): Used to build interactive dashboards and reports that answer real business questions and support product and clinical decision making.; Data Pipelines: Building and maintaining scalable data pipelines to support complex data structures and enable efficient data flow from warehouse to analytics and reporting.; Experimentation and A/B Testing: Leading and enabling self-serve experimentation to validate hypotheses and speed learning through frequent, small experiments.; KPI and Product Metrics Definition and Monitoring: Defining, monitoring, and analyzing key performance indicators and product metrics to identify trends and drivers that inform strategic decisions.; Data-Driven Reporting and Analysis: Creating impactful reports and analyses that strengthen the company's value proposition and inform product decisions.; dbt (Data Build Tool): Experience building data transformation pipelines using dbt to support scalable and maintainable data workflows."
MH0O1Q6IiBqdB79WAAAAAA==,Data Scientist - Sr. Associate,"We have an exciting opportunity for a Data Scientist - Senior Associate to join our Home Lending Data & Analytics team. This role offers the chance to drive meaningful insights that enable the firm to deliver incremental value and an outstanding customer experience. Join us to leverage your analytical skills and business acumen in a dynamic environment that fosters career growth and innovation.

As a Data Scientist - Senior Associate within the Home Lending Data & Analytics team, you will undertake advanced analytics to derive actionable insights supporting our Home Lending Sales strategy and optimization. You will combine quantitative analysis, business acumen, and a focus on problem-solving to drive meaningful insights that enable the firm to drive incremental value and an outstanding customer experience.

Collaborate with Sales, Marketing, Product, Finance, and other Data & Analytics partners to deliver data-driven solutions for complex business challenges. Your work will involve sourcing and integrating data from various platforms to narrate the story of past performance and provide guidance on enhancing Mortgage sales strategy optimization.

Job Responsibilities
• Collaborate with Sales, Marketing, Product, Finance, and other Data & Analytics partners to agree on priorities and deliver data-driven solutions for complex business challenges.
• Source and integrate data from various platforms to narrate the story of past performance and provide guidance on enhancing Mortgage sales strategy optimization.
• Perform descriptive, diagnostic, and predictive analyses to uncover trends, patterns, and actionable business insights.
• Identify opportunities to develop and enhance business intelligence dashboards & automated reporting to facilitate decision-making for business partners.
• Conduct deep-dive analyses to identify and quantify drivers of business performance and recommend actions to improve KPIs.
• Build analytical frameworks to support strategic and complex business priorities.
• Collaborate with team members and business/technical partners on the use of AI & Machine Learning to automate and develop innovative solutions for the HL business.

Required Qualifications, Capabilities, and Skills
• Undergraduate or advanced degree in an analytical field (e.g., Computer Science, Economics, Mathematics, Statistics, Engineering, Operations Research) and 2+ years of experience in data analysis/data science.
• Proficiency using SQL, MS Excel, and Tableau for data manipulation, analysis, and visualization.
• Critical thinking and proven ability to connect data analysis to business strategies and deliver results that drive measurable impact.
• Excellent communication skills to effectively summarize & deliver actionable insights to business stakeholders.
• Strong ability to analyze complex problems, dive deep into data, and design innovative solutions. A relentless curiosity to understand the ""why"" behind data patterns.

Preferred Qualifications, Capabilities, and Skills
• Experience with cloud platforms (e.g., AWS, Snowflake) for large-scale data processing, plus Salesforce for lead management & sales.
• Proficiency in Python coding.
• Background in financial services, plus experience in the Mortgage Business.
• **Relocation assistance is not available for this role.",2025-07-21T00:00:00.000Z,2025-07-25,"['Undergraduate or advanced degree in an analytical field (e.g., Computer Science, Economics, Mathematics, Statistics, Engineering, Operations Research) and 2+ years of experience in data analysis/data science', 'Proficiency using SQL, MS Excel, and Tableau for data manipulation, analysis, and visualization', 'Critical thinking and proven ability to connect data analysis to business strategies and deliver results that drive measurable impact', 'Excellent communication skills to effectively summarize & deliver actionable insights to business stakeholders', 'Strong ability to analyze complex problems, dive deep into data, and design innovative solutions', 'A relentless curiosity to understand the ""why"" behind data patterns']","['As a Data Scientist - Senior Associate within the Home Lending Data & Analytics team, you will undertake advanced analytics to derive actionable insights supporting our Home Lending Sales strategy and optimization', 'You will combine quantitative analysis, business acumen, and a focus on problem-solving to drive meaningful insights that enable the firm to drive incremental value and an outstanding customer experience', 'Collaborate with Sales, Marketing, Product, Finance, and other Data & Analytics partners to deliver data-driven solutions for complex business challenges', 'Your work will involve sourcing and integrating data from various platforms to narrate the story of past performance and provide guidance on enhancing Mortgage sales strategy optimization', 'Collaborate with Sales, Marketing, Product, Finance, and other Data & Analytics partners to agree on priorities and deliver data-driven solutions for complex business challenges', 'Source and integrate data from various platforms to narrate the story of past performance and provide guidance on enhancing Mortgage sales strategy optimization', 'Perform descriptive, diagnostic, and predictive analyses to uncover trends, patterns, and actionable business insights', 'Identify opportunities to develop and enhance business intelligence dashboards & automated reporting to facilitate decision-making for business partners', 'Conduct deep-dive analyses to identify and quantify drivers of business performance and recommend actions to improve KPIs', 'Build analytical frameworks to support strategic and complex business priorities', 'Collaborate with team members and business/technical partners on the use of AI & Machine Learning to automate and develop innovative solutions for the HL business']",True,['Machine Learning'],Machine Learning: Collaborated with team members and business/technical partners to use machine learning for automating and developing innovative solutions in the Home Lending business.,"['Descriptive, Diagnostic, and Predictive Analytics', 'SQL', 'MS Excel', 'Tableau', 'Python', 'Data Integration', 'Business Intelligence Dashboards', 'Advanced Analytics', 'Analytical Frameworks']","Descriptive, Diagnostic, and Predictive Analytics: Used to uncover trends, patterns, and actionable business insights supporting Home Lending Sales strategy and optimization.; SQL: Proficiency required for data manipulation and analysis from various platforms to support business decision-making.; MS Excel: Used for data manipulation and analysis to facilitate business insights and reporting.; Tableau: Used to develop and enhance business intelligence dashboards and automated reporting for decision-making.; Python: Proficiency in coding used to support data analysis and development of innovative solutions in the Mortgage business.; Data Integration: Sourcing and integrating data from various platforms to narrate past performance and guide sales strategy optimization.; Business Intelligence Dashboards: Developed and enhanced to facilitate decision-making for business partners by visualizing key metrics and insights.; Advanced Analytics: Applied to derive actionable insights that drive incremental value and improve customer experience in Home Lending.; Analytical Frameworks: Built to support strategic and complex business priorities within the Home Lending Data & Analytics team."
Md1AP1lvzyB3sM65AAAAAA==,Senior Data Scientist (Machine Learning Engineer),"Climate X is seeking a Senior Data Scientist/Machine Learning Engineer to enhance their NLP model and collaborate with an interdisciplinary team. The role involves developing machine learning models, performing statistical analysis, and visualizing data to support climate adaptation efforts. Candidates should have experience in data science, ML algorithms, and cloud services. The position is fully remote, allowing for contributions to a purpose-driven climate data company.
Senior Data Scientist/Machine Learning Engineer

About Us

Climate X is a purpose-driven climate adaptation data company set to revolutionise how the world manages assets, property, and infrastructure. 

We apply cutting-edge, peer-reviewed science to help prevent the worst impacts of climate change. We combine climate projections, remote sensing observations, and modelling to project the frequency and severity of physical climate risks such as floods, subsidence, storms, etc.

Our SaaS platform lets financial institutions and real estate firms look at future climate pathways to:
• help identify how property/company assets could be damaged by severe weather events and
• what that damage might do to the asset valuations.
• become more resilient to climate change and make smarter investment and lending decisions.

We advocate diversity with our founders, team, and investors from various backgrounds.
We’re not building just a team but a place of innovation where problem solving, and fun coexist to address the most significant challenge our society is facing now. 

The impact you’ll own

As a Senior Data Scientist at Climate X, you will join an interdisciplinary team of other Data Scientists, Climate Scientists and Geospatial experts, collaborating closely with our Engineering and Product teams to deliver impactful products to our clients.

This role will support our NLP model, a core product within the business. This will involve developing an existing code base, research time for exploring new techniques and algorithms, fine-tuning LLM models on domain-specific datasets to enhance the performance of our existing model, perform statistical analysis and techniques for model evaluation, analyse text data to extract meaningful insights and trends and create visualizations to communicate findings and facilitate understanding of the model across the business and our clients.

Essential Skills
• Experience in a product focused Data Science role with previous experience building end-to-end machine learning models.
• Strong experience with ML algorithms and techniques (e.g., regression, classification, clustering), using ML packages in Python (such as sklearn, spaCy, NumPy, SciPy or others).
• Experience with version control systems like Git for managing code changes and collaborating with team members. Knowledge of CI/CD pipelines (e.g. GitHub Actions) is a plus.
• Experience with data visualisation tools and libraries (e.g., Matplotlib, Seaborn, Tableau, Power BI).
• Experience with cloud services (e.g., AWS, Google Cloud Platform, Azure) for data storage and processing.
• Ability to work with cross-functional teams using strong problem-solving skills and share insights to diverse audiences.

Nice to have
• Experience with web scraping using Python (such as BeautifulSoup, Scrapy, Selenium, Requests or others) is a plus.
• Exposure to MLOps frameworks (such as MLFlow, Weights and Biases).
• Knowledge of the financial services or real estate domain from a climate risk perspective, to inform a basic understanding of where data science is being applied, allowing for better context and interpretation of results.
• Experience with processing and analysing geospatial data using Python (geopandas, GDAL, etc.) and/or other GIS software (such as QGIS) is a plus.

Benefits

🌍 Contribute to a business making purposeful impact related to climate change

💡 Monthly training & conference budget to help you upskill and develop your career (£1,000 per year)

📈 6 monthly appraisals and 12 monthly pay reviews

💰 Pension contribution scheme

🏡 Flexible hours and hybrid working (3 days/week in office; core hours 10am-4pm)

🏥 Mental Health and Wellbeing support via Oliva

🏖 25 days holiday, plus Bank Holidays, annual 3-day Christmas-closure, and half day on your birthday (36.5 days total!)

🏏 Optional quarterly socials, dinners, and fun nights out

🥐 A fully stocked supply of snacks, fruit, and refreshments for the days when you are in the office

🚴 Cycle to work scheme via gogeta

🍼 Enhanced maternity and paternity

🐶 Pawternity

🐕 Dog friendly office (official residence of Alfie, Chief Mischief Officer)

Equal Opportunities

Climate X are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. We are committed to creating an inclusive environment for all employees and welcome applications from individuals of all backgrounds.",,2025-07-25,"['Candidates should have experience in data science, ML algorithms, and cloud services', 'Experience in a product focused Data Science role with previous experience building end-to-end machine learning models', 'Strong experience with ML algorithms and techniques (e.g., regression, classification, clustering), using ML packages in Python (such as sklearn, spaCy, NumPy, SciPy or others)', 'Experience with version control systems like Git for managing code changes and collaborating with team members', 'Knowledge of CI/CD pipelines (e.g', 'Experience with data visualisation tools and libraries (e.g., Matplotlib, Seaborn, Tableau, Power BI)', 'Experience with cloud services (e.g., AWS, Google Cloud Platform, Azure) for data storage and processing', 'Ability to work with cross-functional teams using strong problem-solving skills and share insights to diverse audiences', 'Exposure to MLOps frameworks (such as MLFlow, Weights and Biases)', 'Knowledge of the financial services or real estate domain from a climate risk perspective, to inform a basic understanding of where data science is being applied, allowing for better context and interpretation of results']","['The role involves developing machine learning models, performing statistical analysis, and visualizing data to support climate adaptation efforts', 'help identify how property/company assets could be damaged by severe weather events and', 'what that damage might do to the asset valuations', 'become more resilient to climate change and make smarter investment and lending decisions', 'As a Senior Data Scientist at Climate X, you will join an interdisciplinary team of other Data Scientists, Climate Scientists and Geospatial experts, collaborating closely with our Engineering and Product teams to deliver impactful products to our clients', 'This role will support our NLP model, a core product within the business', 'This will involve developing an existing code base, research time for exploring new techniques and algorithms, fine-tuning LLM models on domain-specific datasets to enhance the performance of our existing model, perform statistical analysis and techniques for model evaluation, analyse text data to extract meaningful insights and trends and create visualizations to communicate findings and facilitate understanding of the model across the business and our clients', '🏏 Optional quarterly socials, dinners, and fun nights out']",True,['Large Language Models'],"Large Language Models: Fine-tuning LLMs on domain-specific datasets to enhance the performance of the existing NLP model, which is a core product within the business.","['Machine Learning Algorithms', 'Statistical Analysis', 'NLP Model Development', 'Python ML Packages', 'Data Visualization Tools', 'Cloud Services', 'Version Control and CI/CD', 'MLOps Frameworks', 'Geospatial Data Processing']","Machine Learning Algorithms: The role involves developing machine learning models using algorithms such as regression, classification, and clustering to support climate adaptation efforts and build end-to-end ML models.; Statistical Analysis: Performing statistical analysis and techniques for model evaluation to extract meaningful insights and trends from data.; NLP Model Development: Supporting and enhancing an existing NLP model by analyzing text data to extract insights and improve model performance.; Python ML Packages: Using Python libraries such as scikit-learn, spaCy, NumPy, and SciPy for implementing machine learning algorithms and data processing.; Data Visualization Tools: Creating visualizations to communicate findings and facilitate understanding of models using tools like Matplotlib, Seaborn, Tableau, and Power BI.; Cloud Services: Utilizing cloud platforms such as AWS, Google Cloud Platform, and Azure for data storage and processing.; Version Control and CI/CD: Managing code changes and collaboration using Git and knowledge of CI/CD pipelines like GitHub Actions.; MLOps Frameworks: Exposure to MLOps tools such as MLFlow and Weights and Biases to support machine learning lifecycle management.; Geospatial Data Processing: Processing and analyzing geospatial data using Python libraries like geopandas and GDAL, and GIS software such as QGIS."
6ykd2WNVjOHLQ40DAAAAAA==,Senior Data Scientist,"Senior Data Scientist

Virta Health is pioneering a new standard of care for people to reclaim their lives. We are in the midst of a public health crisis: obesity rates are at an all-time high and over half of US adults have type 2 diabetes or prediabetes, and despite billions spent on new treatments, outcomes are largely worse. Virta reverses these diseases and delivers life-changing results by pairing individualized nutrition with ongoing care from a clinical support team. We have raised over $350 million from top-tier investors, and partner with the largest health plans, employers, and government organizations to help their employees and members restore their health and take back their lives.

Role Overview

The Advanced Analytics & AI (AAA) team is accountable for both pioneering new classes of data that power our business, and ensuring that data is powerful, clear, correct and easy to use throughout the company. The team collaborates closely with the engineering, product development, commercial, and clinical teams to transform data into actionable insights that propel Virta's mission forward.

As a Senior Data Scientist on the AAA team, you will play a crucial role in shaping our data-driven decision making processes and in driving impactful insights that advance our mission. This role offers a unique blend of hands-on coding and strategic leadership, working closely in partnership with the Product Development group that supports adoption of our member-facing products. You will get a chance to work closely with stakeholders to create impactful data-driven reports and analyses that strengthen Virta’s value proposition.

Responsibilities
• Serve as data lead for the Adoption Squad:
• Understand the product – strategy, goals, roadmap, users – deeply enough to identify high-impact, strategic opportunities and risks.
• Use data to steer conversations: bring data-driven hypotheses, challenge assumptions, frame trade-offs, prioritize strategically.
• Translate vague product hunches into sharp analytical questions, and design the right approach to answer them.
• Be the source of truth for KPIs and product metrics: help define and monitor them, and identify trends and drivers.
• Drive decision making with data: Prioritize analyses that meaningfully inform product decisions and change outcomes, reframe analysis requests that won’t do that into ones that will, and design and deliver the resulting analyses properly and rapidly.
• Lead experimentation thoughtfully: guide the team on when and when not to experiment, help enable self-serve experimentation, and focus on frequent, small experiments to speed learning.
• Identify where product strategy and ideas could be better, more easily, or more quickly implemented with the help of AI (ML or GenAI), and help enable this integration.
• Show up as a collaborative leader, not simply a service provider, and help focus work on what matters most.
• Work end-to-end to translate clinical, member, and claims data from our data warehouse into actionable recommendations: work with stakeholders to design reports and dashboards that answer real business questions, design the data flows to support these, and build the required data transformation pipelines.

Must-Haves
• Experience working at a digital health or similar startup, preferably during the growth phase, in order to function effectively in a fast-paced, rapidly changing environment.
• 7+ years of experience in a Healthcare Analytics or Data Science role, working with large datasets and conducting statistical and quantitative modeling, melding analytics with strong programming, data mining, clustering and segmentation.
• 5+ years of work experience working data science and visualization tools (SQL, R, and/or Python)
• Advanced understanding of data storage, ETL frameworks, data transformation, and validation
• Experience in building BI dashboards using tools such as Looker or Tableau
• Ability to explain technology, techniques and approaches to others

Nice-to-Haves
• Experience leading cross-functional efforts to build scalable systems and data pipelines, working with complex data structures
• Understanding of Generative AI concepts and basic usage of GenAI tools (ChatGPT, Claude, etc.)
• Experience building pipelines using dbt
• Demonstrated project management experience

90 Day Plan

Within your first 90 days at Virta, we expect you will do the following:
• Familiarize yourself with the Advanced Analytics & AI team roles and responsibilities. Get a pulse on team structure, key stakeholders, and areas for opportunity with an eye towards scalability and standardization.
• Integrate with the Adoption Squad to understand team dynamics, analyze key product features and data pipelines, and familiarize yourself with the Squad’s product roadmap
• Analyze current member journey to understand Virta’s technology ecosystem
• Meet cross-functional stakeholders to understand how their business needs align with Squad and Team goals
• Identify at least 1 area of opportunity to leverage GenAI to increase team efficiency or improve our processes
• Teach and inspire your team members through knowledge sharing, pair programming, and giving feedback during code reviews

Values-driven culture

Virta’s company values drive our culture, so you’ll do well if:
• You put people first and take care of yourself, your peers, and our patients equally
• You have a strong sense of ownership and take initiative while empowering others to do the same
• You prioritize positive impact over busy work
• You have no ego and understand that everyone has something to bring to the table regardless of experience
• You appreciate transparency and promote trust and empowerment through open access of information
• You are evidence-based and prioritize data and science over seniority or dogma
• You take risks and rapidly iterate

Is this role not quite what you're looking for? Join our Talent Community and follow us on Linkedin to stay connected!

Virta has a location based compensation structure. Starting pay will be based on a number of factors and commensurate with qualifications & experience. For this role, the compensation range is $167,249 - $216,000. Information about Virta’s benefits is on our Careers page at: https://www.virtahealth.com/careers.

As part of your duties at Virta, you may come in contact with sensitive patient information that is governed by HIPAA. Throughout your career at Virta, you will be expected to follow Virta's security and privacy procedures to ensure our patients' information remains strictly confidential. Security and privacy training will be provided.

As a remote-first company, our team is spread across various locations with office hubs in Denver and San Francisco.
Clinical roles: We currently do not hire in the following states: AK, HI, RI
Corporate roles: We currently do not hire in the following states: AK, AR, DE, HI, ME, MS, NM, OK, SD, VT, WI.

#LI-remote",2025-07-19T00:00:00.000Z,2025-07-25,"['Experience working at a digital health or similar startup, preferably during the growth phase, in order to function effectively in a fast-paced, rapidly changing environment', '7+ years of experience in a Healthcare Analytics or Data Science role, working with large datasets and conducting statistical and quantitative modeling, melding analytics with strong programming, data mining, clustering and segmentation', '5+ years of work experience working data science and visualization tools (SQL, R, and/or Python)', 'Advanced understanding of data storage, ETL frameworks, data transformation, and validation', 'Experience in building BI dashboards using tools such as Looker or Tableau', 'Ability to explain technology, techniques and approaches to others', 'Experience leading cross-functional efforts to build scalable systems and data pipelines, working with complex data structures', 'Understanding of Generative AI concepts and basic usage of GenAI tools (ChatGPT, Claude, etc.)', 'Experience building pipelines using dbt', 'Demonstrated project management experience', 'You have a strong sense of ownership and take initiative while empowering others to do the same', 'You prioritize positive impact over busy work', 'You have no ego and understand that everyone has something to bring to the table regardless of experience', 'You appreciate transparency and promote trust and empowerment through open access of information', 'You are evidence-based and prioritize data and science over seniority or dogma', 'You take risks and rapidly iterate']","['As a Senior Data Scientist on the AAA team, you will play a crucial role in shaping our data-driven decision making processes and in driving impactful insights that advance our mission', 'You will get a chance to work closely with stakeholders to create impactful data-driven reports and analyses that strengthen Virta’s value proposition', 'Serve as data lead for the Adoption Squad:', 'Understand the product – strategy, goals, roadmap, users – deeply enough to identify high-impact, strategic opportunities and risks', 'Use data to steer conversations: bring data-driven hypotheses, challenge assumptions, frame trade-offs, prioritize strategically', 'Translate vague product hunches into sharp analytical questions, and design the right approach to answer them', 'Be the source of truth for KPIs and product metrics: help define and monitor them, and identify trends and drivers', 'Drive decision making with data: Prioritize analyses that meaningfully inform product decisions and change outcomes, reframe analysis requests that won’t do that into ones that will, and design and deliver the resulting analyses properly and rapidly', 'Lead experimentation thoughtfully: guide the team on when and when not to experiment, help enable self-serve experimentation, and focus on frequent, small experiments to speed learning', 'Identify where product strategy and ideas could be better, more easily, or more quickly implemented with the help of AI (ML or GenAI), and help enable this integration', 'Show up as a collaborative leader, not simply a service provider, and help focus work on what matters most', 'Work end-to-end to translate clinical, member, and claims data from our data warehouse into actionable recommendations: work with stakeholders to design reports and dashboards that answer real business questions, design the data flows to support these, and build the required data transformation pipelines', 'Familiarize yourself with the Advanced Analytics & AI team roles and responsibilities', 'Get a pulse on team structure, key stakeholders, and areas for opportunity with an eye towards scalability and standardization', 'Integrate with the Adoption Squad to understand team dynamics, analyze key product features and data pipelines, and familiarize yourself with the Squad’s product roadmap', 'Analyze current member journey to understand Virta’s technology ecosystem', 'Meet cross-functional stakeholders to understand how their business needs align with Squad and Team goals', 'Identify at least 1 area of opportunity to leverage GenAI to increase team efficiency or improve our processes', 'Teach and inspire your team members through knowledge sharing, pair programming, and giving feedback during code reviews']",True,['Generative AI'],"Generative AI: Identified opportunities to integrate generative AI technologies to improve team efficiency and product strategy, including basic usage of tools like ChatGPT and Claude.","['Statistical and Quantitative Modeling', 'Data Mining, Clustering, and Segmentation', 'SQL', 'R and Python', 'ETL Frameworks and Data Transformation', 'Data Validation', 'BI Dashboards (Looker, Tableau)', 'Data Pipelines', 'Experimentation and A/B Testing', 'dbt (Data Build Tool)']","Statistical and Quantitative Modeling: Used to analyze large healthcare datasets and conduct data-driven analyses to support decision making and identify trends and drivers.; Data Mining, Clustering, and Segmentation: Applied to extract meaningful patterns and groupings from complex healthcare data to inform product strategy and improve outcomes.; SQL: Utilized for querying and managing data within the data warehouse to support data transformation and reporting.; R and Python: Used as primary programming languages for data science tasks including analysis, modeling, and visualization.; ETL Frameworks and Data Transformation: Involved in designing and building data pipelines and workflows to transform raw clinical, member, and claims data into actionable insights.; Data Validation: Ensures data quality and correctness throughout the data processing and analysis lifecycle.; BI Dashboards (Looker, Tableau): Built and maintained dashboards to visualize KPIs and product metrics, enabling stakeholders to monitor trends and make informed decisions.; Data Pipelines: Developed scalable and complex data pipelines to support data flows and reporting needs across teams.; Experimentation and A/B Testing: Led and guided experimentation efforts to validate hypotheses and accelerate learning through frequent, small experiments.; dbt (Data Build Tool): Used for building and managing data transformation pipelines to ensure scalable and maintainable data workflows."
VZCsO5p6akLRIVwMAAAAAA==,Data Scientist / Machine Learning Engineer/LLM,"Job Title: Data Scientist / Machine Learning Engineer/LLM

Location: Reston, VA (Remote)

Duration: Long term

Job Type : FTE/W2 (Any Visa)

Key Responsibilities:
• Develop and deploy machine learning models using LLMs, NLP, and General AI techniques.
• Utilize Langchain / llamaindex for advanced language processing tasks.
• Implement solutions using Python, Vector DBs, and data analysis tools such as Jupyter Notebook, AWS SageMaker, and Scikit-learn.
• Containerize applications using Docker and manage dependencies with Anaconda/conda/venv or other Python package managers.
• Work with cloud platforms like AWS, Azure, and Google Cloud Platform to scale and deploy AI solutions.
• Perform fine-tuning of models and work with LoRa, PEFT, RAG, and Agentic Frameworks.
• Experience with ML frameworks such as TensorFlow, PyTorch, or similar.
• Collaborate with the MLOps team to ensure smooth deployment and maintenance of models.
• Engage in Multi-Modality research and development to enhance model performance.

Qualifications:
• Proven experience in machine learning, NLP, and AI, Gen AI, LLM.
• Strong programming skills in Python and familiarity with Vector DBs.
• Experience with Jupyter Notebook, AWS SageMaker, Scikit-learn, and Docker.
• Knowledge of cloud services (AWS/Azure/Google Cloud Platform) and model fine-tuning.
• Familiarity with Linux, data streaming tools, MLOps, and multi-modality in AI.
• Excellent problem-solving skills and the ability to work in a fast-paced environment.

Note: Interested Candidates share me the profile to",,2025-07-25,"['Proven experience in machine learning, NLP, and AI, Gen AI, LLM', 'Strong programming skills in Python and familiarity with Vector DBs', 'Experience with Jupyter Notebook, AWS SageMaker, Scikit-learn, and Docker', 'Knowledge of cloud services (AWS/Azure/Google Cloud Platform) and model fine-tuning', 'Familiarity with Linux, data streaming tools, MLOps, and multi-modality in AI', 'Excellent problem-solving skills and the ability to work in a fast-paced environment']","['Develop and deploy machine learning models using LLMs, NLP, and General AI techniques', 'Utilize Langchain / llamaindex for advanced language processing tasks', 'Implement solutions using Python, Vector DBs, and data analysis tools such as Jupyter Notebook, AWS SageMaker, and Scikit-learn', 'Containerize applications using Docker and manage dependencies with Anaconda/conda/venv or other Python package managers', 'Work with cloud platforms like AWS, Azure, and Google Cloud Platform to scale and deploy AI solutions', 'Perform fine-tuning of models and work with LoRa, PEFT, RAG, and Agentic Frameworks', 'Experience with ML frameworks such as TensorFlow, PyTorch, or similar', 'Collaborate with the MLOps team to ensure smooth deployment and maintenance of models', 'Engage in Multi-Modality research and development to enhance model performance']",True,"['Large Language Models', 'Natural Language Processing', 'Generative AI', 'LangChain', 'LlamaIndex', 'Retrieval-Augmented Generation', 'Low-Rank Adaptation', 'Parameter-Efficient Fine-Tuning', 'Agentic Frameworks', 'Multi-Modality', 'PyTorch', 'TensorFlow']",Large Language Models: Develop and deploy models based on large language models (LLMs) for natural language processing and general AI tasks.; Natural Language Processing: Utilize NLP techniques specifically in the context of AI and LLMs to process and analyze language data.; Generative AI: Apply generative AI techniques to create or enhance AI-driven language and multimodal applications.; LangChain: Use LangChain framework for building applications that integrate LLMs with external data sources and workflows.; LlamaIndex: Employ LlamaIndex for advanced indexing and retrieval in language model applications.; Retrieval-Augmented Generation: Implement RAG techniques to enhance language model outputs by integrating external knowledge retrieval.; Low-Rank Adaptation: Use LoRa methods for efficient fine-tuning of large language models.; Parameter-Efficient Fine-Tuning: Apply PEFT techniques to fine-tune models with reduced computational resources.; Agentic Frameworks: Work with agentic frameworks to build autonomous AI agents capable of complex decision-making.; Multi-Modality: Engage in research and development involving multiple data modalities to improve AI model performance.; PyTorch: Use PyTorch deep learning framework specifically for neural network and AI model development.; TensorFlow: Utilize TensorFlow deep learning framework for building and training neural network models.,"['Machine Learning', 'Python', 'Vector Databases', 'Jupyter Notebook', 'AWS SageMaker', 'Scikit-learn', 'Docker', 'Cloud Platforms', 'Model Fine-Tuning', 'ML Frameworks', 'Data Streaming Tools', 'Linux']","Machine Learning: Develop and deploy machine learning models using various techniques; collaborate with MLOps teams to ensure smooth deployment and maintenance of models.; Python: Use Python programming language for implementing solutions, managing dependencies with package managers like Anaconda/conda/venv, and working with data analysis tools.; Vector Databases: Utilize vector databases to support advanced language processing and data retrieval tasks.; Jupyter Notebook: Employ Jupyter Notebook as a data analysis and experimentation environment.; AWS SageMaker: Use AWS SageMaker for building, training, and deploying machine learning models at scale.; Scikit-learn: Apply Scikit-learn for traditional machine learning model development and evaluation.; Docker: Containerize applications to ensure consistent deployment environments.; Cloud Platforms: Leverage cloud platforms such as AWS, Azure, and Google Cloud Platform to scale and deploy AI and machine learning solutions.; Model Fine-Tuning: Perform fine-tuning of machine learning models to improve performance and adapt to specific tasks.; ML Frameworks: Use machine learning frameworks such as TensorFlow and PyTorch for model development and experimentation.; Data Streaming Tools: Familiarity with data streaming tools to handle real-time data processing.; Linux: Work within Linux environments for development and deployment tasks."
8tPDaK1LJ_F71gsvAAAAAA==,"Senior Data Scientist, Materials Science & Chemistry","CAS uses intuitive technology, unparalleled scientific content and unmatched human expertise to help companies create groundbreaking innovations that benefit the world. As the scientific information solutions division of the American Chemical Society, CAS manages the largest curated reservoir of scientific knowledge, and for 118 years, has helped innovators mine, assess and apply that information to keep businesses thriving. The CAS team is global, diverse, endlessly curious and strives to make scientific insights accessible to innovators worldwide.

CAS is currently seeking a Senior Data Scientist specializing in Materials Science & Chemistry applications. This position will be located in our headquarters in Columbus, Ohio.

This role requires a highly self-directed professional who can independently drive complex data science initiatives in materials science and chemistry domains. The successful candidate will provide strategic input into project ideation and implementation, manage multiple high-priority initiatives simultaneously, and demonstrate exceptional ability to translate advanced analytics into tangible business value with minimal oversight.

Key Accountabilities:

Strategic Project Leadership
• Independently conceptualize, design, and execute complex analytical projects in materials science and chemistry applications
• Provide leadership in cross-functional project teams and provide technical direction to junior data scientists
• Drive project ideation and strategic planning, translating business challenges into innovative data science solutions
• Manage multiple high-priority projects simultaneously while maintaining exceptional quality standards

Technical Excellence in Materials Science & Chemistry
• Apply advanced AI/ML techniques to solve complex problems in materials discovery, chemical reaction prediction, molecular design, and other related areas
• Synthesize and analyze chemical and materials data from diverse sources
• Solve unusual problems using a combination of appropriate statistics, machine learning, and computational methods
• Critically evaluate chemical and materials datasets for quality, completeness, and scientific validity using domain expertise

Business Impact & Communication
• Independently synthesize analytical findings and present strategic recommendations to senior executives and C-level stakeholders
• Influence organizational decision-making through compelling data-driven narratives and visualizations
• Lead client presentations and serve as the primary technical liaison for materials science and chemistry projects
• Drive organizational thought leadership through publications, conference presentations, and industry engagement

Organizational Leadership
• Serve as a technical mentor and knowledge leader within the data science team
• Influence and lead initiatives across the organization as part of our shared services model
• Establish and maintain strategic relationships with internal partners and external clients
• Champion best practices in data science methodologies and materials science applications

Qualifications:

Required:
• Master's Degree in Chemistry, Materials Science, Chemical Engineering, or related scientific field with 5-7 years of data science experience, OR Bachelor's degree with 10+ years of combined experience in chemistry/materials science and data science
• Advanced proficiency in modern data science tools and platforms (for example- SQL, Python, R, Spark, graph databases, cloud platforms)
• Proven track record of independently delivering high-impact AI/ML solutions that drive significant business results
• Deep knowledge of chemistry and materials science principles, nomenclature, and research methodologies
• Demonstrated ability to work with chemical databases, molecular representations, and materials property data
• Exceptional presentation and communication skills with proven ability to influence senior stakeholders and lead cross-functional teams
• Strong project management capabilities with experience managing multiple complex initiatives simultaneously

Preferred:
• PhD in Chemistry, Materials Science, Chemical Engineering, or related field
• Experience with cheminformatics tools and molecular modeling software
• Knowledge of materials characterization techniques and experimental design
• Experience in materials development or chemical manufacturing industries
• Track record of publications in peer-reviewed journals combining data science and chemistry/materials science
• Consulting or client-facing experience in chemical or materials sectors

CAS offers a competitive salary and comprehensive benefits package, including a generous vacation plan, medical, dental, vision insurance plans, and employee savings and retirement plans. Candidates for this position must be authorized to work in the United States and not require work authorization sponsorship by our company for this position now or in the future. EEO/Disabled/Veteran

Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities

This employer is required to notify all applicants of their rights pursuant to federal employment laws. For further information, please review the Know Your Rights notice from the Department of Labor.",2025-07-15T00:00:00.000Z,2025-07-25,"['This role requires a highly self-directed professional who can independently drive complex data science initiatives in materials science and chemistry domains', 'Critically evaluate chemical and materials datasets for quality, completeness, and scientific validity using domain expertise', ""Master's Degree in Chemistry, Materials Science, Chemical Engineering, or related scientific field with 5-7 years of data science experience, OR Bachelor's degree with 10+ years of combined experience in chemistry/materials science and data science"", 'Advanced proficiency in modern data science tools and platforms (for example- SQL, Python, R, Spark, graph databases, cloud platforms)', 'Proven track record of independently delivering high-impact AI/ML solutions that drive significant business results', 'Deep knowledge of chemistry and materials science principles, nomenclature, and research methodologies', 'Demonstrated ability to work with chemical databases, molecular representations, and materials property data', 'Exceptional presentation and communication skills with proven ability to influence senior stakeholders and lead cross-functional teams', 'Strong project management capabilities with experience managing multiple complex initiatives simultaneously']","['The successful candidate will provide strategic input into project ideation and implementation, manage multiple high-priority initiatives simultaneously, and demonstrate exceptional ability to translate advanced analytics into tangible business value with minimal oversight', 'Independently conceptualize, design, and execute complex analytical projects in materials science and chemistry applications', 'Provide leadership in cross-functional project teams and provide technical direction to junior data scientists', 'Drive project ideation and strategic planning, translating business challenges into innovative data science solutions', 'Manage multiple high-priority projects simultaneously while maintaining exceptional quality standards', 'Technical Excellence in Materials Science & Chemistry', 'Apply advanced AI/ML techniques to solve complex problems in materials discovery, chemical reaction prediction, molecular design, and other related areas', 'Synthesize and analyze chemical and materials data from diverse sources', 'Solve unusual problems using a combination of appropriate statistics, machine learning, and computational methods', 'Business Impact & Communication', 'Independently synthesize analytical findings and present strategic recommendations to senior executives and C-level stakeholders', 'Influence organizational decision-making through compelling data-driven narratives and visualizations', 'Lead client presentations and serve as the primary technical liaison for materials science and chemistry projects', 'Drive organizational thought leadership through publications, conference presentations, and industry engagement', 'Organizational Leadership', 'Serve as a technical mentor and knowledge leader within the data science team', 'Influence and lead initiatives across the organization as part of our shared services model', 'Establish and maintain strategic relationships with internal partners and external clients', 'Champion best practices in data science methodologies and materials science applications']",True,['Artificial Intelligence and Machine Learning'],"Artificial Intelligence and Machine Learning: Delivering high-impact AI/ML solutions independently that drive significant business results in materials science and chemistry domains, including advanced AI/ML techniques applied to materials discovery and molecular design.","['Advanced AI/ML Techniques', 'Statistical and Computational Methods', 'Chemical and Materials Data Analysis', 'Data Science Tools and Platforms', 'Project Management in Data Science', 'Data-Driven Communication and Visualization', 'Leadership in Data Science Teams', 'Chemical Databases and Molecular Representations']","Advanced AI/ML Techniques: Used to solve complex problems in materials discovery, chemical reaction prediction, molecular design, and related areas within materials science and chemistry.; Statistical and Computational Methods: Applied to solve unusual problems by combining appropriate statistics, machine learning, and computational approaches in materials science and chemistry data analysis.; Chemical and Materials Data Analysis: Involves synthesizing and analyzing chemical and materials data from diverse sources, critically evaluating datasets for quality, completeness, and scientific validity using domain expertise.; Data Science Tools and Platforms: Includes advanced proficiency in SQL, Python, R, Spark, graph databases, and cloud platforms to support data science initiatives in materials science and chemistry.; Project Management in Data Science: Managing multiple high-priority, complex analytical projects simultaneously while maintaining exceptional quality standards and providing strategic input into project ideation and implementation.; Data-Driven Communication and Visualization: Synthesizing analytical findings and presenting strategic recommendations to senior executives and stakeholders through compelling data-driven narratives and visualizations.; Leadership in Data Science Teams: Providing technical direction to junior data scientists, serving as a technical mentor, and leading cross-functional project teams in materials science and chemistry applications.; Chemical Databases and Molecular Representations: Working with chemical databases and molecular representations to support data science projects in materials science and chemistry."
uFzkLiUklwC3z9PoAAAAAA==,"Senior Data Scientist, Client Analysis","Why Socure?

At Socure, we’re on a mission—to verify 100% of good identities in real time and eliminate identity fraud from the internet.

Using predictive analytics and advanced machine learning trained on billions of signals to power RiskOS, Socure has created the most accurate identity verification and fraud prevention platform in the world. Trusted by thousands of leading organizations—from top banks and fintechs to government agencies—we solve real, high-impact problems at scale. Come join us!

About The Role

As a Senior Data Scientist, Client Analysis, you’ll play a critical role in driving Socure’s growth by partnering closely with our go-to-market (GTM) teams to demonstrate the impact of our solutions. You’ll analyze massive datasets, develop compelling data stories, and build tools that help potential and existing customers understand the full value of our identity verification and fraud prevention platform.

This is a high-visibility, high-impact role ideal for a data scientist who thrives at the intersection of data and business. You’ll bring technical excellence, storytelling ability, and a customer-centric mindset to influence key decisions and directly contribute to revenue generation. Data Scientists on the Client Analysis team are rewarded with a generous incentive bonus in addition to a competitive base salary.

What You’ll Do
• Analyze customer datasets to generate actionable insights that inform optimal risk management policies.
• Clearly articulate model performance and outcomes to both technical and non-technical stakeholders.
• Act as a data science advocate by deeply understanding Socure’s solutions and aligning them with customer needs.
• Craft compelling data narratives that demonstrate Socure’s ability to reduce identity fraud and enhance customer experience.
• Represent the customer’s voice in the development of next-generation models and products.
• Develop tools and automated workflows that increase the speed, accuracy, and reproducibility of client-facing analyses.
• Collaborate cross-functionally with Sales, Solution Consultants, Account Managers, and Technical Program Managers to identify new analysis opportunities and support upsell efforts.
• Build machine learning models when exploring alternative approaches adds value beyond existing production models.

What You’ll Bring
• 5+ years of experience in data science, data analysis, or analytics engineering.
• Advanced degree in a quantitative field or equivalent industry experience.
• Expertise in supervised and unsupervised machine learning methods, both theoretically and practically.
• Strong programming skills in Python and PySpark; experienced working with large-scale, real-world datasets.
• Proficient in SQL and comfortable querying relational databases.
• Experience with cloud-based tools and technologies (AWS, Azure, GCP, Databricks).
• Skilled at data visualization and storytelling through dashboards, presentations, and interactive formats.
• Exceptional communication skills with the ability to explain complex models and analyses to non-technical audiences.
• Self-motivated, goal-oriented, and effective in a fast-paced remote startup environment.
• Experience in identity verification and fraud prevention strongly preferred.

Tools We Use

We don’t expect you to know them all—but familiarity with some and a desire to learn others is important.
• Python ecosystem: PySpark, Pandas, NumPy, H2O, SHAP, Seaborn, Jupyter
• Databricks
• Airflow
• Redshift, Snowflake, S3
• Apache Spark, Apache Arrow
• Amazon EMR
• Looker, Tableau

Socure is an equal opportunity employer and values diversity of all kinds at our company. We do not discriminate based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

Follow Us!

YouTube | LinkedIn | X (Twitter) | Facebook

Compensation Range: $160K - $175K",2025-07-20T00:00:00.000Z,2025-07-25,"['5+ years of experience in data science, data analysis, or analytics engineering', 'Advanced degree in a quantitative field or equivalent industry experience', 'Expertise in supervised and unsupervised machine learning methods, both theoretically and practically', 'Strong programming skills in Python and PySpark; experienced working with large-scale, real-world datasets', 'Proficient in SQL and comfortable querying relational databases', 'Experience with cloud-based tools and technologies (AWS, Azure, GCP, Databricks)', 'Skilled at data visualization and storytelling through dashboards, presentations, and interactive formats', 'Exceptional communication skills with the ability to explain complex models and analyses to non-technical audiences', 'Self-motivated, goal-oriented, and effective in a fast-paced remote startup environment', 'We don’t expect you to know them all—but familiarity with some and a desire to learn others is important', 'Python ecosystem: PySpark, Pandas, NumPy, H2O, SHAP, Seaborn, Jupyter']","['As a Senior Data Scientist, Client Analysis, you’ll play a critical role in driving Socure’s growth by partnering closely with our go-to-market (GTM) teams to demonstrate the impact of our solutions', 'You’ll analyze massive datasets, develop compelling data stories, and build tools that help potential and existing customers understand the full value of our identity verification and fraud prevention platform', 'This is a high-visibility, high-impact role ideal for a data scientist who thrives at the intersection of data and business', 'You’ll bring technical excellence, storytelling ability, and a customer-centric mindset to influence key decisions and directly contribute to revenue generation', 'Analyze customer datasets to generate actionable insights that inform optimal risk management policies', 'Clearly articulate model performance and outcomes to both technical and non-technical stakeholders', 'Act as a data science advocate by deeply understanding Socure’s solutions and aligning them with customer needs', 'Craft compelling data narratives that demonstrate Socure’s ability to reduce identity fraud and enhance customer experience', 'Represent the customer’s voice in the development of next-generation models and products', 'Develop tools and automated workflows that increase the speed, accuracy, and reproducibility of client-facing analyses', 'Collaborate cross-functionally with Sales, Solution Consultants, Account Managers, and Technical Program Managers to identify new analysis opportunities and support upsell efforts', 'Build machine learning models when exploring alternative approaches adds value beyond existing production models']",True,[],,"['Supervised and Unsupervised Machine Learning', 'Python Ecosystem', 'SQL', 'Cloud-Based Tools and Technologies', 'Data Visualization and Storytelling', 'Data Analysis and Insight Generation', 'Automated Workflows and Tool Development', 'BI Tools and Dashboards', 'Big Data Technologies']","Supervised and Unsupervised Machine Learning: Expertise in both supervised and unsupervised machine learning methods is required to develop models that improve identity verification and fraud prevention solutions.; Python Ecosystem: Strong programming skills in Python and PySpark are essential for working with large-scale datasets and building data science tools; familiarity with libraries such as Pandas, NumPy, H2O, SHAP, Seaborn, and Jupyter is important for data manipulation, modeling, explainability, visualization, and interactive analysis.; SQL: Proficiency in SQL is necessary for querying relational databases to extract and analyze customer and operational data.; Cloud-Based Tools and Technologies: Experience with cloud platforms like AWS, Azure, GCP, and Databricks is important for handling large-scale data processing and storage in a cloud environment.; Data Visualization and Storytelling: Skills in creating dashboards, presentations, and interactive formats are required to communicate complex model results and data insights effectively to both technical and non-technical stakeholders.; Data Analysis and Insight Generation: Analyzing massive customer datasets to generate actionable insights that inform risk management policies and support business decisions is a core responsibility.; Automated Workflows and Tool Development: Developing tools and automated workflows to increase the speed, accuracy, and reproducibility of client-facing analyses is part of the role.; BI Tools and Dashboards: Familiarity with business intelligence tools such as Looker and Tableau is important for building visualizations and dashboards that support data storytelling and decision-making.; Big Data Technologies: Experience with big data frameworks and tools like Apache Spark, Apache Arrow, Amazon EMR, Redshift, Snowflake, and S3 is relevant for processing and managing large-scale datasets efficiently."
Ki-vKUxWDKEekexeAAAAAA==,Senior Data Science and Analytics Analyst - CRM Analytics,"Company description

Hi there! We’re Razorfish. We’ve been leading the marketing industry with our digital expertise since the start of the internet. But in 2020, we did a full reboot. What’s different? It all starts with people. Weird, wonderful, complex people - with diverse backgrounds in strategy, creative and technology. But no matter how different we are, we all have one thing in common. We believe our differences are our strength. So we push for inclusion, challenge convention and bring in new perspectives, to inspire new ideas. Because when we connect by understanding what makes people different, we can create unforgettable experiences that enrich lives. Join us at razorfish.com.

Overview

Razorfish is looking for a Senior Associate to join its Data Science and Analytics practice. This is an analytics, research, and consulting team that delivers data-driven insights to our clients. Each member of the team is aligned to one or more clients and works closely with other Data Science team members, our clients, and colleagues across other disciplines such as: Client Management, Strategy, Search, Social, Media, User Experience, and Technology.

In this role you will contribute to data-driven projects across one or more client accounts. You will have support from data leadership and fellow analysts.

Core areas of focus for this group include applications in measurement planning and strategy, customer segmentations, testing frameworks, measurement and optimization solutions, performance reporting and analyses, personalization, and forecasting.

Responsibilities
• Be the lead data analyst for internal and external client project work
• Experience with CRM analytics
• Be the subject matter expert (SME) in source tools, platforms, and data flow
• Understands Razorfish data capabilities and how data fits into a client's overall strategy
• Understands the breadth of data services and crafts
• Owns elements of the data process such as syntax and taxonomy management and QA
• Able to manage data team responsibilities within cross-capability projects
• Participates and presents within larger presentations to clients
• Translates data into visuals (charts and graphs) that demonstrate the finding

Qualifications

Data Strategy
• Able to identify / focus on key issues and objectives based on internal and client needs with oversight
• Effectively describes outputs and approach of analysis to internal audiences and clients

Communication Skills
• Is an active listener and thoughtful communicator within internal and client discussions
• Raises questions based on data trends and patterns, explores hypothesis on causation
• Has ownership of own materials and able to answer questions logically and appropriately
• Participates appropriately in meetings, developing confidence in offering ideas and suggestions
• Begins to play leadership role in team discussions and is more comfortable voicing alternatives appropriately (supported with facts)
• Able to independently create sections of client documents with guidance in addition to leveraging pre-existing templates
• Takes comprehensive meeting notes with clear next steps for individual owners
• Shows ability to transform data into visually appealing presentations and able to adapt new formats as necessary

Client Engagement
• Client Partnerships
• Contributes to meetings with internal and external clients
• Able to prioritize work to meet internal and external client deliverables
• ​​​​​​​Relationship Management
• ​​​​​​​Can identify when a request should be completed by the data team
• Understands how to document client feedback and recognizes when to escalate issues
• Questions and output reflect basic knowledge of client’s business – financials, industry economics, competitive dynamics, marketing channels and client strategic issues

Tools & Techniques
• Shows mastery of client-specific data tools and platforms for reporting purposes
• Has advanced Excel skills with experience in manipulating and organizing large data sets
• Has deeper knowledge of statistical concepts / coding languages for advanced analytics capabilities
• Able to assist in vendor assessments
• Proactively identifies own learning gaps and seeks to answer them through internal resources or asking experts
• Comfortable working within BI/Visualization tools
• Able to QA and maintain data integrity at collection, extraction, and activation point

Analytics
• Planning and Implementation
• Able to own sections of learning agenda / measurement plan
• Able to seamlessly implement a measurement program with minimal guidance
• Able to start and end a reporting deliverable with minimal guidance
• ​​​​​​​Insight Generation
• Able to understand the best path to extract, cleanse, manipulate, and analyze data
• Demonstrates ability to synthesize implications (""so whats?"") from analysis with minimal guidance
• Uses these insights to provide hypotheses and useful recommendations to the team

Additional information

The Power of One starts with our people! To do powerful things, we offer powerful resources. Our best-in-class wellness and benefits offerings include:
• Paid Family Care for parents and caregivers for 12 weeks or more
• Monetary assistance and support for Adoption, Surrogacy and Fertility
• Monetary assistance and support for pet adoption
• Employee Assistance Programs and Health/Wellness/Comfort reimbursements to help you invest in your future and work/life balance
• Tuition Assistance
• Paid time off that includes Flexible Time off Vacation, Annual Sick Days, Volunteer Days, Holiday and Identity days, and more
• Matching Gifts programs
• Flexible working arrangements
• ‘Work Your World’ Program encouraging employees to work from anywhere Publicis Groupe has an office for up to 6 weeks a year (based upon eligibility)
• Business Resource Groups that support multiple affinities and alliances

The benefits offerings listed are available to eligible U.S. Based employees, are reviewed on an annual basis, and are governed by the terms of the applicable plan documents.

Razorfish is an Equal Opportunity Employer. Our employment decisions are made without regard to actual or perceived race, color, ethnicity, religion, creed, sex, sexual orientation, gender, gender identity, gender expression, pregnancy, childbirth and related medical conditions, national origin, ancestry, citizenship status, age, disability, medical condition as defined by applicable state law, genetic information, marital status, military service and veteran status, or any other characteristic protected by applicable federal, state or local laws and ordinances.

If you require accommodation or assistance with the application or onboarding process specifically, please contact USMSTACompliance@publicis.com.

All your information will be kept confidential according to EEO guidelines.

Compensation Range: $72390 - $99960. This is the pay range the Company believes it will pay for this position at the time of this posting. Consistent with applicable law, compensation will be determined based on the skills, qualifications, and experience of the applicant along with the requirements of the position, and the Company reserves the right to modify this pay range at any time. Temporary roles may be eligible to participate in our freelancer/temporary employee medical plan through a third-party benefits administration system once certain criteria have been met. Temporary roles may also qualify for participation in our 401(k) plan after eligibility criteria have been met. For regular roles, the Company will offer medical coverage, dental, vision, disability, 401k, and paid time off. The Company anticipates the application deadline for this job posting will be 8/15/25.

#DNI",,2025-07-25,"['Data Strategy', 'Is an active listener and thoughtful communicator within internal and client discussions', 'Has ownership of own materials and able to answer questions logically and appropriately', 'Has advanced Excel skills with experience in manipulating and organizing large data sets', 'Has deeper knowledge of statistical concepts / coding languages for advanced analytics capabilities', 'Able to understand the best path to extract, cleanse, manipulate, and analyze data']","['This is an analytics, research, and consulting team that delivers data-driven insights to our clients', 'Each member of the team is aligned to one or more clients and works closely with other Data Science team members, our clients, and colleagues across other disciplines such as: Client Management, Strategy, Search, Social, Media, User Experience, and Technology', 'In this role you will contribute to data-driven projects across one or more client accounts', 'You will have support from data leadership and fellow analysts', 'Core areas of focus for this group include applications in measurement planning and strategy, customer segmentations, testing frameworks, measurement and optimization solutions, performance reporting and analyses, personalization, and forecasting', 'Be the lead data analyst for internal and external client project work', 'Experience with CRM analytics', 'Be the subject matter expert (SME) in source tools, platforms, and data flow', ""Understands Razorfish data capabilities and how data fits into a client's overall strategy"", 'Understands the breadth of data services and crafts', 'Owns elements of the data process such as syntax and taxonomy management and QA', 'Able to manage data team responsibilities within cross-capability projects', 'Participates and presents within larger presentations to clients', 'Translates data into visuals (charts and graphs) that demonstrate the finding', 'Able to identify / focus on key issues and objectives based on internal and client needs with oversight', 'Effectively describes outputs and approach of analysis to internal audiences and clients', 'Raises questions based on data trends and patterns, explores hypothesis on causation', 'Participates appropriately in meetings, developing confidence in offering ideas and suggestions', 'Begins to play leadership role in team discussions and is more comfortable voicing alternatives appropriately (supported with facts)', 'Able to independently create sections of client documents with guidance in addition to leveraging pre-existing templates', 'Takes comprehensive meeting notes with clear next steps for individual owners', 'Shows ability to transform data into visually appealing presentations and able to adapt new formats as necessary', 'Client Engagement', 'Client Partnerships', 'Contributes to meetings with internal and external clients', 'Able to prioritize work to meet internal and external client deliverables', '\u200b\u200b\u200b\u200b\u200b\u200b\u200bRelationship Management', '\u200b\u200b\u200b\u200b\u200b\u200b\u200bCan identify when a request should be completed by the data team', 'Understands how to document client feedback and recognizes when to escalate issues', 'Questions and output reflect basic knowledge of client’s business – financials, industry economics, competitive dynamics, marketing channels and client strategic issues', 'Shows mastery of client-specific data tools and platforms for reporting purposes', 'Able to assist in vendor assessments', 'Proactively identifies own learning gaps and seeks to answer them through internal resources or asking experts', 'Comfortable working within BI/Visualization tools', 'Able to QA and maintain data integrity at collection, extraction, and activation point', 'Planning and Implementation', 'Able to own sections of learning agenda / measurement plan', 'Able to seamlessly implement a measurement program with minimal guidance', 'Able to start and end a reporting deliverable with minimal guidance', '\u200b\u200b\u200b\u200b\u200b\u200b\u200bInsight Generation', 'Demonstrates ability to synthesize implications (""so whats?"") from analysis with minimal guidance', 'Uses these insights to provide hypotheses and useful recommendations to the team']",True,[],,"['CRM Analytics', 'Measurement Planning and Strategy', 'Customer Segmentation', 'Testing Frameworks', 'Performance Reporting and Analysis', 'Personalization', 'Forecasting', 'Data Visualization', 'Data Quality Assurance (QA)', 'Statistical Concepts and Coding Languages', 'Data Extraction, Cleansing, and Manipulation', 'Business Intelligence (BI) and Visualization Tools', 'Advanced Excel Skills', 'Data Strategy']","CRM Analytics: Experience with customer relationship management analytics to analyze and optimize client data and marketing strategies.; Measurement Planning and Strategy: Involvement in planning and implementing measurement programs and strategies to evaluate marketing and client performance.; Customer Segmentation: Application of segmentation techniques to categorize customers for targeted marketing and analysis.; Testing Frameworks: Use of frameworks to design and analyze tests for marketing and performance optimization.; Performance Reporting and Analysis: Creation and delivery of reports and analyses to track and communicate client and campaign performance.; Personalization: Development and application of personalized marketing and analytics solutions based on data insights.; Forecasting: Use of forecasting methods to predict future trends and outcomes relevant to client strategies.; Data Visualization: Translating data into charts and graphs to effectively communicate findings to clients and internal teams.; Data Quality Assurance (QA): Ownership of data process elements including syntax, taxonomy management, and ensuring data integrity at collection, extraction, and activation points.; Statistical Concepts and Coding Languages: Utilization of advanced statistical knowledge and coding skills to perform complex data analyses.; Data Extraction, Cleansing, and Manipulation: Ability to extract, cleanse, and manipulate data effectively to prepare it for analysis.; Business Intelligence (BI) and Visualization Tools: Comfortable working with BI and visualization platforms to create reports and dashboards for client insights.; Advanced Excel Skills: Expertise in manipulating and organizing large datasets using advanced Excel functionalities.; Data Strategy: Identifying key issues and objectives based on client and internal needs to guide data-driven decision making."
K-7fcf6yuWkAsvXfAAAAAA==,Senior Product Data Scientist,"The Company

PayPal has been revolutionizing commerce globally for more than 25 years. Creating innovative experiences that make moving money, selling, and shopping simple, personalized, and secure, PayPal empowers consumers and businesses in approximately 200 markets to join and thrive in the global economy.

We operate a global, two-sided network at scale that connects hundreds of millions of merchants and consumers. We help merchants and consumers connect, transact, and complete payments, whether they are online or in person. PayPal is more than a connection to third-party payment networks. We provide proprietary payment solutions accepted by merchants that enable the completion of payments on our platform on behalf of our customers.

We offer our customers the flexibility to use their accounts to purchase and receive payments for goods and services, as well as the ability to transfer and withdraw funds. We enable consumers to exchange funds more safely with merchants using a variety of funding sources, which may include a bank account, a PayPal or Venmo account balance, PayPal and Venmo branded credit products, a credit card, a debit card, certain cryptocurrencies, or other stored value products such as gift cards, and eligible credit card rewards. Our PayPal, Venmo, and Xoom products also make it safer and simpler for friends and family to transfer funds to each other. We offer merchants an end-to-end payments solution that provides authorization and settlement capabilities, as well as instant access to funds and payouts. We also help merchants connect with their customers, process exchanges and returns, and manage risk. We enable consumers to engage in cross-border shopping and merchants to extend their global reach while reducing the complexity and friction involved in enabling cross-border trade.

Our beliefs are the foundation for how we conduct business every day. We live each day guided by our core values of Inclusion, Innovation, Collaboration, and Wellness. Together, our values ensure that we work together as one global team with our customers at the center of everything we do – and they push us to ensure we take care of ourselves, each other, and our communities.

Job Description Summary: What you need to know about the role: We are seeking a senior data scientist who can generate valuable insights from data through deep-dive analyses, who is experienced at supporting new product launches with robust experimentation plans, and who can guide and mentor other data scientists on the team. Meet our team: The Consumer Financial Services Analytics team plays a critical role in improving the PayPal product for customers by using the scientific method to generate insights and drive data-driven decisions. We provide product data science support for Financial Services products such as the PayPal Debit Card, PayPal Savings, PayPal Balance, as well as the various funds-in and funds-out methods associated with those.

Job Description:

Your way to impact:
• You believe in data-driven decisions and use data to answer business questions
• You are hyper-analytical, intellectually honest, and passionate about data and A/B experimentation
• You are a highly motivated, result-oriented self-starter, enjoy working in a fast-paced environment, and can deliver successful results with minimal guidance
• You are curious and inquisitive: you love digging into data and uncovering insights
• You are motivated by improving the experience customers have with the products you work on

Your day to day:
• Help to launch, measure, and scale new solutions to improve customers’ experiences with the PayPal App and website
• Identify new opportunities through deep dive analyses leveraging our rich datasets of behavioral and transactional user data
• Translate ambiguous, unstructured business problems into actionable and data-driven analyses
• Size potential impact of new ideas to help prioritize product roadmaps
• Bring clarity to the performance of our key metrics and flows through well-designed dashboards and reports
• Partner closely with product leaders to understand new product offerings being built and recommend the right metrics to measure the performance of those features
• Define and cultivate best practices in analytics instrumentation and experimentation
• Support multiple projects at the same time in a fast-paced, results-oriented environment
• Mentor other data scientists in both technical and non-technical areas

What do you need to bring:
• Bachelors in a quantitative field (math, statistics, computer science, or similar STEM fields), advanced degrees preferred
• At least 5 years of experience analyzing large, multi-dimensional data sets and synthesizing insights into actionable solutions
• Proven track record driving product strategy through analyses and data-centric presentations
• Strong understanding of statistics (e.g. hypothesis testing, statistical inference, regression) and experience designing and evaluating complex experiments
• Fluent in SQL and experience with at least one scripting language (Python or R), comfortable with working with large, complex, and potentially messy datasets
• Strong interpersonal and project management skills, ability to lead cross-functionally
• Proven ability to mentor junior data scientists
• Experience developing new visualizations in tools such as Tableau
• Prior work experience in Product Data Science (or adjacent space) preferred

PayPal is committed to fair and equitable compensation practices.

Actual Compensation is based on various factors including but not limited to work location, and relevant skills and experience.

The total compensation for this practice may include an annual performance bonus (or other incentive compensation, as applicable), equity, and medical, dental, vision, and other benefits. For more information, visit https://www.paypalbenefits.com.

The U.S. national annual pay range for this role is $123,500 to $212,850

For the majority of employees, PayPal's balanced hybrid work model offers 3 days in the office for effective in-person collaboration and 2 days at your choice of either the PayPal office or your home workspace, ensuring that you equally have the benefits and conveniences of both locations.

Our Benefits:

At PayPal, we’re committed to building an equitable and inclusive global economy. And we can’t do this without our most important asset—you. That’s why we offer benefits to help you thrive in every stage of life. We champion your financial, physical, and mental health by offering valuable benefits and resources to help you care for the whole you.

We have great benefits including a flexible work environment, employee shares options, health and life insurance and more. To learn more about our benefits please visit https://www.paypalbenefits.com

Who We Are:

To learn more about our culture and community visit https://about.pypl.com/who-we-are/default.aspx

Commitment to Diversity and Inclusion

PayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state, or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities. If you are unable to submit an application because of incompatible assistive technology or a disability, please contact us at paypalglobaltalentacquisition@paypal.com.

Belonging at PayPal:

Our employees are central to advancing our mission, and we strive to create an environment where everyone can do their best work with a sense of purpose and belonging. Belonging at PayPal means creating a workplace with a sense of acceptance and security where all employees feel included and valued. We are proud to have a diverse workforce reflective of the merchants, consumers, and communities that we serve, and we continue to take tangible actions to cultivate inclusivity and belonging at PayPal.

Any general requests for consideration of your skills, please Join our Talent Community.

We know the confidence gap and imposter syndrome can get in the way of meeting spectacular candidates. Please don’t hesitate to apply.",2025-06-28T00:00:00.000Z,2025-07-25,"['You believe in data-driven decisions and use data to answer business questions', 'You are hyper-analytical, intellectually honest, and passionate about data and A/B experimentation', 'You are a highly motivated, result-oriented self-starter, enjoy working in a fast-paced environment, and can deliver successful results with minimal guidance', 'You are curious and inquisitive: you love digging into data and uncovering insights', 'You are motivated by improving the experience customers have with the products you work on', 'At least 5 years of experience analyzing large, multi-dimensional data sets and synthesizing insights into actionable solutions', 'Proven track record driving product strategy through analyses and data-centric presentations', 'Strong understanding of statistics (e.g. hypothesis testing, statistical inference, regression) and experience designing and evaluating complex experiments', 'Fluent in SQL and experience with at least one scripting language (Python or R), comfortable with working with large, complex, and potentially messy datasets', 'Strong interpersonal and project management skills, ability to lead cross-functionally', 'Proven ability to mentor junior data scientists', 'Experience developing new visualizations in tools such as Tableau']","['We offer our customers the flexibility to use their accounts to purchase and receive payments for goods and services, as well as the ability to transfer and withdraw funds', 'We enable consumers to exchange funds more safely with merchants using a variety of funding sources, which may include a bank account, a PayPal or Venmo account balance, PayPal and Venmo branded credit products, a credit card, a debit card, certain cryptocurrencies, or other stored value products such as gift cards, and eligible credit card rewards', 'We also help merchants connect with their customers, process exchanges and returns, and manage risk', 'We enable consumers to engage in cross-border shopping and merchants to extend their global reach while reducing the complexity and friction involved in enabling cross-border trade', 'Job Description Summary: What you need to know about the role: We are seeking a senior data scientist who can generate valuable insights from data through deep-dive analyses, who is experienced at supporting new product launches with robust experimentation plans, and who can guide and mentor other data scientists on the team', 'Meet our team: The Consumer Financial Services Analytics team plays a critical role in improving the PayPal product for customers by using the scientific method to generate insights and drive data-driven decisions', 'We provide product data science support for Financial Services products such as the PayPal Debit Card, PayPal Savings, PayPal Balance, as well as the various funds-in and funds-out methods associated with those', 'Help to launch, measure, and scale new solutions to improve customers’ experiences with the PayPal App and website', 'Identify new opportunities through deep dive analyses leveraging our rich datasets of behavioral and transactional user data', 'Translate ambiguous, unstructured business problems into actionable and data-driven analyses', 'Size potential impact of new ideas to help prioritize product roadmaps', 'Bring clarity to the performance of our key metrics and flows through well-designed dashboards and reports', 'Partner closely with product leaders to understand new product offerings being built and recommend the right metrics to measure the performance of those features', 'Define and cultivate best practices in analytics instrumentation and experimentation', 'Support multiple projects at the same time in a fast-paced, results-oriented environment', 'Mentor other data scientists in both technical and non-technical areas']",True,[],,"['A/B Testing', 'Behavioral and Transactional Data Analysis', 'Data-Driven Decision Making', 'Data Visualization', 'Experimentation Design and Evaluation', 'Hypothesis Testing and Statistical Inference', 'Multi-Dimensional Data Analysis', 'Product Data Science', 'Python and R Scripting', 'Regression Analysis', 'SQL']","A/B Testing: Used to design and evaluate complex experiments to support new product launches and measure their impact on customer experience.; Behavioral and Transactional Data Analysis: Leveraged deep-dive analyses on rich datasets of behavioral and transactional user data to identify new opportunities and generate valuable insights.; Data-Driven Decision Making: Core approach to answering business questions and driving product strategy through analyses and data-centric presentations.; Data Visualization: Experience developing new visualizations using tools such as Tableau to bring clarity to key metrics and flows through dashboards and reports.; Experimentation Design and Evaluation: Responsible for defining and cultivating best practices in analytics instrumentation and experimentation to measure product performance.; Hypothesis Testing and Statistical Inference: Strong understanding and application of statistical methods such as hypothesis testing and inference to analyze data and support decision making.; Multi-Dimensional Data Analysis: Experience analyzing large, complex, and potentially messy multi-dimensional datasets to synthesize insights into actionable solutions.; Product Data Science: Providing data science support for financial services products by generating insights, supporting product launches, and mentoring other data scientists.; Python and R Scripting: Fluent in at least one scripting language (Python or R) to manipulate and analyze large datasets.; Regression Analysis: Applied regression techniques as part of statistical analysis to understand relationships within data and support product decisions.; SQL: Fluent in SQL for querying and working with large, complex datasets."
ZnzoTWtgb1YvbDueAAAAAA==,"Senior Data Scientist, Emerging Technology and Innovation - Full-time","Sr Data Scientist - GD07AE

We’re determined to make a difference and are proud to be an insurance company that goes well beyond coverages and policies. Working here means having every opportunity to achieve your goals – and to help others accomplish theirs, too. Join our team as we help shape the future.

You are a driven and motivated problem solver ready to pursue meaningful work. You strive to make an impact every day not only at work, but at home and in the community too. If that sounds like you, then you’ve landed in the right place.

Emerging Tech and Innovation is a forward-looking team at The Hartford. We explore the frontier of AI by experimenting with emerging technologies, evaluating cutting-edge vendors, and rapidly prototyping solutions that can transform the insurance landscape.

We are seeking a Senior Data Scientist with deep expertise in computer vision and a passion for experimentation. This role is ideal for someone who thrives in early-stage R&D environments, enjoys working with novel data modalities, and is excited by the challenge of translating emerging capabilities into business value. You’ll collaborate closely with other data science and engineering teams, often handing off successful prototypes for production scaling.

Key Focus Areas

This position will build domain expertise in areas such as:

· Computer vision and convolutional neural networks (CNNs)

· Multimodal generative AI , including image-text models

· Video analytics , including facial detection

· Rapid experimentation and proof-of-concept development

· Vendor and technology evaluations in the AI/ML space

Responsibilities

+ Design and prototype machine learning models for image and video data, with a focus on insurance-relevant use cases.

+ Evaluate emerging technologies and vendors, providing technical assessments and recommendations.

+ Collaborate with business stakeholders to identify high-impact opportunities for AI innovation.

+ Translate ambiguous problems into structured experiments and communicate findings clearly.

+ Partner with engineering and data science teams to transition successful prototypes into production-ready solutions.

+ Stay current on the latest research and trends in AI, computer vision, and generative models.

+ Mentor junior team members and contribute to a culture of curiosity and continuous learning.

What’s in it for you?

+ Work on cutting-edge AI problems in a highly exploratory environment.

+ Collaborate with a high-performing, forward-focused team and engage with product owners and business stakeholders.

+ Expand your technical and strategic skills in a role that blends research, experimentation, and business impact.

+ Influence the future of AI at The Hartford by shaping how new technologies are evaluated and adopted.

+ Thrive in a supportive environment that values innovation, agility, and growth.

This role will have a Hybrid work schedule, with the expectation of working in an office (Columbus, OH, Chicago, IL, Hartford, CT or Charlotte, NC) 3 days a week (Tuesday through Thursday).

Qualifications:

+ Master’s or PhD in a quantitative field such as Data Science, Computer Science, Statistics, Applied Mathematics, or Engineering. A Bachelor’s with additional years of relevant experience can substitute for an advanced degree.

+ 5+ years of experience in data science, machine learning, or a related field.

+ Proficiency in Python and SQL; experience with cloud platforms (AWS, GCP, or Azure).

+ Strong understanding of statistical modeling, machine learning, and data visualization techniques.

+ Excellent problem-solving skills and ability to work independently and collaboratively.

+ Strong communication skills with the ability to present complex ideas to diverse audiences.

+ Self-motivated, strong sense of ownership/accountability, and results oriented with the ability to manage time and schedules effectively

+ Natural curiosity with a strong desire to learn, maintain, and apply knowledge of emerging data technologies

+ Candidate must be authorized to work in the US without company sponsorship. The company will not support the STEM OPT I-983 Training Plan endorsement for this position.

Desired Qualifications:

+ Experience with Computer Vision, Convolutional Neural Networks(CNN), Multimodal GEN AI a plus

+ Familiarity with Agile and CI/CD practices.

+ Experience in innovation and rapid prototyping with a “fail-fast” mindset.

+ Knowledge of Property & Casualty Insurance business is a plus.

Compensation

The listed annualized base pay range is primarily based on analysis of similar positions in the external market. Actual base pay could vary and may be above or below the listed range based on factors including but not limited to performance, proficiency and demonstration of competencies required for the role. The base pay is just one component of The Hartford’s total compensation package for employees. Other rewards may include short-term or annual bonuses, long-term incentives, and on-the-spot recognition. The annualized base pay range for this role is:

$110,720 - $166,080

Equal Opportunity Employer/Sex/Race/Color/Veterans/Disability/Sexual Orientation/Gender Identity or Expression/Religion/Age

About Us (https://www.thehartford.com/about-us) | Culture & Employee Insights (https://www.thehartford.com/careers/employee-stories) | Diversity, Equity and Inclusion (https://www.thehartford.com/about-us/corporate-diversity) | Benefits (https://www.thehartford.com/careers/benefits)

Every day, a day to do right.

Showing up for people isn’t just what we do. It’s who we are – and have been for more than 200 years. We’re devoted to finding innovative ways to serve our customers, communities and employees—continually asking ourselves what more we can do.

Is our policy language as simple and inclusive as it can be? Can we better help businesses navigate our ever-changing world? What else can we do to destigmatize mental health in the workplace? Can we make our communities more equitable?

That we can rise to the challenge of these questions is due in no small part to our company values that our employees have shaped and defined.

And while how we contribute looks different for each of us, it’s these values that drive all of us to do more and to do better every day.

About Us (https://www.thehartford.com/about-us)

Our Culture

What It’s Like to Work Here (https://www.thehartford.com/careers/our-employees)

Perks & Benefits

Legal Notice (https://www.thehartford.com/legal-notice)

Accessibility StatementProducer Compensation (https://www.thehartford.com/producer-compensation)

EEO

Privacy Policy (https://www.thehartford.com/online-privacy-policy)

California Privacy Policy

Your California Privacy Choices (https://www.thehartford.com/data-privacy-opt-out-form)

International Privacy Policy

Canadian Privacy Policy (https://www.thehartford.com/canadian-privacy-policy)

Unincorporated Areas of LA County, CA (Applicant Information)

MA Applicant Notice (https://www.thehartford.com/ma-lie-detector)

Sr Data Scientist - GD07AE

We’re determined to make a difference and are proud to be an insurance company that goes well beyond coverages and policies. Working here means having every opportunity to achieve your goals – and to help others accomplish theirs, too. Join our team as we help shape the future.

You are a driven and motivated problem solver ready to pursue meaningful work. You strive to make an impact every day not only at work, but at home and in the community too. If that sounds like you, then you’ve landed in the right place.

Emerging Tech and Innovation is a forward-looking team at The Hartford. We explore the frontier of AI by experimenting with emerging technologies, evaluating cutting-edge vendors, and rapidly prototyping solutions that can transform the insurance landscape.

We are seeking a Senior Data Scientist with deep expertise in computer vision and a passion for experimentation. This role is ideal for someone who thrives in early-stage R&D environments, enjoys working with novel data modalities, and is excited by the challenge of translating emerging capabilities into business value. You’ll collaborate closely with other data science and engineering teams, often handing off successful prototypes for production scaling.

Key Focus Areas

This position will build domain expertise in areas such as:

· Computer vision and convolutional neural networks (CNNs)

· Multimodal generative AI , including image-text models

· Video analytics , including facial detection

· Rapid experimentation and proof-of-concept development

· Vendor and technology evaluations in the AI/ML space

Responsibilities

+ Design and prototype machine learning models for image and video data, with a focus on insurance-relevant use cases.

+ Evaluate emerging technologies and vendors, providing technical assessments and recommendations.

+ Collaborate with business stakeholders to identify high-impact opportunities for AI innovation.

+ Translate ambiguous problems into structured experiments and communicate findings clearly.

+ Partner with engineering and data science teams to transition successful prototypes into production-ready solutions.

+ Stay current on the latest research and trends in AI, computer vision, and generative models.

+ Mentor junior team members and contribute to a culture of curiosity and continuous learning.

What’s in it for you?

+ Work on cutting-edge AI problems in a highly exploratory environment.

+ Collaborate with a high-performing, forward-focused team and engage with product owners and business stakeholders.

+ Expand your technical and strategic skills in a role that blends research, experimentation, and business impact.

+ Influence the future of AI at The Hartford by shaping how new technologies are evaluated and adopted.

+ Thrive in a supportive environment that values innovation, agility, and growth.

This role will have a Hybrid work schedule, with the expectation of working in an office (Columbus, OH, Chicago, IL, Hartford, CT or Charlotte, NC) 3 days a week (Tuesday through Thursday).

Qualifications:

+ Master’s or PhD in a quantitative field such as Data Science, Computer Science, Statistics, Applied Mathematics, or Engineering. A Bachelor’s with additional years of relevant experience can substitute for an advanced degree.

+ 5+ years of experience in data science, machine learning, or a related field.

+ Proficiency in Python and SQL; experience with cloud platforms (AWS, GCP, or Azure).

+ Strong understanding of statistical modeling, machine learning, and data visualization techniques.

+ Excellent problem-solving skills and ability to work independently and collaboratively.

+ Strong communication skills with the ability to present complex ideas to diverse audiences.

+ Self-motivated, strong sense of ownership/accountability, and results oriented with the ability to manage time and schedules effectively

+ Natural curiosity with a strong desire to learn, maintain, and apply knowledge of emerging data technologies

+ Candidate must be authorized to work in the US without company sponsorship. The company will not support the STEM OPT I-983 Training Plan endorsement for this position.

Desired Qualifications:

+ Experience with Computer Vision, Convolutional Neural Networks(CNN), Multimodal GEN AI a plus

+ Familiarity with Agile and CI/CD practices.

+ Experience in innovation and rapid prototyping with a “fail-fast” mindset.

+ Knowledge of Property & Casualty Insurance business is a plus.

Compensation

The listed annualized base pay range is primarily based on analysis of similar positions in the external market. Actual base pay could vary and may be above or below the listed range based on factors including but not limited to performance, proficiency and demonstration of competencies required for the role. The base pay is just one component of The Hartford’s total compensation package for employees. Other rewards may include short-term or annual bonuses, long-term incentives, and on-the-spot recognition. The annualized base pay range for this role is:

$110,720 - $166,080

Equal Opportunity Employer/Sex/Race/Color/Veterans/Disability/Sexual Orientation/Gender Identity or Expression/Religion/Age

About Us (https://www.thehartford.com/about-us) | Culture & Employee Insights (https://www.thehartford.com/careers/employee-stories) | Diversity, Equity and Inclusion (https://www.thehartford.com/about-us/corporate-diversity) | Benefits (https://www.thehartford.com/careers/benefits)

Every day, a day to do right.

Showing up for people isn’t just what we do. It’s who we are – and have been for more than 200 years. We’re devoted to finding innovative ways to serve our customers, communities and employees—continually asking ourselves what more we can do.

Is our policy language as simple and inclusive as it can be? Can we better help businesses navigate our ever-changing world? What else can we do to destigmatize mental health in the workplace? Can we make our communities more equitable?

That we can rise to the challenge of these questions is due in no small part to our company values that our employees have shaped and defined.

And while how we contribute looks different for each of us, it’s these values that drive all of us to do more and to do better every day.

About Us (https://www.thehartford.com/about-us)

Our Culture

What It’s Like to Work Here (https://www.thehartford.com/careers/our-employees)

Perks & Benefits

Legal Notice (https://www.thehartford.com/legal-notice)

Accessibility StatementProducer Compensation (https://www.thehartford.com/producer-compensation)

EEO

Privacy Policy (https://www.thehartford.com/online-privacy-policy)

California Privacy Policy

Your California Privacy Choices (https://www.thehartford.com/data-privacy-opt-out-form)

International Privacy Policy

Canadian Privacy Policy (https://www.thehartford.com/canadian-privacy-policy)

Unincorporated Areas of LA County, CA (Applicant Information)

MA Applicant Notice (https://www.thehartford.com/ma-lie-detector)",2025-07-25T02:00:00.000Z,2025-07-25,"['You strive to make an impact every day not only at work, but at home and in the community too', 'We are seeking a Senior Data Scientist with deep expertise in computer vision and a passion for experimentation', 'This role is ideal for someone who thrives in early-stage R&D environments, enjoys working with novel data modalities, and is excited by the challenge of translating emerging capabilities into business value', 'Computer vision and convolutional neural networks (CNNs)', 'Video analytics , including facial detection', 'Rapid experimentation and proof-of-concept development', 'Vendor and technology evaluations in the AI/ML space', 'Collaborate with a high-performing, forward-focused team and engage with product owners and business stakeholders', 'Expand your technical and strategic skills in a role that blends research, experimentation, and business impact', 'Master’s or PhD in a quantitative field such as Data Science, Computer Science, Statistics, Applied Mathematics, or Engineering', 'A Bachelor’s with additional years of relevant experience can substitute for an advanced degree', '5+ years of experience in data science, machine learning, or a related field', 'Proficiency in Python and SQL; experience with cloud platforms (AWS, GCP, or Azure)', 'Strong understanding of statistical modeling, machine learning, and data visualization techniques', 'Excellent problem-solving skills and ability to work independently and collaboratively', 'Strong communication skills with the ability to present complex ideas to diverse audiences', 'Self-motivated, strong sense of ownership/accountability, and results oriented with the ability to manage time and schedules effectively', 'Natural curiosity with a strong desire to learn, maintain, and apply knowledge of emerging data technologies', 'Candidate must be authorized to work in the US without company sponsorship', 'You are a driven and motivated problem solver ready to pursue meaningful work', 'You strive to make an impact every day not only at work, but at home and in the community too', 'We are seeking a Senior Data Scientist with deep expertise in computer vision and a passion for experimentation', 'This role is ideal for someone who thrives in early-stage R&D environments, enjoys working with novel data modalities, and is excited by the challenge of translating emerging capabilities into business value', 'Computer vision and convolutional neural networks (CNNs)', 'Multimodal generative AI , including image-text models', 'Video analytics , including facial detection', 'Rapid experimentation and proof-of-concept development', 'Vendor and technology evaluations in the AI/ML space', 'Collaborate with a high-performing, forward-focused team and engage with product owners and business stakeholders', 'Expand your technical and strategic skills in a role that blends research, experimentation, and business impact', 'Master’s or PhD in a quantitative field such as Data Science, Computer Science, Statistics, Applied Mathematics, or Engineering', 'A Bachelor’s with additional years of relevant experience can substitute for an advanced degree', '5+ years of experience in data science, machine learning, or a related field', 'Proficiency in Python and SQL; experience with cloud platforms (AWS, GCP, or Azure)', 'Strong understanding of statistical modeling, machine learning, and data visualization techniques', 'Excellent problem-solving skills and ability to work independently and collaboratively', 'Strong communication skills with the ability to present complex ideas to diverse audiences', 'Self-motivated, strong sense of ownership/accountability, and results oriented with the ability to manage time and schedules effectively', 'Natural curiosity with a strong desire to learn, maintain, and apply knowledge of emerging data technologies', 'Candidate must be authorized to work in the US without company sponsorship']","['You’ll collaborate closely with other data science and engineering teams, often handing off successful prototypes for production scaling', 'This position will build domain expertise in areas such as:', 'Multimodal generative AI , including image-text models', 'Design and prototype machine learning models for image and video data, with a focus on insurance-relevant use cases', 'Evaluate emerging technologies and vendors, providing technical assessments and recommendations', 'Collaborate with business stakeholders to identify high-impact opportunities for AI innovation', 'Translate ambiguous problems into structured experiments and communicate findings clearly', 'Partner with engineering and data science teams to transition successful prototypes into production-ready solutions', 'Stay current on the latest research and trends in AI, computer vision, and generative models', 'Mentor junior team members and contribute to a culture of curiosity and continuous learning', 'This role will have a Hybrid work schedule, with the expectation of working in an office (Columbus, OH, Chicago, IL, Hartford, CT or Charlotte, NC) 3 days a week (Tuesday through Thursday)', 'You’ll collaborate closely with other data science and engineering teams, often handing off successful prototypes for production scaling', 'This position will build domain expertise in areas such as:', 'Design and prototype machine learning models for image and video data, with a focus on insurance-relevant use cases', 'Evaluate emerging technologies and vendors, providing technical assessments and recommendations', 'Collaborate with business stakeholders to identify high-impact opportunities for AI innovation', 'Translate ambiguous problems into structured experiments and communicate findings clearly', 'Partner with engineering and data science teams to transition successful prototypes into production-ready solutions', 'Stay current on the latest research and trends in AI, computer vision, and generative models', 'Mentor junior team members and contribute to a culture of curiosity and continuous learning']",True,"['Multimodal Generative AI', 'Generative AI', 'Computer Vision with Deep Learning']","Multimodal Generative AI: Work with multimodal generative AI models, including image-text models, to explore and prototype innovative AI solutions relevant to insurance use cases.; Generative AI: Engage in research, experimentation, and application of generative AI techniques to develop novel AI capabilities and business value.; Computer Vision with Deep Learning: Apply deep learning methods, specifically convolutional neural networks, for advanced computer vision tasks such as video analytics and facial detection.","['Machine Learning', 'Computer Vision', 'Convolutional Neural Networks', 'Python', 'SQL', 'Cloud Platforms', 'Statistical Modeling', 'Data Visualization', 'Rapid Experimentation and Prototyping', 'Vendor and Technology Evaluation']","Machine Learning: Design and prototype machine learning models for image and video data focused on insurance-relevant use cases; involves building domain expertise in machine learning and statistical modeling techniques relevant to the insurance industry.; Computer Vision: Develop expertise in computer vision techniques including video analytics and facial detection to analyze image and video data for insurance applications.; Convolutional Neural Networks: Apply convolutional neural networks (CNNs) as a core method for computer vision tasks such as image and video analysis within insurance-related projects.; Python: Use Python programming language for data science and machine learning model development, prototyping, and experimentation.; SQL: Utilize SQL for data querying and management to support data science workflows and analytics.; Cloud Platforms: Leverage cloud platforms such as AWS, GCP, or Azure to deploy, scale, and manage data science and machine learning solutions.; Statistical Modeling: Employ statistical modeling techniques to support machine learning and data analysis efforts in insurance-related projects.; Data Visualization: Use data visualization techniques to communicate complex data insights and model results effectively to diverse audiences.; Rapid Experimentation and Prototyping: Engage in rapid experimentation and proof-of-concept development to quickly test and validate emerging data science and machine learning approaches.; Vendor and Technology Evaluation: Evaluate emerging technologies and vendors in the AI/ML space to provide technical assessments and recommendations for adoption."
8KqSNGiTErw9w2nBAAAAAA==,"US E-Consulting Services-Senior Data Scientist, Specialist Senior-S&T Strategy AIDASD/SFL Scientific-WW (303712)","Senior Data Scientist, Specialist Senior SFL Scientific

Our Deloitte Strategy & Transactions team helps guide clients through their most critical moments and transformational initiatives. From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability. Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journeybefore, during, and after any major transformational projects or transactions.

SFL Scientific, a Deloitte Business, is a U.S. based, data science consulting firm specializing in building industry-specific, artificial intelligence (AI) technologies.

We are hiring a Senior Data Scientist to collaborate directly with clients to design and develop novel projects and solutions. Join a rapidly growing team of professionals working to build a world-class data science practice focused on solving complex and R&D problems.

Recruiting for this role ends on 6/30/2025.

Work Youll Do

As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services. You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions.

Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation. Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills.
• Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production
• Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives
• Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization
• Validate AI models and algorithm via code reviews, unit, and integration tests
• Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives
• Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives

The Team

Our Strategy offering architects bold strategies to achieve business and mission goals, enabling growth, competitive advantage, technology modernization, and continuous digital and AI transformation.

SFL Scientific, a Deloitte Business, is a data science professional services practice focused on strategy, technology, and solving business challenges with Artificial Intelligence (AI). The team has a proven track record serving large, market-leading organizations in the private and public sectors, successfully delivering high-quality, novel and complex projects, and offering deep domain and scientific capabilities. Made up of experienced AI strategists, data scientists, and AI engineers, they serve as trusted advisors to executives, helping them understand and evaluate new and essential areas for AI investment and identify unique opportunities to transform their businesses.

Qualifications:
• Masters or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)
• 3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)
• 3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments
• 3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow
• 3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads
• Live within commuting distance to one of Deloittes consulting offices
• Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve
• Limited immigration sponsorship may be available

Preferred:
• 2+ years of experience working in a client-facing, consulting environment
• 2+ years of experience leading project/client engagement teams in the execution of complex AI data science solutions
• 1+ year of experience with LLM/GenAI use cases and developing RAG solutions, tools, and services (i.e., LangChain, LangGraph, MCP, etc.)
• 1+ year of experience with AWS Sagemaker or AWS ML Studio

Information for applicants with a need for accommodation:

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $107,600 to $198,400.

You may also be eligible to participate in a discretionary annual incentive program, subject to the rules governing the program, whereby an award, if any, depends on various factors, including, without limitation, individual and organizational performance.

#MonitorDeloitte

#DeloitteJobs

#StrategyConsulting

#DeloitteStrategy

#Strategy26

#SFL26
Recruiting tips

From developing a stand out resume to putting your best foot forward in the interview, we want you to feel prepared and confident as you explore opportunities at Deloitte. Check out recruiting tips from Deloitte recruiters. Benefits

At Deloitte, we know that great people make a great organization. We value our people and offer employees a broad range of benefits. Learn more about what working at Deloitte can mean for you. Our people and culture

Our inclusive culture empowers our people to be who they are, contribute their unique perspectives, and make a difference individually and collectively. It enables us to leverage different ideas and perspectives, and bring more creativity and innovation to help solve our clients' most complex challenges. This makes Deloitte one of the most rewarding places to work. Our purpose
Deloittes purpose is to make an impact that matters for our people, clients, and communities. At Deloitte, purpose is synonymous with how we work every day. It defines who we are. Our purpose comes through in our work with clients that enables impact and value in their organizations, as well as through our own investments, commitments, and actions across areas that help drive positive outcomes for our communities. Learn more. Professional development

From entry-level employees to senior leaders, we believe theres always room to learn. We offer opportunities to build new skills, take on leadership opportunities and connect and grow through mentorship. From on-the-job learning experiences to formal development programs, our professionals have a variety of opportunities to continue to grow throughout their career. Position Summary

Senior Data Scientist, Specialist Senior SFL Scientific

Our Deloitte Strategy & Transactions team helps guide clients through their most critical moments and transformational initiatives. From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability. Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journeybefore, during, and after any major transformational projects or transactions.

SFL Scientific, a Deloitte Business, is a U.S. based, data science consulting firm specializing in building industry-specific, artificial intelligence (AI) technologies.

We are hiring a Senior Data Scientist to collaborate directly with clients to design and develop novel projects and solutions. Join a rapidly growing team of professionals working to build a world-class data science practice focused on solving complex and R&D problems.

Recruiting for this role ends on 6/30/2025.

Work Youll Do

As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services. You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions.

Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation. Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills.
• Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production
• Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives
• Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization
• Validate AI models and algorithm via code reviews, unit, and integration tests
• Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives
• Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives

The Team

Our Strategy offering architects bold strategies to achieve business and mission goals, enabling growth, competitive advantage, technology modernization, and continuous digital and AI transformation.

SFL Scientific, a Deloitte Business, is a data science professional services practice focused on strategy, technology, and solving business challenges with Artificial Intelligence (AI). The team has a proven track record serving large, market-leading organizations in the private and public sectors, successfully delivering high-quality, novel and complex projects, and offering deep domain and scientific capabilities. Made up of experienced AI strategists, data scientists, and AI engineers, they serve as trusted advisors to executives, helping them understand and evaluate new and essential areas for AI investment and identify unique opportunities to transform their businesses.

Qualifications:
• Masters or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)
• 3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)
• 3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments
• 3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow
• 3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads
• Live within commuting distance to one of Deloittes consulting offices
• Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve
• Limited immigration sponsorship may be available

Preferred:
• 2+ years of experience working in a client-facing, consulting environment
• 2+ years of experience leading project/client engagement teams in the execution of complex AI data science solutions
• 1+ year of experience with LLM/GenAI use cases and developing RAG solutions, tools, and services (i.e., LangChain, LangGraph, MCP, etc.)
• 1+ year of experience with AWS Sagemaker or AWS ML Studio

Information for applicants with a need for accommodation:

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $107,600 to $198,400.

You may also be eligible to participate in a discretionary annual incentive program, subject to the rules governing the program, whereby an award, if any, depends on various factors, including, without limitation, individual and organizational performance.

#MonitorDeloitte

#DeloitteJobs

#StrategyConsulting

#DeloitteStrategy

#Strategy26

#SFL26
Recruiting tips

From developing a stand out resume to putting your best foot forward in the interview, we want you to feel prepared and confident as you explore opportunities at Deloitte. Check out recruiting tips from Deloitte recruiters. Benefits

At Deloitte, we know that great people make a great organization. We value our people and offer employees a broad range of benefits. Learn more about what working at Deloitte can mean for you. Our people and culture

Our inclusive culture empowers our people to be who they are, contribute their unique perspectives, and make a difference individually and collectively. It enables us to leverage different ideas and perspectives, and bring more creativity and innovation to help solve our clients' most complex challenges. This makes Deloitte one of the most rewarding places to work. Our purpose
Deloittes purpose is to make an impact that matters for our people, clients, and communities. At Deloitte, purpose is synonymous with how we work every day. It defines who we are. Our purpose comes through in our work with clients that enables impact and value in their organizations, as well as through our own investments, commitments, and actions across areas that help drive positive outcomes for our communities. Learn more. Professional development

From entry-level employees to senior leaders, we believe theres always room to learn. We offer opportunities to build new skills, take on leadership opportunities and connect and grow through mentorship. From on-the-job learning experiences to formal development programs, our professionals have a variety of opportunities to continue to grow throughout their career.

As used in this posting, ""Deloitte"" means Deloitte Consulting LLP, a subsidiary of Deloitte LLP. Please see www.deloitte.com/us/about for a detailed description of the legal structure of Deloitte LLP and its subsidiaries.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.
Qualified applicants with criminal histories, including arrest or conviction records, will be considered for employment in accordance with the requirements of applicable state and local laws, including the Los Angeles County Fair Chance Ordinance for Employers, City of Los Angeless Fair Chance Initiative for Hiring Ordinance, San Francisco Fair Chance Ordinance, and the California Fair Chance Act. See notices of various fair chance hiring and ban-the-box laws where available. Fair Chance Hiring and Ban-the-Box Notices | Deloitte US Careers Requisition code: 303712 Job ID 303712 Qualified applicants with criminal histories, including arrest or conviction records, will be considered for employment in accordance with the requirements of applicable state and local laws, including the Los Angeles County Fair Chance Ordinance for Employers, City of Los Angeless Fair Chance Initiative for Hiring Ordinance, San Francisco Fair Chance Ordinance, and the California Fair Chance Act. See notices of various fair chance hiring and ban-the-box laws where available. Fair Chance Hiring and Ban-the-Box Notices | Deloitte US Careers Requisition code: 303712 Job ID 303712 Caution against fraudulent job offers!

We have been informed of instances where jobseekers are led to believe of fictitious job opportunities with Deloitte US (Deloitte). In one or more such cases, false promises of actual or potential selection, or initiation or completion of the recruitment formalities appear to have been or are being made. Some jobseekers appear to have been asked to pay money to specified bank accounts of individuals or entities as a condition of their selection for a job with Deloitte. These individuals or entities are in no way connected with Deloitte and do not represent or otherwise act on behalf of Deloitte.

We would like to clarify that:
• At Deloitte, ethics and integrity are fundamental and not negotiable.
• We are against corruption and neither offer bribes nor accept them, nor induce or permit any other party to make or receive bribes on our behalf.
• We have not authorized any party or person to collect any money from jobseekers in any form whatsoever for promises of getting jobs in Deloitte.
• We consider candidates on merit and that we provide an equal opportunity to eligible applicants.
• No one other than designated Deloitte personnel (e.g., a Deloitte recruiter or Deloitte hiring partner) is permitted to extend any job offer from Deloitte.

Anyone who at any time has made or makes any payment to any party in exchange for promises of job or selection for a job with Deloitte or any matter related to this (including those for registration, verification or security deposit) or otherwise engages with any such person who has made or makes fraudulent promises or offers, does so (or has done so) entirely at their own risk. Deloitte takes no responsibility or liability for any such unauthorized or fraudulent actions or engagements. We encourage jobseekers to exercise caution.",,2025-07-25,"['Masters or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)', '3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)', '3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments', '3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow', '3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads', 'Live within commuting distance to one of Deloittes consulting offices', 'Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve', 'Limited immigration sponsorship may be available', 'Senior Data Scientist, Specialist Senior SFL Scientific', 'Masters or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)', '3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)', '3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments', '3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow', '3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads', 'Live within commuting distance to one of Deloittes consulting offices', 'Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve', 'Limited immigration sponsorship may be available', 'Fair Chance Hiring and Ban-the-Box Notices | Deloitte US Careers Requisition code: 303712 Job ID 303712 Qualified applicants with criminal histories, including arrest or conviction records, will be considered for employment in accordance with the requirements of applicable state and local laws, including the Los Angeles County Fair Chance Ordinance for Employers, City of Los Angeless Fair Chance Initiative for Hiring Ordinance, San Francisco Fair Chance Ordinance, and the California Fair Chance Act']","['From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability', 'Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journeybefore, during, and after any major transformational projects or transactions', 'As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services', 'You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions', 'Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation', 'Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills', 'Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production', 'Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives', 'Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization', 'Validate AI models and algorithm via code reviews, unit, and integration tests', 'Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives', 'Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives', 'From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability', 'Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journeybefore, during, and after any major transformational projects or transactions', 'As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services', 'You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions', 'Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation', 'Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills', 'Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production', 'Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives', 'Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization', 'Validate AI models and algorithm via code reviews, unit, and integration tests', 'Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives', 'Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives']",True,"['Generative AI', 'Large Language Models', 'Retrieval-Augmented Generation', 'Deep Learning Frameworks', 'AI Model Deployment and MLOps']","Generative AI: Experience with LLM/GenAI use cases and developing Retrieval-Augmented Generation solutions, tools, and services such as LangChain, LangGraph, and MCP.; Large Language Models: Involves working with LLMs in use cases related to generative AI and AI strategy development.; Retrieval-Augmented Generation: Developing RAG solutions and services to enhance AI capabilities, including integration with tools like LangChain and LangGraph.; Deep Learning Frameworks: Using frameworks such as PyTorch specifically for developing and deploying deep learning models including CNNs, RNNs, and GANs.; AI Model Deployment and MLOps: Deploying and optimizing AI/ML models in production environments using Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, MLflow, and cloud platforms like AWS SageMaker and AWS ML Studio.","['Exploratory Data Analysis', 'Machine Learning', 'Deep Learning', 'Natural Language Processing', 'Time-Series Analysis', 'Computer Vision', 'Model Validation and Testing', 'Model Deployment and Optimization', 'Cloud Computing for AI/ML', 'Data Strategy']","Exploratory Data Analysis: Used to understand client data sets and operational requirements to design long-term solutions and guide AI strategy and development.; Machine Learning: Applied in developing AI/ML solutions, including researching novel approaches, advancing training and solution design, and deploying models into production.; Deep Learning: Utilized techniques such as CNNs, RNNs, and GANs across real-world projects, including model tuning and performance validation in production environments.; Natural Language Processing: Applied as part of data analysis tasks including NLP, time-series analysis, and computer vision to support AI/ML algorithm development.; Time-Series Analysis: Used in data analysis alongside NLP and computer vision to support AI/ML algorithm development.; Computer Vision: Employed as part of data analysis techniques in AI/ML algorithm development.; Model Validation and Testing: Includes validating AI models and algorithms via code reviews, unit tests, and integration tests to ensure model performance and reliability.; Model Deployment and Optimization: Involves deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow to maximize business impact.; Cloud Computing for AI/ML: Leveraging cloud environments such as AWS, Azure, or GCP to deploy AI/ML workloads efficiently.; Data Strategy: Defining data strategy to drive technical development and create next-generation tools, products, and AI services aligned with client needs."
t4yVfsMzzUfK4VS3AAAAAA==,Senior Data Scientist: 24-03073 (No C2C),"Primary Skills: Python (Expert), Pandas (Proficient), Data Analysis (Expert), Statistical Design (Advanced), SQL (Expert) Contract Type: W2 Duration: 8 Months with possible extension Location: Seattle, WA (#LI-Hybrid) Pay Range: $70.00 - $80.00 Per Hour #LPJob Summary:Join client's Worldwide Sustainability (WWS) organization to play a pivotal role in achieving our ambition to become Earth's most sustainable company through innovation and technology. As a Senior Data Scientist within the Sustainability Science and Innovation (SSI) team, you will leverage cutting-edge data science, analytics, and machine learning to tackle complex sustainability challenges. Key Responsibilities:Develop advanced algorithms and models using Python, with a strong emphasis on the Pandas ecosystem for data manipulation.Ensure production-level code quality, incorporating code refactoring and Git version control.Conduct complex data analysis and statistical modeling, especially with unstructured, real-world datasets.Apply foundational statistical methods and experimental design to derive actionable insights.Handle SQL database querying and manipulation of large datasets, with a preference for those with time series forecasting experience. Must-Have Skills:5+ years experience as a data scientist with ability to translate complex analytical problems into practical solutionsProficient in Python, specifically with object-oriented programming.Extensive experience in production-level code development and version control.Strong capability in statistical modeling and data analysis with large, messy datasets. ABOUT AKRAYAAkraya is an award-winning IT staffing firm consistently recognized for our commitment toexcellence and a thriving work environment. Most recently, we were recognized Inc's Best Workplaces 2024 and Silicon Valley's Best Places to Work by the San Francisco Business Journal (2024) and Glassdoor's Best Places to Work (2023 & 2022)! Industry Leaders in IT Staffing As staffing solutions providers for Fortune 100 companies, Akraya's industry recognitions solidify our leadership position in the IT staffing space. We don't just connect you with great jobs, we connect you with a workplace that inspires! Join Akraya Today! Let us lead you to your dream career and experience the Akraya difference. Browse our open positions and join our team!",,2025-07-25,"['As a Senior Data Scientist within the Sustainability Science and Innovation (SSI) team, you will leverage cutting-edge data science, analytics, and machine learning to tackle complex sustainability challenges', 'Handle SQL database querying and manipulation of large datasets, with a preference for those with time series forecasting experience', 'Must-Have Skills:5+ years experience as a data scientist with ability to translate complex analytical problems into practical solutions', 'Proficient in Python, specifically with object-oriented programming', 'Extensive experience in production-level code development and version control', 'Strong capability in statistical modeling and data analysis with large, messy datasets']","['Key Responsibilities:Develop advanced algorithms and models using Python, with a strong emphasis on the Pandas ecosystem for data manipulation', 'Ensure production-level code quality, incorporating code refactoring and Git version control', 'Conduct complex data analysis and statistical modeling, especially with unstructured, real-world datasets', 'Apply foundational statistical methods and experimental design to derive actionable insights']",True,[],,"['Python', 'Pandas', 'Data Analysis', 'Statistical Modeling', 'SQL', 'Time-Series Forecasting', 'Git Version Control']","Python: Used for developing advanced algorithms and models, with emphasis on object-oriented programming and production-level code development.; Pandas: Utilized extensively for data manipulation within the Python ecosystem.; Data Analysis: Conduct complex data analysis on large, messy, and unstructured real-world datasets to derive actionable insights.; Statistical Modeling: Apply foundational statistical methods and experimental design to build models and extract insights from data.; SQL: Handle database querying and manipulation of large datasets, including those involving time series data.; Time-Series Forecasting: Preferred experience in forecasting using time series data to support sustainability challenges.; Git Version Control: Incorporate version control and code refactoring to ensure production-level code quality."
5Hm8PKlFOHNT-sUnAAAAAA==,Senior Analytics Data Engineer,"Additional Location(s): US-MN-Arden Hills

Diversity - Innovation - Caring - Global Collaboration - Winning Spirit - High Performance

At Boston Scientific, we’ll give you the opportunity to harness all that’s within you by working in teams of diverse and high-performing employees, tackling some of the most important health industry challenges. With access to the latest tools, information and training, we’ll help you in advancing your skills and career. Here, you’ll be supported in progressing – whatever your ambitions.

About the role:

We are seeking a Data Engineer to join our Cardiology Marketing & Digital Enablement (CMDE) team. In this role, you will help build a robust, business-focused data ecosystem that enables enhanced reporting, analytics, and AI-powered marketing. This position is crucial in transforming raw marketing, commercial, and healthcare data into curated, accessible datasets that fuel performance dashboards, audience targeting, campaign optimization, and AI marketing use cases.

Work Mode:

Boston Scientific follows a hybrid work model, requiring team members to be on-site at least three days per week to foster strong collaboration and synergy.

Your responsibilities will include:

Data Engineering & Transformation
• Design, build, and maintain scalable data models and transformation workflows using Snowflake, DBT, and SQL.
• Develop and manage business-ready datasets and data marts to support dashboards, performance tracking, AI/ML use cases, and marketing/commercial applications.
• Setup, monitor and validate data workflows to ensure accuracy, reliability, and timely delivery.
• Review code written by other team members, providing constructive feedback and ensuring adherence to quality standards.
• Guide and support team members, helping them improve their coding skills and understanding coding best practices.

Cross-Functional Collaboration
• Collaborate with Data Product Owners and Business Analysts to gather requirements, translate business needs into technical solutions, and prioritize work based on value and urgency.
• Serve as a data subject matter expert (SME) working directly with marketing, analytics, digital solutions, and commercial stakeholders to quickly assess and resolve data challenges.
• Proactively provide hands-on, responsive support to evolving data needs, from exploratory investigations to production-ready pipelines.

Documentation & Governance
• Maintain clear and thorough documentation for data logic, models, lineage, and workflows.
• Ensure all data processes align with internal governance standards, privacy requirements, and documentation protocols.

Advanced Analytics Support
• Enable and enhance AI-powered marketing initiatives, including lead scoring, real-time personalization, and optimization models by delivering clean, structured, and accessible data.

Required qualifications:
• 5+ years of professional experience in data engineering or a similar technical role focused on transforming and modeling data for business use.
• Expertise in SQL, with hands-on experience designing data models and transformation pipelines in Snowflake and DBT.
• Experience in integrating and transforming data from Salesforce.
• Proven ability to work collaboratively with cross-functional partners while operating independently as a data subject matter expert (SME).
• Strong problem-solving skills and ability to provide responsive, hands-on solutions to data-related questions and requests.
• Familiarity with working in regulated industries or with sensitive business data (e.g., healthcare, life sciences).

Preferred qualifications:
• Bachelor’s degree in information technology, Computer Science, Engineering, or a related field.
• Excellent communication and documentation skills.
• Experience with marketing data (e.g., campaign performance, lead funnel, audience segmentation, web/media analytics).
• Experience with healthcare claims and prescription data.
• Experience with Python for data transformation or workflow automation.
• Knowledge of BI tools (e.g., Tableau, Power BI) and enabling data for self-service use.
• Experience supporting AI/ML applications (e.g., lead scoring, predictive modeling, personalization).

Requisition ID: 608643

Minimum Salary: $ 82600

Maximum Salary: $ 156900

The anticipated compensation listed above and the value of core and optional employee benefits offered by Boston Scientific (BSC) – see www.bscbenefitsconnect.com--will vary based on actual location of the position and other pertinent factors considered in determining actual compensation for the role. Compensation will be commensurate with demonstrable level of experience and training, pertinent education including licensure and certifications, among other relevant business or organizational needs. At BSC, it is not typical for an individual to be hired near the bottom or top of the anticipated salary range listed above.

Compensation for non-exempt (hourly), non-sales roles may also include variable compensation from time to time (e.g., any overtime and shift differential) and annual bonus target (subject to plan eligibility and other requirements).

Compensation for exempt, non-sales roles may also include variable compensation, i.e., annual bonus target and long-term incentives (subject to plan eligibility and other requirements).

For MA positions: It is unlawful to require or administer a lie detector test for employment. Violators are subject to criminal penalties and civil liability.

As a leader in medical science for more than 40 years, we are committed to solving the challenges that matter most – united by a deep caring for human life. Our mission to advance science for life is about transforming lives through innovative medical solutions that improve patient lives, create value for our customers, and support our employees and the communities in which we operate. Now more than ever, we have a responsibility to apply those values to everything we do – as a global business and as a global corporate citizen.

So, choosing a career with Boston Scientific (NYSE: BSX) isn’t just business, it’s personal. And if you’re a natural problem-solver with the imagination, determination, and spirit to make a meaningful difference to people worldwide, we encourage you to apply and look forward to connecting with you!

At Boston Scientific, we recognize that nurturing a diverse and inclusive workplace helps us be more innovative and it is important in our work of advancing science for life and improving patient health. That is why we stand for inclusion, equality, and opportunity for all. By embracing the richness of our unique backgrounds and perspectives, we create a better, more rewarding place for our employees to work and reflect the patients, customers, and communities we serve.

Boston Scientific Corporation has been and will continue to be an equal opportunity employer. To ensure full implementation of its equal employment policy, the Company will continue to take steps to assure that recruitment, hiring, assignment, promotion, compensation, and all other personnel decisions are made and administered without regard to race, religion, color, national origin, citizenship, sex, sexual orientation, gender identify, gender expression, veteran status, age, mental or physical disability, genetic information or any other protected class.

Please be advised that certain US based positions, including without limitation field sales and service positions that call on hospitals and/or health care centers, require acceptable proof of COVID-19 vaccination status. Candidates will be notified during the interview and selection process if the role(s) for which they have applied require proof of vaccination as a condition of employment. Boston Scientific continues to evaluate its policies and protocols regarding the COVID-19 vaccine and will comply with all applicable state and federal law and healthcare credentialing requirements. As employees of the Company, you will be expected to meet the ongoing requirements for your roles, including any new requirements, should the Company’s policies or protocols change with regard to COVID-19 vaccination.

Among other requirements, Boston Scientific maintains specific prohibited substance test requirements for safety-sensitive positions. This role is deemed safety-sensitive and, as such, candidates will be subject to a prohibited substance test as a requirement. The goal of the prohibited substance testing is to increase workplace safety in compliance with the applicable law.",2025-06-29T00:00:00.000Z,2025-07-25,"['5+ years of professional experience in data engineering or a similar technical role focused on transforming and modeling data for business use', 'Expertise in SQL, with hands-on experience designing data models and transformation pipelines in Snowflake and DBT', 'Experience in integrating and transforming data from Salesforce', 'Proven ability to work collaboratively with cross-functional partners while operating independently as a data subject matter expert (SME)', 'Strong problem-solving skills and ability to provide responsive, hands-on solutions to data-related questions and requests', 'Familiarity with working in regulated industries or with sensitive business data (e.g., healthcare, life sciences)']","['In this role, you will help build a robust, business-focused data ecosystem that enables enhanced reporting, analytics, and AI-powered marketing', 'This position is crucial in transforming raw marketing, commercial, and healthcare data into curated, accessible datasets that fuel performance dashboards, audience targeting, campaign optimization, and AI marketing use cases', 'Boston Scientific follows a hybrid work model, requiring team members to be on-site at least three days per week to foster strong collaboration and synergy', 'Design, build, and maintain scalable data models and transformation workflows using Snowflake, DBT, and SQL', 'Develop and manage business-ready datasets and data marts to support dashboards, performance tracking, AI/ML use cases, and marketing/commercial applications', 'Setup, monitor and validate data workflows to ensure accuracy, reliability, and timely delivery', 'Review code written by other team members, providing constructive feedback and ensuring adherence to quality standards', 'Guide and support team members, helping them improve their coding skills and understanding coding best practices', 'Cross-Functional Collaboration', 'Collaborate with Data Product Owners and Business Analysts to gather requirements, translate business needs into technical solutions, and prioritize work based on value and urgency', 'Serve as a data subject matter expert (SME) working directly with marketing, analytics, digital solutions, and commercial stakeholders to quickly assess and resolve data challenges', 'Proactively provide hands-on, responsive support to evolving data needs, from exploratory investigations to production-ready pipelines', 'Documentation & Governance', 'Maintain clear and thorough documentation for data logic, models, lineage, and workflows', 'Ensure all data processes align with internal governance standards, privacy requirements, and documentation protocols', 'Advanced Analytics Support', 'Enable and enhance AI-powered marketing initiatives, including lead scoring, real-time personalization, and optimization models by delivering clean, structured, and accessible data']",False,,,,
kMUAZ8sBtdhk9a-cAAAAAA==,"Senior Data Scientist, Specialist Senior - SFL Scientific - Full-time","Senior Data Scientist, Specialist Senior - SFL Scientific

Our Deloitte Strategy & Transactions team helps guide clients through their most critical moments and transformational initiatives. From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability. Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journey-before, during, and after any major transformational projects or transactions.

SFL Scientific, a Deloitte Business, is a U.S. based, data science consulting firm specializing in building industry-specific, artificial intelligence (AI) technologies.

We are hiring a Senior Data Scientist to collaborate directly with clients to design and develop novel projects and solutions. Join a rapidly growing team of professionals working to build a world-class data science practice focused on solving complex and R&D problems.

Recruiting for this role ends on 7/31/2025.

Work You'll Do

As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services. You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions.

Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation. Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills.

+ Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production

+ Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives

+ Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization

+ Validate AI models and algorithm via code reviews, unit, and integration tests

+ Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives

+ Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives

The Team

Our Strategy offering architects bold strategies to achieve business and mission goals, enabling growth, competitive advantage, technology modernization, and continuous digital and AI transformation.

SFL Scientific, a Deloitte Business, is a data science professional services practice focused on strategy, technology, and solving business challenges with Artificial Intelligence (AI). The team has a proven track record serving large, market-leading organizations in the private and public sectors, successfully delivering high-quality, novel and complex projects, and offering deep domain and scientific capabilities. Made up of experienced AI strategists, data scientists, and AI engineers, they serve as trusted advisors to executives, helping them understand and evaluate new and essential areas for AI investment and identify unique opportunities to transform their businesses.

Qualifications:

+ Master's or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)

+ 3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)

+ 3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments

+ 3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow

+ 3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads

+ Live within commuting distance to one of Deloitte's consulting offices

+ Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve

+ Limited immigration sponsorship may be available

Preferred:

+ 2+ years of experience working in a client-facing, consulting environment

+ 2+ years of experience leading project/client engagement teams in the execution of complex AI data science solutions

+ 1+ year of experience with LLM/GenAI use cases and developing RAG solutions, tools, and services (i.e., LangChain, LangGraph, MCP, etc.)

+ 1+ year of experience with AWS Sagemaker or AWS ML Studio

Information for applicants with a need for accommodation: https://www2.deloitte.com/us/en/pages/careers/articles/join-deloitte-assistance-for-disabled-applicants.html

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $107,600 to $198,400.

You may also be eligible to participate in a discretionary annual incentive program, subject to the rules governing the program, whereby an award, if any, depends on various factors, including, without limitation, individual and organizational performance.

#MonitorDeloitte

#DeloitteJobs

#StrategyConsulting

#DeloitteStrategy

#Strategy26

#SFL26

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.

Senior Data Scientist, Specialist Senior - SFL Scientific

Our Deloitte Strategy & Transactions team helps guide clients through their most critical moments and transformational initiatives. From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability. Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journey-before, during, and after any major transformational projects or transactions.

SFL Scientific, a Deloitte Business, is a U.S. based, data science consulting firm specializing in building industry-specific, artificial intelligence (AI) technologies.

We are hiring a Senior Data Scientist to collaborate directly with clients to design and develop novel projects and solutions. Join a rapidly growing team of professionals working to build a world-class data science practice focused on solving complex and R&D problems.

Recruiting for this role ends on 7/31/2025.

Work You'll Do

As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services. You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions.

Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation. Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills.

+ Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production

+ Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives

+ Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization

+ Validate AI models and algorithm via code reviews, unit, and integration tests

+ Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives

+ Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives

The Team

Our Strategy offering architects bold strategies to achieve business and mission goals, enabling growth, competitive advantage, technology modernization, and continuous digital and AI transformation.

SFL Scientific, a Deloitte Business, is a data science professional services practice focused on strategy, technology, and solving business challenges with Artificial Intelligence (AI). The team has a proven track record serving large, market-leading organizations in the private and public sectors, successfully delivering high-quality, novel and complex projects, and offering deep domain and scientific capabilities. Made up of experienced AI strategists, data scientists, and AI engineers, they serve as trusted advisors to executives, helping them understand and evaluate new and essential areas for AI investment and identify unique opportunities to transform their businesses.

Qualifications:

+ Master's or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)

+ 3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)

+ 3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments

+ 3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow

+ 3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads

+ Live within commuting distance to one of Deloitte's consulting offices

+ Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve

+ Limited immigration sponsorship may be available

Preferred:

+ 2+ years of experience working in a client-facing, consulting environment

+ 2+ years of experience leading project/client engagement teams in the execution of complex AI data science solutions

+ 1+ year of experience with LLM/GenAI use cases and developing RAG solutions, tools, and services (i.e., LangChain, LangGraph, MCP, etc.)

+ 1+ year of experience with AWS Sagemaker or AWS ML Studio

Information for applicants with a need for accommodation: https://www2.deloitte.com/us/en/pages/careers/articles/join-deloitte-assistance-for-disabled-applicants.html

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $107,600 to $198,400.

You may also be eligible to participate in a discretionary annual incentive program, subject to the rules governing the program, whereby an award, if any, depends on various factors, including, without limitation, individual and organizational performance.

#MonitorDeloitte

#DeloitteJobs

#StrategyConsulting

#DeloitteStrategy

#Strategy26

#SFL26

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.",2025-07-25T02:00:00.000Z,2025-07-25,"[""Master's or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)"", '3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)', '3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments', '3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow', '3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads', ""Live within commuting distance to one of Deloitte's consulting offices"", 'Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve', 'Limited immigration sponsorship may be available', ""Master's or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)"", '3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)', '3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments', '3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow', '3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads', ""Live within commuting distance to one of Deloitte's consulting offices"", 'Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve', 'Limited immigration sponsorship may be available']","['From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability', 'Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journey-before, during, and after any major transformational projects or transactions', 'As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services', 'You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions', 'Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation', 'Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills', 'Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production', 'Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives', 'Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization', 'Validate AI models and algorithm via code reviews, unit, and integration tests', 'Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives', 'Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives', 'From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability', 'Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journey-before, during, and after any major transformational projects or transactions', 'As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services', 'You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions', 'Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation', 'Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills', 'Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production', 'Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives', 'Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization', 'Validate AI models and algorithm via code reviews, unit, and integration tests', 'Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives', 'Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives']",True,"['Deep Learning', 'PyTorch', 'Generative AI', 'Retrieval-Augmented Generation', 'Large Language Models', 'Prompt Engineering', 'AI Model Deployment and MLOps', 'Cloud AI Services']","Deep Learning: The position requires applying deep learning techniques including convolutional neural networks (CNNs), recurrent neural networks (RNNs), and generative adversarial networks (GANs) across real-world projects, including model tuning and performance validation in production.; PyTorch: PyTorch is used as a core framework for AI/ML algorithm development and deep learning model implementation in this role.; Generative AI: The job includes experience with generative AI use cases, specifically working with large language models (LLMs) and developing retrieval-augmented generation (RAG) solutions, tools, and services.; Retrieval-Augmented Generation: Experience developing RAG solutions and tools such as LangChain and LangGraph is required, supporting advanced AI applications involving LLMs.; Large Language Models: The role involves working with LLMs for generative AI use cases and AI service development.; Prompt Engineering: The job includes responsibilities related to prompt engineering as part of developing and deploying generative AI and LLM-based solutions.; AI Model Deployment and MLOps: Deploying and optimizing AI models using Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow is part of the role, with a focus on AI/ML workloads and production environments.; Cloud AI Services: Experience with cloud AI services such as AWS Sagemaker and AWS ML Studio is preferred for deploying and managing AI/ML workloads.","['Machine Learning', 'Data Analysis', 'Time-Series Analysis', 'Natural Language Processing', 'Computer Vision', 'Model Validation and Testing', 'Model Deployment and Optimization', 'Cloud Computing for AI/ML']","Machine Learning: The role involves developing AI/ML algorithms using core data science languages and frameworks, applying traditional machine learning techniques such as CNNs, RNNs, and GANs, and tuning and validating models in production environments.; Data Analysis: The job requires performing exploratory data analysis on client data sets to understand operational requirements and drive long-term solutions.; Time-Series Analysis: Experience with time-series analysis is required as part of the data analysis and AI/ML algorithm development responsibilities.; Natural Language Processing: The role includes experience with NLP as part of AI/ML algorithm development and data analysis.; Computer Vision: The job involves applying computer vision techniques as part of AI/ML algorithm development and data analysis.; Model Validation and Testing: Responsibilities include validating AI models and algorithms through code reviews, unit tests, and integration tests to ensure model performance and reliability.; Model Deployment and Optimization: The role requires deploying and optimizing machine learning models using tools such as Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow, and leveraging cloud environments like AWS, Azure, or GCP.; Cloud Computing for AI/ML: Experience in leveraging cloud platforms (AWS, Azure, GCP) to deploy AI/ML workloads is essential for the role."
KowIDlQ5DAMy2r0SAAAAAA==,"Senior Data Scientist, Pricing & Promotions","Are you a data-driven problem solver with a passion for pets? Do you thrive in a fast-paced and dynamic environment? Petco is looking for a Senior Data Scientist, Pricing & Promotions to join our team and drive impactful insights to optimize our pricing and promotions strategies. As a key member of our data science team, you will have the opportunity to make a significant impact on our business and help shape the future of the pet retail industry. If you have a strong background in data analysis, statistical modeling, and a knack for translating complex data into actionable business recommendations, we want to hear from you! Join us and use your expertise to help Petco continue to provide the best products and services for pet parents and their furry companions.

Conduct data analysis and develop statistical models to optimize pricing and promotions strategies for Petco.

Collaborate with cross-functional teams, including marketing, merchandising, and finance, to understand business objectives and provide data-driven recommendations.

Utilize data mining techniques to identify patterns and trends in customer behavior and purchasing habits.

Develop and maintain predictive models to forecast sales and evaluate the effectiveness of pricing and promotions strategies.

Communicate complex data and insights in a clear and concise manner to non-technical stakeholders.

Continuously monitor and analyze data to identify opportunities for improvement and provide proactive recommendations.

Stay current with industry trends and advancements in data science to drive innovation and improve processes.

Lead and mentor junior data scientists to support their professional growth and development.

Collaborate with IT teams to ensure data integrity and develop processes for data extraction and analysis.

Use advanced analytics techniques to develop pricing and promotions strategies for new products and services.

Petco is an Equal Opportunity Employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. We do not discriminate based upon race, religion, color, national origin, sex, sexual orientation, gender identity, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.",,2025-07-25,,"['If you have a strong background in data analysis, statistical modeling, and a knack for translating complex data into actionable business recommendations, we want to hear from you!', 'Join us and use your expertise to help Petco continue to provide the best products and services for pet parents and their furry companions', 'Conduct data analysis and develop statistical models to optimize pricing and promotions strategies for Petco', 'Collaborate with cross-functional teams, including marketing, merchandising, and finance, to understand business objectives and provide data-driven recommendations', 'Utilize data mining techniques to identify patterns and trends in customer behavior and purchasing habits', 'Develop and maintain predictive models to forecast sales and evaluate the effectiveness of pricing and promotions strategies', 'Communicate complex data and insights in a clear and concise manner to non-technical stakeholders', 'Continuously monitor and analyze data to identify opportunities for improvement and provide proactive recommendations', 'Stay current with industry trends and advancements in data science to drive innovation and improve processes', 'Lead and mentor junior data scientists to support their professional growth and development', 'Collaborate with IT teams to ensure data integrity and develop processes for data extraction and analysis', 'Use advanced analytics techniques to develop pricing and promotions strategies for new products and services']",True,[],,"['Data Analysis', 'Statistical Modeling', 'Data Mining', 'Predictive Modeling', 'Advanced Analytics', 'Data Communication', 'Data Integrity and Extraction Processes']","Data Analysis: Used to examine and interpret complex data sets to inform pricing and promotions strategies and provide actionable business recommendations.; Statistical Modeling: Applied to develop models that optimize pricing and promotions strategies and forecast sales performance.; Data Mining: Utilized to identify patterns and trends in customer behavior and purchasing habits to support strategic decision-making.; Predictive Modeling: Developed and maintained to forecast sales and evaluate the effectiveness of pricing and promotions strategies.; Advanced Analytics: Employed to create pricing and promotions strategies for new products and services, driving business innovation.; Data Communication: Involves translating complex data and insights into clear, concise information for non-technical stakeholders.; Data Integrity and Extraction Processes: Collaborated with IT teams to ensure data quality and develop processes for data extraction and analysis."
JsXfvWL8uZiXqvP5AAAAAA==,"Senior Data Scientist, Product Analytics","The core responsibilities of the Senior Data Scientist entail a collaborative engagement with key business units to elevate consumer engagement, and conversion rates, and streamline the consumer journey within our ecosystem. By spearheading initiatives to enhance the quality of clickstream tracking and performing in-depth analyses, the successful candidate will unlock new understandings and track shifts in consumer behavior. This role offers a unique opportunity to make a significant, swift impact within the company.

Working in concert with leaders from Product, Design, and Engineering, this role is instrumental in guiding http://Realtor.com ‘s strategic direction. The ideal candidate will have demonstrated success in utilizing web analytics and event tracking to navigate complex data landscapes, delivering insights that drive informed decision-making across the organization. Their mastery of data science and advanced analytics will be vital in distilling valuable information from extensive datasets. Moreover, we are searching for someone who can effectively influence executives and stakeholders, fostering a culture of disciplined achievement.

Candidates should be well-versed in areas such as clickstream tracking, optimizing consumer funnels, consumer analytics, segmentation, and the execution of A/B testing. Responsibilities will also include crafting tracking plans to bolster engagement, analyzing A/B testing results, spotting product development opportunities, dissecting consumer behavior, conducting thorough pre-post analyses, and precisely measuring and reporting performance metrics across http://Realtor.com ‘s consumer internet business segments.

What you’ll do:
• Support the Product team in accomplishing the goals and objectives of the Consumer internet businesses.
• Partner with the engineering and business intelligence teams to drive improvements to track and data quality.
• Conduct deep-dive analysis of complex datasets to understand product performance using statistical techniques, machine learning algorithms, and data visualization tools.
• Identify patterns, trends, and correlations in data to uncover actionable insights and provide recommendations for business improvement.
• Develop and monitor KPIs to drive high-level oversight of business initiatives and company health, and develop regular insights from the data to enable performance management and facilitate accountabilities
• Communicate findings and insights to technical and non-technical stakeholders through clear and compelling visualizations, reports, and presentations.
• Partner with the Product organization on data-driven decision-making, idea generation, and rigorous measurement.
• Lead exploratory analysis to identify and size product development opportunities to determine tradeoffs between product features that grow and optimize the product offering
• Guide and inform OKR development with product leadership.

How we work:

We balance creativity and innovation on a foundation of in-person collaboration. For most roles, our employees work three or more days in our offices, where they have the opportunity to collaborate in-person, adding richness to our culture and knitting us closer together.

What you’ll bring:
• Bachelor’s or Master’s degree with a focus in Analytics, Product Marketing, Statistics, Applied Math, Data Science, Economics, or a related field.
• 5+ years’ experience as a Data Analyst or similar role, with a focus on web analytics or data science
• Experience with designing and executing A/B testing experiments to evaluate the effectiveness of different strategies and interventions, analyzing the results to provide actionable insights and recommendations
• Strong analytical, critical thinking, decision-making, and problem-solving skills; Experience with Product Analytics a plus.
• Solid understanding of SQL and experience working with relational databases.
• Experience in digital tools, including Adobe Analytics, Google Analytics, and data visualization tools such as Tableau, Looker, or Power BI
• Proficiency in programming languages such as Python or R for data analysis and modeling.
• Proven track record of translating business problems into an analytical framework, developing plans for answering complex problems, and delivering analytic insights.
• Experience applying advanced analytic disciplines to financial, consumer audience/user experience, and product-level modeling, forecasting, marketing, etc.
• Strong communication and presentation skills, with the ability to convey complex ideas to both technical and non-technical stakeholders.
• Ability to remain flexible and thrive in a fast-paced and often hectic environment

Do the best work of your life at Realtor.com

Building your career? Build it better at Realtor.com®. Here, you’ll partner with a diverse team of experts as you use leading-edge tech to empower everyone to meet a crucial goal: finding their way home. And you’ll find your way home too. People are our foundation—the core that drives us passionately forward. At Realtor.com, you’ll bring your full self to work as you innovate with speed, serve our consumers, and champion your teammates. In return we’ll provide you with a warm, welcoming, and inclusive culture; intellectual challenges; and the development opportunities you need to grow.

Do the best work of your life at Realtor.com®

Here, you’ll partner with a diverse team of experts as you use leading-edge tech to empower everyone to meet a crucial goal: finding their way home. And you’ll find your way home too. People are our foundation—the core that drives us passionately forward. At Realtor.com®, you’ll bring your full self to work as you innovate with speed, serve our consumers, and champion your teammates. In return we’ll provide you with a warm, welcoming, and inclusive culture; intellectual challenges; and the development opportunities you need to grow.",,2025-07-25,"['Bachelor’s or Master’s degree with a focus in Analytics, Product Marketing, Statistics, Applied Math, Data Science, Economics, or a related field', '5+ years’ experience as a Data Analyst or similar role, with a focus on web analytics or data science', 'Experience with designing and executing A/B testing experiments to evaluate the effectiveness of different strategies and interventions, analyzing the results to provide actionable insights and recommendations', 'Solid understanding of SQL and experience working with relational databases', 'Experience in digital tools, including Adobe Analytics, Google Analytics, and data visualization tools such as Tableau, Looker, or Power BI', 'Proficiency in programming languages such as Python or R for data analysis and modeling', 'Proven track record of translating business problems into an analytical framework, developing plans for answering complex problems, and delivering analytic insights', 'Experience applying advanced analytic disciplines to financial, consumer audience/user experience, and product-level modeling, forecasting, marketing, etc', 'Strong communication and presentation skills, with the ability to convey complex ideas to both technical and non-technical stakeholders', 'Ability to remain flexible and thrive in a fast-paced and often hectic environment']","['The core responsibilities of the Senior Data Scientist entail a collaborative engagement with key business units to elevate consumer engagement, and conversion rates, and streamline the consumer journey within our ecosystem', 'By spearheading initiatives to enhance the quality of clickstream tracking and performing in-depth analyses, the successful candidate will unlock new understandings and track shifts in consumer behavior', 'This role offers a unique opportunity to make a significant, swift impact within the company', 'Working in concert with leaders from Product, Design, and Engineering, this role is instrumental in guiding http://Realtor.com ‘s strategic direction', 'The ideal candidate will have demonstrated success in utilizing web analytics and event tracking to navigate complex data landscapes, delivering insights that drive informed decision-making across the organization', 'Their mastery of data science and advanced analytics will be vital in distilling valuable information from extensive datasets', 'Candidates should be well-versed in areas such as clickstream tracking, optimizing consumer funnels, consumer analytics, segmentation, and the execution of A/B testing', 'Responsibilities will also include crafting tracking plans to bolster engagement, analyzing A/B testing results, spotting product development opportunities, dissecting consumer behavior, conducting thorough pre-post analyses, and precisely measuring and reporting performance metrics across http://Realtor.com ‘s consumer internet business segments', 'Support the Product team in accomplishing the goals and objectives of the Consumer internet businesses', 'Partner with the engineering and business intelligence teams to drive improvements to track and data quality', 'Conduct deep-dive analysis of complex datasets to understand product performance using statistical techniques, machine learning algorithms, and data visualization tools', 'Identify patterns, trends, and correlations in data to uncover actionable insights and provide recommendations for business improvement', 'Develop and monitor KPIs to drive high-level oversight of business initiatives and company health, and develop regular insights from the data to enable performance management and facilitate accountabilities', 'Communicate findings and insights to technical and non-technical stakeholders through clear and compelling visualizations, reports, and presentations', 'Partner with the Product organization on data-driven decision-making, idea generation, and rigorous measurement', 'Lead exploratory analysis to identify and size product development opportunities to determine tradeoffs between product features that grow and optimize the product offering', 'Guide and inform OKR development with product leadership']",True,[],,"['Clickstream Tracking', 'Consumer Analytics', 'A/B Testing', 'SQL', 'Python', 'R', 'Web Analytics Tools', 'Data Visualization Tools', 'Statistical Techniques', 'Machine Learning Algorithms', 'KPI Development and Monitoring', 'Segmentation', 'Pre-Post Analysis', 'Product-Level Modeling and Forecasting']","Clickstream Tracking: Used to enhance the quality of tracking user interactions on the website to analyze consumer behavior and improve engagement and conversion rates.; Consumer Analytics: Applied to dissect consumer behavior, optimize consumer funnels, and segment users to drive product and business improvements.; A/B Testing: Designing, executing, and analyzing experiments to evaluate the effectiveness of different strategies and interventions, providing actionable insights and recommendations.; SQL: Used for querying and working with relational databases to extract and manipulate data for analysis.; Python: Utilized for data analysis and modeling, including applying statistical techniques and machine learning algorithms to complex datasets.; R: Used for data analysis and modeling tasks, supporting statistical and advanced analytic disciplines.; Web Analytics Tools: Experience with tools such as Adobe Analytics and Google Analytics to track and analyze web and event data for product and consumer insights.; Data Visualization Tools: Use of Tableau, Looker, or Power BI to create clear and compelling visualizations, reports, and presentations for communicating findings to stakeholders.; Statistical Techniques: Applied to analyze complex datasets, identify patterns, trends, and correlations to uncover actionable insights for business improvement.; Machine Learning Algorithms: Used to understand product performance and support advanced analytics for predictive modeling and insights generation.; KPI Development and Monitoring: Developing and tracking key performance indicators to oversee business initiatives, measure company health, and enable performance management.; Segmentation: Dividing consumer data into meaningful groups to better understand behavior and tailor product strategies.; Pre-Post Analysis: Conducting analyses before and after interventions or changes to measure impact and effectiveness.; Product-Level Modeling and Forecasting: Applying advanced analytic disciplines to model and forecast product performance and marketing outcomes."
cREQcTyFGDviP22PAAAAAA==,Senior Data Engineer,"EquipmentShare is Hiring a Senior Data Engineer.
Your role in our team

At EquipmentShare, we believe it’s more than just a job. We invest in our people and encourage you to choose the best path for your career. It’s truly about you, your future, and where you want to go.

We are looking for a Senior Data Engineer to help us continue to build the next evolution of our data platform in a scalable, performant, and customer-centric architecture.

Our main tech stack includes Snowflake, Apache Airflow, AWS cloud infrastructure (e.g., Kinesis, Kubernetes/EKS, Lambda, Aurora RDS PostgreSQL), Python and Typescript.
What you'll be doing

We are typically organized into agile cross-functional teams composed of Engineering, Product, and Design, which allows us to develop deep expertise and rapidly deliver high-value features and functionality to our next-generation T3 Platform.

You’ll be part of a close-knit team of data engineers developing and maintaining a data platform built with automation and self-service in mind to support analytics and machine learning data products for the next generation of our T3 Fleet that enable end-users to track, monitor and manage the health of their connected vehicles and deployed assets.

We'll be there to support you as you become familiar with our teams, product domains, tech stack and processes — generally how we all work together.

Primary responsibilities for a Senior Data Engineer
• Collaborate with Product Managers, Designers, Engineers, Data Scientists and Data Analysts to take ideas from concept to production at scale.
• Design, build and maintain our data platform to enable automation and self-service for data scientists, machine learning engineers and analysts.
• Design, build and maintain data product framework to support EquipmentShare application data science and analytics features.
• Design, build and maintain CI/CD pipelines and automated data and machine learning deployment processes.
• Develop data monitoring and alerting capabilities.
• Document architecture, processes and procedures for knowledge sharing and cross-team collaboration.
• Mentor peers to help them build their skills.
Why We’re a Better Place to Work

We can promise that every day will be a little different with new ideas, challenges and rewards.

We’ve been growing as a team and we are not finished just yet— there is plenty of opportunity to shape how we deliver together.

Our mission is to enable the construction industry with tools that unlock substantial increases to productivity. Together with our team and customers, we are building the future of construction.

T3 is the only cloud-based operating system that brings together construction workflows & data from constantly moving elements in one place.
• Competitive base salary and market leading equity package.
• Unlimited PTO.
• Remote first.
• True work/life balance.
• Medical, Dental, Vision and Life Insurance coverage.
• 401(k) + match.
• Opportunities for career and professional development with conferences, events, seminars and continued education.
• On-site fitness center at the Home Office in Columbia, Missouri, complete with weightlifting machines, cardio equipment, group fitness space, racquetball courts, a climbing wall, and much more!
• Volunteering and local charity support that help you nurture and grow the communities you call home through our Giving Back initiative.
• Stocked breakroom and full kitchen with breakfast and lunch provided daily by our chef and kitchen crew.
About You

You're a hands-on developer who enjoys solving complex problems and building impactful solutions. Most importantly, you care about making a difference.
• Take the initiative to own outcomes from start to finish — knowing what needs to be accomplished within your domain and how we work together to deliver the best solution.
• You are passionate about developing your craft — you understand what it takes to build quality, robust and scalable solutions.
• You’ll see the learning opportunity when things don’t quite go to plan — not only for you but for how we continuously improve as a team.
• You take a hypothesis-driven approach — knowing how to source, create and leverage data to inform decision making, using data to drive how we improve, to shape how we evaluate and make platform recommendations.
So, what is important to us?

Above all, you’ll get stuff done. More importantly, you’ll collaborate to do the right things in the right way to achieve the right outcomes.
• 7+ years of relevant data platform development experience building production-grade solutions.
• Proficient with SQL and a high-order object-oriented language (e.g., Python).
• Experience with designing and building distributed data architecture.
• Experience building and managing production-grade data pipelines using tools such as Airflow, dbt, DataHub, MLFlow
• Experience building and managing production-grade data platforms using distributed systems such as Kafka, Spark, Flink and/or others.
• Familiarity with event data streaming at scale.
• Proven track record learning new technologies and applying that learning quickly.
• Experience building observability and monitoring into data products.
• Motivated to identify opportunities for automation to reduce manual toil.

EquipmentShare is committed to a diverse and inclusive workplace. EquipmentShare is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status.

#LI-Remote",,2025-07-25,"[""You're a hands-on developer who enjoys solving complex problems and building impactful solutions"", 'Take the initiative to own outcomes from start to finish — knowing what needs to be accomplished within your domain and how we work together to deliver the best solution', 'You are passionate about developing your craft — you understand what it takes to build quality, robust and scalable solutions', 'You’ll see the learning opportunity when things don’t quite go to plan — not only for you but for how we continuously improve as a team', 'You take a hypothesis-driven approach — knowing how to source, create and leverage data to inform decision making, using data to drive how we improve, to shape how we evaluate and make platform recommendations', '7+ years of relevant data platform development experience building production-grade solutions', 'Proficient with SQL and a high-order object-oriented language (e.g., Python)', 'Experience with designing and building distributed data architecture', 'Experience building and managing production-grade data pipelines using tools such as Airflow, dbt, DataHub, MLFlow', 'Experience building and managing production-grade data platforms using distributed systems such as Kafka, Spark, Flink and/or others', 'Familiarity with event data streaming at scale', 'Experience building observability and monitoring into data products', 'Motivated to identify opportunities for automation to reduce manual toil']","['We are typically organized into agile cross-functional teams composed of Engineering, Product, and Design, which allows us to develop deep expertise and rapidly deliver high-value features and functionality to our next-generation T3 Platform', 'You’ll be part of a close-knit team of data engineers developing and maintaining a data platform built with automation and self-service in mind to support analytics and machine learning data products for the next generation of our T3 Fleet that enable end-users to track, monitor and manage the health of their connected vehicles and deployed assets', ""We'll be there to support you as you become familiar with our teams, product domains, tech stack and processes — generally how we all work together"", 'Primary responsibilities for a Senior Data Engineer', 'Collaborate with Product Managers, Designers, Engineers, Data Scientists and Data Analysts to take ideas from concept to production at scale', 'Design, build and maintain our data platform to enable automation and self-service for data scientists, machine learning engineers and analysts', 'Design, build and maintain data product framework to support EquipmentShare application data science and analytics features', 'Design, build and maintain CI/CD pipelines and automated data and machine learning deployment processes', 'Develop data monitoring and alerting capabilities', 'Document architecture, processes and procedures for knowledge sharing and cross-team collaboration', 'Mentor peers to help them build their skills', 'Volunteering and local charity support that help you nurture and grow the communities you call home through our Giving Back initiative', 'Stocked breakroom and full kitchen with breakfast and lunch provided daily by our chef and kitchen crew', 'More importantly, you’ll collaborate to do the right things in the right way to achieve the right outcomes', 'Proven track record learning new technologies and applying that learning quickly']",False,,,,
X_SgGUG8WLfcAwggAAAAAA==,"Senior Data Scientist - Retail Analytics/IT (Preferred-Austin, MN)","Job Description

SENIOR DATA SCIENTIST -RETAIL - INFORMATION TECHNOLOGY SERVICES - FLEXIBLE LOCATION - (AUSTIN, MN; WILLMAR, MN; EDEN PRAIRIE, MN; OR CHICAGO, IL)

To save time applying, Hormel Foods does not offer sponsorship of job applicants for employment-based visas for this position at this time.

Hormel Foods Corporation

ABOUT HORMEL FOODS - Inspired People. Inspired Food.™

Hormel Foods Corporation, based in Austin, Minnesota, is a global branded food company with over $12 billion in annual revenue across more than 80 countries worldwide. Its brands include Planters®, Skippy®, SPAM®, Hormel® Natural Choice®, Applegate®, Justin's®, Wholly®, Hormel® Black Label®, Columbus®, Jennie-O® and more than 30 other beloved brands. The company is a member of the S&P 500 Index and the S&P 500 Dividend Aristocrats, was named one of the best companies to work for by U.S. News & World Report, one of America's most responsible companies by Newsweek, recognized on Fast Company's list of the 100 Best Workplaces for Innovators, received a perfect score of 100 on the 2023-24 Corporate Equality Index and has received numerous other awards and accolades for its corporate responsibility and community service efforts. The company lives by its purpose statement - Inspired People. Inspired Food.™ - to bring some of the world's most trusted and iconic brands to tables across the globe. For more information, visit hormelfoods.com.

What You Will Do

As a Senior Data Scientist supporting our Retail Business Unit, you'll lead the development of advanced analytics solutions that improve how we partner with retailers and deliver value to consumers. You'll work cross-functionally to solve complex challenges in areas like demand forecasting, promotion optimization, and retail execution.
• Design, develop, and scale predictive and prescriptive models that support retail strategy and execution.
• Collaborate with sales, marketing, supply chain, and IT to identify high-impact analytics opportunities.
• Translate complex data into actionable insights and compelling visual stories for business stakeholders.
• Mentor and lead junior data scientists and foster a culture of innovation and continuous learning.
• Work with tools like Python, Google BigQuery, Oracle, Tableau, and Power BI to build scalable, production-ready solutions.

What You Bring

Required:
• Bachelor's degree in Data Science, Mathematics, Computer Science, or a related field.
• 7+ years of experience in data science, including model development and deployment.
• Strong programming skills and experience with large-scale data environments.
• Proven ability to translate business needs into data-driven solutions, especially in a CPG or retail context.
• Excellent communication and storytelling skills.
• Must be a Citizen or National of the United States, a lawful, permanent resident, or have authorization to work in the United States.
• Applicants must not now, or any time in the future, require sponsorship for an employment visa.

Preferred:
• Master's degree in a quantitative field.
• Experience with Google Cloud Platform and Oracle databases.
• Familiarity with Python IDEs (e.g., PyCharm, Jupyter, Anaconda).
• Experience developing production-grade machine learning models.
• Proficiency in data visualization tools like Tableau or Power BI.
• Experience working with syndicated retail data (e.g., Nielsen, Circona) or POS data

BENEFITS: Hormel Foods offers an excellent benefits package. Competitive base salary plus target incentive, discretionary annual merit increase, annual performance review, medical, dental, vision, non-contributory pension, profit sharing, 401(k) immediate eligible, stock purchase plan, relocation assistance, paid personal time (PTO), FREE two-year community/technical college tuition for children of employees, and more.

Ready to Make a Difference?

Join a company where your work will directly impact how millions of people experience our trusted brands. Apply today and help us continue our journey of Inspired People. Inspired Food.™

At Hormel Foods, base pay is one part of our total compensation package and is determined within a range. The base hiring pay range for this role is between $117,000 - $164,000 per year, and your actual base pay within that range will depend upon a variety of factors including, but not limited to, job-related knowledge, skill set, level of experience, and geographic market location.

At Hormel we invite difference and diversity in all aspects. We offer a space of support, understanding, and community. We are committed to the journey! Learn more about our progress here: https://www.hormelfoods.com/about/diversity-and-inclusion/

Hormel Foods Corporation is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status.",,2025-07-25,"[""Bachelor's degree in Data Science, Mathematics, Computer Science, or a related field"", '7+ years of experience in data science, including model development and deployment', 'Strong programming skills and experience with large-scale data environments', 'Proven ability to translate business needs into data-driven solutions, especially in a CPG or retail context', 'Excellent communication and storytelling skills', 'Must be a Citizen or National of the United States, a lawful, permanent resident, or have authorization to work in the United States', 'Applicants must not now, or any time in the future, require sponsorship for an employment visa']","[""As a Senior Data Scientist supporting our Retail Business Unit, you'll lead the development of advanced analytics solutions that improve how we partner with retailers and deliver value to consumers"", ""You'll work cross-functionally to solve complex challenges in areas like demand forecasting, promotion optimization, and retail execution"", 'Design, develop, and scale predictive and prescriptive models that support retail strategy and execution', 'Collaborate with sales, marketing, supply chain, and IT to identify high-impact analytics opportunities', 'Translate complex data into actionable insights and compelling visual stories for business stakeholders', 'Mentor and lead junior data scientists and foster a culture of innovation and continuous learning', 'Work with tools like Python, Google BigQuery, Oracle, Tableau, and Power BI to build scalable, production-ready solutions']",True,[],,"['Predictive and Prescriptive Modeling', 'Demand Forecasting', 'Promotion Optimization', 'Retail Execution Analytics', 'Data Visualization Tools', 'Python Programming', 'Big Data Platforms', 'Syndicated Retail Data', 'Model Development and Deployment']","Predictive and Prescriptive Modeling: Design, develop, and scale predictive and prescriptive models that support retail strategy and execution, including demand forecasting and promotion optimization.; Demand Forecasting: Solve complex challenges related to predicting future retail demand to improve business planning and execution.; Promotion Optimization: Develop analytics solutions to optimize retail promotions for better consumer engagement and sales performance.; Retail Execution Analytics: Apply advanced analytics to improve how the company partners with retailers and delivers value to consumers through retail execution strategies.; Data Visualization Tools: Use Tableau and Power BI to translate complex data into actionable insights and compelling visual stories for business stakeholders.; Python Programming: Utilize Python programming skills and IDEs such as PyCharm, Jupyter, and Anaconda to build scalable, production-ready data science solutions.; Big Data Platforms: Work with large-scale data environments including Google BigQuery and Oracle databases to manage and analyze retail and syndicated data.; Syndicated Retail Data: Experience working with syndicated retail data sources like Nielsen and Circona, as well as point-of-sale (POS) data, to inform analytics and modeling.; Model Development and Deployment: Develop and deploy production-grade machine learning models to support retail business needs and strategies."
q-70EhlU6v2jLM4bAAAAAA==,Sr. Data Scientist (Operations Research),"EquipmentShare is Hiring a Data Scientist (Operations Research).

EquipmentShare is searching for a Sr Data Scientist specializing in Operations Research (OR) to join our team. This position is fully remote.
Primary Responsibilities

Despite having been fundamentally altered by earlier industrial revolutions, the construction industry has hardly budged with the computer revolution. In fact, since 1970, labor productivity in the US construction industry has actually declined, despite it more than doubling in the rest of the economy. This has contributed to housing shortages and the parlous state of infrastructure in some places, and is sanding the gears of carbon reduction efforts.

We think the industry is ripe for change, and we're pushing the leading edge of that change with our next generation T3 Platform, the OS for Construction. Through T3, we help contractors to coordinate humans and (increasingly smarter) machines to build more effectively.

As a Sr Data Scientist specialized in OR in our small and quickly growing team, you will play a major role in this effort. In particular, you will
• Create and enhance fleet management practices across the company through analytical
techniques
• Develop, from scratch, simulation experiments that lead to implemented optimization
algorithms to solve our complex supply chain problems
• Assist in identifying key KPIs and metrics to measure our company's supply chain
effectiveness
• Help to identify the highest value next opportunities for OR within a big greenfield space,
work cross-functionally to plan and build, and measure your significant business impact
via experimentation
Why We're a Better Place to Work
• Competitive compensation packages
• 401 (k) and company match
• Health insurance and medical coverage benefits
• Unlimited paid time off
• Generous paid parental leave
• Volunteering and local charity initiatives that help you nurture and grow the communities you call home
• Stocked breakroom and full kitchen (corporate HQ)
• State of the art onsite gym (corporate HQ)/Gym stipend for remote employees
• Opportunities for career and professional development with conferences, events, seminars, continued education
About You

Our mission to change an entire industry is not easily achieved, so we only hire people who are inspired by the goal and up for the challenge. In turn, our employees have every opportunity to grow with us, achieve personal and professional success and enjoy making a tangible difference in an industry that's long been resistant to change.
Skills & Qualifications

Minimum Qualifications:
• Graduate degree or equivalent practical experience in statistics, computer science,
applied math, operations research or related field
• 4+ years working on technology-powered products and projects within the OR, supply
chain optimization, or data science roles
• Demonstrated understanding of the techniques and methods of modern algorithm
development
• Strong cross-functional communication skills
• Must be qualified to work in the United States - we are not sponsoring any candidates at
this time

EquipmentShare is committed to a diverse and inclusive workplace. EquipmentShare is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status.

#LI-Remote",,2025-07-25,"['Help to identify the highest value next opportunities for OR within a big greenfield space,', 'Graduate degree or equivalent practical experience in statistics, computer science,', 'applied math, operations research or related field', '4+ years working on technology-powered products and projects within the OR, supply', 'chain optimization, or data science roles', 'Demonstrated understanding of the techniques and methods of modern algorithm', 'Strong cross-functional communication skills', 'Must be qualified to work in the United States - we are not sponsoring any candidates at']","['This position is fully remote', 'Create and enhance fleet management practices across the company through analytical', 'Develop, from scratch, simulation experiments that lead to implemented optimization', 'algorithms to solve our complex supply chain problems', ""Assist in identifying key KPIs and metrics to measure our company's supply chain"", 'work cross-functionally to plan and build, and measure your significant business impact']",True,[],,"['Operations Research', 'Supply Chain Optimization', 'Simulation Experiments', 'Optimization Algorithms', 'Analytical Techniques', 'Key Performance Indicators (KPIs)', 'Algorithm Development', 'Statistics']","Operations Research: Used to develop and implement optimization algorithms and simulation experiments to solve complex supply chain problems and improve fleet management practices.; Supply Chain Optimization: Focuses on identifying key performance indicators and metrics to measure supply chain effectiveness and applying analytical techniques to enhance operational efficiency.; Simulation Experiments: Developed from scratch to model and analyze supply chain scenarios, leading to the creation of optimization algorithms.; Optimization Algorithms: Designed and implemented to address complex supply chain challenges and improve operational decision-making.; Analytical Techniques: Applied to create and enhance fleet management practices and to identify high-value opportunities within operations research.; Key Performance Indicators (KPIs): Assisted in identifying and measuring metrics to evaluate the effectiveness of the company's supply chain.; Algorithm Development: Demonstrated understanding of modern algorithm development techniques and methods relevant to operations research and data science.; Statistics: Utilized as a foundational skill in analyzing data and supporting operations research and supply chain optimization efforts."
36sWFGTvdmvx5R7lAAAAAA==,Senior Data Scientist/Applied Scientist/ AI Products,"At Attentive, we're revolutionizing the way businesses connect with their customers. Our AI-driven marketing platform infuses intelligence into every stage of the consumer journey, helping brands deliver hyper-personalized messages at scale. With a mobile-first approach, engaging two-way conversations, and enterprise-grade technology, we're driving billions in online revenue for leading brands worldwide, including CB2, Urban Outfitters, GUESS, Long John Silver’s, and Wyndham Resort. But we're not just about SMS and email—by expanding our AI capabilities to enhance multiple products and channels, our goal is to help make every interaction more meaningful. As a member of our team, you'll be at the forefront of this innovation, helping to shape the future of customer communication.

Attentive’s growth has been recognized by Deloitte’s Fast 500, Linkedin’s Top Startups and Forbes Cloud 100 all thanks to the hard work from our global employees!

Who we are

Have you ever received text message marketing from your favorite brand? Did you know that effective text message marketing is by far the highest ROI marketing channel? And, did you know that customers are increasingly preferring to interact with brands through text? Now you understand our impact at Attentive. We help the world’s largest brands send 100 to 500 million messages per day, approaching 100 billion per year.

Our Data Science team is a world-class data, applied science, and ML organization that leads data-driven decision-making and the conversational AI efforts for the entire company. Joining our team offers a hockey-stick career opportunity to work with some of the world’s top data scientists in a high-performance and high-impact culture.

As a Senior Data Scientist on our AI team, you will play a crucial role in transforming data into actionable insights and models for our AI product offerings. We are looking for an experienced scientist who relishes the opportunity to develop novel approaches and apply them at Attentive’s scale. Your contributions will directly influence the development of cutting-edge ML solutions, empowering our team to craft highly effective messaging strategies.

What You'll Do
• Lead the development of statistical, econometric, optimization, and machine learning models for a range of applications in our messaging and AI product offerings.
• Design and execute experiments, interpret results, and draw actionable conclusions.
• Use data to understand product performance, identify improvement opportunities, and define product/team roadmaps.
• Present findings to senior leadership to inform and influence business decisions.
• Collaborate with cross-functional teams across product, engineering, customer success, and sales to drive business value from ideation to production.
Basic Qualifications
• Ph.D., M.S. or Bachelors degree in Statistics, Economics, Machine Learning, Operations Research, or other quantitative fields.
• Knowledge of underlying mathematical foundations of statistics, machine learning, optimization, economics, and analytics.
• Knowledge of experimental design and analysis.
• Experience with exploratory data analysis, statistical analysis and testing, and model development.
• Ability to use Python to work efficiently at scale with large data sets.
• Advanced proficiency in SQL.
Preferred Qualifications
• 4+ years of industry experience as an Applied or Data Scientist or equivalent.
• Experience in customer lifetime value modeling.
• Experience in personalization systems and cross-sectional cohort modeling.
• Experience with ads delivery and optimization systems.
• Experience with implementing insights into customer success recommendations.
• Experience with productionizing algorithms for real-time systems.
• Well-honed communication and presentation skills.
• Experience presenting findings to senior management to inform business decisions.
• Strong product and customer-oriented intuition

You'll get competitive perks and benefits, from health & wellness to equity, to help you bring your best self to work.

For US based applicants:

- The US base salary range for this full-time position is $200,000 - $280,000 annually + equity + benefits

- Our salary ranges are determined by role, level and location

#LI-MDK1

Attentive Company Values

Default to Action - Move swiftly and with purpose

Be One Unstoppable Team - Rally as each other’s champions

Champion the Customer - Our success is defined by our customers' success

Act Like an Owner - Take responsibility for Attentive’s success

Learn more about AWAKE, Attentive’s collective of employee resource groups.

If you do not meet all the requirements listed here, we still encourage you to apply! No job description is perfect, and we may also have another opportunity that closely matches your skills and experience.

At Attentive, we know that our Company's strength lies in the diversity of our employees. Attentive is an Equal Opportunity Employer and we welcome applicants from all backgrounds. Our policy is to provide equal employment opportunities for all employees, applicants and covered individuals regardless of protected characteristics. We prioritize and maintain a fair, inclusive and equitable workplace free from discrimination, harassment, and retaliation. Attentive is also committed to providing reasonable accommodations for candidates with disabilities. If you need any assistance or reasonable accommodations, please let your recruiter know.

Original job Senior Data Scientist/Applied Scientist/ AI Products posted on GrabJobs ©. To flag any issues with this job please use the Report Job button on GrabJobs.",2025-07-14T00:00:00.000Z,2025-07-25,"['Ph.D., M.S. or Bachelors degree in Statistics, Economics, Machine Learning, Operations Research, or other quantitative fields', 'Knowledge of underlying mathematical foundations of statistics, machine learning, optimization, economics, and analytics', 'Knowledge of experimental design and analysis', 'Experience with exploratory data analysis, statistical analysis and testing, and model development', 'Ability to use Python to work efficiently at scale with large data sets', 'Advanced proficiency in SQL']","['Lead the development of statistical, econometric, optimization, and machine learning models for a range of applications in our messaging and AI product offerings', 'Design and execute experiments, interpret results, and draw actionable conclusions', 'Use data to understand product performance, identify improvement opportunities, and define product/team roadmaps', 'Present findings to senior leadership to inform and influence business decisions', 'Collaborate with cross-functional teams across product, engineering, customer success, and sales to drive business value from ideation to production', 'Default to Action - Move swiftly and with purpose', 'Be One Unstoppable Team - Rally as each other’s champions', 'Act Like an Owner - Take responsibility for Attentive’s success']",True,['AI Product Development'],AI Product Development: Lead the development of AI-driven product offerings that enhance messaging strategies and customer communication.,"['Statistical Modeling', 'Econometric Modeling', 'Optimization Models', 'Machine Learning Models', 'Experimental Design and Analysis', 'Exploratory Data Analysis', 'Statistical Analysis and Testing', 'Python Programming', 'SQL', 'Customer Lifetime Value Modeling', 'Personalization Systems', 'Ads Delivery and Optimization Systems', 'Productionizing Algorithms']","Statistical Modeling: Lead the development of statistical models to analyze and predict outcomes relevant to messaging and AI product offerings.; Econometric Modeling: Develop econometric models to understand economic relationships and optimize messaging strategies within AI products.; Optimization Models: Create optimization models to improve messaging delivery and AI product performance.; Machine Learning Models: Design and implement machine learning models to support AI product offerings and enhance messaging strategies.; Experimental Design and Analysis: Design and execute experiments, interpret results, and draw actionable conclusions to improve product performance and inform business decisions.; Exploratory Data Analysis: Perform exploratory data analysis to understand data characteristics and identify opportunities for model development and product improvement.; Statistical Analysis and Testing: Conduct statistical analysis and hypothesis testing to validate models and support data-driven decision-making.; Python Programming: Use Python to efficiently process and analyze large datasets at scale for model development and data insights.; SQL: Utilize advanced SQL skills to query and manipulate large datasets for analysis and model input.; Customer Lifetime Value Modeling: Develop models to estimate and predict customer lifetime value to inform personalization and marketing strategies.; Personalization Systems: Work on personalization systems and cross-sectional cohort modeling to tailor messaging and improve customer engagement.; Ads Delivery and Optimization Systems: Apply modeling techniques to optimize ad delivery and improve marketing campaign effectiveness.; Productionizing Algorithms: Implement and deploy algorithms into real-time systems to support scalable AI product functionalities."
iipKSv4Wf8c_UHL9AAAAAA==,Sr. Data Scientist,"Overview

One Trajector. One Mission.

Trajector is where purpose meets progress. We specialize in medical evidence services that become the compass our clients rely on while navigating the intricate terrain of disability benefits. Our calling is clear: to make a real difference, infuse passion, and enhance the quality of life for the disabled community. As part of our global community, you'll join a team of over 1,800 dedicated individuals, each contributing their unique talents to streamline the path to benefits. Urgency propels us, data empowers us, and every step is tailored to ensure those with disabilities access their rightful compensation. Join us in shaping stories of transformation, one life at a time.

Job Overview

The AI/ML team at Trajector builds and productionizes NLP solutions that extract and utilize relevant information from unstructured text and audio to build efficient business solutions. We are seeking a highly experienced Staff Data Scientist specializing in Natural Language Processing (NLP) to lead the development and optimization of state-of-the-art NLP systems for medical and legal documents processing, management and creation. The ideal candidate will have 8-10 years of relevant experience in data science, machine learning, and NLP, with a strong track record of delivering impactful solutions in complex, domain-specific contexts.

About Our Perks, Compensation, & Benefits
• Competitive compensation ranging from $160,000 - $175,000 per year with total compensation ranging from $180,000 - $197,000.
• Medical, dental, vision, 401k program, and more
• Paid time off, including seven (7) federal holidays plus two (2) flex holidays for DEI
• Joining a rapidly growing organization

Responsibilities
• Design, develop, and deploy scalable NLP systems to process, analyze, and extract information from medical and legal documents.
• Lead the exploration and application of cutting-edge NLP techniques, including transformers, large language models, information retrieval, recommendation, summarization, and personalization systems, to solve domain-specific challenges.
• Collaborate with cross-functional teams, including product managers, engineers, and domain experts, to define project goals, requirements, and deliverables.
• Drive end-to-end development of AI/ML solutions, including data preprocessing, model training, evaluation, deployment, and performance monitoring.
• Ensure solutions meet high standards of data security, privacy, and compliance
• Mentor junior data scientists, fostering technical growth and knowledge-sharing within the team.
• Stay abreast of emerging trends and technologies in NLP and machine learning and identify opportunities for their application in our systems.
• Contribute to the strategic direction of technology and product development within the organization
• Contribute to the long-term AI/ML technical vision and roadmap

Qualifications
• Master's or Ph.D. in Computer Science, Data Science, Statistics, Computational Linguistics, or a related field.
• 5-8 years of professional experience in data science, preferably with a focus on natural language processing.
• Proven track record of solving business problems by delivering data science solutions at scale
• Expert in building and deploying machine learning models, including deep learning techniques and model fine-tuning
• Expert in data processing, feature engineering, analytics and visualization for structured and unstructured data
• Proficiency in Python
• Proficiency in SQL
• Proficiency in using source control systems like Github
• Proficiency in AI/ML/NLP frameworks such as Hugging Face, spaCy, scikit-learn, among others
• Proficiency in developing prompts for generative AI including evaluation of output
• Proven skills in translating complex data insights into clear, actionable business strategies
• Background of mathematical fundamentals including statistics, probability, linear algebra and optimization methods
• Experience in demonstrating the impact of data products using appropriate quantitative metrics
• Experience with cloud platforms (e.g., AWS, Azure, Google Cloud) and ML model deployment in production.
• Proven ability in contributing to complex projects and deliver results in a fast-paced environment.

Desired Qualifications
• Experience working with medical or legal documents, including familiarity with domain-specific regulations (e.g., HIPAA, GDPR).
• Familiarity with OCR (Optical Character Recognition) technologies and integrating structured and unstructured data sources.
• Background in reinforcement learning, unsupervised learning, outlier detection, or graph-based NLP techniques.
• Familiarity with Python ML frameworks such as PyTorch or TensorFlow
• Background of linear algebra and neural network architecture
• Experience with MLOps tools and philosophies
• Publications or contributions to open-source NLP projects.

EEO Statement

Trajector is an EOE/Veterans/Disabled/LGBTQ employer.",2025-07-23T00:00:00.000Z,2025-07-25,"['The ideal candidate will have 8-10 years of relevant experience in data science, machine learning, and NLP, with a strong track record of delivering impactful solutions in complex, domain-specific contexts', ""Master's or Ph.D. in Computer Science, Data Science, Statistics, Computational Linguistics, or a related field"", '5-8 years of professional experience in data science, preferably with a focus on natural language processing', 'Proven track record of solving business problems by delivering data science solutions at scale', 'Expert in building and deploying machine learning models, including deep learning techniques and model fine-tuning', 'Expert in data processing, feature engineering, analytics and visualization for structured and unstructured data', 'Proficiency in Python', 'Proficiency in SQL', 'Proficiency in using source control systems like Github', 'Proficiency in AI/ML/NLP frameworks such as Hugging Face, spaCy, scikit-learn, among others', 'Proficiency in developing prompts for generative AI including evaluation of output', 'Proven skills in translating complex data insights into clear, actionable business strategies', 'Background of mathematical fundamentals including statistics, probability, linear algebra and optimization methods', 'Experience in demonstrating the impact of data products using appropriate quantitative metrics', 'Experience with cloud platforms (e.g., AWS, Azure, Google Cloud) and ML model deployment in production', 'Proven ability in contributing to complex projects and deliver results in a fast-paced environment']","['Design, develop, and deploy scalable NLP systems to process, analyze, and extract information from medical and legal documents', 'Lead the exploration and application of cutting-edge NLP techniques, including transformers, large language models, information retrieval, recommendation, summarization, and personalization systems, to solve domain-specific challenges', 'Collaborate with cross-functional teams, including product managers, engineers, and domain experts, to define project goals, requirements, and deliverables', 'Drive end-to-end development of AI/ML solutions, including data preprocessing, model training, evaluation, deployment, and performance monitoring', 'Ensure solutions meet high standards of data security, privacy, and compliance', 'Mentor junior data scientists, fostering technical growth and knowledge-sharing within the team', 'Stay abreast of emerging trends and technologies in NLP and machine learning and identify opportunities for their application in our systems', 'Contribute to the strategic direction of technology and product development within the organization', 'Contribute to the long-term AI/ML technical vision and roadmap']",True,"['Large Language Models', 'Transformers', 'Generative AI']",Large Language Models: Leading the exploration and application of large language models and transformers to develop state-of-the-art NLP systems for medical and legal document processing.; Transformers: Utilizing transformer architectures as part of cutting-edge NLP techniques to solve domain-specific challenges in text and audio data.; Generative AI: Developing and evaluating prompts for generative AI models to enhance NLP solutions and business applications.,"['Natural Language Processing', 'Machine Learning', 'Deep Learning', 'Feature Engineering', 'Python', 'SQL', 'Data Visualization and Analytics', 'Cloud Platforms and Model Deployment', 'MLOps', 'Statistical and Mathematical Fundamentals', 'Optical Character Recognition', 'Reinforcement Learning and Unsupervised Learning', 'Source Control Systems', 'Data Science Frameworks']","Natural Language Processing: Design, development, and deployment of scalable NLP systems to process, analyze, and extract information from medical and legal documents, applying domain-specific NLP techniques such as information retrieval, recommendation, summarization, and personalization.; Machine Learning: Building and deploying machine learning models including data preprocessing, feature engineering, model training, evaluation, deployment, and performance monitoring to deliver impactful data science solutions at scale.; Deep Learning: Expertise in deep learning techniques and model fine-tuning applied to NLP systems, including neural network architectures and linear algebra fundamentals.; Feature Engineering: Data processing and feature engineering for both structured and unstructured data to support analytics and model development.; Python: Proficiency in Python programming language for data science, machine learning, and NLP development.; SQL: Proficiency in SQL for data querying and manipulation relevant to data science workflows.; Data Visualization and Analytics: Analytics and visualization skills to translate complex data insights into clear, actionable business strategies and demonstrate the impact of data products using quantitative metrics.; Cloud Platforms and Model Deployment: Experience with cloud platforms such as AWS, Azure, and Google Cloud for ML model deployment and productionization.; MLOps: Experience with MLOps tools and philosophies to support the deployment and monitoring of machine learning models in production environments.; Statistical and Mathematical Fundamentals: Background in statistics, probability, linear algebra, and optimization methods to underpin data science and machine learning model development.; Optical Character Recognition: Familiarity with OCR technologies to integrate structured and unstructured data sources, particularly in medical and legal document contexts.; Reinforcement Learning and Unsupervised Learning: Background in reinforcement learning, unsupervised learning, outlier detection, and graph-based NLP techniques to enhance NLP system capabilities.; Source Control Systems: Proficiency in using source control systems like GitHub to manage code and collaborate within data science teams.; Data Science Frameworks: Proficiency in AI/ML/NLP frameworks such as scikit-learn, spaCy, and Hugging Face for building and deploying machine learning and NLP models."
_g6t-UajKOyaY_UJAAAAAA==,Senior Data Analyst,"Company description

Hi there! We’re Razorfish. We’ve been leading the marketing industry with our digital expertise since the start of the internet. But in 2020, we did a full reboot. What’s different? It all starts with people. Weird, wonderful, complex people - with diverse backgrounds in strategy, creative and technology. But no matter how different we are, we all have one thing in common. We believe our differences are our strength. So we push for inclusion, challenge convention and bring in new perspectives, to inspire new ideas. Because when we connect by understanding what makes people different, we can create unforgettable experiences that enrich lives. Join us at razorfish.com.

Overview

Razorfish is looking for a Senior Associate to join its Data and Analytics practice. This is an analytics, research, and consulting team that delivers data-driven insights to our clients. Each member of the team is aligned to one or more clients and works closely with other Data team members, our clients, and colleagues across other disciplines such as: Client Management, Strategy, Search, Social, Media, User Experience, and Technology.

In this role you will contribute to data-driven projects across one or more client accounts. You will have support from data leadership and fellow analysts.

Core areas of focus for this group include applications in measurement planning and strategy, customer segmentations, testing frameworks, measurement and optimization solutions, performance reporting and analyses, personalization, and forecasting.

Responsibilities
• Lead data analyst for internal and external client project work
• Subject matter expert (SME) in source tools, platforms, and data flow
• Understands Razorfish data capabilities and how data fits into a client's overall strategy
• Understands the breadth of data services and crafts
• Owns elements of the data process such as syntax and taxonomy management and QA
• Able to manage data team responsibilities within cross-capability projects
• Participates and presents within larger presentations to clients
• Translates data into visuals (charts and graphs) that demonstrate the findings

Data Strategy
• Identify / focus on key issues and objectives based on internal and client needs with oversight
• Effectively describes outputs and approach of analysis to internal audiences and clients

Communication Skills
• Active listener and thoughtful communicator within internal and client discussions
• Raises questions based on data trends and patterns, explores hypotheses on causation
• Has ownership of own materials and able to answer questions logically and appropriately
• Participates appropriately in meetings, developing confidence in offering ideas and suggestions
• Begins to play leadership role in team discussions and is more comfortable voicing alternatives appropriately (supported with facts)
• Independently create sections of client documents with guidance in addition to leveraging pre-existing templates
• Takes comprehensive meeting notes with clear next steps for individual owners
• Shows ability to transform data into visually appealing presentations and able to adapt new formats as necessary

Client Engagement
• Client Partnerships
• Contributes to meetings with internal and external clients
• * Prioritize work to meet internal and external client deliverables
• ​​​​​​​Relationship Management
• * ​​​​​​​Identify when a request should be completed by the data team
• Understands how to document client feedback and recognizes when to raise issues
• Questions and output reflect basic knowledge of client’s business – financials, industry economics, competitive dynamics, marketing channels and client strategic issues

Tools & Techniques
• Shows mastery of client-specific data tools and platforms for reporting purposes
• Has advanced Excel skills with experience in manipulating and organizing large data sets
• Has deeper knowledge of statistical concepts / coding languages for advanced analytics capabilities
• Assist in vendor assessments
• Proactively identifies own learning gaps and seeks to answer them through internal resources or asking experts
• Comfortable working within BI/Visualization tools
• QA and maintain data integrity at collection, extraction, and activation point

Analytics
• Planning and Implementation
• Own sections of learning agenda / measurement plan
• Seamlessly implement a measurement program with minimal guidance
• Start and end a reporting deliverable with minimal guidance
• ​​​​​​​Insight Generation
• Fluent in standard CRM key performance metrics and approaches to measurement such as, email click-through rate, offer redemption rate, incremental sales, incremental margin
• Understand the best path to extract, cleanse, manipulate, and analyze data
• Demonstrates ability to synthesize implications (""so whats?"") from analysis with minimal guidance
• Uses insights to provide hypotheses and useful recommendations to the team

Qualifications
• 3-5+ years of industry experience in data science and marketing field
• Experience in media performance analytics such as attribution modeling, incrementality testing, and advance measurement methodologies
• Proficiency in common data science coding languages such as in SQL, Python and/or R
• Practical experience with Google Cloud Platform and services such as BigQuery, Looker, and DataProc

Additional information

The Power of One starts with our people! To do powerful things, we offer powerful resources. Our best-in-class wellness and benefits offerings include:
• Paid Family Care for parents and caregivers for 12 weeks or more
• Monetary assistance and support for Adoption, Surrogacy and Fertility
• Monetary assistance and support for pet adoption
• Employee Assistance Programs and Health/Wellness/Comfort reimbursements to help you invest in your future and work/life balance
• Tuition Assistance
• Paid time off that includes Flexible Time off Vacation, Annual Sick Days, Volunteer Days, Holiday and Identity days, and more
• Matching Gifts programs
• Flexible working arrangements
• ‘Work Your World’ Program encouraging employees to work from anywhere Publicis Groupe has an office for up to 6 weeks a year (based upon eligibility)
• Business Resource Groups that support multiple affinities and alliances

The benefits offerings listed are available to eligible U.S. Based employees, are reviewed on an annual basis, and are governed by the terms of the applicable plan documents.

Razorfish is an Equal Opportunity Employer. Our employment decisions are made without regard to actual or perceived race, color, ethnicity, religion, creed, sex, sexual orientation, gender, gender identity, gender expression, pregnancy, childbirth and related medical conditions, national origin, ancestry, citizenship status, age, disability, medical condition as defined by applicable state law, genetic information, marital status, military service and veteran status, or any other characteristic protected by applicable federal, state or local laws and ordinances.

If you require accommodation or assistance with the application or onboarding process specifically, please contact USMSTACompliance@publicis.com.

All your information will be kept confidential according to EEO guidelines.

Compensation Range: $70,000 - 95,000. This is the pay range the Company believes it will pay for this position at the time of this posting. Consistent with applicable law, compensation will be determined based on the skills, qualifications, and experience of the applicant along with the requirements of the position, and the Company reserves the right to modify this pay range at any time. Temporary roles may be eligible to participate in our freelancer/temporary employee medical plan through a third-party benefits administration system once certain criteria have been met. Temporary roles may also qualify for participation in our 401(k) plan after eligibility criteria have been met. For regular roles, the Company will offer medical coverage, dental, vision, disability, 401k, and paid time off. The Company anticipates the application deadline for this job posting will be 8/29/25.

#DNI",,2025-07-25,"['Active listener and thoughtful communicator within internal and client discussions', 'Has ownership of own materials and able to answer questions logically and appropriately', 'Has advanced Excel skills with experience in manipulating and organizing large data sets', 'Has deeper knowledge of statistical concepts / coding languages for advanced analytics capabilities', '3-5+ years of industry experience in data science and marketing field', 'Experience in media performance analytics such as attribution modeling, incrementality testing, and advance measurement methodologies', 'Proficiency in common data science coding languages such as in SQL, Python and/or R', 'Practical experience with Google Cloud Platform and services such as BigQuery, Looker, and DataProc']","['This is an analytics, research, and consulting team that delivers data-driven insights to our clients', 'Each member of the team is aligned to one or more clients and works closely with other Data team members, our clients, and colleagues across other disciplines such as: Client Management, Strategy, Search, Social, Media, User Experience, and Technology', 'In this role you will contribute to data-driven projects across one or more client accounts', 'You will have support from data leadership and fellow analysts', 'Core areas of focus for this group include applications in measurement planning and strategy, customer segmentations, testing frameworks, measurement and optimization solutions, performance reporting and analyses, personalization, and forecasting', 'Lead data analyst for internal and external client project work', 'Subject matter expert (SME) in source tools, platforms, and data flow', ""Understands Razorfish data capabilities and how data fits into a client's overall strategy"", 'Understands the breadth of data services and crafts', 'Owns elements of the data process such as syntax and taxonomy management and QA', 'Able to manage data team responsibilities within cross-capability projects', 'Participates and presents within larger presentations to clients', 'Translates data into visuals (charts and graphs) that demonstrate the findings', 'Data Strategy', 'Identify / focus on key issues and objectives based on internal and client needs with oversight', 'Effectively describes outputs and approach of analysis to internal audiences and clients', 'Raises questions based on data trends and patterns, explores hypotheses on causation', 'Participates appropriately in meetings, developing confidence in offering ideas and suggestions', 'Begins to play leadership role in team discussions and is more comfortable voicing alternatives appropriately (supported with facts)', 'Independently create sections of client documents with guidance in addition to leveraging pre-existing templates', 'Takes comprehensive meeting notes with clear next steps for individual owners', 'Shows ability to transform data into visually appealing presentations and able to adapt new formats as necessary', 'Client Engagement', 'Client Partnerships', 'Contributes to meetings with internal and external clients', 'Prioritize work to meet internal and external client deliverables', '\u200b\u200b\u200b\u200b\u200b\u200b\u200bRelationship Management', '\u200b\u200b\u200b\u200b\u200b\u200b\u200bIdentify when a request should be completed by the data team', 'Understands how to document client feedback and recognizes when to raise issues', 'Questions and output reflect basic knowledge of client’s business – financials, industry economics, competitive dynamics, marketing channels and client strategic issues', 'Shows mastery of client-specific data tools and platforms for reporting purposes', 'Assist in vendor assessments', 'Proactively identifies own learning gaps and seeks to answer them through internal resources or asking experts', 'Comfortable working within BI/Visualization tools', 'QA and maintain data integrity at collection, extraction, and activation point', 'Analytics', 'Planning and Implementation', 'Own sections of learning agenda / measurement plan', 'Seamlessly implement a measurement program with minimal guidance', 'Start and end a reporting deliverable with minimal guidance', 'Fluent in standard CRM key performance metrics and approaches to measurement such as, email click-through rate, offer redemption rate, incremental sales, incremental margin', 'Understand the best path to extract, cleanse, manipulate, and analyze data', 'Demonstrates ability to synthesize implications (""so whats?"") from analysis with minimal guidance', 'Uses insights to provide hypotheses and useful recommendations to the team']",True,[],,"['Attribution Modeling', 'Incrementality Testing', 'Advanced Measurement Methodologies', 'SQL', 'Python', 'R', 'Google Cloud Platform', 'BigQuery', 'Looker', 'DataProc', 'Excel', 'BI/Visualization Tools', 'Statistical Concepts', 'Measurement Planning and Strategy', 'Customer Segmentation', 'Testing Frameworks', 'Performance Reporting and Analysis', 'Personalization', 'Forecasting', 'Data QA and Integrity', 'Data Process Management', 'Data Extraction, Cleansing, and Manipulation', 'CRM Key Performance Metrics']","Attribution Modeling: Experience in media performance analytics including attribution modeling to measure the impact of marketing channels on outcomes.; Incrementality Testing: Experience in media performance analytics involving incrementality testing to assess the incremental effect of marketing activities.; Advanced Measurement Methodologies: Use of advanced measurement methodologies for evaluating marketing performance and effectiveness.; SQL: Proficiency in SQL for data extraction, manipulation, and analysis within client projects.; Python: Proficiency in Python for coding and advanced analytics capabilities.; R: Proficiency in R programming language for statistical analysis and advanced analytics.; Google Cloud Platform: Practical experience with Google Cloud Platform services such as BigQuery, Looker, and DataProc for data processing and analytics.; BigQuery: Use of BigQuery as a data warehouse solution within Google Cloud Platform for querying large datasets.; Looker: Use of Looker as a BI and visualization tool to create reports and dashboards for clients.; DataProc: Use of DataProc service on Google Cloud Platform for data processing and analytics workflows.; Excel: Advanced Excel skills for manipulating and organizing large data sets and supporting analytics tasks.; BI/Visualization Tools: Comfortable working with business intelligence and visualization tools to translate data into visuals such as charts and graphs for client presentations.; Statistical Concepts: Deeper knowledge of statistical concepts applied to advanced analytics and measurement planning.; Measurement Planning and Strategy: Application of measurement planning and strategy to support client data-driven projects and analytics.; Customer Segmentation: Use of customer segmentation techniques to analyze and group clients' customer data for insights.; Testing Frameworks: Implementation of testing frameworks to evaluate marketing strategies and performance.; Performance Reporting and Analysis: Creation and delivery of performance reports and analyses to inform client decision-making.; Personalization: Application of personalization techniques to optimize marketing and customer experiences.; Forecasting: Use of forecasting methods to predict future trends and outcomes for clients.; Data QA and Integrity: Quality assurance and maintenance of data integrity at collection, extraction, and activation points.; Data Process Management: Ownership of data process elements such as syntax and taxonomy management and quality assurance.; Data Extraction, Cleansing, and Manipulation: Expertise in extracting, cleansing, manipulating, and analyzing data to generate insights.; CRM Key Performance Metrics: Fluency in standard CRM metrics such as email click-through rate, offer redemption rate, incremental sales, and incremental margin for measurement and reporting."
XJ5j5Ty72RZwbOp-AAAAAA==,"Senior Data Scientist - Python, Tableau and Machine Learning","Position: Senior Data Scientist - Python, Tableau and Machine Learning - 2289596

Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by inclusion, talented peers, comprehensive benefits and career development opportunities.

Come make an impact on the communities we serve as you help us advance health optimization on a global scale. Join us to start Caring. Connecting. Growing together.

Primary Responsibilities:
• Analytics professional in payment integrity - stats and modeling data analytics team. Person will be responsible for delivering various fraud analytics statistical projects based on US healthcare data and other consulting assignment. These projects may involve model development, validation, governance, implementation and end to end delivery
• Lead and work closely with junior/senior statisticians to deliver Fraud, Waste, Abuse (FWA) statistical projects. Team builds models through advanced statistical techniques.
• Provide support to management in business development, client proposals and in building solid relationships with global analytics teams.
• Collaborates across business units with stakeholders, providing thought leadership, and driving day-to-day implementation of our analytics strategy
• Demonstrable leadership ability, superior problem solving and people management skills
• Evaluate statistical methods used to obtain the data to ensure validity, applicability, efficiency and accuracy. Interpret end-user technical requirements by specifying economic decision models, determining appropriate data sources, and performing detailed statistical analysis
• Create, analyze and maintain explanatory/predictive models of clinical behaviours on healthcare claims data. Work includes all phases of the modelling process: research design, data extraction and cleaning, model building and validation
• Research on the new fraud & abuse patterns and ideate new assignments/projects basis the secondary/data driven research
• Lead the advanced statistics domain for the team & develop/refine/improve predictive models using advance SAS, R & machine learning techniques and mentors junior/senior analysts/statisticians to develop their modeling/statistical skills
• Maintains staff by recruiting, selecting, orienting, and training employees; maintaining a safe, secure, and legal work environment; developing personal growth opportunities and accomplishes staff results by communicating job expectations; planning, monitoring, and appraising job results; coaching, counseling, and disciplining employees; developing, coordinating, and enforcing systems, policies, procedures, and productivity standards
• Co-ordinate with clinical/Coding SMEs for seeking the inputs to explore data extraction approach and road map the analysis mile stones
• Develop and maintain working relationships with key customer stakeholders
• Comply with the terms and conditions of the employment contract, company policies and procedures, and any and all directives (such as, but not limited to, transfer and/or re-assignment to different work locations, change in teams and/or work shifts, policies in regards to flexibility of work benefits and/or work environment, alternative work arrangements, and other decisions that may arise due to the changing business environment).

The Company may adopt, vary or rescind these policies and directives in its absolute discretion and without any limitation (implied or otherwise) on its ability to do so

Required Qualifications:
• Masters degree in math or statistics from top universities (Tier I/II) with solid record of achievement and approximately 6+ years of relevant work experience
• 6+ years of work experience in the area(s) of statistical analysis, data modelling
• 6+ years of project management experience
• Experience comprising analytics service delivery, solution design and client management
• Experience in data analytics, predictive & statistical modeling, strategy, project management, team management and business development
• Expert in data analytics with significant amount of project delivery skills in one or more of the following areas:
• Model Building, Model Validation, Fraud detection Analytics, Risk Analytics, Multivariate Analysis
• Expert focused on helping team improve modeling predictability, analytics driven strategy development, operational efficiency
• Knowledge of statistical tools and techniques, especially those relating to data mining & analysis. Should have ability to handle/work on large data sets
• Displays solid communication, interpersonal, and leadership ability across all levels coupled with effective problem solving, conceptual thinking, quantitative and analytical skills
• Demonstrated leadership ability and willingness to take initiative
• Excellent knowledge of SAS, R, or any other statistical software to carry out analysis and drive conclusions
• Solid…",2025-07-15T00:00:00.000Z,2025-07-25,"['Demonstrable leadership ability, superior problem solving and people management skills', 'Masters degree in math or statistics from top universities (Tier I/II) with solid record of achievement and approximately 6+ years of relevant work experience', '6+ years of work experience in the area(s) of statistical analysis, data modelling', '6+ years of project management experience', 'Experience comprising analytics service delivery, solution design and client management', 'Experience in data analytics, predictive & statistical modeling, strategy, project management, team management and business development', 'Expert in data analytics with significant amount of project delivery skills in one or more of the following areas:', 'Model Building, Model Validation, Fraud detection Analytics, Risk Analytics, Multivariate Analysis', 'Expert focused on helping team improve modeling predictability, analytics driven strategy development, operational efficiency', 'Knowledge of statistical tools and techniques, especially those relating to data mining & analysis', 'Should have ability to handle/work on large data sets', 'Displays solid communication, interpersonal, and leadership ability across all levels coupled with effective problem solving, conceptual thinking, quantitative and analytical skills', 'Demonstrated leadership ability and willingness to take initiative', 'Excellent knowledge of SAS, R, or any other statistical software to carry out analysis and drive conclusions', 'Solid…']","['Analytics professional in payment integrity - stats and modeling data analytics team', 'Person will be responsible for delivering various fraud analytics statistical projects based on US healthcare data and other consulting assignment', 'These projects may involve model development, validation, governance, implementation and end to end delivery', 'Lead and work closely with junior/senior statisticians to deliver Fraud, Waste, Abuse (FWA) statistical projects', 'Team builds models through advanced statistical techniques', 'Provide support to management in business development, client proposals and in building solid relationships with global analytics teams', 'Collaborates across business units with stakeholders, providing thought leadership, and driving day-to-day implementation of our analytics strategy', 'Evaluate statistical methods used to obtain the data to ensure validity, applicability, efficiency and accuracy', 'Interpret end-user technical requirements by specifying economic decision models, determining appropriate data sources, and performing detailed statistical analysis', 'Create, analyze and maintain explanatory/predictive models of clinical behaviours on healthcare claims data', 'Work includes all phases of the modelling process: research design, data extraction and cleaning, model building and validation', 'Research on the new fraud & abuse patterns and ideate new assignments/projects basis the secondary/data driven research', 'Lead the advanced statistics domain for the team & develop/refine/improve predictive models using advance SAS, R & machine learning techniques and mentors junior/senior analysts/statisticians to develop their modeling/statistical skills', 'Maintains staff by recruiting, selecting, orienting, and training employees; maintaining a safe, secure, and legal work environment; developing personal growth opportunities and accomplishes staff results by communicating job expectations; planning, monitoring, and appraising job results; coaching, counseling, and disciplining employees; developing, coordinating, and enforcing systems, policies, procedures, and productivity standards', 'Co-ordinate with clinical/Coding SMEs for seeking the inputs to explore data extraction approach and road map the analysis mile stones', 'Develop and maintain working relationships with key customer stakeholders', 'Comply with the terms and conditions of the employment contract, company policies and procedures, and any and all directives (such as, but not limited to, transfer and/or re-assignment to different work locations, change in teams and/or work shifts, policies in regards to flexibility of work benefits and/or work environment, alternative work arrangements, and other decisions that may arise due to the changing business environment)']",True,[],,"['Fraud Detection Analytics', 'Predictive Modeling', 'Statistical Analysis', 'Advanced Statistical Techniques', 'Machine Learning Techniques', 'SAS', 'R Programming', 'Data Mining and Analysis', 'Multivariate Analysis', 'Model Validation', 'Data Extraction and Cleaning', 'Project Management in Analytics', 'Business Development Support']","Fraud Detection Analytics: Responsible for delivering various fraud analytics statistical projects based on US healthcare data, including model development, validation, governance, and end-to-end delivery to detect fraud, waste, and abuse.; Predictive Modeling: Create, analyze, and maintain explanatory and predictive models of clinical behaviors on healthcare claims data, covering all phases from research design, data extraction and cleaning, to model building and validation.; Statistical Analysis: Evaluate statistical methods to ensure validity, applicability, efficiency, and accuracy; perform detailed statistical analysis to interpret end-user technical requirements and specify economic decision models.; Advanced Statistical Techniques: Lead and develop models using advanced statistical techniques and mentor junior/senior analysts and statisticians to improve their modeling and statistical skills.; Machine Learning Techniques: Develop, refine, and improve predictive models using machine learning techniques alongside advanced SAS and R programming.; SAS: Use advanced SAS programming for statistical analysis, model development, and predictive modeling in fraud analytics and healthcare data projects.; R Programming: Utilize R for statistical analysis, model building, validation, and predictive modeling in healthcare fraud detection and other analytics projects.; Data Mining and Analysis: Apply knowledge of statistical tools and techniques related to data mining and analysis, with the ability to handle and work on large datasets.; Multivariate Analysis: Expertise in multivariate analysis techniques to support model building, validation, and fraud detection analytics.; Model Validation: Responsible for validating models developed for fraud detection and predictive analytics to ensure accuracy and reliability.; Data Extraction and Cleaning: Perform data extraction and cleaning as part of the modeling process to prepare healthcare claims data for analysis and model development.; Project Management in Analytics: Manage analytics projects including solution design, delivery, client management, and team leadership to ensure successful implementation of statistical and predictive models.; Business Development Support: Provide support in business development, client proposals, and building relationships with global analytics teams to drive analytics strategy and service delivery."
boY52InL9yYDLpEOAAAAAA==,Senior Data Scientist - Damage Analytics,"Join Our Innovation Team! At Hertz, we are pushing the boundaries of what's possible in damage management technology within the transportation industry. We are looking for brilliant AI & ML minds to join our Damage Science Team and help us innovate in the following areas:
• Real-Time Damage Detection: Utilize advanced computer vision techniques to accurately identify and assess damage.
• Intelligent Repair Estimation: Implement sophisticated Large Language Models to optimize repair routing decisions for efficiency and cost-effectiveness.
• Repair Forecasting: Develop predictive models for future repair and maintenance needs based on historical data.
• Quality Assurance Automation: Create models to evaluate repair quality and ensure our high standards are met.

We anticipate a starting salary around $160K, commensurate with experience.

Your Role:
• Define strategic and tactical steps for the complete model development lifecycle (including problem statement definition, exploratory data analysis, feature engineering, model development/tuning, and implementation).
• Develop and maintain a range of predictive and prescriptive models to evaluate new product and service performance.
• Conduct cross-validation of production models to ensure optimal performance and generalizability.
• Generate accurate analytics, reports, visualizations, and dashboards, effectively communicating results to both technical and non-technical stakeholders.
• Collaborate cross-functionally to identify use cases that enhance operational efficiency and drive business value.
• Adopt an owner mentality to drive business impact, supporting analytics pipeline creation and decision-making processes.
• Provide insights into how advancements in AI and machine learning can impact our business opportunities.
• Mentor and provide technical leadership to junior Data Scientists.

Requirements:
• 5-8 years of hands-on experience in a data science role.
• 5+ years of proficiency in data querying languages (like SQL) and scripting languages (like Python).
• End-to-end experience in machine learning model development (from problem definition to deployment).
• Demonstrated ability to leverage machine learning for business impact.
• Strong background in statistical analysis and modeling techniques.
• Experience mentoring junior scientists.
• Prior experience in an ML or data scientist role at a technology company.
• Master's degree in a quantitative field (statistics, mathematics, data science, economics, or computer science). PhD is preferred.

Benefits:
• Up to 40% off standard Hertz rental.
• Generous Paid Time Off.
• Comprehensive medical, dental, and vision plan options.
• 401(k) retirement plans with employer matching.
• Paid parental leave and adoption assistance.
• Employee assistance program for you and your family.
• Educational reimbursement and discounts.
• Voluntary insurance programs (pet, legal, critical illness).
• Perks and discounts on theme park tickets, gym memberships, and more.

The Hertz Corporation operates multiple car rental brands, including Hertz, Dollar, and Thrifty, across approximately 9,700 locations worldwide. We are one of the largest airport vehicle rental companies globally, and the Hertz brand is one of the most recognized.

Our Commitment to Diversity: At Hertz, we celebrate diversity and inclusion. We promote equal employment opportunities for all individuals, regardless of their unique characteristics. We encourage diverse applicants to contribute to our success!",2025-07-08T00:00:00.000Z,2025-07-25,"['5-8 years of hands-on experience in a data science role', '5+ years of proficiency in data querying languages (like SQL) and scripting languages (like Python)', 'End-to-end experience in machine learning model development (from problem definition to deployment)', 'Demonstrated ability to leverage machine learning for business impact', 'Strong background in statistical analysis and modeling techniques', 'Experience mentoring junior scientists', 'Prior experience in an ML or data scientist role at a technology company', ""Master's degree in a quantitative field (statistics, mathematics, data science, economics, or computer science)""]","['Real-Time Damage Detection: Utilize advanced computer vision techniques to accurately identify and assess damage', 'Intelligent Repair Estimation: Implement sophisticated Large Language Models to optimize repair routing decisions for efficiency and cost-effectiveness', 'Repair Forecasting: Develop predictive models for future repair and maintenance needs based on historical data', 'Quality Assurance Automation: Create models to evaluate repair quality and ensure our high standards are met', 'Define strategic and tactical steps for the complete model development lifecycle (including problem statement definition, exploratory data analysis, feature engineering, model development/tuning, and implementation)', 'Develop and maintain a range of predictive and prescriptive models to evaluate new product and service performance', 'Conduct cross-validation of production models to ensure optimal performance and generalizability', 'Generate accurate analytics, reports, visualizations, and dashboards, effectively communicating results to both technical and non-technical stakeholders', 'Collaborate cross-functionally to identify use cases that enhance operational efficiency and drive business value', 'Adopt an owner mentality to drive business impact, supporting analytics pipeline creation and decision-making processes', 'Provide insights into how advancements in AI and machine learning can impact our business opportunities', 'Mentor and provide technical leadership to junior Data Scientists']",True,['Large Language Models'],Large Language Models: Implement sophisticated Large Language Models to optimize repair routing decisions for efficiency and cost-effectiveness.,"['Predictive Modeling', 'Statistical Analysis and Modeling', 'Feature Engineering', 'Machine Learning Model Development', 'Cross-Validation', 'Data Querying and Scripting', 'Data Analytics and Visualization', 'Computer Vision', 'Analytics Pipeline Creation']","Predictive Modeling: Develop predictive models for future repair and maintenance needs based on historical data to forecast repair requirements.; Statistical Analysis and Modeling: Apply strong statistical analysis and modeling techniques to support data-driven decision making and model development.; Feature Engineering: Perform feature engineering as part of the complete model development lifecycle to improve model performance.; Machine Learning Model Development: End-to-end experience in machine learning model development including problem definition, model tuning, cross-validation, and deployment to create predictive and prescriptive models.; Cross-Validation: Conduct cross-validation of production models to ensure optimal performance and generalizability.; Data Querying and Scripting: Use data querying languages like SQL and scripting languages like Python for data manipulation and analysis.; Data Analytics and Visualization: Generate analytics, reports, visualizations, and dashboards to communicate results effectively to both technical and non-technical stakeholders.; Computer Vision: Utilize advanced computer vision techniques for real-time damage detection to accurately identify and assess damage.; Analytics Pipeline Creation: Support the creation of analytics pipelines to drive business impact and decision-making processes."
81jBdaow2sVgD3jwAAAAAA==,Data Science Director,"Our ideal candidate will possess strong business acumen, coupled with the ability to communicate findings to both business and IT leaders in a way that can influence how our organization approaches a business challenge. The Data Science Director will not just address business problems; instead will be responsible for selecting the right problems that have the most value to the organization.

Responsibilities
• Lead a team of data scientists who undertake multiple client engagements
• In collaboration with the product management and engineering teams, identify opportunities to leverage data science techniques in order to create new or improve existing products
• Advocate the use and potential of data science within the organization and in particular the executive, product management and engineering teams

Qualifications
• 10+ years of experience with applied machine learning
• Strong statistical background and experience with R or other statistical packages
• Strong foundation in coding skills relevant for data science, e.g., Pig, Hive, SQL, Python, etc.
• Strong expertise in building and applying statistical/mathematical methods, machine learning / predictive modelling in real-world use cases
• Track record of successfully managing a diverse team of highly skilled individuals.
• Strong ability to build collaborative partnerships with a wide variety of internal and external stakeholders.
• PhD in a quantitative field (e.g., computer science, physics, engineering, mathematics, etc.)
• Must be inquisitive and can stare data and spot trends",,2025-07-25,"['10+ years of experience with applied machine learning', 'Strong statistical background and experience with R or other statistical packages', 'Strong foundation in coding skills relevant for data science, e.g., Pig, Hive, SQL, Python, etc', 'Strong expertise in building and applying statistical/mathematical methods, machine learning / predictive modelling in real-world use cases', 'Track record of successfully managing a diverse team of highly skilled individuals', 'Strong ability to build collaborative partnerships with a wide variety of internal and external stakeholders', 'PhD in a quantitative field (e.g., computer science, physics, engineering, mathematics, etc.)', 'Must be inquisitive and can stare data and spot trends']","['The Data Science Director will not just address business problems; instead will be responsible for selecting the right problems that have the most value to the organization', 'Lead a team of data scientists who undertake multiple client engagements', 'In collaboration with the product management and engineering teams, identify opportunities to leverage data science techniques in order to create new or improve existing products', 'Advocate the use and potential of data science within the organization and in particular the executive, product management and engineering teams']",True,[],,"['Applied Machine Learning', 'Statistical Methods and Packages', 'Data Science Programming Languages and Tools', 'Statistical and Mathematical Modeling', 'Data Science Team Leadership', 'Data-Driven Business Problem Selection', 'Cross-Functional Collaboration']","Applied Machine Learning: Experience applying machine learning techniques to solve real-world business problems and predictive modeling use cases.; Statistical Methods and Packages: Strong statistical background with experience using R or other statistical software packages for data analysis.; Data Science Programming Languages and Tools: Proficiency in coding languages and tools relevant to data science such as Pig, Hive, SQL, and Python.; Statistical and Mathematical Modeling: Expertise in building and applying statistical and mathematical methods to analyze data and develop predictive models.; Data Science Team Leadership: Leading and managing a team of data scientists working on multiple client engagements.; Data-Driven Business Problem Selection: Identifying and selecting high-value business problems to address using data science techniques.; Cross-Functional Collaboration: Working with product management and engineering teams to identify opportunities to leverage data science for product improvement or creation."
dNME9zPUDS8QGAp3AAAAAA==,Senior Data Scientist – Pricing,"Siamo alla ricerca di un* Senior Data Scientist da inserire nel team di Pricing & Underwriting a Milano.
Se hai una solida esperienza nel settore assicurativo o finanziario, passione per i dati e voglia di contribuire all'evoluzione del nostro motore tecnico, potresti essere la persona giusta
Principali Attività
Valorizzerà il patrimonio dati aziendale, identificando opportunità strategiche e misurandone l'impatto.
Lavorerà allo sviluppo",2025-07-19T00:00:00.000Z,2025-07-25,,,True,[],,"['Pricing Models', 'Data Analysis']",Pricing Models: Used to develop and optimize pricing strategies within the insurance or financial sector by leveraging company data assets.; Data Analysis: Involves identifying strategic opportunities and measuring their impact through analysis of company data.
Vi8rKqszbChnjSNrAAAAAA==,"Senior Data Analyst, External Games","Data Science and Engineering (‘DSE’) at Netflix is aimed at using data, analytics, and sciences to improve various aspects of our business. We are looking for a Senior Analytics Engineer to join our Games DSE team, leading end-to-end analytics & data needs for the Games space. This role will be partnering closely with our Game stakeholders to define key metrics, build and maintain key dashboards and analytic tools and scale data access across our stakeholder set. As an early member of the team, you will also help shape our overall Games Data Strategy at Netflix.

What You Will Do:
• Partner directly with our Game stakeholders (e.g., Netflix Games Studio, Games Product, Game Strategy, Planning & Analysis team) on data, metrics & analytics initiatives
• Lead end-to-end development of reports/dashboards/tools used by your direct stakeholders and a diverse set of teams across the company
• Proactively perform data exploration and analytical deep dives to discover insights or future testing opportunities
• Be a bridge between the business and tech, scaling access to insights that can empower better decision-making
• Maintain and rethink existing data solutions to service a wider variety of use cases
• Balance handling ad hoc requests while also driving larger projects forward

Who You Are:
• 6+ years of experience in data analytics function in gaming industry
• Extensive experience in driving Live Service performance insights
• You are an engineering-minded analyst with a strong bias towards action, delivering results quickly with iteration instead of waiting for perfection
• You are comfortable taking vague requirements and crystallizing them into valuable tools, metrics, or analysis.
• You have strong technical skills in manipulating large data sets with complex SQL and Python (or similar languages), big data technologies (e.g., Hadoop, Spark) and visualization tools (e.g., Tableau)
• You are a self-starter that can work effectively in a fast-paced, ambiguous environment with changing priorities and minimally defined processes.
• You are experienced in managing stakeholder asks, expectations, and relationships across a variety of stakeholders

Our compensation structure consists solely of an annual salary; we do not have bonuses. You choose each year how much of your compensation you want in salary versus stock options. To determine your personal top of market compensation, we rely on market indicators and consider your specific job family, background, skills, and experience to determine your compensation in the market range. The range for this role is $170,000 - $720,000.

Netflix provides comprehensive benefits including Health Plans, Mental Health support, a 401(k) Retirement Plan with employer match, Stock Option Program, Disability Programs, Health Savings and Flexible Spending Accounts, Family-forming benefits, and Life and Serious Injury Benefits. We also offer paid leave of absence programs. Full-time hourly employees accrue 35 days annually for paid time off to be used for vacation, holidays, and sick paid time off. Full-time salaried employees are immediately entitled to flexible time off. See more detail about our Benefits here.",,2025-07-25,"['6+ years of experience in data analytics function in gaming industry', 'Extensive experience in driving Live Service performance insights', 'You are an engineering-minded analyst with a strong bias towards action, delivering results quickly with iteration instead of waiting for perfection', 'You are comfortable taking vague requirements and crystallizing them into valuable tools, metrics, or analysis', 'You have strong technical skills in manipulating large data sets with complex SQL and Python (or similar languages), big data technologies (e.g., Hadoop, Spark) and visualization tools (e.g., Tableau)', 'You are a self-starter that can work effectively in a fast-paced, ambiguous environment with changing priorities and minimally defined processes', 'You are experienced in managing stakeholder asks, expectations, and relationships across a variety of stakeholders']","['This role will be partnering closely with our Game stakeholders to define key metrics, build and maintain key dashboards and analytic tools and scale data access across our stakeholder set', 'Partner directly with our Game stakeholders (e.g., Netflix Games Studio, Games Product, Game Strategy, Planning & Analysis team) on data, metrics & analytics initiatives', 'Lead end-to-end development of reports/dashboards/tools used by your direct stakeholders and a diverse set of teams across the company', 'Proactively perform data exploration and analytical deep dives to discover insights or future testing opportunities', 'Be a bridge between the business and tech, scaling access to insights that can empower better decision-making', 'Maintain and rethink existing data solutions to service a wider variety of use cases', 'Balance handling ad hoc requests while also driving larger projects forward']",True,[],,"['SQL', 'Python', 'Hadoop', 'Spark', 'Tableau', 'Data Exploration', 'Analytics Dashboards', 'Data Strategy']","SQL: Used for manipulating large data sets and performing complex queries to support analytics and reporting needs in the gaming data environment.; Python: Utilized for data manipulation and analysis, enabling the creation of analytic tools and dashboards for stakeholders.; Hadoop: Applied as a big data technology to handle and process large-scale data sets relevant to gaming analytics.; Spark: Used as a big data processing framework to efficiently manage and analyze large volumes of gaming data.; Tableau: Employed as a visualization tool to build and maintain dashboards and reports for diverse stakeholders across the company.; Data Exploration: Performed proactively to discover insights and identify future testing opportunities within gaming data.; Analytics Dashboards: Developed and maintained to provide key metrics and insights to game stakeholders and support decision-making.; Data Strategy: Involved in shaping the overall games data strategy to scale data access and improve analytics capabilities."
nlyQipkD4AMrHSOaAAAAAA==,"Senior, Data Scientist - GenAI Platform - Military veterans preferred","Position Summary...

What you'll do...

Walmart employees more than 2.3 million employees worldwide, with 1.6 million associates in the U.S. Walmart hires 500,000 applicants a year to fill thousands of job profiles from engineers, designers, marketers to pilots and buyers and promotes more than 300,000 people to jobs of greater responsibility. The My Assistant platform team is responsible for developing and deploying Generative AI platform and solutions supporting associates globally.

In this role, you will be building an LLM-powered intelligent experience, inside chatbot or business application, to improve employee experience and productivity. You'll be responsible for designing and building an intelligent conversational interface that enhances communication, automates tasks, accesses data and insights, and provides personalized Q&A support to employees, ultimately creating a more efficient and engaging work environment.

What you'll do
• Work in a highly collaborative environment with a multidisciplinary team.
• Work with lead data scientists to design, architect, and build AI/ML model and model systems.
• Work with machine learning engineers to deploy, operate, and optimize scalable solutions
• Work with product managers to design user journeys, feedback loop and analyze user telemetry.
• Create opportunities to develop yourself with an end-to-end AI/ML product experience.
• Work with a set of robust work standards to ensure we build trustworthy AI/ML solutions

What you'll bring
• Ability to execute our trustworthy AI/ML practice in collaboration with stakeholders across the enterprise.
• Ability to effectively coach junior data scientists to work through technical issues and business understandings.
• Ability to communicate internally and externally through publication, presentations, and other mediums on research progress, major breakthroughs, and product innovation.
• Experience with statistical analysis and programming languages e.g. Python and mainstream machine learning frameworks, e.g. TensorFlow or PyTorch.
• Experience in building machine learning applications

About Walmart Global Tech
Imagine working in an environment where one line of code can make life easier for hundreds of millions of people. That’s what we do at Walmart Global Tech. We’re a team of software engineers, data scientists, cybersecurity expert's and service professionals within the world’s leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.

Walmart’s culture is a competitive advantage, and it’s fostered by being together. Working together in person allows us to collaborate, align quickly and innovate with greater speed. We use our campuses to create purposeful connection rooted in deepening understanding and investing in the development of our associates.
Our hubs: Walmart is a global company with offices across the United States and around the world. Our global headquarters is in Bentonville, Arkansas, with primary hubs in the San Francisco Bay area and New York/New Jersey.

Benefits
Benefits: Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.

Equal Opportunity Employer
Walmart, Inc. is an Equal Opportunity Employer – By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing diversity- unique styles, experiences, identities, ideas and opinions – while being inclusive of all people.

The above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

?

?

?
You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.

?

For information about PTO, see .

?

?
Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

?
Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

?

For information about benefits and eligibility, see .

?
The annual salary range for this position is $90,000.00-$180,000.00

?
Additional compensation includes annual or quarterly performance bonuses.

?
Additional compensation for certain positions may also include:

?

?
- Stock

?

?

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1- Bachelor’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years' experience in an analytics related field. Option 2- Master’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years' experience in an analytics related field. Option 3 - 5 years' experience in an analytics or related field.

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data science, machine learning, optimization models, Master’s degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.

Primary Location...

508 Sw 8Th St, Bentonville, AR 72712, United States of America",2025-07-05T00:00:00.000Z,2025-07-25,"['Ability to effectively coach junior data scientists to work through technical issues and business understandings', 'Ability to communicate internally and externally through publication, presentations, and other mediums on research progress, major breakthroughs, and product innovation', 'Experience with statistical analysis and programming languages e.g. Python and mainstream machine learning frameworks, e.g', 'TensorFlow or PyTorch', 'Experience in building machine learning applications', ""Option 1- Bachelor’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years' experience in an analytics related field"", ""Option 2- Master’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years' experience in an analytics related field"", ""Option 3 - 5 years' experience in an analytics or related field"", 'Data science, machine learning, optimization models, Master’s degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly', 'The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture']","['In this role, you will be building an LLM-powered intelligent experience, inside chatbot or business application, to improve employee experience and productivity', ""You'll be responsible for designing and building an intelligent conversational interface that enhances communication, automates tasks, accesses data and insights, and provides personalized Q&A support to employees, ultimately creating a more efficient and engaging work environment"", 'Work in a highly collaborative environment with a multidisciplinary team', 'Work with lead data scientists to design, architect, and build AI/ML model and model systems', 'Work with machine learning engineers to deploy, operate, and optimize scalable solutions', 'Work with product managers to design user journeys, feedback loop and analyze user telemetry', 'Create opportunities to develop yourself with an end-to-end AI/ML product experience', 'Work with a set of robust work standards to ensure we build trustworthy AI/ML solutions', 'Ability to execute our trustworthy AI/ML practice in collaboration with stakeholders across the enterprise']",True,"['Large Language Models', 'Generative AI', 'Conversational AI', 'Trustworthy AI Practices']","Large Language Models: Building LLM-powered intelligent experiences such as chatbots or business applications to improve employee productivity and communication.; Generative AI: Developing and deploying generative AI platforms and solutions to support associates globally, including intelligent conversational interfaces.; Conversational AI: Designing and building intelligent conversational interfaces that automate tasks, provide personalized Q&A support, and enhance communication within business applications.; Trustworthy AI Practices: Implementing robust standards and practices to ensure AI/ML solutions are trustworthy and reliable across the enterprise.","['Statistical Analysis', 'Python Programming', 'Machine Learning Frameworks', 'Machine Learning Applications', 'Data Science', 'Optimization Models', 'Spark, Scala, R', 'Scikit-learn']","Statistical Analysis: Used to analyze data and support the development of machine learning applications and AI/ML models in the role.; Python Programming: Programming language used for statistical analysis, data science tasks, and building machine learning applications.; Machine Learning Frameworks: Includes mainstream frameworks such as TensorFlow and PyTorch used to build and deploy machine learning models.; Machine Learning Applications: Experience required in building applications that leverage machine learning models to solve business problems.; Data Science: Involves designing, architecting, and building AI/ML models and systems, as well as coaching junior data scientists and collaborating with multidisciplinary teams.; Optimization Models: Preferred qualification involving mathematical models to improve decision-making and efficiency in analytics or machine learning contexts.; Spark, Scala, R: Technologies mentioned as part of assessments and preferred skills for data analytics and data science tasks.; Scikit-learn: Open source machine learning framework referenced as part of the technology stack for building models."
4M_WMfOdeE3FBSQaAAAAAA==,"Senior Data Scientist, Specialist Senior - SFL Scientific - Full-time","Senior Data Scientist, Specialist Senior - SFL Scientific

Our Deloitte Strategy & Transactions team helps guide clients through their most critical moments and transformational initiatives. From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability. Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journey-before, during, and after any major transformational projects or transactions.

SFL Scientific, a Deloitte Business, is a U.S. based, data science consulting firm specializing in building industry-specific, artificial intelligence (AI) technologies.

We are hiring a Senior Data Scientist to collaborate directly with clients to design and develop novel projects and solutions. Join a rapidly growing team of professionals working to build a world-class data science practice focused on solving complex and R&D problems.

Recruiting for this role ends on 7/31/2025.

Work You'll Do

As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services. You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions.

Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation. Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills.

+ Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production

+ Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives

+ Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization

+ Validate AI models and algorithm via code reviews, unit, and integration tests

+ Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives

+ Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives

The Team

Our Strategy offering architects bold strategies to achieve business and mission goals, enabling growth, competitive advantage, technology modernization, and continuous digital and AI transformation.

SFL Scientific, a Deloitte Business, is a data science professional services practice focused on strategy, technology, and solving business challenges with Artificial Intelligence (AI). The team has a proven track record serving large, market-leading organizations in the private and public sectors, successfully delivering high-quality, novel and complex projects, and offering deep domain and scientific capabilities. Made up of experienced AI strategists, data scientists, and AI engineers, they serve as trusted advisors to executives, helping them understand and evaluate new and essential areas for AI investment and identify unique opportunities to transform their businesses.

Qualifications:

+ Master's or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)

+ 3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)

+ 3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments

+ 3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow

+ 3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads

+ Live within commuting distance to one of Deloitte's consulting offices

+ Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve

+ Limited immigration sponsorship may be available

Preferred:

+ 2+ years of experience working in a client-facing, consulting environment

+ 2+ years of experience leading project/client engagement teams in the execution of complex AI data science solutions

+ 1+ year of experience with LLM/GenAI use cases and developing RAG solutions, tools, and services (i.e., LangChain, LangGraph, MCP, etc.)

+ 1+ year of experience with AWS Sagemaker or AWS ML Studio

Information for applicants with a need for accommodation: https://www2.deloitte.com/us/en/pages/careers/articles/join-deloitte-assistance-for-disabled-applicants.html

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $107,600 to $198,400.

You may also be eligible to participate in a discretionary annual incentive program, subject to the rules governing the program, whereby an award, if any, depends on various factors, including, without limitation, individual and organizational performance.

#MonitorDeloitte

#DeloitteJobs

#StrategyConsulting

#DeloitteStrategy

#Strategy26

#SFL26

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.

Senior Data Scientist, Specialist Senior - SFL Scientific

Our Deloitte Strategy & Transactions team helps guide clients through their most critical moments and transformational initiatives. From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability. Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journey-before, during, and after any major transformational projects or transactions.

SFL Scientific, a Deloitte Business, is a U.S. based, data science consulting firm specializing in building industry-specific, artificial intelligence (AI) technologies.

We are hiring a Senior Data Scientist to collaborate directly with clients to design and develop novel projects and solutions. Join a rapidly growing team of professionals working to build a world-class data science practice focused on solving complex and R&D problems.

Recruiting for this role ends on 7/31/2025.

Work You'll Do

As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services. You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions.

Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation. Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills.

+ Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production

+ Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives

+ Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization

+ Validate AI models and algorithm via code reviews, unit, and integration tests

+ Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives

+ Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives

The Team

Our Strategy offering architects bold strategies to achieve business and mission goals, enabling growth, competitive advantage, technology modernization, and continuous digital and AI transformation.

SFL Scientific, a Deloitte Business, is a data science professional services practice focused on strategy, technology, and solving business challenges with Artificial Intelligence (AI). The team has a proven track record serving large, market-leading organizations in the private and public sectors, successfully delivering high-quality, novel and complex projects, and offering deep domain and scientific capabilities. Made up of experienced AI strategists, data scientists, and AI engineers, they serve as trusted advisors to executives, helping them understand and evaluate new and essential areas for AI investment and identify unique opportunities to transform their businesses.

Qualifications:

+ Master's or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)

+ 3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)

+ 3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments

+ 3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow

+ 3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads

+ Live within commuting distance to one of Deloitte's consulting offices

+ Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve

+ Limited immigration sponsorship may be available

Preferred:

+ 2+ years of experience working in a client-facing, consulting environment

+ 2+ years of experience leading project/client engagement teams in the execution of complex AI data science solutions

+ 1+ year of experience with LLM/GenAI use cases and developing RAG solutions, tools, and services (i.e., LangChain, LangGraph, MCP, etc.)

+ 1+ year of experience with AWS Sagemaker or AWS ML Studio

Information for applicants with a need for accommodation: https://www2.deloitte.com/us/en/pages/careers/articles/join-deloitte-assistance-for-disabled-applicants.html

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $107,600 to $198,400.

You may also be eligible to participate in a discretionary annual incentive program, subject to the rules governing the program, whereby an award, if any, depends on various factors, including, without limitation, individual and organizational performance.

#MonitorDeloitte

#DeloitteJobs

#StrategyConsulting

#DeloitteStrategy

#Strategy26

#SFL26

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.",2025-07-24T00:00:00.000Z,2025-07-25,"[""Master's or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)"", '3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)', '3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments', '3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow', '3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads', ""Live within commuting distance to one of Deloitte's consulting offices"", 'Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve', 'Limited immigration sponsorship may be available', ""Master's or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)"", '3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)', '3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments', '3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow', '3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads', ""Live within commuting distance to one of Deloitte's consulting offices"", 'Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve', 'Limited immigration sponsorship may be available']","['From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability', 'Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journey-before, during, and after any major transformational projects or transactions', 'As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services', 'You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions', 'Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation', 'Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills', 'Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production', 'Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives', 'Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization', 'Validate AI models and algorithm via code reviews, unit, and integration tests', 'Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives', 'Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives', 'From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability', 'Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journey-before, during, and after any major transformational projects or transactions', 'As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services', 'You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions', 'Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation', 'Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills', 'Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production', 'Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives', 'Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization', 'Validate AI models and algorithm via code reviews, unit, and integration tests', 'Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives', 'Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives']",True,"['Generative AI', 'Large Language Models (LLMs)', 'Retrieval-Augmented Generation', 'Prompt Engineering', 'Deep Learning Frameworks for AI', 'AI Model Validation and Testing', 'AI Strategy and Development', 'AI/ML Model Deployment and Optimization', 'Cloud AI/ML Workloads', 'AWS SageMaker', 'AWS ML Studio', 'Multi-Modal AI Techniques']","Generative AI: The role involves working on generative AI use cases, including developing solutions and services related to large language models and generative AI technologies.; Large Language Models (LLMs): Experience with LLMs is required, including use cases and development of retrieval-augmented generation (RAG) solutions.; Retrieval-Augmented Generation: Developing RAG solutions, tools, and services such as LangChain and LangGraph is part of the job responsibilities.; Prompt Engineering: The role includes responsibilities related to prompt engineering for AI models.; Deep Learning Frameworks for AI: PyTorch is used specifically for deep learning model development and training in AI projects.; AI Model Validation and Testing: Validating AI models and algorithms through code reviews, unit tests, and integration tests is a key responsibility.; AI Strategy and Development: The role guides clients in AI strategy, including understanding organizational needs, developing AI solutions, and deploying models into production.; AI/ML Model Deployment and Optimization: Deploying and optimizing AI/ML models using tools like Kubernetes, Docker, TensorRT, RAPIDs, Kubeflow, and MLflow is required.; Cloud AI/ML Workloads: Leveraging cloud platforms such as AWS, Azure, or GCP to deploy AI/ML workloads and services is part of the job.; AWS SageMaker: Experience with AWS SageMaker is preferred for deploying and managing AI/ML models in the cloud.; AWS ML Studio: Experience with AWS ML Studio is preferred for building and deploying AI/ML solutions.; Multi-Modal AI Techniques: The role includes working with AI techniques across NLP, computer vision, and time-series analysis within AI projects.","['Machine Learning', 'Deep Learning', 'Exploratory Data Analysis', 'NLP (Natural Language Processing)', 'Time-Series Analysis', 'Computer Vision', 'Python', 'PyTorch', 'Kubernetes', 'Docker', 'TensorRT', 'RAPIDs', 'Kubeflow', 'MLflow', 'Cloud Environments (AWS, Azure, GCP)', 'Valuation Modeling', 'Cost Optimization', 'Restructuring', 'Business Design and Transformation', 'Mergers and Acquisitions (M&A)']","Machine Learning: The role involves developing and deploying machine learning algorithms and models, including traditional ML techniques and model tuning and validation in production environments.; Deep Learning: Experience applying deep learning techniques such as CNNs, RNNs, and GANs across real-world projects is required, including model tuning and performance validation.; Exploratory Data Analysis: Performing exploratory data analysis to understand client data sets and operational requirements is a key responsibility.; NLP (Natural Language Processing): The job requires experience in NLP as part of data analysis tasks.; Time-Series Analysis: Experience with time-series analysis is required for analyzing temporal data in client projects.; Computer Vision: The role includes experience in computer vision techniques as part of data analysis and model development.; Python: Python is a core programming language used for AI/ML algorithm development and data analysis.; PyTorch: PyTorch is used as a framework for AI/ML algorithm development and deep learning model implementation.; Kubernetes: Kubernetes is used for deploying and optimizing machine learning models in production environments.; Docker: Docker is used for containerizing ML models to facilitate deployment and scalability.; TensorRT: TensorRT is used for optimizing ML models for inference performance.; RAPIDs: RAPIDs is used for accelerating ML model deployment and optimization.; Kubeflow: Kubeflow is used to manage ML workflows and pipelines for model deployment and optimization.; MLflow: MLflow is used for managing the machine learning lifecycle including experimentation, reproducibility, and deployment.; Cloud Environments (AWS, Azure, GCP): Experience leveraging cloud platforms such as AWS, Azure, or GCP to deploy AI/ML workloads is required.; Valuation Modeling: The team delivers advisory services including valuation modeling as part of business transformation projects.; Cost Optimization: Cost optimization is part of the integrated support and advisory services provided to clients.; Restructuring: Restructuring is included in the advisory services offered during transformational initiatives.; Business Design and Transformation: The role supports business design and transformation efforts through data science and analytics.; Mergers and Acquisitions (M&A): The team provides support and advisory services related to mergers and acquisitions."
URwTuFHHXHOExfnrAAAAAA==,Data Analyst - Senior,"About the position

The Senior Data Analyst at Cayuse Federal Services plays a crucial role in supporting IRS compliance activities by leveraging data obtained from IRS systems. This position focuses on identifying trends in payment collections and taxpayer behaviors, developing systemic solutions, and documenting analytical work for transfer to appropriate agency functions. The role requires strong analytical skills, effective communication, and the ability to work collaboratively with government clients and internal teams.

Responsibilities
• Meet with Government clients to understand their business needs, define research objectives, identify data sources, and develop analysis plans
,
• Apply critical thinking and creative problem-solving skills to proactively identify and develop solutions for clients' business problems
,
• Conduct exploratory data analysis using large-scale Government data sources and develop briefings and reports to communicate key findings
,
• Work with teams of data scientists to build pipelines for data engineering and machine learning
,
• Collaborate with software developers to build tools for data visualization and analysis
,
• Develop recommendations based on completed research and analysis and present these recommendations to government clients
,
• Demonstrate superior verbal and written communication skills, explaining complex analytical concepts to stakeholders
,
• Take ownership of tasks and develop high-quality work products with minimal supervision
,
• Perform other duties as assigned

Requirements
• Bachelor's in Economics, Statistics, Mathematics, Computer Science, or other quantitative field, or equivalent experience
,
• 5+ years of professional experience
,
• 5+ years of depth understanding of data constructs, basic statistical concepts, and analytical methods
,
• 5+ years of experience formulating data-driven recommendations
,
• Must be able to pass a background check and obtain a Federal Public Trust Clearance
,
• US Citizenship or Lawful Permanent Resident status required for clearance

Nice-to-haves
• Familiarity with statistical programming languages such as SAS, R, or Stata
,
• Experience with structured databases and query languages (e.g., PL/SQL, Postgres, MySQL)

Benefits
• Competitive salary range of USD $135,000.00 - USD $146,000.00 per year
,
• Remote work flexibility
,
• Professional development opportunities
,
• Diversity and equal opportunity workplace",,2025-07-25,"[""Bachelor's in Economics, Statistics, Mathematics, Computer Science, or other quantitative field, or equivalent experience"", '5+ years of professional experience', '5+ years of depth understanding of data constructs, basic statistical concepts, and analytical methods', '5+ years of experience formulating data-driven recommendations', 'Must be able to pass a background check and obtain a Federal Public Trust Clearance', 'US Citizenship or Lawful Permanent Resident status required for clearance', 'Familiarity with statistical programming languages such as SAS, R, or Stata', 'Experience with structured databases and query languages (e.g., PL/SQL, Postgres, MySQL)']","['The Senior Data Analyst at Cayuse Federal Services plays a crucial role in supporting IRS compliance activities by leveraging data obtained from IRS systems', 'This position focuses on identifying trends in payment collections and taxpayer behaviors, developing systemic solutions, and documenting analytical work for transfer to appropriate agency functions', 'The role requires strong analytical skills, effective communication, and the ability to work collaboratively with government clients and internal teams', 'Meet with Government clients to understand their business needs, define research objectives, identify data sources, and develop analysis plans', ""Apply critical thinking and creative problem-solving skills to proactively identify and develop solutions for clients' business problems"", 'Conduct exploratory data analysis using large-scale Government data sources and develop briefings and reports to communicate key findings', 'Work with teams of data scientists to build pipelines for data engineering and machine learning', 'Collaborate with software developers to build tools for data visualization and analysis', 'Develop recommendations based on completed research and analysis and present these recommendations to government clients', 'Demonstrate superior verbal and written communication skills, explaining complex analytical concepts to stakeholders', 'Take ownership of tasks and develop high-quality work products with minimal supervision', 'Perform other duties as assigned']",True,[],,"['Exploratory Data Analysis', 'Data Engineering Pipelines', 'Machine Learning', 'Statistical Programming Languages', 'Structured Query Languages', 'Data-Driven Recommendations', 'Data Visualization Tools', 'Statistical Concepts and Analytical Methods']","Exploratory Data Analysis: Used to analyze large-scale government data sources to identify trends in payment collections and taxpayer behaviors and to develop briefings and reports communicating key findings.; Data Engineering Pipelines: Collaborated with data scientists to build pipelines that support data processing and machine learning workflows.; Machine Learning: Worked with teams of data scientists to support machine learning initiatives as part of data pipeline development.; Statistical Programming Languages: Familiarity with SAS, R, or Stata is considered beneficial for performing statistical analysis and data manipulation.; Structured Query Languages: Experience with PL/SQL, Postgres, and MySQL is valued for querying and managing structured databases.; Data-Driven Recommendations: Formulated actionable recommendations based on data analysis and research to support government clients' business needs.; Data Visualization Tools: Collaborated with software developers to build tools that facilitate data visualization and analysis for stakeholders.; Statistical Concepts and Analytical Methods: Applied basic statistical concepts and analytical methods to support data analysis and problem-solving."
lOCgHizrc8Tp_KfIAAAAAA==,Senior Project Manager Data Analytics,"JOB DETAILS:

Title: IT Project Manager – Data Analytics

Location: Century City, CA (Remote / Hybrid role – 1-2 days onsite, 3-4 days remote work)

Type: 06 -12 plus months contract (possible extension)

Job Description:

As a Project Manager for the Applied Data & Insights team, will lead and orchestrate projects that seamlessly blend engineering, data analytics and data science from API endpoint to strategic Insight.

Focus on; Project management, Scrum practices, change management, user engagement, user training and the creation of technical documentation.
Involve collaborating with cross-functional teams, including engineers, data analysts, data scientists, and stakeholders to deliver innovative solutions that drive our company's success across the Sports and Entertainment business units.
Key Responsibilities:

Project Planning and Scoping:
• Define and document clear project objectives, scope, and deliverables, taking into account the principles of Scrum and Agile project management.
• Develop comprehensive project plans that incorporate well-defined timelines and resource allocation.
• Engage with cross-functional teams, ensuring that they are aligned with project objectives and adhere to project timelines.

Stakeholder Engagement:
• Act as the primary point of contact for project stakeholders, maintaining open and transparent communication.
• Funnel new intake requests to the appropriate channels
• Continuously update stakeholders and senior management on project status, progress, and changes in alignment.

Change Management:
• Work to create awareness and increase adoption of products and tools provided by the data team through stakeholder communications, training, and collecting feedback to bring back to the data teams.
• Implement effective change management strategies to implement new products, and manage changes in project scope, requirements, and stakeholder expectations.
• Ensure a smooth transition when implementing changes, addressing user concerns and promoting user adoption.

Documentation & Training:
• Create and maintain user and technical documentation to support project management, user engagement, and future maintenance.
• Lead and develop instructional training sessions for stakeholders that focus on newly released products.

Qualifications:
• Bachelor's degree in a relevant field or equivalent work experience (e.g., Project Management, Engineering, Computer Science, Data Analytics or Data Science).
• PMP, Scrum Master, or similar project management and Scrum certification is a plus.
• At least 5 years experience managing projects at the intersection of engineering and analytics, while applying Scrum principles.
• Deep Understanding of linear and digital platforms
• Prior major studio project management experience is a plus

Required Skill Sets:
• Excellent communication and presentation skills.
• Strong interpersonal skills with the ability to build stakeholder relationships
• Strong analytical and problem solving skills.
• Proficiency in analytics tools: Looker & Tableau
• Familiarity with: AWS, Redshift, S3 & Snowflake
• Knowledge of engineering principles and Scrum methodologies.
• Adaptability to changing priorities in a fast-paced environment.

Thank you for your time and consideration.

Thanks & Regards

Lokesh (Luke) | Talent Acquisition Specialist

Tel: | Email:

iSpace Inc | El Segundo, CA |",,2025-07-25,"[""Bachelor's degree in a relevant field or equivalent work experience (e.g., Project Management, Engineering, Computer Science, Data Analytics or Data Science)"", 'At least 5 years experience managing projects at the intersection of engineering and analytics, while applying Scrum principles', 'Deep Understanding of linear and digital platforms', 'Excellent communication and presentation skills', 'Strong interpersonal skills with the ability to build stakeholder relationships', 'Strong analytical and problem solving skills', 'Proficiency in analytics tools: Looker & Tableau', 'Familiarity with: AWS, Redshift, S3 & Snowflake', 'Knowledge of engineering principles and Scrum methodologies', 'Adaptability to changing priorities in a fast-paced environment']","['As a Project Manager for the Applied Data & Insights team, will lead and orchestrate projects that seamlessly blend engineering, data analytics and data science from API endpoint to strategic Insight', 'Focus on; Project management, Scrum practices, change management, user engagement, user training and the creation of technical documentation', ""Involve collaborating with cross-functional teams, including engineers, data analysts, data scientists, and stakeholders to deliver innovative solutions that drive our company's success across the Sports and Entertainment business units"", 'Define and document clear project objectives, scope, and deliverables, taking into account the principles of Scrum and Agile project management', 'Develop comprehensive project plans that incorporate well-defined timelines and resource allocation', 'Engage with cross-functional teams, ensuring that they are aligned with project objectives and adhere to project timelines', 'Act as the primary point of contact for project stakeholders, maintaining open and transparent communication', 'Funnel new intake requests to the appropriate channels', 'Continuously update stakeholders and senior management on project status, progress, and changes in alignment', 'Work to create awareness and increase adoption of products and tools provided by the data team through stakeholder communications, training, and collecting feedback to bring back to the data teams', 'Implement effective change management strategies to implement new products, and manage changes in project scope, requirements, and stakeholder expectations', 'Ensure a smooth transition when implementing changes, addressing user concerns and promoting user adoption', 'Create and maintain user and technical documentation to support project management, user engagement, and future maintenance', 'Lead and develop instructional training sessions for stakeholders that focus on newly released products']",False,,,,
YgWt9pI83ZqHguR3AAAAAA==,"Senior Data Analyst, Marketing","EXL is hiring a Senior Data Analyst, Marketing with 5 - 10 years of experience. Based in United States - Minneapolis, MN and with In-office ways of working.

Job description and responsibilities:

Location: Minneapolis, MN or New York City, NY (preferred), Other locations include New Jersey, Pennsylvania, or Delaware

Overview: We are seeking a highly skilled Senior Data Analyst to join our team. In this role, you will collaborate with clients to understand data requirements, analyze large data sets, and deliver actionable insights that drive business decisions. Your deep expertise in marketing analytics will be critical in being successful in this role.

Key Responsibilities
• Partner with business leaders to define and understand data requirements, conduct research, and present analytical solutions.
• Manage and execute large-scale data analytics projects, integrating extensive data sets to provide actionable insights and recommendations.
• Design and implement marketing campaigns, including audience selection, campaign strategies, and performance measurement.
• Develop and execute various testing strategies, including A/B testing, multivariate testing, and holdout tests, to optimize marketing efforts.
• Ideate and implement changes to digital marketing materials based on data-driven insights and testing results.
• Monitor and evaluate the outcomes of testing efforts to refine and enhance marketing strategies.
• Develop and maintain technical documentation and client-facing materials to support data-driven decision-making.
• Apply advanced statistical techniques and tools to interpret data and deliver clear, concise data visualizations.
• Ensure compliance with company standards for data acquisition, sharing, and application of recommendations.

Requirements and qualifications:

Basic Qualifications
• Bachelor’s degree in a quantitative field such as Econometrics, Computer Science, Engineering, Applied Mathematics, or a related discipline, or equivalent work experience.
• Minimum of 5 years of experience in statistics or analytics.

Preferred Skills And Experience
• Extensive experience in marketing analytics, including designing and running marketing campaigns, executing A/B tests, and ideating testing strategies.
• Deep understanding of digital marketing materials and the ability to recommend and implement changes based on analytical insights.
• Proficiency with SAS, SQL, R, or Python for data analysis.
• Expertise in data visualization tools such as Tableau, Power BI, or similar.
• Strong analytical skills with experience in querying and interpreting complex data sets.
• Master’s degree in a relevant field is advantageous.
• Proven experience in designing practical experiments and measuring marketing campaign effectiveness.
• Skilled in analytic storytelling and presentation using PowerPoint or similar tools.
• Effective communication skills for direct interaction with business lines to understand needs and present findings.
• Experience in financial services with in-depth knowledge of financial products, customer interactions, and data systems.
• Demonstrated understanding of statistical analysis methodologies.
• Proven ability to drive analytics into actionable business outcomes.
• Strong project management and organizational skills.
• Ability to work both collaboratively and independently to achieve results.",,2025-07-25,"['Bachelor’s degree in a quantitative field such as Econometrics, Computer Science, Engineering, Applied Mathematics, or a related discipline, or equivalent work experience', 'Minimum of 5 years of experience in statistics or analytics']","['In this role, you will collaborate with clients to understand data requirements, analyze large data sets, and deliver actionable insights that drive business decisions', 'Your deep expertise in marketing analytics will be critical in being successful in this role', 'Partner with business leaders to define and understand data requirements, conduct research, and present analytical solutions', 'Manage and execute large-scale data analytics projects, integrating extensive data sets to provide actionable insights and recommendations', 'Design and implement marketing campaigns, including audience selection, campaign strategies, and performance measurement', 'Develop and execute various testing strategies, including A/B testing, multivariate testing, and holdout tests, to optimize marketing efforts', 'Ideate and implement changes to digital marketing materials based on data-driven insights and testing results', 'Monitor and evaluate the outcomes of testing efforts to refine and enhance marketing strategies', 'Develop and maintain technical documentation and client-facing materials to support data-driven decision-making', 'Apply advanced statistical techniques and tools to interpret data and deliver clear, concise data visualizations', 'Ensure compliance with company standards for data acquisition, sharing, and application of recommendations']",True,[],,"['Marketing Analytics', 'A/B Testing', 'Multivariate Testing', 'Holdout Testing', 'Statistical Analysis', 'Data Visualization', 'SQL', 'Python', 'R', 'SAS', 'Data Integration', 'Analytic Storytelling']","Marketing Analytics: Used to design and run marketing campaigns, execute A/B and multivariate tests, and optimize marketing efforts through data-driven insights and testing results.; A/B Testing: Developed and executed as a testing strategy to optimize marketing campaigns and measure their effectiveness.; Multivariate Testing: Applied as a testing strategy alongside A/B testing and holdout tests to refine marketing strategies and improve campaign performance.; Holdout Testing: Used as a testing method to evaluate marketing campaign effectiveness by comparing test groups with control groups.; Statistical Analysis: Applied advanced statistical techniques to interpret data, support decision-making, and measure marketing campaign effectiveness.; Data Visualization: Created clear and concise visual representations of data using tools like Tableau and Power BI to support data-driven decision-making and client presentations.; SQL: Used for querying and interpreting complex data sets to extract actionable insights.; Python: Utilized for data analysis and statistical computations in marketing analytics projects.; R: Employed for statistical analysis and data manipulation in marketing analytics.; SAS: Used for advanced statistical analysis and data management in marketing analytics.; Data Integration: Managed and executed large-scale data analytics projects by integrating extensive data sets to provide actionable insights and recommendations.; Analytic Storytelling: Used to effectively communicate analytical findings and insights to business stakeholders through presentations and client-facing materials."
I0EBmZc4z5e7wiLPAAAAAA==,"Senior Research Data Scientist, YouTube Search (San Bruno)","Senior Research Data Scientist, YouTube Search

Join to apply for the Senior Research Data Scientist, YouTube Search role at Google
Senior Research Data Scientist, YouTube Search

Join to apply for the Senior Research Data Scientist, YouTube Search role at Google

Get AI-powered advice on this job and more exclusive features.

Note: By applying to this position you will have an opportunity to share your preferred working location from the following: Mountain View, CA, USA; San Bruno, CA, USA.Minimum qualifications:
• Master's degree in Statistics, Data Science, Mathematics, Physics, Economics, Operations Research, Engineering, or a related quantitative field or equivalent practical experience.
• 5 years of experience using analytics to solve product or business problems, coding (e.g., Python, R, SQL), querying databases or statistical analysis, or 3 years of work experience with a PhD degree.

Preferred qualifications:
• 8 years of work experience using analytics to solve product or business problems, coding (e.g., Python, R, SQL), querying databases or statistical analysis, or 6 years of work experience with a PhD degree.

About the jobIn this role, you will develop solutions to problems faced by YouTube (YT) Search. The role also involves participating in experiments to understand issues, and contributing to foundational improvements in data quality.The US base salary range for this full-time position is $166,000-$244,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.

Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google .

Responsibilities
• Collaborate with stakeholders in cross-projects and team settings to identify business or product questions to answer. Provide feedback to translate business questions into analysis, evaluation metrics, or mathematical models.
• Use custom data infrastructure or existing data models. Design and evaluate models to mathematically express and solve defined problems.
• Gather information, business goals, priorities, and organizational context around the questions to answer, as well as the existing and upcoming data infrastructure.
• Own the process of gathering, extracting, and compiling data across sources via tools (e.g., SQL, R, Python). Format, re-structure, or validate data to ensure quality, and review the dataset to ensure it is ready for analysis.

Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .Seniority level
• Seniority levelMid-Senior level
Employment type
• Employment typeFull-time
Job function
• Job functionInformation Technology and Engineering
• IndustriesInformation Services and Technology, Information and Internet

Referrals increase your chances of interviewing at Google by 2x

Get notified about new Senior Data Scientist jobs in San Bruno, CA.

San Francisco, CA $226,085.00-$283,250.00 1 day ago

San Francisco, CA $253,000.00-$314,000.00 6 days ago

Menlo Park, CA $206,000.00-$281,000.00 2 weeks ago

San Francisco, CA $206,000.00-$281,000.00 2 weeks ago

San Francisco, CA $182,000.00-$215,000.00 4 months ago
Clinical Data Scientist (Contract to Hire)Data Science Manager, Ads Horizontal Lead

Oakland, CA $193,000.00-$329,000.00 1 month ago

San Francisco County, CA $240,000.00-$275,000.00 1 month ago

Palo Alto, CA $154,000.00-$237,150.00 2 weeks ago
Geospatial Data Scientist (Research Fellow or Part-time Consultant)

San Francisco, CA $40.00-$80.00 1 month ago
Data Science Manager, Demand Planning and Forecasting

Burlingame, CA $206,000.00-$281,000.00 12 hours ago
Geospatial Data Scientist (Research Fellow or Part-time Consultant)Director, Scientific Content Engineering/Data Science, QDISenior Manager, Infrastructure Data ScienceDirector of Data Science - Recommendations and E-Commerce

San Francisco, CA $201,700.00-$267,300.00 1 month ago
Director, Data Science/AI Product Owner (Gen AI/ Agentic AI)Director, Data Science/AI Product Owner (Predictive AI/ Agentic AI)Senior Manager, Infrastructure Data ScienceDirector, Data Science / AI Product Owner (Analytical Workbench)Manager, Data Science & Analytics - Dasher EarningsSenior/Lead Data Analyst, Paid Media Marketing

San Francisco, CA $156,300.00-$218,900.00 2 weeks ago
Director of Finance and Administration, Biomedical Data Science

Stanford, CA $205,050.00-$283,688.00 1 week ago

Palo Alto, CA $128,000.00-$178,000.00 3 weeks ago

Were unlocking community knowledge in a new way. Experts add insights directly into each article, started with the help of AI.

#J-18808-Ljbffr",2025-07-17T00:00:00.000Z,2025-07-25,"[""Master's degree in Statistics, Data Science, Mathematics, Physics, Economics, Operations Research, Engineering, or a related quantitative field or equivalent practical experience"", '5 years of experience using analytics to solve product or business problems, coding (e.g., Python, R, SQL), querying databases or statistical analysis, or 3 years of work experience with a PhD degree', 'Seniority levelMid-Senior level', 'Geospatial Data Scientist (Research Fellow or Part-time Consultant)', 'San Francisco, CA $40.00-$80.00 1 month ago', 'Data Science Manager, Demand Planning and Forecasting', 'Geospatial Data Scientist (Research Fellow or Part-time Consultant)Director, Scientific Content Engineering/Data Science, QDISenior Manager, Infrastructure Data ScienceDirector of Data Science - Recommendations and E-Commerce', 'San Francisco, CA $201,700.00-$267,300.00 1 month ago', 'Director, Data Science/AI Product Owner (Gen AI/ Agentic AI)Director, Data Science/AI Product Owner (Predictive AI/ Agentic AI)Senior Manager, Infrastructure Data ScienceDirector, Data Science / AI Product Owner (Analytical Workbench)Manager, Data Science & Analytics - Dasher EarningsSenior/Lead Data Analyst, Paid Media Marketing', 'Director of Finance and Administration, Biomedical Data Science']","['In this role, you will develop solutions to problems faced by YouTube (YT) Search', 'The role also involves participating in experiments to understand issues, and contributing to foundational improvements in data quality', 'Collaborate with stakeholders in cross-projects and team settings to identify business or product questions to answer', 'Provide feedback to translate business questions into analysis, evaluation metrics, or mathematical models', 'Use custom data infrastructure or existing data models', 'Design and evaluate models to mathematically express and solve defined problems', 'Gather information, business goals, priorities, and organizational context around the questions to answer, as well as the existing and upcoming data infrastructure', 'Own the process of gathering, extracting, and compiling data across sources via tools (e.g., SQL, R, Python)', 'Format, re-structure, or validate data to ensure quality, and review the dataset to ensure it is ready for analysis', 'IndustriesInformation Services and Technology, Information and Internet']",True,[],,"['Statistical Analysis', 'Python', 'R', 'SQL', 'Data Infrastructure', 'Mathematical Modeling', 'Data Quality Assurance']","Statistical Analysis: Used to analyze and interpret data to solve product or business problems and to evaluate models mathematically expressing defined problems.; Python: Used as a coding tool for data extraction, querying databases, and data manipulation to prepare datasets for analysis.; R: Used as a coding tool for querying databases, statistical analysis, and data manipulation to ensure data quality and readiness for analysis.; SQL: Used to query databases and extract data from multiple sources as part of the data gathering and compilation process.; Data Infrastructure: Involves using custom or existing data models and infrastructure to support data gathering, extraction, and analysis for solving business or product questions.; Mathematical Modeling: Designing and evaluating models to mathematically express and solve defined problems related to YouTube Search.; Data Quality Assurance: Involves formatting, restructuring, validating data, and reviewing datasets to ensure they are accurate and ready for analysis."
e1YXftmzhcWxYPZAAAAAAA==,RWE Data Scientist II,"Job description:
As a Real-World Data (RWD) Scientist , you will be part of a team powering data driven insights that lead to better, faster decisions and therapies for our patients. Acting as a lead data scientist in your project area, you will contribute RWD expertise to broader cross-functional initiatives. Candidates should be excited to drive innovation by implementing new business technology solutions that solve significant scientific or business problems through the use and understanding of complex data. Your role will be to conceive, design and execute analytical components of research studies using sources of Real-World Data and Genetics including, but not limited to large healthcare administrative databases, electronic medical records, registries and surveys. Your expertise will be critical as you investigate, identify, develop, and optimize new methods, algorithms, and technologies to derive Client, competitive insights from disparate data sources.
Responsibilities:
• Conceive, design and implement new RWD business technology solutions that solve significant scientific or business problems through the integration, visualization, and analysis of large and complex data.
• Demonstrate high proficiency across a wide range of technologies related to the integration, visualization, and analysis of large and complex real-world data sets.
• Maintain broad expertise analyzing large real-world data including medical claims data, electronic medical records, survey data, etc.
• Demonstrate the ability to resolve key project hurdles and assumptions by effectively utilizing available information and technical expertise.
• Expand advanced methodology and adopt new technology capabilities such as machine learning, RWE dashboards and visualizations, automation, etc.
• Utilize knowledge of the pharmaceutical and healthcare business in the rapid advancement of agile, impactful, and cost-effective solutions.
• Drive productivity and efficiency gains throughout multiple business areas.
• Highly autonomous and productive in performing activities, requiring only minimal direction from or interaction with supervisor.
• Proactively seek out new information and technologies in the literature/public domain and incorporate into individual project(s) as well as the overall program.
• Understand and adhere to corporate standards regarding applicable Corporate and Divisional Policies, including code of conduct, safety, GxP compliance, and data security.
Requirements:
• M.S. (Master of Science), or PhD with 2 years of experience in HEOR/Epidemiology or related area.
• Background in life sciences or work experience in the pharmaceutical industry preferred.
• Significant experience with SAS, SAS Macro SQL, or other programming for real-world data analytics (i.e. or Python).
• Experience and/or training in the application of advanced scientific and analytical methods.
• Proven implementation of creative technology solutions that advanced the business.
• Excellent written and oral English communication skills.",,2025-07-25,"['M.S. (Master of Science), or PhD with 2 years of experience in HEOR/Epidemiology or related area', 'Significant experience with SAS, SAS Macro SQL, or other programming for real-world data analytics (i.e. or Python)', 'Experience and/or training in the application of advanced scientific and analytical methods', 'Proven implementation of creative technology solutions that advanced the business', 'Excellent written and oral English communication skills']","['Acting as a lead data scientist in your project area, you will contribute RWD expertise to broader cross-functional initiatives', 'Candidates should be excited to drive innovation by implementing new business technology solutions that solve significant scientific or business problems through the use and understanding of complex data', 'Your role will be to conceive, design and execute analytical components of research studies using sources of Real-World Data and Genetics including, but not limited to large healthcare administrative databases, electronic medical records, registries and surveys', 'Your expertise will be critical as you investigate, identify, develop, and optimize new methods, algorithms, and technologies to derive Client, competitive insights from disparate data sources', 'Conceive, design and implement new RWD business technology solutions that solve significant scientific or business problems through the integration, visualization, and analysis of large and complex data', 'Demonstrate high proficiency across a wide range of technologies related to the integration, visualization, and analysis of large and complex real-world data sets', 'Maintain broad expertise analyzing large real-world data including medical claims data, electronic medical records, survey data, etc', 'Demonstrate the ability to resolve key project hurdles and assumptions by effectively utilizing available information and technical expertise', 'Expand advanced methodology and adopt new technology capabilities such as machine learning, RWE dashboards and visualizations, automation, etc', 'Utilize knowledge of the pharmaceutical and healthcare business in the rapid advancement of agile, impactful, and cost-effective solutions', 'Drive productivity and efficiency gains throughout multiple business areas', 'Highly autonomous and productive in performing activities, requiring only minimal direction from or interaction with supervisor', 'Proactively seek out new information and technologies in the literature/public domain and incorporate into individual project(s) as well as the overall program', 'Understand and adhere to corporate standards regarding applicable Corporate and Divisional Policies, including code of conduct, safety, GxP compliance, and data security']",True,[],,"['Real-World Data Analytics', 'SAS and SAS Macro SQL', 'Python Programming', 'Advanced Scientific and Analytical Methods', 'Machine Learning', 'Data Integration and Visualization', 'Real-World Evidence (RWE) Dashboards']","Real-World Data Analytics: Involves analyzing large and complex real-world data sets such as medical claims data, electronic medical records, registries, and surveys to derive insights relevant to healthcare and pharmaceutical research.; SAS and SAS Macro SQL: Used as primary programming tools for real-world data analytics, enabling data manipulation, querying, and analysis within healthcare datasets.; Python Programming: Applied for programming and analytical tasks related to real-world data, supporting data integration, visualization, and advanced analytics.; Advanced Scientific and Analytical Methods: Includes the application and training in sophisticated analytical techniques to solve scientific and business problems using complex data.; Machine Learning: Adopted as an advanced methodology to enhance data analysis, automate processes, and develop predictive models within real-world evidence projects.; Data Integration and Visualization: Involves combining disparate data sources and creating visual representations such as dashboards to support decision-making and insight generation.; Real-World Evidence (RWE) Dashboards: Used to visualize and communicate insights derived from real-world data to stakeholders, facilitating faster and better decision-making."
p047tmTGAAKrsnDzAAAAAA==,"Senior Data Scientist, Marketing Analytics","In order to be considered for this role, after clicking ""Apply Now"" above and being redirected, you must fully complete the application process on the follow-up screen.

At PrizePicks, we are the fastest-growing sports company in North America, as recognized by Inc. 5000. As the leading platform for Daily Fantasy Sports, we cover a diverse range of sports leagues, including the NFL, NBA, and Esports titles like League of Legends and Counter-Strike. Our team of over 450 employees thrives in an inclusive culture that values individuals from diverse backgrounds, regardless of their level of sports fandom. Ready to reimagine the DFS industry together?

We are looking for an inquisitive, highly analytical, and detail-oriented Senior Data Scientist, experienced in Acquisition Marketing. This data-centric role is vital for building and maintaining analytics tools and workflows. A passion for solving problems around marketing attribution, spend optimization, and guiding profitable growth for the business is essential for success. You're an excellent fit for this role if you're comfortable managing projects simultaneously, working with a cross-functional team, and informing and influencing stakeholders with data, using insights to drive outcomes. What you'll do:
• Support the advancement of analytical capabilities across acquisition and retention marketing
• Develop and implement advanced analytics frameworks to tell the story of marketing performance and make budget recommendations, including media mix modeling (MMM) and channel-level marginal CAC
• Drive the learning agenda related to channel strategy, e.g. geo-level testing and media mix testing, working with marketing leadership to operationalize
• Create central reporting solutions to create holistic, executive-level, and cross-functional visibility into marketing performance, and establish and communicate the narrative around performance at appropriate altitude
• Develop required data collection and transformation processes to support reporting and analytics solutions
• Create presentations and written documents with little guidance, and present to both technical and non-technical audiences in an effective way, articulating ideas and opinions clearly and efficiently
• Serve as a mentor to more junior analysts, contributing to the advancement of capabilities and work across the Marketing Analytics organization, and act as an example for the team to follow
What you have:
• Bachelor's degree in Statistics, Economics, Computer Science, Data Science, Engineering, or a related field
• 5+ years' of Marketing Data Analytics experience in an e-commerce, direct-to-consumer environment
• Advanced knowledge of SQL, including comfort with analytics functions, window functions, and common table expressions
• 3+ years' experience with scripting languages (Python) & data visualization tools (Tableau preferred)
• Professional experience with implementing statistical models into business processes
• Advanced ability to draw insights from analysis supported by data, and clearly communicate them to stakeholders, including senior management
• Intellectual curiosity, and solid understanding of data sources and ecosystems, with the ability to see from the brand's business lens
Where you'll live:
• While we prefer candidates based in Atlanta, we are open to qualified applicants from anywhere in the U.S. and are willing to consider remote candidates. #LI-Remote
Working at PrizePicks: The typical salary range for this position is $145,000 to $195,000. At PrizePicks, we consider your role, level, and where you'll be working when determining our salary ranges. The compensation info you see on our job postings gives you an idea of the starting pay range for the position. Your actual pay within that range will depend on your specific work location, as well as your skills, experience, and education. Your recruiter will be happy to chat more about the specific pay range for your location and how we arrived at it during the hiring process. This application period will remain open for 30 days. We're committed to finding the best candidate, so this date may be adjusted, and any changes will be reflected in this posting. Date Posted: May 14th, 2025 1st Extension: June 14th, 2025 2nd Extension: July 14th, 2025

Benefits you'll receive: In addition to your great compensation package, full-time employees will be eligible for the following perks:
• Company-subsidized medical, dental, & vision plans
• 401(k) plan with company match
• Annual bonus
• Flexible PTO to encourage a healthy work/life balance (2 weeks STRONGLY encouraged!)
• Generous paid leave programs, including 16-week paid parental leave and disability benefits
• Workplace flexibility and modern work schedules focused on getting the job done, not hours clocked
• Company-wide in-person events and team outings
• Lifestyle enhancement program
• Company equipment provided (Windows & Mac options)
• Annual performance reviews with opportunities for growth and career development
You must be authorized to work for any employer in the U.S. We are unable to sponsor or take over sponsorship of an employment Visa at this time. PrizePicks is an Equal Opportunity Employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.",,2025-07-25,"['We are looking for an inquisitive, highly analytical, and detail-oriented Senior Data Scientist, experienced in Acquisition Marketing', ""You're an excellent fit for this role if you're comfortable managing projects simultaneously, working with a cross-functional team, and informing and influencing stakeholders with data, using insights to drive outcomes"", ""Bachelor's degree in Statistics, Economics, Computer Science, Data Science, Engineering, or a related field"", ""5+ years' of Marketing Data Analytics experience in an e-commerce, direct-to-consumer environment"", 'Advanced knowledge of SQL, including comfort with analytics functions, window functions, and common table expressions', 'Professional experience with implementing statistical models into business processes', 'Advanced ability to draw insights from analysis supported by data, and clearly communicate them to stakeholders, including senior management', ""Intellectual curiosity, and solid understanding of data sources and ecosystems, with the ability to see from the brand's business lens"", 'You must be authorized to work for any employer in the U.S. We are unable to sponsor or take over sponsorship of an employment Visa at this time']","['This data-centric role is vital for building and maintaining analytics tools and workflows', 'A passion for solving problems around marketing attribution, spend optimization, and guiding profitable growth for the business is essential for success', 'Support the advancement of analytical capabilities across acquisition and retention marketing', 'Develop and implement advanced analytics frameworks to tell the story of marketing performance and make budget recommendations, including media mix modeling (MMM) and channel-level marginal CAC', 'Drive the learning agenda related to channel strategy, e.g. geo-level testing and media mix testing, working with marketing leadership to operationalize', 'Create central reporting solutions to create holistic, executive-level, and cross-functional visibility into marketing performance, and establish and communicate the narrative around performance at appropriate altitude', 'Develop required data collection and transformation processes to support reporting and analytics solutions', 'Create presentations and written documents with little guidance, and present to both technical and non-technical audiences in an effective way, articulating ideas and opinions clearly and efficiently', 'Serve as a mentor to more junior analysts, contributing to the advancement of capabilities and work across the Marketing Analytics organization, and act as an example for the team to follow']",True,[],,"['SQL', 'Python', 'Tableau', 'Statistical Modeling', 'Media Mix Modeling (MMM)', 'Marketing Attribution', 'Data Collection and Transformation', 'Marketing Analytics', 'Geo-level Testing', 'Media Mix Testing']","SQL: Used extensively for data querying and manipulation, including advanced analytics functions, window functions, and common table expressions to support marketing analytics and reporting.; Python: Utilized as a scripting language for data analysis and building analytics workflows in marketing data science projects.; Tableau: Employed as a data visualization tool to create dashboards and reporting solutions that provide executive-level and cross-functional visibility into marketing performance.; Statistical Modeling: Applied to implement advanced analytics frameworks such as media mix modeling (MMM) and channel-level marginal customer acquisition cost (CAC) to inform marketing budget recommendations and optimize spend.; Media Mix Modeling (MMM): Developed and implemented as an advanced analytics framework to analyze marketing performance and guide budget allocation decisions.; Marketing Attribution: Analyzed to solve problems related to understanding the impact of various marketing channels on customer acquisition and retention.; Data Collection and Transformation: Designed and maintained processes to support reporting and analytics solutions, ensuring data is prepared and transformed appropriately for analysis.; Marketing Analytics: Focused on acquisition and retention marketing, involving the development of analytical capabilities to drive profitable growth and inform marketing strategies.; Geo-level Testing: Conducted as part of the learning agenda to evaluate channel strategy effectiveness across different geographic regions.; Media Mix Testing: Performed to assess the impact of different marketing channels and optimize media spend."
ZS6TsMNJHJz7BRKwAAAAAA==,Senior Data Analyst,"We're looking for a Senior Data Analyst with expertise in core banking systems (ABS, LMS) and training junior analysts. As a Senior Data Analyst, you will be responsible for managing and enhancing our data warehouse environment, controlling data quality, fixing and restoration data for DWH key entities, developing BI solutions, and acting as a strategic partner to business units including Sales, Risk, Data Science, and Operations. You’ll ensure data quality, support integrations, and lead efforts to improve standards and governance across the data lifecycle. This role requires strong technical expertise, excellent communication skills, and a deep understanding of banking systems and processes.
Responsibilities:
Administer DWH layers (DDS/CDM) and develop BI assets (e.g., dashboards in Power BI).
Mentor junior analysts and collaborate with stakeholders (Risk, Sales, Data Science, etc.).
Ensure data quality, resolve issues, and support integration of data sources.
Document BI standards and manage data governance strategies.
Oversee task delivery via Jira and maintain data monitoring tools.
Bachelor’s in a quantitative field (Math, Stats, CompSci); Master’s preferred.
3+ years as a Data Analyst in banking/fintech.
Advanced SQL skills and experience with BI tools (Power BI, Grafana).
Strong understanding of DWH architecture, banking platforms (ABS), and CRM systems.
Excellent communication and organizational skills in English and Russian languages; detail-oriented.
Nice to Have:
Familiarity with Agile/Scrum.
Experience with real-time data monitoring and risk analytics.
Flexible and completely remote full-time role
The opportunity to work in an innovative fintech company with a global reach
Engaging tasks and the chance to influence the development of cutting-edge products
The opportunity to grow your skills in a global, distributed team environment.

#J-18808-Ljbffr Renmoney Microfinance Bank Limited",2025-07-21T00:00:00.000Z,2025-07-25,"['3+ years as a Data Analyst in banking/fintech', 'Advanced SQL skills and experience with BI tools (Power BI, Grafana)', 'Strong understanding of DWH architecture, banking platforms (ABS), and CRM systems', 'Excellent communication and organizational skills in English and Russian languages; detail-oriented', 'Familiarity with Agile/Scrum', 'Experience with real-time data monitoring and risk analytics', 'Flexible and completely remote full-time role', 'The opportunity to work in an innovative fintech company with a global reach']","['As a Senior Data Analyst, you will be responsible for managing and enhancing our data warehouse environment, controlling data quality, fixing and restoration data for DWH key entities, developing BI solutions, and acting as a strategic partner to business units including Sales, Risk, Data Science, and Operations', 'You’ll ensure data quality, support integrations, and lead efforts to improve standards and governance across the data lifecycle', 'This role requires strong technical expertise, excellent communication skills, and a deep understanding of banking systems and processes', 'Administer DWH layers (DDS/CDM) and develop BI assets (e.g., dashboards in Power BI)', 'Mentor junior analysts and collaborate with stakeholders (Risk, Sales, Data Science, etc.)', 'Ensure data quality, resolve issues, and support integration of data sources', 'Document BI standards and manage data governance strategies', 'Oversee task delivery via Jira and maintain data monitoring tools', 'Engaging tasks and the chance to influence the development of cutting-edge products']",True,[],,"['Data Warehouse (DWH) Architecture', 'Business Intelligence (BI) Tools', 'SQL', 'Data Quality Management', 'Data Governance', 'Core Banking Systems', 'Real-time Data Monitoring', 'Agile/Scrum Methodology', 'Mentoring and Collaboration', 'Task and Project Management Tools']","Data Warehouse (DWH) Architecture: Managing and enhancing the data warehouse environment including administration of DWH layers such as DDS and CDM, ensuring data quality, fixing and restoring data for key entities, and supporting integration of data sources.; Business Intelligence (BI) Tools: Developing BI solutions and assets such as dashboards using tools like Power BI and Grafana to support business units and decision-making.; SQL: Utilizing advanced SQL skills for querying, managing, and manipulating data within the data warehouse and other data sources.; Data Quality Management: Ensuring data quality by controlling, resolving issues, and leading efforts to improve standards and governance across the data lifecycle.; Data Governance: Documenting BI standards and managing data governance strategies to maintain data integrity and compliance.; Core Banking Systems: Working with banking platforms such as ABS and LMS, and CRM systems to understand and support banking data and processes.; Real-time Data Monitoring: Experience with monitoring data in real-time to support risk analytics and operational decision-making.; Agile/Scrum Methodology: Familiarity with Agile and Scrum frameworks to manage task delivery and collaborate effectively within teams.; Mentoring and Collaboration: Mentoring junior analysts and collaborating with stakeholders across business units including Risk, Sales, Data Science, and Operations.; Task and Project Management Tools: Overseeing task delivery and maintaining data monitoring tools using platforms such as Jira."
vBplUZdVBH3ZtfsSAAAAAA==,"Senior Data Scientist, Pricing","About Us:
Live experiences help people cross today's digital divide and focus on what truly connects us – the here, the now, this once-in-a-lifetime moment that's bringing us together. To fulfill Gametime's mission of uniting the world through shared experiences, we make it easy for people to discover and access the live experiences that matter most.

With platforms on iOS, Android, mobile web and desktop supporting more than 60,000 events across the US and Canada, we are reimagining the event ticket industry in order to move at the speed of life.

About the Role

We're looking for a highly analytical and business-savvy Senior Pricing Data Scientist to join our Pricing Strategy team. In this role, you'll design and execute advanced pricing models, lead experimentation efforts, and uncover insights that power monetization and growth. You'll work cross-functionally with Product, Analytics, Revenue, and Engineering to ensure our pricing strategies are data-driven, rigorously tested, and aligned with customer value.

This is a high-impact opportunity for someone who thrives at the intersection of data science, economics, and strategy, and who is passionate about using data to influence pricing, product design, and long-term business outcomes.
Key ResponsibilitiesModel Development & Optimization
• Design, build, and maintain pricing and demand elasticity models using statistical and machine learning methods.
• Leverage behavioral, transactional, and marketplace data to optimize price points, discount strategies, and product bundling.
• Develop tools to support scenario modeling, revenue forecasting, and price testing simulations.
Experimentation & Testing
• Design A/B and multivariate experiments to test pricing changes, discount strategies, and offer configurations.
• Analyze test results with statistical rigor, including significance testing, confidence intervals, and causal inference techniques.
• Partner with experimentation platform owners to automate and scale pricing experiments across channels and customer segments.
Insight Generation & Strategy Support
• Conduct in-depth analyses of customer willingness to pay, price sensitivity, and competitor pricing strategies.
• Deliver insights on monetization opportunities, marketplace dynamics, and revenue optimization levers.
• Partner with strategy and product teams to develop recommendations based on model outputs and empirical evidence.
Cross-functional Collaboration
• Collaborate closely with Product Managers, Engineers, and Revenue teams to embed pricing intelligence into user experiences.
• Translate complex technical findings into actionable business recommendations for stakeholders across the org.
• Contribute to roadmap planning, strategic decision-making, and post-launch pricing reviews.

What You BringRequired Qualifications
• 5+ years of experience in data science, pricing analytics, or quantitative strategy roles.
• Advanced proficiency in Python or R, SQL, and statistical modeling techniques.
• Strong experience with A/B testing frameworks and causal inference methods (e.g., regression, matching, difference-in-differences).
• Solid understanding of pricing theory, elasticity modeling, and optimization.
Skills & Attributes
• Excellent problem-solving and critical thinking skills; able to distill ambiguity into structured analyses.
• Business-oriented mindset with the ability to prioritize impact and communicate clearly with non-technical audiences.
• Self-starter with a passion for experimentation and continuous improvement.
Preferred
• Degree in Data Science, Statistics, Economics, Applied Mathematics, or a related quantitative discipline (Master's or PhD preferred).
• Experience in a consumer-facing marketplace, e-commerce, or SaaS environment.
• Familiarity with tools such as Looker, Amplitude, dbt, or in-house experimentation platforms.

Why This Role Matters

Your work will help define how we price, scale, and monetize our products. By bringing science and experimentation to our pricing approach, you'll directly impact revenue growth, customer satisfaction, and strategic decision-making.

What We can Offer:
• Flexible PTO
• Competitive salary & equity package
• Monthly Gametime credits for any event ($1,200/yr)
• Medical, dental, & vision insurance
• Life insurance and disability benefits
• Diverse Family-forming benefits through Carrot Fertility
• 401k, HSA, pre-tax savings programs
• Company off-sites and meet-ups
• Wellness programs
• Tenure recognition

At Gametime pay ranges are subject to change and assigned to a job based on specific market median of similar jobs according to 3rd party salary benchmark surveys. Individual pay within that range can vary for several reasons including skills/capabilities, experience, and available budget.

United States - Pay Range
$140,718—$165,550 USD

Gametime is committed to bringing together individuals from different backgrounds and perspectives. We strive to create an inclusive environment where everyone can thrive, feel a sense of belonging, and do great work together. As an equal opportunity employer, we prohibit any unlawful discrimination against a job applicant on the basis of their race, color, religion, veteran status, sex, parental status, gender identity or expression, transgender status, sexual orientation, national origin, age, disability or genetic information. We respect the laws enforced by the EEOC and are dedicated to going above and beyond in fostering diversity across our company.",2025-07-02T00:00:00.000Z,2025-07-25,"['5+ years of experience in data science, pricing analytics, or quantitative strategy roles', 'Advanced proficiency in Python or R, SQL, and statistical modeling techniques', 'Strong experience with A/B testing frameworks and causal inference methods (e.g., regression, matching, difference-in-differences)', 'Solid understanding of pricing theory, elasticity modeling, and optimization', 'Excellent problem-solving and critical thinking skills; able to distill ambiguity into structured analyses', 'Business-oriented mindset with the ability to prioritize impact and communicate clearly with non-technical audiences', 'Self-starter with a passion for experimentation and continuous improvement']","[""In this role, you'll design and execute advanced pricing models, lead experimentation efforts, and uncover insights that power monetization and growth"", ""You'll work cross-functionally with Product, Analytics, Revenue, and Engineering to ensure our pricing strategies are data-driven, rigorously tested, and aligned with customer value"", 'This is a high-impact opportunity for someone who thrives at the intersection of data science, economics, and strategy, and who is passionate about using data to influence pricing, product design, and long-term business outcomes', 'Key ResponsibilitiesModel Development & Optimization', 'Design, build, and maintain pricing and demand elasticity models using statistical and machine learning methods', 'Leverage behavioral, transactional, and marketplace data to optimize price points, discount strategies, and product bundling', 'Develop tools to support scenario modeling, revenue forecasting, and price testing simulations', 'Design A/B and multivariate experiments to test pricing changes, discount strategies, and offer configurations', 'Analyze test results with statistical rigor, including significance testing, confidence intervals, and causal inference techniques', 'Partner with experimentation platform owners to automate and scale pricing experiments across channels and customer segments', 'Insight Generation & Strategy Support', 'Conduct in-depth analyses of customer willingness to pay, price sensitivity, and competitor pricing strategies', 'Deliver insights on monetization opportunities, marketplace dynamics, and revenue optimization levers', 'Partner with strategy and product teams to develop recommendations based on model outputs and empirical evidence', 'Cross-functional Collaboration', 'Collaborate closely with Product Managers, Engineers, and Revenue teams to embed pricing intelligence into user experiences', 'Translate complex technical findings into actionable business recommendations for stakeholders across the org', 'Contribute to roadmap planning, strategic decision-making, and post-launch pricing reviews', 'Your work will help define how we price, scale, and monetize our products']",True,[],,"['Pricing and Demand Elasticity Models', 'Statistical Modeling Techniques', 'A/B and Multivariate Testing', 'Behavioral, Transactional, and Marketplace Data', 'Scenario Modeling and Revenue Forecasting', 'SQL, Python, and R', 'Causal Inference Methods', 'Pricing Theory and Optimization', 'Experimentation Platforms and Automation', 'Looker, Amplitude, dbt']","Pricing and Demand Elasticity Models: Design, build, and maintain advanced pricing and demand elasticity models using statistical and machine learning methods to optimize price points, discount strategies, and product bundling.; Statistical Modeling Techniques: Apply statistical modeling techniques including regression, matching, and difference-in-differences for causal inference and rigorous analysis of pricing experiments.; A/B and Multivariate Testing: Design and analyze A/B and multivariate experiments to test pricing changes, discount strategies, and offer configurations with statistical rigor including significance testing and confidence intervals.; Behavioral, Transactional, and Marketplace Data: Leverage diverse data sources such as behavioral, transactional, and marketplace data to inform pricing optimization and revenue forecasting.; Scenario Modeling and Revenue Forecasting: Develop tools to support scenario modeling, revenue forecasting, and price testing simulations to guide pricing strategy decisions.; SQL, Python, and R: Utilize advanced proficiency in Python or R and SQL for data manipulation, analysis, and building pricing models.; Causal Inference Methods: Employ causal inference methods to analyze test results and understand the impact of pricing changes on customer behavior and revenue.; Pricing Theory and Optimization: Apply solid understanding of pricing theory, elasticity modeling, and optimization techniques to influence pricing strategies and product design.; Experimentation Platforms and Automation: Partner with experimentation platform owners to automate and scale pricing experiments across channels and customer segments.; Looker, Amplitude, dbt: Familiarity with BI and analytics tools such as Looker, Amplitude, and dbt to support data analysis and experimentation."
gz3I4Cz8D4Gz6yTtAAAAAA==,"US E-Consulting Services-Senior Data Scientist, Specialist Senior-S&T Strategy AIDASD/SFL Scientific-WW (303712)","Senior Data Scientist, Specialist Senior SFL Scientific

Our Deloitte Strategy & Transactions team helps guide clients through their most critical moments and transformational initiatives. From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability. Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journeybefore, during, and after any major transformational projects or transactions.

SFL Scientific, a Deloitte Business, is a U.S. based, data science consulting firm specializing in building industry-specific, artificial intelligence (AI) technologies.

We are hiring a Senior Data Scientist to collaborate directly with clients to design and develop novel projects and solutions. Join a rapidly growing team of professionals working to build a world-class data science practice focused on solving complex and R&D problems.

Recruiting for this role ends on 6/30/2025.

Work Youll Do

As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services. You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions.

Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation. Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills.
• Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production
• Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives
• Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization
• Validate AI models and algorithm via code reviews, unit, and integration tests
• Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives
• Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives

The Team

Our Strategy offering architects bold strategies to achieve business and mission goals, enabling growth, competitive advantage, technology modernization, and continuous digital and AI transformation.

SFL Scientific, a Deloitte Business, is a data science professional services practice focused on strategy, technology, and solving business challenges with Artificial Intelligence (AI). The team has a proven track record serving large, market-leading organizations in the private and public sectors, successfully delivering high-quality, novel and complex projects, and offering deep domain and scientific capabilities. Made up of experienced AI strategists, data scientists, and AI engineers, they serve as trusted advisors to executives, helping them understand and evaluate new and essential areas for AI investment and identify unique opportunities to transform their businesses.

Qualifications:
• Masters or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)
• 3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)
• 3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments
• 3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow
• 3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads
• Live within commuting distance to one of Deloittes consulting offices
• Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve
• Limited immigration sponsorship may be available

Preferred:
• 2+ years of experience working in a client-facing, consulting environment
• 2+ years of experience leading project/client engagement teams in the execution of complex AI data science solutions
• 1+ year of experience with LLM/GenAI use cases and developing RAG solutions, tools, and services (i.e., LangChain, LangGraph, MCP, etc.)
• 1+ year of experience with AWS Sagemaker or AWS ML Studio

Information for applicants with a need for accommodation:

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $107,600 to $198,400.

You may also be eligible to participate in a discretionary annual incentive program, subject to the rules governing the program, whereby an award, if any, depends on various factors, including, without limitation, individual and organizational performance.

#MonitorDeloitte

#DeloitteJobs

#StrategyConsulting

#DeloitteStrategy

#Strategy26

#SFL26
Recruiting tips

From developing a stand out resume to putting your best foot forward in the interview, we want you to feel prepared and confident as you explore opportunities at Deloitte. Check out recruiting tips from Deloitte recruiters. Benefits

At Deloitte, we know that great people make a great organization. We value our people and offer employees a broad range of benefits. Learn more about what working at Deloitte can mean for you. Our people and culture

Our inclusive culture empowers our people to be who they are, contribute their unique perspectives, and make a difference individually and collectively. It enables us to leverage different ideas and perspectives, and bring more creativity and innovation to help solve our clients' most complex challenges. This makes Deloitte one of the most rewarding places to work. Our purpose
Deloittes purpose is to make an impact that matters for our people, clients, and communities. At Deloitte, purpose is synonymous with how we work every day. It defines who we are. Our purpose comes through in our work with clients that enables impact and value in their organizations, as well as through our own investments, commitments, and actions across areas that help drive positive outcomes for our communities. Learn more. Professional development

From entry-level employees to senior leaders, we believe theres always room to learn. We offer opportunities to build new skills, take on leadership opportunities and connect and grow through mentorship. From on-the-job learning experiences to formal development programs, our professionals have a variety of opportunities to continue to grow throughout their career. Position Summary

Senior Data Scientist, Specialist Senior SFL Scientific

Our Deloitte Strategy & Transactions team helps guide clients through their most critical moments and transformational initiatives. From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability. Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journeybefore, during, and after any major transformational projects or transactions.

SFL Scientific, a Deloitte Business, is a U.S. based, data science consulting firm specializing in building industry-specific, artificial intelligence (AI) technologies.

We are hiring a Senior Data Scientist to collaborate directly with clients to design and develop novel projects and solutions. Join a rapidly growing team of professionals working to build a world-class data science practice focused on solving complex and R&D problems.

Recruiting for this role ends on 6/30/2025.

Work Youll Do

As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services. You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions.

Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation. Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills.
• Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production
• Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives
• Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization
• Validate AI models and algorithm via code reviews, unit, and integration tests
• Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives
• Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives

The Team

Our Strategy offering architects bold strategies to achieve business and mission goals, enabling growth, competitive advantage, technology modernization, and continuous digital and AI transformation.

SFL Scientific, a Deloitte Business, is a data science professional services practice focused on strategy, technology, and solving business challenges with Artificial Intelligence (AI). The team has a proven track record serving large, market-leading organizations in the private and public sectors, successfully delivering high-quality, novel and complex projects, and offering deep domain and scientific capabilities. Made up of experienced AI strategists, data scientists, and AI engineers, they serve as trusted advisors to executives, helping them understand and evaluate new and essential areas for AI investment and identify unique opportunities to transform their businesses.

Qualifications:
• Masters or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)
• 3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)
• 3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments
• 3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow
• 3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads
• Live within commuting distance to one of Deloittes consulting offices
• Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve
• Limited immigration sponsorship may be available

Preferred:
• 2+ years of experience working in a client-facing, consulting environment
• 2+ years of experience leading project/client engagement teams in the execution of complex AI data science solutions
• 1+ year of experience with LLM/GenAI use cases and developing RAG solutions, tools, and services (i.e., LangChain, LangGraph, MCP, etc.)
• 1+ year of experience with AWS Sagemaker or AWS ML Studio

Information for applicants with a need for accommodation:

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $107,600 to $198,400.

You may also be eligible to participate in a discretionary annual incentive program, subject to the rules governing the program, whereby an award, if any, depends on various factors, including, without limitation, individual and organizational performance.

#MonitorDeloitte

#DeloitteJobs

#StrategyConsulting

#DeloitteStrategy

#Strategy26

#SFL26
Recruiting tips

From developing a stand out resume to putting your best foot forward in the interview, we want you to feel prepared and confident as you explore opportunities at Deloitte. Check out recruiting tips from Deloitte recruiters. Benefits

At Deloitte, we know that great people make a great organization. We value our people and offer employees a broad range of benefits. Learn more about what working at Deloitte can mean for you. Our people and culture

Our inclusive culture empowers our people to be who they are, contribute their unique perspectives, and make a difference individually and collectively. It enables us to leverage different ideas and perspectives, and bring more creativity and innovation to help solve our clients' most complex challenges. This makes Deloitte one of the most rewarding places to work. Our purpose
Deloittes purpose is to make an impact that matters for our people, clients, and communities. At Deloitte, purpose is synonymous with how we work every day. It defines who we are. Our purpose comes through in our work with clients that enables impact and value in their organizations, as well as through our own investments, commitments, and actions across areas that help drive positive outcomes for our communities. Learn more. Professional development

From entry-level employees to senior leaders, we believe theres always room to learn. We offer opportunities to build new skills, take on leadership opportunities and connect and grow through mentorship. From on-the-job learning experiences to formal development programs, our professionals have a variety of opportunities to continue to grow throughout their career.

As used in this posting, ""Deloitte"" means Deloitte Consulting LLP, a subsidiary of Deloitte LLP. Please see www.deloitte.com/us/about for a detailed description of the legal structure of Deloitte LLP and its subsidiaries.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.
Qualified applicants with criminal histories, including arrest or conviction records, will be considered for employment in accordance with the requirements of applicable state and local laws, including the Los Angeles County Fair Chance Ordinance for Employers, City of Los Angeless Fair Chance Initiative for Hiring Ordinance, San Francisco Fair Chance Ordinance, and the California Fair Chance Act. See notices of various fair chance hiring and ban-the-box laws where available. Fair Chance Hiring and Ban-the-Box Notices | Deloitte US Careers Requisition code: 303712 Job ID 303712 Qualified applicants with criminal histories, including arrest or conviction records, will be considered for employment in accordance with the requirements of applicable state and local laws, including the Los Angeles County Fair Chance Ordinance for Employers, City of Los Angeless Fair Chance Initiative for Hiring Ordinance, San Francisco Fair Chance Ordinance, and the California Fair Chance Act. See notices of various fair chance hiring and ban-the-box laws where available. Fair Chance Hiring and Ban-the-Box Notices | Deloitte US Careers Requisition code: 303712 Job ID 303712 Caution against fraudulent job offers!

We have been informed of instances where jobseekers are led to believe of fictitious job opportunities with Deloitte US (Deloitte). In one or more such cases, false promises of actual or potential selection, or initiation or completion of the recruitment formalities appear to have been or are being made. Some jobseekers appear to have been asked to pay money to specified bank accounts of individuals or entities as a condition of their selection for a job with Deloitte. These individuals or entities are in no way connected with Deloitte and do not represent or otherwise act on behalf of Deloitte.

We would like to clarify that:
• At Deloitte, ethics and integrity are fundamental and not negotiable.
• We are against corruption and neither offer bribes nor accept them, nor induce or permit any other party to make or receive bribes on our behalf.
• We have not authorized any party or person to collect any money from jobseekers in any form whatsoever for promises of getting jobs in Deloitte.
• We consider candidates on merit and that we provide an equal opportunity to eligible applicants.
• No one other than designated Deloitte personnel (e.g., a Deloitte recruiter or Deloitte hiring partner) is permitted to extend any job offer from Deloitte.

Anyone who at any time has made or makes any payment to any party in exchange for promises of job or selection for a job with Deloitte or any matter related to this (including those for registration, verification or security deposit) or otherwise engages with any such person who has made or makes fraudulent promises or offers, does so (or has done so) entirely at their own risk. Deloitte takes no responsibility or liability for any such unauthorized or fraudulent actions or engagements. We encourage jobseekers to exercise caution.",,2025-07-25,"['Masters or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)', '3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)', '3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments', '3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow', '3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads', 'Live within commuting distance to one of Deloittes consulting offices', 'Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve', 'Limited immigration sponsorship may be available', 'Senior Data Scientist, Specialist Senior SFL Scientific', 'Masters or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)', '3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)', '3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments', '3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow', '3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads', 'Live within commuting distance to one of Deloittes consulting offices', 'Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve', 'Limited immigration sponsorship may be available', 'Fair Chance Hiring and Ban-the-Box Notices | Deloitte US Careers Requisition code: 303712 Job ID 303712 Qualified applicants with criminal histories, including arrest or conviction records, will be considered for employment in accordance with the requirements of applicable state and local laws, including the Los Angeles County Fair Chance Ordinance for Employers, City of Los Angeless Fair Chance Initiative for Hiring Ordinance, San Francisco Fair Chance Ordinance, and the California Fair Chance Act']","['From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability', 'Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journeybefore, during, and after any major transformational projects or transactions', 'As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services', 'You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions', 'Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation', 'Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills', 'Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production', 'Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives', 'Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization', 'Validate AI models and algorithm via code reviews, unit, and integration tests', 'Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives', 'Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives', 'From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability', 'Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journeybefore, during, and after any major transformational projects or transactions', 'As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services', 'You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions', 'Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation', 'Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills', 'Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production', 'Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives', 'Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization', 'Validate AI models and algorithm via code reviews, unit, and integration tests', 'Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives', 'Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives']",True,"['Generative AI', 'Large Language Models', 'Retrieval-Augmented Generation', 'Deep Learning Frameworks', 'AI Model Deployment and MLOps']","Generative AI: Experience with LLM/GenAI use cases and developing Retrieval-Augmented Generation solutions, tools, and services such as LangChain, LangGraph, and MCP.; Large Language Models: Involved in use cases and development related to LLMs, including fine-tuning and deployment within AI solutions.; Retrieval-Augmented Generation: Developing RAG solutions, tools, and services to enhance AI capabilities, including integration with LLMs.; Deep Learning Frameworks: Use of frameworks like PyTorch specifically for developing and deploying deep learning models including CNNs, RNNs, and GANs.; AI Model Deployment and MLOps: Deploying and optimizing AI/ML models using Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow, with a focus on AI model lifecycle management in production environments.","['Exploratory Data Analysis', 'Machine Learning', 'Deep Learning', 'Natural Language Processing', 'Time-Series Analysis', 'Computer Vision', 'Model Validation and Testing', 'Model Deployment and Optimization', 'Cloud Computing for AI/ML']","Exploratory Data Analysis: Used to understand client data sets and operational requirements to design long-term solutions and guide AI strategy and development.; Machine Learning: Applied in developing AI/ML solutions, including research and implementation of novel approaches, model tuning, performance validation, and deployment in production environments.; Deep Learning: Experience required in applying techniques such as CNNs, RNNs, and GANs across real-world projects, including model tuning and performance validation in production.; Natural Language Processing: Used as part of data analysis techniques alongside time-series analysis and computer vision in AI/ML algorithm development.; Time-Series Analysis: Applied as a data analysis method in AI/ML algorithm development.; Computer Vision: Used as a data analysis technique in AI/ML algorithm development.; Model Validation and Testing: Includes validating AI models and algorithms via code reviews, unit tests, and integration tests to ensure quality and performance.; Model Deployment and Optimization: Involves deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow, and leveraging cloud environments such as AWS, Azure, or GCP.; Cloud Computing for AI/ML: Experience in leveraging cloud platforms (AWS, Azure, GCP) to deploy AI/ML workloads."
6NV_1aLYhYL-zyNRAAAAAA==,"Senior Data Scientist ; Minneapolis, MN","Position: Senior Data Scientist New Charlotte, North Carolina, United States; Minneapolis, MN

RVO Health is building a suite of integrated products that enable data-driven, digital experiences for our brands and partners. You will work with cutting-edge technologies that change how millions of users connect, explore, and work with these brands. As a Senior Data Scientist at RVO Health, you will play a crucial role in designing, implementing, and maintaining our recommendation systems.
What You’ll Do
• Model Development: Use your expertise in machine learning and predictive analytics to design, build, and deploy robust recommendation models. Your work will directly influence the company's decision-making and strategic direction.
• Engage with Business Stakeholders: Regularly communicate and collaborate with key business stakeholders to identify valuable opportunities to leverage data science techniques.
• Model Optimization: Continuously strive for the improvement of existing models by incorporating new data, refining algorithms, or utilizing innovative data science techniques. Your focus will be on enhancing the predictive accuracy of our models to make them more reliable and efficient.
• Results Communication: Communicate complex data science concepts and the model outcomes to non-technical stakeholders in a clear and effective manner.
• Collaborative Teamwork: Collaborate with other data scientists, data engineers, and cross-functional teams in an agile environment to ensure the smooth and timely execution of projects.
What We’re Looking For
• 4+ years of experience as a Data Scientist
• Expert knowledge of machine learning and statistical modeling with experience in at least one of the following areas: recommender systems, NLP, deep learning, or graph theory applications.
• Capability of communicating effectively with business and data science leaders on project status, timeline and technical results.
• Proficient at collecting and mining data from disparate data sources, and willing to dig deeper and understand the process that creates the data.
• Analytical and detail oriented with the ability to prioritize, execute, and deliver projects on time
• Capable of translating business opportunities into data science problems and defining the right project scope and performance metric to measure success
• Must be comfortable with unstructured, fast moving and constantly evolving high-growth environment
• Committed team player who is proactive, takes ownership over the success of their projects, and works hard to support those around them
• Comfortable working onsite in Charlotte or Minneapolis twice a week

Pursuant to various state Fair Pay Acts, below is a summary of compensation elements for this role at the company. The following benefits are provided by RVO Health, subject to eligibility requirements.
• Starting Salary: $93,000 - $120,000
• Note actual salary is based on geographic location, qualifications and experience
• Access to a Free Udemy for Business subscription—thousands of hours of learning content on hundreds of different subjects at your fingertips
• Health Insurance Coverage (medical, dental, and vision)
• Life Insurance
• Short and Long-Term Disability Insurance
• Flexible Spending Accounts
• Paid Time Off
• Holiday Pay
• 401(k) with match
• Employee Assistance Program
• Income Protection Plans
• Pet Services Plans
• Mental Health Support
• Wellness Coaching
• HSA
- Health Savings Account
• Gym & Fitness Center Discount Program

Who We Are:

Founded in 2022, RVO Health is a new healthcare platform of digital media brands, services and technologies focused on building relationships with people throughout their health & wellness journey. We meet people where they are in their personal health journeys and connect them with both the information and the care they need. RVO Health was created by joining teams from both Red Ventures and United Health Group’s Optum Health.

Together we’re focused on delivering on our vision of a stronger and healthier world.

RVO Health is comprised of Healthline Media (Healthline, Medical News Today, Psych Central, Greatist and Bezzy), Health grades, Find Care and Plate Joy;
Optum Perks, Optum Store and the virtual coaching platforms Real Appeal, Wellness Coaching, and Quit For Life .

We offer competitive salaries and a comprehensive…",,2025-07-25,"['4+ years of experience as a Data Scientist', 'Expert knowledge of machine learning and statistical modeling with experience in at least one of the following areas: recommender systems, NLP, deep learning, or graph theory applications', 'Capability of communicating effectively with business and data science leaders on project status, timeline and technical results', 'Proficient at collecting and mining data from disparate data sources, and willing to dig deeper and understand the process that creates the data', 'Analytical and detail oriented with the ability to prioritize, execute, and deliver projects on time', 'Capable of translating business opportunities into data science problems and defining the right project scope and performance metric to measure success', 'Must be comfortable with unstructured, fast moving and constantly evolving high-growth environment', 'Committed team player who is proactive, takes ownership over the success of their projects, and works hard to support those around them', 'Comfortable working onsite in Charlotte or Minneapolis twice a week']","['As a Senior Data Scientist at RVO Health, you will play a crucial role in designing, implementing, and maintaining our recommendation systems', 'Model Development: Use your expertise in machine learning and predictive analytics to design, build, and deploy robust recommendation models', ""Your work will directly influence the company's decision-making and strategic direction"", 'Engage with Business Stakeholders: Regularly communicate and collaborate with key business stakeholders to identify valuable opportunities to leverage data science techniques', 'Model Optimization: Continuously strive for the improvement of existing models by incorporating new data, refining algorithms, or utilizing innovative data science techniques', 'Your focus will be on enhancing the predictive accuracy of our models to make them more reliable and efficient', 'Results Communication: Communicate complex data science concepts and the model outcomes to non-technical stakeholders in a clear and effective manner', 'Collaborative Teamwork: Collaborate with other data scientists, data engineers, and cross-functional teams in an agile environment to ensure the smooth and timely execution of projects']",True,"['Deep Learning', 'Natural Language Processing']","Deep Learning: Recognized as a modern AI technique relevant to the role, indicating experience with neural networks and advanced AI model architectures.; Natural Language Processing: Mentioned as an area of expertise involving AI methods, potentially including transformer-based models or other AI-native NLP techniques used in recommendation systems.","['Machine Learning', 'Predictive Analytics', 'Recommendation Systems', 'Natural Language Processing', 'Deep Learning', 'Graph Theory Applications', 'Data Collection and Mining', 'Statistical Modeling']","Machine Learning: Used to design, build, and deploy robust recommendation models that influence company decision-making and strategic direction.; Predictive Analytics: Applied to develop and optimize recommendation models to enhance their predictive accuracy and reliability.; Recommendation Systems: Designed, implemented, and maintained as core products to provide data-driven digital experiences for users.; Natural Language Processing: Experience in NLP is required as part of expertise in machine learning and statistical modeling, potentially applied to recommendation or data analysis tasks.; Deep Learning: Experience in deep learning is required as part of expertise in machine learning and statistical modeling, supporting advanced model development.; Graph Theory Applications: Experience with graph theory is considered relevant for modeling and analytical tasks within recommendation systems or related data science problems.; Data Collection and Mining: Proficiency in collecting and mining data from disparate sources to understand data generation processes and support model development.; Statistical Modeling: Expert knowledge required to build and refine models that support predictive analytics and recommendation systems."
Y2EnjmLLHhIxktFWAAAAAA==,Data Analyst - Visualization - Entry Level,"Job Summary:

Merchants Bancorp is ranked as one of the top-performing banks in the U.S., and they are seeking a highly skilled Data Analyst with expertise in Power BI visualization and data analytics. The role involves translating complex business requirements into interactive dashboards and reports, collaborating with stakeholders to align visual analytics with business objectives.

Responsibilities:

• Design, develop, and optimize Power BI dashboards and reports to visualize key business metrics.

• Collaborate with business leaders to gather and understand requirements and transform them into effective visualizations.

• Ensure data integrity, accuracy, and consistency by working closely with data engineers and stakeholders.

• Develop data models that support business intelligence reporting.

• Implement best practices in visualization design, ensuring clarity, usability, and impact.

• Identify and recommend improvements for business performance through data-driven insights.

• Stay ahead of industry trends and innovations in Power BI and business intelligence tools.

Qualifications:

Required:

• A bachelor’s or master’s degree in data Analytics, Business Intelligence, Computer Science, or a related field.

• Minimum experience requirements: At least one year of relevant experience with a master’s degree, or three years with a bachelor’s degree, in data analytics, business intelligence, or visualization development.

• Proven expertise in Power BI dashboard development and design.

• Strong business acumen with an ability to align visualizations with operational goals.

• Advanced proficiency in DAX, Power Query, SQL, and data modeling.

• Experience working with large datasets and ensuring efficient data processing.

• Excellent communication skills to translate technical findings into business-friendly insights.

• Strong analytical thinking and problem-solving abilities.

Company:

Ranked as one of the top-performing banks in the U.S. Founded in 1990, the company is headquartered in Carmel, Indiana, USA, with a team of 501-1000 employees. The company is currently Public Company.",2025-07-22T00:00:00.000Z,2025-07-25,"['A bachelor’s or master’s degree in data Analytics, Business Intelligence, Computer Science, or a related field', 'Minimum experience requirements: At least one year of relevant experience with a master’s degree, or three years with a bachelor’s degree, in data analytics, business intelligence, or visualization development', 'Proven expertise in Power BI dashboard development and design', 'Strong business acumen with an ability to align visualizations with operational goals', 'Advanced proficiency in DAX, Power Query, SQL, and data modeling', 'Experience working with large datasets and ensuring efficient data processing', 'Excellent communication skills to translate technical findings into business-friendly insights', 'Strong analytical thinking and problem-solving abilities']","['The role involves translating complex business requirements into interactive dashboards and reports, collaborating with stakeholders to align visual analytics with business objectives', 'Design, develop, and optimize Power BI dashboards and reports to visualize key business metrics', 'Collaborate with business leaders to gather and understand requirements and transform them into effective visualizations', 'Ensure data integrity, accuracy, and consistency by working closely with data engineers and stakeholders', 'Develop data models that support business intelligence reporting', 'Implement best practices in visualization design, ensuring clarity, usability, and impact', 'Identify and recommend improvements for business performance through data-driven insights', 'Stay ahead of industry trends and innovations in Power BI and business intelligence tools']",True,[],,"['Power BI', 'DAX', 'Power Query', 'SQL', 'Data Modeling', 'Data Visualization']","Power BI: Used to design, develop, and optimize interactive dashboards and reports that visualize key business metrics and support business intelligence reporting.; DAX: Applied for advanced data analysis expressions within Power BI to create complex calculations and data models.; Power Query: Utilized for data transformation and preparation to ensure efficient data processing and integration into visualizations.; SQL: Employed to query and manage large datasets, ensuring data integrity, accuracy, and consistency for reporting and visualization purposes.; Data Modeling: Developed to support business intelligence reporting by structuring data effectively for analysis and visualization.; Data Visualization: Implemented best practices in visualization design to create clear, usable, and impactful dashboards aligned with business objectives."
uDm6xPwvq22iQBueAAAAAA==,"(USA) Principal, Data Scientist","Position Summary...

What you'll do...About TeamThe data science team at the Enterprise Business Services Pillar at Walmart Global Tech focuses on using the latest research in machine learning, statistics, and optimization to solve business problems. We mine data, distill insights, extract information, build analytical models, deploy machine learning algorithms, and use the latest technology to empower business decision-making. Additionally, we work with engineers to build reference architectures and machine learning pipelines in a big data ecosystem to productize our solutions. Advanced analytical algorithms driven by our team help Walmart optimize business operations, improve business practices, and change the way our customers shop. The data science community at Walmart Global Tech is active in most hack events, utilizing the petabytes of data at our disposal to build some of the coolest ideas. All the work we do at Walmart Labs will eventually benefit our operations and associates, helping customers save money and live better. Your OpportunityAs a Principal Data Scientist for Walmart Global Tech, you'll have the opportunity to: Drive data-derived insights across a wide range of retail and finance divisions by developing advanced statistical models, machine learning algorithms, and computational algorithms based on business initiatives. Direct the gathering of data, assess data validity, and synthesize data into large analytics datasets to support project goals. Build and train AI/ML models for replication in future projects. Communicate recommendations to business partners and influence future plans based on insights. What You Will Do Consult with business stakeholders regarding algorithm-based recommendations and be a thought leader to develop these into business actions. Closely partner with the Senior Manager and Director of Data Science to drive data science adoption in the domain. Guide data scientists, senior data scientists, and staff data scientists across multiple sub-domains to ensure on-time delivery of ML products. Drive efficiency across the domain in terms of DS and ML best practices, ML Ops practices, resource utilization, reusability, and multi-tenancy. Lead multiple complex ML products and guide senior tech leads in the domain in efficiently leading their products. Drive synergies across different products in terms of algorithmic innovation and sharing of best practices. Proactively identify complex business problems that can be solved using advanced ML, finding opportunities and gaps in the current business domain. Evaluate proposed business cases for projects and initiatives. Translate business requirements into strategies, initiatives, and projects, align them with business strategy and objectives, and drive the execution of deliverables. Set relevant deliverables based on established success criteria and define key metrics to measure progress and effectiveness of the solution. Quantify business impact and ensure regular impact measurement of all ML products in the domain. Identify and review model evaluation metrics based on analytical requirements. Ensure testing information is documented and maintained by the team. Play a key role in solving complex problems pivotal to Walmarts business and driving actionable insights. Utilize a product mindset to build, scale, and deploy holistic data science products after successful prototyping. Demonstrate an incremental solution approach with agile and flexible ability to overcome practical problems. Articulate and present recommendations to business partners and influence plans based on insights. Partner and engage with associates in other regions to deliver the best services to customers around the globe. Work with a customer-centric mindset to deliver high-quality business-driven analytic solutions. Drive innovation in approach, method, practices, process, outcome, delivery, or any component of end-to-end problem solving. Proactively engage in the external community to build Walmarts brand and learn more about industry practices. Promote and support company policies, procedures, mission, values, and standards of ethics and integrity. What You Will Bring Bachelors, Masters, or Ph.D. with 10-15 years of relevant experience. Educational qualifications should be in Computer Science, Statistics, Mathematics, or a related area. Minimum 10 years of experience as a data science technical lead. Ability to lead multiple data science projects end-to-end. Deep experience in building data science solutions in areas like fraud prevention, forecasting, shrink and waste reduction, inventory management, recommendation, assortment, and price optimization. Deep experience in simultaneously leading multiple data science initiatives end-to-end from translating business needs to analytical asks, leading the process of building solutions, and the eventual act of deployment and maintenance of them. Strong experience in machine learning: classification models, regression models, NLP, forecasting, unsupervised models, optimization, graph ML, causal inference, causal ML, statistical learning, experimentation, and Gen-AI. In Gen-AI, it is desirable to have experience in embedding generation from training materials, storage and retrieval from vector databases, setup and provisioning of managed LLM gateways, development of retrieval-augmented generation-based LLM agents, model selection, iterative prompt engineering and fine-tuning based on accuracy and user feedback, monitoring, and governance. Ability to scale and deploy data science solutions. Strong experience with one or more of Python and R. Experience in GCP/Azure. Strong experience in Python, Py Spark. Google Cloud Platform, Vertex AI, Kubeflow, model deployment. Strong experience with big data platforms Hadoop (Hive, Map Reduce, HQL, Scala). Experience with GPU/CUDA for computational efficiency. About Walmart Global TechFrom entry-level to executive positions, Walmart provides limitless opportunities for growth and career development. Walmart started small, with a single discount store and the simple philosophy of selling more for less. Today, we are a growing technology-enabled company founded on the same values as our first store. We establish clear expectations, empower associates to manage their work, and hold ourselves and one another to a high standard. Walmarts scale enables us to have an unmatched reach, with 2.3 million associates worldwide and over 230 million weekly customers. Walmart is reshaping retail by investing in an expanding workforce. While technology is at the heart of our digital transformation, people are the reason we succeed and the force behind our innovations. We train our team in the skillsets of the future and bring in experts like you to help us grow. Flexible, Hybrid WorkWe use a hybrid way of working with primary in-office presence coupled with an optimal mix of virtual presence. We use our campuses to collaborate and be together in person, as business needs require, and for development and networking opportunities. This approach helps us make quicker decisions, remove location barriers across our global team, and be more flexible in our personal lives. BenefitsBeyond our great compensation package, you can receive incentive awards for your performance. Other great perks include a host of best-in-class benefits such as maternity and parental leave, PTO, health benefits, and much more. Equal Opportunity EmployerWalmart, Inc. is an Equal Opportunity Employer by choice. We believe we are best equipped to help our associates, customers, and the communities we serve live better when we really know them. That means understanding, respecting, and valuing Belonging unique styles, experiences, identities, ideas, and opinions while being welcoming of all people.

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

‎

‎

‎
You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.

‎

For information about PTO, see https://one.walmart.com/notices.

‎

‎
Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

‎
Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

‎

For information about benefits and eligibility, see One.Walmart.

‎
The annual salary range for this position is $110,000.00-$220,000.00

‎
Additional compensation includes annual or quarterly performance bonuses.

‎
Additional compensation for certain positions may also include:

‎

‎
- Stock

‎

‎

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 5 years' experience in an analytics related field. Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 3 years' experience in an analytics related field. Option 3: 7 years' experience in an analytics or related field

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data science, machine learning, optimization models, PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Publications or active peer reviewer in related journals or conference, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.

Primary Location...

805 Se Moberly Ln, Bentonville, AR 72712, United States of America",2025-07-23T00:00:00.000Z,2025-07-25,"['What You Will Bring Bachelors, Masters, or Ph.D. with 10-15 years of relevant experience', 'Educational qualifications should be in Computer Science, Statistics, Mathematics, or a related area', 'Minimum 10 years of experience as a data science technical lead', 'Ability to lead multiple data science projects end-to-end', 'Deep experience in building data science solutions in areas like fraud prevention, forecasting, shrink and waste reduction, inventory management, recommendation, assortment, and price optimization', 'Deep experience in simultaneously leading multiple data science initiatives end-to-end from translating business needs to analytical asks, leading the process of building solutions, and the eventual act of deployment and maintenance of them', 'Strong experience in machine learning: classification models, regression models, NLP, forecasting, unsupervised models, optimization, graph ML, causal inference, causal ML, statistical learning, experimentation, and Gen-AI', 'Ability to scale and deploy data science solutions', 'Strong experience with one or more of Python and R', 'Experience in GCP/Azure', 'Strong experience in Python, Py Spark', 'Google Cloud Platform, Vertex AI, Kubeflow, model deployment', 'Strong experience with big data platforms Hadoop (Hive, Map Reduce, HQL, Scala)', 'Experience with GPU/CUDA for computational efficiency', 'That means understanding, respecting, and valuing Belonging unique styles, experiences, identities, ideas, and opinions while being welcoming of all people', ""Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 5 years' experience in an analytics related field"", ""Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 3 years' experience in an analytics related field"", ""Option 3: 7 years' experience in an analytics or related field"", 'Data science, machine learning, optimization models, PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Publications or active peer reviewer in related journals or conference, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly', 'The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture']","['Direct the gathering of data, assess data validity, and synthesize data into large analytics datasets to support project goals', 'Build and train AI/ML models for replication in future projects', 'Communicate recommendations to business partners and influence future plans based on insights', 'What You Will Do Consult with business stakeholders regarding algorithm-based recommendations and be a thought leader to develop these into business actions', 'Closely partner with the Senior Manager and Director of Data Science to drive data science adoption in the domain', 'Guide data scientists, senior data scientists, and staff data scientists across multiple sub-domains to ensure on-time delivery of ML products', 'Drive efficiency across the domain in terms of DS and ML best practices, ML Ops practices, resource utilization, reusability, and multi-tenancy', 'Lead multiple complex ML products and guide senior tech leads in the domain in efficiently leading their products', 'Drive synergies across different products in terms of algorithmic innovation and sharing of best practices', 'Proactively identify complex business problems that can be solved using advanced ML, finding opportunities and gaps in the current business domain', 'Evaluate proposed business cases for projects and initiatives', 'Translate business requirements into strategies, initiatives, and projects, align them with business strategy and objectives, and drive the execution of deliverables', 'Set relevant deliverables based on established success criteria and define key metrics to measure progress and effectiveness of the solution', 'Quantify business impact and ensure regular impact measurement of all ML products in the domain', 'Identify and review model evaluation metrics based on analytical requirements', 'Ensure testing information is documented and maintained by the team', 'Play a key role in solving complex problems pivotal to Walmarts business and driving actionable insights', 'Utilize a product mindset to build, scale, and deploy holistic data science products after successful prototyping', 'Demonstrate an incremental solution approach with agile and flexible ability to overcome practical problems', 'Articulate and present recommendations to business partners and influence plans based on insights', 'Partner and engage with associates in other regions to deliver the best services to customers around the globe', 'Work with a customer-centric mindset to deliver high-quality business-driven analytic solutions', 'Drive innovation in approach, method, practices, process, outcome, delivery, or any component of end-to-end problem solving', 'Proactively engage in the external community to build Walmarts brand and learn more about industry practices', 'Promote and support company policies, procedures, mission, values, and standards of ethics and integrity']",True,"['Generative AI', 'Large Language Models (LLMs)', 'Retrieval-Augmented Generation', 'Prompt Engineering']","Generative AI: Experience in embedding generation from training materials, storage and retrieval from vector databases, setup and provisioning of managed large language model gateways, development of retrieval-augmented generation-based LLM agents, model selection, iterative prompt engineering, fine-tuning based on accuracy and user feedback, monitoring, and governance.; Large Language Models (LLMs): Involved in provisioning, managing, and developing LLM-based agents using retrieval-augmented generation techniques and iterative prompt engineering.; Retrieval-Augmented Generation: Developed as part of LLM agents to enhance information retrieval and generation capabilities in AI solutions.; Prompt Engineering: Applied iteratively to improve model accuracy and user feedback in fine-tuning generative AI models.","['Machine Learning', 'Statistical Models', 'Natural Language Processing', 'Feature Engineering', 'Data Pipelines', 'Big Data Platforms', 'Python', 'R', 'Spark (PySpark)', 'SQL and HQL', 'Optimization Models', 'Forecasting Models', 'Graph Machine Learning', 'Causal Inference and Causal Machine Learning', 'Experimentation and A/B Testing', 'Model Evaluation Metrics', 'Data Science Product Development', 'Cloud Platforms (GCP, Azure)', 'Vertex AI', 'Kubeflow', 'GPU and CUDA', 'Open Source Frameworks (scikit-learn, TensorFlow, PyTorch)']","Machine Learning: Used to develop advanced statistical and computational algorithms to solve business problems and optimize operations, including classification, regression, forecasting, unsupervised models, graph ML, causal inference, and experimentation.; Statistical Models: Developed and applied to extract insights and support business decision-making across retail and finance divisions.; Natural Language Processing: Applied as part of machine learning techniques to build data science solutions, including NLP models relevant to business initiatives.; Feature Engineering: Implied in building and training machine learning models and preparing large analytics datasets to support project goals.; Data Pipelines: Built in collaboration with engineers to productize machine learning solutions within a big data ecosystem.; Big Data Platforms: Experience with Hadoop ecosystem components such as Hive, MapReduce, HQL, and Scala to handle petabytes of data for analytics and model deployment.; Python: Used extensively for building, scaling, and deploying data science solutions, including experience with PySpark for big data processing.; R: Used as one of the primary programming languages for data science projects and analytics.; Spark (PySpark): Utilized for big data processing and building scalable data science solutions.; SQL and HQL: Used for data querying and manipulation within big data platforms to synthesize large analytics datasets.; Optimization Models: Applied to improve business practices such as inventory management, price optimization, and shrink and waste reduction.; Forecasting Models: Developed and applied to predict business trends and support decision-making in retail and finance domains.; Graph Machine Learning: Used to solve complex business problems involving relationships and networks within data.; Causal Inference and Causal Machine Learning: Applied to understand cause-effect relationships and improve decision-making accuracy.; Experimentation and A/B Testing: Used to validate models and measure the impact of machine learning products on business outcomes.; Model Evaluation Metrics: Identified and reviewed to ensure analytical requirements are met and to quantify business impact.; Data Science Product Development: Involves building, scaling, and deploying holistic data science products with a product mindset after successful prototyping.; Cloud Platforms (GCP, Azure): Used for deploying and scaling data science and machine learning solutions, including experience with Google Cloud Platform and Azure.; Vertex AI: Utilized as part of Google Cloud Platform services for model deployment and management.; Kubeflow: Used to build and manage machine learning pipelines and operationalize ML workflows.; GPU and CUDA: Experience with GPU acceleration and CUDA for computational efficiency in model training and deployment.; Open Source Frameworks (scikit-learn, TensorFlow, PyTorch): Used for building machine learning models and conducting assessments in Python, Spark, Scala, or R environments."
Ph1NAgFmz4qnW5v0AAAAAA==,Senior Data Analyst / Data Modeler,"About ngrok Inc.

At ngrok, we believe that doing networking the right way should also be the easy way. Over the last 10 years, we've given developers and engineers simple interfaces for getting traffic into their apps and APIs without forcing them to deal with legacy proxies, external load balancers, or VPNs, and we're now part of the standard stack for more than 9 million developers at some of the world's top technology brands, like GitHub, Okta, HashiCorp, and Twilio.

Over the last few years, we've completely changed how that interface looks and works to make it easier, more composable, and infinitely flexible. We now give anyone who needs a ""front door"" to their apps or APIs powerful tools to orchestrate traffic, secure public endpoints, accelerate their services on a global network, observe all traffic passing to/from their network, and much more. The ngrok that millions love and trust has been completely transformed for the better.

About the Role

As we continue transforming how developers orchestrate and secure their networks, we're building out a world-class data team to help us understand usage patterns, optimize product performance, and guide key business decisions with evidence-not assumptions.

We're looking for a Senior Data Analyst/Modeler who will be instrumental in building our data models, defining key metrics, and uncovering insights that guide both product innovation and go-to-market strategies. You'll work closely with cross-functional teams-from engineering and product to marketing and growth-to help us make smarter, faster decisions backed by data. We expect you to become the resident expert on the product and our customers.

This is a remote position for candidates outside of the Bay Area and a hybrid role for candidates within commuting distance to San Francisco. Our Bay Area employees commute to the office on Tuesdays and Wednesdays.
What You'll Do
• Design, implement, and maintain clean, reusable, and scalable data models using dbt for all teams across ngrok, from product to GTM and finance.
• Analyze user behavior, product adoption, and performance across ngrok's core services.
• Partner with Product, Engineering, and GTM teams to define KPIs and deliver actionable insights.
• Create dashboards in Superset and reports to communicate trends and uncover opportunities for optimization.
• Build predictive and diagnostic models to support business planning and user segmentation.
• Help maintain data integrity and drive best practices in data governance and quality.
What We're Looking For
• 7+ years of experience in data analytics, business intelligence, or data science.
• Strong proficiency in SQL and hands-on experience working with business and product teams to build self-service analytics datasets and dashboards.
• Experience working with high volume, high velocity data sets that model complex, real-world systems
• Experience with a data modeling tool such as dbt or SQLMesh and an orchestration tool such as Dagster or Airbyte for managing data pipelines.
• Experience being part of or working with engineering teams and navigating version control (e.g. git), command line tools, and CI
• Strong experience with BI tools (Superset, Looker, Mode, Metabase, or similar).
• Ability to translate complex data into clear, actionable insights.
• Solid communication and collaboration skills-especially in a remote environment.
• Bonus: Background in supporting product-led growth (PLG) or developer-focused SaaS.
Why ngrok?
• Work on a product loved by millions of developers around the world.
• Join a small, high-impact team where your voice matters.
• Flexible work hours and strong async culture.
• Competitive compensation, equity, and benefits.
• A culture that values autonomy, transparency, and deep respect for builders.
Compensation

Tier 1 (SF, LA, Seattle, NYC): Minimum salary of $172,000 to maximum $215,000

Tier 2: Minimum salary of $158,000 to maximum $197,000

Job level and actual compensation will be evaluated based on factors including, but not limited to, qualifications objectively assessed during the interview process (including skills and prior relevant experience, potential impact, and scope of role), internal equity with other team members, market data, and specific work location. We provide an attractive mix of salary and equity.

#LI-Remote

All candidates must be US-based, and legally authorized to work in the United States.

If your experience is close but doesn't fulfill all requirements, please apply. ngrok is on a mission to build a special company. To achieve our goal, we are focused on hiring people with different backgrounds, perspectives, and experiences!
Benefits

Compensation for this role depends on level, but we provide a competitive mix of salary and equity.

We provide a 401(k) with a 100% match up to 3% of your salary and a 50% match up to another 2%.

We provide healthcare, dental, and vision with premiums fully covered on the base plan for employees. Half of premiums are covered for dependents.

We offer unlimited PTO and a culture in which the overwhelming majority of employees take more than four weeks. Your manager is also on the hook for encouraging you to do the same.",,2025-07-25,"['7+ years of experience in data analytics, business intelligence, or data science', 'Strong proficiency in SQL and hands-on experience working with business and product teams to build self-service analytics datasets and dashboards', 'Experience working with high volume, high velocity data sets that model complex, real-world systems', 'Experience with a data modeling tool such as dbt or SQLMesh and an orchestration tool such as Dagster or Airbyte for managing data pipelines', 'Experience being part of or working with engineering teams and navigating version control (e.g. git), command line tools, and CI', 'Strong experience with BI tools (Superset, Looker, Mode, Metabase, or similar)', 'Ability to translate complex data into clear, actionable insights', 'Solid communication and collaboration skills-especially in a remote environment', 'Bonus: Background in supporting product-led growth (PLG) or developer-focused SaaS', 'Job level and actual compensation will be evaluated based on factors including, but not limited to, qualifications objectively assessed during the interview process (including skills and prior relevant experience, potential impact, and scope of role), internal equity with other team members, market data, and specific work location', 'All candidates must be US-based, and legally authorized to work in the United States']","[""You'll work closely with cross-functional teams-from engineering and product to marketing and growth-to help us make smarter, faster decisions backed by data"", 'We expect you to become the resident expert on the product and our customers', 'Design, implement, and maintain clean, reusable, and scalable data models using dbt for all teams across ngrok, from product to GTM and finance', ""Analyze user behavior, product adoption, and performance across ngrok's core services"", 'Partner with Product, Engineering, and GTM teams to define KPIs and deliver actionable insights', 'Create dashboards in Superset and reports to communicate trends and uncover opportunities for optimization', 'Build predictive and diagnostic models to support business planning and user segmentation', 'Help maintain data integrity and drive best practices in data governance and quality']",True,[],,"['SQL', 'Data Modeling', 'Data Pipelines Orchestration', 'Business Intelligence (BI) Tools', 'Predictive and Diagnostic Modeling', 'Data Governance and Quality', 'Version Control and Continuous Integration']","SQL: Used extensively for querying and managing high volume, high velocity data sets to build self-service analytics datasets and dashboards in collaboration with business and product teams.; Data Modeling: Designing, implementing, and maintaining clean, reusable, and scalable data models using tools such as dbt or SQLMesh to support various teams including product, GTM, and finance.; Data Pipelines Orchestration: Managing data pipelines using orchestration tools like Dagster or Airbyte to ensure reliable data flow and integration across systems.; Business Intelligence (BI) Tools: Creating dashboards and reports using BI tools such as Superset, Looker, Mode, or Metabase to communicate trends and uncover optimization opportunities.; Predictive and Diagnostic Modeling: Building predictive and diagnostic models to support business planning and user segmentation, enabling data-driven decision making.; Data Governance and Quality: Maintaining data integrity and driving best practices in data governance and quality to ensure reliable and accurate data for analysis.; Version Control and Continuous Integration: Working with engineering teams using version control systems like git and command line tools, as well as continuous integration (CI) to manage code and data workflows."
Ws41jgUNn9uFXim5AAAAAA==,Data Scientist,"Company Description

Implify, Inc is a Global IT Solutions and services firm. Since it's inception, Implify, Inc has been providing best-quality and cost-effective IT solutions to fortune 1000 companies, mid-range companies and upcoming companies via its onsite, Offshore and in-house service models.

IMPLIFY is an IT consulting services and software development firm dedicated to business success through long-term relationships with our clients and staff. IMPLIFY has built a dynamic, profitable, service-oriented enterprise, and is positioned to successfully respond to trends and changes in the information technology industry.

Job Description

Data Scientist
Location: Newark NJ
Interview process: Phone and In Person (face to face)

Job Descripction
As a Data Scientist, you solve complex challenges and identify new opportunities using a combination of analytical expertise, business acumen, strategic thinking, and project and relationship management skills. This is an exciting opportunity to be a part of a new strategic initiative & this position is located in Newark, N.J., a quick, easy 15-minute train ride from New York Penn Station.

RESPONSIBILITIES
Integrate and mine large data sets, connecting data from disparate sources to identify insights and patterns using predictive and prescriptive analytics, and machine learning techniques
Conduct intermediate and advanced statistical analysis, such as linear regression, ANOVA, time-series analysis, classification models, neural networks, decision trees, as well as analysis of unstructured data (e.g., social media listening, digital footprints, speech analytics)
Prepare and present written and verbal reports, findings, and presentations to key stakeholders, distilling complex statistical information into easy-to-understand business language
Apply knowledge of U.S. businesses and corporate groups and relevant industry knowledge to analysis and insights
Manage project budgets and timelines, ensuring times and on-budget completion
QUALIFICATIONS
Experience analyzing large data sets using statistical software, such as SAS, R, Python, and SPSS, to discover new business insights
Excel and PowerPoint a must. SQL Programming and experience of at least one DBMS such as IBM DB2, Oracle, SQL Server or Sybase are required. Java strongly desired
Prior experience with building models, analyzing unstructured data, and/or machine learning
Relevant academic experience and work experience in Statistics, with exposure to data structures and data visualization
Master's degree in Mathematics, Statistics, Engineering, Computer Science, or a quantitative discipline plus a minimum of 2-3 years of work experience, or bachelor's degree plus 5 years work experience
Well-developed written and oral communication skills, with ability to present and explain data to business manager
Strong project management skills / experience managing projects, budgets, and schedules to successful completion
Some prior exposure to financial services or insurance industry desired

Additional Information

All your information will be kept confidential according to EEO guidelines.",,2025-07-25,"['As a Data Scientist, you solve complex challenges and identify new opportunities using a combination of analytical expertise, business acumen, strategic thinking, and project and relationship management skills', 'Experience analyzing large data sets using statistical software, such as SAS, R, Python, and SPSS, to discover new business insights', 'Excel and PowerPoint a must', 'SQL Programming and experience of at least one DBMS such as IBM DB2, Oracle, SQL Server or Sybase are required', 'Prior experience with building models, analyzing unstructured data, and/or machine learning', 'Relevant academic experience and work experience in Statistics, with exposure to data structures and data visualization', ""Master's degree in Mathematics, Statistics, Engineering, Computer Science, or a quantitative discipline plus a minimum of 2-3 years of work experience, or bachelor's degree plus 5 years work experience"", 'Well-developed written and oral communication skills, with ability to present and explain data to business manager', 'Strong project management skills / experience managing projects, budgets, and schedules to successful completion']","['Integrate and mine large data sets, connecting data from disparate sources to identify insights and patterns using predictive and prescriptive analytics, and machine learning techniques', 'Conduct intermediate and advanced statistical analysis, such as linear regression, ANOVA, time-series analysis, classification models, neural networks, decision trees, as well as analysis of unstructured data (e.g., social media listening, digital footprints, speech analytics)', 'Prepare and present written and verbal reports, findings, and presentations to key stakeholders, distilling complex statistical information into easy-to-understand business language', 'Apply knowledge of U.S. businesses and corporate groups and relevant industry knowledge to analysis and insights', 'Manage project budgets and timelines, ensuring times and on-budget completion']",True,[],,"['Predictive Analytics', 'Prescriptive Analytics', 'Machine Learning', 'Statistical Analysis', 'Unstructured Data Analysis', 'SAS', 'R', 'Python', 'SPSS', 'Excel', 'PowerPoint', 'SQL Programming', 'DBMS (IBM DB2, Oracle, SQL Server, Sybase)', 'Neural Networks', 'Decision Trees', 'Classification Models', 'Time-Series Analysis']","Predictive Analytics: Used to identify insights and patterns from large, disparate data sets to solve complex challenges and find new opportunities.; Prescriptive Analytics: Applied to recommend actions based on data insights derived from integrated large data sets.; Machine Learning: Utilized techniques including building models and analyzing unstructured data to extract business insights and support decision-making.; Statistical Analysis: Conducted intermediate and advanced analyses such as linear regression, ANOVA, time-series analysis, classification models, neural networks, and decision trees to interpret data and support business objectives.; Unstructured Data Analysis: Analyzed data types like social media listening, digital footprints, and speech analytics to extract meaningful information.; SAS: Used as statistical software for analyzing large data sets to discover new business insights.; R: Employed as a statistical programming language for data analysis and modeling.; Python: Used for statistical analysis, data manipulation, and building machine learning models.; SPSS: Applied as statistical software for data analysis and insights generation.; Excel: Used for data manipulation, analysis, and presentation of findings.; PowerPoint: Utilized to prepare and present reports and findings to stakeholders in an understandable business language.; SQL Programming: Required for querying and managing data within databases such as IBM DB2, Oracle, SQL Server, or Sybase.; DBMS (IBM DB2, Oracle, SQL Server, Sybase): Experience with these database management systems is necessary for data storage, retrieval, and management.; Neural Networks: Applied as part of advanced statistical and machine learning techniques to analyze data and build predictive models.; Decision Trees: Used as a classification model within machine learning and statistical analysis to support data-driven decisions.; Classification Models: Implemented to categorize data points and support predictive analytics.; Time-Series Analysis: Conducted to analyze data points collected or recorded at specific time intervals for trend and pattern identification."
WforHCgGe6I1LGvvAAAAAA==,Junior Data Scientist,"Role: Junior Data Scientist

About Us: Synergistic IT is a full-service staffing and placement firm servicing client in America for the past 12+ years. We are dedicated towards fulfilling the IT needs of our clients. From staffing to full implementation of projects we provide the highest quality IT Services. We Intend to deliver exceptional student outcome. We don't just help you secure a tech job but build a solid career in technology.

Job description

Roles Responsibilities:

Help extract data from multiple sources and join it together to prepare a datapool for the project.

Analyze and recommend the best strategy to develop a powerful model based in the current data generated by our business.

Optimize the current Model to make it scalable and easily configurable for other projects

Develop the explanations to explain models recommendations to the team.

Be prepared for changes in business direction and understand when to adjust designs.

Skills Required:

Specialist in datasets management

Very fluent in SQL data bases for complex queries.

Able to carry on with data conversion from different sources

Ability to use Microsoft Power BI

Notions of Machine learning algorithms

Problem-solving aptitude

Excellent communication and presentation skills

Education Requirement: -

· Bachelors in Computer Science, Engineering or relevant field; graduate degree in Data Science or another quantitative field is preferred.

Benefits:

· On Job Technical support

· E- verified

· Filing of H1b.

· Full time position

Candidate who are missing the required skills, might be provided an option to enhance their skills, so that they can also apply for the role and can make a career in IT industry.

If you do respond via e-mail, please include a daytime phone number so that we can reach you. In considering candidates, time is of the essence, so please respond ASAP.

Thank you",,2025-07-25,"['Specialist in datasets management', 'Very fluent in SQL data bases for complex queries', 'Able to carry on with data conversion from different sources', 'Ability to use Microsoft Power BI', 'Notions of Machine learning algorithms', 'Problem-solving aptitude', 'Excellent communication and presentation skills', 'Filing of H1b']","['Help extract data from multiple sources and join it together to prepare a datapool for the project', 'Analyze and recommend the best strategy to develop a powerful model based in the current data generated by our business', 'Optimize the current Model to make it scalable and easily configurable for other projects', 'Develop the explanations to explain models recommendations to the team', 'Be prepared for changes in business direction and understand when to adjust designs']",True,[],,"['SQL', 'Data Extraction and Integration', 'Data Conversion', 'Microsoft Power BI', 'Machine Learning Algorithms', 'Model Optimization', 'Model Explanation']",SQL: Used for writing complex queries to extract and manage data from databases as part of dataset management.; Data Extraction and Integration: Involves extracting data from multiple sources and joining it together to prepare a consolidated datapool for modeling and analysis.; Data Conversion: Ability to convert data from different sources into usable formats for analysis and modeling.; Microsoft Power BI: Used to create business intelligence dashboards and visualizations to support data analysis and reporting.; Machine Learning Algorithms: Applying machine learning techniques to develop predictive models based on business data.; Model Optimization: Improving existing models to make them scalable and easily configurable for different projects.; Model Explanation: Developing explanations to communicate model recommendations effectively to the team.
HHZH0mYYs6nJHLBrAAAAAA==,"(USA) Principal, Data Scientist","Position Summary...

What you'll do...Position Summary:
Walmart Marketplace is seeking a Principal Scientist with a strong educational background in Data-Science, Mathematics, Statistics, or a related field. With at least 10+ years of industry experience (or 7+ years with a master’s degree), you'll bring extensive knowledge of machine learning, data-science, and statistics to develop innovative products/solutions while applying causal learning and anomaly detection in the ecommerce domain

.Team: Walmart’s Seller Fulfilled Services (SFS) team builds products that connect sellers across the world to buyers enabling access to over 350M+ items, and growing selection. Excellence in the end-to-end shipping and delivery experience is the cornerstone of our promise to our sellers and buyers. We use AI/ML-based products for delivery promise optimization and other touchpoints within the seller and customer journeys, creating a positive experience and impact. We are responsible for providing the best in-class marketplace experience for our sellers and customers through the design, development, and operations of highly scalable systems. We interact with multiple teams within the company to develop scalable, robust technical solutions. This scientist role will be part of the business technology team and will play a key role working along with others program managers, product managers, data scientists, engineers, and business stakeholders to build end-to-end machine learning based predictive products/solutions.
More about Marketplace: https://marketplace.walmart.com/

What you'll do:As a Principal Data Scientist, you'll have the opportunity to:
• Lead the development and deployment of machine learning models across Walmart’s Marketplace but with core focus on offerings which are fulfilled by the sellers themselves. Drawing on your extensive experience, you will work on large-scale data challenges, design innovative algorithms, and collaborate with cross-functional teams to drive measurable business outcomes.
• Lead the end-to-end lifecycle of AI/ML projects, from ideation to deployment, ensuring alignment with Walmart’s Marketplace strategic goals.
• Develop novel algorithms and leverage data science frameworks (e.g., TensorFlow, PyTorch, Sagemaker, etc.) to solve complex problems in promise optimization, abuse detection, return optimization and other business areas.
• Drive data-derived insights across a wide range of retail challenges by developing advanced statistical models, machine learning algorithms and computational algorithms/.
• Direct the gathering of data, assessing data validity and synthesizing data into large analytics datasets to support project goals
• Utilize big data analytics and advanced data science techniques to identify trends, patterns, and discrepancies in data. Determine additional data needed to support insights
• Build and train statistical models and machine learning algorithms, ready for deployment
• Monitor model performance and refine/tune the model parameters to achieve pre-defined outputs at scale. Communicate insights to business partners in WBRs/MBR’s/QBRs, and influence future data-science roadmap.
• Collaborate with teams across business, product, and engineering to understand forward-looking roadmap, and integrate data science solutions seamlessly.
• Advocate for best practices in software development, including continuous integration/continuous deployment, unit testing, and documentation, to ensure robust and reliable systems.
• Mentor junior data scientists and contribute to building a culture of innovation and learning within the data science community at Walmart.
What you'll bring:
• Bachelor’s degree with 10+ years of experience / master’s degree with 7+ years of experience. Educational qualifications should be preferably in Computer Science/ Data Science/ Industrial Engineering/ Mathematics/ Statistics or a related area.
• Proven track record in designing and implementing AI/ML solutions for large-scale, high-performance systems.
• Proven track record of building and maintaining APIs for machine learning or data-driven applications.
• Hands on experience building data-science, machine learning or AI based products/solutions.
• Experience in applying causal learning and anomaly detection in ecommerce domain.
• Experience in machine learning, supervised and unsupervised and deep learning.
• Experience in analyzing complex/ambiguous problems and translating it into data science algorithms/solutions.
• Experience in Python with excellent knowledge of Data Structures
• Experience with big data analytics and platforms (using software like PyTorch, TensorFlor, Hive, Spark)
• Experience with SQL and relational databases, data warehouse.
Preferred Qualifications:
• Masters or Ph.D. in a related discipline.
• 5+ years' experience in e-commerce, Marketplace, or Supply Chain/ Operations optimization.
• Experience with Neural Networks, LLMs, AI is a plus.
• Hands-on experience in network optimization or distributed computing framework like Spark.

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

‎

‎

‎
You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.

‎

For information about PTO, see https://one.walmart.com/notices.

‎

‎
Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

‎
Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

‎

For information about benefits and eligibility, see One.Walmart.

‎
The annual salary range for this position is $143,000.00-$286,000.00

‎
Additional compensation includes annual or quarterly performance bonuses.

‎
Additional compensation for certain positions may also include:

‎

‎
- Stock

‎

‎

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 5 years' experience in an analytics related field. Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 3 years' experience in an analytics related field. Option 3: 7 years' experience in an analytics or related field

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data science, machine learning, optimization models, PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Publications or active peer reviewer in related journals or conference, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.

Primary Location...

840 W California Ave, Sunnyvale, CA 94086-4828, United States of America",2025-07-19T00:00:00.000Z,2025-07-25,"['Walmart Marketplace is seeking a\u202fPrincipal Scientist\u202fwith a\u202fstrong educational background in Data-Science, Mathematics, Statistics, or a related field', ""With at least 10+ years of industry experience (or 7+ years with a master’s degree), you'll bring\u202fextensive knowledge of machine learning, data-science, and statistics\u202fto develop innovative\u202fproducts/solutions while applying causal learning and anomaly detection in the ecommerce domain"", 'Bachelor’s degree with 10+ years of experience / master’s degree with 7+ years of experience.\u202fEducational qualifications should be preferably in\u202fComputer Science/ Data Science/ Industrial Engineering/ Mathematics/ Statistics\u202for a related area', 'Proven track record in designing and implementing AI/ML solutions for large-scale, high-performance systems', 'Proven track record of building and maintaining APIs for machine learning or data-driven applications', 'Hands on experience building\u202fdata-science, machine learning or AI based products/solutions', 'Experience in\u202fapplying causal learning and anomaly detection in ecommerce domain', 'Experience in machine learning, supervised and unsupervised and deep learning', 'Experience in analyzing complex/ambiguous problems and translating it into data science algorithms/solutions', 'Experience in Python with excellent knowledge of Data Structures', 'Experience with big data analytics and platforms (using software like PyTorch, TensorFlor, Hive, Spark)', 'Experience with SQL and relational databases, data warehouse', ""Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 5 years' experience in an analytics related field"", ""Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 3 years' experience in an analytics related field"", ""Option 3: 7 years' experience in an analytics or related field"", 'Data science, machine learning, optimization models, PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Publications or active peer reviewer in related journals or conference, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly', 'The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture']","['.Team:\u202fWalmart’s Seller Fulfilled Services (SFS) team builds products that connect sellers across the world to buyers enabling access to over 350M+ items, and growing selection', 'Excellence in the end-to-end shipping and delivery experience is the cornerstone of our promise to our sellers and buyers', 'We use AI/ML-based products for delivery promise optimization and other touchpoints within the seller and customer journeys, creating a positive experience and impact', 'This scientist role will be part of the business technology team and will play a key role working along with others program managers, product managers, data scientists, engineers, and business stakeholders to build end-to-end machine learning based predictive products/solutions', 'Lead the development and deployment of machine learning models across Walmart’s Marketplace but with core focus on offerings which are fulfilled by the sellers themselves', 'Drawing on your extensive experience, you will work on large-scale data challenges, design innovative algorithms, and collaborate with cross-functional teams to drive measurable business outcomes', 'Lead the end-to-end lifecycle of AI/ML projects, from ideation to deployment, ensuring alignment with Walmart’s Marketplace strategic goals', 'Develop novel algorithms and leverage data science frameworks (e.g., TensorFlow, PyTorch, Sagemaker, etc.)', 'to solve complex problems in promise optimization, abuse detection, return optimization and other business areas', 'Drive data-derived insights across a wide range of retail challenges by developing advanced statistical models, machine learning algorithms and computational algorithms/', 'Direct the gathering of data, assessing data validity and synthesizing data into large analytics datasets to support project goals', 'Utilize big data analytics and advanced data science techniques to identify trends, patterns, and discrepancies in data', 'Determine additional data needed to support insights', 'Build and train statistical models and machine learning algorithms, ready for deployment', 'Monitor model performance and refine/tune the model parameters to achieve pre-defined outputs at scale', 'Communicate insights to business partners in WBRs/MBR’s/QBRs, and influence future data-science roadmap', 'Collaborate with teams across business, product, and engineering to understand forward-looking roadmap, and integrate data science solutions seamlessly', 'Advocate for best practices in software development, including continuous integration/continuous deployment, unit testing, and documentation, to ensure robust and reliable systems', 'Mentor junior data scientists and contribute to building a culture of innovation and learning within the data science community at Walmart']",True,"['Neural Networks', 'Large Language Models (LLMs)', 'TensorFlow', 'PyTorch', 'SageMaker']","Neural Networks: Experience with neural networks as part of deep learning approaches to enhance AI/ML solutions in ecommerce and marketplace optimization.; Large Language Models (LLMs): Preferred experience with LLMs and AI, indicating involvement with modern AI technologies beyond traditional machine learning.; TensorFlow: Use TensorFlow as a deep learning framework to develop and deploy AI/ML models within Walmart’s Marketplace.; PyTorch: Utilize PyTorch for building and training deep learning models as part of AI/ML product development.; SageMaker: Leverage AWS SageMaker for managing the lifecycle of machine learning and AI models, including development and deployment.","['Machine Learning', 'Causal Learning', 'Anomaly Detection', 'Supervised and Unsupervised Learning', 'Deep Learning', 'Statistical Models', 'Data Science Frameworks', 'Big Data Analytics', 'SQL and Relational Databases', 'Python Programming', 'Optimization Models', 'Data Pipelines and APIs', 'Computational Algorithms']","Machine Learning: Lead the development and deployment of machine learning models across Walmart’s Marketplace with a focus on seller-fulfilled offerings; build and train machine learning algorithms ready for deployment; monitor and tune model performance at scale.; Causal Learning: Apply causal learning techniques specifically in the ecommerce domain to develop innovative products and solutions.; Anomaly Detection: Utilize anomaly detection methods in the ecommerce domain to identify unusual patterns and support business objectives.; Supervised and Unsupervised Learning: Experience in applying both supervised and unsupervised machine learning techniques to solve complex problems.; Deep Learning: Experience with deep learning methods, including neural networks, applied to large-scale data challenges and business problems.; Statistical Models: Develop advanced statistical models to drive data-derived insights across retail challenges and support project goals.; Data Science Frameworks: Leverage data science frameworks such as TensorFlow, PyTorch, and SageMaker to develop novel algorithms and solve complex business problems.; Big Data Analytics: Utilize big data analytics platforms and techniques, including Hive and Spark, to analyze large datasets, identify trends, and support insights.; SQL and Relational Databases: Use SQL and relational database technologies to gather, validate, and synthesize data into large analytics datasets.; Python Programming: Employ Python with strong knowledge of data structures for building data science and machine learning solutions.; Optimization Models: Apply optimization models to improve marketplace operations such as delivery promise, abuse detection, and return optimization.; Data Pipelines and APIs: Build and maintain APIs for machine learning or data-driven applications and develop end-to-end data science pipelines.; Computational Algorithms: Design and implement computational algorithms to address complex retail and ecommerce challenges."
wK-RaE65kRZyZKBrAAAAAA==,Lead Data Scientist - Operations Research,"McKesson is an impact-driven, Fortune 10 company that touches virtually every aspect of healthcare. We are known for delivering insights, products, and services that make quality care more accessible and affordable. Here, we focus on the health, happiness, and well-being of you and those we serve - we care.

What you do at McKesson matters. We foster a culture where you can grow, make an impact, and are empowered to bring new ideas. Together, we thrive as we shape the future of health for patients, our communities, and our people. If you want to be part of tomorrow's health today, we want to hear from you.

The Lead Data Scientist, Operations Research role is responsible for architecting and implementing AI/ML, simulation and/or optimization products to enhance the efficiency and effectiveness of McKesson's supply chain operations as part of a McKesson's Supply Chain Operations Research COE.

Our team applies data science methodologies to interdisciplinary business problems across Operations & Supply Chain. This position will primarily work on strategic in-flight use cases around inventory and operating expense management. The position's objectives are:
• Develop stochastic process models and/or optimization models to provide data-driven recommendations to business unit stakeholders
• Lead development and enhancement of enterprise-scale digital twins for network management and control

The candidate should possess the ability to perform statistical modelling techniques and derive business insights that are required to drive analytic innovation at McKesson. The candidate should also be an active learner able to grasp and apply new analytic approaches, as well as mentor junior / developing resources.

Position Description

The purpose of this position is to architect, implement, drive adoption, and measure impact of innovative analytic solutions at McKesson, as well as make significant improvements to existing solutions.

Analytic Responsibilities
• Develop supply chain network design, inventory, and/or transportation cost optimization solutions
• Develop statistical simulation decision frameworks
• Development of AI/ML-based solutions and enhancements where needed in support of simulation and optimization workstreams

Other Responsibilities
• Support stakeholders' analytic needs, gather user requirements, and help drive adoption of developed methodologies
• Cultivate business development opportunities
• Assist in developing and maintaining long-term stakeholder relationships

Education:

Bachelor's degree in technical fields such as Operations Research, Statistics, Computer Science, Applied Mathematics, Engineering or related quantitative majors. Master's and/or PhD preferred.

Minimum Requirements
• A degree or equivalent and typically requires 10+ years of relevant experience. Fewer years required if they have relevant Master's or Doctorate qualifications

Critical Skills
• 7+ years of operations research/data science experience based on a combination of industry and academic experience
• Demonstrated experience with solving enterprise network design, inventory, and/or transportation optimization problems
• Experience with Gurobi, Xpress, CPLEX or open-source solvers (CBC, GLPK)
• Experience with local search techniques and advanced mathematical programming techniques such as column generation and decomposition.
• Knowledge of statistical programming (Python or R)
• Fundamental statistical knowledge (i.e., random variables, probability distributions, confidence intervals, outlier detection)
• Experience with Monte Carlo simulation
• Demonstrated ability in data extraction and wrangling using SQL
• Ability to communicate technical concepts to non-technical audiences

Additional Knowledge & Skills
• Team player
• Strong verbal and written communication
• Proficient with Excel spreadsheets, financial modeling, and reporting
• Knowledge of relational databases (e.g. MS SQL Server, Snowflake, Oracle)
• Knowledge of data warehousing & ETL best practices is a plus
• Knowledge of cloud computing platforms (e.g. Azure, AWS, Databricks) is a plus
• Prior data mining experience using enterprise systems (SAP or JD Edwards preferred) is a plus

Please note that only candidates authorized to work in the US will be considered for this position. Sponsorship is not available.

We are proud to offer a competitive compensation package at McKesson as part of our Total Rewards. This is determined by several factors, including performance, experience and skills, equity, regular job market evaluations, and geographical markets. The pay range shown below is aligned with McKesson's pay philosophy, and pay will always be compliant with any applicable regulations. In addition to base pay, other compensation, such as an annual bonus or long-term incentive opportunities may be offered. For more information regarding benefits at McKesson, please click here.

Our Base Pay Range for this position

$158,000 - $263,300

McKesson is an Equal Opportunity Employer

McKesson provides equal employment opportunities to applicants and employees and is committed to a diverse and inclusive environment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, age or genetic information. For additional information on McKesson's full Equal Employment Opportunity policies, visit our Equal Employment Opportunity page.

Join us at McKesson!",2025-06-25T00:00:00.000Z,2025-07-25,"['The candidate should possess the ability to perform statistical modelling techniques and derive business insights that are required to drive analytic innovation at McKesson', 'The candidate should also be an active learner able to grasp and apply new analytic approaches, as well as mentor junior / developing resources', ""Bachelor's degree in technical fields such as Operations Research, Statistics, Computer Science, Applied Mathematics, Engineering or related quantitative majors"", 'A degree or equivalent and typically requires 10+ years of relevant experience', ""Fewer years required if they have relevant Master's or Doctorate qualifications"", '7+ years of operations research/data science experience based on a combination of industry and academic experience', 'Demonstrated experience with solving enterprise network design, inventory, and/or transportation optimization problems', 'Experience with Gurobi, Xpress, CPLEX or open-source solvers (CBC, GLPK)', 'Experience with local search techniques and advanced mathematical programming techniques such as column generation and decomposition', 'Knowledge of statistical programming (Python or R)', 'Fundamental statistical knowledge (i.e., random variables, probability distributions, confidence intervals, outlier detection)', 'Experience with Monte Carlo simulation', 'Demonstrated ability in data extraction and wrangling using SQL', 'Ability to communicate technical concepts to non-technical audiences', 'Team player', 'Strong verbal and written communication', 'Proficient with Excel spreadsheets, financial modeling, and reporting', 'Knowledge of relational databases (e.g. MS SQL Server, Snowflake, Oracle)']","[""The Lead Data Scientist, Operations Research role is responsible for architecting and implementing AI/ML, simulation and/or optimization products to enhance the efficiency and effectiveness of McKesson's supply chain operations as part of a McKesson's Supply Chain Operations Research COE"", 'Our team applies data science methodologies to interdisciplinary business problems across Operations & Supply Chain', 'This position will primarily work on strategic in-flight use cases around inventory and operating expense management', 'Develop stochastic process models and/or optimization models to provide data-driven recommendations to business unit stakeholders', 'Lead development and enhancement of enterprise-scale digital twins for network management and control', 'The purpose of this position is to architect, implement, drive adoption, and measure impact of innovative analytic solutions at McKesson, as well as make significant improvements to existing solutions', 'Develop supply chain network design, inventory, and/or transportation cost optimization solutions', 'Develop statistical simulation decision frameworks', 'Development of AI/ML-based solutions and enhancements where needed in support of simulation and optimization workstreams', ""Support stakeholders' analytic needs, gather user requirements, and help drive adoption of developed methodologies"", 'Cultivate business development opportunities', 'Assist in developing and maintaining long-term stakeholder relationships']",True,['Artificial Intelligence and Machine Learning'],"Artificial Intelligence and Machine Learning: Architecting and implementing AI/ML-based solutions to enhance simulation and optimization products within supply chain operations, supporting analytic innovation and operational efficiency.","['Operations Research', 'Stochastic Process Models', 'Optimization Models', 'Digital Twins', 'Statistical Simulation', 'AI/ML-based Solutions', 'Mathematical Programming Techniques', 'Solver Tools', 'Statistical Programming', 'Fundamental Statistical Knowledge', 'Data Extraction and Wrangling', 'Relational Databases', 'Data Warehousing and ETL', 'Cloud Computing Platforms', 'Data Mining', 'SQL', 'Excel and Financial Modeling']","Operations Research: The role involves applying operations research techniques such as enterprise network design, inventory, and transportation optimization to improve supply chain operations.; Stochastic Process Models: Developing stochastic process models to provide data-driven recommendations to business unit stakeholders in supply chain management.; Optimization Models: Creating optimization models to enhance efficiency and effectiveness in supply chain network design, inventory, and transportation cost management.; Digital Twins: Leading the development and enhancement of enterprise-scale digital twins for network management and control to simulate and optimize supply chain operations.; Statistical Simulation: Developing statistical simulation decision frameworks, including Monte Carlo simulation, to support decision-making in supply chain operations.; AI/ML-based Solutions: Implementing AI and machine learning solutions to support simulation and optimization workstreams within supply chain operations.; Mathematical Programming Techniques: Using advanced mathematical programming techniques such as column generation, decomposition, and local search methods to solve complex optimization problems.; Solver Tools: Experience with optimization solvers like Gurobi, Xpress, CPLEX, and open-source solvers such as CBC and GLPK to implement optimization models.; Statistical Programming: Utilizing statistical programming languages such as Python or R for data analysis, modeling, and simulation tasks.; Fundamental Statistical Knowledge: Applying knowledge of random variables, probability distributions, confidence intervals, and outlier detection to perform statistical modeling and derive business insights.; Data Extraction and Wrangling: Demonstrated ability to extract and wrangle data using SQL to support analytic needs and model development.; Relational Databases: Knowledge of relational database systems including MS SQL Server, Snowflake, and Oracle to manage and query data relevant to supply chain analytics.; Data Warehousing and ETL: Understanding of data warehousing and ETL best practices to support data integration and preparation for analytics (noted as a plus).; Cloud Computing Platforms: Familiarity with cloud platforms such as Azure, AWS, and Databricks to support scalable data processing and analytics (noted as a plus).; Data Mining: Experience with data mining using enterprise systems like SAP or JD Edwards to extract insights from operational data (noted as a plus).; SQL: Using SQL for data extraction and wrangling to support analytics and modeling efforts.; Excel and Financial Modeling: Proficiency with Excel spreadsheets and financial modeling to support reporting and analysis."
3NVf2GeHN199af05AAAAAA==,"Data Scientist, Marketing","Benefits Start Day 1 for Full-Time Colleagues - No Waiting Period!

For more information about our benefits, see below!

We are proud to be a member of the Rentokil family of companies, the global leader in Pest Control and other services across more than 90 countries. We pride ourselves on being a trusted partner to many of the world's leading brands and serve consumer and business customers across multiple industries. We are extremely proud of our legacy of excellence and constantly work to fulfill our mission to ""protect people, enhance lives, and preserve the planet.""

NO SPONSORSHIP OR OPT AVAILABLE

This role will be responsible to apply their analytical and technical skills to solve real-world business problems. The Data Scientist will work closely with stakeholders to collect, clean, analyze, and interpret data, and contribute to the development and deployment of ML models and data-driven solutions. This role requires a strong foundation in statistical analysis, machine learning concepts, and programming, along with a passion for learning and exploring data.

Duties & Responsibilities
• Assist in the collection, cleaning, and preprocessing of large and complex datasets from various sources.
• Conduct exploratory data analysis (EDA) to identify patterns, trends, and insights in the data.
• Apply statistical techniques and machine learning algorithms to build predictive models, perform classification, clustering, and other data analysis tasks.
• Development and validation of machine learning models (Supervised and Unsupervised), and other categories such as Ensemble Methods, and Time-series models.
• Collaborate with other data scientists and other team members to define project requirements and objectives.
• Communicate findings and insights effectively through visualizations, reports, and presentations.
• Stay up-to-date with the latest advancements in data science, machine learning, and related technologies.
• Document code, methodologies, and results clearly and concisely.
• Participate in the deployment and monitoring of data science models and solutions.
• Contribute to the development of data-driven products and features.
• Assist in the evaluation of new data sources and technologies.
• Independently plan and execute work across multiple projects, stakeholders, and functional areas

Candidate Requirements

Education
• Bachelor's or Master's degree in a quantitative field such as Data Science, Statistics, Mathematics, Computer Science, Engineering, Economics, or a related discipline.

Experience
• 3+ years of relevant experience in data analysis, statistical modeling, or machine learning.
• Strong understanding of statistical concepts, probability theory, and experimental design.
• Familiarity with machine learning algorithms (e.g., regression, classification, clustering, dimensionality reduction).
• Proficiency in at least one programming language commonly used in data science (e.g., Python, R).
• Experience with data manipulation and analysis libraries (e.g., Pandas, NumPy, SciPy in Python; dplyr, tidyr in R).
• Familiarity with data visualization libraries (e.g., Matplotlib, Seaborn, Plotly in Python; ggplot2 in R).
• Basic understanding of database concepts and SQL.
• Strong analytical and problem-solving skills with the ability to work with imperfect data.
• Excellent written and verbal communication skills, with the ability to explain technical concepts to non-technical audiences.
• Ability to work independently and collaboratively within a team environment.
• A strong desire to learn and grow in the field of data science.
• Experience with cloud computing platforms (e.g., AWS, Azure, GCP). (preferred)
• Familiarity with big data technologies (e.g., Spark, Hadoop). (preferred)
• Experience with version control systems (e.g., Git). (preferred)
• Knowledge of specific industry domains relevant to the company. (preferred)
• Experience with deploying machine learning models into production. (preferred)

Physical Demands and Working Conditions

The physical demands are representative of those that must be met by an employee to perform the essential function to this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

Incumbent must be prepared to:
• Move up to 10 pounds occasionally, by lifting, carrying, pushing, pulling, or otherwise repositioning objects.
• Sitting for long periods of time while using office equipment such as computers, phones and etc.
• Performing repetitive motions involving the wrists, hands, and fingers, such as typing, picking, and pinching, within your regular work environment.
• Express or exchange ideas with others through the use of spoken word, quickly, accurately, and at an easily audible volume, and receive detailed information through oral communication at usual speaking levels without correction, and/or make fine discriminations in the nature of sounds in the environment.

Incumbent is required to have:
• Near-range visual acuity for detailed tasks and ability to perform activities with precision such as analyzing data, viewing computer screens or reading extensively.

Incumbent will be subject to:
• Inside working conditions: The change of building environment such as with or without air conditioning and heating.

Annual Earning Potential: $102,000 - $132,600 / year .
While starting pay falls within the given range, it can vary based on factors like geographic location, skills, education, and experience. Total earnings may also be affected by overtime, incentives, commissions, performance, and route assignment (where applicable).

Why Choose Us?

A career with the Rentokil family of companies can be a professional trajectory filled with opportunity. We pride ourselves on being a world-class team that rewards high performance, and we love to promote from within. We offer competitive pay and many of our roles offer performance incentives.

Below you'll find information about some of what we have to offer. All Full-Time Colleagues qualify for the following and Part-Time Colleagues qualify for most benefits after they meet certain criteria.

Click here to read more about our Total Rewards Program which includes:

Professional and Personal Growth
• Multiple avenues to grow your career
• Training and development programs available
• Tuition Reimbursement benefits (for FT Colleagues)

Health and Wellness
• Health benefits including Medical, Dental, Vision, Disability, and Life Insurance plus much more
• Full-time colleagues are eligible to begin enrollment immediately upon hire with benefits starting on day 1

Savings and Retirement
• 401(k) retirement plan with company-matching contributions

Work-Life Balance
• Vacation days & sick days
• Company-paid holidays & floating holidays
• A company mindset that prioritizes health, safety, and flexibility

We are looking for individuals who want to make a difference where our customers live and work. Is that you?

This company is a Drug Free workplace.

Rentokil is committed to complying with all Federal, State, and local laws related to the employment of qualified individuals with disabilities.

Know Your Rights - Workplace Discrimination is Illegal

Pay Transparency - Nondiscrimination Provision

California residents click here to review your privacy rights.

It is unlawful in Massachusetts to require or administer a lie detector test as a condition of employment or continued employment. An employer who violates this law shall be subject to criminal penalties and civil liability.

By applying to this job, you agree to receive initial texts from systems used on behalf of Rentokil North America, Inc., possibly including Workday, Loop, and HireVue. These systems utilize text messages to communicate with you throughout the application, interview, and pre-hire processes. You can set your communication preferences or opt out of text messages from each system at any time following the initial message. Message and data rates may apply.",,2025-07-25,"[""Bachelor's or Master's degree in a quantitative field such as Data Science, Statistics, Mathematics, Computer Science, Engineering, Economics, or a related discipline"", '3+ years of relevant experience in data analysis, statistical modeling, or machine learning', 'Strong understanding of statistical concepts, probability theory, and experimental design', 'Familiarity with machine learning algorithms (e.g., regression, classification, clustering, dimensionality reduction)', 'Proficiency in at least one programming language commonly used in data science (e.g., Python, R)', 'Experience with data manipulation and analysis libraries (e.g., Pandas, NumPy, SciPy in Python; dplyr, tidyr in R)', 'Familiarity with data visualization libraries (e.g., Matplotlib, Seaborn, Plotly in Python; ggplot2 in R)', 'Basic understanding of database concepts and SQL', 'Strong analytical and problem-solving skills with the ability to work with imperfect data', 'Excellent written and verbal communication skills, with the ability to explain technical concepts to non-technical audiences', 'Ability to work independently and collaboratively within a team environment', 'A strong desire to learn and grow in the field of data science', 'Experience with cloud computing platforms (e.g., AWS, Azure, GCP)', 'Sitting for long periods of time while using office equipment such as computers, phones and etc', 'Performing repetitive motions involving the wrists, hands, and fingers, such as typing, picking, and pinching, within your regular work environment', 'Express or exchange ideas with others through the use of spoken word, quickly, accurately, and at an easily audible volume, and receive detailed information through oral communication at usual speaking levels without correction, and/or make fine discriminations in the nature of sounds in the environment', 'Near-range visual acuity for detailed tasks and ability to perform activities with precision such as analyzing data, viewing computer screens or reading extensively']","['This role will be responsible to apply their analytical and technical skills to solve real-world business problems', 'The Data Scientist will work closely with stakeholders to collect, clean, analyze, and interpret data, and contribute to the development and deployment of ML models and data-driven solutions', 'This role requires a strong foundation in statistical analysis, machine learning concepts, and programming, along with a passion for learning and exploring data', 'Assist in the collection, cleaning, and preprocessing of large and complex datasets from various sources', 'Conduct exploratory data analysis (EDA) to identify patterns, trends, and insights in the data', 'Apply statistical techniques and machine learning algorithms to build predictive models, perform classification, clustering, and other data analysis tasks', 'Development and validation of machine learning models (Supervised and Unsupervised), and other categories such as Ensemble Methods, and Time-series models', 'Collaborate with other data scientists and other team members to define project requirements and objectives', 'Communicate findings and insights effectively through visualizations, reports, and presentations', 'Stay up-to-date with the latest advancements in data science, machine learning, and related technologies', 'Document code, methodologies, and results clearly and concisely', 'Participate in the deployment and monitoring of data science models and solutions', 'Contribute to the development of data-driven products and features', 'Assist in the evaluation of new data sources and technologies', 'Independently plan and execute work across multiple projects, stakeholders, and functional areas', 'The physical demands are representative of those that must be met by an employee to perform the essential function to this job', 'Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions', 'Move up to 10 pounds occasionally, by lifting, carrying, pushing, pulling, or otherwise repositioning objects', 'Inside working conditions: The change of building environment such as with or without air conditioning and heating']",True,[],,"['Exploratory Data Analysis', 'Statistical Analysis', 'Machine Learning Algorithms', 'Data Cleaning and Preprocessing', 'Programming Languages for Data Science', 'Data Manipulation Libraries', 'Data Visualization Libraries', 'SQL and Database Concepts', 'Cloud Computing Platforms', 'Big Data Technologies', 'Version Control Systems', 'Model Deployment and Monitoring']","Exploratory Data Analysis: Used to identify patterns, trends, and insights in large and complex datasets as part of the data scientist's responsibilities.; Statistical Analysis: Applied to analyze data and build predictive models, requiring a strong foundation in statistical concepts and probability theory.; Machine Learning Algorithms: Includes supervised and unsupervised learning methods such as regression, classification, clustering, ensemble methods, and time-series models used to develop and validate predictive models.; Data Cleaning and Preprocessing: Involves collecting, cleaning, and preparing large datasets from various sources to ensure data quality for analysis and modeling.; Programming Languages for Data Science: Proficiency in Python or R is required for data manipulation, analysis, and model development.; Data Manipulation Libraries: Experience with libraries such as Pandas, NumPy, SciPy in Python, and dplyr, tidyr in R to handle and process data efficiently.; Data Visualization Libraries: Use of Matplotlib, Seaborn, Plotly in Python, and ggplot2 in R to communicate findings effectively through visualizations.; SQL and Database Concepts: Basic understanding required to query and manage data stored in databases.; Cloud Computing Platforms: Preferred experience with AWS, Azure, or GCP to support data storage, processing, and deployment of models.; Big Data Technologies: Familiarity with Spark and Hadoop is preferred for handling large-scale data processing.; Version Control Systems: Experience with Git is preferred for managing code and collaboration.; Model Deployment and Monitoring: Participation in deploying machine learning models into production and monitoring their performance."
j6OnCVQhiKTpop8TAAAAAA==,People Tech - System Architect-Data Science Senior Manager,"Industry/Sector
Not Applicable

Specialism
Data Science

Management Level
Senior Manager

Job Description & Summary
At PwC, our people in data and analytics engineering focus on leveraging advanced technologies and techniques to design and develop robust data solutions for clients. They play a crucial role in transforming raw data into actionable insights, enabling informed decision-making and driving business growth.

Those in data science and machine learning engineering at PwC will focus on leveraging advanced analytics and machine learning techniques to extract insights from large datasets and drive data-driven decision making. You will work on developing predictive models, conducting statistical analysis, and creating data visualisations to solve complex business problems.

Growing as a strategic advisor, you leverage your influence, expertise, and network to deliver quality results. You motivate and coach others, coming together to solve complex problems. As you increase in autonomy, you apply sound judgment, recognising when to take action and when to escalate. You are expected to solve through complexity, ask thoughtful questions, and clearly communicate how things fit together. Your ability to develop and sustain high performing, diverse, and inclusive teams, and your commitment to excellence, contributes to the success of our Firm.

Examples of the skills, knowledge, and experiences you need to lead and deliver value at this level include but are not limited to:
• Craft and convey clear, impactful and engaging messages that tell a holistic story.
• Apply systems thinking to identify underlying problems and/or opportunities.
• Validate outcomes with clients, share alternative perspectives, and act on client feedback.
• Direct the team through complexity, demonstrating composure through ambiguous, challenging and uncertain situations.
• Deepen and evolve your expertise with a focus on staying relevant.
• Initiate open and honest coaching conversations at all levels.
• Make difficult decisions and take action to resolve issues hindering team effectiveness.
• Model and reinforce professional and technical standards (e.g. refer to specific PwC tax and audit guidance), the Firm's code of conduct, and independence requirements.

The Opportunity
As part of the Data Platform's Data Solution team you are expected to work closely with leaders across product functions to design the analytics roadmap and to support and implement top quality data driven decisions and deliverables. As a Senior Manager you are expected to lead large projects, innovate processes, and maintain operational excellence while interacting with clients at a senior level to drive project success. You are expected to develop and implement quality controls and standards to confirm data integrity and quality.

Responsibilities
- Design the analytics roadmap in collaboration with leaders
- Support and implement data-driven decisions
- Lead large projects confirming operational excellence
- Interact with clients at a strategic level to drive success
- Develop and implement quality controls for data integrity
- Innovate processes to enhance data quality
- Deliver top-quality data solutions
- Foster relationships with product function leaders

What You Must Have
- High School Diploma
- 6 years of progressive roles managing IT architecture and engineering designs and domains

What Sets You Apart
- Bachelor's Degree in Information Technology, Computer Systems Analysis, Management Information Systems, Computer Applications, Computer Engineering, Computer Programming preferred
- Building relationships with clients and developing requests for information
- Prioritizing and handling multiple tasks
- Coaching and collaborating with colleagues
- Understanding application of analytical techniques
- Selecting necessary analytical techniques
- Designing analytics roadmap and supporting data-driven decisions
- Implementing quality controls and standards
- Programming with Python and Java

Travel Requirements
Up to 20%

Job Posting End Date

Learn more about how we work: https://pwc.to/how-we-work

PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.

As PwC is anequal opportunity employer, all qualified applicants will receive consideration for employment at PwC without regard to race; color; religion; national origin; sex (including pregnancy, sexual orientation, and gender identity); age; disability; genetic information (including family medical history); veteran, marital, or citizenship status; or, any other status protected by law.

For only those qualified applicants that are impacted by the Los Angeles County Fair Chance Ordinance for Employers, the Los Angeles' Fair Chance Initiative for Hiring Ordinance, the San Francisco Fair Chance Ordinance, San Diego County Fair Chance Ordinance, and the California Fair Chance Act, where applicable, arrest or conviction records will be considered for Employment in accordance with these laws. At PwC, we recognize that conviction records may have a direct, adverse, and negative relationship to responsibilities such as accessing sensitive company or customer information, handling proprietary assets, or collaborating closely with team members. We evaluate these factors thoughtfully to establish a secure and trusted workplace for all.

Applications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https://pwc.to/us-application-deadlines

The salary range for this position is: $91,000 - $321,500, plus individuals may be eligible for an annual discretionary bonus. For roles that are based in Maryland, this is the listed salary range for this position. Actual compensation within the range will be dependent upon the individual's skills, experience, qualifications and location, and applicable employment laws. PwC offers a wide range of benefits, including medical, dental, vision, 401k, holiday pay, vacation, personal and family sick leave, and more. To view our benefits at a glance, please visit the following link: https://pwc.to/benefits-at-a-glance",2025-07-16T00:00:00.000Z,2025-07-25,"['Your ability to develop and sustain high performing, diverse, and inclusive teams, and your commitment to excellence, contributes to the success of our Firm', 'Craft and convey clear, impactful and engaging messages that tell a holistic story', 'Deepen and evolve your expertise with a focus on staying relevant', 'High School Diploma', '6 years of progressive roles managing IT architecture and engineering designs and domains', 'Building relationships with clients and developing requests for information', 'Prioritizing and handling multiple tasks', 'Coaching and collaborating with colleagues', 'Understanding application of analytical techniques', 'Selecting necessary analytical techniques', 'Designing analytics roadmap and supporting data-driven decisions', 'Programming with Python and Java', 'Travel Requirements']","['They play a crucial role in transforming raw data into actionable insights, enabling informed decision-making and driving business growth', 'Those in data science and machine learning engineering at PwC will focus on leveraging advanced analytics and machine learning techniques to extract insights from large datasets and drive data-driven decision making', 'You will work on developing predictive models, conducting statistical analysis, and creating data visualisations to solve complex business problems', 'Growing as a strategic advisor, you leverage your influence, expertise, and network to deliver quality results', 'You motivate and coach others, coming together to solve complex problems', 'As you increase in autonomy, you apply sound judgment, recognising when to take action and when to escalate', 'You are expected to solve through complexity, ask thoughtful questions, and clearly communicate how things fit together', 'Apply systems thinking to identify underlying problems and/or opportunities', 'Validate outcomes with clients, share alternative perspectives, and act on client feedback', 'Direct the team through complexity, demonstrating composure through ambiguous, challenging and uncertain situations', 'Initiate open and honest coaching conversations at all levels', 'Make difficult decisions and take action to resolve issues hindering team effectiveness', ""Model and reinforce professional and technical standards (e.g. refer to specific PwC tax and audit guidance), the Firm's code of conduct, and independence requirements"", ""As part of the Data Platform's Data Solution team you are expected to work closely with leaders across product functions to design the analytics roadmap and to support and implement top quality data driven decisions and deliverables"", 'As a Senior Manager you are expected to lead large projects, innovate processes, and maintain operational excellence while interacting with clients at a senior level to drive project success', 'You are expected to develop and implement quality controls and standards to confirm data integrity and quality', 'Design the analytics roadmap in collaboration with leaders', 'Support and implement data-driven decisions', 'Lead large projects confirming operational excellence', 'Interact with clients at a strategic level to drive success', 'Develop and implement quality controls for data integrity', 'Innovate processes to enhance data quality', 'Deliver top-quality data solutions', 'Foster relationships with product function leaders', 'Implementing quality controls and standards']",True,[],,"['Data-Driven Decision Making', 'Advanced Analytics', 'Predictive Models', 'Statistical Analysis', 'Data Visualisation', 'Analytics Roadmap Design', 'Quality Controls and Standards for Data Integrity', 'Programming with Python and Java', 'Systems Thinking']","Data-Driven Decision Making: Used to support and implement decisions based on data insights to drive business growth and project success.; Advanced Analytics: Leveraged to extract insights from large datasets and solve complex business problems through statistical analysis and predictive modeling.; Predictive Models: Developed to forecast outcomes and support data-driven decision making in complex business scenarios.; Statistical Analysis: Conducted to analyze data and validate outcomes, enabling informed decision-making and quality results.; Data Visualisation: Created to communicate insights clearly and effectively, supporting storytelling and holistic understanding of data.; Analytics Roadmap Design: Designed collaboratively with leaders to guide analytics strategy and support data-driven deliverables.; Quality Controls and Standards for Data Integrity: Developed and implemented to ensure data accuracy, integrity, and operational excellence in data solutions.; Programming with Python and Java: Used for developing data solutions, implementing analytical techniques, and supporting engineering designs.; Systems Thinking: Applied to identify underlying problems or opportunities within complex data and business environments."
2M3Q5hJ8jDS_BFwMAAAAAA==,Staff Data Scientist - Damages,"A Day in the Life:

At Hertz, we are at the forefront of innovation, leveraging cutting-edge technologies to build the best damage management technologies in the transportation industry. We want the brightest AI & ML minds to join our Damage Science Team to help us develop and/or maintain capabilities to:
• Detect Damage via Machine Vision: Utilize computer vision techniques to accurately detect and assess damage in real-time.
• Rationalize Repair Estimates and Invoices with Large Language Models (LLMs): Implement sophisticated LLMs to make intelligent repair routing decisions, ensuring repairs are conducted efficiently and cost-effectively.
• Forecast Repair Needs: Develop models to predict future repair & maintenance needs based on historical data and trends.
• Automate Quality Assurance: Create models to evaluate the quality of repairs and ensure they meet our high standards.

We anticipate the salary to start around 160K; commensurate with experience.

What You Will Do:
• Formulate the strategic and tactical steps to carry out the model development lifecycle end-to-end (i.e. problem statement definition, exploratory data analysis, feature engineering, model development / tuning, and model implementation).
• Build and maintain descriptive, predictive, and prescriptive models to measure the performance of the new products and services.
• Cross validating production models to ensure high performance and generalizability
• Define and implement best practices to generate accurate analytics, reports, visualizations, and dashboards to explain results simply and succinctly to technical, non-technical, and senior management
• Build partnerships and work cross-functionally to identify use cases and opportunities to enhance operational efficiency and drive business value through positive impact on OKRs.
• Work with an owner mentality to drive business impact even if that means supporting pipeline creation or decision support analytics.
• Serve as a voice on how technological advancements in AI and machine learning may impact our business and the opportunities they may create.
• Provide technical leadership to more junior Data Scientist team members.

What We are Looking For:
• 5-8 years hands-on experience in a data science role
• 5+ years of data querying languages (e.g. SQL) and scripting languages (e.g. Python)
• 5+ years of end-to-end machine learning model development experience (e.g. problem statement definition, exploratory data analysis, feature engineering, model development / tuning, and deployment)
• Demonstrated experience using machine learning to drive a business impact
• Strong experience with statistical analysis, statistical modeling, and machine learning techniques
• Experience mentoring and supporting development of more junior scientists
• Experience in a ML or data scientist role with a technology company
• Master's degree in a quantitative field such as statistics, mathematics, data science, economics, or computer science
• Preferred PhD in a quantitative field such as statistics, mathematics, data science, economics, or computer science

What You'll Get:
• Up to 40% off any standard Hertz Rental
• Paid Time Off
• Medical, Dental & Vision plan options
• Retirement programs, including 401(k) employer matching
• Paid Parental Leave & Adoption Assistance
• Employee Assistance Program for employees & family
• Educational Reimbursement & Discounts
• Voluntary Insurance Programs - Pet, Legal/Identity Theft, Critical Illness
• Perks & Discounts -Theme Park Tickets, Gym Discounts & more
The Hertz Corporation operates the Hertz, Dollar Car Rental, Thrifty Car Rental brands in approximately 9,700 corporate and franchisee locations throughout North America, Europe, The Caribbean, Latin America, Africa, the Middle East, Asia, Australia and New Zealand. The Hertz Corporation is one of the largest worldwide airport general use vehicle rental companies, and the Hertz brand is one of the most recognized in the world.
US EEO STATEMENT At Hertz, we champion and celebrate a culture of diversity and inclusion. We take affirmative steps to promote employment and advancement opportunities. The endless variety of perspectives, experiences, skills and talents that our employees invest in their work every day represent a significant part of our culture - and our success and reputation as a company.
Individuals are encouraged to apply for positions because of the characteristics that make them unique.
EOE, including disability/veteran",,2025-07-25,"['5-8 years hands-on experience in a data science role', '5+ years of data querying languages (e.g. SQL) and scripting languages (e.g. Python)', '5+ years of end-to-end machine learning model development experience (e.g. problem statement definition, exploratory data analysis, feature engineering, model development / tuning, and deployment)', 'Demonstrated experience using machine learning to drive a business impact', 'Strong experience with statistical analysis, statistical modeling, and machine learning techniques', 'Experience mentoring and supporting development of more junior scientists', 'Experience in a ML or data scientist role with a technology company', ""Master's degree in a quantitative field such as statistics, mathematics, data science, economics, or computer science""]","['Detect Damage via Machine Vision: Utilize computer vision techniques to accurately detect and assess damage in real-time', 'Rationalize Repair Estimates and Invoices with Large Language Models (LLMs): Implement sophisticated LLMs to make intelligent repair routing decisions, ensuring repairs are conducted efficiently and cost-effectively', 'Forecast Repair Needs: Develop models to predict future repair & maintenance needs based on historical data and trends', 'Automate Quality Assurance: Create models to evaluate the quality of repairs and ensure they meet our high standards', 'Formulate the strategic and tactical steps to carry out the model development lifecycle end-to-end (i.e. problem statement definition, exploratory data analysis, feature engineering, model development / tuning, and model implementation)', 'Build and maintain descriptive, predictive, and prescriptive models to measure the performance of the new products and services', 'Cross validating production models to ensure high performance and generalizability', 'Define and implement best practices to generate accurate analytics, reports, visualizations, and dashboards to explain results simply and succinctly to technical, non-technical, and senior management', 'Build partnerships and work cross-functionally to identify use cases and opportunities to enhance operational efficiency and drive business value through positive impact on OKRs', 'Work with an owner mentality to drive business impact even if that means supporting pipeline creation or decision support analytics', 'Serve as a voice on how technological advancements in AI and machine learning may impact our business and the opportunities they may create', 'Provide technical leadership to more junior Data Scientist team members']",True,['Large Language Models'],"Large Language Models: Implement sophisticated LLMs to make intelligent repair routing decisions, ensuring repairs are conducted efficiently and cost-effectively.","['Machine Vision', 'Large Language Models', 'Predictive Modeling', 'Quality Assurance Modeling', 'Model Development Lifecycle', 'Descriptive, Predictive, and Prescriptive Models', 'Cross Validation', 'Analytics and Visualization', 'SQL and Python', 'Statistical Analysis and Modeling']","Machine Vision: Utilize computer vision techniques to accurately detect and assess damage in real-time as part of damage management technology development.; Large Language Models: Implement sophisticated LLMs to make intelligent repair routing decisions, ensuring repairs are conducted efficiently and cost-effectively.; Predictive Modeling: Develop models to forecast future repair and maintenance needs based on historical data and trends.; Quality Assurance Modeling: Create models to evaluate the quality of repairs and ensure they meet high standards.; Model Development Lifecycle: Formulate strategic and tactical steps for end-to-end model development including problem statement definition, exploratory data analysis, feature engineering, model development, tuning, and implementation.; Descriptive, Predictive, and Prescriptive Models: Build and maintain models to measure the performance of new products and services.; Cross Validation: Apply cross validation techniques to production models to ensure high performance and generalizability.; Analytics and Visualization: Define and implement best practices to generate accurate analytics, reports, visualizations, and dashboards to communicate results effectively to technical and non-technical stakeholders.; SQL and Python: Use data querying languages like SQL and scripting languages such as Python for data manipulation and analysis.; Statistical Analysis and Modeling: Apply statistical analysis and modeling techniques to support machine learning and data science initiatives."
adtj_7QRa5DaMfKcAAAAAA==,"Principal, Data Scientist - Converse","Position Summary...

What you'll do...

We are looking for an experiencedPrincipal Data Scientist to join our emerging tech team. At Walmart Global Tech, we are leading the way in revolutionizing retail throughadvanced technology and data science. Our team of experts is committed to solving current supply chain challenges and conducting research and development to create models thataddress the future requirements of our complex omni-channel international business.

About Team:
Cortex Team is Walmarts core A.I. conversational platform, powering the vision of delivering the worlds best personal assistants to Walmarts customers, accessible via natural voice commands, text messages, rich UI interactions, and a mix of all of the above via multi-modal experiences. We believe /conversations/ are a natural and powerful user interface for interacting with technology and enable a richer customer experience -- both online and in-store. We are building and designing the next generation of Natural Language Understanding (NLU) services that other teams can easily integrate and leverage, and build rich experiences: from pure voice and text shopping assistants (Siri, [[https://tech.walmart.com/content/walmart-global-tech/en_us/blog/post/walmart-is-building-a-genai-powered-shopping-assistant.html][Sparky]]), to customer care channels, to mobile apps with rich, intertwined, multi-modal interaction modes ([[https://apps.apple.com/us/app/me-walmart/id1459898418][Me@Walmart]]).

Whatyou'lldo:

We need passionate and seasoned NLP data-scientists to help us improve and evolve our capabilities, considering the full conversational context, multi-modal interactions, and an ever-increasing list of use cases. Come at the right time, and you will have an enormous opportunity to make a massive impact on the design, architecture, and implementation of an innovative, mission critical product, driven by data-science, used every day, by people you know, and which customers love. As part of the emerging tech group, you will also have the additional opportunity of building demos, proof of concepts, creating white papers, writing blogs, etc.

Whatyou'llbring:
• Proficient in Python; solid knowledge of SQL
• Hands on experience with classical ML models, test/train/evaluation metrics, key parameters/techniques that affect model performance
• Understanding of relevant statistical measures such as confidence intervals, significance of error measurements, development and evaluation data sets
• Familiar with NLU/NLP, more recent deep ML models (e.g., Transformers, BERT, Llama, Gpts, Gemini) including safe fine-tuning of these
• Ability to communicate with model consumers and present results intuitively
• Experience in identifying patterns, conducting error/ deviation analysis, and optimizing data representation
• Bachelors degree or certification in Machine Learning, Computer Science, Engineering, Mathematics, Statistics or any other related field

Preferred Qualifications:
• Exposure to real-world, production grade agentic systems
• Familiarity with LLMs serving optimizations and multi-Lo Ra
• Ability to develop experimental and analytic plans for data modeling processes, use of strong baselines, ability to accurately determine cause and effect relations
• Strong attention to detail and exceptional organizational skills
• Proven ability to achieve results in a fast paced, highly collaborative and dynamic work environment
• Hands-on expertise across the full model lifecycle, including data pipelines, extraction, model training, model serving, labeling tools, ML-ops and ad-hoc tooling.
• Ph D in a relevant field (Machine Learning, Computer Science, Engineering, Mathematics, Physics, Statistics or a related field)

About Walmart Global Tech

Imagine working where one line of code can make life easier for hundreds of millions of people. Thats what we do at Walmart Global Tech. Were a team of software engineers, data scientists, cybersecurity experts and service professionals within the worlds leading retailer who make epic impact and are leading the next retail disruption. People are why we innovate, and people power our innovations.

Who We Are:

Join Walmart and your work could help approximately 220 million global customers live better every week. Yes, we are the Fortune #1 company. But you'll quickly find were a company who wants you to feel comfortable bringing your whole self to work. Our mission spreads far beyond the walls of our stores. Here at the worlds leading retailer, you can make career defining accomplishments, learn new skills, gain experience from virtually every industry and leverage your expertise to innovate at scale, impact millions and reimagine the future of retail. Discover why we are a world leader in technology, culture of belonging, sustainability and community involvement. careers.walmart.com.

Equal Opportunity Employer:

Walmart, Inc. is an Equal Opportunity Employer By Choice. We believe we are best equipped to help our associates, customers, and the communities we serve live better when we really know them. That means understanding, respecting, and valuing unique styles, experiences, identities, ideas, and opinions while being welcoming of all people.

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

‎

‎

‎
You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.

‎

For information about PTO, see https://one.walmart.com/notices.

‎

‎
Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

‎
Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

‎

For information about benefits and eligibility, see One.Walmart.

‎
The annual salary range for this position is $143,000.00-$286,000.00

‎
Additional compensation includes annual or quarterly performance bonuses.

‎
Additional compensation for certain positions may also include:

‎

‎
- Stock

‎

‎

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 5 years' experience in an analytics related field. Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 3 years' experience in an analytics related field. Option 3: 7 years' experience in an analytics or related field

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data science, machine learning, optimization models, PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Publications or active peer reviewer in related journals or conference, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.

Primary Location...

680 West California Avenue, Sunnyvale, CA 94086-4834, United States of America",2025-07-22T00:00:00.000Z,2025-07-25,"['Proficient in Python; solid knowledge of SQL', 'Hands on experience with classical ML models, test/train/evaluation metrics, key parameters/techniques that affect model performance', 'Understanding of relevant statistical measures such as confidence intervals, significance of error measurements, development and evaluation data sets', 'Familiar with NLU/NLP, more recent deep ML models (e.g., Transformers, BERT, Llama, Gpts, Gemini) including safe fine-tuning of these', 'Ability to communicate with model consumers and present results intuitively', 'Experience in identifying patterns, conducting error/ deviation analysis, and optimizing data representation', 'Bachelors degree or certification in Machine Learning, Computer Science, Engineering, Mathematics, Statistics or any other related field', 'That means understanding, respecting, and valuing unique styles, experiences, identities, ideas, and opinions while being welcoming of all people', ""Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 5 years' experience in an analytics related field"", ""Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 3 years' experience in an analytics related field"", ""Option 3: 7 years' experience in an analytics or related field"", 'Data science, machine learning, optimization models, PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Publications or active peer reviewer in related journals or conference, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly', 'The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture']","['Come at the right time, and you will have an enormous opportunity to make a massive impact on the design, architecture, and implementation of an innovative, mission critical product, driven by data-science, used every day, by people you know, and which customers love', 'As part of the emerging tech group, you will also have the additional opportunity of building demos, proof of concepts, creating white papers, writing blogs, etc']",True,"['Transformers', 'Large Language Models (LLMs)', 'Generative AI', 'Fine-tuning of LLMs', 'Agentic Systems']","Transformers: Familiarity with recent deep learning models based on transformer architectures used for advanced NLP tasks within conversational AI systems.; Large Language Models (LLMs): Experience working with large language models such as BERT, LLaMA, GPTs, and Gemini, including safe fine-tuning and serving optimizations for production conversational agents.; Generative AI: Involvement in building generative AI-powered conversational platforms and shopping assistants that leverage natural voice commands, text, and multi-modal interactions.; Fine-tuning of LLMs: Ability to safely fine-tune large language models to adapt them for specific conversational use cases and improve performance.; Agentic Systems: Exposure to real-world, production-grade autonomous agent systems that power conversational AI and multi-modal user experiences.","['Python', 'SQL', 'Classical Machine Learning Models', 'Statistical Measures', 'Natural Language Understanding (NLU) and Natural Language Processing (NLP)', 'Data Pattern Identification and Error Analysis', 'Data Pipelines and Model Lifecycle', 'Open Source Frameworks for Machine Learning', 'Optimization Models', 'Spark, Scala, R']","Python: Required proficiency in Python programming language for data science tasks and model development.; SQL: Solid knowledge of SQL for data querying and manipulation.; Classical Machine Learning Models: Hands-on experience with traditional machine learning models including training, testing, evaluation metrics, and tuning key parameters to optimize model performance.; Statistical Measures: Understanding of statistical concepts such as confidence intervals, significance of error measurements, and development and evaluation of datasets to assess model quality.; Natural Language Understanding (NLU) and Natural Language Processing (NLP): Familiarity with NLU/NLP techniques to improve conversational AI capabilities, including handling multi-modal interactions and contextual understanding.; Data Pattern Identification and Error Analysis: Experience in identifying data patterns, conducting error and deviation analysis, and optimizing data representation to enhance model accuracy and reliability.; Data Pipelines and Model Lifecycle: Hands-on expertise across the full model lifecycle including data extraction, data pipelines, model training, model serving, labeling tools, and ML-ops for production-grade deployment.; Open Source Frameworks for Machine Learning: Experience using open source frameworks such as scikit-learn, TensorFlow, and PyTorch for building and deploying machine learning models.; Optimization Models: Knowledge and application of optimization models to solve complex business problems and improve operational efficiency.; Spark, Scala, R: Experience or successful completion of assessments in big data and analytics tools such as Apache Spark, Scala, and R."
D4HPJ8yoWAUX3-1AAAAAAA==,"Data Scientist / Senior Data Scientist, Analytics","About the Team

The Analytics team is looking for experienced Data Scientists and Senior Data Scientists to guide measurement, strategy, and tactical decision-making across the company across a variety of teams and levels. Data Scientists at DoorDash work to uncover insights and turn them into relevant recommendations, driving decisions for the entire organization. Analytics is integral to all operational areas at DoorDash.

Please apply here for all non-managerial levels within the following analytics teams:
• Consumer & Growth
• Business Operations
• Dasher & Logistics
• Customer Experience & Integrity
• Merchant, Ads & Sales
• New Verticals
• International Data Science

About the Role

As a Data Scientist at DoorDash, you'll use your quantitative background to mentor other scientists and dive into large datasets to guide decision-making. We solve a multitude of exciting challenges including customer acquisition, fraud and support, marketing, balancing supply and demand, new city launches, marketplace efficiency, and more. If you enjoy finding patterns amidst chaos, and have experience using analytics to affect revenue, growth, operations or beyond, we're looking for someone like you!

You're excited about this opportunity because you will…
• Use quantitative analysis and the presentation of data to see beyond the numbers and understand what drives our business
• Build full-cycle analytics experiments, reports, and dashboards using SQL, R, Python, or other scripting and statistical tools
• Work with and mentor junior analysts on how to use more advanced methods and solve challenges
• Produce recommendations and use statistical techniques and hypothesis testing to validate your findings
• Provide insights to help business and product leaders understand marketplace dynamics, user behaviors, and long-term trends
• Identify and measure levers to help move essential metrics and make recommendations
• Work backwards from understanding and sizing problems to ideating solutions
• Report against our goals by identifying essential metrics and building executive-facing dashboards to track progress
• Collaborate with engineering to implement, document, validate, and monitor our logging

We're excited about you because you have…
• A degree in Math, Physics, Statistics, Economics, Computer Science, or a similar domain
• 2+ years of experience in data analytics, consulting, or related role
• Experience working with funnel optimization, user segmentation, cohort analyses, time series analyses, regression models, etc
• Expertise of SQL queries, ETL, A/B Testing, and statistical analysis (e.g. hypothesis testing, experimentation, regressions) with statistical packages, such as Matlab, R, SAS or Python
• Proficiency in one or more analytics & visualization tools (e.g. Chartio, Looker, Tableau)
• The insight to take ambiguous problems and solve them in a structured, hypothesis-driven, data-supported way

Notice to Applicants for Jobs Located in NYC or Remote Jobs Associated With Office in NYC Only

We use Covey as part of our hiring and/or promotional process for jobs in NYC and certain features may qualify it as an AEDT in NYC. As part of the hiring and/or promotion process, we provide Covey with job requirements and candidate submitted applications. We began using Covey Scout for Inbound from August 21, 2023, through December 21, 2023, and resumed using Covey Scout for Inbound again on June 29, 2024.

The Covey tool has been reviewed by an independent auditor. Results of the audit may be viewed here: Covey

About DoorDash

At DoorDash, our mission to empower local economies shapes how our team members move quickly, learn, and reiterate in order to make impactful decisions that display empathy for our range of users—from Dashers to merchant partners to consumers. We are a technology and logistics company that started with door-to-door delivery, and we are looking for team members who can help us go from a company that is known for delivering food to a company that people turn to for any and all goods.

DoorDash is growing rapidly and changing constantly, which gives our team members the opportunity to share their unique perspectives, solve new challenges, and own their careers. We're committed to supporting employees' happiness, healthiness, and overall well-being by providing comprehensive benefits and perks including premium healthcare, wellness expense reimbursement, paid parental leave and more.

Our Commitment to Diversity and Inclusion

We're committed to growing and empowering a more inclusive community within our company, industry, and cities. That's why we hire and cultivate diverse teams of people from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunity to excel.

Statement of Non-Discrimination: In keeping with our beliefs and goals, no employee or applicant will face discrimination or harassment based on: race, color, ancestry, national origin, religion, age, gender, marital/domestic partner status, sexual orientation, gender identity or expression, disability status, or veteran status. Above and beyond discrimination and harassment based on ""protected categories,"" we also strive to prevent other subtler forms of inappropriate behavior (i.e., stereotyping) from ever gaining a foothold in our office. Whether blatant or hidden, barriers to success have no place at DoorDash. We value a diverse workforce – people who identify as women, non-binary or gender non-conforming, LGBTQIA+, American Indian or Native Alaskan, Black or African American, Hispanic or Latinx, Native Hawaiian or Other Pacific Islander, differently-abled, caretakers and parents, and veterans are strongly encouraged to apply. Thank you to the Level Playing Field Institute for this statement of non-discrimination.

Pursuant to the San Francisco Fair Chance Ordinance, Los Angeles Fair Chance Initiative for Hiring Ordinance, and any other state or local hiring regulations, we will consider for employment any qualified applicant, including those with arrest and conviction records, in a manner consistent with the applicable regulation.

If you need any accommodations, please inform your recruiting contact upon initial connection.",,2025-07-25,"['Build full-cycle analytics experiments, reports, and dashboards using SQL, R, Python, or other scripting and statistical tools', 'A degree in Math, Physics, Statistics, Economics, Computer Science, or a similar domain', '2+ years of experience in data analytics, consulting, or related role', 'Experience working with funnel optimization, user segmentation, cohort analyses, time series analyses, regression models, etc', 'Expertise of SQL queries, ETL, A/B Testing, and statistical analysis (e.g. hypothesis testing, experimentation, regressions) with statistical packages, such as Matlab, R, SAS or Python', 'Proficiency in one or more analytics & visualization tools (e.g. Chartio, Looker, Tableau)', 'The insight to take ambiguous problems and solve them in a structured, hypothesis-driven, data-supported way', 'Notice to Applicants for Jobs Located in NYC or Remote Jobs Associated With Office in NYC Only']","[""As a Data Scientist at DoorDash, you'll use your quantitative background to mentor other scientists and dive into large datasets to guide decision-making"", 'We solve a multitude of exciting challenges including customer acquisition, fraud and support, marketing, balancing supply and demand, new city launches, marketplace efficiency, and more', 'Use quantitative analysis and the presentation of data to see beyond the numbers and understand what drives our business', 'Work with and mentor junior analysts on how to use more advanced methods and solve challenges', 'Produce recommendations and use statistical techniques and hypothesis testing to validate your findings', 'Provide insights to help business and product leaders understand marketplace dynamics, user behaviors, and long-term trends', 'Identify and measure levers to help move essential metrics and make recommendations', 'Work backwards from understanding and sizing problems to ideating solutions', 'Report against our goals by identifying essential metrics and building executive-facing dashboards to track progress', 'Collaborate with engineering to implement, document, validate, and monitor our logging']",True,[],,"['SQL', 'R', 'Python', 'Regression Models', 'Time Series Analysis', 'A/B Testing', 'Statistical Analysis', 'ETL (Extract, Transform, Load)', 'Funnel Optimization', 'User Segmentation', 'Cohort Analysis', 'Statistical Packages (Matlab, R, SAS)', 'Analytics & Visualization Tools (Chartio, Looker, Tableau)']","SQL: Used to build full-cycle analytics experiments, reports, and dashboards, and to perform queries for data analysis and decision-making.; R: Utilized as a statistical tool and scripting language for building analytics experiments, performing statistical analysis, and mentoring junior analysts.; Python: Employed for scripting, statistical analysis, building analytics experiments, and mentoring junior analysts in advanced methods.; Regression Models: Applied to analyze data patterns and support hypothesis testing and experimentation for business insights.; Time Series Analysis: Used to analyze trends over time to understand long-term user behaviors and marketplace dynamics.; A/B Testing: Implemented as a statistical technique to validate findings and optimize business metrics through experimentation.; Statistical Analysis: Includes hypothesis testing, experimentation, and regressions to produce validated recommendations and insights.; ETL (Extract, Transform, Load): Expertise required to manage data pipelines and prepare data for analysis and reporting.; Funnel Optimization: Experience in analyzing and improving user conversion funnels to drive growth and operational efficiency.; User Segmentation: Used to categorize users into meaningful groups for targeted analysis and strategy development.; Cohort Analysis: Applied to study user behavior and trends across defined groups over time to inform business decisions.; Statistical Packages (Matlab, R, SAS): Used for advanced statistical analysis and experimentation to support data-driven decision-making.; Analytics & Visualization Tools (Chartio, Looker, Tableau): Proficiency in these tools is required to create dashboards and reports that track essential business metrics and communicate insights."
J2E6bP-FHYgAVybHAAAAAA==,Senior Data Analyst (NSWC-Dahlgren),"Responsibilities

Sabre Systems is seeking a Senior Data Analyst to join our team in support of the Naval Surface Warfare Center Dahlgren Division (NSWCDD) in Dahlgren, VA. This role plays a critical part in NSWCDD’s strategic initiative to modernize, optimize, and simplify its IT infrastructure while advancing IT Service Management (ITSM) practices to deliver measurable, mission-focused outcomes.

This initiative not only includes the continued operation and maintenance of the existing IT environment but also emphasizes digital transformation, information management, infrastructure engineering, and the implementation of modern development, deployment, and automation technologies. The selected candidate will be essential to enhancing IT service delivery and ensuring efficient, customer-focused support in a dynamic and evolving environment.

Responsibilities include but are not limited to:
• Applies mathematics, statistics, predictive modelling and machine learning techniques to discover meaningful patterns and knowledge in recorded data
• Develops definition and application designs in the form of logical data models, data interface specifications, on-line query, and reports specifications
• Uses structured query languages (SQL)
• Presents findings and data insights in creative ways to facilitate the understanding of data across a range of technical and non-technical audiences
• Identifies, validates, and exploits internal and external data sets generated from a diverse range of processes
• Manages data and information in all its forms and the analysis of information structure (including logical analysis of taxonomies, data and metadata)

Qualifications

Qualifications:
• Bachelor’s degree in a business-related field from an accredited college or university
• Minimum of six (6) years of professional experience in relation to analysis, design, and development related to data warehousing and integration capabilities.
• Experience with help desk tools, such as ServiceNow
• Experience with requirements developing definition and application designs in the form of logical data models, data interface specifications, on-line query and report specifications, structured query language (SQL), database performance loading specifications, and data validation specifications.
• Experience with data warehouse development and design, data knowledge acquisition, legacy conversion specifications and design of data structures/load specifications, and knowledge of Working Capital Fund and Enterprise Resource Planning (ERP), financial, and human resources systems methods and strategies for data warehousing.
• Advanced proficiency in Cybersecurity Workforce (CWF) to focuses on building, managing, and operationalizing data pipelines.
• Must be a U.S. Citizen with an active DoD Secret clearance or higher
• Must be available to work onsite in Dahlgren, VA daily
• This position is contingent upon contract award and/or customer approval.

#LI-EN1

Compensation

Senior Level: At Sabre Systems, LLC, compensation is based on factors such as location, qualifications, experience, and contract-specific requirements. The general salary range for this position is $70,000-$200,000; however, final compensation will be determined by individual qualifications and applicable contract terms.

Sabre Overview

Sabre Systems, LLC, has been providing innovative technological solutions and services for Department of Defense, Federal Civilian, and commercial customers for more than 35 years. We support the ever-evolving areas of advanced communication technologies, cyber, systems and software engineering, and digital transformation.

With over three decades in business, Sabre Systems, LLC remains committed to our small business values and a people-first philosophy. We foster a welcoming, inclusive culture that values diverse perspectives and encourages open communication. Our collaborative environment supports continuous learning and professional growth at all levels. We prioritize the health, well-being, and success of our employees, offering comprehensive, evolving benefits designed to meet their diverse needs. Join us and be part of a thriving, people-driven culture.

We respect the unique perspectives that a diverse workforce of minorities, women, individuals with disabilities, and protected veterans brings not only to our company, but also to our customers. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex (including pregnancy, gender identity and sexual orientation), national origin, age, disability or genetic information.

EOE Minorities/Females/Disability/Veterans; VEVRAA Federal Contractor

Beware of employment scams—Sabre Systems will never request payment, extend offers without an interview, or contact you from an email that doesn’t end in @sabresystems.com; always apply directly at https://careers.sabresystems.com/.
Qualifications:

Qualifications:
• Bachelor’s degree in a business-related field from an accredited college or university
• Minimum of six (6) years of professional experience in relation to analysis, design, and development related to data warehousing and integration capabilities.
• Experience with help desk tools, such as ServiceNow
• Experience with requirements developing definition and application designs in the form of logical data models, data interface specifications, on-line query and report specifications, structured query language (SQL), database performance loading specifications, and data validation specifications.
• Experience with data warehouse development and design, data knowledge acquisition, legacy conversion specifications and design of data structures/load specifications, and knowledge of Working Capital Fund and Enterprise Resource Planning (ERP), financial, and human resources systems methods and strategies for data warehousing.
• Advanced proficiency in Cybersecurity Workforce (CWF) to focuses on building, managing, and operationalizing data pipelines.
• Must be a U.S. Citizen with an active DoD Secret clearance or higher
• Must be available to work onsite in Dahlgren, VA daily
• This position is contingent upon contract award and/or customer approval.

#LI-EN1
Education:UNAVAILABLEEmployment Type: FULL_TIME",2025-07-14T00:00:00.000Z,2025-07-25,"['Bachelor’s degree in a business-related field from an accredited college or university', 'Minimum of six (6) years of professional experience in relation to analysis, design, and development related to data warehousing and integration capabilities', 'Experience with help desk tools, such as ServiceNow', 'Experience with requirements developing definition and application designs in the form of logical data models, data interface specifications, on-line query and report specifications, structured query language (SQL), database performance loading specifications, and data validation specifications', 'Experience with data warehouse development and design, data knowledge acquisition, legacy conversion specifications and design of data structures/load specifications, and knowledge of Working Capital Fund and Enterprise Resource Planning (ERP), financial, and human resources systems methods and strategies for data warehousing', 'Advanced proficiency in Cybersecurity Workforce (CWF) to focuses on building, managing, and operationalizing data pipelines', 'Must be a U.S. Citizen with an active DoD Secret clearance or higher', 'Must be available to work onsite in Dahlgren, VA daily', 'This position is contingent upon contract award and/or customer approval', 'Bachelor’s degree in a business-related field from an accredited college or university', 'Minimum of six (6) years of professional experience in relation to analysis, design, and development related to data warehousing and integration capabilities', 'Experience with help desk tools, such as ServiceNow', 'Experience with requirements developing definition and application designs in the form of logical data models, data interface specifications, on-line query and report specifications, structured query language (SQL), database performance loading specifications, and data validation specifications', 'Experience with data warehouse development and design, data knowledge acquisition, legacy conversion specifications and design of data structures/load specifications, and knowledge of Working Capital Fund and Enterprise Resource Planning (ERP), financial, and human resources systems methods and strategies for data warehousing', 'Advanced proficiency in Cybersecurity Workforce (CWF) to focuses on building, managing, and operationalizing data pipelines', 'Must be a U.S. Citizen with an active DoD Secret clearance or higher', 'Must be available to work onsite in Dahlgren, VA daily', 'This position is contingent upon contract award and/or customer approval']","['Sabre Systems is seeking a Senior Data Analyst to join our team in support of the Naval Surface Warfare Center Dahlgren Division (NSWCDD) in Dahlgren, VA', 'This role plays a critical part in NSWCDD’s strategic initiative to modernize, optimize, and simplify its IT infrastructure while advancing IT Service Management (ITSM) practices to deliver measurable, mission-focused outcomes', 'This initiative not only includes the continued operation and maintenance of the existing IT environment but also emphasizes digital transformation, information management, infrastructure engineering, and the implementation of modern development, deployment, and automation technologies', 'The selected candidate will be essential to enhancing IT service delivery and ensuring efficient, customer-focused support in a dynamic and evolving environment', 'Applies mathematics, statistics, predictive modelling and machine learning techniques to discover meaningful patterns and knowledge in recorded data', 'Develops definition and application designs in the form of logical data models, data interface specifications, on-line query, and reports specifications', 'Uses structured query languages (SQL)', 'Presents findings and data insights in creative ways to facilitate the understanding of data across a range of technical and non-technical audiences', 'Identifies, validates, and exploits internal and external data sets generated from a diverse range of processes', 'Manages data and information in all its forms and the analysis of information structure (including logical analysis of taxonomies, data and metadata)']",True,[],,"['Predictive Modeling', 'Machine Learning', 'Mathematics and Statistics', 'Logical Data Models', 'Data Interface Specifications', 'Online Query and Report Specifications', 'Structured Query Language (SQL)', 'Data Presentation and Visualization', 'Data Identification and Validation', 'Data and Metadata Management', 'Data Warehousing and Integration', 'Help Desk Tools (ServiceNow)', 'Database Performance and Loading Specifications', 'Legacy Data Conversion and Data Structure Design', 'Enterprise Resource Planning (ERP) Systems Knowledge', 'Data Pipelines']","Predictive Modeling: Uses predictive modeling techniques to discover meaningful patterns and knowledge in recorded data.; Machine Learning: Applies machine learning techniques to analyze data and extract insights.; Mathematics and Statistics: Utilizes mathematics and statistics to support data analysis and pattern discovery.; Logical Data Models: Develops logical data models as part of definition and application design to structure data effectively.; Data Interface Specifications: Creates data interface specifications to define how data is exchanged and integrated.; Online Query and Report Specifications: Designs on-line query and report specifications to facilitate data retrieval and presentation.; Structured Query Language (SQL): Uses SQL for querying databases and managing data.; Data Presentation and Visualization: Presents findings and data insights creatively to facilitate understanding across technical and non-technical audiences.; Data Identification and Validation: Identifies, validates, and exploits internal and external data sets from diverse processes.; Data and Metadata Management: Manages data and information in all forms, including analysis of information structure such as taxonomies, data, and metadata.; Data Warehousing and Integration: Experienced in analysis, design, and development related to data warehousing and integration capabilities.; Help Desk Tools (ServiceNow): Experience with help desk tools like ServiceNow to support IT service management.; Database Performance and Loading Specifications: Develops database performance loading specifications and data validation specifications to ensure efficient data processing.; Legacy Data Conversion and Data Structure Design: Designs legacy conversion specifications and data structures/load specifications for data warehousing.; Enterprise Resource Planning (ERP) Systems Knowledge: Knowledge of ERP, financial, and human resources systems methods and strategies for data warehousing.; Data Pipelines: Builds, manages, and operationalizes data pipelines, with advanced proficiency in Cybersecurity Workforce (CWF) context."
Se3xX3nIzCVGQVCxAAAAAA==,Senior Data Analyst,"Join or sign in to find your next job Join to apply for the Senior Data Analyst role at Circle Join to apply for the Senior Data Analyst role at Circle Circle is a financial technology company at the epicenter of the emerging internet of money, where value can finally travel like other digital data — globally, nearly instantly and less expensively than legacy settlement systems. This ground-breaking new internet layer opens up previously unimaginable possibilities for payments, commerce and markets that can help raise global economic prosperity and enhance inclusion. Our infrastructure – including USDC, a blockchain-based dollar – helps businesses, institutions and developers harness these breakthroughs and capitalize on this major turning point in the evolution of money and technology. What You’ll Be Part Of Circle is committed to visibility and stability in everything we do. As we grow as an organization, we're expanding into some of the world's strongest jurisdictions. Speed and efficiency are motivators for our success and our employees live by our company values: High Integrity, Future Forward, Multistakeholder, Mindful, and Driven by Excellence. We have built a flexible and diverse work environment where new ideas are encouraged and everyone is a stakeholder. What You’ll Be Responsible For As a Data Analyst at Circle, you’ll work closely with business partners to better understand our products, better understand the ecosystem, and enable better decision-making with data. We are a passionate team with a deeply analytical approach and your work will support our mission to be a world-class company driven by data. If you are curious about data, enjoy deriving insights, have experience improving data insights, and are motivated by impacting business, we want to hear from you. What You'll Work On Partner with the business by translating the business needs to design and develop core tables, build dashboards, define metrics, conduct ad hoc analyses, and do deep dive investigations to create situational awareness and derive insights Perform strategic analysis and research to identify new opportunities where business can be improved Create data visualizations to translate analytic results for broad understanding across the business Build scalable automation solutions using SQL, dashboards, and other tools to create leverage for yourself and the organization Partner with leaders effectively employing clear and structured communication to tell a “story” focused on business insights & data Develop strategic problem-solving, quantitative analytics, and communication skills What You'll Bring To Circle Senior Data Analyst (III) 4+ years of industry experience in data analytics Bachelor’s Degree or equivalent experience in a quantitative major (Finance, Accounting, Economics, Mathematics, Engineering) Strong analytical and data skills, including top notch SQL skills. Ideally (but not necessary to apply), you will also be able to build simple pipelines to help scale yourself Good communication skills - be able partner across the organization and identify business needs and difficulties, articulate issues clearly and concisely, and present effectively in both oral and written presentations to all levels in the organization Strong business sense and the ability to work through complex and ambiguous business requirements Self-starter - an entrepreneurial spirit that thrives in a fast-paced environment, deals well with ambiguity and focuses on driving impact Prior experience with visualization using Superset, Tableau or similar BI tools Expert in data analyses using SQL Basic understanding of Python is an added advantage Good understanding of statistics and experience applying them to solve business problems Domain experience in one of the following areas: financial services, business banking, product analytics, marketing, crypto ecosystem, or risk analytics Lead Data Analyst (IV) Includes All Senior Data Analyst Requirements, Plus 8+ years of industry experience in data analytics Deep understanding of statistics and experience applying them to solve business problems Circle is on a mission to create an inclusive financial future, with transparency at our core. We consider a wide variety of elements when crafting our compensation ranges and total compensation packages. Starting pay is determined by various factors, including but not limited to: relevant experience, skill set, qualifications, and other business and organizational needs. Please note that compensation ranges may differ for candidates in other locations. Base Pay Range Senior Data Analyst: $122,500 - $162,500 Lead Data Analyst: $145,000 - $192,500 We are an equal opportunity employer and value diversity at Circle. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. Additionally, Circle participates in the E-Verify Program in certain locations, as required by law. Should you require accommodations or assistance in our interview process because of a disability, please reach out to accommodations@circle.com for support. We respect your privacy and will connect with you separately from our interview process to accommodate your needs. Seniority level Seniority level Mid-Senior level Employment type Employment type Full-time Job function Job function Information Technology Referrals increase your chances of interviewing at Circle by 2x Get notified about new Senior Data Analyst jobs in Portland, Oregon Metropolitan Area . Senior Business Analyst - Operations (Remote) Business Analyst I (User Subject Matter Expert) Portland, OR $59,562.00-$89,057.00 4 months ago Business Intelligence Analyst (System Application Analyst) We’re unlocking community knowledge in a new way. Experts add insights directly into each article, started with the help of AI. #J-18808-Ljbffr",2025-07-22T00:00:00.000Z,2025-07-25,,,True,[],,"['SQL', 'Data Visualization Tools', 'Statistics', 'Data Pipelines', 'Quantitative Analytics']","SQL: Used extensively for data analysis, building scalable automation solutions, and creating core tables to support business decision-making.; Data Visualization Tools: Experience with tools like Superset and Tableau to create visualizations that translate analytic results for broad understanding across the business.; Statistics: Applied to solve business problems and perform strategic analysis and research to identify new business opportunities.; Data Pipelines: Ability to build simple pipelines to help scale data analysis efforts and automate processes.; Quantitative Analytics: Used to develop strategic problem-solving skills and derive insights from data to impact business decisions."
82c7Q47tRU65uhP7AAAAAA==,Senior Data Analyst,"Visa is hiring a Senior Data Analyst with 5 - 10 years of experience. Based in United States - Foster City, CA and with Hybrid ways of working.

Job description and responsibilities:

The Sr. Data Analyst will be responsible for leading the data analysis function end-to-end (from requirements to report/dashboard delivery) for the Reimage Work (RW) Portfolio Reporting Automation effort. This includes upfront requirements gathering, followed by detailed data analysis, identification of data sources, creating of Entity-Relationship Diagrams, as well as metrics calculations. In addition, this position will also liaison with the Enterprise Architect, as well as various teams involved (UX Design, Data Hub buildout, Analytics), and will interact with a wide range of stakeholders both within Technology and also with cross-functional teams (Transformation Office, Finance, Product, Legal, HR, and Regulatory). This position will report to the Sr. Director of Technology Strategic Initiatives. Responsibilities Lead all aspects of the Reimagine Work (RW) Portfolio Reporting Automation data analysis function. Lead problem solving sessions to develop analytical solutions which help product & technology leaders to make data driven decisions Lead reporting automation requirements gathering for report/dashboard automation Drive detailed data analysis including the identification of data sources and data elements, creating of Entity-Relationship Diagrams, as well as detailed metrics calculations Support other allied architecture and integration activities. Assist in developing documentation around system integration, data flows, data dictionary, user guides and best practices. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, evaluating our infrastructure for greater scalability, etc. Obtain data steward approvals for data access for various data sources, and help establish connectivity of data sources with the data warehouse and data lake Support the creation of UX wireframes as well as the actual reports and dashboards and perform appropriate quality checks to ensure accuracy Lead other ad-hoc business management initiatives as needed.

This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office two days a week, Tuesdays and Wednesdays with a general guidepost of being in the office 50% of the time based on business needs.

Travel Requirements: This position requires travel 5-10% of the time.

Requirements and qualifications:
• 5 or more years of relevant work experience with a Bachelors Degree or at least 2 years of work experience with an Advanced degree (e.g. Masters, MBA, JD, MD) or 0 years of work experience with a PhD Preferred Qualifications
• 6 or more years of work experience with a Bachelors Degree or 4 or more years of relevant experience with an Advanced Degree (e.g. Masters, MBA, JD, MD) or up to 3 years of relevant experience with a PhD
• The ideal candidate would demonstrate a blend of a data analysis / process improvement skillset, with a management consulting background, transformation program experience, and a bias for action.
• 7-10 years of work experience in the data management space, driving data analysis for complex, cross-functional programs, experience in financial / Banking, Management Consulting, and/or technology industries a plus but not required.
• Advanced working knowledge and experience in SQL and relational databases. Experience with MS-SQL & data virtualization technologies like Denodo would be plus.
• Excellent verbal, written, and presentation skills. In particular, a demonstrated ability to effectively communicate technical and business issues and/or solutions to multiple organizational levels internally and externally as needed.
• Solid analytical and problem-solving skills, ability to think strategically and drive decision making.
• Ability to work independently with strong time management and ability to execute on multiple concurrent deliverables
• Demonstrated ability to manage through influence, but without direct management authority.",,2025-07-25,"['6 or more years of work experience with a Bachelors Degree or 4 or more years of relevant experience with an Advanced Degree (e.g. Masters, MBA, JD, MD) or up to 3 years of relevant experience with a PhD', 'The ideal candidate would demonstrate a blend of a data analysis / process improvement skillset, with a management consulting background, transformation program experience, and a bias for action', 'Advanced working knowledge and experience in SQL and relational databases', 'Experience with MS-SQL & data virtualization technologies like Denodo would be plus', 'Excellent verbal, written, and presentation skills', 'In particular, a demonstrated ability to effectively communicate technical and business issues and/or solutions to multiple organizational levels internally and externally as needed', 'Solid analytical and problem-solving skills, ability to think strategically and drive decision making', 'Ability to work independently with strong time management and ability to execute on multiple concurrent deliverables', 'Demonstrated ability to manage through influence, but without direct management authority']","['Data Analyst will be responsible for leading the data analysis function end-to-end (from requirements to report/dashboard delivery) for the Reimage Work (RW) Portfolio Reporting Automation effort', 'This includes upfront requirements gathering, followed by detailed data analysis, identification of data sources, creating of Entity-Relationship Diagrams, as well as metrics calculations', 'In addition, this position will also liaison with the Enterprise Architect, as well as various teams involved (UX Design, Data Hub buildout, Analytics), and will interact with a wide range of stakeholders both within Technology and also with cross-functional teams (Transformation Office, Finance, Product, Legal, HR, and Regulatory)', 'This position will report to the Sr', 'Director of Technology Strategic Initiatives', 'Responsibilities Lead all aspects of the Reimagine Work (RW) Portfolio Reporting Automation data analysis function', 'Lead problem solving sessions to develop analytical solutions which help product & technology leaders to make data driven decisions Lead reporting automation requirements gathering for report/dashboard automation Drive detailed data analysis including the identification of data sources and data elements, creating of Entity-Relationship Diagrams, as well as detailed metrics calculations Support other allied architecture and integration activities', 'Assist in developing documentation around system integration, data flows, data dictionary, user guides and best practices', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, evaluating our infrastructure for greater scalability, etc', 'Obtain data steward approvals for data access for various data sources, and help establish connectivity of data sources with the data warehouse and data lake Support the creation of UX wireframes as well as the actual reports and dashboards and perform appropriate quality checks to ensure accuracy Lead other ad-hoc business management initiatives as needed', 'Employees in hybrid roles are expected to work from the office two days a week, Tuesdays and Wednesdays with a general guidepost of being in the office 50% of the time based on business needs', 'Travel Requirements: This position requires travel 5-10% of the time']",True,[],,"['SQL', 'Relational Databases', 'Entity-Relationship Diagrams', 'Reporting Automation', 'Data Analysis', 'Data Pipelines', 'Data Dictionary', 'Process Improvement', 'Data Visualization and Dashboards', 'Data Stewardship', 'Data Virtualization']","SQL: Used extensively for querying and managing relational databases as part of data analysis and reporting automation efforts.; Relational Databases: Involved in identifying data sources and establishing connectivity with data warehouses and data lakes to support reporting and analytics.; Entity-Relationship Diagrams: Created to model data sources and data elements, supporting detailed data analysis and system integration documentation.; Reporting Automation: Leading requirements gathering and development of automated reports and dashboards to enable data-driven decision making.; Data Analysis: Conducting detailed analysis including metrics calculations and identification of data sources to support portfolio reporting and business initiatives.; Data Pipelines: Supporting architecture and integration activities to connect various data sources with data warehouses and data lakes for scalable data delivery.; Data Dictionary: Developing documentation to define data elements and support data governance and user understanding.; Process Improvement: Designing and implementing internal process improvements such as automating manual processes and optimizing data delivery infrastructure for scalability.; Data Visualization and Dashboards: Supporting creation of UX wireframes and actual reports/dashboards, including quality checks to ensure accuracy for stakeholders.; Data Stewardship: Obtaining approvals for data access and ensuring proper governance in data source connectivity and usage.; Data Virtualization: Experience with data virtualization technologies like Denodo to facilitate data access and integration across multiple sources."
tpeZ1K8W5U18X7saAAAAAA==,"Senior Data Analyst, Project Management","At CVS Health, we're building a world of health around every consumer and surrounding ourselves with dedicated colleagues who are passionate about transforming health care.As the nation's leading health solutions company, we reach millions of Americans through our local presence, digital channels and more than 300,000 purpose-driven colleagues - caring for people where, when and how they choose in a way that is uniquely more connected, more convenient and more compassionate. And we do it all with heart, each and every day.Position SummaryDevelops and manages program operations focused on improving clinical and financial outcomes, member engagement, and satisfaction.Develops strategies to mitigate high cost/high need utilization of services and assist members with assuming self-management of their conditions.Formulates and implements strategy for achieving applicable department/unit metrics and provides operational direction.Serves as technical, professional, and business resource (may cross multiple business functions).Directs/provides enhancements to business processes, policies, and infrastructure to improve operational efficiency (may cross multiple business functions).Develops, implements, and evaluates business analysis, which meet business needs (may cross multiple business functions).Creates reports needed to support business operations.Collaborates and partners with other business areas across/within regions or segments and within other centralized corporate areas to ensure all workflow processes and interdependencies are identified and addressed on an on-going basis.Promotes a clear vision aligned with company values and direction; sets specific challenging and achievable objectives and action plans; motivates others to balance customer needs and business success; challenges self and others to look to the future to create quality products, services, and solutions.Collaborates with licensed staff from other areas that assist with oversight of clinical staff and activities of licensed personnel.Support state-driven deliverablesRequired Qualifications5-7 years work experience in informatics/data analysis2+ years experience with execution and delivery (planning, delivering, and supporting)2+ years experience communicating in a highly effective manner with internal and external constituents in both written and oral format.2+ years experience evaluating and interpreting data for the purpose of developing new programs and processes to meet business demands (Quantitative and Qualitative analysis)2+ years experience synthesizing program performance and clinical outcomes.Adept at problem solving and decision making skillsAdept at collaboration and teamworkAdept at growth mindset (agility and developing yourself and others) skillsPreferred QualificationsLTSS, NCQA, and Managed Care experienceManaging QuickBase and PowerBIEducationBachelor's Degree RequiredAnticipated Weekly Hours40Time TypeFull timePay RangeThe typical pay range for this role is:$46,988.00 - $112,200.00This pay range represents the base hourly rate or base annual full-time salary for all positions in the job grade within which this position falls. The actual base salary offer will depend on a variety of factors including experience, education, geography and other relevant factors. This position is eligible for a CVS Health bonus, commission or short-term incentive program in addition to the base pay range listed above. Our people fuel our future. Our teams reflect the customers, patients, members and communities we serve and we are committed to fostering a workplace where every colleague feels valued and that they belong.Great benefits for great peopleWe take pride in our comprehensive and competitive mix of pay and benefits - investing in the physical, emotional and financial wellness of our colleagues and their families to help them be the healthiest they can be. In addition to our competitive wages, our great benefits include:Affordable medical plan options, a 401(k) plan (including matching company contributions), and an employee stock purchase plan.No-cost programs for all colleagues including wellness screenings, tobacco cessation and weight management programs, confidential counseling and financial coaching.Benefit solutions that address the different needs and preferences of our colleagues including paid time off, flexible work schedules, family leave, dependent care resources, colleague assistance programs, tuition assistance, retiree medical access and many other benefits depending on eligibility.For more information, visit https://jobs.cvshealth.com/us/en/benefitsWe anticipate the application window for this opening will close on: 04/28/2025Qualified applicants with arrest or conviction records will be considered for employment in accordance with all federal, state and local laws.",,2025-07-25,"['Support state-driven deliverablesRequired Qualifications5-7 years work experience in informatics/data analysis2+ years experience with execution and delivery (planning, delivering, and supporting)2+ years experience communicating in a highly effective manner with internal and external constituents in both written and oral format.2+ years experience evaluating and interpreting data for the purpose of developing new programs and processes to meet business demands (Quantitative and Qualitative analysis)2+ years experience synthesizing program performance and clinical outcomes', 'Adept at problem solving and decision making skills', 'Adept at collaboration and teamwork', 'Adept at growth mindset (agility and developing yourself and others) skills', ""Managing QuickBase and PowerBIEducationBachelor's Degree RequiredAnticipated Weekly Hours40Time TypeFull time""]","['Position SummaryDevelops and manages program operations focused on improving clinical and financial outcomes, member engagement, and satisfaction', 'Develops strategies to mitigate high cost/high need utilization of services and assist members with assuming self-management of their conditions', 'Formulates and implements strategy for achieving applicable department/unit metrics and provides operational direction', 'Serves as technical, professional, and business resource (may cross multiple business functions).Directs/provides enhancements to business processes, policies, and infrastructure to improve operational efficiency (may cross multiple business functions).Develops, implements, and evaluates business analysis, which meet business needs (may cross multiple business functions)', 'Creates reports needed to support business operations', 'Collaborates and partners with other business areas across/within regions or segments and within other centralized corporate areas to ensure all workflow processes and interdependencies are identified and addressed on an on-going basis', 'Promotes a clear vision aligned with company values and direction; sets specific challenging and achievable objectives and action plans; motivates others to balance customer needs and business success; challenges self and others to look to the future to create quality products, services, and solutions', 'Collaborates with licensed staff from other areas that assist with oversight of clinical staff and activities of licensed personnel']",False,,,,
QRaerQP-yQ4HsNzyAAAAAA==,Senior Data Analyst (multiple openings),"Job Location:

InnovAccer, Inc.101 Mission Street, Suite 1950, San Francisco, CA 94105 (travel to unanticipated client sites in U.S. and allows for telecommuting)

Job Duties

With a high level of independent decision-making capability and minimum supervision, the Senior Data Analyst will be responsible for the following job duties:
• Building complex data pipelines from different source to map to data warehouse schema;
• Performing ETL logic as per required by building complex data pipelines;
• Analyzing data and visualization using tools like Power BI or Tableau.
• Engaging with business and technical client teams to document and explain technical problems and concepts concisely;
• Leading junior engineer teams;
• Supporting customer incidents to resolutions;
• Working with relational database and AWS; and Engaging in SQL programming and writing on a fly query to complete complex data analysis.

This position requires travel to unanticipated client sites throughout the U.S and allows for telecommuting

Education:

U.S. Master’s degree or foreign equivalent in Bus Analytics, IS, CS, or closely related/equivalent.

Experience:

Three (3) years of experience as an App Dev/Data Analyst, or closely related.

Skills:
• Must have experience with:
• Data processing;
• Data analysis;
• Python;
• SQL;
• Git Version Control;
• Power BI or Tableau or Si-Sense;
• Linux/Unix or Powershell;
• IntelliJ, Pycharm, or DE Beaver;
• Agile or scrum methodology; and
• ML models

Contact:

Kimberly Saied, Director, People eXperience,

kimberley.saied@innovaccer.com",,2025-07-25,"['U.S. Master’s degree or foreign equivalent in Bus Analytics, IS, CS, or closely related/equivalent', 'Three (3) years of experience as an App Dev/Data Analyst, or closely related', 'Must have experience with:', 'Data processing;', 'Python;', 'SQL;', 'Git Version Control;', 'Power BI or Tableau or Si-Sense;', 'Linux/Unix or Powershell;', 'IntelliJ, Pycharm, or DE Beaver;', 'Agile or scrum methodology; and', 'ML models']","['With a high level of independent decision-making capability and minimum supervision, the Senior Data Analyst will be responsible for the following job duties:', 'Building complex data pipelines from different source to map to data warehouse schema;', 'Performing ETL logic as per required by building complex data pipelines;', 'Analyzing data and visualization using tools like Power BI or Tableau', 'Engaging with business and technical client teams to document and explain technical problems and concepts concisely;', 'Leading junior engineer teams;', 'Supporting customer incidents to resolutions;', 'Working with relational database and AWS; and Engaging in SQL programming and writing on a fly query to complete complex data analysis', 'This position requires travel to unanticipated client sites throughout the U.S and allows for telecommuting', 'Data analysis;']",True,[],,"['Data Pipelines', 'ETL (Extract, Transform, Load)', 'Data Visualization', 'SQL', 'Python', 'Relational Databases', 'Machine Learning Models', 'Version Control', 'Agile Methodology']","Data Pipelines: Building complex data pipelines from different sources to map to data warehouse schema and performing ETL logic as required.; ETL (Extract, Transform, Load): Performing ETL logic as part of building complex data pipelines to process and prepare data for analysis.; Data Visualization: Analyzing data and creating visualizations using BI tools such as Power BI, Tableau, or Si-Sense to support business insights.; SQL: Engaging in SQL programming and writing on-the-fly queries to complete complex data analysis tasks involving relational databases.; Python: Using Python for data processing and analysis tasks as part of the data analyst role.; Relational Databases: Working with relational database systems and AWS infrastructure to manage and query data.; Machine Learning Models: Applying machine learning models as part of data analysis responsibilities.; Version Control: Using Git version control to manage code and collaborate within the team.; Agile Methodology: Following Agile or Scrum methodologies for project management and team collaboration."
DUfnR_OQQwQvdtj_AAAAAA==,"(USA) Senior, Data Analyst - Transportation Strategy","Position Summary...

What you'll do...

This Senior Data Analyst will be a part of the Portfolio Optimization team within transportation. This role will make an impact by identifying new workload opportunities, areas of top loss in execution and ways to drive improved profitability. This role supports operational stakeholders across the E2E delivery network with heavy cross-functional engagement with transportation planning and procurement teams. This role is based in Bentonville, AR.

 

You’ll sweep us off our feet if…
• You have finance, supply chain and/or transportation experience.
• You possess strong skills in SQL and Python, and have experience in advanced analytics, including advanced exploratory data analysis skills, and the ability to make analytical, data-driven recommendations and solutions.
• Data visualization experience with tools like Tableau or PowerBI.
• You have extreme ownership and Intellectual curiosity that leads to process and business improvement.
• You are comfortable with shifting priorities in fast moving and sometimes ambiguous environment.

 

You’ll make an impact by…
• Advanced Analytics: In-depth investigation of key drivers of transportation dynamic optimization and data quality. Work with large, disparate datasets to measure business KPIs and to conduct strategic analyses to inform critical business decisions. Create data visualizations to monitor and quantify the impact of changes and unique business challenges and use data to influence strategic decision making. Develop advanced logic to identify cost savings opportunities to drive improved execution and recommendations for process improvement.
• Partnership and Collaboration: Engaging with team members and cross-functional partners on a consistent basis and establish credibility and influence change. Drive process optimization and collaboration across teams. Conduct exploratory analysis and inform team of findings.
• Continuous Improvement: Analyze and improve processes by leveraging lean, six sigma, and zero-loss principles. Identify opportunities to positively impact cost and growth plans. Lead efforts to improve data integrity and quality by proactively identifying and addressing issues. Formulate technical problems and solutions for data related challenges.

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

‎

‎

‎
You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.

‎

For information about PTO, see https://one.walmart.com/notices.

‎

‎
Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

‎
Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

‎

For information about benefits and eligibility, see One.Walmart.

‎
The annual salary range for this position is $80,000.00-$155,000.00

‎
Additional compensation includes annual or quarterly performance bonuses.

‎
Additional compensation for certain positions may also include:

‎

‎
- Stock

‎

‎

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelor's degree in Business, Engineering, Statistics, Economics, Analytics, Mathematics, Arts, Finance or related field and 2 years' experience in data analysis, data science, statistics, or related field. Option 2: Master's degree in Business, Engineering, Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field. Option 3: 4 years' experience in data analysis, data science, statistics, or related field.

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data science, data analysis, statistics, or related field, Master’s degree in Business, Computer Science, Engineering, Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field, Related industry experience (for example, retail, merchandising, healthcare, eCommerce), Successful completion of assessments in data analysis and Business Intelligence tools and scripting languages (for example, SQL, Python, Spark, Scala, R, Power BI, or Tableau)

Primary Location...

311 North Walton Boulevard, Bentonville, AR 72716, United States of America",2025-07-21T00:00:00.000Z,2025-07-25,"['You have finance, supply chain and/or transportation experience', 'You possess strong skills in SQL and Python, and have experience in advanced analytics, including advanced exploratory data analysis skills, and the ability to make analytical, data-driven recommendations and solutions', 'Data visualization experience with tools like Tableau or PowerBI', 'You have extreme ownership and Intellectual curiosity that leads to process and business improvement', 'You are comfortable with shifting priorities in fast moving and sometimes ambiguous environment', ""Option 1: Bachelor's degree in Business, Engineering, Statistics, Economics, Analytics, Mathematics, Arts, Finance or related field and 2 years' experience in data analysis, data science, statistics, or related field"", ""Option 2: Master's degree in Business, Engineering, Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field"", ""Option 3: 4 years' experience in data analysis, data science, statistics, or related field"", 'Data science, data analysis, statistics, or related field, Master’s degree in Business, Computer Science, Engineering, Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field, Related industry experience (for example, retail, merchandising, healthcare, eCommerce), Successful completion of assessments in data analysis and Business Intelligence tools and scripting languages (for example, SQL, Python, Spark, Scala, R, Power BI, or Tableau)']","['This Senior Data Analyst will be a part of the Portfolio Optimization team within transportation', 'This role will make an impact by identifying new workload opportunities, areas of top loss in execution and ways to drive improved profitability', 'This role supports operational stakeholders across the E2E delivery network with heavy cross-functional engagement with transportation planning and procurement teams', 'Advanced Analytics: In-depth investigation of key drivers of transportation dynamic optimization and data quality', 'Work with large, disparate datasets to measure business KPIs and to conduct strategic analyses to inform critical business decisions', 'Create data visualizations to monitor and quantify the impact of changes and unique business challenges and use data to influence strategic decision making', 'Develop advanced logic to identify cost savings opportunities to drive improved execution and recommendations for process improvement', 'Partnership and Collaboration: Engaging with team members and cross-functional partners on a consistent basis and establish credibility and influence change', 'Drive process optimization and collaboration across teams', 'Conduct exploratory analysis and inform team of findings', 'Continuous Improvement: Analyze and improve processes by leveraging lean, six sigma, and zero-loss principles', 'Identify opportunities to positively impact cost and growth plans', 'Lead efforts to improve data integrity and quality by proactively identifying and addressing issues', 'Formulate technical problems and solutions for data related challenges']",True,[],,"['SQL', 'Python', 'Data Visualization Tools', 'Advanced Exploratory Data Analysis', 'Business Intelligence (BI)', 'Lean, Six Sigma, and Zero-Loss Principles', 'Data Integrity and Quality Management', 'Exploratory Analysis']","SQL: Used for querying and managing large, disparate datasets to measure business KPIs and conduct strategic analyses in transportation optimization.; Python: Utilized for advanced analytics, including exploratory data analysis and developing advanced logic to identify cost savings and process improvements.; Data Visualization Tools: Tools like Tableau and Power BI are employed to create visualizations that monitor and quantify the impact of changes and business challenges, aiding strategic decision making.; Advanced Exploratory Data Analysis: Applied to investigate key drivers of transportation dynamic optimization and data quality, supporting data-driven recommendations and solutions.; Business Intelligence (BI): Used to support operational stakeholders by analyzing data to influence strategic decisions and identify opportunities for cost savings and process improvements.; Lean, Six Sigma, and Zero-Loss Principles: Leveraged to analyze and improve processes, identify opportunities to impact cost and growth plans, and enhance data integrity and quality.; Data Integrity and Quality Management: Involves proactively identifying and addressing data issues to ensure reliable data for analysis and decision making.; Exploratory Analysis: Conducted to inform teams of findings and support collaboration and process optimization across cross-functional partners."
v14PJcF50YHncd3BAAAAAA==,Senior Data Analytics Analyst,"At U.S. Bank, we're on a journey to do our best. Helping the customers and businesses we serve to make better and smarter financial decisions and enabling the communities we support to grow and succeed. We believe it takes all of us to bring our shared ambition to life, and each person is unique in their potential. A career with U.S. Bank gives you a wide, ever-growing range of opportunities to discover what makes you thrive at every stage of your career. Try new things, learn new skills and discover what you excel at-all from Day One.

Job Description

Responsible for working on big data/analytics projects that gather and integrate large volumes of data, performs analysis, interprets results and develops actionable insights and recommendations for use across the company. Acquires data from multiple data sources in order to perform analysis. Identifies, analyzes and interprets trends or patterns in complex data in order to provide answers to business questions as well as provide recommendations for action. Interprets data and analyze results using various statistical techniques and tools. Presents data and analysis in a clear and concise manner allowing the audience to quickly understand the results and recommendations so they activate upon them and make data driven decisions. Collaborate with various partners to provide a holistic view of the analysis. Measures and monitors results of applied recommendations and present adjustments. Ensures all data acquisition, sharing and results of applied recommendations are compliant with company standards.

Basic Qualifications
• Bachelor's degree in a related field, or equivalent work experience
• Six to eight years of statistical and/or data analytics experience

Preferred Skills/Experience
• Working knowledge of analytics and statistical software such as SQL, R, Python, Excel, Hadoop, SAS, SPSS, Geo-spatial tools and others to perform analysis and interpret data
• Experience in analytics, advanced analytics/statistics, predictive modeling
• Strong analytic skills with the ability to extract, collect, organize, analyze and interpret trends or patterns in complex data sets
• Demonstrated project management skills
• Effective interpersonal, verbal and written communication skills
• Experience using a variety of different systems including but not limited to: Salesforce, Precision Lender and nCino
• Experience using a variety of different tools including but not limited to: SQL Server Management Studio, Tableau, Analytics, PowerBI and on-platform reporting

If there's anything we can do to accommodate a disability during any portion of the application or hiring process, please refer to our disability accommodations for applicants.

Benefits:

Our approach to benefits and total rewards considers our team members' whole selves and what may be needed to thrive in and outside work. That's why our benefits are designed to help you and your family boost your health, protect your financial security and give you peace of mind. Our benefits include the following (some may vary based on role, location or hours):
• Healthcare (medical, dental, vision)
• Basic term and optional term life insurance
• Short-term and long-term disability
• Pregnancy disability and parental leave
• 401(k) and employer-funded retirement plan
• Paid vacation (from two to five weeks depending on salary grade and tenure)
• Up to 11 paid holiday opportunities
• Adoption assistance
• Sick and Safe Leave accruals of one hour for every 30 worked, up to 80 hours per calendar year unless otherwise provided by law

U.S. Bank is an equal opportunity employer. We consider all qualified applicants without regard to race, religion, color, sex, national origin, age, sexual orientation, gender identity, disability or veteran status, and other factors protected under applicable law.

E-Verify

U.S. Bank participates in the U.S. Department of Homeland Security E-Verify program in all facilities located in the United States and certain U.S. territories. The E-Verify program is an Internet-based employment eligibility verification system operated by the U.S. Citizenship and Immigration Services. Learn more about the E-Verify program.

The salary range reflects figures based on the primary location, which is listed first. The actual range for the role may differ based on the location of the role. In addition to salary, U.S. Bank offers a comprehensive benefits package, including incentive and recognition programs, equity stock purchase 401(k) contribution and pension (all benefits are subject to eligibility requirements). Pay Range: $119,765.00 - $140,900.00

U.S. Bank will consider qualified applicants with arrest or conviction records for employment. U.S. Bank conducts background checks consistent with applicable local laws, including the Los Angeles County Fair Chance Ordinance and the California Fair Chance Act as well as the San Francisco Fair Chance Ordinance. U.S. Bank is subject to, and conducts background checks consistent with the requirements of Section 19 of the Federal Deposit Insurance Act (FDIA). In addition, certain positions may also be subject to the requirements of FINRA, NMLS registration, Reg Z, Reg G, OFAC, the NFA, the FCPA, the Bank Secrecy Act, the SAFE Act, and/or federal guidelines applicable to an agreement, such as those related to ethics, safety, or operational procedures.

Applicants must be able to comply with U.S. Bank policies and procedures including the Code of Ethics and Business Conduct and related workplace conduct and safety policies.

Posting may be closed earlier due to high volume of applicants.",2025-07-12T00:00:00.000Z,2025-07-25,"[""Bachelor's degree in a related field, or equivalent work experience"", 'Six to eight years of statistical and/or data analytics experience', 'In addition, certain positions may also be subject to the requirements of FINRA, NMLS registration, Reg Z, Reg G, OFAC, the NFA, the FCPA, the Bank Secrecy Act, the SAFE Act, and/or federal guidelines applicable to an agreement, such as those related to ethics, safety, or operational procedures', 'Applicants must be able to comply with U.S. Bank policies and procedures including the Code of Ethics and Business Conduct and related workplace conduct and safety policies']","['Responsible for working on big data/analytics projects that gather and integrate large volumes of data, performs analysis, interprets results and develops actionable insights and recommendations for use across the company', 'Acquires data from multiple data sources in order to perform analysis', 'Identifies, analyzes and interprets trends or patterns in complex data in order to provide answers to business questions as well as provide recommendations for action', 'Interprets data and analyze results using various statistical techniques and tools', 'Presents data and analysis in a clear and concise manner allowing the audience to quickly understand the results and recommendations so they activate upon them and make data driven decisions', 'Collaborate with various partners to provide a holistic view of the analysis', 'Measures and monitors results of applied recommendations and present adjustments', 'Ensures all data acquisition, sharing and results of applied recommendations are compliant with company standards']",True,[],,"['Big Data Analytics', 'Data Acquisition', 'Statistical Analysis', 'Predictive Modeling', 'Data Visualization and BI Tools', 'SQL', 'Python and R', 'Hadoop', 'SAS and SPSS', 'Geo-spatial Tools', 'Advanced Analytics', 'Project Management']","Big Data Analytics: Responsible for working on projects that gather and integrate large volumes of data to perform analysis and develop actionable insights and recommendations across the company.; Data Acquisition: Acquires data from multiple data sources to perform analysis and ensure compliance with company standards for data sharing and results.; Statistical Analysis: Interprets data and analyzes results using various statistical techniques and tools to identify trends or patterns in complex data and provide answers to business questions.; Predictive Modeling: Experience in advanced analytics and predictive modeling to support data-driven decision making.; Data Visualization and BI Tools: Uses tools such as Tableau and PowerBI to present data and analysis clearly and concisely, enabling stakeholders to quickly understand results and activate upon recommendations.; SQL: Utilizes SQL and SQL Server Management Studio for data extraction, collection, and organization from various systems.; Python and R: Employs Python and R programming languages for analytics and statistical analysis.; Hadoop: Uses Hadoop for handling and processing large-scale data sets as part of big data analytics projects.; SAS and SPSS: Utilizes SAS and SPSS statistical software for data analysis and interpretation.; Geo-spatial Tools: Applies geo-spatial tools to analyze location-based data as part of the analytics process.; Advanced Analytics: Applies advanced analytics techniques to extract, analyze, and interpret trends or patterns in complex data sets to inform business decisions.; Project Management: Demonstrates project management skills to coordinate analytics projects and collaborate with partners for holistic analysis."
fRysXtQWXytn9LlHAAAAAA==,Mergers and Acquisitions Data Analyst Senior or Lead,"Progressive is dedicated to helping employees move forward and live fully in their careers. Your journey has already begun. Apply today and take the first step to Destination: Progress.

As a data analyst senior or lead on the Corporate Finance Merger & Acquisitions (M&A) team, you’ll prioritize a data-driven approach to end-to-end finance integration activities for mergers, acquisitions, and other business initiatives. You’ll work independently on a multitude of projects for the Corporate Finance organization, including accounting and finance due diligence, discovery and planning for merger activities, and supporting execution of post-merger integration projects. In this role, you’ll seek to understand the data, processes, systems, people, technology, contracts and assets of both Progressive and the acquired company. You’ll also identify current state for every finance related function, perform gap analysis, and develop a commonality roadmap. Additionally, you’ll drive solutions, collaborate across functions resolve project issues, dependencies, and risks, resolve issues, and advance critical problems.

Must-have qualifications
• A minimum of six years of analytical work experience.
• {OR} Bachelor's degree or higher and a minimum of five years of analytical work experience.
• {OR} Bachelor's degree or higher in a quantitative field of study and a minimum of three years analytical work experience.

Preferred skills
• Experience with financial integration activities
• Understanding of treasury functions such as banking, cash management, and pay operations
• Strong organization and collaboration skills to present insights to partners for alignment
• Aptitude to learn and understand the various areas of discipline within a finance organization, including their dependencies.

Compensation
• $79,200 - $127,700/year depending on position level and experience
• Gainshare annual cash incentive payment up to 30% your eligible earnings based on company performance

Benefits
• 401(k) with dollar-for-dollar company match up to 6%
• Medical, dental & vision, including free preventative care
• Wellness & mental health programs
• Health care flexible spending accounts, health savings accounts, & life insurance
• Paid time off, including volunteer time off
• Paid & unpaid sick leave where applicable, as well as short & long-term disability
• Parental & family leave; military leave & pay
• Diverse, inclusive & welcoming culture with Employee Resource Groups
• Career development & tuition assistance
• Onsite gym & healthcare at large locations

Energage recognizes Progressive as a 2025 Top Workplace for: Innovation, Purposes & Values, Work-Life Flexibility, Compensation & Benefits, and Leadership.

Sponsorship for work authorization for foreign national candidates is not available for this position.

Equal Opportunity Employer

For ideas about how you might be able to protect yourself from job scams, visit our scam-awareness page at https://careers.progressive.com/pages/how-we-hire-faq-job-scams/",2025-07-21T00:00:00.000Z,2025-07-25,"['A minimum of six years of analytical work experience', ""{OR} Bachelor's degree or higher and a minimum of five years of analytical work experience"", ""{OR} Bachelor's degree or higher in a quantitative field of study and a minimum of three years analytical work experience""]","['As a data analyst senior or lead on the Corporate Finance Merger & Acquisitions (M&A) team, you’ll prioritize a data-driven approach to end-to-end finance integration activities for mergers, acquisitions, and other business initiatives', 'You’ll work independently on a multitude of projects for the Corporate Finance organization, including accounting and finance due diligence, discovery and planning for merger activities, and supporting execution of post-merger integration projects', 'In this role, you’ll seek to understand the data, processes, systems, people, technology, contracts and assets of both Progressive and the acquired company', 'You’ll also identify current state for every finance related function, perform gap analysis, and develop a commonality roadmap', 'Additionally, you’ll drive solutions, collaborate across functions resolve project issues, dependencies, and risks, resolve issues, and advance critical problems']",False,,,,
KGwdgfxpOFbJ4d2aAAAAAA==,Senior Data Analyst Job at Corporate Tools LLC in Post Falls,"Corporate Tools is looking for a Senior Data Analyst to join our finance team located in Post Falls, ID. Corporate Tools is a privately held, debt-free, growing company. We don’t answer to shareholders or investors. Because of this, we focus on taking the time to provide solutions for our clients, not maximizing profits for shareholders. As an employer, we recognize that you’ve been gracious enough to give us 40 hours of your week. We want to respect that time commitment and be able to provide you with a job that you enjoy coming to and a work schedule that allows you to maintain a healthy work/life balance.Are you a data wizard with a passion for numbers? Then we want to talk to you! In this position, you won’t just be running numbers through a system and handing the results off to someone else. You will be running the numbers, understanding the results, and then using the final data sets to direct the company towards impactful moments for our customers.This position is coded as “Hybrid,” which means after initial training and onboarding in the office, occasional remote work is available. However, this role will be expected to continue to work in our Post Falls, Idaho office or our Spokane, WA office 2-3 days/week.Wage:$100,000 - $125,000 depending on meeting requirements100% employer-paid medical, dental, and vision for employeesAnnual review with raise option22 days Paid Time Off accrued annually, and 4 holidaysAfter 3 years, PTO increases to 29 days. Employees transition to flexible time off after 5 years with the company—not accrued, not capped, take time off when you wantThe 4 holidays are: New Year’s Day, Fourth of July, Thanksgiving, and Christmas DayPaid Maternity and Paternity Leave4% company matching 401(k) with no vesting periodQuarterly ""Work Wherever"" allowanceUse to make your remote work wherever set up more comfortable, for continuing education classes, a plant for your desk, coffee for your coworker, a massage for yourself... really, whateverOpen concept office with friendly coworkersCreative environment where you can make a differenceTrail Mix BarResponsibilities:Data Analysis Product leader facilitating product planning and prioritization, execution, and reporting for the overall product - incorporating product mindset throughout.Primary contact responsible for communication management throughout the organization for Data Analysis Product.Effectively communicate complex information to a variety of stakeholders to help inform business decisions.Collaborates with the analytics team to plan and scale analytics, working to harvest and grow the data culture across the company.Consults stakeholders in the development of KPIs, ad hoc analyses, and automated reporting to best fit their needs and act as a leader in promoting data literacy.Works with the data engineering team to plan, build, and maintain data structures to support analysis and reporting needs.Conduct complex data analysis to support strategic initiatives, leveraging your unique expertise in analytics tools and statistical methods.Leverage advanced SQL and Python/R expertise to wrangle even the most elusive sets of data—capturing trends, patterns, and anomalies.Create and maintain beautiful, intuitive business intelligence dashboards, making it easy for teams to see the stories hidden in the data.Develop models that help us predict market trends, customer behavior, and data migrations, improving decision-making across the organization.Partner with cross-functional teams to understand their data needs, translating these into actionable insights and recommendations.Ensure the highest quality and accuracy of all data by developing processes and standards that keep the data pristine.Organizes and prioritizes tickets using Jira and Confluence.As a Senior Data Analyst, you’ll mentor the analyst team and share best practices.Requirements:5+ years in data analytics or a related field, ideally with experience working for fast-growing, high-impact organizations.Bachelor’s (BA or BS) in business, accounting, or related field, or relevant experience.Advanced experience using SQL to extract data from relational databases (Postgres, MySQL, T-SQL, etc.).Proficient in advanced programming languages (Python, R, etc.) for data manipulation, analysis, and visualization in various contexts such as statistical analysis, machine learning, and data mining.Demonstrated analytical and problem-solving skills.Experience extracting meaning from large data sets.Experience building dashboards and reports using business intelligence tools (Tableau, PowerBI, Looker, Metabase, etc.). Metabase experience would be a plus.Exceptional skills in data modeling, statistical analysis, and predictive modeling.Ability to think outside the box, constantly seeking new ways to interpret and use data.Ability to translate complex data findings into narratives for both technical and non-technical audiences.Ability to act as a consultant to help stakeholders create relevant KPIs and understand the meaning behind the data.Team management/leadership experience including developing others.Preferred experience presenting insights to executive leadership.Bonus Points: Experience working on ETL processes and data modeling. DBT experience is highly preferred.Data is what you do, it’s your niche. Finding ways to move the company forward using data as your storyboard excites you!
#J-18808-Ljbffr",2025-07-22T00:00:00.000Z,2025-07-25,"['Organizes and prioritizes tickets using Jira and Confluence.As a Senior Data Analyst, you’ll mentor the analyst team and share best practices.Requirements:5+ years in data analytics or a related field, ideally with experience working for fast-growing, high-impact organizations.Bachelor’s (BA or BS) in business, accounting, or related field, or relevant experience', 'Advanced experience using SQL to extract data from relational databases (Postgres, MySQL, T-SQL, etc.).Proficient in advanced programming languages (Python, R, etc.) for data manipulation, analysis, and visualization in various contexts such as statistical analysis, machine learning, and data mining', 'Demonstrated analytical and problem-solving skills', 'Experience extracting meaning from large data sets', 'Experience building dashboards and reports using business intelligence tools (Tableau, PowerBI, Looker, Metabase, etc.)', 'Exceptional skills in data modeling, statistical analysis, and predictive modeling', 'Ability to think outside the box, constantly seeking new ways to interpret and use data', 'Ability to translate complex data findings into narratives for both technical and non-technical audiences', 'Ability to act as a consultant to help stakeholders create relevant KPIs and understand the meaning behind the data', 'Team management/leadership experience including developing others', 'Bonus Points: Experience working on ETL processes and data modeling']","['In this position, you won’t just be running numbers through a system and handing the results off to someone else', 'You will be running the numbers, understanding the results, and then using the final data sets to direct the company towards impactful moments for our customers', 'Trail Mix BarResponsibilities:Data Analysis Product leader facilitating product planning and prioritization, execution, and reporting for the overall product - incorporating product mindset throughout', 'Primary contact responsible for communication management throughout the organization for Data Analysis Product', 'Effectively communicate complex information to a variety of stakeholders to help inform business decisions', 'Collaborates with the analytics team to plan and scale analytics, working to harvest and grow the data culture across the company', 'Consults stakeholders in the development of KPIs, ad hoc analyses, and automated reporting to best fit their needs and act as a leader in promoting data literacy', 'Works with the data engineering team to plan, build, and maintain data structures to support analysis and reporting needs', 'Conduct complex data analysis to support strategic initiatives, leveraging your unique expertise in analytics tools and statistical methods', 'Leverage advanced SQL and Python/R expertise to wrangle even the most elusive sets of data—capturing trends, patterns, and anomalies', 'Create and maintain beautiful, intuitive business intelligence dashboards, making it easy for teams to see the stories hidden in the data', 'Develop models that help us predict market trends, customer behavior, and data migrations, improving decision-making across the organization', 'Partner with cross-functional teams to understand their data needs, translating these into actionable insights and recommendations', 'Ensure the highest quality and accuracy of all data by developing processes and standards that keep the data pristine']",True,[],,"['SQL', 'Python', 'R', 'Business Intelligence Tools', 'Data Modeling', 'Statistical Analysis', 'Predictive Modeling', 'ETL Processes', 'Data Pipelines', 'KPI Development', 'Data Literacy Promotion', 'Data Analysis']","SQL: Used extensively to extract data from relational databases such as Postgres, MySQL, and T-SQL to support data analysis and reporting needs.; Python: Utilized for data manipulation, analysis, and visualization, including statistical analysis, machine learning, and data mining tasks.; R: Applied for advanced data manipulation, statistical analysis, and visualization to support complex data analysis and predictive modeling.; Business Intelligence Tools: Experience building dashboards and reports using tools like Tableau, PowerBI, Looker, and Metabase to create intuitive visualizations that communicate data insights effectively.; Data Modeling: Involved in designing and developing data models to support analysis, reporting, and predictive modeling efforts.; Statistical Analysis: Conduct complex statistical analyses to extract meaningful insights from large datasets and support strategic initiatives.; Predictive Modeling: Develop models to predict market trends, customer behavior, and data migrations, thereby improving organizational decision-making.; ETL Processes: Experience working on Extract, Transform, Load (ETL) processes to prepare and manage data for analysis and reporting.; Data Pipelines: Collaborate with data engineering teams to plan, build, and maintain data structures and pipelines that support analytics and reporting.; KPI Development: Consult with stakeholders to develop relevant Key Performance Indicators (KPIs) and translate complex data findings into actionable business insights.; Data Literacy Promotion: Act as a leader in promoting data literacy across the organization by facilitating understanding and effective use of data.; Data Analysis: Perform complex data analysis to support strategic business decisions and initiatives, leveraging advanced analytics tools and statistical methods."
OKOzvEm3BJJAS-RpAAAAAA==,Senior Data Analyst,"About Arlo: At Arlo, we're passionate about creating innovative and reliable solutions that help people protect what matters most to them. Our team is dedicated to delivering products that exceed our customers' expectations, while always pushing the boundaries of what's possible in the world of protection technology. We believe that everyone deserves to feel safe and secure, whether they're at home or away, and we're committed to providing our customers with the peace of mind they need to live their lives without worry. Arlo’s deep expertise in AI- and CV-powered analytics, cloud services, user experience, product design, and innovative wireless and RF connectivity enables the delivery of a seamless, smart security experience for Arlo users that is easy to set up and interact with every day. We’re looking for a Senior Data Analyst to join our analytics team. This is a great opportunity for someone with a few years of experience under their belt who’s ready to take on more responsibility and grow their impact in a fast-paced, data-led environment. As a Senior Data Analyst, you’ll work across our product, subscription, and hardware ecosystem to deliver insights that directly influence how we design experiences, retain users, and grow our business. You'll have the space to operate independently on well-scoped projects while learning from experienced analysts and collaborating with product, engineering, and marketing teams across Europe and the US. What You’ll Be Doing Analyse user behavior across our cameras, doorbells, and subscription plans to uncover patterns, identify opportunities, and highlight risks Build dashboards and reports using SQL and tools like Tableau or Looker to track key business metrics, such as: Subscription conversion Monthly active users (MAU) Customer churn Lifetime value (LTV) Average revenue per user (ARPU) Partner with product teams to measure feature performance and run A/B tests Work with our marketing and lifecycle teams to understand campaign performance and customer segmentation Support instrumentation and data QA by partnering with engineers to improve tracking and event quality Share insights with stakeholders through compelling storytelling and clear data visualization What You’ll Bring 7+ years of hands-on experience in a data analyst, BI analyst, or similar role with a bachelor's degree 5+ years with a master's degree or equivalent Strong SQL skills – able to write clean, efficient queries and handle large datasets Experience with data visualization tools: Tableau desired; Looker, Power BI, or equivalent will be considered. A solid grasp of subscription metrics and familiarity with mobile Business-to-Consumer (b2c) audiences. Very comfortable working independently to scope and identify problems, form and execute solutions, and managing your own workflow. Strong communicator – you know how to explain findings to non-technical stakeholders clearly and confidently. Curious, methodical, and interested in how people use technology in everyday life. Ideal to Have: Background in a connected device, smart home, or hardware + SaaS business Exposure to tools like Python or R for deeper analysis or prototyping Experience with event-based analytics tools (e.g. Mixpanel, Amplitude) Familiarity with experimentation frameworks and A/B testing basics The pay range for this position reflects the minimum and maximum target for new hire salaries at commencement of employment and is expected to be between CAD $115,000-170,000/year. However, base pay offered may vary depending on multiple factors, including role, job-related knowledge, skills, relevant education and experience. The total compensation package for this position may also include other elements, including bonus, equity, and a full range of benefits. Details of all benefits will be provided if an employee receives an offer of employment. We’re committed to inclusivity and selecting the strongest candidate—no matter their background. Even if you don’t meet every listed qualification, we encourage you to apply. We’re happy to support growth in areas essential to the role. Interested in learning more about our workplace? Visit and follow our LinkedIn, and Glassdoor pages to read employee insights and get updates of what it’s like to be part of Arlo. Arlo is proud to be an Equal Opportunity Employer. We value inclusion and are committed to inclusive, and harassment-free workplace. We prohibit discrimination and harassment based on all legally protected statuses in all hiring and employment. We provide reasonable accommodations to applicants and employees with disabilities, who are pregnant or have a related medical condition, or who have sincerely held religious beliefs, observances, and practices. Pursuant to applicable state and municipal Fair Chance Laws and Ordinances, the Company will consider for employment qualified applicants with arrest and conviction records. We are a passionate and diverse group of thought leaders, creators, and developers across all disciplines dedicated to changing how people protect and connect with the people and things they love. Our talented employees, located throughout the United States, Canada, Asia, Australia, and Europe communicate, connect and work together to lead the industry in delivering a world-class end-to-end connected lifestyle solution. At every location, passionate and innovative employees work together to shape the future of connectivity. At Arlo, our employees are recognized as central to our business success, now and into the future.",2025-06-25T00:00:00.000Z,2025-07-25,,,True,[],,"['SQL', 'Data Visualization Tools', 'A/B Testing', 'Event-Based Analytics Tools', 'Subscription Metrics', 'Data Quality Assurance (Data QA)', 'User Behavior Analysis', 'Customer Segmentation', 'Python or R']","SQL: Used to write clean, efficient queries and handle large datasets for building dashboards and reports tracking key business metrics.; Data Visualization Tools: Tools like Tableau, Looker, and Power BI are used to create dashboards and reports that communicate insights and track business metrics such as subscription conversion, MAU, churn, LTV, and ARPU.; A/B Testing: Used to measure feature performance and understand campaign effectiveness by running controlled experiments.; Event-Based Analytics Tools: Tools such as Mixpanel and Amplitude are used to analyze user behavior and event tracking data to support insights and data quality assurance.; Subscription Metrics: Metrics like subscription conversion, monthly active users, customer churn, lifetime value, and average revenue per user are analyzed to influence product design, user retention, and business growth.; Data Quality Assurance (Data QA): Partnering with engineers to improve tracking and event quality to ensure reliable data for analysis.; User Behavior Analysis: Analyzing user interactions across devices and subscription plans to uncover patterns, identify opportunities, and highlight risks.; Customer Segmentation: Working with marketing and lifecycle teams to understand different customer groups and campaign performance.; Python or R: Used for deeper analysis or prototyping beyond standard SQL and visualization tools."
zR9q3DsgnW1GJNv7AAAAAA==,"Senior Data Analyst, Global S&O","Gartner is hiring a Senior Data Analyst, Global S&O with 3 - 5 years of experience. Based in United States - Irving, TX and with Hybrid ways of working.

Job description and responsibilities:

Hiring near our Irving, TX, Stamford CT or Fort Myers, FL - Hybrid Work Environment.

Join our dynamic team within Gartner's Global Strategy and Operations (GSO) division, where innovation meets impact. Our Service Analytics & Productivity team is at the forefront of driving automated data solutions across Gartner’s Global Services & Delivery team, leveraging data to uncover new insights and strategies to enhance productivity and boost client retention. This is your chance to be part of a high-impact analytics team dedicated to automation, problem-solving, and stakeholder management, ultimately delivering significant business outcomes.

Key Responsibilities:
• Strategic Collaboration: Partner with business stakeholders to transform strategic needs into actionable automated data insights, driving informed decision-making across the organization.
• Business Intelligence Development: Design, develop, and maintain robust business intelligence solutions using Power BI, ensuring scalability and stability to support evolving business needs.
• Initiative Leadership: Spearhead automation initiatives to streamline data processes, enhancing business efficiency and agility through innovative solutions
• Stakeholder Management: Cultivate strong relationships with stakeholders by effectively communicating automation strategies and priorities, ensuring alignment and understanding.
• Ethical Standards & Teamwork: Uphold the highest ethical standards while fostering a culture of teamwork and collaboration, contributing to a positive and productive work environment.

Requirements and qualifications:

Qualifications:
• Educational Background: 4-6 years of professional experience with a degree in Engineering, Math, Statistics, or related fields.
• Data Visualization Expertise: Mastery of data visualization techniques and tools for impactful storytelling through dashboards, with a primary focus on Power BI.
• Technical Proficiency: Proficiency in Python and essential libraries such as NumPy and Pandas, with a proven track record of creating efficient ETL processes, preferably in Databricks.
• SQL skills for data extraction and manipulation, enabling the creation of innovative data solutions.
• Problem-Solving Skills: A knack for creative problem-solving, with sharp qualitative and quantitative abilities and a keen eye for detail and accuracy.
• Communication Skills: Exceptional communication skills, with the ability to engage with senior leaders and manage multiple stakeholders effectively.
• Microsoft Office Proficiency: Advanced proficiency in Microsoft Office suite, particularly Excel and PowerPoint, to support data analysis and presentation.",,2025-07-25,"['Gartner is hiring a Senior Data Analyst, Global S&O with 3 - 5 years of experience', 'Educational Background: 4-6 years of professional experience with a degree in Engineering, Math, Statistics, or related fields', 'Data Visualization Expertise: Mastery of data visualization techniques and tools for impactful storytelling through dashboards, with a primary focus on Power BI', 'Technical Proficiency: Proficiency in Python and essential libraries such as NumPy and Pandas, with a proven track record of creating efficient ETL processes, preferably in Databricks', 'SQL skills for data extraction and manipulation, enabling the creation of innovative data solutions', 'Problem-Solving Skills: A knack for creative problem-solving, with sharp qualitative and quantitative abilities and a keen eye for detail and accuracy', 'Communication Skills: Exceptional communication skills, with the ability to engage with senior leaders and manage multiple stakeholders effectively', 'Microsoft Office Proficiency: Advanced proficiency in Microsoft Office suite, particularly Excel and PowerPoint, to support data analysis and presentation']","['This is your chance to be part of a high-impact analytics team dedicated to automation, problem-solving, and stakeholder management, ultimately delivering significant business outcomes', 'Strategic Collaboration: Partner with business stakeholders to transform strategic needs into actionable automated data insights, driving informed decision-making across the organization', 'Business Intelligence Development: Design, develop, and maintain robust business intelligence solutions using Power BI, ensuring scalability and stability to support evolving business needs', 'Initiative Leadership: Spearhead automation initiatives to streamline data processes, enhancing business efficiency and agility through innovative solutions', 'Stakeholder Management: Cultivate strong relationships with stakeholders by effectively communicating automation strategies and priorities, ensuring alignment and understanding', 'Ethical Standards & Teamwork: Uphold the highest ethical standards while fostering a culture of teamwork and collaboration, contributing to a positive and productive work environment']",True,[],,"['Power BI', 'Python', 'NumPy', 'Pandas', 'ETL Processes', 'SQL', 'Data Visualization', 'Stakeholder Management', 'Business Intelligence']","Power BI: Used to design, develop, and maintain scalable and stable business intelligence solutions and dashboards that support evolving business needs and enable impactful storytelling.; Python: Utilized for creating efficient ETL processes and data manipulation, leveraging essential libraries such as NumPy and Pandas.; NumPy: A Python library employed for numerical computing tasks within data processing and ETL workflows.; Pandas: A Python library used for data manipulation and analysis, supporting the creation of automated data insights and ETL processes.; ETL Processes: Development and automation of data extraction, transformation, and loading workflows to streamline data processes and enhance business efficiency.; SQL: Applied for data extraction and manipulation to create innovative data solutions that support strategic decision-making.; Data Visualization: Mastery of techniques and tools to create dashboards and visual storytelling that communicate data insights effectively to stakeholders.; Stakeholder Management: Engaging and collaborating with business stakeholders to translate strategic needs into actionable data insights and ensure alignment on automation strategies.; Business Intelligence: Designing and maintaining data-driven solutions that provide actionable insights to drive informed decision-making and improve productivity."
2jQUGnt__tj0nxC2AAAAAA==,Senior Data Analyst,"At Oshkosh, we build, serve and protect people and communities around the world by designing and manufacturing some of the toughest specialty trucks and access equipment. We employ over 18,000 team members all united by a common purpose. Our engineering and product innovation help keep soldiers and firefighters safe, is critical in building and keeping communities clean and helps people do their jobs every day.

SUMMARY:

PLEASE NOTE: This role is an onsite role located in Oshkosh, WI.

As a member of the Data Analyst team, your primary responsibilities will be to identify, collect, process, and analyze datasets to help make informed business decisions. You will also assist with data analysis assignments, projects, visualization tasks, data quality improvements, and troubleshooting of data incidents.

YOUR IMPACT:
• Discover, acquire, explore, prepare, assess and maintain datasets from a variety of data sources (including external sources) to support analyses and ad-hoc investigative requests for project and products covering multiple related functions or related business units
• Perform data analysis assignments, projects, visualization tasks, data quality improvements, and troubleshooting of data incidents, including the resolution of root causes.
• Serve as a Subject Matter Expert in the application of SQL and statistical techniques to the acquisition, enrichment, and analysis of data.
• Resolve and document solutions to track and manage incidents, changes, problems, tasks, and demands
• Review and approve data views, design, and documentation by other team members to ensure governance standards and the utilization of appropriate technical components and techniques.
• Serve as subject matter expert in the process, people, product, data, and systems of related business functions across a variety of business units and/or unrelated business functions within related business units (i.e. Oshkosh Segment)
• Pursue and Define Business Problems & Opportunities
• Propose and Define Relevant Dimensions & Measures
• Collaborating with Data Engineers, draft and test data views to meet business needs for projects and products
• Collaborating with Data Scientists, identify opportunities to incorporate predictive and prescriptive analytics, as well as machine learning and artificial intelligence into projects and products
• Facilitate Conversations to Confirm Problems & Opportunities
• Propose and Align Goals, Roles, and Sustainment Plans with Leaders
• Coaches Leaders on Projects & Programs
• Collaborate with cross-functional teams (e.g. scientists, data engineers, business operations support, consultants) on data needs for business requirements on solutions which may be projects/products focused on a single business function that spans multiple business units or multiple related functions within a single business unit (Medium Complexity)
• Apply technical writing and verbal communication skills to drive the change management (e.g. training plan, communications plan) and on-going management of data solutions.
• Serve as a subject matter expert in Function/Business Unit/Digital Technology participation in Analytics Communities of Practice
• Coach and teach business citizen analysts in building views and in analyzing, interpreting, and communicating data insights.

MINIMUM QUALIFICATIONS:
• Bachelor's degree in Computer Science, Information Systems or equivalent.
• Five (5) or more years of experience in Data Analysis, Information Technology, or in a related area.
• Proficient with various web-based software applications including Power Bi Microsoft Office Word, Excel, PowerPoint, SharePoint, etc.
• Ability to travel 20%
• Experience in data analysis, analytics
• Ability influence and storytelling
• Attention to detail, problem solving, and decision-making skills.
• Advanced Analytical, written, and verbal communication skills.

Pay Range:
$82,000.00 - $132,800.00

The above pay range reflects the minimum and maximum target pay for the position across all U.S. locations. Within this range, individual pay is determined by various factors, including the scope and responsibilities of the role, the candidate's experience, education and skills, as well as the equity of pay among team members in similar positions. Beyond offering a competitive total rewards package, we prioritize a people-first culture and offer various opportunities to support team member growth and success.

Oshkosh is committed to working with and offering reasonable accommodation to job applicants with disabilities. If you need assistance or an accommodation due to disability for any part of the employment process, please contact us at corporatetalentacquisition@oshkoshcorp.com.

Oshkosh Corporation is a merit-based Equal Opportunity Employer. Job opportunities are open for application to all qualified individuals and selection decisions are made without regard to race, color, religion, sex, national origin, age, disability, veteran status, or other protected characteristic. To the extent that information is provided or collected regarding categories as provided by law it will in no way affect the decision regarding an employment application.

Oshkosh Corporation will not discharge or in any manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with Oshkosh Corporation's legal duty to furnish information.

Certain positions with Oshkosh Corporation require access to controlled goods and technologies subject to the International Traffic in Arms Regulations or the Export Administration Regulations. Applicants for these positions may need to be ""U.S. Persons,"" as defined in these regulations. Generally, a ""U.S. Person"" is a U.S. citizen, lawful permanent resident, or an individual who has been admitted as a refugee or granted asylum.",,2025-07-25,"[""Bachelor's degree in Computer Science, Information Systems or equivalent"", 'Five (5) or more years of experience in Data Analysis, Information Technology, or in a related area', 'Proficient with various web-based software applications including Power Bi Microsoft Office Word, Excel, PowerPoint, SharePoint, etc', 'Ability to travel 20%', 'Experience in data analysis, analytics', 'Ability influence and storytelling', 'Attention to detail, problem solving, and decision-making skills', 'Advanced Analytical, written, and verbal communication skills', 'Generally, a ""U.S. Person"" is a U.S. citizen, lawful permanent resident, or an individual who has been admitted as a refugee or granted asylum']","['As a member of the Data Analyst team, your primary responsibilities will be to identify, collect, process, and analyze datasets to help make informed business decisions', 'You will also assist with data analysis assignments, projects, visualization tasks, data quality improvements, and troubleshooting of data incidents', 'Discover, acquire, explore, prepare, assess and maintain datasets from a variety of data sources (including external sources) to support analyses and ad-hoc investigative requests for project and products covering multiple related functions or related business units', 'Perform data analysis assignments, projects, visualization tasks, data quality improvements, and troubleshooting of data incidents, including the resolution of root causes', 'Serve as a Subject Matter Expert in the application of SQL and statistical techniques to the acquisition, enrichment, and analysis of data', 'Resolve and document solutions to track and manage incidents, changes, problems, tasks, and demands', 'Review and approve data views, design, and documentation by other team members to ensure governance standards and the utilization of appropriate technical components and techniques', 'Serve as subject matter expert in the process, people, product, data, and systems of related business functions across a variety of business units and/or unrelated business functions within related business units (i.e', 'Pursue and Define Business Problems & Opportunities', 'Propose and Define Relevant Dimensions & Measures', 'Collaborating with Data Engineers, draft and test data views to meet business needs for projects and products', 'Collaborating with Data Scientists, identify opportunities to incorporate predictive and prescriptive analytics, as well as machine learning and artificial intelligence into projects and products', 'Facilitate Conversations to Confirm Problems & Opportunities', 'Propose and Align Goals, Roles, and Sustainment Plans with Leaders', 'Coaches Leaders on Projects & Programs', 'Collaborate with cross-functional teams (e.g. scientists, data engineers, business operations support, consultants) on data needs for business requirements on solutions which may be projects/products focused on a single business function that spans multiple business units or multiple related functions within a single business unit (Medium Complexity)', 'Apply technical writing and verbal communication skills to drive the change management (e.g. training plan, communications plan) and on-going management of data solutions', 'Serve as a subject matter expert in Function/Business Unit/Digital Technology participation in Analytics Communities of Practice', 'Coach and teach business citizen analysts in building views and in analyzing, interpreting, and communicating data insights']",True,[],,"['SQL', 'Statistical Techniques', 'Data Visualization', 'Data Quality Management', 'Data Acquisition and Preparation', 'Predictive and Prescriptive Analytics', 'Collaboration with Data Engineers and Data Scientists', 'Business Intelligence Tools', 'Data Governance and Documentation', 'Data Storytelling and Communication']","SQL: Used as a subject matter expert tool for data acquisition, enrichment, and analysis to support business decision-making and data quality improvements.; Statistical Techniques: Applied to analyze data, improve data quality, and troubleshoot data incidents as part of data analysis assignments and projects.; Data Visualization: Performed visualization tasks to communicate data insights and support business decisions.; Data Quality Management: Involves improving data quality, troubleshooting data incidents, and resolving root causes to ensure reliable data for analysis.; Data Acquisition and Preparation: Includes discovering, acquiring, exploring, preparing, assessing, and maintaining datasets from various sources to support analyses and investigative requests.; Predictive and Prescriptive Analytics: Identified opportunities to incorporate these analytics methods into projects and products in collaboration with data scientists.; Collaboration with Data Engineers and Data Scientists: Involves drafting and testing data views with data engineers and identifying analytics and machine learning opportunities with data scientists to meet business needs.; Business Intelligence Tools: Proficiency with Power BI and Microsoft Office tools (Word, Excel, PowerPoint, SharePoint) to support data analysis, reporting, and communication.; Data Governance and Documentation: Reviewing and approving data views, design, and documentation to ensure governance standards and appropriate technical components are utilized.; Data Storytelling and Communication: Using analytical, written, and verbal communication skills to influence, coach leaders, and teach business analysts in interpreting and communicating data insights."
ny-9dTFQI_8p29_YAAAAAA==,Sr Data Reporting Analyst,"Use our easy apply form to send your application to Lisa Maloney, the Jobot Pro hosting this job. Compensation Based on Experience.

Sr Data Reporting Analyst

$100000 - $125000 per year | Johnstown, OH | On-Site | Permanent

Hybrid - Sr Data Reporting Analyst for Established Manufacturer - Base + Bonus!

A bit about us:

We are a family owned, international manufacturer and distributor of more than 10,000 automotive and industrial rubber products that support customers in 95 countries. We create and extract value from materials that were formerly considered to be at the end of their useful life. We serve the end-to-end needs of our customers who implement earth-friendly, sustainable solutions using our products.

Why join us?

We offer the following benefits:
• Medical/dental/vision insurance
• 401k with a 4% match that is immediately 100% vested
• Profit sharing plan
• Competitive salary and bonus structure
• 3 weeks of paid time off, 40 hours of sick time, 2 personal days, and 9 paid holidays
• Employee of the quarter with incentives, recognized throughout the year
• A family oriented culture with employee engagement lunches, holiday parties, and more!

Job Details

We are seeking a highly motivated and experienced Sr Data Reporting Analyst to join our dynamic team in the Manufacturing industry. As a Sr Data Reporting Analyst, you will be responsible for analyzing complex data sets, creating insightful reports, and presenting findings to key stakeholders. You will work closely with cross-functional teams to identify business opportunities, develop strategies, and drive business growth.

Responsibilities:

• Analyze complex data sets using SQL and other analytical tools to identify trends, patterns, and insights
• Develop and maintain reports and dashboards using Tableau and Excel to provide actionable insights to stakeholders
• Collaborate with cross-functional teams to understand business requirements and translate them into data-driven solutions
• Develop and maintain data models to support business analysis and reporting
• Create process flow diagrams and visualizations using Visio to improve business processes
• Manage and maintain SharePoint sites and libraries to ensure data accuracy and accessibility
• Provide ERP analyst support to ensure data accuracy and integrity
• Identify opportunities for process improvements and automation to increase efficiency and reduce errors

Qualifications:

• Bachelor's degree in Computer Science, Mathematics, Statistics, or related field
• 3+ years of experience in data analysis, reporting, and visualization
• Proficient in SQL, Tableau, Visio, SharePoint, Excel, and ERP systems
• Strong analytical and problem-solving skills with the ability to work with large data sets
• Excellent communication and presentation skills with the ability to effectively communicate complex data insights to stakeholders
• Strong attention to detail and ability to work independently and in a team environment
• Experience in the Manufacturing industry is a plus

If you are passionate about data analysis, reporting, and visualization and want to work in a fast-paced and dynamic environment, we encourage you to apply for this exciting opportunity as a Sr Data Reporting Analyst in the Manufacturing industry.

Jobot is an Equal Opportunity Employer. We provide an inclusive work environment that celebrates diversity and all qualified candidates receive consideration for employment without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.

Sometimes Jobot is required to perform background checks with your authorization. Jobot will consider qualified candidates with criminal histories in a manner consistent with any applicable federal, state, or local law regarding criminal backgrounds, including but not limited to the Los Angeles Fair Chance Initiative for Hiring and the San Francisco Fair Chance Ordinance.",,2025-07-25,"['We are seeking a highly motivated and experienced Sr Data Reporting Analyst to join our dynamic team in the Manufacturing industry', ""Bachelor's degree in Computer Science, Mathematics, Statistics, or related field"", '3+ years of experience in data analysis, reporting, and visualization', 'Proficient in SQL, Tableau, Visio, SharePoint, Excel, and ERP systems', 'Strong analytical and problem-solving skills with the ability to work with large data sets', 'Excellent communication and presentation skills with the ability to effectively communicate complex data insights to stakeholders', 'Strong attention to detail and ability to work independently and in a team environment', 'Sometimes Jobot is required to perform background checks with your authorization', 'Jobot will consider qualified candidates with criminal histories in a manner consistent with any applicable federal, state, or local law regarding criminal backgrounds, including but not limited to the Los Angeles Fair Chance Initiative for Hiring and the San Francisco Fair Chance Ordinance']","['As a Sr Data Reporting Analyst, you will be responsible for analyzing complex data sets, creating insightful reports, and presenting findings to key stakeholders', 'You will work closely with cross-functional teams to identify business opportunities, develop strategies, and drive business growth', 'Analyze complex data sets using SQL and other analytical tools to identify trends, patterns, and insights', 'Develop and maintain reports and dashboards using Tableau and Excel to provide actionable insights to stakeholders', 'Collaborate with cross-functional teams to understand business requirements and translate them into data-driven solutions', 'Develop and maintain data models to support business analysis and reporting', 'Create process flow diagrams and visualizations using Visio to improve business processes', 'Manage and maintain SharePoint sites and libraries to ensure data accuracy and accessibility', 'Provide ERP analyst support to ensure data accuracy and integrity', 'Identify opportunities for process improvements and automation to increase efficiency and reduce errors']",True,[],,"['SQL', 'Tableau', 'Excel', 'Data Modeling', 'Data Analysis', 'Data Visualization', 'Visio', 'SharePoint', 'ERP Systems', 'Reporting']","SQL: Used to analyze complex data sets to identify trends, patterns, and insights relevant to business opportunities and growth.; Tableau: Employed to develop and maintain reports and dashboards that provide actionable insights to stakeholders.; Excel: Utilized for creating reports and dashboards to visualize data and support decision-making processes.; Data Modeling: Developed and maintained to support business analysis and reporting activities.; Data Analysis: Performed on complex data sets to extract insights and inform business strategies.; Data Visualization: Created using tools like Tableau, Excel, and Visio to present data insights and improve business processes.; Visio: Used to create process flow diagrams and visualizations aimed at improving business processes.; SharePoint: Managed and maintained to ensure data accuracy and accessibility across teams.; ERP Systems: Supported to ensure data accuracy and integrity within enterprise resource planning environments.; Reporting: Involves creating insightful reports and presenting findings to key stakeholders to drive business growth."
MY7BQj-ZMRRZ-_o6AAAAAA==,Senior Data Analyst,"Summary

World Insurance Associates is a unique insurance organization offering top products and services from major providers, combined with attentive service from local agents.

Founded in 2011, World is one of the fastest-growing insurance brokers in the U.S. with over 2,200 employees in over 260 offices across North America. We specialize in personal and commercial insurance lines, surety and bonding, employee benefits, financial and retirement services, and human capital management solutions.

Our rapid growth and market leading presence has created opportunities throughout the state and we offer top talent the choice to work from one of our multiple offices throughout the region.

Position Overview

This position’s primary responsibility will be to provide technical expertise, coordinate day-to-day deliverables for the data analysis & data governance team, manage junior data analysts, and interpret and analyze large datasets. The candidate should be well versed in the fields of analytics, testing, programming, and development; able to research technologies independently to recommend appropriate solutions & should contribute to technology-specific best practices & standards; contribute to success criteria from design through deployment; contribute expertise on significant application components, program languages, databases, operating systems, testing phases etc.

Key Responsibilities
• Conduct in-depth analysis of large datasets to identify trends, patterns, and anomalies
• Data cleansing and preparation, including cleaning and preprocessing raw data to ensure accuracy and reliability, developing and implement data quality standards and working with a team to integrate and automate data pipelines
• Create and maintain comprehensive dashboards and reports for key performance indicators
• Use visualization tools (e.g., Tableau, Power BI) to present complex data in an understandable format
• Provide training and guidance to junior analysts on data visualization best practices
• Self-motivated with ability to work effectively with limited supervision, enthusiasm for collaboration, continuous learning, and a team player.
• Advanced Excel expertise (pivot tables, VLOOKUPS, Power Pivot, functions, etc.)
• Understand importance of code review and automated testing and different levels at which these need to be performed and write and implement tests as required.
• Bachelor’s degree or foreign equivalent from an accredited institution.

Preferred Qualifications
• Experience in design, development, and deployment of BI solutions using PowerBI (DAX, RLS), Python, Pyspark, Google Big query.
• Knowledge or experience in implementing solutions with Microsoft PowerApps, Power Automate, and/or Common Data Service (Power Platform).
• Data Governance, Data Quality, Master Data Management knowledge.
• 5 years of proven experiences as a data analyst
• 5 years of T-SQL language/query experience with data manipulation (SQL) like stored procedures, functions etc.
• Knowledge of data models, data modelling (Relational and Dimensional), Data profiling and working with large data environments.
• Strong communication, team player and advance analytical skills to analyze data issues and drive appropriate actions with data operations and business processes.

Equal Employment Opportunity

At World Insurance Associates (WIA), we celebrate and support our differences. We know employing a team rich in diverse thoughts, experiences, and opinions allows our employees, our products, and our community to flourish. WIA is honored to be an equal opportunity workplace. We are dedicated to equal employment opportunities regardless of race, color, ancestry, religion, sex, national orientation, age, citizenship, marital status, disability, gender identity, sexual orientation, or Veteran status. In addition, WIA makes reasonable accommodations to known physical or mental limitations of an otherwise qualified applicant or employee with a disability, unless the accommodation would impose an undue hardship on the operation of our business.

To Executive Search Firms And Staffing Agencies

World does not accept unsolicited resumes from any agencies that have not signed a mutual service agreement. All unsolicited resumes will be considered World’s property, and World will not be obligated to pay a referral fee. This includes resumes submitted directly to Hiring Managers without contacting World’s Human Resources Talent Department.",2025-07-05T00:00:00.000Z,2025-07-25,"['The candidate should be well versed in the fields of analytics, testing, programming, and development; able to research technologies independently to recommend appropriate solutions & should contribute to technology-specific best practices & standards; contribute to success criteria from design through deployment; contribute expertise on significant application components, program languages, databases, operating systems, testing phases etc', 'Advanced Excel expertise (pivot tables, VLOOKUPS, Power Pivot, functions, etc.)', 'Bachelor’s degree or foreign equivalent from an accredited institution']","['This position’s primary responsibility will be to provide technical expertise, coordinate day-to-day deliverables for the data analysis & data governance team, manage junior data analysts, and interpret and analyze large datasets', 'Conduct in-depth analysis of large datasets to identify trends, patterns, and anomalies', 'Data cleansing and preparation, including cleaning and preprocessing raw data to ensure accuracy and reliability, developing and implement data quality standards and working with a team to integrate and automate data pipelines', 'Create and maintain comprehensive dashboards and reports for key performance indicators', 'Use visualization tools (e.g., Tableau, Power BI) to present complex data in an understandable format', 'Provide training and guidance to junior analysts on data visualization best practices', 'Self-motivated with ability to work effectively with limited supervision, enthusiasm for collaboration, continuous learning, and a team player', 'Understand importance of code review and automated testing and different levels at which these need to be performed and write and implement tests as required']",True,[],,"['Data Analysis', 'Data Cleansing and Preparation', 'Data Pipelines', 'Dashboards and Reporting', 'Data Visualization Tools', 'Advanced Excel', 'SQL and T-SQL', 'Python and PySpark', 'Google BigQuery', 'Business Intelligence (BI) Solutions', 'Data Governance and Data Quality', 'Data Modeling', 'Code Review and Automated Testing']","Data Analysis: Perform in-depth analysis of large datasets to identify trends, patterns, and anomalies relevant to business insights and decision-making.; Data Cleansing and Preparation: Clean and preprocess raw data to ensure accuracy and reliability, develop and implement data quality standards, and collaborate on integrating and automating data pipelines.; Data Pipelines: Work with a team to integrate and automate data pipelines to streamline data processing and ensure data availability for analysis.; Dashboards and Reporting: Create and maintain comprehensive dashboards and reports for key performance indicators to communicate data insights effectively.; Data Visualization Tools: Use tools such as Tableau and Power BI to present complex data in an understandable format and provide training on visualization best practices to junior analysts.; Advanced Excel: Utilize advanced Excel features including pivot tables, VLOOKUPs, Power Pivot, and functions to manipulate and analyze data.; SQL and T-SQL: Use T-SQL language and queries, including stored procedures and functions, for data manipulation and extraction from large data environments.; Python and PySpark: Apply Python and PySpark for data processing, analysis, and development of BI solutions.; Google BigQuery: Leverage Google BigQuery for handling and querying large-scale datasets efficiently.; Business Intelligence (BI) Solutions: Design, develop, and deploy BI solutions using Power BI with capabilities such as DAX and Row-Level Security (RLS).; Data Governance and Data Quality: Implement data governance practices, ensure data quality, and apply master data management principles to maintain data integrity.; Data Modeling: Understand and apply relational and dimensional data modeling techniques to structure data effectively for analysis and reporting.; Code Review and Automated Testing: Recognize the importance of code review and automated testing at various levels and write and implement tests to ensure code quality and reliability."
HGiZwhznwxKGCuoLAAAAAA==,"BlueSnap, Inc is hiring: Senior Data Analyst in Snowflake","Appnext offers end-to-end discovery solutions covering all the touchpoints users have with their devices. Thanks to Appnext’s direct partnerships with top OEM brands and carriers, user engagement is achieved from the moment they personalize their device for the first time and throughout their daily mobile journey.Appnext ‘Timeline’, a patented behavioral analytics technology, is uniquely capable of predicting the apps users are likely to need next. This innovative solution means app developers and marketers can seamlessly engage with users directly on their smartphones through personalized, contextual recommendations.Established in 2012 and now with 12 offices globally, Appnext is the fastest-growing and largest independent mobile discovery platform in emerging markets.We’re looking for a Senior Data Analyst to join our data-driven team at an ad-tech company that thrives on turning complexity into clarity. Our analysts play a critical role in transforming raw, noisy data into accurate, actionable signals that drive real-time decision-making and long-term strategy. You’ll work closely with product, engineering, and business teams to uncover insights, shape KPIs, and guide performance optimization.Responsibilities:Analyze large-scale datasets from multiple sources to uncover actionable insights and drive business impact.Design, monitor, and maintain key performance indicators (KPIs) across ad delivery, bidding, and monetization systems.Partner with product, engineering, and operations teams to define metrics, run deep-dive analyses, and influence strategic decisions.Develop and maintain dashboards, automated reports, and data pipelines to ensure data accessibility and accuracy.Lead investigative analysis of anomalies or unexpected trends in campaign performance, traffic quality, or platform behavior.RequirementsBA / BSc in Industrial Engineering and Management / Information Systems Engineering / Economics / Statistics / Mathematics / similar background.3+ years of experience in Data Analysis and interpretation (Marketing/ Business/ Product).High proficiency in SQL.Experience with data visualization of large data sets using BI systems (Qlik Sense, Sisense, Tableau, Looker, etc.).Experience working with data warehouse/data lake tools like Athena / Redshift / Snowflake /BigQuery.Knowledge of Python - An advantage.Experience building ETL processes – An advantage.Fluent in English both written and spoken - Must
#J-18808-Ljbffr",2025-07-18T00:00:00.000Z,2025-07-25,"['RequirementsBA / BSc in Industrial Engineering and Management / Information Systems Engineering / Economics / Statistics / Mathematics / similar background.3+ years of experience in Data Analysis and interpretation (Marketing/ Business/ Product)', 'High proficiency in SQL', 'Experience with data visualization of large data sets using BI systems (Qlik Sense, Sisense, Tableau, Looker, etc.).Experience working with data warehouse/data lake tools like Athena / Redshift / Snowflake /BigQuery', 'Knowledge of Python - An advantage', 'Experience building ETL processes – An advantage', 'Fluent in English both written and spoken - Must']","['This innovative solution means app developers and marketers can seamlessly engage with users directly on their smartphones through personalized, contextual recommendations', 'You’ll work closely with product, engineering, and business teams to uncover insights, shape KPIs, and guide performance optimization.Responsibilities:Analyze large-scale datasets from multiple sources to uncover actionable insights and drive business impact.Design, monitor, and maintain key performance indicators (KPIs) across ad delivery, bidding, and monetization systems', 'Partner with product, engineering, and operations teams to define metrics, run deep-dive analyses, and influence strategic decisions', 'Develop and maintain dashboards, automated reports, and data pipelines to ensure data accessibility and accuracy', 'Lead investigative analysis of anomalies or unexpected trends in campaign performance, traffic quality, or platform behavior']",True,[],,"['SQL', 'Data Visualization', 'Data Warehousing', 'ETL Processes', 'Python', 'KPI Design and Monitoring', 'Anomaly Detection', 'Data Analysis', 'Dashboard Development', 'Behavioral Analytics']","SQL: Used with high proficiency to query and analyze large-scale datasets from multiple sources to uncover actionable insights and drive business impact.; Data Visualization: Experience with BI tools such as Qlik Sense, Sisense, Tableau, and Looker to visualize large datasets and develop dashboards and automated reports for data accessibility and accuracy.; Data Warehousing: Working knowledge of data warehouse and data lake tools including Athena, Redshift, Snowflake, and BigQuery to manage and analyze large datasets.; ETL Processes: Experience building ETL pipelines to transform and prepare data for analysis and reporting.; Python: Knowledge of Python is considered an advantage for data analysis and interpretation.; KPI Design and Monitoring: Designing, monitoring, and maintaining key performance indicators across ad delivery, bidding, and monetization systems to guide performance optimization.; Anomaly Detection: Leading investigative analysis of anomalies or unexpected trends in campaign performance, traffic quality, or platform behavior.; Data Analysis: Analyzing large-scale datasets from multiple sources to uncover actionable insights, support strategic decisions, and drive business impact.; Dashboard Development: Developing and maintaining dashboards and automated reports to ensure data accessibility and accuracy for stakeholders.; Behavioral Analytics: Utilizing patented behavioral analytics technology to predict user app needs and support personalized, contextual recommendations."
SGkqMM25VxWMZYIlAAAAAA==,Senior Health Data Analyst I,"Overview

The Senior Healthcare Data Analyst I contributes to the overall success of the organization bydeveloping analytic solutions that support activities related to health services utilizationmanagement, care coordination, quality improvement and population health. Through analyzingpatient claims, member enrollment, and other data, the Senior Healthcare Data Analystparticipates in identifying progress, performance and opportunities for improvement onprograms, quality of care, patient experience, and other metrics. This position requires athorough understanding of healthcare data and workflows, combined with an extensiveexperience working with large data sets, conducting data analysis, including standard statisticalsoftware (SAS), and creating reports using Tableau.

Responsibilities
• Works collaboratively with business partners, other analysts, and IT to gather andintegrate data from disparate sources.
• Responds to ad hoc data requests from business units and leadership
• Assists in design and development of data collection strategies, aggregation, analysis,and reporting to ensure data integrity and enhance information value.
• Participates in design and interpretation of data analyses; provides recommendations forimprovement of data quality and reporting.
• Helps build, manage, and/or enhance predictive models
• Assesses reporting and automation requirements and develops appropriate solutions.
• Maintains in-depth knowledge of health plan operations, including claims processing,utilization management, quality improvement activities and pay for performance programs.
• Critically analyzes data, draws conclusions and effectively articulates results.
• Presents data and conclusions to non-technical audience; uses data visualizations andsummaries to highlight key findings.
• Creates and maintains thorough and consistent documentation of programs used tocreate reports.
• Manages and prioritizes workload while meeting deliverables and expectations.
• Works autonomously and collaboratively with report requestors, providing guidance todefine report requirements and validate results.
• Works collaboratively across departments to understand and meet the organization’sanalytic needs.

SECONDARY DUTIES AND RESPONSIBILITIES
• Performs other assigned or needed activities required to assure success of theorganization.
• Participates in special projects as needed.
• Performs other duties as assigned.

General Traits
• Passionate about data, willing to acquire new skills and knowledge, flexible, selfmotivated, and very curious.
• Creative problem-solver, critical thinker, independent worker, data-driven mentality.
• Communicates clearly and directly, relates well to others, engages people, provides and seeks feedback, articulates clearly, actively listens.

Qualifications

Education and Experience

Bachelor’s degree with concentration in health informatics, health administration, public health, computing, epidemiology, statistics or related field, Master’s degree preferred. Minimum four (4) years ofexperience in data analysis and reporting. Knowledge of major health plan operations: healthcare claims processing, membership, provider, and benefits; or equivalent combination of education and experience.Excellent knowledge of data collection, analysis, statistics and data presentation with experience in data mining techniques and procedures. Experience using statistical packages for analyzing large data sets, SAS and/or SQL a plus. Experience working with administrative data, ideally health care data (Medicaid data a plus). Understanding of health data formats including claims, lab and pharmacy. Knowledge of clinical coding systems (e.g., ICD9, ICD10, CPT).

Special Skills, Licenses and Certifications

Proficiency in inferential and predictive statistical analysis. MS Office, Excel, SQL, SAS, Tableau.Ability to present complex information in an understandable and compelling manner.

Performance Based Competencies

Ability to quickly acquire in-depth knowledge of various systems related to claims processing, membership, provider, and benefits at PHC. Strong written and oral communication skills with ability to interpret andunderstand technical requirements. Excellent analytical skills to troubleshoot and resolve data issues. Must be highly organized and proficient at multi-tasking. Must be willing and able to provide gracious assistance to users, providers, and other constituents of PHC.

Work Environment And Physical Demands

More than 50% of work time is spent at a video display terminal.

All HealthPlan employees are expected to:
• Provide the highest possible level of service to clients;
• Promote teamwork and cooperative effort among employees;
• Maintain safe practices; and
• Abide by the HealthPlan’s policies and procedures, as they may from time to time be updated.

HIRING RANGE:

$103,059.95 - $133,977.94

IMPORTANT DISCLAIMER NOTICE

The job duties, elements, responsibilities, skills, functions, experience, educational factors and the requirements and conditions listed in this job description are representative only and not exhaustive or definitive of the tasks that an employee may be required to perform. The employer reserves the right to revise this job description at any time and to require employees to perform other tasks as circumstances or conditions of its business, competitive considerations, or work environment change.",,2025-07-25,"['Passionate about data, willing to acquire new skills and knowledge, flexible, selfmotivated, and very curious', 'Creative problem-solver, critical thinker, independent worker, data-driven mentality', 'Minimum four (4) years ofexperience in data analysis and reporting', 'Knowledge of major health plan operations: healthcare claims processing, membership, provider, and benefits; or equivalent combination of education and experience', 'Excellent knowledge of data collection, analysis, statistics and data presentation with experience in data mining techniques and procedures', 'Understanding of health data formats including claims, lab and pharmacy', 'Knowledge of clinical coding systems (e.g., ICD9, ICD10, CPT)', 'Special Skills, Licenses and Certifications', 'Proficiency in inferential and predictive statistical analysis', 'MS Office, Excel, SQL, SAS, Tableau', 'Ability to present complex information in an understandable and compelling manner', 'Ability to quickly acquire in-depth knowledge of various systems related to claims processing, membership, provider, and benefits at PHC', 'Strong written and oral communication skills with ability to interpret andunderstand technical requirements', 'Excellent analytical skills to troubleshoot and resolve data issues', 'Must be highly organized and proficient at multi-tasking', 'Must be willing and able to provide gracious assistance to users, providers, and other constituents of PHC', 'The employer reserves the right to revise this job description at any time and to require employees to perform other tasks as circumstances or conditions of its business, competitive considerations, or work environment change']","['The Senior Healthcare Data Analyst I contributes to the overall success of the organization bydeveloping analytic solutions that support activities related to health services utilizationmanagement, care coordination, quality improvement and population health', 'Through analyzingpatient claims, member enrollment, and other data, the Senior Healthcare Data Analystparticipates in identifying progress, performance and opportunities for improvement onprograms, quality of care, patient experience, and other metrics', 'This position requires athorough understanding of healthcare data and workflows, combined with an extensiveexperience working with large data sets, conducting data analysis, including standard statisticalsoftware (SAS), and creating reports using Tableau', 'Works collaboratively with business partners, other analysts, and IT to gather andintegrate data from disparate sources', 'Responds to ad hoc data requests from business units and leadership', 'Assists in design and development of data collection strategies, aggregation, analysis,and reporting to ensure data integrity and enhance information value', 'Participates in design and interpretation of data analyses; provides recommendations forimprovement of data quality and reporting', 'Helps build, manage, and/or enhance predictive models', 'Assesses reporting and automation requirements and develops appropriate solutions', 'Maintains in-depth knowledge of health plan operations, including claims processing,utilization management, quality improvement activities and pay for performance programs', 'Critically analyzes data, draws conclusions and effectively articulates results', 'Presents data and conclusions to non-technical audience; uses data visualizations andsummaries to highlight key findings', 'Creates and maintains thorough and consistent documentation of programs used tocreate reports', 'Manages and prioritizes workload while meeting deliverables and expectations', 'Works autonomously and collaboratively with report requestors, providing guidance todefine report requirements and validate results', 'Works collaboratively across departments to understand and meet the organization’sanalytic needs', 'SECONDARY DUTIES AND RESPONSIBILITIES', 'Performs other assigned or needed activities required to assure success of theorganization', 'Participates in special projects as needed', 'Performs other duties as assigned', 'Communicates clearly and directly, relates well to others, engages people, provides and seeks feedback, articulates clearly, actively listens', 'Provide the highest possible level of service to clients;', 'Promote teamwork and cooperative effort among employees;', 'Maintain safe practices; and', 'Abide by the HealthPlan’s policies and procedures, as they may from time to time be updated']",True,[],,"['Healthcare Data Analysis', 'Data Integration', 'Data Collection and Aggregation', 'Statistical Software (SAS)', 'Predictive Modeling', 'Data Reporting and Visualization', 'SQL', 'Data Quality and Validation', 'Healthcare Data Formats and Clinical Coding', 'Inferential and Predictive Statistical Analysis', 'Data Documentation', 'Data Mining Techniques', 'Business Intelligence Tools']","Healthcare Data Analysis: Analyzing patient claims, member enrollment, and other healthcare data to identify progress, performance, and opportunities for improvement on programs, quality of care, patient experience, and other metrics.; Data Integration: Working collaboratively with business partners, analysts, and IT to gather and integrate data from disparate sources to support analytic solutions.; Data Collection and Aggregation: Designing and developing data collection strategies, aggregation, analysis, and reporting to ensure data integrity and enhance information value.; Statistical Software (SAS): Using standard statistical software such as SAS for conducting data analysis on large datasets.; Predictive Modeling: Building, managing, and enhancing predictive models to support healthcare analytics and quality improvement activities.; Data Reporting and Visualization: Creating reports and visualizations using Tableau to present data and conclusions effectively to non-technical audiences.; SQL: Using SQL for querying and managing data as part of data analysis and reporting tasks.; Data Quality and Validation: Participating in the design and interpretation of data analyses, providing recommendations for improving data quality and reporting, and validating report results.; Healthcare Data Formats and Clinical Coding: Understanding health data formats including claims, lab, and pharmacy data, as well as clinical coding systems such as ICD9, ICD10, and CPT.; Inferential and Predictive Statistical Analysis: Applying inferential and predictive statistical techniques to analyze healthcare data and support decision-making.; Data Documentation: Creating and maintaining thorough and consistent documentation of programs used to create reports and analyses.; Data Mining Techniques: Utilizing data mining techniques and procedures to extract insights from large healthcare datasets.; Business Intelligence Tools: Using BI tools like Tableau to develop dashboards and reports that highlight key findings and support organizational analytic needs."
0xpyTuMSpUirqR2vAAAAAA==,Sr. Data Analyst (Excel Modeler) - Locals Only,"Duties:
Develop and maintain complex Excel models for forecasting, planning, and analysis.
Automate data processing and reporting tasks using advanced Excel functions and VBA.
Create dynamic dashboards and visualizations to support decision-making processes.
Ability to consume various data sets and build user friendly excel models for business users.
Develop models to support demand forecasting, supply planning (safety stock/buffer calc.), EOL/NPI Planning and Inventory Reporting.
Assist in the creation of S&OP meeting materials, including data analysis.
Write and optimize SQL queries to extract and manipulate data from various databases (Google Cloud Platform).
Integrate SQL data with Excel models and Tableau to ensure accurate and up-to-date reporting.
Assist in the maintenance and improvement of SQL databases to support business needs.
Ensure data accuracy and consistency across various reporting tools and platforms.
Collaborate with stakeholders to understand requirements and build excel models that can support the business.
Document processes and logic behind automation.

Key Skills:
Advanced proficiency in Excel, including functions, pivot tables, and VBA.
Ability to write SQL Queries
Ability to consume and analyze large sets of data
Understanding of Supply Chain Planning is a plus
Excellent Analytical and Problem-Solving Skills
Strong Communication skills and should be able to collaborate with multiple teams
Knowledge of statistical analysis and forecasting models

Education:
Bachelor's in business, Supply Chain, Data Science or related field",,2025-07-25,"['Advanced proficiency in Excel, including functions, pivot tables, and VBA', 'Ability to write SQL Queries', 'Ability to consume and analyze large sets of data', 'Excellent Analytical and Problem-Solving Skills', 'Strong Communication skills and should be able to collaborate with multiple teams', 'Knowledge of statistical analysis and forecasting models', ""Bachelor's in business, Supply Chain, Data Science or related field""]","['Develop and maintain complex Excel models for forecasting, planning, and analysis', 'Automate data processing and reporting tasks using advanced Excel functions and VBA', 'Create dynamic dashboards and visualizations to support decision-making processes', 'Ability to consume various data sets and build user friendly excel models for business users', 'Develop models to support demand forecasting, supply planning (safety stock/buffer calc.), EOL/NPI Planning and Inventory Reporting', 'Assist in the creation of S&OP meeting materials, including data analysis', 'Write and optimize SQL queries to extract and manipulate data from various databases (Google Cloud Platform)', 'Integrate SQL data with Excel models and Tableau to ensure accurate and up-to-date reporting', 'Assist in the maintenance and improvement of SQL databases to support business needs', 'Ensure data accuracy and consistency across various reporting tools and platforms', 'Collaborate with stakeholders to understand requirements and build excel models that can support the business', 'Document processes and logic behind automation']",True,[],,"['Excel Modeling', 'SQL', 'Forecasting Models', 'Data Visualization and BI Tools', 'Data Analysis', 'Automation with VBA']","Excel Modeling: Develop and maintain complex Excel models for forecasting, planning, and analysis; build user-friendly Excel models for business users; automate data processing and reporting tasks using advanced Excel functions and VBA; create dynamic dashboards and visualizations to support decision-making.; SQL: Write and optimize SQL queries to extract and manipulate data from various databases including Google Cloud Platform; integrate SQL data with Excel models and Tableau to ensure accurate and up-to-date reporting; assist in the maintenance and improvement of SQL databases to support business needs.; Forecasting Models: Develop models to support demand forecasting, supply planning including safety stock and buffer calculations, EOL/NPI planning, and inventory reporting; apply knowledge of statistical analysis and forecasting models to support business planning.; Data Visualization and BI Tools: Create dynamic dashboards and visualizations using Excel and Tableau to support decision-making processes and ensure accurate reporting.; Data Analysis: Consume and analyze large data sets to support business needs; assist in the creation of S&OP meeting materials through data analysis; ensure data accuracy and consistency across various reporting tools and platforms.; Automation with VBA: Automate data processing and reporting tasks using VBA within Excel to improve efficiency and accuracy."
H_0d6MgIKt-jSxCtAAAAAA==,Senior Data Analyst,"The Scaled Solutions and Insights Data Analyst mission is to empower the Operations Service Center stakeholders with a range of data products and technical solutions to help them gather deeper insights and intelligence to amplify business outcomes in alignment to core priorities and strategic planning.

We are looking for aSenior Data Analyst who is willing to work in a dynamic environment. You will need to be adept at managing business change, evolving requirements, adjustments in a strategic direction, and emerging technologies. This is an amazing opportunity to be at the center of building a showcase worthy data capability, the successful candidates should have proven experience in working with ambiguity, program management, a understanding of business and engineering priorities, analytical, financial, organizational and delivery skills.

Microsoft's mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.

Responsibilities:
• Business and Data Landscape: Apply in-depth knowledge of the business, evolving data landscape, tools, and technologies to link business topics to relevant data sources and external trends. Anticipate data and business requirements, develop data frames and analytical solutions, and identify opportunities to enhance or automate data infrastructure and analyses .
• Customer/Stakeholder Orientation: Understand customer needs and perspectives, validate requirements, and deliver accessible data insights and tools. Build trust by leveraging knowledge of Microsoft products and solutions, interpreting data within relevant contexts, and articulating key details to drive realistic customer expectations.
• Expertise in Data: Applies expertise in data sources, formats, and quality to identify and leverage data across multiple sources, understands data requirements, and evaluates the sufficiency of data for addressing relevant and impactful business questions. Determines and leverages optimal methods and tools for integrating data and proactively works to identify and address data integrity, quality, and/or access issues. Recommends opportunities to build new data pipelines or integrations to better meet requirements, and initiates collaborative action to source additional data. Develops and/or recommends initial/prototype data models and/or tools for others' consumption, leverages relevant data and frameworks from other teams, and escalates complex issues with data or data models to appropriate Engineering or Data-Science teams.
• Data Analysis: Applies expertise in data, business, and customer needs to evaluate and determine ideal analytical and statistical techniques to address business and/or research questions. Guides and establishes partnerships with others to execute complex analyses, resolve analytical challenges, interpret results across relevant contexts, and provide actionable recommendations. Critically evaluates the choice of tools, techniques, and assumptions to highlight potential gaps and ensure they are utilized appropriately within context, that outcomes align with business and/or research needs, and provides feedback on features and functions of analytical tools and/or models. Anticipates the risks of data leakage, analytical tradeoffs, methodological limitations, etc., and can guide teammates on solutions.
• Reporting and Sharing Results: Share insights through dashboards, reports, data visualizations, and interactive self-service platforms. Synthesize and simplify details across analyses to highlight relevant findings and inform business decisions.
• Experimentation and Innovation: Design and execute formal experiments or prototypes to evaluate the impact of new features or processes. Partner cross-functionally to advise on experimental design and evaluation frameworks, and make data-driven recommendations for strategic business goals.
• Improvement and Efficiency: Promote methods for efficient analytics and reporting, automate ad-hoc analyses, and participate in peer reviews to ensure quality and relevance. Recommend and socialize optimal methods for operationalizing, sharing, and scaling insights . Shares critical domain expertise to create clarity, ensure readiness to appropriately consume and leverage data and/or insights, and evaluate the viability of automated methods for use in data collection, reporting, and/or analysis.
• Data Model Evaluation: Understands and evaluates the relationship between analytical model(s) and business objectives , highlight gaps, and present s findings to senior stakeholders. Establish clear linkage between generated data models and desired business objectives . Coaches and mentors less experienced analysts as needed.
• O rchestration and Collaboration: Collaborate with internal stakeholders to ensure quality execution of data sourcing, analysis, and the adoption of best practices. Leverage expertise to identify areas for innovation and address evolving business needs .
• Data Privacy and Governance: Maintain expertise in data privacy and security requirements, ensure compliance with regulations, and enforce standards related to data usage and handling. Guide others to uphold and apply updated data privacy and governance standards.
Other
• E mbody our culture and values

Qualifications:

Required/Minimum Qualifications
• Bachelor's Degree in Statistics, Mathematics, Analytics, Data Science, Engineering, Computer Science, Business, Economics or related field AND 4+ years experience in data analysis and reporting, data science, business intelligence, or business and financial analysis
• *
• OR Master's Degree in Mathematics, Analytics, Engineering, Computer Science, Marketing, Business, Economics or related field AND 2+ years' experience in data analysis and reporting, business intelligence, or business and financial analysis
• OR equivalent experience.
• 4+ years experience managing business change, evolving requirements, adjustments in a strategic direction, OR emerging technologies (ie. Artificial Intelligence).
Additional/ Preferred Qualifications
• Bachelor's Degree in Statistics, Mathematics, Analytics, Engineering, Computer Science, Marketing, Business, Economics or related field AND 6+ years' experience in data analysis and reporting, business intelligence, or business and financial analysis
• * OR Master's Degree in Mathematics, Analytics, Engineering, Computer Science, Marketing, Business, Economics or related field AND 4+ years experience in data analysis and reporting, business intelligence, or business and financial analysis
• OR equivalent experience

Business Analytics IC4 - The typical base pay range for this role across the U.S. is USD $106,400 - $203,600 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $137,600 - $222,600 per year.

Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here: https://careers.microsoft.com/us/en/us-corporate-pay

Microsoft will accept applications for the role until May 30,2025

Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form .

Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.",,2025-07-25,"['You will need to be adept at managing business change, evolving requirements, adjustments in a strategic direction, and emerging technologies', 'This is an amazing opportunity to be at the center of building a showcase worthy data capability, the successful candidates should have proven experience in working with ambiguity, program management, a understanding of business and engineering priorities, analytical, financial, organizational and delivery skills', 'O rchestration and Collaboration: Collaborate with internal stakeholders to ensure quality execution of data sourcing, analysis, and the adoption of best practices', 'Data Privacy and Governance: Maintain expertise in data privacy and security requirements, ensure compliance with regulations, and enforce standards related to data usage and handling', ""Bachelor's Degree in Statistics, Mathematics, Analytics, Data Science, Engineering, Computer Science, Business, Economics or related field AND 4+ years experience in data analysis and reporting, data science, business intelligence, or business and financial analysis"", ""OR Master's Degree in Mathematics, Analytics, Engineering, Computer Science, Marketing, Business, Economics or related field AND 2+ years' experience in data analysis and reporting, business intelligence, or business and financial analysis"", 'OR equivalent experience', '4+ years experience managing business change, evolving requirements, adjustments in a strategic direction, OR emerging technologies (ie']","['The Scaled Solutions and Insights Data Analyst mission is to empower the Operations Service Center stakeholders with a range of data products and technical solutions to help them gather deeper insights and intelligence to amplify business outcomes in alignment to core priorities and strategic planning', 'We are looking for aSenior Data Analyst who is willing to work in a dynamic environment', 'Business and Data Landscape: Apply in-depth knowledge of the business, evolving data landscape, tools, and technologies to link business topics to relevant data sources and external trends', 'Anticipate data and business requirements, develop data frames and analytical solutions, and identify opportunities to enhance or automate data infrastructure and analyses ', 'Customer/Stakeholder Orientation: Understand customer needs and perspectives, validate requirements, and deliver accessible data insights and tools', 'Build trust by leveraging knowledge of Microsoft products and solutions, interpreting data within relevant contexts, and articulating key details to drive realistic customer expectations', 'Expertise in Data: Applies expertise in data sources, formats, and quality to identify and leverage data across multiple sources, understands data requirements, and evaluates the sufficiency of data for addressing relevant and impactful business questions', 'Determines and leverages optimal methods and tools for integrating data and proactively works to identify and address data integrity, quality, and/or access issues', 'Recommends opportunities to build new data pipelines or integrations to better meet requirements, and initiates collaborative action to source additional data', ""Develops and/or recommends initial/prototype data models and/or tools for others' consumption, leverages relevant data and frameworks from other teams, and escalates complex issues with data or data models to appropriate Engineering or Data-Science teams"", 'Data Analysis: Applies expertise in data, business, and customer needs to evaluate and determine ideal analytical and statistical techniques to address business and/or research questions', 'Guides and establishes partnerships with others to execute complex analyses, resolve analytical challenges, interpret results across relevant contexts, and provide actionable recommendations', 'Critically evaluates the choice of tools, techniques, and assumptions to highlight potential gaps and ensure they are utilized appropriately within context, that outcomes align with business and/or research needs, and provides feedback on features and functions of analytical tools and/or models', 'Anticipates the risks of data leakage, analytical tradeoffs, methodological limitations, etc., and can guide teammates on solutions', 'Reporting and Sharing Results: Share insights through dashboards, reports, data visualizations, and interactive self-service platforms', 'Synthesize and simplify details across analyses to highlight relevant findings and inform business decisions', 'Experimentation and Innovation: Design and execute formal experiments or prototypes to evaluate the impact of new features or processes', 'Partner cross-functionally to advise on experimental design and evaluation frameworks, and make data-driven recommendations for strategic business goals', 'Improvement and Efficiency: Promote methods for efficient analytics and reporting, automate ad-hoc analyses, and participate in peer reviews to ensure quality and relevance', 'Recommend and socialize optimal methods for operationalizing, sharing, and scaling insights ', 'Shares critical domain expertise to create clarity, ensure readiness to appropriately consume and leverage data and/or insights, and evaluate the viability of automated methods for use in data collection, reporting, and/or analysis', 'Data Model Evaluation: Understands and evaluates the relationship between analytical model(s) and business objectives , highlight gaps, and present s findings to senior stakeholders', 'Establish clear linkage between generated data models and desired business objectives ', 'Coaches and mentors less experienced analysts as needed', 'Leverage expertise to identify areas for innovation and address evolving business needs ', 'Guide others to uphold and apply updated data privacy and governance standards']",True,[],,"['Data Pipelines', 'Data Analysis', 'Data Visualization and Reporting', 'Data Quality and Integrity', 'Data Modeling', 'Statistical and Analytical Techniques', 'Experimentation and A/B Testing', 'Business Intelligence (BI)', 'Data Privacy and Governance', 'Data Integration']","Data Pipelines: Recommends opportunities to build new data pipelines or integrations to better meet requirements and initiates collaborative action to source additional data.; Data Analysis: Applies expertise in data, business, and customer needs to evaluate and determine ideal analytical and statistical techniques to address business and/or research questions, guides and establishes partnerships to execute complex analyses, resolve analytical challenges, interpret results, and provide actionable recommendations.; Data Visualization and Reporting: Shares insights through dashboards, reports, data visualizations, and interactive self-service platforms to synthesize and simplify details across analyses and inform business decisions.; Data Quality and Integrity: Determines and leverages optimal methods and tools for integrating data and proactively works to identify and address data integrity, quality, and/or access issues.; Data Modeling: Develops and/or recommends initial or prototype data models and/or tools for others' consumption, evaluates the relationship between analytical models and business objectives, highlights gaps, and presents findings to senior stakeholders.; Statistical and Analytical Techniques: Critically evaluates the choice of tools, techniques, and assumptions to highlight potential gaps, ensures appropriate utilization within context, anticipates risks such as data leakage and methodological limitations, and provides feedback on analytical tools and models.; Experimentation and A/B Testing: Designs and executes formal experiments or prototypes to evaluate the impact of new features or processes, partners cross-functionally to advise on experimental design and evaluation frameworks, and makes data-driven recommendations for strategic business goals.; Business Intelligence (BI): Delivers accessible data insights and tools, builds trust by leveraging knowledge of Microsoft products and solutions, and promotes methods for efficient analytics and reporting including automation of ad-hoc analyses.; Data Privacy and Governance: Maintains expertise in data privacy and security requirements, ensures compliance with regulations, enforces standards related to data usage and handling, and guides others to uphold and apply updated data privacy and governance standards.; Data Integration: Identifies and leverages data across multiple sources, understands data requirements, evaluates sufficiency of data for business questions, and recommends integration methods to enhance data infrastructure and analyses."
XBuBBdrd6I1FWh3EAAAAAA==,"Senior Data Analyst, Demand Modeling (Revenue Growth Management)","McDonald's is a global leader in the Quick Service Restaurant industry focusing on revenue growth through innovative pricing strategies and advanced analytics. The company is looking for a highly skilled analyst to address complex challenges in revenue management. This role involves managing pricing tests across various markets and utilizing advanced analytical techniques for pricing strategies. Additionally, it includes applying machine learning methods to develop solutions that drive revenue growth.",,2025-07-25,,"['This role involves managing pricing tests across various markets and utilizing advanced analytical techniques for pricing strategies', 'Additionally, it includes applying machine learning methods to develop solutions that drive revenue growth']",True,[],,"['Pricing Tests', 'Advanced Analytical Techniques', 'Machine Learning']",Pricing Tests: Managing pricing tests across various markets to evaluate and optimize pricing strategies for revenue growth.; Advanced Analytical Techniques: Utilizing advanced analytical methods to develop and refine pricing strategies in revenue management.; Machine Learning: Applying machine learning methods to develop solutions that drive revenue growth through improved pricing and demand modeling.
dzZVz-TjVghNE55KAAAAAA==,Senior Data Analyst,"Headquartered in Dublin, Ohio, Cardinal Health, Inc. (NYSE: CAH) is a global, integrated healthcare services and products company, providing customized solutions for hospitals, health systems, pharmacies, ambulatory surgery centers, clinical laboratories and physician offices worldwide.
• *Department Overview:**

At Navista, our mission is to empower community oncology practices to deliver patient-centered cancer care. Navista, a Cardinal Health company, is an oncology practice alliance co-created with oncologists and practice leaders that offers advanced support services and technology to help practices remain independent and thrive. True to our name, our experienced team is passionate about helping oncology practices navigate the future.

We are currently hiring for a **Senior Data Analyst** within Navista - Data & Advanced Analytics team to support the growth of our Navista Application Suite and the Integrated Oncology Network (IoN).

The Data & Analytics Function oversees the analytics lifecycle to identify, analyze and present relevant insights that drive business decisions and anticipate opportunities to achieve a competitive advantage. This function manages analytic data platforms, the access, design and implementation of reporting/business intelligence solutions, and the application of advanced quantitative modeling.
• *Job Overview:**

As a **Senior Data Analyst** , you will work cross-functionally to solve problems by performing analysis, recommending solutions, and building analytic products to enable better decision making in the following areas:

+ Revenue Cycle Management

+ Practice Performance Insights

+ Metrics/Performance reporting
• *Responsibilities:**

+ Applies knowledge of business processes, systems, data, and analytical tools to explore and identify root causes of problems.

+ System monitoring to ensure processes are executing as expected and correcting issue to ensure purchase orders and receiving not impacted by errors.

+ Partner with cross-functional project teams to ideate, develop, and recommend solutions. Listen to partners and ask questions to clearly define and document business problems.

+ Perform exploratory analysis to determine root causes of problems and confirm / reject hypotheses.

+ Apply advanced analytics methodologies to model, analyze and clean datasets

+ Recommend ways to improve performance and assist with rationalization of the multi-cloud platform.

+ Summarize the financial and operational impact of the recommendation and pros/cons of alternatives considered.

+ Work with Data Engineers to create data models for analysis, reporting and help create standard reporting of metrics.

+ Lead analytics projects and initiatives that drive meaningful ROI. Guide business teams/partners towards solving their analytical problems.

+ Acts as a mentor to less experienced colleagues

+ Independently determines method for completion of new projects

+ Works on or may lead complex projects of large scope

+ Problem solver, Self-Starter, team player, high EQ.
• *Qualifications:**

Required proven experience in the following:

+ Bachelor's Degree in related field, or equivalent work experience, preferred

+ Strong SQL background required.

+ Multi Cloud experience - GCP, Azure preferred.

+ 8-12 years of experience, preferred

+ 5+ years of experience in Business Intelligence tools such as Power BI preferred.

+ Healthcare analytics, value-based care experience preferred

+ Experience in writing complex SQL queries, stored procedures, etc.

+ Have excellent verbal and oral communication skills

+ Experience in Agile methodologies preferred

+ Experience in Version control and CI/CD pipelines.

+ Oncology data experience preferred

+ RCM experience is a plus
• *Anticipated salary range:** $103,500 - $147,900
• *Bonus eligible:** Yes
• *Benefits:** Cardinal Health offers a wide variety of benefits and programs to support health and well-being.

+ Medical, dental and vision coverage

+ Paid time off plan

+ Health savings account (HSA)

+ 401k savings plan

+ Access to wages before pay day with myFlexPay

+ Flexible spending accounts (FSAs)

+ Short- and long-term disability coverage

+ Work-Life resources

+ Paid parental leave

+ Healthy lifestyle programs
• *Application window anticipated to close:** 7/28/2025 *if interested in opportunity, please submit application as soon as possible.

The salary range listed is an estimate. Pay at Cardinal Health is determined by multiple factors including, but not limited to, a candidate's geographical location, relevant education, experience and skills and an evaluation of internal pay equity.

_Candidates who are back-to-work, people with disabilities, without a college degree, and Veterans are encouraged to apply._

_Cardinal Health supports an inclusive workplace that values diversity of thought, experience and background. We celebrate the power of our differences to create better solutions for our customers by ensuring employees can be their authentic selves each day. Cardinal Health is an Equal_ _Opportunity/Affirmative_ _Action employer. All qualified applicants will receive consideration for employment without regard to race, religion, color, national origin, ancestry, age, physical or mental disability, sex, sexual orientation, gender identity/expression, pregnancy, veteran status, marital status, creed, status with regard to public assistance, genetic status or any other status protected by federal, state or local law._

_To read and review this privacy notice click_ here (https://www.cardinalhealth.com/content/dam/corp/email/documents/corp/cardinal-health-online-application-privacy-policy.pdf)",,2025-07-25,"['Required proven experience in the following:', 'Strong SQL background required', 'Experience in writing complex SQL queries, stored procedures, etc', 'Have excellent verbal and oral communication skills', 'Experience in Version control and CI/CD pipelines', 'Medical, dental and vision coverage', 'Flexible spending accounts (FSAs)', 'Short- and long-term disability coverage', 'Healthy lifestyle programs', '*Application window anticipated to close:*']","['The Data & Analytics Function oversees the analytics lifecycle to identify, analyze and present relevant insights that drive business decisions and anticipate opportunities to achieve a competitive advantage', 'This function manages analytic data platforms, the access, design and implementation of reporting/business intelligence solutions, and the application of advanced quantitative modeling', 'As a **Senior Data Analyst** , you will work cross-functionally to solve problems by performing analysis, recommending solutions, and building analytic products to enable better decision making in the following areas:', 'Revenue Cycle Management', 'Practice Performance Insights', 'Metrics/Performance reporting', 'Applies knowledge of business processes, systems, data, and analytical tools to explore and identify root causes of problems', 'System monitoring to ensure processes are executing as expected and correcting issue to ensure purchase orders and receiving not impacted by errors', 'Partner with cross-functional project teams to ideate, develop, and recommend solutions', 'Listen to partners and ask questions to clearly define and document business problems', 'Perform exploratory analysis to determine root causes of problems and confirm / reject hypotheses', 'Apply advanced analytics methodologies to model, analyze and clean datasets', 'Recommend ways to improve performance and assist with rationalization of the multi-cloud platform', 'Summarize the financial and operational impact of the recommendation and pros/cons of alternatives considered', 'Work with Data Engineers to create data models for analysis, reporting and help create standard reporting of metrics', 'Lead analytics projects and initiatives that drive meaningful ROI', 'Guide business teams/partners towards solving their analytical problems', 'Acts as a mentor to less experienced colleagues', 'Independently determines method for completion of new projects', 'Works on or may lead complex projects of large scope', 'Problem solver, Self-Starter, team player, high EQ']",True,[],,"['SQL', 'Business Intelligence Tools', 'Advanced Analytics Methodologies', 'Data Modeling', 'Multi-Cloud Platforms', 'Exploratory Data Analysis', 'Analytics Lifecycle Management', 'Revenue Cycle Management Analytics', 'Performance Metrics and Reporting', 'Version Control and CI/CD Pipelines']","SQL: Used extensively for writing complex queries and stored procedures to extract and manipulate data for analysis and reporting.; Business Intelligence Tools: Utilized tools such as Power BI to design and implement reporting solutions and dashboards that support decision making and performance monitoring.; Advanced Analytics Methodologies: Applied to model, analyze, and clean datasets to identify root causes of problems and recommend solutions that improve business performance.; Data Modeling: Collaborated with Data Engineers to create data models that facilitate analysis, reporting, and standardization of metrics.; Multi-Cloud Platforms: Experience with cloud environments like GCP and Azure to support data platform rationalization and performance improvements.; Exploratory Data Analysis: Performed to investigate data, confirm or reject hypotheses, and identify root causes of business problems.; Analytics Lifecycle Management: Oversaw the end-to-end process of identifying, analyzing, and presenting insights that drive business decisions and competitive advantage.; Revenue Cycle Management Analytics: Analyzed financial and operational data related to revenue cycle processes to support better decision making.; Performance Metrics and Reporting: Developed and maintained metrics and performance reports to provide insights into practice performance and operational effectiveness.; Version Control and CI/CD Pipelines: Used to manage code and automate deployment processes, ensuring reliable and repeatable analytics solutions."
Qu0mEm0SXfGskamgAAAAAA==,Sr. Financial Data Analyst x  100K - 110K + bonus + equity x East LA,"Senior Financial Analyst – Sr. Financial Analyst – Senior Business Analyst – Sr. Business Analyst – SQL – Senior Data Analyst – Salesforce – Alteryx – Power BI – Tableau – Lookr

Are you an experienced data savvy Financial Analyst OR Data Analyst who understands the ins and outs around finance? If so, then we are working on a Senior Financial Data Analyst opportunity that would be a great fit for your skillsets. Read more about the opportunity below!

An East LA start up is looking for a Senior Financial Data Analyst to join their team. Reporting to the VP of Finance, the Senior Financial Data Analyst will be responsible for analyzing large datasets, trend analysis, working with SQL databases, elevating processes, and supporting strategy. To be successful in this Senior Financial Data Analyst role, this person should have executive presentation, be detail-oriented, and be very data analytical. Does this sound like you or someone you know? If so, then please read the Senior Financial Data Analyst full job description below to see if this could be your next role!

What do you need for this Senior Financial Data Analyst role?
• Bachelor’s Degree in Computer Science, Economics, Finance, or related degree
• 4+ years of experience
• MUST be savvy with SQL and Salesforce
• Data visualization software experience is a plus

What will you do in this Senior Financial Data Analyst role?
• Create, upkeep, and verify data integrity, process efficiencies, and related reporting
• Analyze and clean up data to resolve disparities, and verify data integrity, reliability, and accuracy
• Load, change, and take data from multiple areas into our database to be used by finance and accounting teams
• Provide insights and recommendations through data utilization
• Assist with trend forecasts, risk assessment, and financial projections
• Analyze revenue and cost date to create margin analysis for reporting
• Assist with budgeting, forecasting, planning, and resource allocation
• Prepare data visualization and create dashboards
• Conduct cost-benefit analysis and analyze ROI
• Support strategic initiatives with financial evaluations
• Maintain accuracy and organization of data
• Support design of ERP solutions and integrations to maintain data integrity and consistency
• Act as a solutions design and architecture lead while looking for ways to optimize platforms
• Outline and maintain compliance around governance policies for the company’s systems

What is in this Senior Financial Data Analyst role for you?
• Company operates on a unique model within their business
• More than 100 locations and growing
• In series C (and has other funding) and on an exit path
• Unlimited PTO, holiday shut down, 401K match
• Bonus and equity
• Lots of room for growth

So, if you are a financial-minded Data Analyst looking for your next opportunity, then we would like to see your resume for this Senior Financial Data Analyst role. Please send it our way as we would love to connect!",,2025-07-25,"['To be successful in this Senior Financial Data Analyst role, this person should have executive presentation, be detail-oriented, and be very data analytical', 'Bachelor’s Degree in Computer Science, Economics, Finance, or related degree', '4+ years of experience', 'MUST be savvy with SQL and Salesforce']","['Reporting to the VP of Finance, the Senior Financial Data Analyst will be responsible for analyzing large datasets, trend analysis, working with SQL databases, elevating processes, and supporting strategy', 'Create, upkeep, and verify data integrity, process efficiencies, and related reporting', 'Analyze and clean up data to resolve disparities, and verify data integrity, reliability, and accuracy', 'Load, change, and take data from multiple areas into our database to be used by finance and accounting teams', 'Provide insights and recommendations through data utilization', 'Assist with trend forecasts, risk assessment, and financial projections', 'Analyze revenue and cost date to create margin analysis for reporting', 'Assist with budgeting, forecasting, planning, and resource allocation', 'Prepare data visualization and create dashboards', 'Conduct cost-benefit analysis and analyze ROI', 'Support strategic initiatives with financial evaluations', 'Maintain accuracy and organization of data', 'Support design of ERP solutions and integrations to maintain data integrity and consistency', 'Act as a solutions design and architecture lead while looking for ways to optimize platforms', 'Outline and maintain compliance around governance policies for the company’s systems']",True,[],,"['SQL', 'Salesforce', 'Data Visualization Tools', 'Trend Analysis', 'Data Integrity and Cleaning', 'Financial Forecasting and Budgeting', 'Cost-Benefit and ROI Analysis', 'ERP Solutions and Integrations', 'Dashboard and Reporting']","SQL: Used for working with databases to analyze large datasets, load and change data from multiple areas, and support finance and accounting teams.; Salesforce: Utilized as a data platform requiring proficiency to manage and analyze financial data.; Data Visualization Tools: Experience with tools like Power BI, Tableau, and Looker is used to prepare data visualizations and create dashboards for reporting and insights.; Trend Analysis: Applied to analyze financial data trends, assist with forecasting, risk assessment, and financial projections.; Data Integrity and Cleaning: Responsibilities include creating, verifying, and maintaining data integrity, resolving data disparities, and ensuring data accuracy and reliability.; Financial Forecasting and Budgeting: Involves assisting with budgeting, forecasting, planning, and resource allocation based on analyzed data.; Cost-Benefit and ROI Analysis: Conducted to evaluate financial performance and support strategic initiatives through financial evaluations.; ERP Solutions and Integrations: Supporting the design and integration of ERP systems to maintain data integrity and consistency across platforms.; Dashboard and Reporting: Creating dashboards and reports to provide insights and recommendations for financial strategy and decision-making."
oZYCoKZJuovlcPk8AAAAAA==,Senior Data Analyst,"Join to apply for the Senior Data Analyst role at HCSS Join to apply for the Senior Data Analyst role at HCSS We’re HCSS . We’re a software company based in Sugar Land, TX and we provide innovative solutions for the construction industry that helps streamline their operations. Our mission at HCSS is helping customers achieve excellence through our proven, customer-centric, end-to-end solutions and exceptionally helpful service, while providing a great life for our employees. With this mission at the forefront of everything we do, we’re recognized as a pioneer and leader in our market and have been recognized for our award-winning culture year after year, earning honors for 16 consecutive years as one of the best places to work in Texas. WHO WE NEED : We are seeking an experienced Senior Data Analyst to lead our data-driven initiatives and drive strategic decision-making across the organization. The ideal candidate will have 5+ years of experience in data analytics , with expertise in advanced data modeling, automation, and business intelligence solutions. This role requires a deep understanding of data architecture, the ability to mentor junior analysts, and strong collaboration with cross-functional teams to deliver impactful insights. Qualifications Bachelor’s or Master’s degree in Business Intelligence, Data Science, Computer Science, Statistics, or a related field. Advanced proficiency in Power BI, including DAX, Power Query, and Power BI Report Builder. Strong SQL skills, with experience in database management, performance tuning, and optimization. Hands-on experience with Microsoft Azure services such as Azure Synapse, Azure Data Factory, and Databricks. Familiarity with CI/CD pipelines and version control systems such as Git for analytics workflow management. Demonstrated ability to translate business requirements into scalable, data-driven solutions and communicate insights effectively to both technical and non-technical stakeholders. Preferred Skills Experience with Python for automation or predictive analytics. Understanding of machine learning techniques, including classification, regression, and clustering. Knowledge of data governance, compliance, and security best practices. Certifications such as Microsoft Certified: Data Analyst Associate or relevant Azure/cloud certifications. Proven ability to coach and mentor junior analysts, fostering a culture of learning and data excellence. What You’ll Do Requirements Gathering – Partner with stakeholders to understand reporting needs and deliver targeted analytical solutions. Data Visualization & Storytelling – Build interactive dashboards that clearly communicate insights and drive action. Data Integration – Work closely with data engineering teams to ensure accurate and consistent data from multiple sources. Data Governance – Maintain high standards of data quality, consistency, and security in reporting and analysis. Collaboration – Engage with cross-functional teams, including product, operations, and leadership, to identify opportunities for data-driven improvement. Continuous Improvement – Stay current with BI and analytics trends, tools, and best practices to enhance team capabilities continuously. BENEFITS & PERKS :Part of our mission statement is to provide a great life for our employees. We believe that happy employees make for a better company, so we take care of them. Here are a few of the perks we offer: Flexibility for you to work in-office, remote or hybrid. Medical and Dental Premiums. On-site amenities include a covered basketball court, soccer field, 200-meter track, etc. 401K with match. Tuition reimbursement. And more! Seniority level Seniority level Mid-Senior level Employment type Employment type Full-time Job function Job function Information Technology Industries Software Development Referrals increase your chances of interviewing at HCSS by 2x Sign in to set job alerts for “Senior Data Analyst” roles. Sr Analyst Supply Chain Data and Analytics Foundation Senior IT Data Specialist - Hybrid Greater Houston $85,000.00-$110,000.00 11 hours ago Middle Office / Business Analyst - Aviation Houston, TX $50,000.00-$80,000.00 3 weeks ago Senior Business Analyst - AOCT Administration Houston, TX $50,200.00-$107,400.00 2 weeks ago Houston, TX $65,000.00-$70,000.00 1 day ago Business Analyst with data modeling and system integration across platforms like RADAR, GMAS, and B Houston, TX $72,821.00-$83,745.00 1 week ago Houston, TX $77,500.00-$131,500.00 14 hours ago Senior Business Analyst - Energy Trading Risk Management Systems Houston, TX $90,000.00-$140,000.00 1 week ago Senior Business Analyst Hybrid Role Fortune 100 CO Direct Hire (Hiring ASAP) Houston, TX $110,000.00-$115,000.00 4 weeks ago Business Analyst - Default Systems and Support - (On - Site) Business Analyst With Oracle JDE/EBS - Full Time Business Analyst - Digital Transformation- Relocate to Saudi Arabia Business Analyst - Hosp Ops - Day Shift - Ben Taub We’re unlocking community knowledge in a new way. Experts add insights directly into each article, started with the help of AI. #J-18808-Ljbffr",2025-07-17T00:00:00.000Z,2025-07-25,,,True,[],,"['Data Modeling', 'Business Intelligence', 'Power BI', 'SQL', 'Microsoft Azure Data Services', 'CI/CD Pipelines and Version Control', 'Python', 'Machine Learning Techniques', 'Data Governance']","Data Modeling: Used for advanced data modeling to support data-driven initiatives and strategic decision-making across the organization.; Business Intelligence: Development and delivery of business intelligence solutions including building interactive dashboards to communicate insights and drive action.; Power BI: Advanced proficiency required, including use of DAX, Power Query, and Power BI Report Builder for data visualization and reporting.; SQL: Strong skills needed for database management, performance tuning, and optimization to support data analytics workflows.; Microsoft Azure Data Services: Hands-on experience with Azure Synapse, Azure Data Factory, and Databricks for data integration and processing.; CI/CD Pipelines and Version Control: Familiarity with CI/CD pipelines and version control systems such as Git to manage analytics workflow and ensure reproducibility.; Python: Used for automation and predictive analytics tasks within the data analytics function.; Machine Learning Techniques: Understanding of classification, regression, and clustering methods to support predictive analytics and data modeling.; Data Governance: Maintaining high standards of data quality, consistency, security, and compliance in reporting and analysis."
ZtzBT9B1LQq8HckrAAAAAA==,Data Analyst (Senior),"Join to apply for the Data Analyst (Senior) role at ProSoDel (Professional Solutions Delivered, LLC)
2 months ago Be among the first 25 applicants
Join to apply for the Data Analyst (Senior) role at ProSoDel (Professional Solutions Delivered, LLC)
Get AI-powered advice on this job and more exclusive features.
Professional Solutions Delivered, LLC (ProSoDel) is a total solutions provider for government and commercial customers in the areas of Program Management, Logistics, Organizational Change Management, Communications, Training, and Information Technology (IT) Support Services. We are currently seeking a Data Analyst (Senior) to join our team of professionals in support of the USMC MCICOM G-9 Directorate.
Essential Duties & Job Functions
Develop and refine the COLS framework installation function and subfunction capabilities, performance risk levels, and measures (COLS Refresh).
Facilitate the development and implementation of the annual COLS other than labor costing, manpower costing, and performance management data collection efforts, including determining changes, analyzing and updating business rules, obtaining feedback, and responding to information requests.
Determine and manage detailed requirements for refining and developing the LFS Apps COLS Application, ensuring accurate data imports from other systems, and developing reports, splash pages, and dashboards for improved staff review.
Refine and develop the COLS Power BI Dashboard, incorporating analyses and visuals using COLS data, PBIS data, and DAI data for organizational use.
Provide administrative support for managing and maintaining the COLS App and COLS aspects of the Manpower App.
Facilitate COLS functional communities of interest (HQ and regional experts) in refining COLS definitions, cost estimates, and performance data.
Support the development and implementation of the COLS Executive Resource and Risk Management system for MCICOM COLS levels, aiding in leadership reviews and feedback loops.
Analyze COLS OTL and Labor out-year cost estimate data for all organizational levels, ensuring validation, consistency, and decision-making accuracy, coordinated with BOS Study efforts.
Review analytic results with subject matter experts for consistency with empirical data.
Use DoD cost estimation techniques, statistical methods, and cost driver data for analysis.
Recommendations must adhere to MIL-STD-3022 guidelines for VV&A for decision support.
Develop approaches to limit error and implement them as directed.
Analyze COLS cost estimates against PBIS, DAI, and COLS data to validate alignment and improve understanding.
Update and administer COLS 101, COLS App, COLS cost estimates, COLS performance, and training as needed.
Conduct reviews and propose updates to orders, directives, and policies governing COLS programs, ensuring effective communication with G-5 leads.
Facilitate development of the Commander’s Organizational Risk Estimate (CORE) report annually, including tool creation, data collection, training, analysis, and reporting.
Perform related work as assigned.
Job Requirements (Education, Experience, Professional Associations)
Education
Education: Must have at least ten (10) years of relevant experience and a Bachelor’s degree or at least five ( 5) years of experience and a Master’s degree.
Experience
Must be able to travel both CONUS and OCONUS as required/necessary.
Must be skilled in developing executive-level correspondence and management programs involving executive-level participants.
Must have proficiency in briefing and communication skills to senior Military (e.g., O-6 level and above), Military Commanders and their staff, organizational leaders, and peers.
Must have experience working with a diverse and often conflicting group of stakeholders from a cross section of all staff divisions/efforts.
USMC or other Military service experience a HUGE PLUS.
Clearance
Must be a United States Citizen.
Must be able to obtain and maintain a Common Access Card (CAC); active DoD clearance highly desired.
As a condition of employment, employee must successfully complete a background investigation and a drug screen in accordance with all federal, state, and local laws.
Seniority level Seniority level Mid-Senior level
Employment type Employment type Full-time
Job function Job function Information Technology
Industries Defense & Space
Referrals increase your chances of interviewing at ProSoDel (Professional Solutions Delivered, LLC) by 2x
Get notified about new Senior Data Analyst jobs in Arlington, VA .
Senior Data Analyst/VBA(Excel)_Onsite Full time role Chantilly, VA $90,300.00-$189,600.00 2 days ago
Senior Data Analyst - Talent Acquisition Senior Benefits Data & Operations Analyst Washington, DC $85,100.00-$127,700.00 2 days ago
Senior Enterprise Data Analyst - Must hold an active BI/NACLC Public Trust security clearance Washington, DC $115,000.00-$130,000.00 1 month ago
Senior Data Analyst (TRICARE Encounter Data) Sr. Manager, Data Analyst - Small Business Bank Washington, DC $122,000.00-$169,000.00 2 weeks ago
McLean, VA $70,000.00-$78,000.00 2 weeks ago
Manager Data Analyst - Retail Bank, Small Business Bank Senior Business Analyst (Infrastructure) Bethesda, MD $97,000.00-$120,150.00 5 months ago
McLean, VA $115,000.00-$151,500.00 1 week ago
Business Analyst (Technical Writing & Azure Data Focus) Senior Business Systems Analyst, Quote to Cash Washington, DC $135,300.00-$200,400.00 3 days ago
Senior Business Process & Performance Analyst Senior Analyst, Business Process Innovation Senior Analyst, Risk Advisory, Production eDiscovery Specialist Business Intelligence Analyst – Remote (DC Locals Preferred) We’re unlocking community knowledge in a new way. Experts add insights directly into each article, started with the help of AI.
#J-18808-Ljbffr",2025-07-10T00:00:00.000Z,2025-07-25,"['Education: Must have at least ten (10) years of relevant experience and a Bachelor’s degree or at least five ( 5) years of experience and a Master’s degree', 'Must be able to travel both CONUS and OCONUS as required/necessary', 'Must be skilled in developing executive-level correspondence and management programs involving executive-level participants', 'Must have proficiency in briefing and communication skills to senior Military (e.g., O-6 level and above), Military Commanders and their staff, organizational leaders, and peers', 'Must have experience working with a diverse and often conflicting group of stakeholders from a cross section of all staff divisions/efforts', 'USMC or other Military service experience a HUGE PLUS', 'Must be a United States Citizen', 'As a condition of employment, employee must successfully complete a background investigation and a drug screen in accordance with all federal, state, and local laws', 'Seniority level Seniority level Mid-Senior level', 'Senior Enterprise Data Analyst - Must hold an active BI/NACLC Public Trust security clearance Washington, DC $115,000.00-$130,000.00 1 month ago', 'Senior Data Analyst (TRICARE Encounter Data) Sr']","['Develop and refine the COLS framework installation function and subfunction capabilities, performance risk levels, and measures (COLS Refresh)', 'Facilitate the development and implementation of the annual COLS other than labor costing, manpower costing, and performance management data collection efforts, including determining changes, analyzing and updating business rules, obtaining feedback, and responding to information requests', 'Determine and manage detailed requirements for refining and developing the LFS Apps COLS Application, ensuring accurate data imports from other systems, and developing reports, splash pages, and dashboards for improved staff review', 'Refine and develop the COLS Power BI Dashboard, incorporating analyses and visuals using COLS data, PBIS data, and DAI data for organizational use', 'Provide administrative support for managing and maintaining the COLS App and COLS aspects of the Manpower App', 'Facilitate COLS functional communities of interest (HQ and regional experts) in refining COLS definitions, cost estimates, and performance data', 'Support the development and implementation of the COLS Executive Resource and Risk Management system for MCICOM COLS levels, aiding in leadership reviews and feedback loops', 'Analyze COLS OTL and Labor out-year cost estimate data for all organizational levels, ensuring validation, consistency, and decision-making accuracy, coordinated with BOS Study efforts', 'Review analytic results with subject matter experts for consistency with empirical data', 'Use DoD cost estimation techniques, statistical methods, and cost driver data for analysis', 'Recommendations must adhere to MIL-STD-3022 guidelines for VV&A for decision support', 'Develop approaches to limit error and implement them as directed', 'Analyze COLS cost estimates against PBIS, DAI, and COLS data to validate alignment and improve understanding', 'Update and administer COLS 101, COLS App, COLS cost estimates, COLS performance, and training as needed', 'Conduct reviews and propose updates to orders, directives, and policies governing COLS programs, ensuring effective communication with G-5 leads', 'Facilitate development of the Commander’s Organizational Risk Estimate (CORE) report annually, including tool creation, data collection, training, analysis, and reporting', 'Perform related work as assigned']",True,[],,"['Power BI', 'Data Collection and Analysis', 'Statistical Methods', 'Reporting and Dashboard Development', 'Data Integration and Management', 'Cost Estimation and Validation']","Power BI: Used to develop and refine dashboards incorporating analyses and visuals from multiple data sources (COLS, PBIS, DAI) for organizational use and improved staff review.; Data Collection and Analysis: Involves facilitating data collection efforts for labor costing, manpower costing, and performance management, analyzing cost estimates and performance data, and validating analytic results with subject matter experts to ensure consistency with empirical data.; Statistical Methods: Applied in analyzing cost driver data and DoD cost estimation techniques to support decision-making and ensure validation and consistency of cost estimates.; Reporting and Dashboard Development: Developing reports, splash pages, and dashboards to support staff review and leadership feedback loops, including the Commander’s Organizational Risk Estimate (CORE) report.; Data Integration and Management: Managing detailed requirements for data imports from other systems into the COLS Application and providing administrative support for maintaining COLS and Manpower applications.; Cost Estimation and Validation: Analyzing COLS OTL and labor out-year cost estimate data, comparing cost estimates against multiple data sources (PBIS, DAI, COLS) to validate alignment and improve understanding, adhering to MIL-STD-3022 guidelines for VV&A for decision support."
DHEqVg1KpOlHVDgLAAAAAA==,Sr Data Analyst Brand Consultant,"The Opportunity:

Do you thrive on uncovering insights through data are a seasoned data storyteller and looking for an exciting career supporting brands like Hot Wheels Barbie and Fisher Price The Product Quality Analytics team is seeking a highly skilled Senior Data Analyst with a strong focus on data storytelling to join our dynamic analytics team that supports global Quality Safety and Sustainability. This role involves collaboration with Global Brand teams Quality Engineering partners and various stakeholders to ensure datadriven decisionmaking and continuous improvement. The ideal candidate will be a relationship builder and excel in translating complex data into insights.

What Your Impact Will Be:
• Prepare and deliver highimpact insights to stakeholders to drive the development of highquality products.
• Data analysis and interpretation: Conduct thorough data analysis to identify key trends patterns and insights and present findings in a clear and visually engaging manner.
• Collaborate with stakeholders: Work closely with crossfunctional teams including Quality Engineering Global Brand teams and leadership understand their data needs and translate them into effective insights for future development.
• Lead defective product returns process: Drive continuous improvement by standardizing workflows assist in tool enhancements for automation standardize documentation of defective analysis and coordination of defective sample disposition.
• Collaborate with Product Quality Analytics team to design and develop selfservice dashboards and implement advanced analytic (AI) solutions.
• Innovation and experimentation: Continuously improving on tools and technologies to introduce new ways to work using AI.
• Project management: Manage multiple projects simultaneously ensuring timely delivery and alignment with business objectives.

Qualifications :

What Were Looking For:
• Experience: Minimum of 2 years of experience in data storytelling and data analysis with a demonstrated success of influence on actionable decisions made through datadriven insights.
• Technical Skills: Tableau knowledge strong analytical and visualization skills. Has a curiosity of AI and what it can do to enhance our capabilities and tools.
• Presentation Skills: Ability to present complex information clearly and concisely while tailoring the narrative to specific needs and knowledge level of the audience. Excellent verbal and written communication skills.
• ProblemSolving: Strong problemsolving skills with the ability to think critically and creatively.
• Team Player: Ability to work collaboratively in a team environment and manage relationships with stakeholders at all levels.
• Demonstrated a growth mindset by staying curious and continuously learning embracing challenges and improving themselves.

The annual base salary range for this position is between $69800 and $87300.
• *This range is indicative of projected hiring range however annual base salary will be determined based on a candidates work location skills and experience. Mattel offers competitive total pay programs comprehensive benefits and resources to help empower a culture where every employee can reach their full potential.

Additional Information :

Dont meet every single requirement At Mattel we are dedicated to an inclusive workplace and a culture of belonging. If youre excited about this role but your past experience doesnt align perfectly with every qualification in the job description we still encourage you to apply. You may be just the right candidate for this or other roles.
How We Work:
We are a purpose driven company aiming to empower generations to explore the wonder of childhood and reach their full potential. We live up to our purpose employing the following behaviors:
• We collaborate: Being a part of Mattel means being part of one team with shared values and common goals. Every person counts and working closely together always brings better results. Partnership is our process and our collective capabilities is our superpower.
• We innovate: At Mattel we always aim to find new and better ways to create innovative products and experiences. No matter where you work in the organization you can always make a difference and have real impact. We welcome new ideas and value new initiatives that challenge conventional thinking.
• We execute: We are a performancedriven company. We strive for excellence and are focused on pursuing bestinclass outcomes. We believe in accountability and ownership and know that our people are at their best when they are empowered to create and deliver results.

Who We Are:
Mattel is a leading global toy and family entertainment company and owner of one of the most iconic brand portfolios in the world. We engage consumers and fans through our franchise brands including Barbie Hot Wheels FisherPrice American Girl Thomas & Friends UNO Masters of the Universe Matchbox Monster High MEGA and Polly Pocket as well as other popular properties that we own or license in partnership with global entertainment companies. Our offerings include toys content consumer products digital and live experiences. Our products are sold in collaboration with the worlds leading retail and ecommerce companies. Since its founding in 1945 Mattel is proud to be a trusted partner in empowering generations to explore the wonder of childhood and reach their full potential.

Mattels awardwinning workplace culture has been recognized by Forbes Fast Company Newsweek Great Place to Work TIME and more.

Visit us at is an Affirmative Action/Equal Opportunity Employer where we want you to bring your authentic self to work every day. We welcome all job seekers and all applicants will receive consideration for employment without regard to race ethnicity color national origin religion sex gender gender identity or expression sexual orientation veteran and protected veteran status disability status and or any other basis protected by applicable federal state or local law.

Pursuant to the Los Angeles Fair Chance Ordinance and the California Fair Chance Act qualified applicants with arrest or conviction records will be considered for employment.

Videos to watch:
The Culture at Mattel
Mattel Investor Highlights

Remote Work :

No

Employment Type :

Fulltime",,2025-07-25,"['The ideal candidate will be a relationship builder and excel in translating complex data into insights', 'Experience: Minimum of 2 years of experience in data storytelling and data analysis with a demonstrated success of influence on actionable decisions made through datadriven insights', 'Technical Skills: Tableau knowledge strong analytical and visualization skills', 'Has a curiosity of AI and what it can do to enhance our capabilities and tools', 'Presentation Skills: Ability to present complex information clearly and concisely while tailoring the narrative to specific needs and knowledge level of the audience', 'Excellent verbal and written communication skills', 'ProblemSolving: Strong problemsolving skills with the ability to think critically and creatively', 'Team Player: Ability to work collaboratively in a team environment and manage relationships with stakeholders at all levels', 'Demonstrated a growth mindset by staying curious and continuously learning embracing challenges and improving themselves']","['Do you thrive on uncovering insights through data are a seasoned data storyteller and looking for an exciting career supporting brands like Hot Wheels Barbie and Fisher Price The Product Quality Analytics team is seeking a highly skilled Senior Data Analyst with a strong focus on data storytelling to join our dynamic analytics team that supports global Quality Safety and Sustainability', 'This role involves collaboration with Global Brand teams Quality Engineering partners and various stakeholders to ensure datadriven decisionmaking and continuous improvement', 'Prepare and deliver highimpact insights to stakeholders to drive the development of highquality products', 'Data analysis and interpretation: Conduct thorough data analysis to identify key trends patterns and insights and present findings in a clear and visually engaging manner', 'Collaborate with stakeholders: Work closely with crossfunctional teams including Quality Engineering Global Brand teams and leadership understand their data needs and translate them into effective insights for future development', 'Lead defective product returns process: Drive continuous improvement by standardizing workflows assist in tool enhancements for automation standardize documentation of defective analysis and coordination of defective sample disposition', 'Collaborate with Product Quality Analytics team to design and develop selfservice dashboards and implement advanced analytic (AI) solutions', 'Innovation and experimentation: Continuously improving on tools and technologies to introduce new ways to work using AI', 'Project management: Manage multiple projects simultaneously ensuring timely delivery and alignment with business objectives']",True,['Advanced Analytics with AI'],Advanced Analytics with AI: Implementing advanced analytic solutions involving AI to innovate and improve tools and technologies for enhanced data capabilities and insights.,"['Data Storytelling', 'Data Analysis', 'Data Visualization', 'Dashboard Development', 'Workflow Standardization and Automation']","Data Storytelling: Used to translate complex data into actionable insights and influence decision-making by preparing and delivering high-impact insights to stakeholders.; Data Analysis: Conducting thorough analysis to identify key trends, patterns, and insights relevant to product quality, safety, and sustainability.; Data Visualization: Presenting findings in a clear and visually engaging manner using tools like Tableau to support data-driven decision-making.; Dashboard Development: Designing and developing self-service dashboards in collaboration with the Product Quality Analytics team to enable stakeholders to access and interpret data independently.; Workflow Standardization and Automation: Driving continuous improvement by standardizing workflows, assisting in tool enhancements for automation, and standardizing documentation related to defective product analysis and sample disposition."
_6FHbm4E5CPyDyMJAAAAAA==,Senior Data Protection Analyst - Cyber,"Are you passionate about technology and interested in joining a community of collaborative colleagues who respectfully and courageously seek to challenge the status quo? If so, read on to learn more about an exciting opportunity with Deloitte Technology US (DT - US). We are curious and life-long learners focused on technology and innovation.

Recruiting for this role ends on 7/31/2025.

Work you'll do

DT-US Cyber Data Protection team is responsible for securing and protecting confidential data of Deloitte US Member Firm, our clients, and our employees. The team's core mission is to implement consistent security controls to protect Firm's data and data entrusted to us by our clients to build their trust and protect our brand. We are seeking an experienced and energetic Senior Data Protection Analyst with outstanding communication, analytical and cyber security technical skills to join our Cyber Data Protection team within Deloitte Technology US (DT - US).

If you're an experienced, hands-on IT professional with strong systems administration, engineering, IT technical support and/or cyber security technical skills who's interested in growing in the cybersecurity field, this may be the job for you. As part of our Cyber Data Protection team, you will be assisting in designing, deploying, and managing cyber technology and process solutions to reduce the potential of data compromise. You will be assisting with testing of data protection and data security solutions. You will work to enhance and mature existing cyber security data protection capabilities for Deloitte US Member Firm and provide on-going support for them. You will require an understanding of the ecosystem of data protection including well-rounded understanding of the information security domains and their inter-relations across that ecosystem. You will be responsible for providing technical product and troubleshooting assistance to Deloitte Employees. You will work closely with management, lead analysts, peers, development teams, business analysts, and end users to ensure data protection technologies and data protection controls for systems are operating appropriately without causing business impact.

As part of the DT- US Cyber Data Protection team, you will have the following core responsibilities:
• Assist with the development, deployment and support of cyber data protection solutions.
• Assist with the implementation of data security controls and design principles.
• Provide Tier 2 technical support to Deloitte end users for several of the cyber data protection services supported by the team that includes but not limited to Data Loss Prevention, Data Minimization, Data Classification and Rights Management, CASB, Web Security, Web Application Firewall, Next Generation Anti-virus and Endpoint Detection and Response technology, Endpoint Admin Rights Management/Privilege Management technology, PKI Certificate Lifecycle Management, Encryption Key Management, Digital Code Signing, Removable Media Protection, Data Discovery Roll Off Scans etc.
• Assist in maturing existing data protection solutions protecting against data exfiltration.
• Assist in rolling out new data protection services to employees, getting them adopted and providing on-going support for those services.
• Assist with technology and software reviews based on data protection and endpoint risks.
• Provide technical engineering and troubleshooting support to employees for data protection services.

Experience working with various data protection technologies:
• Data Loss Prevention (DLP) technology
• Data Classification and Rights Management technology
• Cloud Access Security Broker (CASB)
• Secure Web Gateway/Proxy (SWG) technology
• Next Generation Anti-virus and Endpoint Detection and Response technology
• Endpoint Admin Rights Management/Privilege Management technology
• PKI Certificate Management technology
• Encryption Key Management technology
• Web Application Firewall technology
• Confidential Data Reduction technology
• Data Access Governance technology
• Removable Media Protection technology
• Database Encryption technologies

The team

Deloitte Technology US (DT - US) helps power Deloitte's success, which serves many of the world's largest, most respected organizations. We develop and deploy cutting-edge internal and go-to-market solutions that help Deloitte operate effectively and lead in the market. Our reputation is built on a tradition of delivering with excellence.

The ~3,000 professionals in DT - US deliver services including:
• Cyber Security
• Technology Support
• Technology & Infrastructure
• Applications
• Relationship Management
• Strategy & Communications
• Project Management
• Financials

Cyber Security

Cyber Security vigilantly protects Deloitte and client data. The team leads a strategic cyber risk program that adapts to a rapidly changing threat landscape, changes in business strategies, risks, and vulnerabilities. Using situational awareness, threat intelligence, and building a security culture across the organization, the team helps to protect the Deloitte brand.

Areas of focus include:
• Risk & Compliance
• Identity & Access Management
• Data Protection
• Cyber Design
• Incident Response
• Security Architecture
• Business Partnership

Required Qualifications:
• Bachelor's degree or equivalent in Computer Science or Engineering.
• Minimum 5 years of combined experience in the Information Security/Cybersecurity domain.
• Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future

Preferred Qualifications:
• Experienced with implementing and managing data protection strategies across data at rest, data in motion, and data in use.
• Experience with troubleshooting issues and assisting end users to mitigate technical challenges.
• Familiarity with change management and deployment processes in large IT organizations.
• Working knowledge with common IT technologies such as Windows Server, Linux/Unix, Databases, Active Directory/LDAP, virtualization, end-user devices etc.
• Working knowledge of IT/security principles such as encryption, identity, cloud, etc.
• Experience with PowerShell command-line scripting is a plus.
• Professional security certification desirable, such as Security+ or CISSP.
• Understanding of industry best practices related to risk assessment, mitigation, and incident response.
• Knowledge of data protection regulations and standards (e.g., ISO 27001, ISO 27018, NIST 800-171).
• Understanding of networking and core networking protocols (e.g., TCP/IP, UDP, DNS, SMTP, HTTP, TLS, and distributed networks).
• Knowledge in different types of VPN, Encryption Standards, Certificates.
• Understanding of security controls in public cloud environments (i.e., Amazon Web Services (AWS), Microsoft Azure, Google Cloud Platform) and SaaS services hardening.
• Ability to write technical reports and communicate technical content to business users.
• Self-motivated with a strong willingness to learn and grow with changing cloud technologies.
• Experience working in a virtual team.
• Troubleshooting and problem analysis skills.
• Understanding of information security frameworks, incident management/response, security operations, and application security best practices.
• Competency with Microsoft Windows and/or MacOS Operating Systems

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $84,300 - $173,300.

You may also be eligible to participate in a discretionary annual incentive program, subject to the rules governing the program, whereby an award, if any, depends on various factors, including, without limitation, individual and organizational performance.

Information for applicants with a need for accommodation: https://www2.deloitte.com/us/en/pages/careers/articles/join-deloitte-assistance-for-disabled-applicants.html

EA_ExpHire

RITM9065907

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.",2025-07-17T00:00:00.000Z,2025-07-25,"['Data Loss Prevention (DLP) technology', 'Secure Web Gateway/Proxy (SWG) technology', 'Next Generation Anti-virus and Endpoint Detection and Response technology', 'Endpoint Admin Rights Management/Privilege Management technology', 'PKI Certificate Management technology', 'Encryption Key Management technology', 'Web Application Firewall technology', 'Confidential Data Reduction technology', 'Data Access Governance technology', 'Removable Media Protection technology', 'Database Encryption technologies', 'Identity & Access Management', ""Bachelor's degree or equivalent in Computer Science or Engineering"", 'Minimum 5 years of combined experience in the Information Security/Cybersecurity domain', 'Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future', 'The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs']","['As part of our Cyber Data Protection team, you will be assisting in designing, deploying, and managing cyber technology and process solutions to reduce the potential of data compromise', 'You will be assisting with testing of data protection and data security solutions', 'You will work to enhance and mature existing cyber security data protection capabilities for Deloitte US Member Firm and provide on-going support for them', 'You will require an understanding of the ecosystem of data protection including well-rounded understanding of the information security domains and their inter-relations across that ecosystem', 'You will be responsible for providing technical product and troubleshooting assistance to Deloitte Employees', 'You will work closely with management, lead analysts, peers, development teams, business analysts, and end users to ensure data protection technologies and data protection controls for systems are operating appropriately without causing business impact', 'As part of the DT- US Cyber Data Protection team, you will have the following core responsibilities:', 'Assist with the development, deployment and support of cyber data protection solutions', 'Assist with the implementation of data security controls and design principles', 'Provide Tier 2 technical support to Deloitte end users for several of the cyber data protection services supported by the team that includes but not limited to Data Loss Prevention, Data Minimization, Data Classification and Rights Management, CASB, Web Security, Web Application Firewall, Next Generation Anti-virus and Endpoint Detection and Response technology, Endpoint Admin Rights Management/Privilege Management technology, PKI Certificate Lifecycle Management, Encryption Key Management, Digital Code Signing, Removable Media Protection, Data Discovery Roll Off Scans etc', 'Assist in maturing existing data protection solutions protecting against data exfiltration', 'Assist in rolling out new data protection services to employees, getting them adopted and providing on-going support for those services', 'Assist with technology and software reviews based on data protection and endpoint risks', 'Provide technical engineering and troubleshooting support to employees for data protection services', 'Cloud Access Security Broker (CASB)', 'Strategy & Communications', 'Project Management']",False,,,,
zKKin4SP6joHQ8cuAAAAAA==,"Senior Data Analyst, Program Integration","Strategy Development: Collaborate with senior management, stakeholders and colleagues to understand business needs, define strategies, identify opportunities and address key challenges. Provide advanced analysis of existing data and structures, consultation, interpretation, and presentation of complex data environments. Develop innovative data-driven solutions for strategic decision-making and business growth.Clinical Program Integration and Evaluation: Evaluate the effectiveness, impact, and use of clinical programs and present to requesting stakeholders. Analyze program performance metrics, key performance indicators (KPIs), and outcome measures to assess program effectiveness and identify areas for improvement.Team Leadership: Provide leadership, guidance, and mentorship to a team of data analysts and data management technicians, fostering a collaborative and high-performance work environment. Assign tasks, set goals, and monitor progress to ensure timely and successful project completion. Lead recruitment, onboarding, training, and professional development efforts for the data team. Supervise full-time staff and student assistants. Technical Expertise: Perform and review complex (senior-level) data analysis and data research work. Provide advanced analysis of existing data and satisfies ad-hoc reporting/analysis requests; serve as a first point of escalation for leadership.Quality Assurance/Compliance: Oversee regular reviews and audits to identify and address data integrity issues. Define, develop, and implement data and reporting standards, best practices, and quality assurance processes to ensure accuracy, consistency, and reliability of analytical findings and deliverables. Implement necessary changes to ensure data quality improvement.Documentation and Reporting: Ensure comprehensive documentation of data analysis methodologies, specifications, tools, processes, and outcomes. Deliver clear, concise, and actionable reports, presentations, and dashboards to communicate analytical findings, key insights, and recommendations to stakeholders at all levels of the organization. Oversee development of technical workflows, project plans, and timelines to ensure scalable data management processes and increase efficiencies across platforms, departments, teams, and institutions.Relationship Management: Build and maintain strong relationships with internal and external stakeholders, foster trust, transparency, and collaboration. Act as a liaison between the data analytics team and other units, clinics, and programs, facilitate communication and resolve conflicts, across the organization. Support continued collaboration with program coordinators and clinical staff, analyze quantitative and qualitative data from satisfaction surveys, focus groups, and other sources to monitor quality, assess fidelity of program implementation, and drive continuous improvement. Represent Dell Medical School in inter-institutional data governance committees and represent DMS TCMHCP at Consortium level.Perform other related duties as assigned.",,2025-07-25,,"['Strategy Development: Collaborate with senior management, stakeholders and colleagues to understand business needs, define strategies, identify opportunities and address key challenges', 'Provide advanced analysis of existing data and structures, consultation, interpretation, and presentation of complex data environments', 'Develop innovative data-driven solutions for strategic decision-making and business growth', 'Clinical Program Integration and Evaluation: Evaluate the effectiveness, impact, and use of clinical programs and present to requesting stakeholders', 'Analyze program performance metrics, key performance indicators (KPIs), and outcome measures to assess program effectiveness and identify areas for improvement', 'Team Leadership: Provide leadership, guidance, and mentorship to a team of data analysts and data management technicians, fostering a collaborative and high-performance work environment', 'Assign tasks, set goals, and monitor progress to ensure timely and successful project completion', 'Lead recruitment, onboarding, training, and professional development efforts for the data team', 'Supervise full-time staff and student assistants', 'Technical Expertise: Perform and review complex (senior-level) data analysis and data research work', 'Provide advanced analysis of existing data and satisfies ad-hoc reporting/analysis requests; serve as a first point of escalation for leadership', 'Quality Assurance/Compliance: Oversee regular reviews and audits to identify and address data integrity issues', 'Define, develop, and implement data and reporting standards, best practices, and quality assurance processes to ensure accuracy, consistency, and reliability of analytical findings and deliverables', 'Implement necessary changes to ensure data quality improvement', 'Documentation and Reporting: Ensure comprehensive documentation of data analysis methodologies, specifications, tools, processes, and outcomes', 'Deliver clear, concise, and actionable reports, presentations, and dashboards to communicate analytical findings, key insights, and recommendations to stakeholders at all levels of the organization', 'Oversee development of technical workflows, project plans, and timelines to ensure scalable data management processes and increase efficiencies across platforms, departments, teams, and institutions', 'Relationship Management: Build and maintain strong relationships with internal and external stakeholders, foster trust, transparency, and collaboration', 'Act as a liaison between the data analytics team and other units, clinics, and programs, facilitate communication and resolve conflicts, across the organization', 'Support continued collaboration with program coordinators and clinical staff, analyze quantitative and qualitative data from satisfaction surveys, focus groups, and other sources to monitor quality, assess fidelity of program implementation, and drive continuous improvement', 'Represent Dell Medical School in inter-institutional data governance committees and represent DMS TCMHCP at Consortium level', 'Perform other related duties as assigned']",True,[],,"['Data Analysis', 'Program Evaluation', 'Data-Driven Strategy Development', 'Data Quality Assurance and Compliance', 'Reporting and Dashboarding', 'Documentation and Workflow Management', 'Quantitative and Qualitative Data Analysis', 'Team Leadership and Mentorship', 'Stakeholder and Relationship Management']","Data Analysis: Perform and review complex senior-level data analysis and data research work to provide advanced analysis of existing data and satisfy ad-hoc reporting and analysis requests, serving as a first point of escalation for leadership.; Program Evaluation: Evaluate the effectiveness, impact, and use of clinical programs by analyzing program performance metrics, key performance indicators (KPIs), and outcome measures to assess program effectiveness and identify areas for improvement.; Data-Driven Strategy Development: Collaborate with senior management and stakeholders to understand business needs, define strategies, identify opportunities, and develop innovative data-driven solutions for strategic decision-making and business growth.; Data Quality Assurance and Compliance: Oversee regular reviews and audits to identify and address data integrity issues, define and implement data and reporting standards, best practices, and quality assurance processes to ensure accuracy, consistency, and reliability of analytical findings and deliverables, and implement necessary changes to improve data quality.; Reporting and Dashboarding: Deliver clear, concise, and actionable reports, presentations, and dashboards to communicate analytical findings, key insights, and recommendations to stakeholders at all organizational levels.; Documentation and Workflow Management: Ensure comprehensive documentation of data analysis methodologies, specifications, tools, processes, and outcomes, and oversee development of technical workflows, project plans, and timelines to ensure scalable data management processes and increase efficiencies across platforms, departments, teams, and institutions.; Quantitative and Qualitative Data Analysis: Analyze quantitative and qualitative data from satisfaction surveys, focus groups, and other sources to monitor quality, assess fidelity of program implementation, and drive continuous improvement.; Team Leadership and Mentorship: Provide leadership, guidance, and mentorship to a team of data analysts and data management technicians, assign tasks, set goals, monitor progress, and lead recruitment, onboarding, training, and professional development efforts.; Stakeholder and Relationship Management: Build and maintain strong relationships with internal and external stakeholders, act as a liaison between the data analytics team and other units, clinics, and programs, facilitate communication, resolve conflicts, and represent the organization in inter-institutional data governance committees."
8ZeIbLlifPuIpR6sAAAAAA==,Sr. Data Privacy Analyst,"Job Description

Location: Open to market areas outside of Dallas/Fort Worth

Your role

We are seeking an experienced Data Protection (Privacy) Senior Analyst to join our organization. The IT function at Digital Realty takes responsibility to manage and secure some of the world’s most critical infrastructure on behalf of our customers. The Data Protection (Privacy) Senior Analyst will be detail-oriented, self-driven and forward-thinking individual who is well versed in implementing and maintaining Data Protection policies and procedures, monitoring compliance with relevant regulatory requirements, analyzing privacy & security risks, and responsible for supporting the IT Data Protection/Privacy maturity efforts. The candidate will work closely with the existing Privacy and Data Governance Programs.

What You’ll Do
• Collaborate closely with the Privacy program, Data Governance and other business functions involved in driving Data Protection requirements at DLR.
• Support with performing privacy impact assessments (PIA) and data mapping activities.
• Assist in ensuring successful and effective execution of IT data protection goals, implementation, as well as exceptional services in ongoing operation of DLR’s IT Data Protection objectives.
• Support the implementation of privacy policies and procedures across the organization and provide guidance to ensure business processes adhere to policies and procedures.
• Works closely with internal stakeholders to evaluate and identify any gaps and supports finding solutions & strategies to ensure full compliance with data protection & privacy regulations and requirements.
• Identifies and reports privacy risks appropriately and assist with the implementation of risk mitigation strategies.
• Support Data Subject Access Requests (DSARs) within the IT organization.
• Assists in the preparation, maintenance, and implementation of data protection policies and standard operating procedures.
• Ensures business strategies, plans and initiatives are driven/delivered in compliance with governing regulations, internal policies, and procedures.
• Participate in projects to verify business practices align with company privacy program including regulatory requirements.
• Facilitates discussions with the business on privacy/data protection Awareness & Requirements, including those relevant to cybersecurity controls.
• Stays abreast of applicable Global, Federal and State privacy Regulations and accreditation standards and monitors advancements in information governance technologies to ensure that they support the Data Protection (Privacy) program and organization in adaptation and compliance efforts.
• Support the development and Implementation of metrics and dashboards for reporting and monitoring the effectiveness of the IT data protection program.
• Completes other duties as assigned.

What You’ll Need
• Bachelor’s degree in computer science, information Technology, Data Science, or related fields.
• 4+ years of experience in a Data Protection or Privacy role or Cybersecurity with a focus on data protection.
• Experience with regulatory compliance frameworks such as GDPR, CCPA, HIPAA, PCI DSS, ISO 27001, SOX, NIST CSF, etc. Ability to support IT assessment and audit efforts is a strong bonus.
• Experience performing Privacy Impact Assessments (PIA) and Data Protection Impact Assessments (DPIA).
• Experience responding to and adhering to Data Subject Access Requests (DSARs).
• Experience implementing privacy design into information systems and recommending appropriate technical design to adequately protect data.
• Experience supporting privacy training and privacy compliance activities.
• Excellent communication and partnering skills.
• Ability to build a strong data protection and privacy culture mindset framed by risk management and operational consistency across technical teams and business units.
• Good project management, multitasking and organizational skills.
• Relevant certifications such as CIPP, CIPT, CIPM, CDPSE, are highly desirable.
• Proficiency in Microsoft Excel, PowerPoint, Power BI and other Microsoft Tools.
• Good understanding of global privacy and data protection regulations and frameworks, such as the GDPR, CCPA, CPRA, HIPAA, NIST, ISO, and more.
• Experience with tools such as OneTrust, Securiti.ai, WireWheel, and BigID across use cases such as data mapping, data discovery, privacy impact assessments, consent/preference management, cookie compliance, data subject rights, and more, is preferred.
• Ability to clearly communicate data protection and privacy issues verbally on both a formal and informal basis to all levels of the organization.
• Possessing a working understanding of risk management, organization-wide compliance programs, and corporate communications.
• Data privacy, governance/risk/ compliance, and/or information security operations background is required.
• Proactivity and an ability to work independently.
• Excellent attention to detail and strong organizational skills.
• A strong technology background is needed.
• Good research skills with an ability to analyze and interpret complex information.
• Understanding of data security in the cloud is desired.

A Bit About Us

Digital Realty supports the world's leading enterprises and service providers by delivering the full spectrum of data center, colocation and interconnection solutions. PlatformDIGITAL®, our global data center platform, gives customers a reliable foundation for scaling their digital business and efficiently managing data gravity challenges. The size and scale of our business puts us in a unique position to offer customers access to 300+ facilities in 50+ metros across 25+ countries and six continents.

A Bit About Our Digital Team

IT

Our IT team is at the heart of our business. We develop infrastructures, design and build networks, support servers and provide the first line of support by delivering rich connectivity for our customers. With new data centers coming online all the time, it’s a rapidly changing technical environment so our team is always ready to innovate and take the lead on projects. We constantly develop, deploy and support vital networks and data services that drive business performance and improve life for customers around the globe.

What We Can Offer You

Our rapidly evolving business sector offers the opportunity to be part of a courageous and passionate team who work together to understand and meet the changing needs of our global customers.

Join us and you’ll be part of a supportive and inclusive environment where you can bring your whole self to work. As part of our team, you’ll get to work with people from different business areas, challenge the way we do things and put your ideas into action. We’ll also give you plenty of development opportunities so you can build a rewarding and successful career with us.

Our Compensation Philosophy

Digital Realty offers its employees a highly competitive compensation package, excellent benefits, and an environment that recognizes and rewards your contributions. Central to our compensation philosophy is rewarding our employees for achieving the values and objectives aligned to the company's overall goals and values.

This is an exciting time to join our business so apply now and make your mark on our future.

Notes

The above statements are intended to describe the general nature and level of work being performed by people assigned to this job. They are not intended to be an exhaustive list of all responsibilities, duties, and skills required of personnel so classified.

Digital Realty is an equal opportunity employer, EOE/AA/M/F/Vets/Disabled. All applicants will receive consideration for employment and will not be discriminated against on the basis of race, color, religion, sex, sexual orientation, gender identity, age, national origin, disability or protected veteran status, or other status protected by law or Company policy.

Digital Realty is a publicly traded company (NYSE: DLR) with investment grade ratings from all three major ratings agencies.

Please do not forward unsolicited resumes to any employee of Digital Realty and its subsidiaries. Digital Realty is not responsible for any fees related to unsolicited referrals.",2025-07-17T00:00:00.000Z,2025-07-25,"['Bachelor’s degree in computer science, information Technology, Data Science, or related fields', '4+ years of experience in a Data Protection or Privacy role or Cybersecurity with a focus on data protection', 'Experience with regulatory compliance frameworks such as GDPR, CCPA, HIPAA, PCI DSS, ISO 27001, SOX, NIST CSF, etc', 'Ability to support IT assessment and audit efforts is a strong bonus', 'Experience performing Privacy Impact Assessments (PIA) and Data Protection Impact Assessments (DPIA)', 'Experience responding to and adhering to Data Subject Access Requests (DSARs)', 'Experience implementing privacy design into information systems and recommending appropriate technical design to adequately protect data', 'Experience supporting privacy training and privacy compliance activities', 'Excellent communication and partnering skills', 'Ability to build a strong data protection and privacy culture mindset framed by risk management and operational consistency across technical teams and business units', 'Good project management, multitasking and organizational skills', 'Proficiency in Microsoft Excel, PowerPoint, Power BI and other Microsoft Tools', 'Good understanding of global privacy and data protection regulations and frameworks, such as the GDPR, CCPA, CPRA, HIPAA, NIST, ISO, and more', 'Ability to clearly communicate data protection and privacy issues verbally on both a formal and informal basis to all levels of the organization', 'Possessing a working understanding of risk management, organization-wide compliance programs, and corporate communications', 'Data privacy, governance/risk/ compliance, and/or information security operations background is required', 'Proactivity and an ability to work independently', 'Excellent attention to detail and strong organizational skills', 'A strong technology background is needed', 'Good research skills with an ability to analyze and interpret complex information']","['The Data Protection (Privacy) Senior Analyst will be detail-oriented, self-driven and forward-thinking individual who is well versed in implementing and maintaining Data Protection policies and procedures, monitoring compliance with relevant regulatory requirements, analyzing privacy & security risks, and responsible for supporting the IT Data Protection/Privacy maturity efforts', 'The candidate will work closely with the existing Privacy and Data Governance Programs', 'Collaborate closely with the Privacy program, Data Governance and other business functions involved in driving Data Protection requirements at DLR', 'Support with performing privacy impact assessments (PIA) and data mapping activities', 'Assist in ensuring successful and effective execution of IT data protection goals, implementation, as well as exceptional services in ongoing operation of DLR’s IT Data Protection objectives', 'Support the implementation of privacy policies and procedures across the organization and provide guidance to ensure business processes adhere to policies and procedures', 'Works closely with internal stakeholders to evaluate and identify any gaps and supports finding solutions & strategies to ensure full compliance with data protection & privacy regulations and requirements', 'Identifies and reports privacy risks appropriately and assist with the implementation of risk mitigation strategies', 'Support Data Subject Access Requests (DSARs) within the IT organization', 'Assists in the preparation, maintenance, and implementation of data protection policies and standard operating procedures', 'Ensures business strategies, plans and initiatives are driven/delivered in compliance with governing regulations, internal policies, and procedures', 'Participate in projects to verify business practices align with company privacy program including regulatory requirements', 'Facilitates discussions with the business on privacy/data protection Awareness & Requirements, including those relevant to cybersecurity controls', 'Stays abreast of applicable Global, Federal and State privacy Regulations and accreditation standards and monitors advancements in information governance technologies to ensure that they support the Data Protection (Privacy) program and organization in adaptation and compliance efforts', 'Support the development and Implementation of metrics and dashboards for reporting and monitoring the effectiveness of the IT data protection program', 'Completes other duties as assigned']",False,,,,
WBpigE1EQGpRhE3aAAAAAA==,Senior Data Scientist,"Company Description

By working at Harvard University, you join a vibrant community that
advances Harvard's world-changing mission in meaningful ways,
inspires innovation and collaboration, and builds skills and
expertise. We are dedicated to creating a diverse and welcoming
environment where everyone can thrive.

Why join the Harvard Graduate School of Education?

The Harvard Graduate School of Education (HGSE) is a diverse
community of learners, teachers, and employees who are passionate
about changing the world through education and striving for maximum
impact in the field of education.

Many choose to work at the Harvard Graduate School of Education
because they believe in our mission and are excited by our vision
for the future. We have a reputation as a great place to work, for
our excellent leadership, and we are a strong community that values
diversity. For more information about HGSE, its programs, research,
and faculty, please visit: www.gse.harvard.edu .

Job Description

Job Summary:

Design, plan, and implement software and data services that support
and enrich research productivity and reliability. Develop software
and data services with researchers to ensure that modern standards
of reproducible research are kept.

Position Description:

HGSE is a diverse community of learners, teachers, and
employees who are passionate about changing the world through
education and striving for maximum impact in the field of
education. The Senior Data Scientist at the Center for Education
Policy Research (CEPR) at Harvard University leads statistical
programming, collaborates with Principal Investigators to develop
advanced models and analysis tools, develops data architecture and
data processing pipelines, works with multiple stakeholders and
develops visualizations to communicate key findings to
non-technical audiences, and advises projects on state-of-the-art
software and data solutions to support the research. CEPR partners
with school districts, charter school networks, and state education
agencies to bring high quality research methods and data analysis
to bear on strategic management and policy decisions. We believe
that (1) policy and management decisions directly influence the
ability of schools and teachers to improve student achievement; and
(2) valid and reliable data analysis significantly improves the
quality of decision-making. We design our work around the theory of
action that if we bring together the right people, the right data,
and the right analysis, significantly better decision-making will
occur, and student outcomes will be improved.

The Senior Data Scientist reports to CEPR’s Director of Research
who will identify specific projects and tasks that would benefit
from the Senior Data Scientist’s expertise.

Job-Specific Responsibilities:
• Develops advanced models and performs complex statistical
programming to support the research.
• Advises research projects on state-of-the-art technical
solutions to analytic and data challenges.
• Translates complex analyses for policy and practitioner
audiences and develop visualizations that help people understand
key findings and new insights.
• Mentors research analysts on statistical programming and
informally supervise the analyst on any tasks that the Senior Data
Scientist assigns to them.
• Serves as a resource to the team for computer programming and
statistics. Occasionally, group training on specific tools or
models.
• Builds internal code design and development guides for future
contributors,
• Conducts quality assurance to ensure the reproducibility of
analyses, documentation of methods and algorithms, and use of
appropriate statistical tests.
• Collaborates with Principal Investigators and Project Directors
to develop research plans and statistical analyses.
• Contributes to papers and reports.

Please Note: Any candidate wishing to be considered must supply
a cover letter in addition to their resume showing that they meet
the required basic qualifications. Any candidate invited to an
initial round of interview will be asked to submit a sample
program. Any candidate invited to a second round of interview will
be asked to complete a case. This is a one-year term position from
the date of hire, with the possibility of extension, contingent
upon work performance and continued funding to support the
position.

Physical Requirements:

Working Conditions:

HGSE is currently developing dynamic workplace models which will
actively support a combination of on-campus and remote work (within
a state in which Harvard is registered to do business) where
business and operational needs allow. You and your manager will
discuss the best schedule based on your role and operational need.
If your role allows for remote work, please note that all remote
work must be performed within a state in which Harvard is
registered to do business (CA (Only Exempt), CT, GA, IL, MA, MD,
ME, NH, NJ, NY, RI, VA, VT, and WA). Please also note that Harvard
will withhold each applicable state’s required tax and other
withholdings from your paycheck for the time you work there.

The health of our workforce is a priority for Harvard University.
With that in mind, we strongly encourage all employees to be
up-to-date on CDC-recommended vaccines.

We regret that the Harvard Graduate School of Education does not
provide Visa sponsorship.

Qualifications

Basic Qualifications:
• Minimum of seven years’ post-secondary education or relevant
work experience

Additional Qualifications and Skills:

Bachelor’s degree in computer science, Statistics, Data Science,
Economics, Mathematics, or a related field.

7+ years of relevant experience or post-secondary education.

3+ years’ experience in advanced statistical programming using
Stata or R.

Additional Qualifications and Skills:

Master’s degree preferred.

5+ years experience in statistical programming preferred.

3+ years experience supporting social science research projects
preferred.

Experience with Bayesian estimation, machine learning, natural
language processing, cloud-based computing, and/or Artificial
Intelligence strongly preferred.

Experience with managing and analyzing large datasets, scaling
processes, developing data architectures, and developing R packages
preferred.

Experience with version control software (such as Git), code
reviews, and unit testing preferred.

Ability to translate technical topics for non-technical audiences
and to develop analyses and visualizations that convey key findings
clearly.

Demonstrated creative ability to solve challenges in novel ways
using state-of-the-art statistical and data processing
techniques.

Experience working with K-12 or postsecondary education data a
plus.

Certificates and Licenses:

Additional Information
• Standard Hours/Schedule: 35 hours per week
• Visa Sponsorship Information: Harvard University is
unable to provide visa sponsorship for this position
• Pre-Employment Screening:Education,Identity
• Other Information:

HGSE Human Resources values diversity in all forms and believes
that each employee brings a set of diverse experiences and
identities to the workplace that makes us stronger, encourages
innovation, and enhances our collective contributions. We continue
to develop and support a workforce that reflects the diversity of
those we serve; fosters an environment that allows everyone to
belong and to bring their best self to work; and creates the
conditions that empower employees to contribute their full
potential to advancing the work of the school.

We do this by:
• Hiring and retaining staff reflecting the diversity of those we
serve
• Providing employees opportunities to learn, grow, and be
challenged
• Reviewing and ensuring fairness and equity in HR practices and
policies including but not limited to hiring, promotion, and
compensation
• Developing strong relationships and partnerships internal and
external to our community to advance diversity and inclusion
• Communicating transparently and respectfully; and
• Fostering an inclusive, respectful, and professional work
environment

About the Harvard Graduate School of Education

Many choose to work at the Harvard Graduate School of Education
because they believe in our mission and are excited by our vision
for the future. We have a reputation as a great place to work, for
our excellent leadership, and we are a strong community that values
diversity. For more information about HGSE, its programs, research,
and faculty, please visit: www.gse.harvard.edu

Work Format Details

This is a position that is based at a Harvard campus location with
some remote work options available. Additional details will be
discussed during the interview process. All remote work must be
performed within one of the Harvard Registered Payroll States,
which currently includes Massachusetts, Connecticut, Maine, New
Hampshire, Rhode Island, Vermont, Georgia, Illinois, Maryland, New
Jersey, New York, Virginia, Washington, and California (CA for
exempt positions only). Certain visa types and funding sources may
limit work location. Individuals must meet work location
sponsorship requirements prior to employment.

Salary Grade and Ranges

This position is salary grade level 058. Please visit  Harvard's Salary Ranges
  to view the corresponding salary range and related
information.

Benefits

Harvard offers a comprehensive benefits package that is designed to
support a healthy work-life balance and your physical, mental and
financial wellbeing. Because here, you are what matters. Our
benefits include, but are not limited to:
• Generous paid time off including parental leave
• Medical, dental, and vision health insurance coverage starting
on day one
• Retirement plans with university contributions
• Wellbeing and mental health resources
• Support for families and caregivers
• Professional development opportunities including tuition
assistance and reimbursement
• Commuter benefits, discounts and campus perks

Learn more about these and additional benefits on our Benefits &
Wellbeing Page .

EEO/Non-Discrimination Commitment Statement

Harvard University is committed to
equal opportunity and
non-discrimination . We seek talent from all parts of society
and the world, and we strive to ensure everyone at Harvard thrives.
Our differences help our community advance Harvard’s academic
purposes.

Harvard has an
equal employment opportunity policy that outlines our
commitment to prohibiting discrimination on the basis of race, sex,
ethnicity, color, national origin, religion, disability, or any
other characteristic protected by law or identified in the
university’s
non-discrimination policy . Harvard’s
equal employment opportunity policy and
non-discrimination policy help all community members
participate fully in work and campus life free from harassment and
discrimination.",2025-07-16T00:00:00.000Z,2025-07-25,"['ability of schools and teachers to improve student achievement; and', '(2) valid and reliable data analysis significantly improves the', 'a state in which Harvard is registered to do business) where', 'business and operational needs allow', 'work must be performed within a state in which Harvard is', 'registered to do business (CA (Only Exempt), CT, GA, IL, MA, MD,', 'Minimum of seven years’ post-secondary education or relevant', 'Bachelor’s degree in computer science, Statistics, Data Science,', 'Economics, Mathematics, or a related field', '7+ years of relevant experience or post-secondary education', '3+ years’ experience in advanced statistical programming using', 'Stata or R', '3+ years experience supporting social science research projects', 'Experience with Bayesian estimation, machine learning, natural', 'language processing, cloud-based computing, and/or Artificial', 'Experience with managing and analyzing large datasets, scaling', 'processes, developing data architectures, and developing R packages', 'Experience with version control software (such as Git), code', 'Ability to translate technical topics for non-technical audiences', 'Demonstrated creative ability to solve challenges in novel ways', 'using state-of-the-art statistical and data processing', 'Experience working with K-12 or postsecondary education data a', 'Visa Sponsorship Information: Harvard University is', 'Reviewing and ensuring fairness and equity in HR practices and']","['about changing the world through education and striving for maximum', 'Design, plan, and implement software and data services that support', 'and enrich research productivity and reliability', 'Develop software', 'and data services with researchers to ensure that modern standards', 'of reproducible research are kept', 'education and striving for maximum impact in the field of', 'programming, collaborates with Principal Investigators to develop', 'advanced models and analysis tools, develops data architecture and', 'data processing pipelines, works with multiple stakeholders and', 'develops visualizations to communicate key findings to', 'non-technical audiences, and advises projects on state-of-the-art', 'software and data solutions to support the research', 'agencies to bring high quality research methods and data analysis', 'to bear on strategic management and policy decisions', 'We design our work around the theory of', 'and the right analysis, significantly better decision-making will', 'occur, and student outcomes will be improved', 'The Senior Data Scientist reports to CEPR’s Director of Research', 'who will identify specific projects and tasks that would benefit', 'Develops advanced models and performs complex statistical', 'programming to support the research', 'Advises research projects on state-of-the-art technical', 'solutions to analytic and data challenges', 'Translates complex analyses for policy and practitioner', 'audiences and develop visualizations that help people understand', 'Mentors research analysts on statistical programming and', 'informally supervise the analyst on any tasks that the Senior Data', 'Scientist assigns to them', 'Serves as a resource to the team for computer programming and', 'Occasionally, group training on specific tools or', 'Builds internal code design and development guides for future', 'Conducts quality assurance to ensure the reproducibility of', 'analyses, documentation of methods and algorithms, and use of', 'appropriate statistical tests', 'Collaborates with Principal Investigators and Project Directors', 'to develop research plans and statistical analyses', 'Contributes to papers and reports', 'upon work performance and continued funding to support the', 'HGSE is currently developing dynamic workplace models which will', 'actively support a combination of on-campus and remote work (within', 'discuss the best schedule based on your role and operational need', 'If your role allows for remote work, please note that all remote', 'will withhold each applicable state’s required tax and other', 'and to develop analyses and visualizations that convey key findings', 'Standard Hours/Schedule: 35 hours per week', 'conditions that empower employees to contribute their full', 'Providing employees opportunities to learn, grow, and be', 'Developing strong relationships and partnerships internal and', 'external to our community to advance diversity and inclusion', 'Communicating transparently and respectfully; and', 'Fostering an inclusive, respectful, and professional work']",True,[],,"['Statistical Programming', 'Bayesian Estimation', 'Machine Learning', 'Natural Language Processing', 'Data Architecture', 'Data Processing Pipelines', 'Data Visualization', 'Reproducible Research', 'Version Control', 'R Programming', 'Stata']","Statistical Programming: Used to develop advanced models and perform complex statistical analyses to support research projects, including mentoring analysts and ensuring reproducibility of analyses.; Bayesian Estimation: Applied as an advanced statistical method preferred for supporting social science research projects and solving analytic challenges.; Machine Learning: Preferred experience involving the application of machine learning techniques to support research and data analysis.; Natural Language Processing: Experience preferred in applying NLP techniques, likely for analyzing educational or social science data.; Data Architecture: Developing and managing data architectures to support large datasets and scalable data processing pipelines.; Data Processing Pipelines: Designing and implementing pipelines to process and manage data efficiently for research purposes.; Data Visualization: Creating visualizations to communicate key findings and complex analyses clearly to non-technical audiences including policy and practitioner stakeholders.; Reproducible Research: Ensuring that research methods, analyses, and algorithms are documented and reproducible, maintaining high standards of research reliability.; Version Control: Using version control software such as Git to manage code, conduct code reviews, and support collaborative software development.; R Programming: Utilized for advanced statistical programming, developing R packages, and supporting data analysis workflows.; Stata: Used for advanced statistical programming and supporting social science research projects."
XrGXmWQT_mRCZOTmAAAAAA==,Senior Data Analyst and Engineer,"Senior Data Analyst and Engineer to join our dynamic team. In this role, you will play a key role in analyzing large datasets, building data pipelines, and developing innovative solutions to extract actionable insights. The ideal candidate is highly skilled in both data analysis and engineering, with a passion for turning data into valuable business intelligence.

Responsibilities:
Analyze complex datasets to identify trends, patterns, and opportunities for optimizationDesign and develop robust data pipelines to extract, transform, and load (ETL) data from various sourcesCollaborate with cross-functional teams to understand business requirements and translate them into technical solutionsBuild predictive models and algorithms to support data-driven decision-makingPerform exploratory data analysis to uncover insights and inform strategic initiativesOptimize and maintain existing data infrastructure to ensure scalability, reliability, and performanceMentor and provide guidance to junior team membersStay updated on emerging technologies and trends in data an
Minimum Requirements:
Proficiency in SQL and experience with relational databases (e.g., MySQL, PostgreSQL)Strong programming skills in languages such as Python, R, or JavaExperience with data visualization tools (e.g., Tableau, Power BI)Knowledge of statistical analysis and machine learning techniquesFamiliarity with cloud platforms (e.g., AWS, Azure, Google Cloud) and big data technologies (e.g., Hadoop, Spark)Excellent analytical and problem-solving skillsStrong communication and collaboration skills",2025-07-02T00:00:00.000Z,2025-07-25,"['The ideal candidate is highly skilled in both data analysis and engineering, with a passion for turning data into valuable business intelligence', 'Proficiency in SQL and experience with relational databases (e.g., MySQL, PostgreSQL)Strong programming skills in languages such as Python, R, or JavaExperience with data visualization tools (e.g., Tableau, Power BI)Knowledge of statistical analysis and machine learning techniques', 'Familiarity with cloud platforms (e.g., AWS, Azure, Google Cloud) and big data technologies (e.g., Hadoop, Spark)Excellent analytical and problem-solving skills', 'Strong communication and collaboration skills']","['In this role, you will play a key role in analyzing large datasets, building data pipelines, and developing innovative solutions to extract actionable insights', 'Analyze complex datasets to identify trends, patterns, and opportunities for optimization', 'Design and develop robust data pipelines to extract, transform, and load (ETL) data from various sources', 'Collaborate with cross-functional teams to understand business requirements and translate them into technical solutions', 'Build predictive models and algorithms to support data-driven decision-makingPerform exploratory data analysis to uncover insights and inform strategic initiatives', 'Optimize and maintain existing data infrastructure to ensure scalability, reliability, and performance', 'Mentor and provide guidance to junior team members', 'Stay updated on emerging technologies and trends in data an']",True,[],,"['SQL', 'Relational Databases', 'Python', 'R', 'Java', 'Data Visualization Tools', 'Statistical Analysis', 'Machine Learning', 'Data Pipelines', 'Exploratory Data Analysis', 'Cloud Platforms', 'Big Data Technologies', 'Predictive Models', 'Data Infrastructure Optimization']","SQL: Used for querying and managing relational databases such as MySQL and PostgreSQL to support data analysis and engineering tasks.; Relational Databases: Experience with databases like MySQL and PostgreSQL is required to store, retrieve, and manage structured data efficiently.; Python: Programming language used for data analysis, building data pipelines, and developing predictive models.; R: Programming language utilized for statistical analysis and data visualization.; Java: Programming language employed for data engineering and building scalable data solutions.; Data Visualization Tools: Tools such as Tableau and Power BI are used to create dashboards and visual representations of data insights for business intelligence.; Statistical Analysis: Applied to analyze complex datasets, identify trends and patterns, and support data-driven decision-making.; Machine Learning: Techniques used to build predictive models and algorithms that enhance data-driven decision-making processes.; Data Pipelines: Designing and developing ETL processes to extract, transform, and load data from various sources to support analytics and reporting.; Exploratory Data Analysis: Performed to uncover insights from data and inform strategic initiatives.; Cloud Platforms: Familiarity with AWS, Azure, and Google Cloud is required to leverage cloud infrastructure for data storage, processing, and analytics.; Big Data Technologies: Experience with Hadoop and Spark to handle large-scale data processing and analytics.; Predictive Models: Built to support data-driven decision-making by forecasting outcomes based on historical data.; Data Infrastructure Optimization: Maintaining and optimizing data systems to ensure scalability, reliability, and performance."
RFznnWszOvS3d7z7AAAAAA==,Senior Data Analyst - Data Modeler,"Description:
• At ngrok, we believe that doing networking the right way should also be the easy way.
• As we continue transforming how developers orchestrate and secure their networks, we’re building out a world-class data team to help us understand usage patterns, optimize product performance, and guide key business decisions with evidence-not assumptions.
• We’re looking for a Senior Data Analyst/Modeler who will be instrumental in building our data models, defining key metrics, and uncovering insights that guide both product innovation and go-to-market strategies.
• You’ll work closely with cross-functional teams-from engineering and product to marketing and growth-to help us make smarter, faster decisions backed by data.
• Help maintain data integrity and drive best practices in data governance and quality.

Requirements:
• 7+ years of experience in data analytics, business intelligence, or data science.
• Strong proficiency in SQL and hands-on experience working with business and product teams to build self-service analytics datasets and dashboards.
• Experience working with high volume, high velocity data sets that model complex, real-world systems
• Experience with a data modeling tool such as dbt or SQLMesh and an orchestration tool such as Dagster or Airbyte for managing data pipelines.
• Experience being part of or working with engineering teams and navigating version control (e.g. git), command line tools, and CI
• Strong experience with BI tools (Superset, Looker, Mode, Metabase, or similar).
• Ability to translate complex data into clear, actionable insights.
• Solid communication and collaboration skills-especially in a remote environment.
• Bonus: Background in supporting product-led growth (PLG) or developer-focused SaaS.

Benefits:
• Compensation for this role depends on level, but we provide a competitive mix of salary and equity.
• We provide a 401(k) with a 100% match up to 3% of your salary and a 50% match up to another 2%.
• We provide healthcare, dental, and vision with premiums fully covered on the base plan for employees. Half of premiums are covered for dependents.
• We offer unlimited PTO and a culture in which the overwhelming majority of employees take more than four weeks. Your manager is also on the hook for encouraging you to do the same.",,2025-07-25,"['7+ years of experience in data analytics, business intelligence, or data science', 'Strong proficiency in SQL and hands-on experience working with business and product teams to build self-service analytics datasets and dashboards', 'Experience working with high volume, high velocity data sets that model complex, real-world systems', 'Experience with a data modeling tool such as dbt or SQLMesh and an orchestration tool such as Dagster or Airbyte for managing data pipelines', 'Experience being part of or working with engineering teams and navigating version control (e.g. git), command line tools, and CI', 'Strong experience with BI tools (Superset, Looker, Mode, Metabase, or similar)', 'Ability to translate complex data into clear, actionable insights', 'Solid communication and collaboration skills-especially in a remote environment', 'Bonus: Background in supporting product-led growth (PLG) or developer-focused SaaS']","['You’ll work closely with cross-functional teams-from engineering and product to marketing and growth-to help us make smarter, faster decisions backed by data', 'Help maintain data integrity and drive best practices in data governance and quality']",True,[],,"['SQL', 'Data Modeling', 'Data Pipelines Orchestration', 'Business Intelligence (BI) Tools', 'Data Governance and Quality', 'Version Control and CI']","SQL: Used for querying and managing data to build self-service analytics datasets and dashboards in collaboration with business and product teams.; Data Modeling: Involves building data models to represent complex, real-world systems and defining key metrics to guide product innovation and go-to-market strategies, using tools such as dbt or SQLMesh.; Data Pipelines Orchestration: Managing and automating data workflows using orchestration tools like Dagster or Airbyte to handle high volume, high velocity data sets.; Business Intelligence (BI) Tools: Utilizing BI platforms such as Superset, Looker, Mode, or Metabase to create dashboards and enable data-driven decision making across teams.; Data Governance and Quality: Maintaining data integrity and driving best practices to ensure reliable and accurate data for analysis and reporting.; Version Control and CI: Collaborating with engineering teams using version control systems like git and command line tools, as well as continuous integration practices to support data workflows and analytics development."
9NDG4fJBUaNoAxDoAAAAAA==,Business Data Analyst,"Overview

Grow With Us! At Hilb Group, we recognize that our associates are our greatest asset. We promote a service-driven culture of high performance that encourages career and professional development. The Hilb Group is currently seeking a motivated and ambitious Business Data Analyst to join our team. This position will report to our agency located in Roseland, NJ. The ideal candidate will be motivated to succeed, is well organized, able to prioritize, and able to work well with a team. This is an in-office position. Responsibilities: Risk Management support Manage vendor certificate, analyze compliance, analyze loss trends, create client claim reports, perform claim task workflows. Participate as a Team member in a fast-paced, growing sales environment open to continuous improvement. Qualifications: Minimum High School degree required, college preferred Licensing not required. Demonstrated analytical skills. Strong time management skills Benefits: Company Paid Life Insurance, Long-Term and Short-Term Disability. Medical, Dental, Vision and FSA/HSA plans. 401(k) with company match. Additional voluntary benefits including Critical Illness, Accident Insurance, Hospital Indemnity and Supplemental Life Insurance, Legal and Identity Protection, and Pet benefits. Generous PTO. An awesome team of professionals! The Hilb Group is an equal opportunity employer, and we actively support and comply with all applicable federal, state, and local laws prohibiting all forms of discrimination in employment. Additionally, we have a zero-tolerance policy for all forms of harassment in violation of federal, state, and local laws.",2025-07-22T00:00:00.000Z,2025-07-25,"['The ideal candidate will be motivated to succeed, is well organized, able to prioritize, and able to work well with a team', 'Demonstrated analytical skills']","['Responsibilities: Risk Management support Manage vendor certificate, analyze compliance, analyze loss trends, create client claim reports, perform claim task workflows', 'Participate as a Team member in a fast-paced, growing sales environment open to continuous improvement']",False,,,,
TJy5OnpWfXBgyiJWAAAAAA==,Marketing Data Analyst II – Pricing,"The role's responsibilities will encompass a blend of pricing strategy, promotional analysis, category management, and budgeting insights.

OVERVIEW

Assist in creating and driving business value and growth though the effective use of Sheetz’ most valuable resource: Data. Responsible for leading Sheetz’ data and information strategy through data analysis and visualization in order to facilitate and enhance organizational decision-making and data utilization across the company. Provides advanced data analytics support to the Senior Data Analyst while providing mentorship to the Data Analyst I around data analytics and information strategy.

RESPONSIBILITIES (other duties may be assigned)
• Cultivate data-driven insights that help support exploitation of strategic and tactical business opportunities, and be a champion for a data-driven, decision-making culture.
• Support data strategy leadership in the development, assessment, refinement and implementation of corporate strategy through effective use of data analytics.
• Provide enterprise-wide data science and business intelligence services as well as recommendations to decentralized, embedded data scientists and analysts throughout the business.
• Assist Senior Data Analysts and management in providing training for departmental and distributed data analysts.
• Oversee and present robust ad-hoc reports, data models, and deep dive analysis to provide clear observations so that managers can make more informed decisions.
• Develop and mentor future data-driven, analytical leaders and strategists within the team.
• Assist with a wide array of analytical tasks and projects requested by other departments.
• Supports the Senior Data Analyst position with ad-hoc advanced analytics.
• Assist in the creation of policies and procedures for the access, analysis and visualization of data and associated business insights; partnering with IT and RISC.
• Responsible for the documenting and classifying data assets and making accessible and discoverable across the organization.

QUALIFICATIONS

(Equivalent combinations of education, licenses, certifications and/or experience may be considered)

Education
• Bachelor’s degree in Economics, Statistics, Mathematics, Actuarial /Data / Computer Science or related field required

Experience
• Minimum 3 years demonstrated experience in data modeling, optimization, and application to business strategies required.
• Minimum 3 years demonstrated experience in integrating complex, inter-departmental processes and information strategies, and/or designing strategic metrics and scorecards required.
• Thorough understanding of the latest data mining, machine learning and/or artificial intelligence techniques required.
• In-depth experience with or coursework in designing and implementing information solutions required.

Licenses/Certifications
• None required

Tools & Equipment (Other than general office equipment):
• General Office Equipment

ACCOMMODATIONS

Sheetz is committed to the full inclusion of all qualified individuals. Sheetz is committed to considering all applicants regardless of disability who can perform all essential job duties with or without accommodations.",2025-07-25T00:00:00.000Z,2025-07-25,"['(Equivalent combinations of education, licenses, certifications and/or experience may be considered)', 'Bachelor’s degree in Economics, Statistics, Mathematics, Actuarial /Data / Computer Science or related field required', 'Minimum 3 years demonstrated experience in data modeling, optimization, and application to business strategies required', 'Minimum 3 years demonstrated experience in integrating complex, inter-departmental processes and information strategies, and/or designing strategic metrics and scorecards required', 'Thorough understanding of the latest data mining, machine learning and/or artificial intelligence techniques required', 'In-depth experience with or coursework in designing and implementing information solutions required']","[""The role's responsibilities will encompass a blend of pricing strategy, promotional analysis, category management, and budgeting insights"", 'Assist in creating and driving business value and growth though the effective use of Sheetz’ most valuable resource: Data', 'Responsible for leading Sheetz’ data and information strategy through data analysis and visualization in order to facilitate and enhance organizational decision-making and data utilization across the company', 'Provides advanced data analytics support to the Senior Data Analyst while providing mentorship to the Data Analyst I around data analytics and information strategy', 'RESPONSIBILITIES (other duties may be assigned)', 'Cultivate data-driven insights that help support exploitation of strategic and tactical business opportunities, and be a champion for a data-driven, decision-making culture', 'Support data strategy leadership in the development, assessment, refinement and implementation of corporate strategy through effective use of data analytics', 'Provide enterprise-wide data science and business intelligence services as well as recommendations to decentralized, embedded data scientists and analysts throughout the business', 'Assist Senior Data Analysts and management in providing training for departmental and distributed data analysts', 'Oversee and present robust ad-hoc reports, data models, and deep dive analysis to provide clear observations so that managers can make more informed decisions', 'Develop and mentor future data-driven, analytical leaders and strategists within the team', 'Assist with a wide array of analytical tasks and projects requested by other departments', 'Supports the Senior Data Analyst position with ad-hoc advanced analytics', 'Assist in the creation of policies and procedures for the access, analysis and visualization of data and associated business insights; partnering with IT and RISC', 'Responsible for the documenting and classifying data assets and making accessible and discoverable across the organization']",True,[],,"['Data Analysis', 'Data Visualization', 'Data Modeling', 'Optimization', 'Data Mining', 'Machine Learning', 'Business Intelligence', 'Ad-hoc Reporting', 'Data Strategy', 'Data Analytics', 'Training and Mentorship', 'Data Asset Management']","Data Analysis: Used to lead the company's data and information strategy to enhance organizational decision-making and data utilization across the company.; Data Visualization: Employed to facilitate and enhance organizational decision-making and data utilization across the company.; Data Modeling: Applied in developing optimization and business strategies, with a minimum of 3 years demonstrated experience required.; Optimization: Used in conjunction with data modeling to apply to business strategies, requiring demonstrated experience.; Data Mining: Requires a thorough understanding of the latest data mining techniques as part of the role's qualifications.; Machine Learning: Requires a thorough understanding of the latest machine learning techniques as part of the role's qualifications.; Business Intelligence: Provided enterprise-wide as services and recommendations to decentralized, embedded data scientists and analysts throughout the business.; Ad-hoc Reporting: Oversees and presents robust ad-hoc reports and deep dive analysis to provide clear observations for informed managerial decisions.; Data Strategy: Supports leadership in the development, assessment, refinement, and implementation of corporate strategy through effective use of data analytics.; Data Analytics: Used to cultivate data-driven insights supporting strategic and tactical business opportunities and to champion a data-driven decision-making culture.; Training and Mentorship: Provides training and mentorship to junior data analysts and supports senior data analysts with advanced analytics.; Data Asset Management: Responsible for documenting, classifying, and making data assets accessible and discoverable across the organization."
7sn8sBGbUiK7rVLwAAAAAA==,"Data Analyst, Health","GoldBelt is hiring a Data Analyst, Health with 5 - 10 years of experience. Based in United States - Rockville, MD and with In-office ways of working.

Job description and responsibilities:

Goldbelt Frontier fosters a collaborative environment where employees are encouraged to utilize and employ their operational and leadership skills. Many senior project managers and business analysts are subject matter experts in their respective fields. Frontier understands how to support multiple stakeholders to aid in developing and implementing national policies, strategies, and doctrine.

Summary:

We are looking for a Health Data Analyst to provide support for the National Action Alliance to Advance Patient Safety contract within partnership with Health and Human Services (HHS). This position shall support the Action Alliance the identification, dissemination and utilization of evidence based practices and best practices.

Essential Job Functions:
• Conduct routine analysis on process and outcome data and share recommendations and insights at the direction of AHRQ
• Assist in preparing reports and materials that demonstrate program impact for internal and external stakeholders
• Leverage public/external data sources to benchmark and inform program outcomes and objectives
• Evaluate pilot programs and strategic initiatives at both the program and organizational level
• Maintain and periodically update core evaluation infrastructure such as evaluation manuals, data dictionaries, etc.
• Support the continuous improvement of evaluation methods, systems, and practices Data Management
• Maintain internal data systems to ensure high quality data processes and analysis
• Develop meaningful data dashboards that can be easily accessed, understood and utilized by frontline staff to drive a continuous improvement process
• In collaboration with ARQ, conduct periodic review, analysis, and reporting of data needed to measure program impact, Action Alliance progress, establish program priorities, and support continuous improvement of all Center programs and initiatives

Requirements and qualifications:

Necessary Skills and Knowledge:
• Your ability to exude a strong executive presence while also managing tactical execution by internal and external stakeholders will be critical to success in the role
• Ability to contribute to projects across practice areas and divisions to help troubleshoot and problem solve on complex issues
• Strategic, consultative presence with a problem-solving mentality
• Experience communicating directly and effectively to executive leadership.
• Demonstrated knowledge of client priorities, preferences, and regulations
• Demonstrated expertise in MS Office, with excellent Excel skills
• Demonstrated knowledge of relevant systems, processes, and approaches, with excellent financial management skills
• Effective communicator with internal and external clients
• Strong research skills, including knowledge of research methodologies, data analysis, and statistics.
• Advanced analytical knowledge of data
• Proficiency with data visualization software such as Tableau or similar 5. High level of facility with data management, imports, and exports through MS Excel. Ability to summarize data through use of formulas, run reports and queries, generate mailing lists, and perform similar tasks
• Strong observational, analytical and critical thinking skills, coupled with ability to discern trends and deduce reasons for results
• Strong organizational and communication skills (written, oral and presentation)
• Familiarity with creating and managing online surveys
• Motivated self-starter with demonstrated ability to work independently and collaboratively within a systematic program approach.

Minimum Qualifications:
• Bachelor’s degree, including successful completion of coursework in statistics and research/survey methods.
• 5- 7 years conducting program evaluation (process and outcome) and developing reports that examine and disseminate findings regarding impact and recommendations for improvement
• 5-7 years of experience managing and presenting data using Microsoft Office and Google Suite / G Suite (docs, sheets, forms, presentations, etc.)

Experience with the following:
• Conducting big data analysis
• Developing software and data models
• Developing algorithms
• Business analysis
• Business process modeling—enterprise to department level
• Process oriented with great documentation skills

Preferred Qualifications:
• Master's degree in statistics or a PhD in a specific area of health research or clinical practice.
• Familiarity with student information systems and experience working with sensitive, protected data preferred.",,2025-07-25,"['Your ability to exude a strong executive presence while also managing tactical execution by internal and external stakeholders will be critical to success in the role', 'Ability to contribute to projects across practice areas and divisions to help troubleshoot and problem solve on complex issues', 'Strategic, consultative presence with a problem-solving mentality', 'Experience communicating directly and effectively to executive leadership', 'Demonstrated knowledge of client priorities, preferences, and regulations', 'Demonstrated expertise in MS Office, with excellent Excel skills', 'Demonstrated knowledge of relevant systems, processes, and approaches, with excellent financial management skills', 'Effective communicator with internal and external clients', 'Strong research skills, including knowledge of research methodologies, data analysis, and statistics', 'Advanced analytical knowledge of data', 'Proficiency with data visualization software such as Tableau or similar 5', 'High level of facility with data management, imports, and exports through MS Excel', 'Ability to summarize data through use of formulas, run reports and queries, generate mailing lists, and perform similar tasks', 'Strong observational, analytical and critical thinking skills, coupled with ability to discern trends and deduce reasons for results', 'Strong organizational and communication skills (written, oral and presentation)', 'Familiarity with creating and managing online surveys', 'Motivated self-starter with demonstrated ability to work independently and collaboratively within a systematic program approach', 'Bachelor’s degree, including successful completion of coursework in statistics and research/survey methods', '5- 7 years conducting program evaluation (process and outcome) and developing reports that examine and disseminate findings regarding impact and recommendations for improvement', '5-7 years of experience managing and presenting data using Microsoft Office and Google Suite / G Suite (docs, sheets, forms, presentations, etc.)', 'Conducting big data analysis', 'Developing software and data models', 'Developing algorithms', 'Business process modeling—enterprise to department level', 'Process oriented with great documentation skills']","['Many senior project managers and business analysts are subject matter experts in their respective fields', 'This position shall support the Action Alliance the identification, dissemination and utilization of evidence based practices and best practices', 'Conduct routine analysis on process and outcome data and share recommendations and insights at the direction of AHRQ', 'Assist in preparing reports and materials that demonstrate program impact for internal and external stakeholders', 'Leverage public/external data sources to benchmark and inform program outcomes and objectives', 'Evaluate pilot programs and strategic initiatives at both the program and organizational level', 'Maintain and periodically update core evaluation infrastructure such as evaluation manuals, data dictionaries, etc', 'Support the continuous improvement of evaluation methods, systems, and practices Data Management', 'Maintain internal data systems to ensure high quality data processes and analysis', 'Develop meaningful data dashboards that can be easily accessed, understood and utilized by frontline staff to drive a continuous improvement process', 'In collaboration with ARQ, conduct periodic review, analysis, and reporting of data needed to measure program impact, Action Alliance progress, establish program priorities, and support continuous improvement of all Center programs and initiatives']",True,[],,"['Program Evaluation', 'Data Analysis', 'Data Visualization', 'Data Management', 'Statistical Methods', 'Reporting and Communication', 'Business Process Modeling', 'Algorithm Development', 'Survey Design and Management']","Program Evaluation: Conduct routine analysis on process and outcome data to assess program impact and support continuous improvement of programs and initiatives.; Data Analysis: Perform data analysis including big data analysis to generate insights, identify trends, and support decision-making for health-related programs.; Data Visualization: Develop meaningful data dashboards using tools such as Tableau or similar software to enable frontline staff and stakeholders to access, understand, and utilize data effectively.; Data Management: Maintain internal data systems ensuring high quality data processes, including data imports, exports, and management through tools like MS Excel and Google Suite.; Statistical Methods: Apply knowledge of statistics and research methodologies to analyze data, evaluate pilot programs, and support evidence-based practices.; Reporting and Communication: Prepare reports and materials that demonstrate program impact for internal and external stakeholders, communicating findings effectively to executive leadership and clients.; Business Process Modeling: Engage in business process modeling at enterprise to department level to support program evaluation and strategic initiatives.; Algorithm Development: Develop software and data models and algorithms to support data analysis and program evaluation.; Survey Design and Management: Create and manage online surveys to collect data relevant to program evaluation and research."
hqBDLRuo4rlY4DXHAAAAAA==,Senior Financial Data Analyst,"Job Title: Senior Financial Data Analyst

Company: GPFS is the fund administrator of choice for a wide range of clients in the US, UK, and EU. Every day, with every decision and every client interaction, our values serve as guideposts, to improve the quality of our work, and strengthen our employee and client relationships.

As a business that is all about people; culture isn't an initiative, it's an innate value that's critical to every decision we make. At GPFS, people come first.

At GPFS, diversity is a source of strength, both from our people and ideas. GPFS is a collaborative team-oriented organization where we support each other both personally and professionally. Our culture is defined by our behavior, our curiosity and our support of innovative ideas and perspectives.

Our inclusive culture supports and encourages our team members to try new things, share ideas openly and always ask the question why. It brings us together and makes the team stronger by inspiring all to connect, belong and thrive.

Location: Latham, NY - In office

Job Type: Full-time

This position is part of a growing team at GPFS which focuses on providing comprehensive data and reporting solutions for Private Market clients. In this role you will focus on the ingestion, normalization, and enhancement of data (i.e., accounting, financial, regulatory) from multiple sources to support / maintain reporting needs for various organizational stakeholders.

Essential Duties:
• Support the cleansing, preparation, and enhancement of large / complex datasets for clients and internal teams.
• Carry out exploratory data analysis.
• Support reporting environment by maintaining and updating reports and records as needed.
• Reconcile reporting output to source documents.
• Identify areas for process improvement or automation.
• Demonstrate attention to detail and accuracy.
• Strong multi-tasking and organizational skills in a project-based environment.
• Ability to research and resolve issues with various degrees of complexity.
• Strong written and verbal communication skills
• Ability to work as a strong team member as well as an independent contributor.
• Flexibility to work hours needed to complete client deliverables.

Qualifications
• Degree: 4 Year with master's preferred
• Years of experience: 3+

Additional Eligibility Qualifications
• Excel / VBA
• SQL / SSRS
• R / Python
• Business Intelligence / visualization software
• Finance or Economics background a plus

Competencies
• Intellectual curiosity - researching methods or ideas that could benefit the group or project.
• Self-motivating - ability to work independently.
• Analytical skills - understanding relationships within the data and disseminating information accurately.
• Organized
• Highly flexible - adapting to new formats, tools, and sometimes ambiguous work environment.
• Results Driven - working through multiple iterations to achieve success.
• Collaborative - working with multiple groups both within and outside the organization.
• Detailed Orientated
• Ethical

GPFS Vision

Our purpose is to create enduring relationships with our employees and clients by constantly delivering exceptional opportunities and service.

GPFS Value Statement

Investing in people and culture

Core Values

Camaraderie: Being supportive of one another and celebrating each other's successes

Excellence: Consistently delivering exceptional work and going above and beyond

Empowerment: Fostering a deep sense of agency and ownership over one's choices and actions

Innovation: The drive to think differently and solve problems creatively

Inclusion: Recognizing individual's unique strengths and perspectives with mutual trust and respect

#LI-GP1",,2025-07-25,"['Strong multi-tasking and organizational skills in a project-based environment', 'Ability to research and resolve issues with various degrees of complexity', 'Strong written and verbal communication skills', 'Ability to work as a strong team member as well as an independent contributor', 'Years of experience: 3+', 'Excel / VBA', 'SQL / SSRS', 'R / Python', 'Business Intelligence / visualization software', 'Intellectual curiosity - researching methods or ideas that could benefit the group or project', 'Self-motivating - ability to work independently', 'Analytical skills - understanding relationships within the data and disseminating information accurately', 'Organized', 'Highly flexible - adapting to new formats, tools, and sometimes ambiguous work environment', 'Results Driven - working through multiple iterations to achieve success', 'Collaborative - working with multiple groups both within and outside the organization', 'Detailed Orientated', 'Ethical', ""Camaraderie: Being supportive of one another and celebrating each other's successes"", 'Excellence: Consistently delivering exceptional work and going above and beyond', 'Innovation: The drive to think differently and solve problems creatively', ""Inclusion: Recognizing individual's unique strengths and perspectives with mutual trust and respect""]","['This position is part of a growing team at GPFS which focuses on providing comprehensive data and reporting solutions for Private Market clients', 'In this role you will focus on the ingestion, normalization, and enhancement of data (i.e., accounting, financial, regulatory) from multiple sources to support / maintain reporting needs for various organizational stakeholders', 'Support the cleansing, preparation, and enhancement of large / complex datasets for clients and internal teams', 'Carry out exploratory data analysis', 'Support reporting environment by maintaining and updating reports and records as needed', 'Reconcile reporting output to source documents', 'Identify areas for process improvement or automation', 'Demonstrate attention to detail and accuracy', 'Flexibility to work hours needed to complete client deliverables']",True,[],,"['Data Ingestion and Normalization', 'Data Cleansing and Preparation', 'Exploratory Data Analysis', 'Reporting and Data Reconciliation', 'Process Improvement and Automation', 'SQL and SSRS', 'Excel and VBA', 'R and Python', 'Business Intelligence and Visualization Tools']","Data Ingestion and Normalization: Responsible for ingesting, normalizing, and enhancing accounting, financial, and regulatory data from multiple sources to support reporting needs for organizational stakeholders.; Data Cleansing and Preparation: Supports cleansing, preparation, and enhancement of large and complex datasets for clients and internal teams to ensure data quality and usability.; Exploratory Data Analysis: Performs exploratory data analysis to understand data characteristics and identify insights relevant to reporting and decision-making.; Reporting and Data Reconciliation: Maintains and updates reports and records as needed, and reconciles reporting outputs to source documents to ensure accuracy and consistency.; Process Improvement and Automation: Identifies areas for process improvement or automation to enhance efficiency and accuracy in data handling and reporting workflows.; SQL and SSRS: Utilizes SQL and SQL Server Reporting Services (SSRS) for querying databases and generating reports to support data analysis and reporting requirements.; Excel and VBA: Uses Excel and VBA for data manipulation, analysis, and automation of repetitive tasks within reporting and data preparation processes.; R and Python: Employs R and Python programming languages for data analysis, statistical modeling, and scripting to support data science tasks.; Business Intelligence and Visualization Tools: Leverages business intelligence and visualization software to create dashboards and reports that communicate data insights effectively."
phqd2bATrSnCJjrHAAAAAA==,Senior Data Analytics Specialist - Relocate to Saudi Arabia,"Candidate must relocate to Saudi Arabia.

Aramco energizes the world economy.

Aramco occupies a special position in the global energy industry. We are one of the world’s largest producers of hydrocarbon energy and chemicals, with among the lowest Upstream carbon intensities of any major producer. With our significant investment in technology and infrastructure, we strive to maximize the value of the energy we produce for the world along with a commitment to enhance Aramco’s value to society.

Headquartered in the Kingdom of Saudi Arabia, and with offices around the world, we combine market discipline with a generations’ spanning view of the future, born of our nine decades experience as responsible stewards of the Kingdom’s vast hydrocarbon resources. This responsibility has driven us to deliver significant societal and economic benefits to not just the Kingdom, but also to a vast number of communities, economies, and countries that rely on the vital and reliable energy that we supply.

We are one of the most profitable companies in the world, as well as amongst the top five global companies by market capitalization.

Position description

We are seeking Data Analytics Specialist to join our Digital Engineering Solutions Division under Process & Control Systems Department. Process and Control Systems Department provides services in the field of process engineering, automation, new energy and digitalization to various entities within Aramco.

As a Data Analytics Engineer your role will be to lead innovation within the business and define how the business creates additional value through the utilization of its data assets and analytics. You will identify and solve strategic and tactical analytic business problems to enhance operational efficiency.

Duties and Responsibilities

As a successful candidate you will be required to perform the following:
• Identify and develop advanced analytics use cases to resolve complex technical challenges, optimize processes, enhance revenue, ensure environmental sustainability, and improve safety.
• Drive ideas from conception to production using best-in-class Machine Learning Operations (MLOps) and Development Operations (DevOps) practices.
• Develop and optimize Machine Learning (ML) models and pipelines, ensuring their efficient deployment, monitoring, and scaling.
• Explore diverse data sources to improve predictive modeling and optimize business strategies.
• Assess Artificial Intelligence (AI) tools and methods for data analysis, enhancing business impact and decision-making.
• Implement predictive modeling techniques to optimize production facilities, revenue streams, and operational efficiencies.
• Generate documentation in line with established standards to support the development and deployment process.
• Collaborate with cross-functional teams, including IT, engineering, and business stakeholders, to drive data-driven solutions.
• Contribute to technical task forces investigating incidents and solving domain-specific problems using AI/ML techniques.
• Publish research papers for peer-reviewed journals and presents findings to other organizations and conferences to advance industry knowledge.
• Promotes a learning environment through knowledge-sharing, and fosters a culture of continuous learning and innovation.
• Provide leadership and mentorship to junior team members and specialists.

Minimum Requirements

As a successful candidate you will hold a:
• Bachelor’s degree in Data Science, Computer Science, Engineering, or a related field. An advanced degree (Master’s or PhD) focused on Data Science, AI, or ML Engineering with a background in Engineering is highly preferred.
• 20 years of overall experience, with hands-on experience in Data Science, Natural Language Processing (NLP), Computer Vision, and/or ML projects in the industry.
• Expertise in MLOps, DevOps, AIOps, DataOps and related operational frameworks for model deployment, monitoring, and automation.
• Experience in data collection, cleaning, preprocessing, and wrangling for industry-related problems based on domain knowledge.
• Proficiency in Platforms such as Python, R, SQL, SAS, Scala, and cloud platforms such as Azure and Google Cloud (Vertex AI).
• Expertise in visualization tools and packages; User Interface (UI) experience with Power Business Intelligence (Power BI) or similar tools.
• Experience with IT architecture and deploying models in on-prem environments.
• Strong understanding of continuous integration / continuous deployment (CI/CD) pipelines, containerization (Docker, Kubernetes), and automation frameworks.
• Demonstrated ability to publish research or contribute to industry knowledge through journal papers, conference proceedings, or whitepapers.

Working environment

Our high-performing employees are drawn by the challenging and rewarding professional, technical and industrial opportunities we offer, and are remunerated accordingly. At Aramco, our people work on truly world-scale projects, supported by investment in capital and technology that is second to none. And because, as a global energy company, we are faced with addressing some of the world’s biggest technical, logistical and environmental challenges, we invest heavily in talent development. We have a proud history of educating and training our workforce over many decades. Employees at all levels are encouraged to improve their sector-specific knowledge and competencies through our workforce development programs – one of the largest in the world.",2025-07-21T00:00:00.000Z,2025-07-25,"['Identify and develop advanced analytics use cases to resolve complex technical challenges, optimize processes, enhance revenue, ensure environmental sustainability, and improve safety', 'Bachelor’s degree in Data Science, Computer Science, Engineering, or a related field']","['Process and Control Systems Department provides services in the field of process engineering, automation, new energy and digitalization to various entities within Aramco', 'As a Data Analytics Engineer your role will be to lead innovation within the business and define how the business creates additional value through the utilization of its data assets and analytics', 'You will identify and solve strategic and tactical analytic business problems to enhance operational efficiency', 'Drive ideas from conception to production using best-in-class Machine Learning Operations (MLOps) and Development Operations (DevOps) practices', 'Develop and optimize Machine Learning (ML) models and pipelines, ensuring their efficient deployment, monitoring, and scaling', 'Explore diverse data sources to improve predictive modeling and optimize business strategies', 'Assess Artificial Intelligence (AI) tools and methods for data analysis, enhancing business impact and decision-making', 'Implement predictive modeling techniques to optimize production facilities, revenue streams, and operational efficiencies', 'Generate documentation in line with established standards to support the development and deployment process', 'Collaborate with cross-functional teams, including IT, engineering, and business stakeholders, to drive data-driven solutions', 'Contribute to technical task forces investigating incidents and solving domain-specific problems using AI/ML techniques', 'Publish research papers for peer-reviewed journals and presents findings to other organizations and conferences to advance industry knowledge', 'Promotes a learning environment through knowledge-sharing, and fosters a culture of continuous learning and innovation', 'Provide leadership and mentorship to junior team members and specialists']",True,"['Artificial Intelligence', 'Natural Language Processing', 'Computer Vision', 'AIOps']","Artificial Intelligence: Assess AI tools and methods for data analysis to enhance business impact and decision-making, and contribute to technical task forces solving domain-specific problems using AI/ML techniques.; Natural Language Processing: Hands-on experience in NLP projects within the industry, contributing to data science and AI initiatives.; Computer Vision: Experience in computer vision projects as part of AI and machine learning applications in the industry.; AIOps: Expertise in AIOps frameworks for operationalizing AI models and automating IT and business processes.","['Machine Learning', 'MLOps', 'DevOps', 'Predictive Modeling', 'Data Collection and Preprocessing', 'SQL', 'Python', 'R', 'SAS', 'Scala', 'Cloud Platforms', 'Data Visualization', 'CI/CD Pipelines', 'Containerization']","Machine Learning: Develop and optimize machine learning models and pipelines, ensuring their efficient deployment, monitoring, and scaling to solve strategic and tactical analytic business problems and enhance operational efficiency.; MLOps: Drive ideas from conception to production using best-in-class Machine Learning Operations practices to support model deployment, monitoring, and automation.; DevOps: Utilize Development Operations practices alongside MLOps to drive ideas from conception to production and support continuous integration and deployment pipelines.; Predictive Modeling: Implement predictive modeling techniques to optimize production facilities, revenue streams, and operational efficiencies by exploring diverse data sources to improve business strategies.; Data Collection and Preprocessing: Experience in data collection, cleaning, preprocessing, and wrangling for industry-related problems based on domain knowledge to support analytics and modeling efforts.; SQL: Proficiency in SQL for data querying and manipulation as part of data analytics and engineering tasks.; Python: Use of Python as a primary platform for data science, machine learning, and analytics development.; R: Utilize R programming language for statistical analysis and data science tasks.; SAS: Experience with SAS for advanced analytics and statistical modeling.; Scala: Use of Scala programming language for data processing and analytics.; Cloud Platforms: Proficiency with cloud platforms such as Azure and Google Cloud (including Vertex AI) to deploy and manage data and machine learning solutions.; Data Visualization: Expertise in visualization tools and packages, including Power BI or similar tools, to create dashboards and support data-driven decision-making.; CI/CD Pipelines: Strong understanding and implementation of continuous integration and continuous deployment pipelines to automate and streamline model and software delivery.; Containerization: Experience with containerization technologies such as Docker and Kubernetes to support deployment and scaling of analytics and machine learning models."
aIf525Bn8ViIxXsSAAAAAA==,Sr. Data Standardization Analyst,"Location: Hybrid arrangement, with office located in Pittsburgh, PA; 100% Remote candidates also considered

Job Type: Full-time

Work Authorization: U.S. Citizen or Green Card

The A.C. Coy Company is currently hiring for a full-time Sr. Data Standardization Analyst role. This individual will work with cross-functional teams and manufacturers to develop and apply standards to the product data they supply. Our ideal candidate will have 5+ years of experience in a Data Analytics role and a strong background in data normalization, data flows, data quality, and data risk management.

Our Client is offering flexible hours and a hybrid or remote work arrangement, as well as an attractive benefits package including health coverage, 401K, and unlimited PTO.
• Collaborate closely with assortment and merchandising managers to understand the strategy for the category and define requirements for product data to support that strategy
• Establish standardization rules for the attributes belonging to your assigned product categories
• Design the functional logic for data transformation and conformation to those rules
• Define detailed requirements for technical developers to implement transformation rules
• Perform hands-on data analysis and manipulation to assess gaps in existing data and develop strategies for improving data content and quality
• Work with manufacturer data teams to communicate our data standards and guide them in conforming their data to those standards Save
• Create functional definitions for data transformation to our standards for data elements that cannot be conformed by the manufacturers
• Identify opportunities for improved efficiency in product data standardization processes

Required:
• Bachelor’s Degree in Business, Information Systems, Computer Science or a related field
• 5+ years of experience in a Data Analytics role, including 2+ years of data standardization
• Strong understanding of data, data flows and how data supports various business processes in a supply chain environment
• Understanding of data quality and data risk management, including understanding of standards, methods, processes, tools, and controls
• Excellent organizational and time management skills with the ability to juggle multiple priorities
• Ability to conduct root cause analysis and communicate recommendations to resolve
• Ability to travel 25-50% of the time

Preferred:
• Master's Degree in Business, Information Systems, Computer Science or a related field",2025-07-18T00:00:00.000Z,2025-07-25,"['Work Authorization: U.S. Citizen or Green Card', 'Our ideal candidate will have 5+ years of experience in a Data Analytics role and a strong background in data normalization, data flows, data quality, and data risk management', 'Bachelor’s Degree in Business, Information Systems, Computer Science or a related field', '5+ years of experience in a Data Analytics role, including 2+ years of data standardization', 'Strong understanding of data, data flows and how data supports various business processes in a supply chain environment', 'Understanding of data quality and data risk management, including understanding of standards, methods, processes, tools, and controls', 'Excellent organizational and time management skills with the ability to juggle multiple priorities', 'Ability to conduct root cause analysis and communicate recommendations to resolve', 'Ability to travel 25-50% of the time']","['Data Standardization Analyst role', 'This individual will work with cross-functional teams and manufacturers to develop and apply standards to the product data they supply', 'Collaborate closely with assortment and merchandising managers to understand the strategy for the category and define requirements for product data to support that strategy', 'Establish standardization rules for the attributes belonging to your assigned product categories', 'Design the functional logic for data transformation and conformation to those rules', 'Define detailed requirements for technical developers to implement transformation rules', 'Perform hands-on data analysis and manipulation to assess gaps in existing data and develop strategies for improving data content and quality', 'Work with manufacturer data teams to communicate our data standards and guide them in conforming their data to those standards Save', 'Create functional definitions for data transformation to our standards for data elements that cannot be conformed by the manufacturers', 'Identify opportunities for improved efficiency in product data standardization processes']",True,[],,"['Data Standardization', 'Data Normalization', 'Data Flows', 'Data Quality Management', 'Data Risk Management', 'Root Cause Analysis']","Data Standardization: Developing and applying standards to product data supplied by manufacturers to ensure consistency and quality across data attributes.; Data Normalization: Using techniques to transform and conform product data attributes to established standards to improve data quality and usability.; Data Flows: Understanding and managing how data moves through various business processes, particularly in a supply chain environment, to support data standardization and quality.; Data Quality Management: Assessing gaps in existing data, performing data analysis and manipulation to improve data content, and implementing controls to maintain high data quality standards.; Data Risk Management: Applying standards, methods, processes, tools, and controls to identify and mitigate risks associated with data quality and integrity.; Root Cause Analysis: Conducting investigations to identify underlying issues in data quality or processes and communicating recommendations to resolve these issues."
pMuqDWepe6FzERL2AAAAAA==,Customer Experience Insights - Data Analyst,"AppFolio is more than a company. We’re a community of dreamers, big thinkers, problem solvers, active listeners, and multipliers. At every opportunity, we set the pace while delivering innovation built to carry real estate into the future. One in which every experience feels effortless, yet meaningful. Where customers are empowered to take on any opportunity. We show up as one team, connected by our values to be a force for good. Because together, we have the power to create extraordinary outcomes for our customers, our communities, and ourselves.

We’re seeking a data-driven, customer-obsessed Customer Experience Insights expert to help us better understand our customers and optimize their experience across every touchpoint. You’ll be a critical partner in uncovering actionable insights that guide cross-functional decisions and fuel exceptional customer journeys.

Your impact
• Drive strategic decision-making by identifying customer insights, opportunities, and pain points through the analysis of structured and unstructured data from multiple sources (e.g. surveys, support tickets, call transcripts, NPS/CSAT/Customer Effort scores, behavioral data)
• Socialize insights and influence organizational strategies using tools like Tableau and reports with effective data visualizations and clear narratives
• Enhance cross-functional collaboration by acting as a central hub for customer insights, fostering a shared understanding of the customer across all departments, and promoting a customer-centric culture
• Partner across Services teams to inform and support efforts to build customer experiences based on customer expectations, needs, preferences, and behaviors

Qualifications
• 3–5+ years of experience in customer insights, data analysis, or customer experience strategy roles.
• Familiarity with survey tools (Qualtrics, Alchemer (fka SurveyGizmo)) and VoC platforms.
• Excellent communication skills with the ability to translate data into clear, actionable recommendations.
• Experience interacting cross-functionally with teams such as Product, Customer Support, and Marketing.
• Experience working in a fast-paced, data-driven B2B SaaS environment is preferred.
• Bachelor's degree or equivalent experience.

Must have
• Expertise in analyzing customer feedback data, using tools like Excel/GSheets and SQL, including text analytics experience.
• Experience leveraging data warehouses to extract and transform raw data.
• Strong experience building visualizations in Google Slides or PowerPoint and dashboards in Tableau.
• Strong attention to detail and data accuracy in reporting.
• Curiosity, empathy, and a passion for improving the customer experience.

Location

Find out more about our locations by visiting our site.

Compensation & Benefits

The compensation that we reasonably expect to pay for this role is: $80,000 - $103,000 [base pay / OTE].

The actual compensation for this role will be determined by a variety of factors, including but not limited to the candidate’s skills, education, experience, and internal equity.

Please note that compensation is just one aspect of a comprehensive Total Rewards package. The compensation range listed here does not include additional benefits or any discretionary bonuses you may be eligible for based on your role and/or employment type.

Regular full-time employees are eligible for benefits - see here.",2025-07-14T00:00:00.000Z,2025-07-25,"['3–5+ years of experience in customer insights, data analysis, or customer experience strategy roles', 'Familiarity with survey tools (Qualtrics, Alchemer (fka SurveyGizmo)) and VoC platforms', 'Excellent communication skills with the ability to translate data into clear, actionable recommendations', 'Experience interacting cross-functionally with teams such as Product, Customer Support, and Marketing', ""Bachelor's degree or equivalent experience"", 'Expertise in analyzing customer feedback data, using tools like Excel/GSheets and SQL, including text analytics experience', 'Experience leveraging data warehouses to extract and transform raw data', 'Strong experience building visualizations in Google Slides or PowerPoint and dashboards in Tableau', 'Strong attention to detail and data accuracy in reporting', 'Curiosity, empathy, and a passion for improving the customer experience']","['You’ll be a critical partner in uncovering actionable insights that guide cross-functional decisions and fuel exceptional customer journeys', 'Drive strategic decision-making by identifying customer insights, opportunities, and pain points through the analysis of structured and unstructured data from multiple sources (e.g. surveys, support tickets, call transcripts, NPS/CSAT/Customer Effort scores, behavioral data)', 'Socialize insights and influence organizational strategies using tools like Tableau and reports with effective data visualizations and clear narratives', 'Enhance cross-functional collaboration by acting as a central hub for customer insights, fostering a shared understanding of the customer across all departments, and promoting a customer-centric culture', 'Partner across Services teams to inform and support efforts to build customer experiences based on customer expectations, needs, preferences, and behaviors']",True,[],,"['Customer Feedback Analysis', 'SQL', 'Data Visualization', 'Text Analytics', 'Survey Tools']","Customer Feedback Analysis: Analyzing customer feedback data from multiple sources including surveys, support tickets, call transcripts, and customer satisfaction metrics to identify insights, opportunities, and pain points that inform strategic decision-making and improve customer experience.; SQL: Using SQL to extract and transform raw data from data warehouses to support analysis and reporting.; Data Visualization: Building dashboards and reports using Tableau, Google Slides, and PowerPoint to effectively communicate insights and influence organizational strategies with clear narratives and visual storytelling.; Text Analytics: Applying text analytics techniques to unstructured data such as call transcripts and support tickets to derive meaningful customer insights.; Survey Tools: Utilizing survey platforms like Qualtrics and Alchemer to collect and analyze customer feedback data."
yoPki0mc0ZKhQjdQAAAAAA==,Data Analyst & Data Modeler,"Candidates must have an active U.S. government security clearance, or the ability to obtain one to be considered for this position. Please read the “Security Clearance Eligibility” section below before applying to this position.

NineTwelve is seeking an individual to fill a Data Analyst & Modeler position for a hybrid role in Crane, Indiana. This position requires working onsite in Crane, Indiana, at least 50% of the time and occasionally in Indianapolis. This is a junior-level position that supports a government hypersonic testing program in the gathering and analysis of hypersonic testing data. Ideal candidates have prior government experience in sensor packages, data collection, recovery, and analytics. Additionally, candidates must be self-motivated and highly organized, have the ability to engage and collaborate with key internal and external stakeholders, and take initiative on developing, implementing, and maintaining processes and deliverables.

Security Clearance Eligibility

A candidate must have an active U.S. government security clearance OR be eligible to obtain and hold a security clearance.

Candidates must:
• Be a U.S. citizen.
• Not be considered a dual citizen, AND are not currently holding a passport from a country other than the U.S.
• Not have been dishonorably discharged from the military.
• Not be currently involved in illegal drug use.
• Not had a clearance revoked for security reasons.

DUTIES AND RESPONSIBILITIES
• Create Data Handling and Management Plan (DHMP) Review Template
• Coordinate with the tech Team to get DHMP for a flight test
• Coordinate review of flight test platform DHMPs with all teams/companies represented on HyperLink
• Identify HyperLink data of interest, gaps in data collection, and data uncertainties from the DHMP
• Coordinate with Tech Team to influence instrumentation on the flight to get relevant data from the flight and close gaps identified from DHMP
• Participate in DARs
• Collect documentation from hypersonic community on sensor packages available, whether through MACH-TB or experiments or other programs
• Identify what parameters affect M&S models the most and what flight-testing instrumentation are being used to measure those parameters. Account for data uncertainty introduced by the instrumentation itself
• Populate sensor matrix
• Document data discovery process and storage requirements

QUALIFICATIONS & SKILLS
• Bachelor's degree in engineering, Computer Science, or related field
• 1-2 years of Data Analytics experience in government (preferred)
• Knowledge or awareness of flight-testing sensors, on and off-board
• Experience reading and using DHMPs
• Data entry and/or engineering skills
• Data analysis experience
• Excellent oral and written communication and interpersonal skills
• Highly organized
• Ability to interface, collaborate, and build working relationships with government representatives, internal personnel, contractors, and other stakeholders

EDUCATION

Bachelor's degree in engineering, computer science, or related field

REQUIRED QUALIFICATIONS

Active U.S. government security clearance, or the ability to obtain one (see SECURITY CLEARANCE ELIGIBILITY)

COMPENSATION

The salary range is $60,000-$85,000 (per year) and is based on experience and qualifications. Benefits include company sponsored health insurance, 401k, and two weeks’ PTO for full-time employees.",2025-07-24T00:00:00.000Z,2025-07-25,"['Candidates must have an active U.S. government security clearance, or the ability to obtain one to be considered for this position', 'Ideal candidates have prior government experience in sensor packages, data collection, recovery, and analytics', 'Additionally, candidates must be self-motivated and highly organized, have the ability to engage and collaborate with key internal and external stakeholders, and take initiative on developing, implementing, and maintaining processes and deliverables', 'A candidate must have an active U.S. government security clearance OR be eligible to obtain and hold a security clearance', 'Be a U.S. citizen', 'Not be considered a dual citizen, AND are not currently holding a passport from a country other than the U.S', 'Not have been dishonorably discharged from the military', 'Not be currently involved in illegal drug use', 'Not had a clearance revoked for security reasons', 'Document data discovery process and storage requirements', ""Bachelor's degree in engineering, Computer Science, or related field"", 'Knowledge or awareness of flight-testing sensors, on and off-board', 'Experience reading and using DHMPs', 'Data entry and/or engineering skills', 'Data analysis experience', 'Excellent oral and written communication and interpersonal skills', 'Highly organized', 'Ability to interface, collaborate, and build working relationships with government representatives, internal personnel, contractors, and other stakeholders', ""Bachelor's degree in engineering, computer science, or related field"", 'Active U.S. government security clearance, or the ability to obtain one (see SECURITY CLEARANCE ELIGIBILITY)']","['Create Data Handling and Management Plan (DHMP) Review Template', 'Coordinate with the tech Team to get DHMP for a flight test', 'Coordinate review of flight test platform DHMPs with all teams/companies represented on HyperLink', 'Identify HyperLink data of interest, gaps in data collection, and data uncertainties from the DHMP', 'Coordinate with Tech Team to influence instrumentation on the flight to get relevant data from the flight and close gaps identified from DHMP', 'Participate in DARs', 'Collect documentation from hypersonic community on sensor packages available, whether through MACH-TB or experiments or other programs', 'Identify what parameters affect M&S models the most and what flight-testing instrumentation are being used to measure those parameters', 'Account for data uncertainty introduced by the instrumentation itself', 'Populate sensor matrix']",True,[],,"['Data Handling and Management Plan (DHMP)', 'Data Collection and Recovery', 'Data Analysis', 'Sensor Data and Instrumentation', 'Data Uncertainty Management', 'Data Documentation and Storage Requirements']","Data Handling and Management Plan (DHMP): Used to review and coordinate data collection and management processes for flight tests, ensuring relevant data is captured and gaps or uncertainties are identified and addressed.; Data Collection and Recovery: Involves gathering hypersonic testing data from sensor packages and flight instrumentation, and ensuring data integrity and completeness for analysis.; Data Analysis: Applied to analyze hypersonic testing data, identify parameters affecting modeling and simulation (M&S) models, and support decision-making related to flight test instrumentation and data quality.; Sensor Data and Instrumentation: Knowledge and awareness of flight-testing sensors, both on-board and off-board, to understand data sources, measurement parameters, and uncertainties introduced by instrumentation.; Data Uncertainty Management: Accounting for uncertainties introduced by flight-testing instrumentation to improve the reliability and accuracy of data used in modeling and analysis.; Data Documentation and Storage Requirements: Documenting the data discovery process and defining storage needs to ensure proper data management and accessibility for hypersonic testing programs."
9ZfVslBUqr53kvS6AAAAAA==,Lead Data Analyst,"Overview

Come join Bethesda Game Studios, the award-winning development team behind Starfield, The Elder Scrolls and Fallout. Bethesda Game Studios strives to offer its employees a well-balanced home and work life by providing competitive salaries, a generous benefits program, and offices located in some of North America’s best cities.

With a goal of creating a culture as fun and diverse as our games and our players, we welcome applicants with unique skillsets, experience levels and backgrounds. If you are passionate about making a meaningful contribution to some of the most significant games in the industry, we’d love to hear from you!

We will consider candidates for any of our four Bethesda Game Studios office locations: Rockville, MD; Montreal, Quebec; Austin, TX; Dallas, TX.

Responsibilities

Your Daily Life at Bethesda Game Studios

As Lead Data Analyst, you will…
• Lead a small team of data analysts focused on engagement, performance, and stability for a portfolio of Bethesda’s games (usually 2-3 related titles)
• Partner with design, production, and business counterparts to elicit and document data needs, gather requirements, and translate them into product specifications and development priorities.
• Establish guidelines and documentation for the data analytics workflow; act as a bridge between technical and non-technical stakeholders to ensure alignment on the use of analytics to support product vision and goals.
• Mentor team members on analytics and communication best practices; conduct feedback and reviews to ensure their growth and smooth integration of new team members.
• Identify trends in game and business data to advise development team and senior leadership on product strategy and opportunities based on technical expertise, quantitative and qualitative analysis, and forecasting.
• Provide actionable insights and analysis to our development and business teams to facilitate the full cycle of game development
• Act as a subject matter expert and resource for best practices in accessing and analyzing data using available reporting methods
• Own the roadmap for data analytics products supporting the product strategy for assigned portfolio of titles. Assist with task assignment towards that goal, when necessary.
• Work with data and gameplay programmers to design, develop, launch, and maintain scalable data products, ensuring that they meet high standards of performance, usability, and accuracy

Qualifications

What Makes You S.P.E.C.I.A.L.
• You have 5 or more years of experience in a data analyst role.
• You have 3 or more years of experience in a lead or manager role
• You possess management skills, including the capacity to provide feedback to and help direct a team of data analysts as well as manage programs for data collection.
• You have applied knowledge of current data analysis visualization techniques, including practical experience with data visualization software (e.g. Tableau, Looker)
• You have strong critical thinking skills with knowledge and experience in analytic techniques and statistics
• You have strong to advanced SQL knowledge, including familiarity with statistical, aggregate, and windowing functions
• You are able to gather requirements and define business needs for data collection and analysis, especially within the game development field
• You have excellent verbal and written communication skills
• You have a passion for Bethesda Game Studios titles

Salary Range

Lead Data Analyst - The typical base pay range for this position at the start of employment is expected to be between $115,000 - $220,000 per year.

ZeniMax has different base pay ranges for different work locations within the United States, which allows us to pay employees competitively and consistently in different geographic markets. The range above reflects the potential base pay across the U.S. for this role; the applicable base pay range will depend on what ultimately is determined to be the candidate’s primary work location. Individual base pay depends on various factors, in addition to primary work location, such as complexity and responsibility of role, job duties/requirements, and relevant experience and skills. Base pay ranges are reviewed and typically updated each year. Offers are made within the base pay range applicable at the time.

At ZeniMax certain roles are eligible for additional rewards, such as merit increases and discretionary bonuses. These awards are allocated based on individual performance and are not guaranteed. Benefits/perks listed here may vary depending on the nature of employment with ZeniMax and the country work location. U.S.-based employees have access to healthcare benefits, a 401(k) plan and company match, short-term and long-term disability coverage, basic life insurance, wellbeing benefits, paid vacation time, paid sick and mental health time, and several paid holidays, among others.

This position is in a union and represented by the Communication Workers of America.

We embrace diversity, equity, and inclusion in everything we do – from recruiting for our studios, publishing and operations to fostering safe and respectful workplaces that encourage collaboration. Our culture is based on principles of respect, inclusion, and fair treatment and we welcome anyone into our family without regard to race, religion, gender identity, sexual orientation, or age.

Our diversity fuels our innovation and inspires us to create game worlds that bring us closer to the global community of players we serve.",,2025-07-25,"['You have 5 or more years of experience in a data analyst role', 'You have 3 or more years of experience in a lead or manager role', 'You possess management skills, including the capacity to provide feedback to and help direct a team of data analysts as well as manage programs for data collection', 'You have applied knowledge of current data analysis visualization techniques, including practical experience with data visualization software (e.g', 'You have strong critical thinking skills with knowledge and experience in analytic techniques and statistics', 'You have strong to advanced SQL knowledge, including familiarity with statistical, aggregate, and windowing functions', 'You are able to gather requirements and define business needs for data collection and analysis, especially within the game development field', 'You have excellent verbal and written communication skills']","['Lead a small team of data analysts focused on engagement, performance, and stability for a portfolio of Bethesda’s games (usually 2-3 related titles)', 'Partner with design, production, and business counterparts to elicit and document data needs, gather requirements, and translate them into product specifications and development priorities', 'Establish guidelines and documentation for the data analytics workflow; act as a bridge between technical and non-technical stakeholders to ensure alignment on the use of analytics to support product vision and goals', 'Mentor team members on analytics and communication best practices; conduct feedback and reviews to ensure their growth and smooth integration of new team members', 'Identify trends in game and business data to advise development team and senior leadership on product strategy and opportunities based on technical expertise, quantitative and qualitative analysis, and forecasting', 'Provide actionable insights and analysis to our development and business teams to facilitate the full cycle of game development', 'Act as a subject matter expert and resource for best practices in accessing and analyzing data using available reporting methods', 'Own the roadmap for data analytics products supporting the product strategy for assigned portfolio of titles', 'Assist with task assignment towards that goal, when necessary', 'Work with data and gameplay programmers to design, develop, launch, and maintain scalable data products, ensuring that they meet high standards of performance, usability, and accuracy']",True,[],,"['Data Visualization Tools', 'SQL', 'Data Analytics Workflow', 'Quantitative and Qualitative Analysis', 'Forecasting', 'Data Collection Management', 'Team Leadership in Data Analytics', 'Scalable Data Products Development']","Data Visualization Tools: The job requires practical experience with data visualization software such as Tableau and Looker to support data analysis and communication of insights.; SQL: Strong to advanced knowledge of SQL is required, including familiarity with statistical, aggregate, and windowing functions to query and analyze game and business data.; Data Analytics Workflow: The role involves establishing guidelines and documentation for the data analytics workflow to ensure alignment between technical and non-technical stakeholders and support product vision and goals.; Quantitative and Qualitative Analysis: The position requires identifying trends in game and business data through quantitative and qualitative analysis to advise development teams and senior leadership on product strategy and opportunities.; Forecasting: The job includes using forecasting techniques to analyze data trends and provide actionable insights for game development and business strategy.; Data Collection Management: Managing programs for data collection is a key responsibility, including gathering requirements and defining business needs for data collection and analysis within the game development field.; Team Leadership in Data Analytics: The role involves leading and mentoring a small team of data analysts, providing feedback, and ensuring smooth integration and growth of team members focused on game engagement, performance, and stability.; Scalable Data Products Development: Collaborating with data and gameplay programmers to design, develop, launch, and maintain scalable data products that meet high standards of performance, usability, and accuracy."
zQ9-rN43aeJNuHiIAAAAAA==,Senior Digital Data Analyst,"Overview

You have a passion for data—finding answers, creating stories, and driving business results. Come, love what you do as a Senior Digital Data Analyst at Room & Board.

As a Senior Digital Data Analyst at Room & Board, you’ll play a pivotal role in advancing our e-commerce strategy, which has grown from basic reporting to sophisticated, data-driven personalization and optimization powered by Adobe Experience Cloud tools. You’ll lead initiatives in analytics, personalization, and data pipeline development—bridging technical implementation with business strategy to deliver scalable, personalized customer experiences that drive measurable outcomes.

You’ll work hands-on with Adobe Analytics SDK, Adobe Target Premium, Adobe Tags, and Alteryx, collaborating with teams across brand experience, product, web development, and business systems. With approximately 10–20% of your time focused on data science and the rest dedicated to implementation and analytics, you’ll be a key leader in shaping our data-driven approach to e-commerce.

Location: Our Central Office

4600 Olson Memorial Highway, Golden Valley, MN 55422

Please note: This is a hybrid role working 3 days in our office. We are not currently considering fully remote candidates.

You’ll share your talents as a Senior Digital Data Analyst in the following ways:
• Lead the implementation and maintenance of digital analytics tools and infrastructure, applying strong hands-on experience to ensure scalable, reliable data systems.
• Shape and evolve our personalization strategy by defining audience segments, setting conversion goals, and executing A/B testing and targeted experiences.
• Build and optimize data pipelines that support reporting, personalization, and marketing strategies.
• Serve as the primary analytics and personalization contact, collaborating across web development, digital experience, branding, product, and business systems teams.
• Ensure data accuracy and governance through tag management, tagging audits, and data quality initiatives.
• Manage analytics projects aligned with marketing campaigns, product launches, and development timelines, balancing strategic priorities with execution.
• Develop predictive models and segmentation strategies to support business goals and enhance customer experiences.
• Deliver ongoing and ad hoc reporting, translating complex data into actionable insights for stakeholders.
• Foster a culture of continuous learning by sharing best practices and encouraging data-driven decision-making.
• Partner with the Director of Business Intelligence to define and execute long-term analytics and personalization strategies, including regular audits and roadmap development.

The attributes you’ll bring as a Senior Digital Data Analyst:

You exemplify our Staff Member Attributes – Inclusive, Authentic, Work Ethic, Collaborative, and Curious.
• You build inclusive environments by aligning analytics efforts with diverse team needs.
• You communicate transparently and align your work with Room & Board’s customer-centric values.
• You demonstrate accountability and a commitment to delivering high-quality, data-driven outcomes.
• You collaborate effectively across departments to drive shared goals.
• You’re curious and proactive in exploring new technologies and personalization strategies.
• You support others by sharing expertise, offering feedback, and fostering a culture of innovation.
• You have excellent verbal and written communication skills and can convey complex data clearly to diverse audiences.

The knowledge, education, and experience you’ll bring as a Senior Digital Data Analyst:
• Bachelor’s degree in Data Science, Statistics, Computer Science, or a related quantitative field.
• 5+ years of experience in e-commerce or digital marketing as a Data Scientist or similar role.
• Certifications (preferred): Adobe Analytics Data Analyst/Developer, Adobe Experience Platform Data Engineer, Adobe Target Business Practitioner.
• Proficiency in Adobe Tags, Adobe Analytics SDK, and Adobe Target.
• Expertise in predictive modeling, statistical analysis, and machine learning.
• Experience with ETL tools like Alteryx and API data connections.
• Strong programming skills in Python or R, Java, REGEX, and SQL.
• Familiarity with A4T integration and e-commerce metrics.

What you'll find working here as a Senior Digital Data Analyst:
• Salary: $120,000 - $160,000 / year based on experience/qualifications.
• Benefits that focus on holistic well-being. The whole person matters, not just the one who shows up for work. That's why we invest in holistic well-being that supports and encourages you to live a full life. Besides a competitive paycheck, we offer several awesome perks to help you thrive in every aspect of life. Picture this: three weeks paid vacation, a generous 401(k) match, profit-sharing, and a whole bunch of cool extras. And here's something we're especially proud of - we're a 100% employee-owned company. Through our Employee Stock Ownership Plan, every staff member shares in our growth and success. These are benefits that support you physically, emotionally, and financially - from head to toe!
• Meaningful work. We create a meaningful work experience by empowering everyone to contribute, taking pride in everything we do, and making the world sustainable, inclusive and beautiful.
• A culture of respect. We sustain a culture of respect by relying on our shared values, building supportive and kind teams, and ensuring all voices are heard and celebrated. To view our benefits in detail and to learn more about our culture, please visit our career site at https://www.roomanboard.com/careers.

Application Deadline: The position will remain open until filled; there is no specified deadline.

Room and Board is a modern furniture and home decor retailer committed to creating beautiful, well-made products while providing exceptional customer service. Our mission is to help people create homes they love through timeless designs, sustainable practices, and a focus on quality craftsmanship. To view our benefits in detail and to learn more about our culture, please visit our career site at https://www.roomanboard.com/careers.

Room & Board is an equal employment opportunity employer. Our policy is not to unlawfully discriminate against any applicant or staff member on the basis of age, race, color, sex, sexual orientation, gender identity or expression, religion, national origin, disability, or any other consideration made unlawful by applicable federal, state, or local laws. We also prohibit harassment of applicants and staff members based on any protected category, characteristic or status. It is also our policy to comply with all applicable state, federal and local laws respecting consideration of unemployment status in making hiring decisions.

As an applicant, you have rights under Federal Employment Laws, and your state may offer additional protections. To view applicable laws, visit our partner site.

Discover a career designed to be different.

Salary",2025-07-25T04:00:00.000Z,2025-07-25,"['You support others by sharing expertise, offering feedback, and fostering a culture of innovation', 'You have excellent verbal and written communication skills and can convey complex data clearly to diverse audiences', 'The knowledge, education, and experience you’ll bring as a Senior Digital Data Analyst:', 'Bachelor’s degree in Data Science, Statistics, Computer Science, or a related quantitative field', '5+ years of experience in e-commerce or digital marketing as a Data Scientist or similar role', 'Proficiency in Adobe Tags, Adobe Analytics SDK, and Adobe Target', 'Expertise in predictive modeling, statistical analysis, and machine learning', 'Experience with ETL tools like Alteryx and API data connections', 'Strong programming skills in Python or R, Java, REGEX, and SQL', 'Familiarity with A4T integration and e-commerce metrics']","['As a Senior Digital Data Analyst at Room & Board, you’ll play a pivotal role in advancing our e-commerce strategy, which has grown from basic reporting to sophisticated, data-driven personalization and optimization powered by Adobe Experience Cloud tools', 'You’ll lead initiatives in analytics, personalization, and data pipeline development—bridging technical implementation with business strategy to deliver scalable, personalized customer experiences that drive measurable outcomes', 'You’ll work hands-on with Adobe Analytics SDK, Adobe Target Premium, Adobe Tags, and Alteryx, collaborating with teams across brand experience, product, web development, and business systems', 'With approximately 10–20% of your time focused on data science and the rest dedicated to implementation and analytics, you’ll be a key leader in shaping our data-driven approach to e-commerce', 'Lead the implementation and maintenance of digital analytics tools and infrastructure, applying strong hands-on experience to ensure scalable, reliable data systems', 'Shape and evolve our personalization strategy by defining audience segments, setting conversion goals, and executing A/B testing and targeted experiences', 'Build and optimize data pipelines that support reporting, personalization, and marketing strategies', 'Serve as the primary analytics and personalization contact, collaborating across web development, digital experience, branding, product, and business systems teams', 'Ensure data accuracy and governance through tag management, tagging audits, and data quality initiatives', 'Manage analytics projects aligned with marketing campaigns, product launches, and development timelines, balancing strategic priorities with execution', 'Develop predictive models and segmentation strategies to support business goals and enhance customer experiences', 'Deliver ongoing and ad hoc reporting, translating complex data into actionable insights for stakeholders', 'Foster a culture of continuous learning by sharing best practices and encouraging data-driven decision-making', 'Partner with the Director of Business Intelligence to define and execute long-term analytics and personalization strategies, including regular audits and roadmap development', 'You exemplify our Staff Member Attributes – Inclusive, Authentic, Work Ethic, Collaborative, and Curious', 'You build inclusive environments by aligning analytics efforts with diverse team needs', 'You communicate transparently and align your work with Room & Board’s customer-centric values', 'You demonstrate accountability and a commitment to delivering high-quality, data-driven outcomes', 'You collaborate effectively across departments to drive shared goals', 'You’re curious and proactive in exploring new technologies and personalization strategies']",True,[],,"['Predictive Modeling', 'Statistical Analysis', 'Machine Learning', 'A/B Testing', 'Data Pipelines', 'SQL', 'Python', 'R', 'Java', 'REGEX', 'ETL Tools', 'Adobe Analytics SDK', 'Adobe Target', 'Adobe Tags', 'Digital Analytics Tools', 'Data Governance', 'Reporting and Dashboards', 'Personalization Strategy']","Predictive Modeling: Develop predictive models and segmentation strategies to support business goals and enhance customer experiences.; Statistical Analysis: Apply statistical analysis techniques as part of data science efforts to derive insights and support personalization and optimization strategies.; Machine Learning: Utilize machine learning methods to advance e-commerce strategy and personalization initiatives.; A/B Testing: Execute A/B testing to define audience segments, set conversion goals, and optimize targeted experiences.; Data Pipelines: Build and optimize data pipelines that support reporting, personalization, and marketing strategies.; SQL: Use SQL programming skills to manage and query data relevant to analytics and reporting.; Python: Apply Python programming skills for data science, analytics, and pipeline development tasks.; R: Use R programming skills for statistical analysis and data science activities.; Java: Employ Java programming skills as part of technical implementation and analytics work.; REGEX: Utilize REGEX for data parsing, tagging audits, and ensuring data quality.; ETL Tools: Use ETL tools like Alteryx and API data connections to extract, transform, and load data for analytics and personalization.; Adobe Analytics SDK: Work hands-on with Adobe Analytics SDK to implement and maintain digital analytics tools and infrastructure.; Adobe Target: Leverage Adobe Target Premium for personalization strategy, including audience segmentation and targeted experiences.; Adobe Tags: Manage Adobe Tags for tag management, tagging audits, and ensuring data accuracy and governance.; Digital Analytics Tools: Lead the implementation and maintenance of digital analytics tools and infrastructure to ensure scalable and reliable data systems.; Data Governance: Ensure data accuracy and governance through tag management, tagging audits, and data quality initiatives.; Reporting and Dashboards: Deliver ongoing and ad hoc reporting, translating complex data into actionable insights for stakeholders.; Personalization Strategy: Shape and evolve personalization strategy by defining audience segments, setting conversion goals, and executing targeted experiences."
Da7J1WaGX3sj9qDgAAAAAA==,Data Analyst,"Odyssey Reinsurance Company (OdysseyRe) is the global reinsurance arm of Odyssey Group, one of the world’s leading providers of reinsurance and specialty insurance. OdysseyRe offers a broad range of property, casualty, and specialty reinsurance products, providing capital and risk management solutions for clients to efficiently manage economic risk through a network of branch and representative offices across North America, Latin America, EMEA (Europe, Middle East & Africa), AsiaPacific and London.

OdysseyRe is an equal opportunity employer with excellent benefits and a strong commitment to providing training and opportunities for our staff. We provide employees an innovative, enriching environment and take great pride in their career growth.

OdysseyRe is rated A+ (Superior) by AM Best and A+ (Strong) by Standard and Poor’s. Odyssey Group is a subsidiary of Fairfax Financial Holdings Limited, which is traded on the Toronto Stock Exchange under the symbol FFH.

Data Analyst

We are an E-Verify employer - all hired positions require successfully passing an E-Verify Check.

Navigate the links below to learn more about careers at OdysseyRe.

Workplace Initiatives

Career Areas for Professionals

A Rewarding Workplace

Follow us on LinkedIn for company highlights",2025-07-20T00:00:00.000Z,2025-07-25,,,False,,,,
cmKgYTV8VSvb052yAAAAAA==,Lead Data Analyst,"Vanguard is looking for a senior level data analyst with experience presenting recommendations to senior management, developing innovative solutions, and is technically skilled in data quality & analytics tools. You will become an expert in the critical data managed, provide thought leadership into transformative decisions and initiatives, and deepen relationships and business acumen while consulting with stakeholders and partners, inclusive of our external data vendors. By innovating new ways to improve our data management processes to enable AI ready data, we want to leverage evolving data management capabilities and analytics tools to move our clients forward creating trusted data to support AI and BI solutions.

Core Responsibilities
• Serves as a subject matter expert (SME) of data sets for a given industry, data storage systems, and the operational processes being supported. Maintains awareness of changing business needs to create appropriate project solutions.
• Leads process design efforts to support new offerings, business initiatives, or improvement projects. Performs root cause analyses of complex data errors. Identifies opportunities to eliminate future occurrences, prioritizes initiatives, mitigates risk, leverages technology, and recommends short- and long-term solutions for issues.
• Focuses on improving Data Management's service offer and communicates with stakeholders and management to obtain their input and buy-in as appropriate. Recommends, coordinates, documents, and implements changes that will enhance work-flows and procedures. Integrates new or existing technologies into work-flows and communicates to all team members. Analyzes impacts and prepares environment for change.
• Builds and maintains relationships with internal and external partners to define data requirements, develop project specifications, and execute data projects to ensure that the expected outputs are delivered. Provides validation and approval of project deliverables.
• Identifies solutions independently and with input from internal and external partners, external vendors, and industry contacts to enable best-in-class data management practices, scalability, and cost effectiveness. Leads and consults on new projects to ensure operational readiness upon implementation into the live environment.
• Participates in special projects and performs other duties as assigned.

Qualifications
• Intermediate to advanced technical skills required – SQL, Python, AWS, Tableau
• Strong consultation, data storytelling, and stakeholder management skills
• Strong professional presence and experience presenting recommendations to senior management.
• Strong data analysis and problem-solving skills.
• Skilled and passionate about developing innovative solutions.
• Expertise in Data Management & Data Quality best practices.
• Financial or Investment data background is a plus.
• Minimum of five years of related work experience.
• Undergraduate degree or equivalent combination of training and experience. Graduate degree preferred.
• Nice to have- MS Dynamics

Special Factors

Sponsorship
Vanguard is not offering visa sponsorship for this position.

About Vanguard

At Vanguard, we don't just have a mission—we're on a mission.

To work for the long-term financial wellbeing of our clients. To lead through product and services that transform our clients' lives. To learn and develop our skills as individuals and as a team. From Malvern to Melbourne, our mission drives us forward and inspires us to be our best.

How We Work

Vanguard has implemented a hybrid working model for the majority of our crew members, designed to capture the benefits of enhanced flexibility while enabling in-person learning, collaboration, and connection. We believe our mission-driven and highly collaborative culture is a critical enabler to support long-term client outcomes and enrich the employee experience.",2025-07-18T00:00:00.000Z,2025-07-25,"['Vanguard is looking for a senior level data analyst with experience presenting recommendations to senior management, developing innovative solutions, and is technically skilled in data quality & analytics tools', 'Intermediate to advanced technical skills required – SQL, Python, AWS, Tableau', 'Strong consultation, data storytelling, and stakeholder management skills', 'Strong professional presence and experience presenting recommendations to senior management', 'Strong data analysis and problem-solving skills', 'Skilled and passionate about developing innovative solutions', 'Expertise in Data Management & Data Quality best practices', 'Minimum of five years of related work experience', 'Undergraduate degree or equivalent combination of training and experience']","['You will become an expert in the critical data managed, provide thought leadership into transformative decisions and initiatives, and deepen relationships and business acumen while consulting with stakeholders and partners, inclusive of our external data vendors', 'By innovating new ways to improve our data management processes to enable AI ready data, we want to leverage evolving data management capabilities and analytics tools to move our clients forward creating trusted data to support AI and BI solutions', 'Serves as a subject matter expert (SME) of data sets for a given industry, data storage systems, and the operational processes being supported', 'Maintains awareness of changing business needs to create appropriate project solutions', 'Leads process design efforts to support new offerings, business initiatives, or improvement projects', 'Performs root cause analyses of complex data errors', 'Identifies opportunities to eliminate future occurrences, prioritizes initiatives, mitigates risk, leverages technology, and recommends short- and long-term solutions for issues', ""Focuses on improving Data Management's service offer and communicates with stakeholders and management to obtain their input and buy-in as appropriate"", 'Recommends, coordinates, documents, and implements changes that will enhance work-flows and procedures', 'Integrates new or existing technologies into work-flows and communicates to all team members', 'Analyzes impacts and prepares environment for change', 'Builds and maintains relationships with internal and external partners to define data requirements, develop project specifications, and execute data projects to ensure that the expected outputs are delivered', 'Provides validation and approval of project deliverables', 'Identifies solutions independently and with input from internal and external partners, external vendors, and industry contacts to enable best-in-class data management practices, scalability, and cost effectiveness', 'Leads and consults on new projects to ensure operational readiness upon implementation into the live environment', 'Participates in special projects and performs other duties as assigned']",True,[],,"['SQL', 'Python', 'AWS', 'Tableau', 'Data Quality', 'Data Management', 'Data Storytelling', 'Root Cause Analysis', 'Stakeholder Management']","SQL: Used as a technical skill for querying and managing data within the organization's data management processes.; Python: Utilized as a technical skill to develop innovative data solutions and perform data analysis tasks.; AWS: Applied as a cloud platform to support data storage, management, and analytics capabilities.; Tableau: Employed as a BI tool to create dashboards and support data storytelling and visualization for stakeholders and senior management.; Data Quality: Expertise required to ensure accuracy, consistency, and reliability of data used in analytics and decision-making processes.; Data Management: Involves managing critical data sets, improving data management processes, and enabling AI-ready data to support analytics and business intelligence solutions.; Data Storytelling: Skill used to effectively communicate data insights and recommendations to senior management and stakeholders.; Root Cause Analysis: Performed to identify and resolve complex data errors and improve data processes.; Stakeholder Management: Engaged to consult with internal and external partners, including external data vendors, to define data requirements and ensure project success."
sAxzYOVGt9V0xvF9AAAAAA==,Systems and Data Analyst (Systems and Data Analyst-General),"Job Description

At Boeing, we innovate and collaborate to make the world a better place. We’re committed to fostering an environment for every teammate that’s welcoming, respectful and inclusive, with great opportunity for professional growth. Find your future with us.

Boeing Global Services, Digital Solutions & Analytics (DS&A) is seeking a level 2 Technical Product Support Analyst for 24x7x365 technical customer support. The scope of support covers Boeing’s current and next generation Software as a Service (SaaS) platforms, licensed software products, Identity and Access Management services spanning large-scale hybrid cloud environments. This includes e-Commerce, traditional web application and native mobile application delivery channels.

This position may be based out of our Seattle Washington and/or Englewood Colorado offices.

Your primary job responsibilities include technical product support investigating, analyzing, troubleshooting, and resolving high/medium/low priority service requests from our internal (Boeing) and external Customers (Aircraft Owner, Operator, MRO, Partners and Suppliers) as defined in our Licensed Software Support Policy.

This is a variable shift position and shift slotting will be determined by business and customer needs.

Position Responsibilities:
• Provide responsive 24x7x365 world class technical customer service and support for service requests, phone calls and email inquiries.
• Utilize and maintain knowledge, troubleshooting guides and self-help resources for internal team and external customer usage.
• Contribute to continuous improvement, problem management, root cause and corrective action (RCCA) activities to improve customer satisfaction, reduce repetitive issues, and eliminate negative impacting events.
• Draft and publish global communications for hardware/software related changes, upgrades, issues, known defects and high/medium priority alerts.
• Continuous learning by staying up to date with new software/hardware products, features and Information Technology (IT) support methods.
• Be a resource and partner with cross functional and matrix organization team members in delivering superior customer service and support.

Basic Qualifications (Required Skills/Experience):
• Experience and competency in troubleshooting, analysis and problem solving strategies to address simple to complex customer inquiries.
• Effective written and speaking skills to communicate with individuals with English as a primary language and those with English as a second language.
• Willingness to work in 24x7x365 technical customer support environment.

Preferred Qualifications (Desired Skills/Experience):
• Associate’s degree or higher
• IT support or equivalent background across one or more of the software systems development / sustaining disciplines a plus.
• Project management tools and practices as well as knowledge of project and software implementation a plus.
• Knowledge and/or experience within the aviation industry
• Knowledge of Aviation training practices and protocols.

Drug Free Workplace:

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Pay & Benefits:

At Boeing, we strive to deliver a Total Rewards package that will attract, engage and retain the top talent. Elements of the Total Rewards package include competitive base pay and variable compensation opportunities.

The Boeing Company also provides eligible employees with an opportunity to enroll in a variety of benefit programs, generally including health insurance, flexible spending accounts, health savings accounts, retirement savings plans, life and disability insurance programs, and a number of programs that provide for both paid and unpaid time away from work.

The specific programs and options available to any given employee may vary depending on eligibility factors such as geographic location, date of hire, and the applicability of collective bargaining agreements.

Pay is based upon candidate experience and qualifications, as well as market and business considerations.

Summary Pay Range: $75,650.00-$102,350.00

Applications for this position will be accepted until Jul. 24, 2025

Export Control Requirements: This position must meet export control compliance requirements. To meet export control compliance requirements, a “U.S. Person” as defined by 22 C.F.R. §120.15 is required. “U.S. Person” includes U.S. Citizen, lawful permanent resident, refugee, or asylee.

Export Control Details: US based job, US Person required

Relocation

Relocation assistance is not a negotiable benefit for this position.

Visa Sponsorship

Employer will not sponsor applicants for employment visa status.

Shift

This position is for 2nd shift

Equal Opportunity Employer:

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.",2025-07-08T00:00:00.000Z,2025-07-25,"['Experience and competency in troubleshooting, analysis and problem solving strategies to address simple to complex customer inquiries', 'Effective written and speaking skills to communicate with individuals with English as a primary language and those with English as a second language', 'Willingness to work in 24x7x365 technical customer support environment', 'To meet export control compliance requirements, a “U.S. Person” as defined by 22 C.F.R. §120.15 is required', '“U.S. Person” includes U.S. Citizen, lawful permanent resident, refugee, or asylee', 'Export Control Details: US based job, US Person required']","['The scope of support covers Boeing’s current and next generation Software as a Service (SaaS) platforms, licensed software products, Identity and Access Management services spanning large-scale hybrid cloud environments', 'Your primary job responsibilities include technical product support investigating, analyzing, troubleshooting, and resolving high/medium/low priority service requests from our internal (Boeing) and external Customers (Aircraft Owner, Operator, MRO, Partners and Suppliers) as defined in our Licensed Software Support Policy', 'This is a variable shift position and shift slotting will be determined by business and customer needs', 'Provide responsive 24x7x365 world class technical customer service and support for service requests, phone calls and email inquiries', 'Utilize and maintain knowledge, troubleshooting guides and self-help resources for internal team and external customer usage', 'Contribute to continuous improvement, problem management, root cause and corrective action (RCCA) activities to improve customer satisfaction, reduce repetitive issues, and eliminate negative impacting events', 'Draft and publish global communications for hardware/software related changes, upgrades, issues, known defects and high/medium priority alerts', 'Continuous learning by staying up to date with new software/hardware products, features and Information Technology (IT) support methods', 'Be a resource and partner with cross functional and matrix organization team members in delivering superior customer service and support', 'Export Control Requirements: This position must meet export control compliance requirements']",False,,,,
yc4y5bmxG1zHCC8fAAAAAA==,"Analyst, Data Analytics, US Portfolio Transformation","At Johnson & Johnson, we believe health is everything. Our strength in healthcare innovation empowers us to build a world where complex diseases are prevented, treated, and cured, where treatments are smarter and less invasive, and solutions are personal. Through our expertise in Innovative Medicine and MedTech, we are uniquely positioned to innovate across the full spectrum of healthcare solutions today to deliver the breakthroughs of tomorrow, and profoundly impact health for humanity. Learn more at https://www.jnj.com

Job Function:
Sales Enablement

Job Sub Function:
Sales Operations & Administration

Job Category:
Professional

All Job Posting Locations:
Cincinnati, Ohio, United States of America, Raritan, New Jersey, United States of America

Job Description:

Johnson & Johnson is recruiting for an Analyst, Data Analytics, US Portfolio Transformation to join our MedTech Surgery business located at our Raritan, NJ or Cincinnati, OH sites.

#Li-Hybrid

This is a limited duration role. (12/31/2026 end date)

Eligibility for severance.

About Surgery

Fueled by innovation at the intersection of biology and technology, we're developing the next generation of smarter, less invasive, more personalized treatments.

Are you passionate about improving and expanding the possibilities of surgery? Ready to join a team that's reimagining how we heal? Our Surgery team will give you the chance to deliver surgical technologies and solutions to surgeons and healthcare professionals around the world. Your contributions will help effectively treat some of the world's most prevalent conditions such as obesity, cardiovascular disease and cancer. Patients are waiting!

Your unique talents will help patients on their journey to wellness. Learn more at https://www.jnj.com/medtech

The Analyst, Data Analytics - US Portfolio Transformation, will deliver data driven insights and develop analytics resources to support the Medtech Surgery transformation. Will partner and collaborate closely with the Supply Chain, Marketing, FSO, KAM, and Customer Solutions teams. Key responsibilities include:
• Deliver the metrics and reporting tools linked to transformation execution inclusive of financial indicators, conversion progress, performance vs plan, and other key information to commercial leadership including Director, US Portfolio Transformation.
• Delivers National, Area, Regional, and Account level analytics and insights related to transformation activities.
• Responsible for KPI measurement and reporting for all related transformation initiatives.
• Collaborates with multidisciplinary partners to drive Surgery transformation forward in a timely manner.
• Execution of innovative initiatives aligned to the HIT Next needs of the commercial organization.
• Ensures data analytics are integrated at all levels (National, GPO, IDN, Area, Region, Territory, Account) to monitor and ultimately improve execution, speed to next action, and accountability across the organization.

This job is salaried.

Qualifications
• Bachelor's degree required

Experience:
• 2+ years professional business experience across Commercial or Supply Chain roles preferred
• Data Analytics experience required
• Technical Skills including Tableau, MS Office, Power BI and other data tool sets required.
• Strong knowledge of Excel (i.e. vLookups, pivot tables) is required.
• Experience in Medical Devices/Technology preferred
• Experience partnering with multi-functional business partners preferred.

Knowledge, Skills and Abilities:
• The ability to manage multiple projects and initiatives and work independently while demonstrating initiative.
• The ability to work across functions (Sales, Marketing, KAM, Supply Chain, Finance) where priorities change rapidly and strict timelines exist is required
• Deep knowledge of MedTech Industry and US Hospital Systems
• Understanding of data analysis, US sales/ contracting landscape to build out meaningful and actionable reporting and metrics.
• Understanding of US Medtech Surgery systems and data workflows.
• Creative thinking to develop effective strategies and translate into actionable insights to monitor and drive commercial effectiveness.
• Ability to establish a strategy, a complex project plan and then complete proactively, be it independently or within a team
• Exceptional interpersonal, professionalism, communication and presentation skills.
• Lean, Six-Sigma or Process Excellence training and/or certification is appreciated.

Benefits Summary:
• Employees and/or eligible dependents may be eligible to participate in the following Company sponsored employee benefit programs: medical, dental, vision, life insurance, short- and long-term disability, business accident insurance, and group legal insurance.
• Employees may be eligible to participate in the Company's consolidated retirement plan (pension) and savings plan (401(k)).
• This position is eligible to participate in the Company's long-term incentive program.
• Employees are eligible for the following time off benefits:
• Vacation - up to 120 hours per calendar year
• Sick time - up to 40 hours per calendar year; for employees who reside in the State of Washington - up to 56 hours per calendar year
• Holiday pay, including Floating Holidays - up to 13 days per calendar year
• Work, Personal and Family Time - up to 40 hours per calendar year

Additional information can be found through the link below!

https://www.careers.jnj.com/employee-benefits

Johnson & Johnson is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, national origin, disability, protected veteran status or other characteristics protected by federal, state or local law. We actively seek qualified candidates who are protected veterans and individuals with disabilities as defined under VEVRAA and Section 503 of the Rehabilitation Act.

Johnson & Johnson is committed to providing an interview process that is inclusive of our applicants' needs. If you are an individual with a disability and would like to request an accommodation, please contact us via https://www.jnj.com/contact-us/careers or contact AskGS to be directed to your accommodation resource.

The anticipated base pay range for this position is :
$63,000 - $102,350

Additional Description for Pay Transparency:
The Company maintains highly competitive, performance-based compensation programs. Under current guidelines, this position is eligible for an annual performance bonus in accordance with the terms of the applicable plan. The annual performance bonus is a cash bonus intended to provide an incentive to achieve annual targeted results by rewarding for individual and the corporation's performance over a calendar/performance year. Bonuses are awarded at the Company's discretion on an individual basis.",2025-07-10T00:00:00.000Z,2025-07-25,"[""Bachelor's degree required"", 'Data Analytics experience required', 'Technical Skills including Tableau, MS Office, Power BI and other data tool sets required', 'Strong knowledge of Excel (i.e', 'vLookups, pivot tables) is required', 'The ability to manage multiple projects and initiatives and work independently while demonstrating initiative', 'The ability to work across functions (Sales, Marketing, KAM, Supply Chain, Finance) where priorities change rapidly and strict timelines exist is required', 'Deep knowledge of MedTech Industry and US Hospital Systems', 'Understanding of data analysis, US sales/ contracting landscape to build out meaningful and actionable reporting and metrics', 'Understanding of US Medtech Surgery systems and data workflows', 'Creative thinking to develop effective strategies and translate into actionable insights to monitor and drive commercial effectiveness', 'Ability to establish a strategy, a complex project plan and then complete proactively, be it independently or within a team', 'Exceptional interpersonal, professionalism, communication and presentation skills', 'Lean, Six-Sigma or Process Excellence training and/or certification is appreciated']","[""Your contributions will help effectively treat some of the world's most prevalent conditions such as obesity, cardiovascular disease and cancer"", 'The Analyst, Data Analytics - US Portfolio Transformation, will deliver data driven insights and develop analytics resources to support the Medtech Surgery transformation', 'Will partner and collaborate closely with the Supply Chain, Marketing, FSO, KAM, and Customer Solutions teams', 'Deliver the metrics and reporting tools linked to transformation execution inclusive of financial indicators, conversion progress, performance vs plan, and other key information to commercial leadership including Director, US Portfolio Transformation', 'Delivers National, Area, Regional, and Account level analytics and insights related to transformation activities', 'Responsible for KPI measurement and reporting for all related transformation initiatives', 'Collaborates with multidisciplinary partners to drive Surgery transformation forward in a timely manner', 'Execution of innovative initiatives aligned to the HIT Next needs of the commercial organization', 'Ensures data analytics are integrated at all levels (National, GPO, IDN, Area, Region, Territory, Account) to monitor and ultimately improve execution, speed to next action, and accountability across the organization']",True,[],,"['Data Analytics', 'Tableau', 'Power BI', 'Microsoft Excel', 'KPI Measurement and Reporting', 'Data Integration', 'Commercial Analytics', 'Cross-Functional Collaboration', 'Lean and Six Sigma']","Data Analytics: Used to deliver data driven insights and develop analytics resources supporting Medtech Surgery transformation, including KPI measurement and reporting for transformation initiatives.; Tableau: A technical tool required for creating metrics and reporting tools linked to transformation execution and commercial leadership insights.; Power BI: A technical tool required for building data visualizations and dashboards to support reporting and analytics across multiple organizational levels.; Microsoft Excel: Strong knowledge required, including advanced functions like vLookups and pivot tables, to manage and analyze data for reporting and insights.; KPI Measurement and Reporting: Responsible for defining, measuring, and reporting key performance indicators related to transformation activities at various organizational levels.; Data Integration: Ensures data analytics are integrated across multiple organizational levels (National, GPO, IDN, Area, Region, Territory, Account) to monitor and improve execution and accountability.; Commercial Analytics: Delivers analytics and insights related to commercial transformation activities, including financial indicators, conversion progress, and performance versus plan.; Cross-Functional Collaboration: Partners with Supply Chain, Marketing, FSO, KAM, and Customer Solutions teams to drive transformation and analytics initiatives.; Lean and Six Sigma: Process excellence methodologies appreciated for improving data-driven processes and project execution within the organization."
FLrA7FAa0FoXbqFaAAAAAA==,Mid-Level Data Analyst,"Patterned Learning AI is hiring a Mid-Level Data Analyst with 0 - 3 years of experience. Based in United States - Remote and with Remote ways of working.

Job description and responsibilities:

Role Responsibilities
• Work in close collaboration with the Business Intelligence Lead, Federal Data Lead and other Program teams
• Develop, maintain, and improve BI tools, build and enhance standard operating procedures (SOPs)
• Manage various data sets and active Google workbooks with adjacent contract teams, monitor and analyze financial health information at the project and program levels
• Communicate with client leadership to assess data needs and emerging requirements
• Lead Tableau projects for the BI team - will be responsible for developing new (custom) dashboards, maintaining and enhancing existing tools, and driving the adoption and growth of dashboard-based data consumption throughout the organization.
• Work with large data sets, workbooks and spreadsheets to manipulate and manage program-level information using macros, queries, scripts, etc.
• Gather requirements and lead development of long-term data management tools, processes and solutions based on organizational needs.
• Be comfortable working with collaboration tools such as; Google Suite, Microsoft Office
• Providing general support to the client including, but not limited to, analysis, data calls, financial management, risk management, audits, and project management related tasks.

Requirements and qualifications:

Qualifications
• Bachelor's Degree in business, business intelligence, data or information management, or similar.
• Proficient in Google Scripts
• Minimum 2 years of data or information management and/or data analysis experience.
• Minimum 2 years of experience working with data visualization tools (Tableau/Power BI, ideally focused in developing custom dashboards).
• Experience using Microsoft Excel and Google Sheets (macros, imports, query functions).
• Experience with developing in Google App Script is a plus.
• Experience using SQL Developer is a plus.
• Excellent written and verbal communication skills.
• Consulting / client management experience recommended.
• Willing to work in an administratively manual environment while working towards automation of processes in the future.
• Clearable (able to pass both a criminal background check and credit check).",,2025-07-25,"['Patterned Learning AI is hiring a Mid-Level Data Analyst with 0 - 3 years of experience', ""Bachelor's Degree in business, business intelligence, data or information management, or similar"", 'Proficient in Google Scripts', 'Minimum 2 years of data or information management and/or data analysis experience', 'Minimum 2 years of experience working with data visualization tools (Tableau/Power BI, ideally focused in developing custom dashboards)', 'Experience using Microsoft Excel and Google Sheets (macros, imports, query functions)', 'Excellent written and verbal communication skills', 'Consulting / client management experience recommended', 'Willing to work in an administratively manual environment while working towards automation of processes in the future', 'Clearable (able to pass both a criminal background check and credit check)']","['Based in United States - Remote and with Remote ways of working', 'Work in close collaboration with the Business Intelligence Lead, Federal Data Lead and other Program teams', 'Develop, maintain, and improve BI tools, build and enhance standard operating procedures (SOPs)', 'Manage various data sets and active Google workbooks with adjacent contract teams, monitor and analyze financial health information at the project and program levels', 'Communicate with client leadership to assess data needs and emerging requirements', 'Lead Tableau projects for the BI team - will be responsible for developing new (custom) dashboards, maintaining and enhancing existing tools, and driving the adoption and growth of dashboard-based data consumption throughout the organization', 'Work with large data sets, workbooks and spreadsheets to manipulate and manage program-level information using macros, queries, scripts, etc', 'Gather requirements and lead development of long-term data management tools, processes and solutions based on organizational needs', 'Be comfortable working with collaboration tools such as; Google Suite, Microsoft Office', 'Providing general support to the client including, but not limited to, analysis, data calls, financial management, risk management, audits, and project management related tasks']",True,[],,"['Business Intelligence', 'Tableau', 'Power BI', 'Google Sheets', 'Microsoft Excel', 'Google Scripts', 'SQL Developer', 'Data Management', 'Data Analysis', 'Macros and Queries', 'Standard Operating Procedures (SOPs)']","Business Intelligence: The role involves developing, maintaining, and improving BI tools and dashboards to support data consumption and decision-making within the organization.; Tableau: Responsible for leading Tableau projects including developing new custom dashboards, maintaining existing tools, and promoting dashboard adoption across the organization.; Power BI: Experience with Power BI is preferred for developing custom dashboards as part of data visualization efforts.; Google Sheets: Used extensively for managing and manipulating large data sets and workbooks, including use of macros, imports, and query functions.; Microsoft Excel: Utilized for data manipulation and management, including use of macros and other advanced spreadsheet functions.; Google Scripts: Proficiency required for automating tasks and managing data workflows within Google Sheets and other Google Suite tools.; SQL Developer: Experience with SQL Developer is a plus, indicating involvement in querying and managing structured data.; Data Management: The role includes managing various data sets, developing long-term data management tools, processes, and solutions based on organizational needs.; Data Analysis: Responsibilities include analyzing financial health information, supporting data calls, risk management, audits, and project management related to data.; Macros and Queries: Used to manipulate and manage program-level information within spreadsheets and workbooks to support data analysis and reporting.; Standard Operating Procedures (SOPs): Involved in building and enhancing SOPs to standardize data processes and improve operational efficiency."
NUZLYaLrF9ZTpUygAAAAAA==,"Analyst, Data Visualization & Business Intelligence","This position is on – site in our Royal Caribbean Miami 1050 Building

Journey with us! Combine your career goals and sense of adventure by joining our incredible team of employees at Royal Caribbean Group. We are proud to offer a competitive compensation and benefits package, and excellent career development opportunities, each offering unique ways to explore the world.

We are proud to be the vacation-industry leader with global brands — including Royal Caribbean International, Celebrity Cruises and Silversea Cruises — the most innovative fleet and private destinations, and the best people. Together, we are dedicated to turning the vacation of a lifetime into a lifetime of vacations for our guests.

Royal Caribbean team has an exciting career opportunity for a full-time Analyst, Data Visualization and Business Intelligence reporting to the Sr Manager, Business Intelligence.

Position Summary

Responsibilities include the design, implementation, and development of reporting and analytics solutions, with particular emphasis on Data Visualizations. Candidate must have strong understanding of data visualization and an ability to deliver engaging, informative data stories using a variety of techniques and tools. This individual is capable of working under minimal supervision. He/She will be responsible for interacting with various departments within Royal Caribbean to find, consolidate & manipulate data from multiple large data sets; to analyze and understand results; and to create reports, presentations and/or dashboards.

Essential Duties and Responsibilities
• Designs, implements and develops Data Visualizations using Power BI, Custom Visuals, and R Visualizations
• Meet with business stakeholders to clarify and document reporting requirements
• Meet with technical stakeholders to perform code reviews and elicit feedback
• Recommend data architecture and engineering structures necessary to support reports and dashboards
• Works autonomously and with little direction to complete assignments, coordinating business processes, programs and projects based on the outlined strategies and defined directives.
• Aggregates large data sets in SAS, Excel and other analytical tools for analysis. Develops data strategies
• Specifically, around data structures, identifying critical information, as well as the tools used to retrieve and analyze the data. Performs research and analysis on large data sets - data exploration, trending, modeling, etc.
• Works with management & other team members to understand & clarify data analysis and reporting needs. Provides guidance and insight on data visualization options for report design.
• Influences business decisions through analytics and identifies actionable, data-driven insights. Makes recommendations and influences the direction of the business by effectively communicating results to a cross functional group as well as department executives.
• Creates dashboards, automated reports, report templates and presentations. Uses advanced data visualization tools, such as PowerBI, to provide an easy-to-understand interface for end users to quickly identify key themes within data. Responsible for daily/weekly/monthly reporting on business trends and the status of digital experience initiatives for senior management

This position description in no way states or implies that these are the only duties to be performed by the employee occupying this position. Employee will be required to perform any other job-related duties assigned by their supervisor or management.

Qualifications, Knowledge & Skills
• Four-year Bachelor’s degree preferably in Mathematics/Statistics/Computer Science/ Economics /Analytics/Business/Engineering or BS/BA with combination thereof and related analytic work experience/ and or relevant certifications.
• 2 years of work experience in data analysis, data mining, business case development or other related analytical projects.
• Strong proficiency in query/reporting tools, SQL, Advanced Excel, Tableau (or similar visualization tool), R/SAS/Python or other statistical tools.
• 2 years of work experience required, with experience performing either strategic digital analysis, financial analysis or business intelligence/marketing analytics highly preferred
• Experience working with very large data sets (on relational as well as non-relational data stores)
• Understanding of Forecasting, Data cleansing and Transformations
• Understanding of SQL and DAX, R and R Scripting of visualizations in Power BI
• Experience working with databases, including Oracle, SQL Server, and AS400
• Ability to work on complex development BI projects including the proactive identification of issues and coordination of resolutions.
• Ability to work independently to implement solutions with minimal guidance and communicate effectively with both business and technical stakeholders.

Physical Requirement

The physical demands described here are representative of those requirements employees must meet to perform the essential functions of this job with or without reasonable accommodations. While performing job functions the employee is regularly required to sit, stand, write, review and type reports, compile data, operate a pc, communicate, listen, and assess information. The employee may move about the office complex, may travel to other office locations and may lift, push, pull or move 10 - 15 pounds. Visual requirements include distant, close and color vision, and ability to adjust focus.

Working Conditions

Miami based position with some travel. The work environment characteristics described here are representative of those an employee encounters while performing the essential functions of the job with or without reasonable accommodations. The environment includes office locations, and/or moving inside/outside the office.

We know there's a lot to consider.

As you go through the application process, our recruiters will be glad to provide guidance, and more relevant details to answer any additional questions. Thank you again for your interest in Royal Caribbean Group. We'll hope to see you onboard soon!

It is the policy of the Company to ensure equal employment and promotion opportunity to qualified candidates without discrimination or harassment on the basis of race, color, religion, sex, age, national origin, disability, sexual orientation, sexuality, gender identity or expression, marital status, or any other characteristic protected by law. Royal Caribbean Group and each of its subsidiaries prohibit and will not tolerate discrimination or harassment.

#LI-FM1",2025-06-27T00:00:00.000Z,2025-07-25,"['Candidate must have strong understanding of data visualization and an ability to deliver engaging, informative data stories using a variety of techniques and tools', 'Responsible for daily/weekly/monthly reporting on business trends and the status of digital experience initiatives for senior management', 'Four-year Bachelor’s degree preferably in Mathematics/Statistics/Computer Science/ Economics /Analytics/Business/Engineering or BS/BA with combination thereof and related analytic work experience/ and or relevant certifications', '2 years of work experience in data analysis, data mining, business case development or other related analytical projects', 'Strong proficiency in query/reporting tools, SQL, Advanced Excel, Tableau (or similar visualization tool), R/SAS/Python or other statistical tools', 'Experience working with very large data sets (on relational as well as non-relational data stores)', 'Understanding of Forecasting, Data cleansing and Transformations', 'Understanding of SQL and DAX, R and R Scripting of visualizations in Power BI', 'Experience working with databases, including Oracle, SQL Server, and AS400', 'Ability to work on complex development BI projects including the proactive identification of issues and coordination of resolutions', 'Ability to work independently to implement solutions with minimal guidance and communicate effectively with both business and technical stakeholders', 'The physical demands described here are representative of those requirements employees must meet to perform the essential functions of this job with or without reasonable accommodations', 'Visual requirements include distant, close and color vision, and ability to adjust focus', 'Miami based position with some travel']","['Responsibilities include the design, implementation, and development of reporting and analytics solutions, with particular emphasis on Data Visualizations', 'This individual is capable of working under minimal supervision', 'He/She will be responsible for interacting with various departments within Royal Caribbean to find, consolidate & manipulate data from multiple large data sets; to analyze and understand results; and to create reports, presentations and/or dashboards', 'Designs, implements and develops Data Visualizations using Power BI, Custom Visuals, and R Visualizations', 'Meet with business stakeholders to clarify and document reporting requirements', 'Meet with technical stakeholders to perform code reviews and elicit feedback', 'Recommend data architecture and engineering structures necessary to support reports and dashboards', 'Works autonomously and with little direction to complete assignments, coordinating business processes, programs and projects based on the outlined strategies and defined directives', 'Aggregates large data sets in SAS, Excel and other analytical tools for analysis', 'Develops data strategies', 'Specifically, around data structures, identifying critical information, as well as the tools used to retrieve and analyze the data', 'Performs research and analysis on large data sets - data exploration, trending, modeling, etc', 'Works with management & other team members to understand & clarify data analysis and reporting needs', 'Provides guidance and insight on data visualization options for report design', 'Influences business decisions through analytics and identifies actionable, data-driven insights', 'Makes recommendations and influences the direction of the business by effectively communicating results to a cross functional group as well as department executives', 'Creates dashboards, automated reports, report templates and presentations', 'Uses advanced data visualization tools, such as PowerBI, to provide an easy-to-understand interface for end users to quickly identify key themes within data', 'Employee will be required to perform any other job-related duties assigned by their supervisor or management', 'While performing job functions the employee is regularly required to sit, stand, write, review and type reports, compile data, operate a pc, communicate, listen, and assess information', 'The employee may move about the office complex, may travel to other office locations and may lift, push, pull or move 10 - 15 pounds']",True,[],,"['Data Visualization', 'Power BI', 'SQL', 'Advanced Excel', 'Tableau', 'R', 'SAS', 'Python', 'Data Exploration and Trending', 'Data Cleansing and Transformations', 'Forecasting', 'DAX', 'Data Architecture and Engineering Structures', 'Business Intelligence (BI) Tools and Dashboards']","Data Visualization: Designs, implements, and develops data visualizations using tools such as Power BI, Custom Visuals, and R Visualizations to deliver engaging and informative data stories and support reporting and analytics solutions.; Power BI: Used to create dashboards, automated reports, report templates, and presentations, providing an easy-to-understand interface for end users to quickly identify key themes within data.; SQL: Utilized for querying and reporting, including working with databases such as Oracle, SQL Server, and AS400, to retrieve and manipulate data from large data sets.; Advanced Excel: Used for data aggregation, analysis, and reporting, supporting the handling of large data sets and complex business intelligence projects.; Tableau: Employed as a data visualization tool similar to Power BI to create reports and dashboards that communicate data insights effectively.; R: Used for scripting visualizations in Power BI and performing statistical analysis, data exploration, trending, and modeling on large data sets.; SAS: Applied for aggregating large data sets and conducting data analysis as part of business intelligence and reporting tasks.; Python: Utilized as a statistical tool for data analysis and scripting within the analytics and reporting processes.; Data Exploration and Trending: Performs research and analysis on large data sets to identify patterns, trends, and insights that inform business decisions.; Data Cleansing and Transformations: Involves preparing and transforming data to ensure accuracy and usability for analysis and reporting.; Forecasting: Understanding and applying forecasting techniques to support business trend analysis and decision-making.; DAX: Used alongside SQL and R for scripting and creating calculations within Power BI visualizations.; Data Architecture and Engineering Structures: Recommends and designs data structures necessary to support reports and dashboards, ensuring efficient data retrieval and analysis.; Business Intelligence (BI) Tools and Dashboards: Creates and manages dashboards and reports to provide actionable, data-driven insights that influence business decisions and communicate results to stakeholders."
zrG9xsRw8Feq-thIAAAAAA==,"Data Transformation Analyst (US, remote)","Data Transformation Analyst (US, remote)

Summary:

GTreasury, the leading innovator of integrated SaaS treasury and risk management solutions for the digital treasurer is currently looking to hire a motivated Account Manager to join our growing global sales organization to support our EMEA region. Developed using the latest technology, GTreasury helps empower organizations on their path to strategic treasury, by enabling total visibility into their cash, liquidity, payments and financial risk management. With enterprise clients spanning North America, EMEA and APAC, GTreasury is headquartered in Chicago with offices in London, Sydney and Manila.

GTreasury is currently seeking a dynamic Data Transformation Analyst to join our growing Data Services team. This role is ideal for someone who is passionate about data integration, automation, and scripting. You will play a key role in transforming and mapping financial data to support our clients' treasury operations.

Key Responsibilities:
• Design, develop, and maintain data transformation workflows using PowerShell and Liquid scripting.
• Build, test and deploy API's for banking and ERP applications
• Create and maintain documentation for API's built
• Collaborate with implementation consultants, banks and clients to understand data requirements and deliver tailored solutions.
• Analyze and troubleshoot data issues, ensuring accuracy and consistency across systems.
• Automate data ingestion and transformation processes to improve efficiency and scalability.
• Integrate and interact with APIs to support data exchange and automation.
• Document transformation logic and maintain best practices for scripting and data handling.

Qualifications:
• 2+ years of experience in data transformation, scripting, or ETL processes.
• Proficiency in PowerShell and experience with Liquid templating language (preferred).
• Experience working with APIs for data integration and automation.
• Experience with XSLT for XML data transformation is a plus.
• Strong analytical and problem-solving skills with attention to detail.
• Familiarity with financial systems or treasury management software is a plus.
• Excellent communication skills and the ability to work independently in a remote environment.

What You Will Get:
• A high impact, high visibility role at a growing SaaS company that values personal growth, accountability, and the concept of ""good work.""
• This is a great opportunity for someone who wants to make a big impact, work in a fast-paced and collaborative environment, and win as a team to scale a growing business.
• A culture of open collaboration and problem solving.
• An empowered role on our transforms team, responsible for implementing best practices and delivering critical results for our global customers.
• Great benefits, culture, and the ability to work remotely.
• Our benefits include:
• Salary: The expected annual median salary for this role is $85,000. Actual compensation for an individual may vary depending on skills, performance, qualifications, experience, and location.
Excellent medical, dental and vision insurance options
• HSA and FSA options + company HSA contributions
• 401K matching
• 100% paid parental leave
• 15 paid holidays + competitive PTO
• 100% remote working

About GTreasury:

GTreasury believes there is opportunity in complexity. We connect treasury and finance teams with industry-leading experts, technology solutions and untapped possibility. By simplifying complexity, teams can unleash their organization's potential to gain strategic advantages and grow. GTreasury helps organizations reach that potential by connecting treasury and digital finance operations through a world-class SaaS treasury and risk management platform and integrated ecosystem where cash, debt, investments, and exposures are seamlessly managed within the office of the CFO. GTreasury delivers intelligent insights, while connecting financial value chains and extending workflows to third-party systems, exchanges, portals, and services. Headquartered in Chicago, with locations serving EMEA (London) and APAC (Sydney and Manila), GTreasury's global community includes more than 800 customers and 30+ industries reaching 160+ countries worldwide.

At GTreasury / Hedge Trackers, we know that our people are what makes GTreasury great and we celebrate the unique perspectives and experiences that our diverse teams bring to the table. GTreasury does not discriminate against employees or prospective candidates based on race, color, religion, sex, national origin, gender identity or expression, age, disability, pregnancy (including childbirth, breastfeeding, or related medical condition), genetic information, protected military or veteran status, sexual orientation, or any other characteristic protected by applicable federal, state or local laws and we strongly encourage people from underrepresented groups to apply!

To learn more about GTreasury: https://gtreasury.com/",2025-07-19T00:00:00.000Z,2025-07-25,"['2+ years of experience in data transformation, scripting, or ETL processes', 'Experience working with APIs for data integration and automation', 'Strong analytical and problem-solving skills with attention to detail', 'Excellent communication skills and the ability to work independently in a remote environment', 'This is a great opportunity for someone who wants to make a big impact, work in a fast-paced and collaborative environment, and win as a team to scale a growing business']","['This role is ideal for someone who is passionate about data integration, automation, and scripting', ""You will play a key role in transforming and mapping financial data to support our clients' treasury operations"", 'Design, develop, and maintain data transformation workflows using PowerShell and Liquid scripting', ""Build, test and deploy API's for banking and ERP applications"", ""Create and maintain documentation for API's built"", 'Collaborate with implementation consultants, banks and clients to understand data requirements and deliver tailored solutions', 'Analyze and troubleshoot data issues, ensuring accuracy and consistency across systems', 'Automate data ingestion and transformation processes to improve efficiency and scalability', 'Integrate and interact with APIs to support data exchange and automation', 'Document transformation logic and maintain best practices for scripting and data handling']",False,,,,
_RSyd7-vmOinX-TgAAAAAA==,Data Scientist,"Job Title: Data Scientist

Work Location: Remote (preference for candidates located in the National Capital Region - DMV)

Clearance Required: TS or CBP BI or DHS Suitability tier 4 (clearance adjudicated within the past 4 years)

People Centered. Data Driven

Elder Research Inc. is a Data Science consulting firm specialized in providing analytic solutions to clients in Commercial and Government industries. Providing analytic solutions to hundreds of companies across numerous industries, our team enjoys a great variety in the type of work they do and exposure to a wide range of techniques and tools

We are trusted advisors to our clients, building lasting relationships and partnering as preferred analytics providers. We use a variety of programming languages and tools to create analytic solutions, often fitting within our clients’ environment and needs.

Join our team and find great opportunities to hone your analytic skills, work on complex problems with amazing teammates, and gain valuable analytics consulting experience.?

Summary of Position:

We are looking for a talented and motivated data scientist experienced in working directly with clients, managers, and technical staff to understand business needs, develop technical plans, and deliver data-driven analytical solutions that solve client problems. This role will assist the client in integrating data analytics into their daily operations. You will create and deploy predictive models from a variety of data sources and types using the latest mathematical and statistical methods. You will also have the freedom to grow a team to support the client's data analytics needs.

Job Specifications/Requirements:
• Six (6) years of relevant experience in applied research, big data analytics, statistics, applied mathematics, data science, computer science, operations research or other closely related other quantitative or mathematical discipline. At least three (3) years of direct experience in machine learning.
• Advanced Degree (Masters or PhD) in Statistics, Applied Mathematics, Data Science, Computer
• Science, Operations Research or other closely related other quantitative or mathematical discipline. A PhD degree may be substituted for up to three (3) years of relevant experience.
• Demonstrates knowledge of data mining methods, databases, data visualization and machine learning.
• Ability to communicate analysis techniques, concepts and products.
• Ability to develop data-driven solutions, data models, and visualizations

Desired Skills
• Experience building AI/ML solutions from large JSON data stores
• Experience with graph technologies and tools
• Experience with analysis and visualization of worldwide data flows
• Experience in developing algorithms in support of fraud detection
• Familiarity with Databricks or similar cloud-based distributed database technologies
• Familiarity with PySpark and Python
• Comfortable developing complex SQL queries to extract, transform, and load data
• Experience with analytic techniques such as Anomaly detection, Clustering, and Time-series (e.g., ARIMA)
• Experience implementing NLP concepts including preprocessing (stemming, etc.), TF-IDF, Named Entity Recognition, and LLMs.

About Elder Research, Inc

Elder Research is a fast growing consulting firm specializing in predictive analytics. Being in the data mining business almost 30 years, we pride ourselves in our ability to find creative, cutting edge solutions to real-world problems. We work hard to provide the best value to our clients and allow each person to contribute their ideas and put their skills to use immediately.

Our team members are passionate, curious, life-long learners. We value humility, servant-leadership, teamwork, and integrity. We seek to serve our clients and our teammates to the best of our abilities. In keeping with our entrepreneurial spirit, we want candidates who are self-motivated with an innate curiosity and strong team work.

Elder Research believes in continuous learning - along with providing time for professional development, each week the entire company attends a “Tech Talk”. Elder Research provides a supportive work environment with established parental, bereavement, and PTO policies. By prioritizing a healthy work-life balance - with reasonable hours, solid pay, low travel, and extremely flexible time off - Elder Research enables and encourages its employees to serve others and enjoy their lives.

Elder Research, Inc. is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability.

Elder Research is a Government contractor and many positions require US Citizenship.

Equal Opportunity Employer, including disability/protected veterans

Equal employment opportunity, including veterans and individuals with disabilities.

PI276149450",2025-07-25T12:00:00.000Z,2025-07-25,"['Clearance Required: TS or CBP BI or DHS Suitability tier 4 (clearance adjudicated within the past 4 years)', 'Six (6) years of relevant experience in applied research, big data analytics, statistics, applied mathematics, data science, computer science, operations research or other closely related other quantitative or mathematical discipline', 'At least three (3) years of direct experience in machine learning', 'Advanced Degree (Masters or PhD) in Statistics, Applied Mathematics, Data Science, Computer', 'Science, Operations Research or other closely related other quantitative or mathematical discipline', 'A PhD degree may be substituted for up to three (3) years of relevant experience', 'Demonstrates knowledge of data mining methods, databases, data visualization and machine learning', 'Ability to communicate analysis techniques, concepts and products', 'Ability to develop data-driven solutions, data models, and visualizations', 'In keeping with our entrepreneurial spirit, we want candidates who are self-motivated with an innate curiosity and strong team work']","['We are looking for a talented and motivated data scientist experienced in working directly with clients, managers, and technical staff to understand business needs, develop technical plans, and deliver data-driven analytical solutions that solve client problems', 'This role will assist the client in integrating data analytics into their daily operations', 'You will create and deploy predictive models from a variety of data sources and types using the latest mathematical and statistical methods', ""You will also have the freedom to grow a team to support the client's data analytics needs""]",True,['Large Language Models'],Large Language Models: The job includes experience with large language models (LLMs) as part of implementing NLP concepts to enhance analytic solutions.,"['Machine Learning', 'Data Mining', 'Data Visualization', 'Predictive Modeling', 'SQL', 'Python and PySpark', 'Graph Technologies', 'Anomaly Detection, Clustering, and Time-Series Analysis', 'NLP Concepts (Preprocessing, TF-IDF, Named Entity Recognition)', 'Big Data Analytics', 'Data-Driven Solutions and Data Models']","Machine Learning: The role requires at least three years of direct experience in machine learning and involves creating and deploying predictive models using the latest mathematical and statistical methods.; Data Mining: The candidate must demonstrate knowledge of data mining methods to extract insights and build analytic solutions for clients.; Data Visualization: The job involves developing data visualizations to communicate analysis techniques, concepts, and products effectively to clients and stakeholders.; Predictive Modeling: The position includes creating and deploying predictive models from various data sources to solve client problems and integrate analytics into daily operations.; SQL: The candidate should be comfortable developing complex SQL queries to extract, transform, and load data as part of the analytic solutions.; Python and PySpark: Experience with Python and PySpark is desired for developing analytic solutions and handling large-scale data processing.; Graph Technologies: Experience with graph technologies and tools is preferred to support analysis and visualization of complex data relationships.; Anomaly Detection, Clustering, and Time-Series Analysis: The job requires experience with analytic techniques such as anomaly detection, clustering, and time-series modeling (e.g., ARIMA) to analyze data patterns and trends.; NLP Concepts (Preprocessing, TF-IDF, Named Entity Recognition): The role involves implementing natural language processing concepts including text preprocessing, TF-IDF, and named entity recognition to support analytic solutions.; Big Data Analytics: The candidate should have experience in big data analytics, including working with large JSON data stores and distributed database technologies like Databricks.; Data-Driven Solutions and Data Models: The position focuses on developing data-driven solutions and data models tailored to client needs to support decision-making and operational integration."
RJMAzVpuaAdM1qcVAAAAAA==,Data Analyst / Financial Engineer – Treasury Dept. (Associate),"Key Responsibilities
• Collaborate with and support the Treasury desk, Financial Technology, model validation and project management team in model creation, methodology and testing documentation, validation and remediation, signoff, maintenance and production deployment
• Use quantitative and technological techniques to solve complex business problems
• Build analysis, data visualization tool, and create information report that reflects the business requirement
• Enhance and maintain the existing Treasury system for PL analysis and monitoring, scenario analysis, process automation
• Planning and developing new tools and systems being valuable for our business, not only Treasury but including corporate-wide in the future.
• Conduct research on cutting edge technologies in AI/BI/ML/NLP, alternative data, FinTech, high performance computing (e.g. GPU, quantum computing) to discover the potential opportunities to the business applications
• Conduct quantitative research and predictive modeling for market related businesses by sourcing, integrating and analyzing traditional and alternative dataset to discover new insights and strategies
• Collaborate with and support the Treasury desk, Financial Technology, model validation and Risk management in model creation, methodology and testing documentation, validation and remediation, signoff, maintenance and production deployment
• Use quantitative and technological techniques to solve complex business problems.

Required Qualifications
• Master’s degree or higher in a quantitative field such as mathematics, statistics, engineering, physics strongly desired
• Strong, clear and concise written and oral communication skills
• 2-5+ years of hands-on Python, SQL, Typescript/Javascript and Linux development experience.
• 2-5+ years of experience in wide range of statistical and machine-learning techniques (e.g. time series analysis, NLP, deep learning and etc.)
• Experience developing or working with REST APIs
• Experience working with BI tools (e.g. PowerBI, Tableau)
• Knowledge of financial mathematics (e.g. stochastic calculus, interest rate models), capital market and derivative products (e.g. interest rate swaps, cross currency swaps, options and etc.)

The expected base salary ranges from $79,000 - $151,500. Salary offers are based on a wide range of factors including relevant skills, training, experience, education, and, where applicable, certifications and licenses obtained. Market and organizational factors are also considered. In addition to salary and a generous employee benefits package, successful candidates are eligible to receive a discretionary bonus.

#Hybrid

Other requirements

Mizuho has in place a hybrid working program, with varying opportunities for remote work depending on the nature of the role, needs of your department, as well as local laws and regulatory obligations. Roles in some of our departments have greater in-office requirements that will be communicated to you as part of the recruitment process.

Company Overview

Mizuho Financial Group, Inc. is the 15th largest bank in the world as measured by total assets of ~$2 trillion. Mizuho's 60,000 employees worldwide offer comprehensive financial services to clients in 35 countries and 800 offices throughout the Americas, EMEA and Asia. Mizuho Americas is a leading provider of corporate and investment banking services to clients in the US, Canada, and Latin America. Through its acquisition of Greenhill​, Mizuho provides M&A, restructuring and private capital advisory capabilities across Americas, Europe and Asia. Mizuho Americas employs approximately 3,500 professionals, and its capabilities span corporate and investment banking, capital markets, equity and fixed income sales & trading, derivatives, FX, custody and research. Visit www.mizuhoamericas.com.​​

Mizuho Americas offers a competitive total rewards package.

We are an EEO/AA Employer - M/F/Disability/Veteran.

We participate in the E-Verify program.

We maintain a drug-free workplace and reserve the right to require pre- and post-hire drug testing as permitted by applicable law.

#LI-MIZUHO",,2025-07-25,"['Strong, clear and concise written and oral communication skills', '2-5+ years of hands-on Python, SQL, Typescript/Javascript and Linux development experience', '2-5+ years of experience in wide range of statistical and machine-learning techniques (e.g. time series analysis, NLP, deep learning and etc.)', 'Experience developing or working with REST APIs', 'Experience working with BI tools (e.g. PowerBI, Tableau)', 'Knowledge of financial mathematics (e.g. stochastic calculus, interest rate models), capital market and derivative products (e.g. interest rate swaps, cross currency swaps, options and etc.)']","['Collaborate with and support the Treasury desk, Financial Technology, model validation and project management team in model creation, methodology and testing documentation, validation and remediation, signoff, maintenance and production deployment', 'Use quantitative and technological techniques to solve complex business problems', 'Build analysis, data visualization tool, and create information report that reflects the business requirement', 'Enhance and maintain the existing Treasury system for PL analysis and monitoring, scenario analysis, process automation', 'Planning and developing new tools and systems being valuable for our business, not only Treasury but including corporate-wide in the future', 'Conduct research on cutting edge technologies in AI/BI/ML/NLP, alternative data, FinTech, high performance computing (e.g. GPU, quantum computing) to discover the potential opportunities to the business applications', 'Conduct quantitative research and predictive modeling for market related businesses by sourcing, integrating and analyzing traditional and alternative dataset to discover new insights and strategies', 'Collaborate with and support the Treasury desk, Financial Technology, model validation and Risk management in model creation, methodology and testing documentation, validation and remediation, signoff, maintenance and production deployment', 'Use quantitative and technological techniques to solve complex business problems']",True,"['Natural Language Processing (NLP)', 'Deep Learning']",Natural Language Processing (NLP): Explicitly mentioned as a cutting-edge AI technology researched and applied to discover potential business opportunities and enhance quantitative research in financial contexts.; Deep Learning: Included as part of AI-related techniques researched and applied for advanced modeling and predictive analytics in the Treasury and financial engineering domain.,"['Python', 'SQL', 'Typescript/Javascript', 'Linux', 'Statistical and Machine Learning Techniques', 'Time Series Analysis', 'Natural Language Processing (NLP)', 'Deep Learning', 'REST APIs', 'BI Tools', 'Predictive Modeling', 'Data Visualization', 'Model Validation and Testing', 'Financial Mathematics', 'Alternative Data']","Python: Used for hands-on development and implementation of data analysis, statistical and machine learning techniques in the Treasury and financial engineering context.; SQL: Utilized for querying and managing traditional and alternative datasets to support quantitative research and predictive modeling.; Typescript/Javascript: Applied in development tasks related to building analysis and data visualization tools and creating information reports reflecting business requirements.; Linux: Used as the operating system environment for development and deployment of data science and financial engineering solutions.; Statistical and Machine Learning Techniques: Includes a wide range of methods such as time series analysis, NLP, and deep learning applied to quantitative research, predictive modeling, and solving complex business problems in finance.; Time Series Analysis: Employed for analyzing market-related data and financial time-dependent variables to support predictive modeling and strategy development.; Natural Language Processing (NLP): Used as part of statistical and machine learning techniques to analyze textual data relevant to financial markets and business insights.; Deep Learning: Applied within machine learning techniques to enhance predictive modeling and quantitative research in financial contexts.; REST APIs: Experience developing or working with REST APIs to integrate and access data or services necessary for financial modeling and analysis.; BI Tools: Experience with business intelligence tools such as PowerBI and Tableau to build data visualization tools and create reports that reflect business requirements.; Predictive Modeling: Conducted for market-related businesses by sourcing, integrating, and analyzing traditional and alternative datasets to discover new insights and strategies.; Data Visualization: Building tools and reports to visually represent data and analysis results to support business decision-making in Treasury and corporate-wide applications.; Model Validation and Testing: Involves creation, methodology, documentation, validation, remediation, signoff, maintenance, and production deployment of financial and predictive models.; Financial Mathematics: Knowledge of stochastic calculus, interest rate models, and derivative products used to support quantitative modeling and risk management in Treasury.; Alternative Data: Sourcing and integrating non-traditional datasets to enhance quantitative research and predictive modeling for market-related business insights."
0vCgYbJlilJjeSuIAAAAAA==,Data Analytics Consultant (Insights Analyst),"We're Hiring: Data Analytics Consultant (Insights Analyst) | San Jose, CA - Who can work 2 3 days from the office weekly

Are you passionate about turning complex data into meaningful insights that drive real business impact? Join us as an Insights Analyst / Manager supporting the customer Cloud domain an exciting and fast-paced space that s constantly evolving.

We re looking for a data-driven storyteller with strong business acumen and technical expertise who can deep-dive into data, stitch together multiple sources, and build scalable reporting solutions.
Location: San Jose, California (Onsite/Hybrid options may vary)

What You ll Do
• Lead strategic analytics projects and deliver actionable insights to key stakeholders
• Build robust data pipelines and reporting solutions (primarily using Adobe Analytics clickstream data)
• Co-design and analyze A/B tests to measure impact and optimize strategies
• Conduct ad-hoc analyses and explore customer behavior patterns
• Collaborate with cross-functional teams to ensure data quality and validation
• Translate business requirements into scalable datasets and visualizations
• Navigate complex data landscapes and solve problems creatively

What You ll Bring
• 5+ years of relevant professional experience
• Bachelor s in CS, Engineering, Info Systems (Master s preferred)
• Strong skills in SQL, Apache Hadoop, Hive, Presto, or similar technologies
• Proficiency in Python, Excel, and data visualization tools (Tableau, Power BI)
• Web analytics and A/B testing experience highly desired
• Experience with Adobe Analytics Workspace is a big plus
• Detail-oriented with strong problem-solving and stakeholder management abilities
• Understanding of statistical modeling, machine learning, or data mining is a bonus",2025-07-21T00:00:00.000Z,2025-07-25,"['5+ years of relevant professional experience', 'Strong skills in SQL, Apache Hadoop, Hive, Presto, or similar technologies', 'Proficiency in Python, Excel, and data visualization tools (Tableau, Power BI)', 'Experience with Adobe Analytics Workspace is a big plus', 'Detail-oriented with strong problem-solving and stakeholder management abilities', 'Understanding of statistical modeling, machine learning, or data mining is a bonus']","['Lead strategic analytics projects and deliver actionable insights to key stakeholders', 'Build robust data pipelines and reporting solutions (primarily using Adobe Analytics clickstream data)', 'Co-design and analyze A/B tests to measure impact and optimize strategies', 'Conduct ad-hoc analyses and explore customer behavior patterns', 'Collaborate with cross-functional teams to ensure data quality and validation', 'Translate business requirements into scalable datasets and visualizations', 'Navigate complex data landscapes and solve problems creatively']",True,[],,"['SQL', 'Apache Hadoop', 'Hive', 'Presto', 'Python', 'Excel', 'Tableau', 'Power BI', 'Adobe Analytics', 'A/B Testing', 'Data Pipelines', 'Statistical Modeling', 'Machine Learning']","SQL: Used for querying and managing data to build scalable datasets and support data pipelines.; Apache Hadoop: Employed as a big data framework to handle large-scale data processing and storage.; Hive: Utilized for querying and managing large datasets stored in Hadoop, supporting data pipeline construction.; Presto: Used as a distributed SQL query engine to analyze large datasets efficiently.; Python: Applied for data analysis, scripting, and building reporting solutions.; Excel: Used for data manipulation, analysis, and visualization tasks.; Tableau: A data visualization tool used to create dashboards and visual representations of data insights.; Power BI: A business intelligence tool used to develop interactive reports and dashboards.; Adobe Analytics: Used to analyze clickstream data and build reporting solutions focused on customer behavior.; A/B Testing: Co-designed and analyzed experiments to measure impact and optimize business strategies.; Data Pipelines: Built robust data pipelines to integrate and process data from multiple sources for reporting and analysis.; Statistical Modeling: Understanding of statistical techniques to analyze data and derive insights.; Machine Learning: Knowledge of machine learning methods as a bonus for enhancing data analysis and predictive capabilities."
jEzrv_10Ou-QJBYaAAAAAA==,Senior Systems Analyst (Data Analyst),"Senior Systems Analyst (Data Analyst)

Lead II - Software Engineering

Who We Are:

Born digital, UST transforms lives through the power of technology. We walk alongside our clients and partners, embedding innovation and agility into everything they do. We help them create transformative experiences and human-centered solutions for a better world.

UST is a mission-driven group of 29,000+ practical problem solvers and creative thinkers in more than 30 countries. Our entrepreneurial teams are empowered to innovate, act nimbly, and create a lasting and sustainable impact for our clients, their customers, and the communities in which we live.

With us, you’ll create a boundless impact that transforms your career—and the lives of people across the world.

Visit us at UST.com.

You Are:

We are seeking a highly skilled and experienced Senior Systems Analyst (Data Analyst) to support data analysis and architecture initiatives within a healthcare payer clinical data ecosystem. This role requires a detail-oriented, proactive professional with a strong background in data management, data warehousing, and healthcare analytics.

The opportunity:

· Data Analysis & Design: Contribute to the design, modeling, implementation, and maintenance of data solutions within the clinical data ecosystem.

· ETL Process Understanding: Interpret ETL terminologies and processes including jobs, Psets, graphs, schedules, and job series (100, 300, 500).

· Data Modeling: Follow data model standards and understand entity-relationship (ER) modeling using tools like Erwin.

· PHI/PII Data Handling: Ensure compliance with data privacy standards by preventing exposure to PHI/PII and applying data masking techniques.

· SA Deliverables: Create and maintain key deliverables such as Source-to-Target (S2T) mappings, Data Element Dictionaries (DED), Functional Requirement Specifications (FRS), data models, design documents, and impact analyses.

· Performance Optimization: Optimize performance through index creation, efficient SQL writing, and process design.

This position description identifies the responsibilities and tasks typically associated with the performance of the position. Other relevant essential functions may be required.

What you need:

· Proficiency in dimensional modeling, SQL, and data warehousing concepts.

· Experience with DB2, ETL tools (Ab Initio), and reporting tools (Cognos, Tableau).

· Familiarity with data modeling tools like Erwin.

· Strong understanding of ETL processes, data governance, and metadata management.

· Knowledge of healthcare payer systems, including claims and clinical decision support.

· Soft Skills

· Strong analytical and problem-solving abilities.

· Excellent verbal and written communication skills.

· Ability to work independently and collaboratively in a team environment.

· Education & Experience

· Bachelor’s or Master’s degree in Computer Science, Information Systems, or a related field.

· 7–10 years of experience in systems analysis, with a focus on data warehousing in the healthcare payer sector.

Compensation can differ depending on factors including but not limited to the specific office location, role, skill set, education, and level of experience. UST provides a reasonable range of compensation for roles that may be hired in various U.S. markets as set forth below.

Role Location: Remote

Compensation Range: $82,000-$123,000

Benefits

Full-time, regular employees accrue a minimum of 10 days of paid vacation per year, receive 6 days of paid sick leave each year (pro-rated for new hires throughout the year), 10 paid holidays, and are eligible for paid bereavement leave and jury duty. They are eligible to participate in the Company’s 401(k) Retirement Plan with employer matching. They and their dependents residing in the US are eligible for medical, dental, and vision insurance, as well as the following Company-paid Employee Only benefits: basic life insurance, accidental death and disability insurance, and short- and long-term disability benefits. Regular employees may purchase additional voluntary short-term disability benefits, and participate in a Health Savings Account (HSA) as well as a Flexible Spending Account (FSA) for healthcare, dependent child care, and/or commuting expenses as allowable under IRS guidelines. Benefits offerings vary in Puerto Rico.

Part-time employees receive 6 days of paid sick leave each year (pro-rated for new hires throughout the year) and are eligible to participate in the Company’s 401(k) Retirement Plan with employer matching.

Full-time temporary employees receive 6 days of paid sick leave each year (pro-rated for new hires throughout the year) and are eligible to participate in the Company’s 401(k) program with employer matching. They and their dependents residing in the US are eligible for medical, dental, and vision insurance.

Part-time temporary employees receive 6 days of paid sick leave each year (pro-rated for new hires throughout the year).

All US employees who work in a state or locality with more generous paid sick leave benefits than specified here will receive the benefit of those sick leave laws.

What we believe:

We proudly embrace the values that have shaped UST since day one. We build our culture of Humility, Humanity, and Integrity. These values inspire us to nurture a people-first, human centric culture that fosters belonging, prioritizes sustainable solutions, and keeps our people and clients at the forefront of all decisions.

Humility:

We will listen, learn, be empathetic and help selflessly in our interactions with everyone.

Humanity:

Through business, we will better the lives of those less fortunate than ourselves.

Integrity:

We honor our commitments and act with responsibility in all our relationships.

Equal Employment Opportunity Statement

UST is an Equal Opportunity Employer.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other applicable characteristics protected by law. We will consider qualified applicants with arrest or conviction records in accordance with state and local laws and “fair chance” ordinances.

UST reserves the right to periodically redefine your roles and responsibilities based on the requirements of the organization and/or your performance.

#UST

#CB

#LI-IS1

#LI-Remote",2025-07-21T00:00:00.000Z,2025-07-25,"['We are seeking a highly skilled and experienced Senior Systems Analyst (Data Analyst) to support data analysis and architecture initiatives within a healthcare payer clinical data ecosystem', 'This role requires a detail-oriented, proactive professional with a strong background in data management, data warehousing, and healthcare analytics', 'Proficiency in dimensional modeling, SQL, and data warehousing concepts', 'Experience with DB2, ETL tools (Ab Initio), and reporting tools (Cognos, Tableau)', 'Familiarity with data modeling tools like Erwin', 'Strong understanding of ETL processes, data governance, and metadata management', 'Knowledge of healthcare payer systems, including claims and clinical decision support', 'Soft Skills', 'Strong analytical and problem-solving abilities', 'Excellent verbal and written communication skills', 'Ability to work independently and collaboratively in a team environment', 'Education & Experience', 'Bachelor’s or Master’s degree in Computer Science, Information Systems, or a related field', '7–10 years of experience in systems analysis, with a focus on data warehousing in the healthcare payer sector', 'UST reserves the right to periodically redefine your roles and responsibilities based on the requirements of the organization and/or your performance']","['Data Analysis & Design: Contribute to the design, modeling, implementation, and maintenance of data solutions within the clinical data ecosystem', 'ETL Process Understanding: Interpret ETL terminologies and processes including jobs, Psets, graphs, schedules, and job series (100, 300, 500)', 'Data Modeling: Follow data model standards and understand entity-relationship (ER) modeling using tools like Erwin', 'PHI/PII Data Handling: Ensure compliance with data privacy standards by preventing exposure to PHI/PII and applying data masking techniques', 'SA Deliverables: Create and maintain key deliverables such as Source-to-Target (S2T) mappings, Data Element Dictionaries (DED), Functional Requirement Specifications (FRS), data models, design documents, and impact analyses', 'Performance Optimization: Optimize performance through index creation, efficient SQL writing, and process design', 'This position description identifies the responsibilities and tasks typically associated with the performance of the position', 'Other relevant essential functions may be required']",True,[],,"['Dimensional Modeling', 'SQL', 'Data Warehousing', 'ETL Processes', 'Entity-Relationship (ER) Modeling', 'Data Masking', 'Source-to-Target (S2T) Mappings', 'Data Element Dictionaries (DED)', 'Functional Requirement Specifications (FRS)', 'Data Modeling Tools', 'Performance Optimization', 'DB2', 'ETL Tools', 'Reporting and BI Tools', 'Data Governance', 'Metadata Management']","Dimensional Modeling: Used to design and model data solutions within the clinical data ecosystem, supporting data warehousing and analytics in healthcare payer systems.; SQL: Applied for writing efficient queries to optimize performance and support data analysis and process design in the clinical data environment.; Data Warehousing: Central to the role, involving design, implementation, and maintenance of data solutions and architecture within healthcare payer clinical data ecosystems.; ETL Processes: Understanding and interpreting ETL terminologies and workflows such as jobs, Psets, graphs, schedules, and job series to support data integration and transformation.; Entity-Relationship (ER) Modeling: Following data model standards and using ER modeling techniques with tools like Erwin to design and maintain data models.; Data Masking: Applied to ensure compliance with data privacy standards by preventing exposure of PHI/PII in healthcare data environments.; Source-to-Target (S2T) Mappings: Creating and maintaining mappings that define data flow from source systems to target data stores as part of data architecture deliverables.; Data Element Dictionaries (DED): Maintaining comprehensive dictionaries that document data elements to support data governance and clarity in the clinical data ecosystem.; Functional Requirement Specifications (FRS): Developing detailed specifications that outline functional requirements for data solutions and system design.; Data Modeling Tools: Using tools like Erwin to support data modeling, design, and documentation within the healthcare payer data environment.; Performance Optimization: Improving system and query performance through index creation, efficient SQL writing, and process design.; DB2: Experience with the DB2 database system as part of the data warehousing and management technology stack.; ETL Tools: Utilizing ETL tools such as Ab Initio to support data extraction, transformation, and loading processes.; Reporting and BI Tools: Using tools like Cognos and Tableau to create reports and dashboards for data analysis and visualization.; Data Governance: Ensuring data quality, compliance, and management practices within the healthcare payer clinical data ecosystem.; Metadata Management: Managing metadata to support data governance, lineage, and understanding of data assets."
W-poE1bKK2KGnW48AAAAAA==,"Senior Analytics Strategist, Industry Insights","Responsibilities: Engages with internal partners to understand business strategy, questions and goals. Brings structure to business requests, translates requirements into an analytical project approach, and leads complex projects through completion. Delegates tasks and provides tactical and strategic guidance to peers. Serves as the analytics expert on cross-functional teams for large strategic initiatives. Acquires and compiles structured and unstructured data and verifies its quality, accuracy and reasonableness. Performs analyses of historical data to surface trends and insights using advanced analytical methods. Validates analytical techniques employed by other analysts. Prepares and delivers expert level visualizations and internal presentations that translate analytic insights into tangible, actionable solutions for business partners to implement. Develops, owns and manages recurring analytic or reporting processes. Actively develops the analytics community at Vanguard by mentoring, coaching and connecting others with resources and training. Participates and presents during scheduled analytics seminars. Participates in special projects and performs other duties as assigned. What it takes: This role is central to FAS’s vision of being the “advisor to the advisor,” using data to anticipate client needs and deliver the right products and services at the right time. The analyst will play a key role in shaping how FAS understands and responds to industry dynamics. Minimum of 8–10 years of related work experience in analytics, strategy, or financial services. Proven experience in delivering insights from structured and unstructured data using advanced statistical and machine learning methods (e.g., regression, segmentation, time series analysis, Bayesian methods). Familiarity with financial products such as ETFs and mutual funds, and experience working with broker-dealers, RIAs, and bank trust departments. Ability to translate business questions into analytical projects and deliver insights that influence decision-making Experience in scenario planning, forecasting, and ROI analysis for marketing or distribution strategies Consultative approach with business functional and technical skills with Validated experience in building and delivering data & analytics products and insights. Experience working with Morningstar and Bloomberg data is highly valued, especially for competitive and market trend analysis. Proficiency in data analysis tools such as SQL, Python, R, and Tableau . Experience with data visualization, dashboard creation, and storytelling with data. Strong understanding of data modeling, predictive analytics, and scenario analysis. Special Factors Sponsorship Vanguard is offering visa sponsorship for this position. About Vanguard At Vanguard, we don't just have a mission—we're on a mission. To work for the long-term financial wellbeing of our clients. To lead through product and services that transform our clients' lives. To learn and develop our skills as individuals and as a team. From Malvern to Melbourne, our mission drives us forward and inspires us to be our best. How We Work Vanguard has implemented a hybrid working model for the majority of our crew members, designed to capture the benefits of enhanced flexibility while enabling in-person learning, collaboration, and connection. We believe our mission-driven and highly collaborative culture is a critical enabler to support long-term client outcomes and enrich the employee experience. Vanguard, one of the world's largest investment management companies, serves individual investors, institutions, employer-sponsored retirement plans, and financial professionals. We have a diverse and talented crew with a culture that promotes teamwork, along with an unwavering focus on serving our clients' best interests. This website uses ""cookies"" to distinguish you from other users. A cookie is a small file of letters and numbers placed on your computer or device. This helps us to provide you with a good experience when you browse our website and also allows us to improve our site and services. The cookies are stored locally on your computer or mobile device. To accept cookies you can continue browsing as normal. Or you can go to our Privacy Policy to read more information and learn how to change your preferences.",2025-07-14T00:00:00.000Z,2025-07-25,"['Minimum of 8–10 years of related work experience in analytics, strategy, or financial services', 'Proven experience in delivering insights from structured and unstructured data using advanced statistical and machine learning methods (e.g., regression, segmentation, time series analysis, Bayesian methods)', 'Familiarity with financial products such as ETFs and mutual funds, and experience working with broker-dealers, RIAs, and bank trust departments', 'Ability to translate business questions into analytical projects and deliver insights that influence decision-making Experience in scenario planning, forecasting, and ROI analysis for marketing or distribution strategies Consultative approach with business functional and technical skills with Validated experience in building and delivering data & analytics products and insights', 'Experience working with Morningstar and Bloomberg data is highly valued, especially for competitive and market trend analysis', 'Proficiency in data analysis tools such as SQL, Python, R, and Tableau ', 'Experience with data visualization, dashboard creation, and storytelling with data', 'Strong understanding of data modeling, predictive analytics, and scenario analysis']","['Responsibilities: Engages with internal partners to understand business strategy, questions and goals', 'Brings structure to business requests, translates requirements into an analytical project approach, and leads complex projects through completion', 'Delegates tasks and provides tactical and strategic guidance to peers', 'Serves as the analytics expert on cross-functional teams for large strategic initiatives', 'Acquires and compiles structured and unstructured data and verifies its quality, accuracy and reasonableness', 'Performs analyses of historical data to surface trends and insights using advanced analytical methods', 'Validates analytical techniques employed by other analysts', 'Prepares and delivers expert level visualizations and internal presentations that translate analytic insights into tangible, actionable solutions for business partners to implement', 'Develops, owns and manages recurring analytic or reporting processes', 'Actively develops the analytics community at Vanguard by mentoring, coaching and connecting others with resources and training', 'Participates and presents during scheduled analytics seminars', 'Participates in special projects and performs other duties as assigned', 'What it takes: This role is central to FAS’s vision of being the “advisor to the advisor,” using data to anticipate client needs and deliver the right products and services at the right time', 'The analyst will play a key role in shaping how FAS understands and responds to industry dynamics', ""To lead through product and services that transform our clients' lives""]",True,[],,"['Regression models', 'Segmentation', 'Time-series analysis', 'Bayesian methods', 'SQL', 'Python', 'R', 'Tableau', 'Data modeling', 'Predictive analytics', 'Scenario analysis', 'Machine learning', 'Data visualization', 'Dashboard creation', 'Advanced statistical methods', 'Morningstar and Bloomberg data']","Regression models: Used as an advanced statistical method to analyze historical data and deliver insights that influence decision-making.; Segmentation: Applied as an advanced analytical method to surface trends and insights from structured and unstructured data.; Time-series analysis: Employed for scenario planning, forecasting, and analyzing historical data trends to support marketing or distribution strategies.; Bayesian methods: Utilized as part of advanced statistical techniques to validate analytical approaches and deliver insights from data.; SQL: Used as a data analysis tool to acquire, compile, and verify structured and unstructured data quality and accuracy.; Python: Applied for data analysis, building analytics products, and delivering insights through advanced statistical and machine learning methods.; R: Used for data analysis, statistical modeling, and creating predictive analytics and scenario analysis.; Tableau: Employed for data visualization, dashboard creation, and storytelling with data to translate analytic insights into actionable business solutions.; Data modeling: Involves building predictive analytics and scenario analysis models to support business strategy and decision-making.; Predictive analytics: Used to forecast outcomes and support scenario planning and ROI analysis for marketing or distribution strategies.; Scenario analysis: Applied to evaluate potential business outcomes and support strategic planning and forecasting efforts.; Machine learning: Used as an advanced method to deliver insights from structured and unstructured data, including validation of analytical techniques.; Data visualization: Involves preparing expert-level visualizations and presentations to communicate analytic insights effectively to business partners.; Dashboard creation: Developed and managed recurring analytic or reporting processes to provide ongoing insights and support decision-making.; Advanced statistical methods: Employed to analyze historical data, surface trends, and validate analytical techniques used by other analysts.; Morningstar and Bloomberg data: Used for competitive and market trend analysis to inform strategic initiatives and industry insights."
3vfOErC4TqhPs8CnAAAAAA==,Data Quality Analyst,"Welcome to the American Red Cross, where our mission is to alleviate human suffering in the face of emergencies. We are seeking a highly motivated and detail-oriented Data Quality Analyst to join our team. As a Data Quality Analyst, you will play a critical role in ensuring the accuracy and integrity of our data, ultimately helping us make informed decisions and better serve those in need. If you are passionate about using your analytical skills to make a meaningful impact, have a strong attention to detail, and thrive in a fast-paced environment, we encourage you to apply. Join us in our mission to provide aid and relief to those affected by disasters and emergencies across the country.

Conduct regular audits of data to identify any errors, inconsistencies, or anomalies.
Collaborate with cross-functional teams to establish data quality standards and protocols.
Develop and implement data cleansing and data validation procedures.
Monitor data entry processes and ensure adherence to data quality standards.
Identify and resolve data quality issues in a timely manner.
Develop and maintain data quality reports and metrics to track and communicate data accuracy.
Stay up-to-date with industry best practices and recommend improvements to data quality processes.
Train and support staff on data entry protocols and procedures.
Investigate and troubleshoot data discrepancies and provide solutions.
Communicate and escalate data quality issues to appropriate stakeholders.
Ensure compliance with data privacy and security regulations.
Participate in data governance initiatives and contribute to the development of data quality policies and procedures.
Use data analysis techniques to identify trends and patterns and provide insights to improve data quality.
Continuously monitor and evaluate data quality processes and make recommendations for improvements.
Collaborate with IT teams to implement data quality tools and technologies.
Support data migration initiatives and ensure data integrity during the process.
Provide support and guidance to colleagues regarding data quality issues and procedures.
Participate in team meetings and contribute to the overall goals and objectives of the organization.

American Red Cross is an Equal Opportunity Employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. We do not discriminate based upon race, religion, color, national origin, sex, sexual orientation, gender identity, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.",,2025-07-25,,"['As a Data Quality Analyst, you will play a critical role in ensuring the accuracy and integrity of our data, ultimately helping us make informed decisions and better serve those in need', 'If you are passionate about using your analytical skills to make a meaningful impact, have a strong attention to detail, and thrive in a fast-paced environment, we encourage you to apply', 'Join us in our mission to provide aid and relief to those affected by disasters and emergencies across the country', 'Conduct regular audits of data to identify any errors, inconsistencies, or anomalies', 'Collaborate with cross-functional teams to establish data quality standards and protocols', 'Develop and implement data cleansing and data validation procedures', 'Monitor data entry processes and ensure adherence to data quality standards', 'Identify and resolve data quality issues in a timely manner', 'Develop and maintain data quality reports and metrics to track and communicate data accuracy', 'Stay up-to-date with industry best practices and recommend improvements to data quality processes', 'Train and support staff on data entry protocols and procedures', 'Investigate and troubleshoot data discrepancies and provide solutions', 'Communicate and escalate data quality issues to appropriate stakeholders', 'Ensure compliance with data privacy and security regulations', 'Participate in data governance initiatives and contribute to the development of data quality policies and procedures', 'Use data analysis techniques to identify trends and patterns and provide insights to improve data quality', 'Continuously monitor and evaluate data quality processes and make recommendations for improvements', 'Collaborate with IT teams to implement data quality tools and technologies', 'Support data migration initiatives and ensure data integrity during the process', 'Provide support and guidance to colleagues regarding data quality issues and procedures', 'Participate in team meetings and contribute to the overall goals and objectives of the organization']",False,,,,
TD41iLrpCk_xL4BOAAAAAA==,Psychometric Data Analyst II,"When you join Renaissance®, you join a global leader in pre-K-12 education technology! Renaissance's solutions help educators analyze, customize, and plan personalized learning paths for students, allowing time for what matters-creating energizing learning experiences in the classroom.

Our fiercely passionate employees and educational partners have helped drive phenomenal student growth, with Renaissance solutions being used in over one-third of US schools and in more than 100 countries worldwide.

Every day, we are connected to our mission by exemplifying our values: trust each other, win together, strive for the best, own our actions, and grow and evolve.

This role is related to Renaissance's educational technology products, with a primary focus on the assessment products that include the Star Computerized Adaptive tests (CAT) and the Star curriculum-based measures (CBM).
• *In this role as a Psychometric Data Analyst II, you will: **

+ Extract assessment data from Snowflake and/or MongoDB as needed for various analyses

+ Analyze psychometric data related to item and test content, quality, and performance from a variety of sources, both structured and unstructured

+ Define and track assessment quality and performance related metrics

+ Design and implement research, testing, and data mining projects, including scenarios and simulations

+ Communicate results of analyses through written reports, visual displays, and verbal communication

+ Support the psychometricians with statistical analyses related to advanced psychometric work.

+ Maintain an accurate and up-to-date knowledge on statistical analysis techniques and applications
• *For this role as a Psychometric Data Analyst II, you must have:**

+ Bachelor's degree in statistics, mathematics, data science, or a related field from four-year accredited college or university, and

+ Minimum 6 years' experience implementing analysis and testing plans and defining and tracking metrics, OR

+ Equivalent combination of education and experience

+ Extensive database management experience in both structured (SQL) and unstructured (NoSQL) databases especially MongoDB.

+ Ability to manipulate and analyze data in SAS, r, and Python.

+ Exceptional attention to detail.

+ Demonstrated ability to work well within a team and cross functionally.
• *Bonus points for:**

+ Master's degree in Statistics or a related field

All your information will be kept confidential according to EEO guidelines.

Salary Range: $61,800 to $85,000 This range is based on national market data and may vary by experience and location.
• *Benefits for eligible employees include:**

+ World Class Health Benefits: Medical, Prescription, Dental, Vision, Telehealth

+ Health Savings and Flexible Spending Accounts

+ 401(k) and Roth 401(k) with company match

+ Paid Vacation and Sick Time Off

+ 12 Paid Holidays

+ Parental Leave (20 total weeks with 14 weeks paid) & Milk Stork program

+ Tuition Reimbursement

+ Life & Disability Insurance

+ Well-being and Employee Assistance Programs

Frequently cited statistics show that some women, underrepresented individuals, protected veterans and individuals with disabilities may only apply to roles if they meet 100% of the qualifications. At Renaissance, we encourage all applications! Roles evolve over time, especially with innovation, and you may be just the person we need for the future!

EQUAL OPPORTUNITY EMPLOYER

Renaissance is an equal opportunity employer and does not discriminate with respect to any term, condition or privilege of employment based on race, color, religion, sex, sexual orientation, gender identity or expression, age, disability, military or veteran status, marital status, or status of an individual in any group or class protected by applicable federal, state, or local law.

REASONABLE ACCOMMODATIONS

Renaissance also provides reasonable accommodations for qualified individuals with disabilities in accordance with the Americans with Disabilities Act and applicable state and local laws. If accommodation is needed to participate in the job application or interview process, please contact Talent Acquisition (TATeam@renlearnCRM.onmicrosoft.com) .

EMPLOYMENT AUTHORIZATION

Applicants must be authorized to work for any employer in the United States. We are unable to sponsor or take over sponsorship of an employment Visa at this time.

For information about Renaissance, visit: https://www.renaissance.com/",2025-07-21T00:00:00.000Z,2025-07-25,"['Maintain an accurate and up-to-date knowledge on statistical analysis techniques and applications', '*For this role as a Psychometric Data Analyst II, you must have:**', ""Bachelor's degree in statistics, mathematics, data science, or a related field from four-year accredited college or university, and"", ""Minimum 6 years' experience implementing analysis and testing plans and defining and tracking metrics, OR"", 'Equivalent combination of education and experience', 'Extensive database management experience in both structured (SQL) and unstructured (NoSQL) databases especially MongoDB', 'Ability to manipulate and analyze data in SAS, r, and Python', 'Exceptional attention to detail', 'Demonstrated ability to work well within a team and cross functionally', ""Master's degree in Statistics or a related field"", 'Applicants must be authorized to work for any employer in the United States']","['*In this role as a Psychometric Data Analyst II, you will: **', 'Extract assessment data from Snowflake and/or MongoDB as needed for various analyses', 'Analyze psychometric data related to item and test content, quality, and performance from a variety of sources, both structured and unstructured', 'Define and track assessment quality and performance related metrics', 'Design and implement research, testing, and data mining projects, including scenarios and simulations', 'Communicate results of analyses through written reports, visual displays, and verbal communication', 'Support the psychometricians with statistical analyses related to advanced psychometric work']",True,[],,"['SQL', 'NoSQL', 'MongoDB', 'Psychometric Data Analysis', 'Statistical Analysis Techniques', 'Data Mining', 'SAS', 'R', 'Python', 'Assessment Quality Metrics', 'Data Visualization']","SQL: Used for extracting assessment data from structured databases such as Snowflake to support various analyses.; NoSQL: Used for extracting assessment data from unstructured databases such as MongoDB to support various analyses.; MongoDB: A NoSQL database specifically mentioned as a source for assessment data extraction and management.; Psychometric Data Analysis: Involves analyzing item and test content, quality, and performance data from multiple sources to support educational assessment products.; Statistical Analysis Techniques: Applied to support advanced psychometric work and to maintain up-to-date knowledge for accurate data interpretation and research.; Data Mining: Used to design and implement projects including scenarios and simulations for research and testing purposes.; SAS: A tool used to manipulate and analyze psychometric and assessment data.; R: A programming language used to manipulate and analyze psychometric and assessment data.; Python: A programming language used to manipulate and analyze psychometric and assessment data.; Assessment Quality Metrics: Defined and tracked to evaluate the quality and performance of educational assessments.; Data Visualization: Used to communicate results of analyses through visual displays to support understanding of psychometric data."
CFCiDRKk1ZL6XOfbAAAAAA==,Senior Data Protection Analyst - Cyber,"Are you passionate about technology and interested in joining a community of collaborative colleagues who respectfully and courageously seek to challenge the status quo? If so, read on to learn more about an exciting opportunity with Deloitte Technology US (DT - US). We are curious and life-long learners focused on technology and innovation.

Recruiting for this role ends on 7/31/2025.

Work you'll do

DT-US Cyber Data Protection team is responsible for securing and protecting confidential data of Deloitte US Member Firm, our clients, and our employees. The team's core mission is to implement consistent security controls to protect Firm's data and data entrusted to us by our clients to build their trust and protect our brand. We are seeking an experienced and energetic Senior Data Protection Analyst with outstanding communication, analytical and cyber security technical skills to join our Cyber Data Protection team within Deloitte Technology US (DT - US).

If you're an experienced, hands-on IT professional with strong systems administration, engineering, IT technical support and/or cyber security technical skills who's interested in growing in the cybersecurity field, this may be the job for you. As part of our Cyber Data Protection team, you will be assisting in designing, deploying, and managing cyber technology and process solutions to reduce the potential of data compromise. You will be assisting with testing of data protection and data security solutions. You will work to enhance and mature existing cyber security data protection capabilities for Deloitte US Member Firm and provide on-going support for them. You will require an understanding of the ecosystem of data protection including well-rounded understanding of the information security domains and their inter-relations across that ecosystem. You will be responsible for providing technical product and troubleshooting assistance to Deloitte Employees. You will work closely with management, lead analysts, peers, development teams, business analysts, and end users to ensure data protection technologies and data protection controls for systems are operating appropriately without causing business impact.

As part of the DT- US Cyber Data Protection team, you will have the following core responsibilities:
• Assist with the development, deployment and support of cyber data protection solutions.
• Assist with the implementation of data security controls and design principles.
• Provide Tier 2 technical support to Deloitte end users for several of the cyber data protection services supported by the team that includes but not limited to Data Loss Prevention, Data Minimization, Data Classification and Rights Management, CASB, Web Security, Web Application Firewall, Next Generation Anti-virus and Endpoint Detection and Response technology, Endpoint Admin Rights Management/Privilege Management technology, PKI Certificate Lifecycle Management, Encryption Key Management, Digital Code Signing, Removable Media Protection, Data Discovery Roll Off Scans etc.
• Assist in maturing existing data protection solutions protecting against data exfiltration.
• Assist in rolling out new data protection services to employees, getting them adopted and providing on-going support for those services.
• Assist with technology and software reviews based on data protection and endpoint risks.
• Provide technical engineering and troubleshooting support to employees for data protection services.

Experience working with various data protection technologies:
• Data Loss Prevention (DLP) technology
• Data Classification and Rights Management technology
• Cloud Access Security Broker (CASB)
• Secure Web Gateway/Proxy (SWG) technology
• Next Generation Anti-virus and Endpoint Detection and Response technology
• Endpoint Admin Rights Management/Privilege Management technology
• PKI Certificate Management technology
• Encryption Key Management technology
• Web Application Firewall technology
• Confidential Data Reduction technology
• Data Access Governance technology
• Removable Media Protection technology
• Database Encryption technologies

The team

Deloitte Technology US (DT - US) helps power Deloitte's success, which serves many of the world's largest, most respected organizations. We develop and deploy cutting-edge internal and go-to-market solutions that help Deloitte operate effectively and lead in the market. Our reputation is built on a tradition of delivering with excellence.

The ~3,000 professionals in DT - US deliver services including:
• Cyber Security
• Technology Support
• Technology & Infrastructure
• Applications
• Relationship Management
• Strategy & Communications
• Project Management
• Financials

Cyber Security

Cyber Security vigilantly protects Deloitte and client data. The team leads a strategic cyber risk program that adapts to a rapidly changing threat landscape, changes in business strategies, risks, and vulnerabilities. Using situational awareness, threat intelligence, and building a security culture across the organization, the team helps to protect the Deloitte brand.

Areas of focus include:
• Risk & Compliance
• Identity & Access Management
• Data Protection
• Cyber Design
• Incident Response
• Security Architecture
• Business Partnership

Required Qualifications:
• Bachelor's degree or equivalent in Computer Science or Engineering.
• Minimum 5 years of combined experience in the Information Security/Cybersecurity domain.
• Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future

Preferred Qualifications:
• Experienced with implementing and managing data protection strategies across data at rest, data in motion, and data in use.
• Experience with troubleshooting issues and assisting end users to mitigate technical challenges.
• Familiarity with change management and deployment processes in large IT organizations.
• Working knowledge with common IT technologies such as Windows Server, Linux/Unix, Databases, Active Directory/LDAP, virtualization, end-user devices etc.
• Working knowledge of IT/security principles such as encryption, identity, cloud, etc.
• Experience with PowerShell command-line scripting is a plus.
• Professional security certification desirable, such as Security+ or CISSP.
• Understanding of industry best practices related to risk assessment, mitigation, and incident response.
• Knowledge of data protection regulations and standards (e.g., ISO 27001, ISO 27018, NIST 800-171).
• Understanding of networking and core networking protocols (e.g., TCP/IP, UDP, DNS, SMTP, HTTP, TLS, and distributed networks).
• Knowledge in different types of VPN, Encryption Standards, Certificates.
• Understanding of security controls in public cloud environments (i.e., Amazon Web Services (AWS), Microsoft Azure, Google Cloud Platform) and SaaS services hardening.
• Ability to write technical reports and communicate technical content to business users.
• Self-motivated with a strong willingness to learn and grow with changing cloud technologies.
• Experience working in a virtual team.
• Troubleshooting and problem analysis skills.
• Understanding of information security frameworks, incident management/response, security operations, and application security best practices.
• Competency with Microsoft Windows and/or MacOS Operating Systems

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $84,300 - $173,300.

You may also be eligible to participate in a discretionary annual incentive program, subject to the rules governing the program, whereby an award, if any, depends on various factors, including, without limitation, individual and organizational performance.

Information for applicants with a need for accommodation: https://www2.deloitte.com/us/en/pages/careers/articles/join-deloitte-assistance-for-disabled-applicants.html

EA_ExpHire

RITM9065907

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.",2025-07-17T00:00:00.000Z,2025-07-25,"['Data Loss Prevention (DLP) technology', 'Secure Web Gateway/Proxy (SWG) technology', 'Next Generation Anti-virus and Endpoint Detection and Response technology', 'Endpoint Admin Rights Management/Privilege Management technology', 'PKI Certificate Management technology', 'Encryption Key Management technology', 'Web Application Firewall technology', 'Confidential Data Reduction technology', 'Data Access Governance technology', 'Removable Media Protection technology', 'Database Encryption technologies', 'Identity & Access Management', ""Bachelor's degree or equivalent in Computer Science or Engineering"", 'Minimum 5 years of combined experience in the Information Security/Cybersecurity domain', 'Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future', 'The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs']","['As part of our Cyber Data Protection team, you will be assisting in designing, deploying, and managing cyber technology and process solutions to reduce the potential of data compromise', 'You will be assisting with testing of data protection and data security solutions', 'You will work to enhance and mature existing cyber security data protection capabilities for Deloitte US Member Firm and provide on-going support for them', 'You will require an understanding of the ecosystem of data protection including well-rounded understanding of the information security domains and their inter-relations across that ecosystem', 'You will be responsible for providing technical product and troubleshooting assistance to Deloitte Employees', 'You will work closely with management, lead analysts, peers, development teams, business analysts, and end users to ensure data protection technologies and data protection controls for systems are operating appropriately without causing business impact', 'As part of the DT- US Cyber Data Protection team, you will have the following core responsibilities:', 'Assist with the development, deployment and support of cyber data protection solutions', 'Assist with the implementation of data security controls and design principles', 'Provide Tier 2 technical support to Deloitte end users for several of the cyber data protection services supported by the team that includes but not limited to Data Loss Prevention, Data Minimization, Data Classification and Rights Management, CASB, Web Security, Web Application Firewall, Next Generation Anti-virus and Endpoint Detection and Response technology, Endpoint Admin Rights Management/Privilege Management technology, PKI Certificate Lifecycle Management, Encryption Key Management, Digital Code Signing, Removable Media Protection, Data Discovery Roll Off Scans etc', 'Assist in maturing existing data protection solutions protecting against data exfiltration', 'Assist in rolling out new data protection services to employees, getting them adopted and providing on-going support for those services', 'Assist with technology and software reviews based on data protection and endpoint risks', 'Provide technical engineering and troubleshooting support to employees for data protection services', 'Cloud Access Security Broker (CASB)', 'Strategy & Communications', 'Project Management']",False,,,,
d2U_5v716K_r4I5AAAAAAA==,"Associate, Data Analytics","About Us

Social Finance is a national nonprofit and a registered investment advisor (SF Advisors, LLC). We work with the public, private, and social sectors to create partnerships and investments that measurably improve lives. Since our founding in 2011, we have mobilized over $400 million in new investments designed to help people and communities realize improved outcomes in workforce and economic mobility, health, and housing.

We are driven by the belief that social and economic systems should enable all people to thrive, and the conviction that we can create the most meaningful and measurable change in our communities when governments and markets work together. Our organization is built upon five core values: people, performance, integrity, collaboration, and inclusion.

Our work spans four areas: Impact-first Investing, Workforce and Education Investments, Advisory & Public Sector Practice, and the Social Finance Institute. Our Impact-first Investment team designs, launches, and manages investments that provide solutions for effectively deploying impact capital across a range of social outcomes. Our Workforce and Education Investments team designs, launches and manages financial solutions focused on addressing workforce challenges, including skills acquisition and training access. Our Advisory team partners with government and philanthropy leaders to implement data-driven programs for advancing social impact. And through the Social Finance Institute, we aim to build the field and change systems through actionable research, communities of practice, and educational outreach.

Note: To be considered for our open roles, candidates must hold permanent U.S. work authorization at the time of application, which will not require employer sponsorship at point-of-hire or in the future.

The Opportunity

The Data Analytics team works across the organization to deepen our development and execution of data analysis and visualization, data management and strategy, and program assessment and learning workstreams. We are seeking a dedicated, driven and team-oriented Associate, Data Analytics to serve as an integral member of the Social Finance team and help us deliver on our Data Solutions service offerings, joining a team of four other data analytics professionals. While the data analytics team works across all areas of our business, this role will initially focus on data analytics efforts within our Impact Advisory & Public Sector Practice team. The early portfolio for this position may include:
• Impact Advisory & Public Sector Practice: Analyzing administrative data, developing and updating data dashboards, supporting primary quantitative and qualitative data collection, and assessing and providing recommendations on data management strategies.

Project allocation may evolve over time to support other data analytics needs across the Social Finance team. This position reports to the Director, Data Analytics & Evaluation.

Responsibilities
• Data analysis. Use statistical software (such as Stata or R) to validate, structure, clean, and analyze public sector data
• Visualizing and presenting data. Create effective visual storytelling through data dashboards, interactive figures, and internal and external communication materials
• Data collection. Support primary data collection by developing surveys and interview guides, including programming surveys in programs such as Qualtrics
• Data management. Assessing and providing recommendations to clients on best practices for organizing, structuring, storing, and accessing data
• Program assessment. Support assessment of program performance through identifying key research questions and analyzing performance using quantitative and qualitative data
• Drive stakeholder engagement in data analytics efforts. Develop and manage internal and external stakeholder relationships and engagement on data analytics workstreams
• Implementing data equity principles. Ensure data analysis and data visualization workstreams follow best practices in data equity in terms of design, structure, and format
• Provide support to teams carrying out data analysis and data visualization tasks, including troubleshooting challenges and conducting testing and quality assurance on coding and product development
• Contribute to firm capacity-building initiatives, such as recruiting, professional development, knowledge management, fundraising, or other internal projects

Qualifications
• 2 to 5 years of full-time professional experience with relevant and transferable skills related to data analysis, data visualization, program assessment, and data collection
• Bachelor's degree or related certificate in computer science, data analytics, economics, finance, engineering, political science, or related field
• Experience coding in Stata or R, or experience with another statistical analysis program and willingness and demonstrated capacity to learn Stata or R
• Experience developing data dashboards in Tableau or PowerBi, or experience with another data visualization software and willingness and demonstrated capacity to learn Tableau.
• Experience with or an understanding of the public sector and social service delivery
• Experience or familiarity with at least one of our core issue areas: children and families, workforce development and economic mobility, housing and homelessness, or public safety.
• Detail-oriented and adept at instituting quality control checks and ensuring accuracy in data analysis
• Strong oral and written communications skills, with the ability to summarize and explain research studies in a compelling way, including through well-written memos and PowerPoint presentations.
• Ability to communicate, work closely with, and build relationships with many types of partners across multiple sectors
• Ability to adapt, be flexible, and work independently to complete high-quality project work
• Commitment to enhancing a team culture of inclusion, belonging and equity

Benefits

At Social Finance, we strive to deliver a benefits program that will enhance our overall value proposition to employees. Our current benefit offerings include:
• Comprehensive health care coverage: medical, dental and vision insurance, flexible spending accounts, and more
• Retirement savings plan with employer contribution
• Short-term, long-term and life insurance policies
• Commuter benefits and cell phone reimbursements
• Hybrid work model (in office at least two days per week)
• Dedicated budgets for team building and employee recognition
• Annual budget for external professional development opportunities
• Mentorship and onboarding programs
• Collaborative and energizing workspaces in downtown Boston, MA; San Francisco, CA; Austin, TX; Washington, D.C.; and New York, NY
• Paid vacation and paid holidays (with 12/24-1/1 off every year)
• Paid parental leave
• A truly stellar team of high performing, values-driven and fun (!) professionals

Salary

Social Finance uses a lockstep compensation model for purposes of equity and transparency - we strive for everyone coming in at a given level to be paid equitably. For this position, at the Associate level, the starting base salary is $81,000; however, during the interview process, we will take into account a candidate's full work experience and may adjust the job title, and commensurate starting salary, as appropriate. At this level, employees typically receive a $2,500 salary increase annually and are eligible to participate in our firmwide annual bonus program. Bonuses are typically between 5-10%, though bonuses are not guaranteed and are dependent on both organizational and individual performance.

If joining our San Francisco office, this hire would receive a cost of living adjustment, which includes an additional $1,000 for every month they are residing in the state of California within a commutable distance of our office in San Francisco

Review of applications will begin immediately. No phone calls, please.

Applicants must be permanently authorized to work in the United States on a full-time basis.

Please note that, at this time, to be in-person at a Social Finance office, client location or Social Finance-sponsored event, you must be fully vaccinated against COVID-19, including receiving a booster shot.

Social Finance, Inc. is an equal opportunity employer, and all qualified applicants will be afforded equal employment opportunities without discrimination because of actual or perceived race, color, national origin, sex, age, religion, creed, disability, marital status, citizenship, ancestry, personal appearance, sexual orientation, gender identity or expression, political affiliation, military status, status as a protected veteran, genetic information or any other legally protected status.

It is unlawful in Massachusetts to require or administer a lie detector test as a condition of employment or continued employment. An employer who violates this law shall be subject to criminal penalties and civil liability.

When submitting your resume below, please submit as a PDF. Thank you!",,2025-07-25,"['2 to 5 years of full-time professional experience with relevant and transferable skills related to data analysis, data visualization, program assessment, and data collection', ""Bachelor's degree or related certificate in computer science, data analytics, economics, finance, engineering, political science, or related field"", 'Experience coding in Stata or R, or experience with another statistical analysis program and willingness and demonstrated capacity to learn Stata or R', 'Experience developing data dashboards in Tableau or PowerBi, or experience with another data visualization software and willingness and demonstrated capacity to learn Tableau', 'Experience with or an understanding of the public sector and social service delivery', 'Experience or familiarity with at least one of our core issue areas: children and families, workforce development and economic mobility, housing and homelessness, or public safety', 'Detail-oriented and adept at instituting quality control checks and ensuring accuracy in data analysis', 'Strong oral and written communications skills, with the ability to summarize and explain research studies in a compelling way, including through well-written memos and PowerPoint presentations', 'Ability to communicate, work closely with, and build relationships with many types of partners across multiple sectors', 'Ability to adapt, be flexible, and work independently to complete high-quality project work', 'Commitment to enhancing a team culture of inclusion, belonging and equity', 'Applicants must be permanently authorized to work in the United States on a full-time basis', 'Please note that, at this time, to be in-person at a Social Finance office, client location or Social Finance-sponsored event, you must be fully vaccinated against COVID-19, including receiving a booster shot']","['The Data Analytics team works across the organization to deepen our development and execution of data analysis and visualization, data management and strategy, and program assessment and learning workstreams', 'While the data analytics team works across all areas of our business, this role will initially focus on data analytics efforts within our Impact Advisory & Public Sector Practice team', 'Impact Advisory & Public Sector Practice: Analyzing administrative data, developing and updating data dashboards, supporting primary quantitative and qualitative data collection, and assessing and providing recommendations on data management strategies', 'Project allocation may evolve over time to support other data analytics needs across the Social Finance team', 'This position reports to the Director, Data Analytics & Evaluation', 'Data analysis', 'Use statistical software (such as Stata or R) to validate, structure, clean, and analyze public sector data', 'Visualizing and presenting data', 'Create effective visual storytelling through data dashboards, interactive figures, and internal and external communication materials', 'Data collection', 'Support primary data collection by developing surveys and interview guides, including programming surveys in programs such as Qualtrics', 'Data management', 'Assessing and providing recommendations to clients on best practices for organizing, structuring, storing, and accessing data', 'Program assessment', 'Support assessment of program performance through identifying key research questions and analyzing performance using quantitative and qualitative data', 'Drive stakeholder engagement in data analytics efforts', 'Develop and manage internal and external stakeholder relationships and engagement on data analytics workstreams', 'Implementing data equity principles', 'Ensure data analysis and data visualization workstreams follow best practices in data equity in terms of design, structure, and format', 'Provide support to teams carrying out data analysis and data visualization tasks, including troubleshooting challenges and conducting testing and quality assurance on coding and product development', 'Contribute to firm capacity-building initiatives, such as recruiting, professional development, knowledge management, fundraising, or other internal projects']",True,[],,"['Statistical Software (Stata, R)', 'Data Dashboards (Tableau, Power BI)', 'Data Collection Tools (Qualtrics)', 'Data Management', 'Program Assessment', 'Data Visualization', 'Data Analysis', 'Data Equity Principles']","Statistical Software (Stata, R): Used to validate, structure, clean, and analyze public sector data as part of data analysis tasks.; Data Dashboards (Tableau, Power BI): Developed and updated to create effective visual storytelling through interactive figures and communication materials for internal and external stakeholders.; Data Collection Tools (Qualtrics): Used to support primary data collection by developing and programming surveys and interview guides.; Data Management: Involves assessing and providing recommendations on best practices for organizing, structuring, storing, and accessing data to clients.; Program Assessment: Supports assessment of program performance by identifying key research questions and analyzing performance using quantitative and qualitative data.; Data Visualization: Creating visual storytelling through dashboards and interactive figures to communicate data insights effectively.; Data Analysis: Involves cleaning, validating, structuring, and analyzing data using statistical software to support decision-making and program evaluation.; Data Equity Principles: Ensuring data analysis and visualization follow best practices in design, structure, and format to promote equity in data work."
H0I1lCNDyz3fz5iFAAAAAA==,Junior Data Analyst,"For more than 15 years Synergisticit has helped Jobseekers stand out from other Jobseekers by providing candidates the requisite skills, experience and technical competence to outperform at interviews and at clients.
Here at SynergisticIT We just don't focus on getting you a tech Job we make careers.
In this market also our candidates get multiple job offers and $100k + salaries.

please check the below links :
https://www.synergisticit.com/candidate-outcomes/

https://synergisticit.wistia.com/medias/o5gmv7i9eu

https://www.youtube.com/playlist?list=PLJgkOBQ51j5AHT5I6n29glr0q6trzkxYD

https://synergisticit.wistia.com/medias/k6t6a1n4kb

Why do Tech Companies not Hire recent Computer Science Graduates | SynergisticIT

Technical Skills or Experience? | Which one is important to get a Job? | SynergisticIT

All Positions are open for all visas and US citizens
We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.
Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Engineers/Data Scientists, Machine Learning engineers for full time positions with clients.
Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.
We assist in filing for STEM extension and also for H1b and Green card filing to Candidates
We want Data Science/Machine learning/Data Analyst and Java Full stack candidates
For data Science/Machine learning Positions
REQUIRED SKILLS
Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
Project work on the technologies needed
Highly motivated, self-learner, and technically inquisitive
Experience in programming language Java and understanding of the software development life cycle
Knowledge of Statistics, Python, Computer Vision, data visualization tools
Excellent written and verbal communication skills
Preferred skills: Snowflake, Databricks, Text mining, Tableau, PowerBI, Databricks, Tensorflow

REQUIRED SKILLS For Java /Full stack/Software Positions
Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
Highly motivated, self-learner, and technically inquisitive
Experience in programming language Java and understanding of the software development life cycle
Project work on the skills
Knowledge of Core Java , javascript , C++ or software programming
Spring boot, AWS Microservices, Docker, Jenkins and REST API's experience
Excellent written and verbal communication skills

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",,2025-07-25,"['Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry', 'For data Science/Machine learning Positions', 'Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT', 'Project work on the technologies needed', 'Highly motivated, self-learner, and technically inquisitive', 'Experience in programming language Java and understanding of the software development life cycle', 'Knowledge of Statistics, Python, Computer Vision, data visualization tools', 'Excellent written and verbal communication skills', 'REQUIRED SKILLS For Java /Full stack/Software Positions', 'Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT', 'Highly motivated, self-learner, and technically inquisitive', 'Experience in programming language Java and understanding of the software development life cycle', 'Project work on the skills', 'Knowledge of Core Java , javascript , C++ or software programming', ""Spring boot, AWS Microservices, Docker, Jenkins and REST API's experience"", 'Excellent written and verbal communication skills']",,True,[],,"['Statistics', 'Python', 'Data Visualization Tools', 'Text Mining', 'Snowflake', 'Databricks', 'Java', 'Core Java', 'JavaScript', 'C++', 'Spring Boot', 'AWS Microservices', 'Docker', 'Jenkins', 'REST APIs', 'Computer Vision', 'TensorFlow']","Statistics: Knowledge of statistics is required for data science and machine learning positions to analyze and interpret data effectively.; Python: Python programming language is required for data science and machine learning roles, supporting data analysis, scripting, and development.; Data Visualization Tools: Experience with data visualization tools such as Tableau and PowerBI is preferred to create dashboards and visual reports.; Text Mining: Text mining skills are preferred to extract meaningful information from textual data in data science projects.; Snowflake: Snowflake is a preferred data warehousing tool for managing and querying large datasets.; Databricks: Databricks is preferred for big data processing and collaborative data science workflows.; Java: Experience in Java programming and understanding of the software development life cycle is required for data science and software development roles.; Core Java: Knowledge of Core Java is required for software programming and full stack development.; JavaScript: JavaScript knowledge is required for software programming and full stack development.; C++: C++ programming knowledge is required for software programming roles.; Spring Boot: Spring Boot experience is required for building Java-based microservices in full stack development.; AWS Microservices: Experience with AWS microservices is required for cloud-based software development.; Docker: Docker experience is required for containerization in software development.; Jenkins: Jenkins experience is required for continuous integration and deployment in software projects.; REST APIs: Experience with REST APIs is required for building and integrating web services.; Computer Vision: Knowledge of computer vision is required for data science and machine learning roles involving image data.; TensorFlow: TensorFlow is a preferred framework for machine learning projects."
QBRYVs0WAtDhm7rAAAAAAA==,Business Data Analyst,"An employer is seeking a Business Data Analyst for a large financial client sitting in Jacksonville, FL. This person will be responsible for ensuring that all sites are compliant with all bank regulations. They will be responsible for debugging the UI on the backend, onboarding new applications and new websites, publishing the cookies as well as links that need to be added to the websites. This role is responsible for assessing policies, procedures, and operations to ensure the organization meets privacy requirements. They will work with stakeholders to determine requirements derived from privacy legislation. They will collaborate with a variety of groups to manage the workflow from privacy requirements to technical deliverables. Individuals in this role possess a working knowledge of the business/technical domain and the main applications within that domain.
Determine project scope documentation and identify/refine requirements.
Track and report on project status/deliverables and produce project artifacts.
Understand stakeholder needs to help envision and create a solution to solve a problem.
Gather and catalogue functional, non-functional, and technical requirements for stakeholder requests.
Provide subject matter expertise within the business / technical domain to support scope and requirement decisions.
Ensure changes to the application are compliant with bank standards and policies

We are a company committed to creating diverse and inclusive environments where people can bring their full, authentic selves to work every day. We are an equal opportunity/affirmative action employer that believes everyone matters. Qualified candidates will receive consideration for employment regardless of their race, color, ethnicity, religion, sex (including pregnancy), sexual orientation, gender identity and expression, marital status, national origin, ancestry, genetic factors, age, disability, protected veteran status, military or uniformed service member status, or any other status or characteristic protected by applicable laws, regulations, and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application or recruiting process, please send a request to HR@insightglobal.com.

To learn more about how we collect, keep, and process your private information, please review Insight Global's Workforce Privacy Policy: https://insightglobal.com/workforce-privacy-policy/ .",,2025-07-25,,"['This person will be responsible for ensuring that all sites are compliant with all bank regulations', 'They will be responsible for debugging the UI on the backend, onboarding new applications and new websites, publishing the cookies as well as links that need to be added to the websites', 'This role is responsible for assessing policies, procedures, and operations to ensure the organization meets privacy requirements', 'They will work with stakeholders to determine requirements derived from privacy legislation', 'They will collaborate with a variety of groups to manage the workflow from privacy requirements to technical deliverables', 'Individuals in this role possess a working knowledge of the business/technical domain and the main applications within that domain', 'Determine project scope documentation and identify/refine requirements', 'Track and report on project status/deliverables and produce project artifacts', 'Understand stakeholder needs to help envision and create a solution to solve a problem', 'Gather and catalogue functional, non-functional, and technical requirements for stakeholder requests', 'Provide subject matter expertise within the business / technical domain to support scope and requirement decisions', 'Ensure changes to the application are compliant with bank standards and policies']",False,,,,
jWLfCiK47FmY1HOVAAAAAA==,Marketing Analyst,"This role is hybrid in Union Square, NY
The Marketing Data Analytics Consultant will be an integral component of the Market Research Team within the Marketing Department. This person will report to the Analytics Sr Specialist whose job it is to work closely with market researchers, brand managers, marketing specialists, and social media managers to collect and analyze data that will be used to assess the impact of marketing activities in market and craft marketing strategies.
Key Responsibilities, Skills and Qualifications
• Pull data from various sources (internal, ad agency, Sprinkler, Google Analytics, Questline).
• Ensure data integrity. Mine raw data files and structure data to prepare for input into dashboards.
• Set up API connections with vendor platforms to automate data transfers
• Work with Analytics Sr. Specialist to: set up data pipelines and create new reports leveraging various data sources
• Proficient with query languages such as SQL, Python, R.
• Proficient with data visualization tools such as Power BI, Tableau, Data Studio
• Proficient with data platforms such as Google Analytics, Oracle, Azure
• Undergrad degree in data science, analytics or related field required.
• Previous experience in data analytics, data science or similar role.
• Machine Learning and Modeling experience preferred
• Experience working with large customer databases
• Experience working with marketing data preferred
The target hiring compensation range for this role is $40 to $45 an hour. Compensation is based on several factors including, but not limited to education, relevant work experience, relevant certifications, and location.",2025-06-30T00:00:00.000Z,2025-07-25,"['Proficient with query languages such as SQL, Python, R', 'Proficient with data visualization tools such as Power BI, Tableau, Data Studio', 'Proficient with data platforms such as Google Analytics, Oracle, Azure', 'Undergrad degree in data science, analytics or related field required', 'Previous experience in data analytics, data science or similar role', 'Experience working with large customer databases']","['The Marketing Data Analytics Consultant will be an integral component of the Market Research Team within the Marketing Department', 'This person will report to the Analytics Sr Specialist whose job it is to work closely with market researchers, brand managers, marketing specialists, and social media managers to collect and analyze data that will be used to assess the impact of marketing activities in market and craft marketing strategies', 'Pull data from various sources (internal, ad agency, Sprinkler, Google Analytics, Questline)', 'Ensure data integrity', 'Mine raw data files and structure data to prepare for input into dashboards', 'Set up API connections with vendor platforms to automate data transfers', 'Work with Analytics Sr', 'Specialist to: set up data pipelines and create new reports leveraging various data sources']",True,[],,"['SQL', 'Python', 'R', 'Data Visualization Tools', 'Data Platforms', 'Data Pipelines', 'Data Integrity', 'Machine Learning', 'Large Customer Databases']","SQL: Used to query and extract data from various data sources to support marketing data analysis and reporting.; Python: Utilized for data manipulation, analysis, and possibly building data pipelines in the marketing analytics context.; R: Employed for statistical analysis and data science tasks related to marketing data.; Data Visualization Tools: Power BI, Tableau, and Data Studio are used to create dashboards and reports that visualize marketing data insights.; Data Platforms: Google Analytics, Oracle, and Azure platforms are leveraged to collect, store, and analyze marketing and customer data.; Data Pipelines: Setting up automated data pipelines and API connections to integrate data from multiple vendor platforms and sources for analysis and reporting.; Data Integrity: Ensuring the accuracy and consistency of marketing data collected from various sources before analysis and reporting.; Machine Learning: Experience preferred for applying predictive modeling and analytical techniques to marketing data.; Large Customer Databases: Experience working with extensive customer data sets to derive marketing insights and support data-driven decision making."
kE8oPxNiUE-RX-IvAAAAAA==,Junior Data Analyst,"Responsibilities Scrutinize and validate revenue data collected from third-party delivery platforms. Ensure accuracy completeness and consistency of financial information. Analyze revenue trends and patterns to identify discrepancies or anomalies. Provide actionable insights to optimize revenue streams and enhance operational efficiency. Generate regular reports detailing revenue metrics and key performance indicators. Work closely with cross-functional teams including finance operations and IT to address data-related challenges and implement improvements. Implement quality assurance measures to guarantee the reliability of data sources.

Qualifications Associate's degree in Data Science Statistics Business Analytics or related field. Proven experience in data analysis preferably in the context of restaurants. Intermediate level of Excel. Strong analytical and problem-solving skills. Excellent communication skills with the ability to convey complex findings to non-technical stakeholders.

Key Skills Statistics. Excel. SQL. Python. Data Visualization. Presentation skills. Problem-solving and critical thinking skills.",,2025-07-25,"[""Qualifications Associate's degree in Data Science Statistics Business Analytics or related field"", 'Proven experience in data analysis preferably in the context of restaurants', 'Intermediate level of Excel', 'Strong analytical and problem-solving skills', 'Excellent communication skills with the ability to convey complex findings to non-technical stakeholders', 'Key Skills Statistics', 'Excel', 'SQL', 'Python', 'Presentation skills', 'Problem-solving and critical thinking skills']","['Responsibilities Scrutinize and validate revenue data collected from third-party delivery platforms', 'Ensure accuracy completeness and consistency of financial information', 'Analyze revenue trends and patterns to identify discrepancies or anomalies', 'Provide actionable insights to optimize revenue streams and enhance operational efficiency', 'Generate regular reports detailing revenue metrics and key performance indicators', 'Work closely with cross-functional teams including finance operations and IT to address data-related challenges and implement improvements', 'Implement quality assurance measures to guarantee the reliability of data sources']",True,[],,"['Data Analysis', 'Data Validation and Quality Assurance', 'SQL', 'Excel', 'Python', 'Statistics', 'Data Visualization', 'Reporting and Dashboarding']","Data Analysis: Analyze revenue trends and patterns to identify discrepancies or anomalies and provide actionable insights to optimize revenue streams and enhance operational efficiency.; Data Validation and Quality Assurance: Scrutinize and validate revenue data collected from third-party delivery platforms and implement quality assurance measures to guarantee the reliability of data sources.; SQL: Use SQL to query and manage data relevant to revenue and financial information.; Excel: Utilize intermediate-level Excel skills for data manipulation, analysis, and reporting.; Python: Apply Python programming for data analysis tasks.; Statistics: Employ statistical methods to analyze revenue data and support data-driven decision making.; Data Visualization: Create visual representations of revenue metrics and key performance indicators to communicate findings effectively.; Reporting and Dashboarding: Generate regular reports detailing revenue metrics and key performance indicators for stakeholders."
hJeVOiPwVMxk7jSZAAAAAA==,Data Analytics Power BI Developer,"Are you passionate about leveraging data to drive business decisions? Do you have experience with Power BI and a strong understanding of data analytics? State Street is seeking a talented Data Analytics Power BI Developer to join our dynamic team. In this role, you will have the opportunity to work with cutting-edge technology and collaborate with cross-functional teams to deliver data-driven solutions. We are looking for a highly motivated individual with a strong technical background and a proven track record of implementing complex BI solutions. If you are a self-starter with a passion for data and a desire to make an impact, we want to hear from you!

Develop and maintain data analytics solutions using Power BI to support business decision-making processes.
Collaborate with cross-functional teams to understand business requirements and design data models and visualizations that meet their needs.
Utilize strong technical skills to build and optimize data pipelines, dashboards, and reports.
Conduct data analysis to identify trends, patterns, and insights to inform business strategies.
Ensure data quality and accuracy by performing regular audits and troubleshooting any issues.
Stay up-to-date with advancements in data analytics, BI tools, and techniques to continuously improve solutions.
Communicate complex data and analytical findings to non-technical stakeholders in a clear and concise manner.
Manage and prioritize multiple projects and deadlines effectively.
Collaborate with team members to identify areas for improvement and implement process enhancements.
Act as a subject matter expert and provide technical support and guidance to team members as needed.
Proactively identify and resolve data-related issues and troubleshoot technical problems.
Continuously monitor and evaluate the performance of BI solutions and make recommendations for optimization.
Adhere to data security and privacy standards to protect sensitive information.
Document and maintain data analytics processes, procedures, and best practices.
Conduct training and knowledge-sharing sessions for colleagues to promote a data-driven culture.

State Street is an Equal Opportunity Employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. We do not discriminate based upon race, religion, color, national origin, sex, sexual orientation, gender identity, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.",,2025-07-25,"['Do you have experience with Power BI and a strong understanding of data analytics?', 'We are looking for a highly motivated individual with a strong technical background and a proven track record of implementing complex BI solutions']","['Develop and maintain data analytics solutions using Power BI to support business decision-making processes', 'Collaborate with cross-functional teams to understand business requirements and design data models and visualizations that meet their needs', 'Utilize strong technical skills to build and optimize data pipelines, dashboards, and reports', 'Conduct data analysis to identify trends, patterns, and insights to inform business strategies', 'Ensure data quality and accuracy by performing regular audits and troubleshooting any issues', 'Stay up-to-date with advancements in data analytics, BI tools, and techniques to continuously improve solutions', 'Communicate complex data and analytical findings to non-technical stakeholders in a clear and concise manner', 'Manage and prioritize multiple projects and deadlines effectively', 'Collaborate with team members to identify areas for improvement and implement process enhancements', 'Act as a subject matter expert and provide technical support and guidance to team members as needed', 'Proactively identify and resolve data-related issues and troubleshoot technical problems', 'Continuously monitor and evaluate the performance of BI solutions and make recommendations for optimization', 'Adhere to data security and privacy standards to protect sensitive information', 'Document and maintain data analytics processes, procedures, and best practices', 'Conduct training and knowledge-sharing sessions for colleagues to promote a data-driven culture']",True,[],,"['Power BI', 'Data Pipelines', 'Data Analysis', 'Business Intelligence (BI) Tools', 'Data Quality and Auditing', 'Data Modeling', 'Data Visualization']","Power BI: Used to develop and maintain data analytics solutions, including dashboards and reports, to support business decision-making processes and visualize data models that meet business requirements.; Data Pipelines: Built and optimized to facilitate the flow and transformation of data for analytics and reporting purposes.; Data Analysis: Conducted to identify trends, patterns, and insights that inform business strategies and support decision-making.; Business Intelligence (BI) Tools: Utilized to create complex BI solutions, including dashboards and reports, and to continuously improve data analytics capabilities.; Data Quality and Auditing: Ensured through regular audits and troubleshooting to maintain accuracy and reliability of data used in analytics solutions.; Data Modeling: Designed to meet business needs by structuring data appropriately for analysis and visualization in BI tools.; Data Visualization: Created to communicate complex data and analytical findings clearly and concisely to non-technical stakeholders."
vf1g4kXS6JowF5X8AAAAAA==,Associate Research/Data Analyst-OEWS,"You will be joining a Department committed to a culture of TEAMWORK to accomplish our goals together, where we deliver excellence through COLLABORATION with partners and stakeholders, embody ACCOUNTABILITY through trust and professionalism, and embrace WORK-LIFE BALANCE by prioritizing respect, boundaries, and time. While working at DHEWD you will be helping to develop the workforce of the future! Join us as we pursue our vision of “Every Missourian empowered with the skills and education needed for success.”

This position works within Missouri’s Occupational Employment and Wage Statistics (OEWS) team, a program administered by the Bureau of Labor Statistics (BLS). OEWS collects data related to the number of workers in Missouri and the wage ranges by occupation. This information is used for analysis of the occupational composition of different industries, for determining national policy related to structural unemployment, and for other purposes such as training and employment planning at state and local levels. As a member of this team, you will be responsible for reaching out to Missouri employers to gather their data. Contacts will be made through phone calls, emails, and mailings. The position allows an opportunity to both work together as a team and to work independently to get assigned tasks completed. Candidates interested in this position should be flexible and able to adjust as the demand and focus on work shifts.

To perform this job successfully, an individual must be able to perform each essential function of the job with or without reasonable accommodation.
• Collect detailed occupational employment and wage information for Missouri employers by conducting a high volume of phone calls, emails, and other collection methods.
• Analyze job classification information by understanding and utilizing the Standard Occupational Classification (SOC) system and industry classification information by using the North American Classification System (NAICS) received from the US Department of Labor, Bureau of Labor Statistics.
• Properly track and enter activity into the data collection software system.
• Analyze returned employer reports for data quality, accuracy, and completeness.
• Develop and maintain working knowledge of staffing patterns, occupational differences, and occupational coding systems, as well as industry classifications, to solicit and properly code survey responses.
• Proficiently use programs used in the OEWS Program, including Word, Excel, and other program specific software.
• Follow guidelines and requirements put forth by the U.S. Bureau of Labor Statistics in the Cooperative Agreement with the State of Missouri.
• Answer questions regarding the program and how the data is used and the importance of it.
• Research employers to find information related to them, including contact information and industry details.
• Other duties related to the collection and coding of data for the OEWS program.
• Perform other related work as assigned.
• Demonstrate regular and reliable attendance.

Beneficial education and/or work-related experience includes technical or professional experience in business, personnel, public administration or closely related area, including military service.

The State of Missouri offers an excellent benefits package that includes a defined pension plan, generous amounts of leave and holiday time, and eligibility for health insurance coverage. Your total compensation is more than the dollars you receive in your paycheck. To help demonstrate the value of working for the State of Missouri, we have created an interactive Total Compensation Calculator. This tool provides a comprehensive view of benefits and more that are offered to prospective employees. The Total Compensation Calculator and other applicant resources can be found here .

The State of Missouri is an equal opportunity employer.

DHEWDHR@dhewd.mo.gov",,2025-07-25,"['Candidates interested in this position should be flexible and able to adjust as the demand and focus on work shifts', 'To perform this job successfully, an individual must be able to perform each essential function of the job with or without reasonable accommodation', 'Proficiently use programs used in the OEWS Program, including Word, Excel, and other program specific software', 'Follow guidelines and requirements put forth by the U.S. Bureau of Labor Statistics in the Cooperative Agreement with the State of Missouri', 'Beneficial education and/or work-related experience includes technical or professional experience in business, personnel, public administration or closely related area, including military service']","['This information is used for analysis of the occupational composition of different industries, for determining national policy related to structural unemployment, and for other purposes such as training and employment planning at state and local levels', 'As a member of this team, you will be responsible for reaching out to Missouri employers to gather their data', 'Contacts will be made through phone calls, emails, and mailings', 'The position allows an opportunity to both work together as a team and to work independently to get assigned tasks completed', 'Collect detailed occupational employment and wage information for Missouri employers by conducting a high volume of phone calls, emails, and other collection methods', 'Analyze job classification information by understanding and utilizing the Standard Occupational Classification (SOC) system and industry classification information by using the North American Classification System (NAICS) received from the US Department of Labor, Bureau of Labor Statistics', 'Properly track and enter activity into the data collection software system', 'Analyze returned employer reports for data quality, accuracy, and completeness', 'Develop and maintain working knowledge of staffing patterns, occupational differences, and occupational coding systems, as well as industry classifications, to solicit and properly code survey responses', 'Answer questions regarding the program and how the data is used and the importance of it', 'Research employers to find information related to them, including contact information and industry details', 'Other duties related to the collection and coding of data for the OEWS program', 'Perform other related work as assigned', 'Demonstrate regular and reliable attendance']",False,,,,
CUnGbokAezvJeakTAAAAAA==,Cloud Data & Analytics Implementation Senior Associate (Insurance),"Industry/Sector
Insurance

Specialism
Data, Analytics & AI

Management Level
Senior Associate

Job Description & Summary
A career within Data and Analytics services will provide you with the opportunity to help organisations uncover enterprise insights and drive business results using smarter data analytics. We focus on a collection of organisational technology capabilities, including business intelligence, data management, and data assurance that help our clients drive innovation, growth, and change within their organisations in order to keep up with the changing nature of customers and technology. We make impactful decisions by mixing mind and machine to leverage data, understand and navigate risk, and help our clients gain a competitive edge.

You'll focus on aligning client data strategies to their business strategy. You will assist clients in choosing a platform, defining their data needs and migrating them to a modern cloud data environment using cloud providers such as Azure, Google Cloud Platform, Amazon Web Services, Snowflake, Databricks or Teradata.

To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.

As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:
• Use feedback and reflection to develop self awareness, personal strengths and address development areas.
• Delegate to others to provide stretch opportunities, coaching them to deliver results.
• Demonstrate critical thinking and the ability to bring order to unstructured problems.
• Use a broad range of tools and techniques to extract insights from current industry or sector trends.
• Review your work and that of others for quality, accuracy and relevance.
• Know how and when to use tools available for a given situation and can explain the reasons for this choice.
• Seek and embrace opportunities which give exposure to different situations, environments and perspectives.
• Use straightforward communication, in a structured way, when influencing and connecting with others.
• Able to read situations and modify behavior to build quality relationships.
• Uphold the firm's code of ethics and business conduct.

Job Requirements and Preferences:

Basic Qualifications:

Minimum Degree Required:
Bachelor Degree

Minimum Years of Experience:
4 year(s)

Preferred Qualifications:

Certification(s) Preferred:
• Certification in one of the following cloud platform - AWS/Azure/GCP
• Certification in Snowflake
• Certification in any ETL/ELT tool

Preferred Knowledge/Skills:

Demonstrates thorough knowledge and success as both team leader and member roles within a professional services firm or large enterprise.
• Understanding and experience with modern cloud data architectures and engineering for one or more of the following cloud providers - AWS, Azure, GCP;
• Implementing cloud data architecture and data integration patterns for one or more of the cloud providers (AWS Glue, Azure Data Factory, Event Hub, Databricks,Snowflake etc.), storage and processing (Redshift, Azure Synapse, BigQuery, Snowflake); Infrastructure as code (CloudFormation, Terraform);
• Understanding and thorough knowledge of Data Warehousing concepts (normalization, OLAP, OLTP, Vault data model, graphs, star & snowflake schemas);
• Applying knowledge and relevant work experience in Big data engineering (Hadoop, Spark, Scala, Kafka) and ETL pipeline development tools (tools: IICS/AWS Glue/Matillion/Abinitio SSIS/SnapLogic); preferable in P&C/L&A Insurance data warehouse;
• Developing file and object-based storage solutions using Azure ADLS 2.0 or AWS S3;
• Applying knowledge in SQL, report generation using visualization tools such as Tableau/Power BI/Cognos
• Programming using Python/Spark
• Understanding of enterprise data concepts such as Master Data Management Data Governance and Enterprise Data Warehouse;
• Support cross-functional teams to understand their workflow and automation needs.
• Design and develop scalable data warehouse solutions that meet the organization's data storage, retrieval, and analysis requirements.
• Understanding and familiarity of one or more is a big plus - CI/CD, cloud devops, containers (kubernetes/Docker, etc.);
• Understanding of insurance data, underlying KPIs and how they are used; and,
• Demonstrating prior P&C/L&A Insurance industry experience.

Demonstrates thorough abilities success with managing the identification and addressing of client needs:
• Applying modern, cloud-based technology skills, ability to research emerging trends, analyst publications, and adoption of modern technologies in solution architectures;
• Contributing as a team member by understanding personal and team roles, contributing to a positive working environment by building proven relationships with team members, proactively seeking guidance, clarification and feedback;and,
• Prioritizing and handling multiple tasks, researching and analyzing pertinent client, industry and technical matters, utilizing problem-solving skills, and communicating effectively in written and verbal formats to various audiences (including various levels of management and external clients) in a professional business environment.

Travel Requirements
Up to 80%

Job Posting End Date

Learn more about how we work: https://pwc.to/how-we-work

PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.

As PwC is anequal opportunity employer, all qualified applicants will receive consideration for employment at PwC without regard to race; color; religion; national origin; sex (including pregnancy, sexual orientation, and gender identity); age; disability; genetic information (including family medical history); veteran, marital, or citizenship status; or, any other status protected by law.

For only those qualified applicants that are impacted by the Los Angeles County Fair Chance Ordinance for Employers, the Los Angeles' Fair Chance Initiative for Hiring Ordinance, the San Francisco Fair Chance Ordinance, San Diego County Fair Chance Ordinance, and the California Fair Chance Act, where applicable, arrest or conviction records will be considered for Employment in accordance with these laws. At PwC, we recognize that conviction records may have a direct, adverse, and negative relationship to responsibilities such as accessing sensitive company or customer information, handling proprietary assets, or collaborating closely with team members. We evaluate these factors thoughtfully to establish a secure and trusted workplace for all.

Applications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https://pwc.to/us-application-deadlines

The salary range for this position is: $77,000 - $202,000, plus individuals may be eligible for an annual discretionary bonus. For roles that are based in Maryland, this is the listed salary range for this position. Actual compensation within the range will be dependent upon the individual's skills, experience, qualifications and location, and applicable employment laws. PwC offers a wide range of benefits, including medical, dental, vision, 401k, holiday pay, vacation, personal and family sick leave, and more. To view our benefits at a glance, please visit the following link: https://pwc.to/benefits-at-a-glance",2025-07-16T00:00:00.000Z,2025-07-25,"['Bachelor Degree', '4 year(s)', 'Demonstrates thorough knowledge and success as both team leader and member roles within a professional services firm or large enterprise', 'Understanding and experience with modern cloud data architectures and engineering for one or more of the following cloud providers - AWS, Azure, GCP;', 'Implementing cloud data architecture and data integration patterns for one or more of the cloud providers (AWS Glue, Azure Data Factory, Event Hub, Databricks,Snowflake etc.), storage and processing (Redshift, Azure Synapse, BigQuery, Snowflake); Infrastructure as code (CloudFormation, Terraform);', 'Understanding and thorough knowledge of Data Warehousing concepts (normalization, OLAP, OLTP, Vault data model, graphs, star & snowflake schemas);', 'Applying knowledge and relevant work experience in Big data engineering (Hadoop, Spark, Scala, Kafka) and ETL pipeline development tools (tools: IICS/AWS Glue/Matillion/Abinitio SSIS/SnapLogic); preferable in P&C/L&A Insurance data warehouse;', 'Developing file and object-based storage solutions using Azure ADLS 2.0 or AWS S3;', 'Applying knowledge in SQL, report generation using visualization tools such as Tableau/Power BI/Cognos', 'Programming using Python/Spark', 'Understanding of enterprise data concepts such as Master Data Management Data Governance and Enterprise Data Warehouse;', 'Understanding and familiarity of one or more is a big plus - CI/CD, cloud devops, containers (kubernetes/Docker, etc.);', 'Demonstrating prior P&C/L&A Insurance industry experience', 'Demonstrates thorough abilities success with managing the identification and addressing of client needs:', 'Applying modern, cloud-based technology skills, ability to research emerging trends, analyst publications, and adoption of modern technologies in solution architectures;', 'Contributing as a team member by understanding personal and team roles, contributing to a positive working environment by building proven relationships with team members, proactively seeking guidance, clarification and feedback;and,', 'Prioritizing and handling multiple tasks, researching and analyzing pertinent client, industry and technical matters, utilizing problem-solving skills, and communicating effectively in written and verbal formats to various audiences (including various levels of management and external clients) in a professional business environment']","['We make impactful decisions by mixing mind and machine to leverage data, understand and navigate risk, and help our clients gain a competitive edge', ""You'll focus on aligning client data strategies to their business strategy"", 'You will assist clients in choosing a platform, defining their data needs and migrating them to a modern cloud data environment using cloud providers such as Azure, Google Cloud Platform, Amazon Web Services, Snowflake, Databricks or Teradata', ""As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution"", 'PwC Professional skills and responsibilities for this management level include but are not limited to:', 'Use feedback and reflection to develop self awareness, personal strengths and address development areas', 'Delegate to others to provide stretch opportunities, coaching them to deliver results', 'Demonstrate critical thinking and the ability to bring order to unstructured problems', 'Use a broad range of tools and techniques to extract insights from current industry or sector trends', 'Review your work and that of others for quality, accuracy and relevance', 'Know how and when to use tools available for a given situation and can explain the reasons for this choice', 'Seek and embrace opportunities which give exposure to different situations, environments and perspectives', 'Use straightforward communication, in a structured way, when influencing and connecting with others', 'Able to read situations and modify behavior to build quality relationships', ""Uphold the firm's code of ethics and business conduct"", 'Support cross-functional teams to understand their workflow and automation needs', ""Design and develop scalable data warehouse solutions that meet the organization's data storage, retrieval, and analysis requirements"", 'Understanding of insurance data, underlying KPIs and how they are used; and,']",True,[],,"['Cloud Data Architecture', 'Data Integration Patterns', 'Infrastructure as Code', 'Data Warehousing Concepts', 'Big Data Engineering', 'ETL Pipeline Development', 'File and Object Storage Solutions', 'SQL and Data Visualization', 'Programming with Python and Spark', 'Enterprise Data Concepts', 'CI/CD and Cloud DevOps', 'Insurance Data and KPIs']","Cloud Data Architecture: Implementing and migrating client data strategies to modern cloud data environments using cloud providers such as AWS, Azure, Google Cloud Platform, Snowflake, Databricks, and Teradata.; Data Integration Patterns: Applying cloud data integration patterns using tools like AWS Glue, Azure Data Factory, Event Hub, Databricks, and Snowflake to support data migration and processing.; Infrastructure as Code: Using tools such as CloudFormation and Terraform to manage cloud infrastructure deployments as part of data architecture implementation.; Data Warehousing Concepts: Applying knowledge of data warehousing including normalization, OLAP, OLTP, Vault data model, graph databases, star and snowflake schemas to design scalable data warehouse solutions.; Big Data Engineering: Utilizing big data technologies such as Hadoop, Spark, Scala, and Kafka for data processing and engineering, particularly in insurance data warehouse contexts.; ETL Pipeline Development: Developing ETL pipelines using tools like IICS, AWS Glue, Matillion, Abinitio, SSIS, and SnapLogic to support data ingestion and transformation.; File and Object Storage Solutions: Developing storage solutions using Azure ADLS 2.0 and AWS S3 for scalable data storage in cloud environments.; SQL and Data Visualization: Applying SQL for data querying and generating reports using visualization tools such as Tableau, Power BI, and Cognos to extract insights and support decision-making.; Programming with Python and Spark: Using Python and Spark programming for data processing, analytics, and pipeline development within cloud data environments.; Enterprise Data Concepts: Understanding and applying enterprise data management principles including Master Data Management, Data Governance, and Enterprise Data Warehouse design.; CI/CD and Cloud DevOps: Familiarity with continuous integration/continuous deployment practices and cloud DevOps tools including containerization technologies like Kubernetes and Docker to support data platform automation and scalability.; Insurance Data and KPIs: Applying domain knowledge of insurance data, key performance indicators, and their usage to tailor data solutions for P&C and L&A insurance sectors."
lVstnHrIi1w40Nb-AAAAAA==,Actuarial Support Analyst III (Entry Level),"About the position

At USAA, we have an important mission: facilitating the financial security of millions of U.S. military members and their families. We are seeking a dedicated Actuarial Support Analyst III (Entry Level) to support actuarial and loss reserving work through various activities such as data manipulation, validation, and analysis. This position requires an individual to be in the office 4 days per week and can be based in several locations including Phoenix, AZ; San Antonio, TX; Plano, TX; Chesapeake, VA; Charlotte, NC; Colorado Springs, CO or Tampa, FL. Relocation assistance is not available for this position.

Responsibilities
• Supports actuarial and loss reserving work through data manipulation, validation, and analysis.
,
• Performs research and prepares and validates reports to support actuarial staff.
,
• Compiles data and provides technical and analytical support for studies, projects, or reviews.
,
• Seeks guidance from team members to resolve issues and to identify appropriate issues for escalation.

Requirements
• Bachelor's degree (4 additional years of related experience beyond the minimum required may be substituted in lieu of a Degree)
,
• Up to 2 years relevant business and/or general analysis experience
,
• Foundational knowledge of Microsoft Office tools including Word, Excel, PowerPoint, and Access
,
• Foundational knowledge of relevant data analysis tools; Basic knowledge of relevant data extraction tools.

Nice-to-haves
• Prior property insurance product or pricing experience
,
• Strong problem-solving, innovation, and process improvement skills
,
• Advanced level knowledge of Microsoft Excel
,
• Work experience with data analytics
,
• Work experience with Python, SQL, or other programming language
,
• Work experience with Earnix
,
• US military experience through military service or a military spouse/domestic partner

Benefits
• Comprehensive medical, dental and vision plans
,
• 401(k)
,
• Pension
,
• Life insurance
,
• Parental benefits
,
• Adoption assistance
,
• Paid time off program with paid holidays plus 16 paid volunteer hours
,
• Various wellness programs
,
• Career path planning and continuing education assistance",,2025-07-25,"['This position requires an individual to be in the office 4 days per week and can be based in several locations including Phoenix, AZ; San Antonio, TX; Plano, TX; Chesapeake, VA; Charlotte, NC; Colorado Springs, CO or Tampa, FL', ""Bachelor's degree (4 additional years of related experience beyond the minimum required may be substituted in lieu of a Degree)"", 'Up to 2 years relevant business and/or general analysis experience', 'Foundational knowledge of Microsoft Office tools including Word, Excel, PowerPoint, and Access', 'Foundational knowledge of relevant data analysis tools; Basic knowledge of relevant data extraction tools', 'Prior property insurance product or pricing experience', 'Strong problem-solving, innovation, and process improvement skills', 'Advanced level knowledge of Microsoft Excel', 'Work experience with data analytics', 'Work experience with Python, SQL, or other programming language', 'Work experience with Earnix', 'US military experience through military service or a military spouse/domestic partner']","['We are seeking a dedicated Actuarial Support Analyst III (Entry Level) to support actuarial and loss reserving work through various activities such as data manipulation, validation, and analysis', 'Supports actuarial and loss reserving work through data manipulation, validation, and analysis', 'Performs research and prepares and validates reports to support actuarial staff', 'Compiles data and provides technical and analytical support for studies, projects, or reviews', 'Seeks guidance from team members to resolve issues and to identify appropriate issues for escalation']",False,,,,
h3gffiseL3cHej7oAAAAAA==,"Senior Analyst, Revenue Data Analytics","Join Axon and be a Force for Good.

At Axon, we're on a mission to Protect Life. We're explorers, pursuing society's most critical safety and justice issues with our ecosystem of devices and cloud software. Like our products, we work better together. We connect with candor and care, seeking out diverse perspectives from our customers, communities and each other.

Life at Axon is fast-paced, challenging and meaningful. Here, you'll take ownership and drive real change. Constantly grow as you work hard for a mission that matters at a company where you matter.

Your Impact

As a Senior Analyst, Revenue Data Analytics at Axon and a member of the Revenue Transformation team you will support the Revenue Accounting org in advancing their reporting and analytics maturity by building scalable reporting solutions, enhancing data governance, and ensuring analytical insights are effectively used in strategic decision-making. You will partner cross-functionally with Accounting, Finance, Data Engineering, IT, and Business Intelligence teams to drive reporting excellence and elevate Axon's revenue analytics capabilities. You will be expected to own key datasets, develop insightful reports and dashboards, and collaborate with stakeholders to define analytical needs and implement effective solutions tailored to the business's specifications. Your work will fuel operational improvements, data-driven decisions, and help scale a high-performing finance and accounting ecosystem.

What You'll Do
Location: Hybrid at a US Hub Location (Scottsdale, Seattle, San Francisco, Denver, Sterling, Washington DC, Atlanta, Boston)
Reports to: Sr, Director Revenue Transformation
Direct Reports: 0
• Revenue Analytics Development: Design, build, and maintain robust, user-friendly dashboards and reports to support revenue and accounting teams. Ensure outputs are actionable, scalable, and aligned with strategic goals.
• Data Governance: Partner with business stakeholders to implement and uphold data governance standards across key revenue data assets, contributing to data accuracy and consistency.
• Data Integration & Collaboration: Work closely with Data Engineering to define data pipelines, ensure seamless integration between source systems (Microsoft Dynamics 365, RevStream, Salesforce), and optimize end-to-end data workflows.
• Process Optimization: Support transformation initiatives by identifying bottlenecks, proposing enhancements, and contributing to continuous improvement efforts in revenue-related processes.
• Business Partnership: Serve as a strategic partner to revenue, finance, and accounting leaders by translating business questions into analytical problems and delivering impactful insights.
• Ad Hoc Reporting & Analysis: Execute timely and accurate reporting for ad hoc needs, internal audits, and executive reviews.
• Technology Enablement: Contribute to the advancement of analytics platforms and tools by supporting adoption of solutions such as Power BI, DBT, and Snowflake.
• Documentation & Testing: Maintain documentation for analytics solutions and ensure rigorous testing standards to preserve data integrity.
What You Bring
• Bachelor's degree in Accounting, Finance, Computer Science, Information Systems, or a related field
• 5+ years of experience in FP&A, data analytics or a similar analytical role, preferably supporting revenue, accounting, or finance teams
• Proficiency in SQL with demonstrated ability to write complex queries across large datasets. Python is a strong plus.
• Hands-on experience with Power BI and/or other dashboarding tools (e.g., Tableau, Looker, Sigma Computing)
• Exposure to enterprise data warehouses (Snowflake preferred), cloud ecosystems, and modern ELT tools (DBT)
• Understanding of ERP and CRM systems, particularly Microsoft Dynamics 365, RevStream, and Salesforce
• Familiarity with data pipeline integration and cross-functional system connectivity
• Demonstrated ability to work autonomously in a fast-paced, agile environment
• Strong communication skills and high contextual business acumen
• Ability to pull business requirements from SMEs and translate to technical requirements
• Passion for data quality, governance, and scalable design
• Python experience a strong plus
Benefits that Benefit You
• Competitive salary and 401k with employer match
• Discretionary paid time off
• Paid parental leave for all
• Medical, Dental, Vision plans
• Fitness Programs
• Emotional & Mental Wellness support
• Learning & Development programs
• And yes, we have snacks in our offices

Benefits listed herein may vary depending on the nature of your employment and the location where you work.

The Pay: Axon is a total compensation company, meaning compensation is made up of base pay, bonus, and stock awards. The starting base pay for this role is between USD 74,550 in the lowest geographic market and USD 119,280 in the highest geographic market. The actual base pay is dependent upon many factors, such as: level, function, training, transferable skills, work experience, business needs, geographic market, and often a combination of all these factors. Our benefits offer an array of options to help support you physically, financially and emotionally through the big milestones and in your everyday life. To see more details on our benefits offerings please visit www.axon.com/careers/benefits.

Don't meet every single requirement? That's ok. At Axon, we Aim Far. We think big with a long-term view because we want to reinvent the world to be a safer, better place. We are also committed to building diverse teams that reflect the communities we serve.

Studies have shown that women and people of color are less likely to apply to jobs unless they check every box in the job description. If you're excited about this role and our mission to Protect Life but your experience doesn't align perfectly with every qualification listed here, we encourage you to apply anyways. You may be just the right candidate for this or other roles.

Important Notes

The above job description is not intended as, nor should it be construed as, exhaustive of all duties, responsibilities, skills, efforts, or working conditions associated with this job. The job description may change or be supplemented at any time in accordance with business needs and conditions.

Some roles may also require legal eligibility to work in a firearms environment.

Axon's mission is to Protect Life and is committed to the well-being and safety of its employees as well as Axon's impact on the environment. All Axon employees must be aware of and committed to the appropriate environmental, health, and safety regulations, policies, and procedures. Axon employees are empowered to report safety concerns as they arise and activities potentially impacting the environment.

We are an equal opportunity employer that promotes justice, advances equity, values diversity and fosters inclusion. We're committed to hiring the best talent - regardless of race, creed, color, ancestry, religion, sex (including pregnancy), national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, genetic information, veteran status, or any other characteristic protected by applicable laws, regulations and ordinances - and empowering all of our employees so they can do their best work. If you have a disability or special need that requires assistance or accommodation during the application or the recruiting process, please email recruitingops@axon.com. Please note that this email address is for accommodation purposes only. Axon will not respond to inquiries for other purposes.#J-18808-Ljbffr",2025-07-22T00:00:00.000Z,2025-07-25,"[""Bachelor's degree in Accounting, Finance, Computer Science, Information Systems, or a related field"", '5+ years of experience in FP&A, data analytics or a similar analytical role, preferably supporting revenue, accounting, or finance teams', 'Proficiency in SQL with demonstrated ability to write complex queries across large datasets', 'Python is a strong plus', 'Hands-on experience with Power BI and/or other dashboarding tools (e.g., Tableau, Looker, Sigma Computing)', 'Understanding of ERP and CRM systems, particularly Microsoft Dynamics 365, RevStream, and Salesforce', 'Familiarity with data pipeline integration and cross-functional system connectivity', 'Demonstrated ability to work autonomously in a fast-paced, agile environment', 'Strong communication skills and high contextual business acumen', 'Ability to pull business requirements from SMEs and translate to technical requirements', 'Passion for data quality, governance, and scalable design', 'Python experience a strong plus', 'Some roles may also require legal eligibility to work in a firearms environment']","['As a Senior Analyst, Revenue Data Analytics at Axon and a member of the Revenue Transformation team you will support the Revenue Accounting org in advancing their reporting and analytics maturity by building scalable reporting solutions, enhancing data governance, and ensuring analytical insights are effectively used in strategic decision-making', ""You will partner cross-functionally with Accounting, Finance, Data Engineering, IT, and Business Intelligence teams to drive reporting excellence and elevate Axon's revenue analytics capabilities"", ""You will be expected to own key datasets, develop insightful reports and dashboards, and collaborate with stakeholders to define analytical needs and implement effective solutions tailored to the business's specifications"", 'Your work will fuel operational improvements, data-driven decisions, and help scale a high-performing finance and accounting ecosystem', 'Location: Hybrid at a US Hub Location (Scottsdale, Seattle, San Francisco, Denver, Sterling, Washington DC, Atlanta, Boston)', 'Reports to: Sr, Director Revenue Transformation', 'Revenue Analytics Development: Design, build, and maintain robust, user-friendly dashboards and reports to support revenue and accounting teams', 'Ensure outputs are actionable, scalable, and aligned with strategic goals', 'Data Governance: Partner with business stakeholders to implement and uphold data governance standards across key revenue data assets, contributing to data accuracy and consistency', 'Data Integration & Collaboration: Work closely with Data Engineering to define data pipelines, ensure seamless integration between source systems (Microsoft Dynamics 365, RevStream, Salesforce), and optimize end-to-end data workflows', 'Process Optimization: Support transformation initiatives by identifying bottlenecks, proposing enhancements, and contributing to continuous improvement efforts in revenue-related processes', 'Business Partnership: Serve as a strategic partner to revenue, finance, and accounting leaders by translating business questions into analytical problems and delivering impactful insights', 'Ad Hoc Reporting & Analysis: Execute timely and accurate reporting for ad hoc needs, internal audits, and executive reviews', 'Technology Enablement: Contribute to the advancement of analytics platforms and tools by supporting adoption of solutions such as Power BI, DBT, and Snowflake', 'Documentation & Testing: Maintain documentation for analytics solutions and ensure rigorous testing standards to preserve data integrity']",True,[],,"['SQL', 'Python', 'Power BI', 'Tableau', 'Looker', 'Sigma Computing', 'Snowflake', 'DBT (Data Build Tool)', 'Data Governance', 'Data Pipelines', 'ERP and CRM Systems', 'Dashboards and Reporting', 'Ad Hoc Reporting and Analysis', 'Process Optimization', 'Business Intelligence (BI) Tools']","SQL: Used to write complex queries across large datasets to support revenue and accounting analytics and reporting.; Python: Utilized as a programming language to enhance data analytics capabilities, considered a strong plus for the role.; Power BI: Employed to design, build, and maintain user-friendly dashboards and reports that support revenue and accounting teams.; Tableau: Mentioned as an alternative dashboarding tool for creating visual analytics and reports.; Looker: Listed as another dashboarding tool option for developing business intelligence reports and visualizations.; Sigma Computing: Included as a dashboarding tool to support data visualization and reporting needs.; Snowflake: Used as an enterprise data warehouse platform to support cloud-based data storage and analytics.; DBT (Data Build Tool): Applied as a modern ELT tool to support data transformation and pipeline development in analytics workflows.; Data Governance: Implemented to uphold standards across key revenue data assets, ensuring data accuracy, consistency, and quality.; Data Pipelines: Defined and optimized in collaboration with Data Engineering to ensure seamless integration between source systems and efficient end-to-end data workflows.; ERP and CRM Systems: Understanding and integration of systems such as Microsoft Dynamics 365, RevStream, and Salesforce to support revenue data analytics and reporting.; Dashboards and Reporting: Developed and maintained to provide actionable, scalable insights aligned with strategic goals for revenue and accounting teams.; Ad Hoc Reporting and Analysis: Performed to deliver timely and accurate reports for internal audits, executive reviews, and specific business needs.; Process Optimization: Engaged in identifying bottlenecks and proposing enhancements to improve revenue-related processes and analytics maturity.; Business Intelligence (BI) Tools: Utilized to advance analytics platforms and support data-driven decision-making within the revenue and finance functions."
VDurN2eyRv7WzJG2AAAAAA==,Data Analyst Co-op,This job listing in Suffolk - MA has been recently added. Tallo will add a summary here for this job shortly.,,2025-07-25,,,False,,,,
6ORuhMAMyhhWFGJ3AAAAAA==,Associate Data Analyst - Temp,"Are you passionate about data integrity and analysis? Join our dynamic team and help shape the future of reporting!

At FedPoint, we are looking for a Data Integrity Specialist to play a key role in maintaining accurate, insightful, and timely data reporting for our diverse range of stakeholders. This is an exciting opportunity to make an impact through your analytical skills and contribute to our business success.

About The Role

As a Data Integrity Specialist, you’ll be responsible for managing data collection processes and maintaining the accuracy of key performance metrics. You will work closely with business owners to resolve discrepancies, create reporting templates, perform trend analysis, and provide valuable insights that will guide decision-making at all levels of the organization.

You Will
• Administer data collection for recurring metrics and resolve any discrepancies with business owners.
• Create and update reporting templates, ensuring accuracy and consistency.
• Perform quality assurance checks to ensure data integrity and conduct trend analysis to identify insights.
• Draft business requirements and recommend improvements for data gathering and reporting processes.

Key Responsibilities:

Data integrity projects for reporting and metrics as assigned.

What We’re Looking For

Education and Experience:
• High school diploma or equivalent required; college or certificate course work in accounting, business, or related field preferred.
• 1+ years’ experience handling performance measurements such as Key Performance Indicators (KPI’s), and or other quality assurance measurements and calculations, including performing quality control audits and peer review.
• 1+ years’ experience performing data analysis, using data visualization to convey findings; experience narrating findings a plus.
• Exposure to gathering and writing business requirements preferred.
• Experience documenting procedures.
• Experience working in a project planning environment a plus; demonstrated ability to work toward specific milestones and meet deliverables.

Location: Portsmouth, NH - Hybrid Role

Schedule: Hybrid 2 days in the office, 3 days telework - Monday-Friday

Compensation: The typical starting salary would be between $23-$25/hr, based on qualifications and experience as it relates to our requirements. This position is eligible for an annual discretionary employee bonus plan based on company metric performance as well as a full suite of benefits, listed below.

About FedPoint

FedPoint creates and operates digital benefits marketplaces that make it easy for our millions of federal and military customers to understand, select, and use their benefits. A subsidiary of John Hancock Life & Health Insurance Company, FedPoint was founded in 2002 and is headquartered in Portsmouth, NH. To learn more, visit fedpointusa.com.

Why Join Us?",,2025-07-25,"['1+ years’ experience handling performance measurements such as Key Performance Indicators (KPI’s), and or other quality assurance measurements and calculations, including performing quality control audits and peer review', 'Experience documenting procedures']","['Join our dynamic team and help shape the future of reporting!', 'At FedPoint, we are looking for a Data Integrity Specialist to play a key role in maintaining accurate, insightful, and timely data reporting for our diverse range of stakeholders', 'As a Data Integrity Specialist, you’ll be responsible for managing data collection processes and maintaining the accuracy of key performance metrics', 'You will work closely with business owners to resolve discrepancies, create reporting templates, perform trend analysis, and provide valuable insights that will guide decision-making at all levels of the organization', 'Administer data collection for recurring metrics and resolve any discrepancies with business owners', 'Create and update reporting templates, ensuring accuracy and consistency', 'Perform quality assurance checks to ensure data integrity and conduct trend analysis to identify insights', 'Draft business requirements and recommend improvements for data gathering and reporting processes', 'Data integrity projects for reporting and metrics as assigned']",True,[],,"['Key Performance Indicators (KPIs)', 'Data Collection Processes', 'Data Integrity', 'Trend Analysis', 'Reporting Templates', 'Quality Assurance Audits', 'Business Requirements Documentation', 'Data Visualization']","Key Performance Indicators (KPIs): Used to measure and monitor performance metrics critical to business success, requiring management and accuracy maintenance.; Data Collection Processes: Managing the gathering of data for recurring metrics and ensuring completeness and correctness.; Data Integrity: Ensuring accuracy, consistency, and quality of data through quality assurance checks and resolving discrepancies.; Trend Analysis: Analyzing data trends to identify insights that inform decision-making across organizational levels.; Reporting Templates: Creating and updating standardized templates to ensure consistent and accurate data reporting.; Quality Assurance Audits: Performing quality control audits and peer reviews to maintain data accuracy and reliability.; Business Requirements Documentation: Drafting and documenting business requirements to improve data gathering and reporting processes.; Data Visualization: Using visualization techniques to convey analytical findings effectively to stakeholders."
WpAHQdHE1-8aYJgAAAAAAA==,SENIOR HEALTH ECONOMICS ANALYST,"Senior Health Economics Analyst

Location: Remote

Supervisor/Reporting to: Director, Performance Reliability

Job Purpose: The Senior Health Economics Analyst is responsible for identifying and delivering data-driven insights and analytical support to senior leadership of IVIRMA North America. Success in the role will be achieved through the ability to leverage both qualitative and quantitative data to create business intelligence to guide strategic execution. This role serves to create and deliver reliable, insightful and actionable insight to improvements and opportunities for performance reliability – supporting our teammates in delivering a world-class patient experience.

Essential Functions and Accountabilities:
• Supports the design, development, and implementation of reporting to support data-driven decision making and insight. Partners with finance, commercial and business leaders to translate needs and requirements into dashboards and reporting with high utility.
• Assists in the design and evaluation of organizational KPIs for potential replacement or evolution as the organization grows.
• Prepares and analyzes medical cost and leading indicator data to develop presentations for executive and senior leadership. Interpret results and articulate actionable recommendations that maximize outcomes and ensures organizational targets are met.
• Tracks performance of key performance indicators for outlined regions and teams as requested.
• Supports finance, commercial and operations in the annual and multi-year planning processes including market durability
• Performs data validation to ensure completeness and accuracy of queries and reports and reconciles discrepancies.
• Participates in the maintenance of existing queries and reports, re-writing and enhancing these queries as needed.
• Participates in the presentation of complex concepts and results to end users and stakeholders

Academic Training:
• Bachelor’s degree in Computer Science, Information Services, or other technical or healthcare field – highly preferred
• Studies level: University Education (Bachelor’s Degree)
• Studies area: Computer Science/Engineering or other related field

Position Requirements/Experience:
• Experience working in medical/healthcare industry - preferred
• Knowledge of data collection, storage, and maintenance concepts - required
• Knowledge in predictive modeling - a plus
• Database organization, design, and maintenance skills.
• Ability to troubleshoot database programs

Technical Skills:
• Knowledge of PowerBI - required
• Knowledge of Microsoft Office Suite: Word, Excel (Pivot Tables/Look-Ups), Access, and OneNote – required
• Knowledge of Tableau - preferred

IVI-RMA offers a comprehensive benefits package to all employees who work a minimum of 30 hours per week.
• Medical, Dental, Vision Insurance Options
• Retirement 401K Plan
• Paid Time Off & Paid Holidays
• Company Paid: Life Insurance & Long-Term Disability & AD&D
• Flexible Spending Accounts
• Employee Assistance Program
• Tuition Reimbursement

About IVIRMA Global:

IVIRMA is the largest group in the world devoted exclusively to human Assisted Reproduction Technology. Along with the great privilege of providing fertility care to our patients, IVIRMA embraces the great responsibility of advancing the field of human reproduction. IVIRMA Innovation, as one of the pillars of IVIRMA Global, is a renowned leader in fertility research and science. Check out our websites at: https://rmanetwork.com/ & https://www.ivirma.com/

EEO

“IVIRMA is an Equal Opportunity Employer and Prohibits Discrimination and Harassment of Any Kind: IVIRMA is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at IVIRMA are based on business needs, job requirements and individual qualifications, without regard to race, color, religion and/or belief, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. IVIRMA will not tolerate discrimination or harassment based on any of these characteristics. IVIRMA encourages applicants of all ages.”",2025-07-03T00:00:00.000Z,2025-07-25,"['Studies level: University Education (Bachelor’s Degree)', 'Studies area: Computer Science/Engineering or other related field', 'Knowledge of data collection, storage, and maintenance concepts - required', 'Database organization, design, and maintenance skills', 'Ability to troubleshoot database programs', 'Knowledge of PowerBI - required', 'Knowledge of Microsoft Office Suite: Word, Excel (Pivot Tables/Look-Ups), Access, and OneNote – required']","['Supervisor/Reporting to: Director, Performance Reliability', 'Job Purpose: The Senior Health Economics Analyst is responsible for identifying and delivering data-driven insights and analytical support to senior leadership of IVIRMA North America', 'Success in the role will be achieved through the ability to leverage both qualitative and quantitative data to create business intelligence to guide strategic execution', 'This role serves to create and deliver reliable, insightful and actionable insight to improvements and opportunities for performance reliability – supporting our teammates in delivering a world-class patient experience', 'Supports the design, development, and implementation of reporting to support data-driven decision making and insight', 'Partners with finance, commercial and business leaders to translate needs and requirements into dashboards and reporting with high utility', 'Assists in the design and evaluation of organizational KPIs for potential replacement or evolution as the organization grows', 'Prepares and analyzes medical cost and leading indicator data to develop presentations for executive and senior leadership', 'Interpret results and articulate actionable recommendations that maximize outcomes and ensures organizational targets are met', 'Tracks performance of key performance indicators for outlined regions and teams as requested', 'Supports finance, commercial and operations in the annual and multi-year planning processes including market durability', 'Performs data validation to ensure completeness and accuracy of queries and reports and reconciles discrepancies', 'Participates in the maintenance of existing queries and reports, re-writing and enhancing these queries as needed', 'Participates in the presentation of complex concepts and results to end users and stakeholders']",True,[],,"['Business Intelligence', 'Data-Driven Decision Making', 'Key Performance Indicators (KPIs)', 'Data Validation', 'Data Reporting and Dashboards', 'Medical Cost and Leading Indicator Data Analysis', 'Database Organization and Maintenance', 'Power BI', 'Tableau', 'Microsoft Excel (Pivot Tables, Look-Ups)']","Business Intelligence: Used to create data-driven insights and guide strategic execution for senior leadership in healthcare performance reliability.; Data-Driven Decision Making: Supports the design, development, and implementation of reporting and dashboards to enable informed decisions by finance, commercial, and business leaders.; Key Performance Indicators (KPIs): Assists in the design, evaluation, and tracking of organizational KPIs to monitor performance and support organizational growth.; Data Validation: Performs validation to ensure completeness and accuracy of queries and reports, reconciling discrepancies to maintain data integrity.; Data Reporting and Dashboards: Develops and maintains reports and dashboards with high utility for executive and senior leadership to communicate insights and performance metrics.; Medical Cost and Leading Indicator Data Analysis: Prepares and analyzes healthcare-related cost and indicator data to develop presentations and actionable recommendations for leadership.; Database Organization and Maintenance: Involves skills in database design, organization, maintenance, and troubleshooting to support data collection and storage.; Power BI: Required tool knowledge for creating dashboards and reports to support data-driven insights and decision making.; Tableau: Preferred tool knowledge for data visualization and reporting to support business intelligence efforts.; Microsoft Excel (Pivot Tables, Look-Ups): Used for data analysis, manipulation, and reporting within the Microsoft Office Suite."
M0w2cQAtRxfPuuXsAAAAAA==,Data Analytics Consulting Staff (Finance & Accounting),"**Data Analytics Consulting Staff \(Finance & Accounting\)**
• *Description**

At Moss Adams, we champion authenticity. For us, that means fostering a culture of talented people who care-about you, about our clients, and about our communities. Here, you'll work towards our mission of empowering others to embrace opportunity, growing as a leader along the way. Our firm's size, middle-market clients, customized career paths, and supportive culture make this a reality. Join a values-driven firm where you'll have fun while solving complex and interesting business challenges.

As a member of the Data Analytics Consulting Staff at Moss Adams, your primary role will be to analyze data to identify actionable insights that support our clients' business objectives. You will collaborate with other team members to develop and implement data-driven solutions that enhance operational efficiency and provide strategic business insights. Your responsibilities will include interpreting complex datasets, recommending process improvements, and contributing to the enhancement of our analytics infrastructure. The success of this position is measured by your ability to effectively support decision-making processes, improve client satisfaction through accurate data analysis, and the tangible improvements seen in client operations.

Individuals who thrive at Moss Adams exhibit the following success skills - Collaboration, Critical Thinking, Emotional Intelligence, Executive Presence, Growth Mindset, Intellectual Curiosity, and Results Focus.
• *Responsibilities:**

+ Collaborate with Moss Adams cross-functional teams and clients to gather business requirements and develop tailored analytics strategies

+ Analyze data, processes, and technologies to identify operational inefficiencies and critical business challenges

+ Design and implement data-driven solutions to enhance business processes and improve decision-making

+ May perform other consulting activities that include conducting interviews, reviewing documents, performing a variety of analysis, and preparing client deliverables such as findings, recommendations, and draft and final reports

+ Create and present insights through dashboards, reports, and data visualizations to communicate findings and drive action

+ Evaluate and refine data collection methods and tools to ensure high-quality data inputs for analysis
• *Qualifications:**

+ Bachelor's degree required; emphasis in Accounting or Finance, Business or related fields preferred. Technology course work is also desired

+ Ability to adapt to a changing work environment, including the use of software systems and technology

+ Experience in Accounting or Finance preferred

+ Proven commitment to providing exceptional client service

+ Ability to think critically, identify creative solutions and provide research or other information in a well organized and logical fashion

+ Strong verbal and written communication skills

+ Ability to collaborate and work effectively across functions/departments/teams while building trusted relationships and positively influencing others

+ Self-directed professional with strong interpersonal skills

+ Executes effectively by using resources efficiently; meeting deadlines and keeping others informed of work plans and progress toward goals

+ Proficiency in Microsoft Office \(Word, Excel, PowerPoint, Outlook, and SharePoint\), experience with Tableau, Power BI, and/or Alteryx highly desirable

+ Ability to work overtime and travel as needed, approximately 5%

- - -
• *Moss Adams is an Equal Opportunity Employer as to all protected groups, including protected veterans and individuals with disabilities.**
• *Moss Adams complies with federal and state disability laws and makes reasonable accommodations for applicants and employees with disabilities. If reasonable accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment, please contact** **careers@mossadams.com** **.**
• *Certain jurisdictions in the United States require employers to disclose the pay range in job postings. This is the typical range of pay for the position. Actual compensation may depend on factors such as qualifications, work experience, skills, and geographic location. This position may be eligible for an annual discretionary bonus. For more information about our benefit offerings and other total rewards, visit our** **careers** **page.**

\#LI-MD1
• *Compensation Range \(Denver Market ONLY\):** Washington State: $84,000 - $105,000, California State: $90,000-$108,000, Colorado State: $80,000 - $105,000
• *Primary Location** Seattle, WA
• *Other Locations** Napa, CA, Pasadena, CA, Woodland Hills, CA, San Diego, CA, Bellingham, WA, Denver, CO, Walnut Creek, CA, El Segundo, CA, San Francisco, CA, Everett, WA, Phoenix, AZ, Healdsburg, CA, Tri-Cities, WA, Santa Rosa, CA, Albuquerque, NM, Salinas, CA, Salt Lake City, UT, Spokane, WA, Orange County, CA, Eugene, OR, Tacoma, WA, Wenatchee, WA, Medford, OR, Dallas, TX, Yakima, WA, Stockton, CA, Silicon Valley, CA, Sacramento, CA, Portland, OR, Fresno, CA, Houston, TX
• *Employee Status:** Regular
• *Schedule:** Full Time
• *Req ID:** 28200",2025-07-18T00:00:00.000Z,2025-07-25,"['Individuals who thrive at Moss Adams exhibit the following success skills - Collaboration, Critical Thinking, Emotional Intelligence, Executive Presence, Growth Mindset, Intellectual Curiosity, and Results Focus', '*Certain jurisdictions in the United States require employers to disclose the pay range in job postings']","[""As a member of the Data Analytics Consulting Staff at Moss Adams, your primary role will be to analyze data to identify actionable insights that support our clients' business objectives"", 'You will collaborate with other team members to develop and implement data-driven solutions that enhance operational efficiency and provide strategic business insights', 'Your responsibilities will include interpreting complex datasets, recommending process improvements, and contributing to the enhancement of our analytics infrastructure', 'The success of this position is measured by your ability to effectively support decision-making processes, improve client satisfaction through accurate data analysis, and the tangible improvements seen in client operations', 'Collaborate with Moss Adams cross-functional teams and clients to gather business requirements and develop tailored analytics strategies', 'Analyze data, processes, and technologies to identify operational inefficiencies and critical business challenges', 'Design and implement data-driven solutions to enhance business processes and improve decision-making', 'May perform other consulting activities that include conducting interviews, reviewing documents, performing a variety of analysis, and preparing client deliverables such as findings, recommendations, and draft and final reports', 'Create and present insights through dashboards, reports, and data visualizations to communicate findings and drive action', 'Evaluate and refine data collection methods and tools to ensure high-quality data inputs for analysis']",True,[],,"['Data Analysis', 'Data-Driven Solutions', 'Data Visualization and Dashboards', 'Data Collection and Quality Assurance', 'Business Analytics Strategy']","Data Analysis: Analyze data to identify actionable insights that support clients' business objectives and improve decision-making processes.; Data-Driven Solutions: Develop and implement solutions based on data analysis to enhance operational efficiency and business processes.; Data Visualization and Dashboards: Create and present insights through dashboards, reports, and visualizations to communicate findings and drive action.; Data Collection and Quality Assurance: Evaluate and refine data collection methods and tools to ensure high-quality data inputs for analysis.; Business Analytics Strategy: Collaborate with cross-functional teams and clients to gather business requirements and develop tailored analytics strategies."
sfm1iZKL7DgOl0eoAAAAAA==,Data Analyst,"Location: Water Mill
About

The Role

Grade Level (for internal use):

09

Job Description Summary

Business Intelligence Analysts within the automotive

Mastermind (aM) Product Insights team play a critical role in measuring the effects of aM in the market, communicating the value each product within the portfolio delivers, and identifying opportunities to strengthen the products and the processes by which they are created.

a Successful Business Intelligence Analyst Will
• Rigorous identification, analysis, and interpretation of trends or patterns in complex data sets
• Application of deep, creative, rigorous thinking to solve broad, platform-wide technical and/or business problems
• Design and develop management reports and supporting ad hoc analyses answering key questions such as… Is the product performance aligned with the sales pitch? Are key product components delivering value? Is marketing outreach effective? Are results consistent across clients?
• Identify key value drivers and key opportunities for/sources of error across products and processes
• Create client-facing visualizations to clearly articulate the aM value proposition and identify business opportunities for internal and external stakeholders
• Develop short-term preventive or detective measures, and leading medium/long-term product improvement initiatives arrived at via close collaboration with data transformation, engineering, QA, and production support team members
• Support and inform account leads with respect to client and regional sales mix, performance, and aM contributions
• Communicate clearly across business stakeholders as well as analytics customers
• Identify and access additional data assets that could be leveraged to answer a given business problem
• Coordinate with data engineers as appropriate to design and enable repeatable processes and generate deliverables to answer routine business questions

Minimum Requirements
• 3+ years of professional/internship experience as a Data Analyst or Business Intelligence Analyst in a similar analytical + technical role
• Familiarity with application of statistics and experience using statistical packages for analyzing large datasets (Excel, R, SPSS, SAS)
• Familiarity with visualization software packages (Data Studio, Tableau, Power

BI)
• Awareness of reporting packages (Business Objects), databases (SQL), programming (XML, Java script, or ETL frameworks)
• Strong analytical and problem-solving skills
• Ability to think quickly on your feet and handle ambiguity
• Excellent written and verbal communication skills
• Ability to execute against multiple projects as part of a team or independently, while managing competing deadlines
• Automotive experience a plus
• Regularly assess your own performance and adapt your work to achieve better results
• Continually look to improve your professional career, as well as strive for personal growth
Compensation/Benefits Information (US Applicants Only)
• S&P Global states that the anticipated base salary range for this position is $59,212 to $103,897. Final base salary for this role will be based on the individual’s geographical location as well as experience and qualifications for the role.
• In addition to base compensation, this role is eligible for an annual incentive plan.
• This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit link
About Automotive Mastermind

Who we are:

Founded in 2012, automotive

Mastermind is a leading provider of predictive analytics and marketing automation solutions for the automotive industry and believes that technology can transform data, revealing key customer insights to accurately predict automotive sales. Through its proprietary automated sales and marketing platform, Mastermind, the company empowers dealers to close more deals by predicting future buyers and consistently marketing to them. automotive

Mastermind is headquartered in New York City. For more information, visit

At automotive

Mastermind, we thrive on high energy at high speed. We’re an organization in hyper-growth mode and have a fast-paced culture to match. Our highly engaged teams feel passionately about both our product and our people. This passion is what…",2025-07-21T00:00:00.000Z,2025-07-25,"['Rigorous identification, analysis, and interpretation of trends or patterns in complex data sets', 'Application of deep, creative, rigorous thinking to solve broad, platform-wide technical and/or business problems', '3+ years of professional/internship experience as a Data Analyst or Business Intelligence Analyst in a similar analytical + technical role', 'Familiarity with application of statistics and experience using statistical packages for analyzing large datasets (Excel, R, SPSS, SAS)', 'Familiarity with visualization software packages (Data Studio, Tableau, Power', 'BI)', 'Awareness of reporting packages (Business Objects), databases (SQL), programming (XML, Java script, or ETL frameworks)', 'Strong analytical and problem-solving skills', 'Ability to think quickly on your feet and handle ambiguity', 'Excellent written and verbal communication skills', 'Ability to execute against multiple projects as part of a team or independently, while managing competing deadlines']","['Mastermind (aM) Product Insights team play a critical role in measuring the effects of aM in the market, communicating the value each product within the portfolio delivers, and identifying opportunities to strengthen the products and the processes by which they are created', 'a Successful Business Intelligence Analyst Will', 'Design and develop management reports and supporting ad hoc analyses answering key questions such as…', 'Is the product performance aligned with the sales pitch?', 'Identify key value drivers and key opportunities for/sources of error across products and processes', 'Create client-facing visualizations to clearly articulate the aM value proposition and identify business opportunities for internal and external stakeholders', 'Develop short-term preventive or detective measures, and leading medium/long-term product improvement initiatives arrived at via close collaboration with data transformation, engineering, QA, and production support team members', 'Support and inform account leads with respect to client and regional sales mix, performance, and aM contributions', 'Communicate clearly across business stakeholders as well as analytics customers', 'Identify and access additional data assets that could be leveraged to answer a given business problem', 'Coordinate with data engineers as appropriate to design and enable repeatable processes and generate deliverables to answer routine business questions']",True,[],,"['Statistical Analysis', 'Business Intelligence Reporting', 'Data Visualization Tools', 'SQL and Databases', 'ETL Frameworks and Programming', 'Trend and Pattern Analysis', 'Data Collaboration and Process Improvement']","Statistical Analysis: Use of statistical packages such as Excel, R, SPSS, and SAS to analyze large datasets and identify trends or patterns relevant to business and product performance.; Business Intelligence Reporting: Designing and developing management reports and ad hoc analyses to answer key business questions and communicate product value and performance.; Data Visualization Tools: Creating client-facing visualizations using software like Data Studio, Tableau, and Power BI to clearly articulate value propositions and identify business opportunities.; SQL and Databases: Awareness and use of databases and SQL for data querying and supporting data-driven decision making.; ETL Frameworks and Programming: Familiarity with ETL frameworks and programming languages such as XML and JavaScript to support data transformation and enable repeatable data processes.; Trend and Pattern Analysis: Rigorous identification, analysis, and interpretation of trends or patterns in complex data sets to inform business insights and product improvements.; Data Collaboration and Process Improvement: Collaborating with data transformation, engineering, QA, and production support teams to develop preventive measures and lead product improvement initiatives."
fmvkHmSbbWlPSRxiAAAAAA==,Principal Engineer Data Analytics,"Location(s):

United States of America

City/Cities:

Atlanta

Travel Required:

Relocation Provided:

Job Posting End Date:

September 16, 2024

Shift:

Job Description Summary:

General Summary:

We are looking for a highly skilled and experienced Principal Data Engineer to architect and lead the development of our data infrastructure. The successful candidate will possess deep technical expertise in data engineering and will be responsible for designing, building, and managing large-scale data processing systems, ensuring their scalability, reliability, and performance. This role will work closely with data engineering teams, product leads, and business stakeholders in support of Coca-Cola’s North America Operating Unit.

Key Responsibilities:
• Data Pipeline Development:
• Design, develop, and maintain scalable and efficient data pipelines using Azure Data Factory, Azure Synapse, PySpark, and other Azure services that support complex data transformations and large-scale processing.
• Implement ETL/ELT processes to ingest, transform, and load data from various sources into Azure data storage solutions (e.g., Azure Blob Storage, Azure Data Lake, Azure SQL Database)
• Implement and maintain data management frameworks, ensuring data quality, consistency, and security.
• Data Modeling and Warehousing:
• Develop and maintain data models, schemas, and data warehouses to support business intelligence and analytics needs.
• Optimize data storage and retrieval strategies to enhance performance and scalability. Collaboration and Leadership
• Data Integration:
• Integrate data from multiple sources, including on-premises databases, cloud services, APIs, and third-party systems.
• Ensure data quality, consistency, and reliability across all data sources.
• Collaboration and Support:
• Collaborate with cross-functional teams including data scientists, analysts, and business stakeholders to understand data requirements and deliver efficient solutions.
• Troubleshoot and resolve performance bottlenecks and other technical issues related to data infrastructure.
• Mentor and guide junior data engineers, providing technical leadership and fostering a culture of continuous improvement and innovation.
• Automation and Optimization:
• Automate repetitive tasks and processes to improve efficiency and reduce manual intervention.
• Continuously monitor and optimize data pipelines for performance and cost-effectiveness.

Qualifications:
• Bachelor’s degree in Computer Science, Engineering, Information Technology, or 10+ year’s experience in the data engineering field
• Minimum of 8+ years of experience in data engineering or a related role, with a proven track record of working on large-scale data projects.
• Strong expertise in Python and SQL
• Proven experience with Azure and its data warehousing (Synapse, Redshift) and big data technologies (e.g., Spark)
• Proven experience in designing and building scalable data pipelines and data warehouses.
• Deep understanding of database theory, data modeling, and ETL/ELT processes
• Demonstrated ability to work in a fast-paced environment, managing multiple projects and deadlines.
• Excellent problem-solving skills, attention to detail, and ability to think critically and analytically.

Strong communication skills, with the ability to effectively convey complex technical concepts to non-technical stakeholders.

Preferred Qualifications:
• Azure Data Engineer certifications (e.g., Microsoft Certified: Azure Data Engineer Associate).
• Experience with DevOps practices and tools, including CI/CD pipelines, version control, and infrastructure as code (e.g., GitHub Actions, Azure DevOps, Terraform).
• Experience developing in the Power Platform, specifically Power BI and Power Apps
• Additional experience in programming languages Scala, Java, Node.js
• Additional experience in AWS Data Lake technologies, such as AWS Redshift and AWS Glue
• Experience in the consumer packaged goods industry
• Experience with machine learning and AI-driven data processing techniques.

Skills:

Pay Range:

$159,300 - $184,700

Base pay offered may vary depending on geography, job-related knowledge, skills, and experience. A full range of medical, financial, and/or other benefits, dependent on the position, is offered.

Annual Incentive Reference Value Percentage:

30

Annual Incentive reference value is a market-based competitive value for your role. It falls in the middle of the range for your role, indicating performance at target.

Our Purpose and Growth Culture:

We are taking deliberate action to nurture an inclusive culture that is grounded in our company purpose, to refresh the world and make a difference. We act with a growth mindset, take an expansive approach to what’s possible and believe in continuous learning to improve our business and ourselves. We focus on four key behaviors – curious, empowered, inclusive and agile – and value how we work as much as what we achieve. We believe that our culture is one of the reasons our company continues to thrive after 130+ years. Visit Our Purpose and Vision to learn more about these behaviors and how you can bring them to life in your next role at Coca-Cola.

We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity and/or expression, status as a veteran, and basis of disability or any other federal, state or local protected class. When we collect your personal information as part of a job application or offer of employment, we do so in accordance with industry standards and best practices and in compliance with applicable privacy laws.",,2025-07-25,"['The successful candidate will possess deep technical expertise in data engineering and will be responsible for designing, building, and managing large-scale data processing systems, ensuring their scalability, reliability, and performance', 'Bachelor’s degree in Computer Science, Engineering, Information Technology, or 10+ year’s experience in the data engineering field', 'Minimum of 8+ years of experience in data engineering or a related role, with a proven track record of working on large-scale data projects', 'Strong expertise in Python and SQL', 'Proven experience with Azure and its data warehousing (Synapse, Redshift) and big data technologies (e.g., Spark)', 'Proven experience in designing and building scalable data pipelines and data warehouses', 'Deep understanding of database theory, data modeling, and ETL/ELT processes', 'Demonstrated ability to work in a fast-paced environment, managing multiple projects and deadlines', 'Excellent problem-solving skills, attention to detail, and ability to think critically and analytically', 'Strong communication skills, with the ability to effectively convey complex technical concepts to non-technical stakeholders']","['This role will work closely with data engineering teams, product leads, and business stakeholders in support of Coca-Cola’s North America Operating Unit', 'Data Pipeline Development:', 'Design, develop, and maintain scalable and efficient data pipelines using Azure Data Factory, Azure Synapse, PySpark, and other Azure services that support complex data transformations and large-scale processing', 'Implement ETL/ELT processes to ingest, transform, and load data from various sources into Azure data storage solutions (e.g., Azure Blob Storage, Azure Data Lake, Azure SQL Database)', 'Implement and maintain data management frameworks, ensuring data quality, consistency, and security', 'Data Modeling and Warehousing:', 'Develop and maintain data models, schemas, and data warehouses to support business intelligence and analytics needs', 'Optimize data storage and retrieval strategies to enhance performance and scalability', 'Integrate data from multiple sources, including on-premises databases, cloud services, APIs, and third-party systems', 'Ensure data quality, consistency, and reliability across all data sources', 'Collaboration and Support:', 'Collaborate with cross-functional teams including data scientists, analysts, and business stakeholders to understand data requirements and deliver efficient solutions', 'Troubleshoot and resolve performance bottlenecks and other technical issues related to data infrastructure', 'Mentor and guide junior data engineers, providing technical leadership and fostering a culture of continuous improvement and innovation', 'Automation and Optimization:', 'Automate repetitive tasks and processes to improve efficiency and reduce manual intervention', 'Continuously monitor and optimize data pipelines for performance and cost-effectiveness']",False,,,,
GhDl-jKIqt_ZEoiUAAAAAA==,Business Operations Analyst,"About us
• At Sierra, we’re creating a platform to help businesses build better, more human customer experiences with AI. We are primarily an in-person company based in San Francisco, with growing offices in Atlanta, New York, and London.
• We are guided by a set of values that are at the core of our actions and define our culture: Trust, Customer Obsession, Craftsmanship, Intensity, and Family. These values are the foundation of our work, and we are committed to upholding them in everything we do.
• Our co-founders are Bret Taylor and Clay Bavor. Bret currently serves as Board Chair of OpenAI. Previously, he was co-CEO of Salesforce (which had acquired the company he founded, Quip) and CTO of Facebook. Bret was also one of Google's earliest product managers and co-creator of Google Maps. Before founding Sierra, Clay spent 18 years at Google, where he most recently led Google Labs. Earlier, he started and led Google’s AR/VR effort, Project Starline, and Google Lens. Before that, Clay led the product and design teams for Google Workspace.

What you’ll do
• Master Sierra’s daily operations, identify inefficiencies and improve our capabilities by optimizing existing processes and introducing new ones
• Drive end-to-end strategic projects such as building business cases and execution plans for new markets, performing financial and data analysis on product performance, and developing frameworks for annual planning
• Act as a thought partner to leaders across the company to improve business planning, performance & execution
• Coordinate with Sales, Marketing, Product, and Engineering teams to ensure seamless execution of cross-functional projects
• Wear many hats! In this unique role, you’ll have the opportunity to define your future by gaining broad exposure to all aspects of Sierra’s operations

What you’ll bring
• 2-4 years of experience in management consulting, corporate strategy, or business operations
• Proficiency in data analysis tools (e.g., Excel, Google Sheets) and experience with data visualization tools (e.g., Tableau, Looker, or Power BI)
• A detail-oriented, methodical, and process-driven mentality that is focused on both accuracy and efficiency
• Demonstrated ability to manage multiple projects, prioritize effectively, and meet deadlines
• A proactive mindset with the ability to navigate ambiguity, drive and execute initiatives, and deliver results in a fast-paced, dynamic environment
• Strong written and verbal communication skills, with the ability to distill complex ideas and problems into straightforward, actionable recommendations, especially to executives

Even better…
• SQL experience
• Familiarity with CRM platforms (e.g., Salesforce, HubSpot) and marketing automation tools
• Previous 0-1 startup or operational experience

Our values
• Trust: We build trust with our customers with our accountability, empathy, quality, and responsiveness. We build trust in AI by making it more accessible, safe, and useful. We build trust with each other by showing up for each other professionally and personally, creating an environment that enables all of us to do our best work.
• Customer Obsession: We deeply understand our customers’ business goals and relentlessly focus on driving outcomes, not just technical milestones. Everyone at the company knows and spends time with our customers. When our customer is having an issue, we drop everything and fix it.
• Craftsmanship: We get the details right, from the words on the page to the system architecture. We have good taste. When we notice something isn’t right, we take the time to fix it. We are proud of the products we produce. We continuously self-reflect to continuously self-improve.
• Intensity: We know we don’t have the luxury of patience. We play to win. We care about our product being the best, and when it isn’t, we fix it. When we fail, we talk about it openly and without blame so we succeed the next time.
• Family: We know that balance and intensity are compatible, and we model it in our actions and processes. We are the best technology company for parents. We support and respect each other and celebrate each other’s personal and professional achievements.

What we offer

We want our benefits to reflect our values and offer the following to full-time employees:
• Flexible (Unlimited) Paid Time Off
• Medical, Dental, and Vision benefits for you and your family
• Life Insurance and Disability Benefits
• Retirement Plan (e.g., 401K, pension) with Sierra match
• Parental Leave
• Fertility and family building benefits through Carrot
• Lunch, as well as delicious snacks and coffee to keep you energized
• Discretionary Benefit Stipend giving people the ability to spend where it matters most
• Free alphorn lessons

These benefits are further detailed in Sierra's policies and are subject to change at any time, consistent with the terms of any applicable compensation or benefits plans. Eligible full-time employees can participate in Sierra's equity plans subject to the terms of the applicable plans and policies.
Be you, with us

We're working to bring the transformative power of AI to every organization in the world. To do so, it is important to us that the diversity of our employees represents the diversity of our customers. We believe that our work and culture are better when we encourage, support, and respect different skills and experiences represented within our team. We encourage you to apply even if your experience doesn't precisely match the job description. We strive to evaluate all applicants consistently without regard to race, color, religion, gender, national origin, age, disability, veteran status, pregnancy, gender expression or identity, sexual orientation, citizenship, or any other legally protected class.",,2025-07-25,"['2-4 years of experience in management consulting, corporate strategy, or business operations', 'Proficiency in data analysis tools (e.g., Excel, Google Sheets) and experience with data visualization tools (e.g., Tableau, Looker, or Power BI)', 'A detail-oriented, methodical, and process-driven mentality that is focused on both accuracy and efficiency', 'Demonstrated ability to manage multiple projects, prioritize effectively, and meet deadlines', 'A proactive mindset with the ability to navigate ambiguity, drive and execute initiatives, and deliver results in a fast-paced, dynamic environment', 'Strong written and verbal communication skills, with the ability to distill complex ideas and problems into straightforward, actionable recommendations, especially to executives', 'SQL experience', 'Familiarity with CRM platforms (e.g., Salesforce, HubSpot) and marketing automation tools', 'Previous 0-1 startup or operational experience']","['Master Sierra’s daily operations, identify inefficiencies and improve our capabilities by optimizing existing processes and introducing new ones', 'Drive end-to-end strategic projects such as building business cases and execution plans for new markets, performing financial and data analysis on product performance, and developing frameworks for annual planning', 'Act as a thought partner to leaders across the company to improve business planning, performance & execution', 'Coordinate with Sales, Marketing, Product, and Engineering teams to ensure seamless execution of cross-functional projects', 'Wear many hats!', 'In this unique role, you’ll have the opportunity to define your future by gaining broad exposure to all aspects of Sierra’s operations', 'When our customer is having an issue, we drop everything and fix it', 'Craftsmanship: We get the details right, from the words on the page to the system architecture']",False,,,,
q_9ag-oDqGFEDnYmAAAAAA==,"Senior Financial Data Analyst - Strategy & Project Management at HEALTH CONNECT AMERICA, INC Franklin, TN","Senior Financial Data Analyst - Strategy & Project Management job at HEALTH CONNECT AMERICA, INC. Franklin, TN. Overview:

Join Our Impactful Team at Health Connect America!

Before you get started on your journey with Health Connect America , take some time to learn more about us. Health Connect America and its affiliate brands are leaders in providing mental and behavioral health services to children, families, and adults across the nation. We provide our services directly to those in need whether that be within a person's home, their community, or in one of our office settings. HCA is honored to be a part of the communities we serve and the clients we walk alongside as they embark on a journey to self-improvement and more fulfilling lives. At Health Connect America , we are dedicated to making meaningful connections every day through creating quality, affordable opportunities for individuals and families to achieve their greatest potential in a safe, positive living environment.

Come make a difference and grow with us!

Our Brands

Responsibilities:

The Senior Financial Strategy Analyst focusing on Project Management and Data Analytics , reporting to the Vice President of Strategy & Platform Development, will support M&A, key strategic initiatives and financial initiatives within the company. This position will require someone to work in a hybrid capacity (partially remote and partially in the office in Franklin, TN) . This position will provide effective project management and financial strategy coordination across all company departments. This position will use a combination of tools, techniques, and technologies to generate, analyze, report, and interpret moderately complex data used across the organization. This work will support Health Connect America’s future growth plans and will receive executive level attention and exposure.

Essential Duties & Responsibilities:
• Facilitate meetings to ensure focused planning and coordination between teams working on company strategic initiatives
• Develop financial models through benchmarking and process analysis for both M&A and Organic Expansion opportunities
• Assist leadership to produce and monitor key performance indicators to measure and improve team performance
• Complete special projects and initiatives with skillful oversight and support
• Conduct thorough research of historical financial data including analysis on organic growth initiatives
• Coordinate with the Chief Financial Officer (CFO) and the executive team on long-term financial planning
• Assist VP of Strategy & Platform Development to create in-depth investment memorandums and related presentations for review by senior management, private equity sponsors, and other third-party advisors as required
• Assist in creating/executing diligence and integration plans for successful deal execution
• Maintain confidentiality of financial information and investment decisions
• Perform other duties as assigned to support operations and mission of the Company
Qualifications:
• Preferred Education and Experience Credentials:
• CPA
• MBA
• 5-7 years of Accounting/Financial Analysis experience
• Experience in multi-state healthcare organizations
• Preferred Knowledge, Skills, and Abilities:
• Microsoft Programs: Excel, PowerPoint, Outlook, Prophix
• Data Analytics: Alteryx and PowerBI
• Financial Valuation and Modeling

Be Well with HCA:
• We recognize the importance of self-care and work/life balance.
• We offer flexibility in scheduling and provide all employees access to our Employee Assistance Program (EAP), which includes 8 mental health counseling sessions annually.
• Full-time HCA employees enjoy paid time off, paid holidays, and a comprehensive benefits package that includes medical, dental, vision, and other voluntary insurance products.
• Additional benefits include:
• Access to a Health Navigator
• Health Savings Account with company contribution
• Dependent Daycare Flexible Spending Account
• Health Reimbursement Account
• 401(k) Retirement Plan
• Benefits Hub
• Tickets at Work

Join a team where your contributions truly make a difference in the lives of others. Apply now to be part of our dynamic and supportive community at Health Connect America!

Employment at Health Connect America and it's companies is contingent upon meeting the requirements of a comprehensive background investigation prior to joining our team.

Health Connect America and its companies are an Equal Opportunity Employer and consider applicants for employment without regard to race, color, religion, sex, orientation, national origin, age, disability, genetics, or any other basis forbidden under federal, state, or local law. For more information on Equal Opportunity, please click here",2025-07-25T00:00:00.000Z,2025-07-25,"['CPA', 'MBA', '5-7 years of Accounting/Financial Analysis experience', 'Experience in multi-state healthcare organizations', 'Microsoft Programs: Excel, PowerPoint, Outlook, Prophix', 'Data Analytics: Alteryx and PowerBI', 'Financial Valuation and Modeling', 'We recognize the importance of self-care and work/life balance']","['The Senior Financial Strategy Analyst focusing on Project Management and Data Analytics , reporting to the Vice President of Strategy & Platform Development, will support M&A, key strategic initiatives and financial initiatives within the company', 'This position will require someone to work in a hybrid capacity (partially remote and partially in the office in Franklin, TN) ', 'This position will provide effective project management and financial strategy coordination across all company departments', 'This position will use a combination of tools, techniques, and technologies to generate, analyze, report, and interpret moderately complex data used across the organization', 'This work will support Health Connect America’s future growth plans and will receive executive level attention and exposure', 'Facilitate meetings to ensure focused planning and coordination between teams working on company strategic initiatives', 'Develop financial models through benchmarking and process analysis for both M&A and Organic Expansion opportunities', 'Assist leadership to produce and monitor key performance indicators to measure and improve team performance', 'Complete special projects and initiatives with skillful oversight and support', 'Conduct thorough research of historical financial data including analysis on organic growth initiatives', 'Coordinate with the Chief Financial Officer (CFO) and the executive team on long-term financial planning', 'Assist VP of Strategy & Platform Development to create in-depth investment memorandums and related presentations for review by senior management, private equity sponsors, and other third-party advisors as required', 'Assist in creating/executing diligence and integration plans for successful deal execution', 'Maintain confidentiality of financial information and investment decisions', 'Perform other duties as assigned to support operations and mission of the Company']",False,,,,
a0_LjSMjfaSC-SvWAAAAAA==,WFH | Online Data Analyst - Spanish Speaker in the United States,"Are you a detail-oriented individual with a passion for research and a good understanding of national and local geography? This freelance opportunity allows you to work at your own pace and from the comfort of your own home.

A Day in the Life of an Online Data Analyst:
• In this role, you will be working on a project aimed at enhancing the content and quality of digital maps that are used by millions of people worldwide
• Completing research and evaluation tasks in a web-based environment, such as verifying and comparing data, and determining the relevance and accuracy of information.

Join us today and be part of a dynamic and innovative team that is making a difference in the world!

TELUS Digital AI Community

Our global AI Community is a vibrant network of 1 million+ contributors from diverse backgrounds who help our customers collect, enhance, train, translate, and localize content to build better AI models. Become part of our growing community and make an impact supporting the machine learning models of some of the world’s largest brands

Qualification path

No previous professional experience is required to apply to this role, however, working on this project will require you to pass the basic requirements and go through a standard assessment process. This is a part-time long-term project and your work will be subject to our standard quality assurance checks during the term of this agreement.

Basic Requirements
• Full Professional Proficiency in Spanish language
• Being a resident in United States for the last 2 consecutive years and having familiarity with current and historical business, media, sport, news, social media, and cultural affairs in United States
• Ability to follow guidelines and conduct online research using search engines, online maps, and website information
• Flexibility to work across a diverse set of task types, including maps, news, audio tasks, and relevance
• Daily access to a broadband internet connection, computer, and relevant software

Assessment

In order to be hired into the program, you’ll take an open book qualification exam that will determine your suitability for the position and complete ID verification. Our team will provide you with guidelines and learning materials before your qualification exam. You will be required to complete the exam in a specific timeframe but at your convenience.

Equal Opportunity

All qualified applicants will receive consideration for a contractual relationship without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or protected veteran status. At TELUS Digital AI, we are proud to offer equal opportunities and are committed to creating a diverse and inclusive community. All aspects of selection are based on applicants’ qualifications, merits, competence, and performance without regard to any characteristic related to diversity.",2025-07-15T00:00:00.000Z,2025-07-25,"['No previous professional experience is required to apply to this role, however, working on this project will require you to pass the basic requirements and go through a standard assessment process', 'Full Professional Proficiency in Spanish language', 'Being a resident in United States for the last 2 consecutive years and having familiarity with current and historical business, media, sport, news, social media, and cultural affairs in United States', 'Ability to follow guidelines and conduct online research using search engines, online maps, and website information', 'Flexibility to work across a diverse set of task types, including maps, news, audio tasks, and relevance', 'Daily access to a broadband internet connection, computer, and relevant software', 'In order to be hired into the program, you’ll take an open book qualification exam that will determine your suitability for the position and complete ID verification', 'Our team will provide you with guidelines and learning materials before your qualification exam']","['In this role, you will be working on a project aimed at enhancing the content and quality of digital maps that are used by millions of people worldwide', 'Completing research and evaluation tasks in a web-based environment, such as verifying and comparing data, and determining the relevance and accuracy of information', 'This is a part-time long-term project and your work will be subject to our standard quality assurance checks during the term of this agreement']",False,,,,
XZbRG7Xze6RMrMfPAAAAAA==,Data Analyst - L3,"Wipro Limited (NYSE: WIT, BSE: 507685, NSE: WIPRO) is a leading technology services and consulting company focused on building innovative solutions that address clients' most complex digital transformation needs. Leveraging our holistic portfolio of capabilities in consulting, design, engineering, and operations, we help clients realize their boldest ambitions and build future-ready, sustainable businesses. With over 230,000 employees and business partners across 65 countries, we deliver on the promise of helping our customers, colleagues, and communities thrive in an ever-changing world. For additional information, visit us at www.wipro.com. Job Description

Role Purpose

The purpose of the role is to liaison and bridging the gap between customer and Wipro delivery team to comprehend and analyze customer requirements and articulating aptly to delivery teams thereby, ensuring right solutioning to the customer.

Do

1. Customer requirements gathering and engagement
• Interface and coordinate with client engagement partners to understand the RFP/ RFI requirements
• Detail out scope documents, functional & non-functional requirements, features etc ensuring all stated and unstated customer needs are captured
• Construct workflow charts and diagrams, studying system capabilities, writing specification after thorough research and analysis of customer requirements
• Engage and interact with internal team - project managers, pre-sales team, tech leads, architects to design and formulate accurate and timely response to RFP/RFIs
• Understand and communicate the financial and operational impact of any changes
• Periodic cadence with customers to seek clarifications and feedback wrt solution proposed for a particular RFP/ RFI and accordingly instructing delivery team to make changes in the design
• Empower the customers through demonstration and presentation of the proposed solution/ prototype
• Maintain relationships with customers to optimize business integration and lead generation
• Ensure ongoing reviews and feedback from customers to improve and deliver better value (services/ products) to the customers

2. Engage with delivery team to ensure right solution is proposed to the customer

a. Periodic cadence with delivery team to:
• Provide them with customer feedback/ inputs on the proposed solution
• Review the test cases to check 100% coverage of customer requirements
• Conduct root cause analysis to understand the proposed solution/ demo/ prototype before sharing it with the customer
• Deploy and facilitate new change requests to cater to customer needs and requirements
• Support QA team with periodic testing to ensure solutions meet the needs of businesses by giving timely inputs/feedback
• Conduct Integration Testing and User Acceptance demo's testing to validate implemented solutions and ensure 100% success rate
• Use data modelling practices to analyze the findings and design, develop improvements and changes
• Ensure 100% utilization by studying systems capabilities and understanding business specifications
• Stitch the entire response/ solution proposed to the RFP/ RFI before its presented to the customer

b. Support Project Manager/ Delivery Team in delivering the solution to the customer
• Define and plan project milestones, phases and different elements involved in the project along with the principal consultant
• Drive and challenge the presumptions of delivery teams on how will they successfully execute their plans
• Ensure Customer Satisfaction through quality deliverable on time

3. Build domain expertise and contribute to knowledge repository
• Engage and interact with other BA's to share expertise and increase domain knowledge across the vertical
• Write whitepapers/ research papers, point of views and share with the consulting community at large
• Identify and create used cases for a different project/ account that can be brought at Wipro level for business enhancements
• Conduct market research for content and development to provide latest inputs into the projects thereby ensuring customer delight

Deliver
No. Performance Parameter Measure 1. Customer Engagement and Delivery Management PCSAT, utilization % achievement, no. of leads generated from the business interaction, no. of errors/ gaps in documenting customer requirements, feedback from project manager, process flow diagrams (quality and timeliness), % of deal solutioning completed within timeline, velocity generated. 2. Knowledge Management No. of whitepapers/ research papers written, no. of user stories created, % of proposal documentation completed and uploaded into knowledge repository, No of reusable components developed for proposal during quarter

Mandatory Skills: Data Visualization .

Experience: 3-5 Years .

Expected annual pay for this role ranges from $45,000 to $110,000 . Based on the position, the role is also eligible for Wipro's standard benefits including a full range of medical and dental benefits options, disability insurance, paid time off (inclusive of sick leave), other paid and unpaid leave options.

Reinvent your world. We are building a modern Wipro. We are an end-to-end digital transformation partner with the boldest ambitions. To realize them, we need people inspired by reinvention. Of yourself, your career, and your skills. We want to see the constant evolution of our business and our industry. It has always been in our DNA - as the world around us changes, so do we. Join a business powered by purpose and a place that empowers you to design your own reinvention. Come to Wipro. Realize your ambitions. Applications from people with disabilities are explicitly welcome.",2025-07-13T00:00:00.000Z,2025-07-25,"['Mandatory Skills: Data Visualization ', 'Experience: 3-5 Years ']","['The purpose of the role is to liaison and bridging the gap between customer and Wipro delivery team to comprehend and analyze customer requirements and articulating aptly to delivery teams thereby, ensuring right solutioning to the customer', 'Customer requirements gathering and engagement', 'Interface and coordinate with client engagement partners to understand the RFP/ RFI requirements', 'Detail out scope documents, functional & non-functional requirements, features etc ensuring all stated and unstated customer needs are captured', 'Construct workflow charts and diagrams, studying system capabilities, writing specification after thorough research and analysis of customer requirements', 'Engage and interact with internal team - project managers, pre-sales team, tech leads, architects to design and formulate accurate and timely response to RFP/RFIs', 'Understand and communicate the financial and operational impact of any changes', 'Periodic cadence with customers to seek clarifications and feedback wrt solution proposed for a particular RFP/ RFI and accordingly instructing delivery team to make changes in the design', 'Empower the customers through demonstration and presentation of the proposed solution/ prototype', 'Maintain relationships with customers to optimize business integration and lead generation', 'Ensure ongoing reviews and feedback from customers to improve and deliver better value (services/ products) to the customers', 'Engage with delivery team to ensure right solution is proposed to the customer', 'Periodic cadence with delivery team to:', 'Provide them with customer feedback/ inputs on the proposed solution', 'Review the test cases to check 100% coverage of customer requirements', 'Conduct root cause analysis to understand the proposed solution/ demo/ prototype before sharing it with the customer', 'Deploy and facilitate new change requests to cater to customer needs and requirements', 'Support QA team with periodic testing to ensure solutions meet the needs of businesses by giving timely inputs/feedback', ""Conduct Integration Testing and User Acceptance demo's testing to validate implemented solutions and ensure 100% success rate"", 'Use data modelling practices to analyze the findings and design, develop improvements and changes', 'Ensure 100% utilization by studying systems capabilities and understanding business specifications', 'Stitch the entire response/ solution proposed to the RFP/ RFI before its presented to the customer', 'Support Project Manager/ Delivery Team in delivering the solution to the customer', 'Define and plan project milestones, phases and different elements involved in the project along with the principal consultant', 'Drive and challenge the presumptions of delivery teams on how will they successfully execute their plans', 'Ensure Customer Satisfaction through quality deliverable on time', 'Build domain expertise and contribute to knowledge repository', ""Engage and interact with other BA's to share expertise and increase domain knowledge across the vertical"", 'Write whitepapers/ research papers, point of views and share with the consulting community at large', 'Identify and create used cases for a different project/ account that can be brought at Wipro level for business enhancements', 'Conduct market research for content and development to provide latest inputs into the projects thereby ensuring customer delight', 'Customer Engagement and Delivery Management PCSAT, utilization % achievement, no', 'of leads generated from the business interaction, no', 'of errors/ gaps in documenting customer requirements, feedback from project manager, process flow diagrams (quality and timeliness), % of deal solutioning completed within timeline, velocity generated', 'Knowledge Management No. of whitepapers/ research papers written, no', 'of user stories created, % of proposal documentation completed and uploaded into knowledge repository, No of reusable components developed for proposal during quarter']",False,,,,
0RPj7-j0a7dKpU6NAAAAAA==,"Scientific Business Analyst, Scientific AI- Boston","Who We Are

TetraScience is the Scientific Data and AI Cloud company. We are catalyzing the Scientific AI revolution by designing and industrializing AI-native scientific data sets, which we bring to life in a growing suite of next gen lab data management solutions, scientific use cases, and AI-enabled outcomes.

TetraScience is the category leader in this vital new market, generating more revenue than all other companies in the aggregate. In the last year alone, the world’s dominant players in compute, cloud, data, and AI infrastructure have converged on TetraScience as the de facto standard, entering into co-innovation and go-to-market partnerships: Latest News and Announcements | TetraScience Newsroom:

In connection with your candidacy, you will be asked to carefully review the Tetra Way letter, authored directly by Patrick Grady, our co-founder and CEO. This letter is designed to assist you in better understanding whether TetraScience is the right fit for you from a values and ethos perspective.

It is impossible to overstate the importance of this document and you are encouraged to take it literally and reflect on whether you are aligned with our unique approach to company and team building. If you join us, you will be expected to embody its contents each day.

Who You Are

You are a strategic, analytically minded professional with a passion for bridging scientific insights and cutting-edge technology. You thrive in environments where you can collaborate with scientists, product managers, and engineers to transform complex scientific data into actionable outcomes.

With deep domain knowledge in drug discovery/preclinical development, CMC, or Quality, you are skilled at uncovering innovative use cases that drive AI and machine learning applications. Your ability to engage with scientists and business leaders alike makes you a key player in maximizing the value of scientific data.

You will need to be a high clock speed and forward-thinking individual with a passion for developing requirements for complex solutions targeted to R&D and Quality personas inside of Life Sciences.

You will need to be a high clock-speed, forward-thinking individual with a passion for developing requirements for complex solutions targeted to R&D and Quality personas inside Life Sciences. You embody extreme ownership and have a demonstrated history of deriving maximum value from data through enrichment, analysis, and integration with AI and machine learning applications.

You should also be energized by regularly working onsite with customers. You thrive in dynamic, high-impact, face-to-face collaborative environments where you can build deep relationships and drive scientific transformation firsthand.

Requirements

What You Have Done
• PhD with 15+ years of industry experience in life sciences, preferably across pharma, biotech, or health tech, with deep domain expertise in discovery, preclinical, CMC, and/or Quality.
• Extensive hands-on experience or direct oversight in one or more of the following areas: high throughput screening, preclinical toxicology, materials engineering, analytical development, drug substance (DS) synthesis and manufacturing.
• Delivered requirements for AI/ML-driven solutions in operational or productized environments that improved efficiency, reduced cost, and enhanced data utilization.
• Extensive hands-on experience with scientific data workflows and lab automation; exposure to FAIR principles and modern data architecture is a plus.
• Strong coding or scripting background (e.g., Python, Nextflow, AWS, SDKs) and familiarity with scientific tools, databases, and ontologies is preferred.
• Exceptional communication and storytelling ability to engage technical and executive stakeholders.
• Prior experience in customer-facing, consulting, or commercial-scientific interface roles.

What You Will Do
• You will be a critical team member in a unique partnership to industrialize Scientific AI. As such, you will engage directly with customers onsite up to 4-5 days per week in the Boston Region
• Customer Data Exploration: Investigate diverse customer datasets, identifying enrichment and AI-readiness opportunities.
• Scientific Use Case Development: Collaborate with customers to define, iterate, and implement innovative scientific AI/ML use cases.
• Stakeholder Engagement: Conduct onsite interviews and workshops to deeply understand customer challenges and data landscapes.
• Data Analysis and Enrichment: Perform exploratory data analysis and define transformation workflows that enable scientific AI.
• Workflow Documentation: Develop visual documentation including workflow diagrams, ERDs, and ontology definitions.
• AI Model Evaluation: Provide practical scientific input on model output, with suggestions to improve real-world performance.
• Customer Enablement: Deliver onsite demonstrations, conduct working sessions, and act as a trusted advisor in AI adoption.
• Strategic Insight: Propose new directions, experiments, or platforms that can amplify scientific discovery and development.

Benefits
• 100% employer-paid benefits for all eligible employees and immediate family members
• Unlimited paid time off (PTO)
• 401K
• Remote working opportunities, when not at customer sites
• Company paid Life Insurance, LTD/STD
• A culture of continuous improvement where you can grow your career and get coaching",,2025-07-25,"['You are a strategic, analytically minded professional with a passion for bridging scientific insights and cutting-edge technology', 'You thrive in environments where you can collaborate with scientists, product managers, and engineers to transform complex scientific data into actionable outcomes', 'With deep domain knowledge in drug discovery/preclinical development, CMC, or Quality, you are skilled at uncovering innovative use cases that drive AI and machine learning applications', 'Your ability to engage with scientists and business leaders alike makes you a key player in maximizing the value of scientific data', 'You will need to be a high clock speed and forward-thinking individual with a passion for developing requirements for complex solutions targeted to R&D and Quality personas inside of Life Sciences', 'You will need to be a high clock-speed, forward-thinking individual with a passion for developing requirements for complex solutions targeted to R&D and Quality personas inside Life Sciences', 'You embody extreme ownership and have a demonstrated history of deriving maximum value from data through enrichment, analysis, and integration with AI and machine learning applications', 'PhD with 15+ years of industry experience in life sciences, preferably across pharma, biotech, or health tech, with deep domain expertise in discovery, preclinical, CMC, and/or Quality', 'Extensive hands-on experience or direct oversight in one or more of the following areas: high throughput screening, preclinical toxicology, materials engineering, analytical development, drug substance (DS) synthesis and manufacturing', 'Delivered requirements for AI/ML-driven solutions in operational or productized environments that improved efficiency, reduced cost, and enhanced data utilization', 'Exceptional communication and storytelling ability to engage technical and executive stakeholders', 'Prior experience in customer-facing, consulting, or commercial-scientific interface roles']","['You should also be energized by regularly working onsite with customers', 'You thrive in dynamic, high-impact, face-to-face collaborative environments where you can build deep relationships and drive scientific transformation firsthand', 'You will be a critical team member in a unique partnership to industrialize Scientific AI', 'As such, you will engage directly with customers onsite up to 4-5 days per week in the Boston Region', 'Customer Data Exploration: Investigate diverse customer datasets, identifying enrichment and AI-readiness opportunities', 'Scientific Use Case Development: Collaborate with customers to define, iterate, and implement innovative scientific AI/ML use cases', 'Stakeholder Engagement: Conduct onsite interviews and workshops to deeply understand customer challenges and data landscapes', 'Data Analysis and Enrichment: Perform exploratory data analysis and define transformation workflows that enable scientific AI', 'Workflow Documentation: Develop visual documentation including workflow diagrams, ERDs, and ontology definitions', 'AI Model Evaluation: Provide practical scientific input on model output, with suggestions to improve real-world performance', 'Customer Enablement: Deliver onsite demonstrations, conduct working sessions, and act as a trusted advisor in AI adoption', 'Strategic Insight: Propose new directions, experiments, or platforms that can amplify scientific discovery and development']",True,"['AI-Driven Scientific Solutions', 'Scientific AI Use Cases', 'AI Model Evaluation', 'AI Adoption Enablement']","AI-Driven Scientific Solutions: Delivering AI and machine learning-driven solutions in operational or productized environments to improve efficiency, reduce costs, and enhance scientific data utilization.; Scientific AI Use Cases: Developing and implementing AI and machine learning use cases specifically tailored to scientific domains like drug discovery, preclinical development, and quality assurance.; AI Model Evaluation: Providing scientific input and feedback on AI model outputs to improve real-world performance and applicability in scientific contexts.; AI Adoption Enablement: Engaging with customers through onsite demonstrations and working sessions to facilitate adoption and trust in AI technologies within scientific workflows.","['Scientific Data Workflows', 'Exploratory Data Analysis', 'Data Enrichment', 'Data Transformation Workflows', 'Feature Engineering', 'Machine Learning Applications', 'Scientific Use Case Development', 'Workflow Documentation', 'Scientific Data Architecture', 'High Throughput Screening Data', 'Lab Automation Data', 'Python Programming', 'SDKs and Cloud Tools']","Scientific Data Workflows: Involved in managing and analyzing complex scientific datasets to enable AI and machine learning applications in life sciences.; Exploratory Data Analysis: Performing initial investigations on diverse customer datasets to identify enrichment and transformation opportunities that support scientific AI use cases.; Data Enrichment: Enhancing raw scientific data through integration and transformation to maximize its value for AI and machine learning applications.; Data Transformation Workflows: Defining and implementing workflows that convert and prepare scientific data to be AI-ready and support downstream AI/ML models.; Feature Engineering: Deriving meaningful features from scientific data to improve AI and machine learning model performance in drug discovery and quality domains.; Machine Learning Applications: Driving AI and machine learning use cases in scientific domains such as drug discovery, preclinical development, and quality control.; Scientific Use Case Development: Collaborating with customers to define, iterate, and implement innovative AI/ML-driven scientific use cases that improve operational efficiency and data utilization.; Workflow Documentation: Creating visual documentation such as workflow diagrams, entity-relationship diagrams (ERDs), and ontology definitions to support scientific data management and AI integration.; Scientific Data Architecture: Applying modern data architecture principles, including FAIR data principles, to organize and manage scientific data for AI readiness and interoperability.; High Throughput Screening Data: Experience with datasets generated from high throughput screening processes relevant to drug discovery and preclinical research.; Lab Automation Data: Handling data generated from automated laboratory processes to support scientific AI and machine learning workflows.; Python Programming: Using Python scripting and coding skills to manipulate scientific data, develop data workflows, and support AI/ML solution delivery.; SDKs and Cloud Tools: Utilizing software development kits (SDKs) and cloud platforms such as AWS to build and deploy scientific data and AI solutions."
X_ayPIoPy9Kzho7-AAAAAA==,Data Analyst with Security Clearance,"M&S Consulting was conceived in 2002 with the vision of creating highly effective teams of elite consultants to deliver strategic process and technology solutions to enterprise organizations across the US. Our commitment to delivery in complex environments and long-term customer success has merged process and technology into innovative solutions, established deep pockets of expertise, and enabled innovative transformation for evolving businesses.

We have intentionally cultivated steady growth focused on being approachable and helpful to our dearly valued clients and closely cared-for employees. M&S people simply “care hard”, and this reflects in our work products, our interactions, and our culture.

M&S Consulting is seeking a Data Analyst to work in Huntsville, AL. Candidate must possess an active Top Secret/SCI Eligible clearance.

The Data Analyst will perform analysis on relevant information from a variety of sources to prepare documents, reports, summaries and replies to inquiries, ensuring accuracy and proper format of the information provided. The candidate will manage the compilation, cataloging, caching, distribution, and retrieval of data. The successful candidate will participate in Ad hoc data projects and analyses that produce actionable recommendations that build relevant insights for internal and external stakeholders. The Data Analyst will collect data and run basic reports in response to client inquiries, work closely with key internal stakeholders to ensure sound knowledge of client requirements to support development of best-in-class analytical solutions, and accurately enter required data into one or more databases, documents and/or spreadsheets.

Job Requirements:
• Active Top Secret/SCI Eligibility Clearance
• At least six (6+) years of data analysis experience
• Possess strong statistical and analytical knowledge
• Proficient communication, problem-solving, and critical thinking skills
• Bachelor’s degree in related field OR in lieu of degree, 4 additional years of experience

Preferred:
• UAM (User Activity Monitoring) experience
• M&S Consulting proactively fulfills its role as an equal opportunity employer. We do not discriminate against any employee or applicant for employment because of race, color, sex, religion, age, sexual orientation, gender identity and expression, national origin, marital status, physical or mental disability, status as a protected veteran, or any other characteristic protected by law.",,2025-07-25,"['Candidate must possess an active Top Secret/SCI Eligible clearance', 'Active Top Secret/SCI Eligibility Clearance', 'At least six (6+) years of data analysis experience', 'Possess strong statistical and analytical knowledge', 'Proficient communication, problem-solving, and critical thinking skills', 'Bachelor’s degree in related field OR in lieu of degree, 4 additional years of experience']","['The Data Analyst will perform analysis on relevant information from a variety of sources to prepare documents, reports, summaries and replies to inquiries, ensuring accuracy and proper format of the information provided', 'The candidate will manage the compilation, cataloging, caching, distribution, and retrieval of data', 'The successful candidate will participate in Ad hoc data projects and analyses that produce actionable recommendations that build relevant insights for internal and external stakeholders', 'The Data Analyst will collect data and run basic reports in response to client inquiries, work closely with key internal stakeholders to ensure sound knowledge of client requirements to support development of best-in-class analytical solutions, and accurately enter required data into one or more databases, documents and/or spreadsheets']",True,[],,"['Data Analysis', 'Data Management', 'Ad Hoc Data Projects', 'Reporting', 'Statistical and Analytical Knowledge']","Data Analysis: Perform analysis on relevant information from various sources to prepare accurate documents, reports, summaries, and replies to inquiries.; Data Management: Manage the compilation, cataloging, caching, distribution, and retrieval of data to support organizational needs.; Ad Hoc Data Projects: Participate in ad hoc data projects and analyses that produce actionable recommendations and build relevant insights for internal and external stakeholders.; Reporting: Collect data and run basic reports in response to client inquiries to support decision-making and client requirements.; Statistical and Analytical Knowledge: Apply strong statistical and analytical knowledge to analyze data effectively and support problem-solving and critical thinking."
_rU6sFGYh2fmCHkCAAAAAA==,"Sr Business Information Mgmt Analyst (""Credit Card"") - Excel/SQL/Tableau/Python/Jira","Work Location:
Mount Laurel, New Jersey, United States of America

Hours:
40

Pay Details:
$68,640 - $112,320 USD

TD is committed to providing fair and equitable compensation opportunities to all colleagues. Growth opportunities and skill development are defining features of the colleague experience at TD. Our compensation policies and practices have been designed to allow colleagues to progress through the salary range over time as they progress in their role. The base pay actually offered may vary based upon the candidate's skills and experience, job-related knowledge, geographic location, and other specific business and organizational needs.

As a candidate, you are encouraged to ask compensation related questions and have an open dialogue with your recruiter who can provide you more specific details for this role.

Line of Business:
Data & Analytics

Job Description:

The Senior Business Information Management Analyst (US) provides business technical leadership across a broad range of information management functions to support the various areas of data and analytics. Works independently as a senior lead and may manage and direct activities related to analysis, design and support of business data management solutions on various projects ranging up to larger projects.

Position Overview:

This position will support the US DMO (Data Management Office) in executing on the Initiative Data Management team's mandate for the Consumer Banking ""Credit Card"" Portfolios:
• Work on complex business information management initiatives for a key business/functional area that may have enterprise wide scope
• Provide expertise within the specialized field and/or other data management functions that support business needs
• Work closely with cross functional teams to ensure the implementation of data management processes and enforce data governance policies to meet specific project needs, regulatory requirements and best practices
• Support the development of presentations /communications of data quality results
• Understand department objectives and contribute by supporting data management activities
• Support the management of data in accordance with the Enterprise Data Policy, Standards and Strategy/ Enterprise Data Management Office (EDMO) Standards
• Support data related activities and analysis on business projects and initiatives
• Data mapping, understanding flow of data from source to target systems, Well versed with process flows
• Assess current capabilities and high-level business requirements and apply technical background/understanding in the development of system requirements and functional documents
• Work in close partnership with business partners / technology / project teams and stakeholders to plan, elicit, analyze, document, communicate and manage detailed functional specifications

Depth & Scope:
• Expert level professional role, considered subject matter expert with in-depth knowledge / expertise in own domain / field of specialty and working knowledge of broader related areas
• Requires expert level conceptual and practical knowledge for own area of specialty and knowledge of broader related areas
• Advanced analytical and problem solving skills and fluent in one or two programming language
• Works autonomously on a range of tasks and may be relied upon to coach / educate others
• Lead projects of moderately to complex risk and resource requirements; may lead end-to-end processes or functional programs
• In-depth experience working with very large datasets and familiarity with big data technologies
• Keeps abreast of rapid business and technology innovation within business information management field
• Familiar with visualization tools
• Analyzes, designs, develops data repositories, warehouses and marts, data movement, data wrangling, data mapping and transformation (ETL) processes
• Supports solutions, applications, platforms, and/or tools that are leveraged across all functional groups (e.g., Data Scientists, Business Insights & Analytics, etc.)
• May also be responsible for developing sophisticated data preparation frameworks and architecture to create or modify data features for consumption by Data Scientists
• Supports data modeling capabilities in order to structure business data to be consumed / translated into a variety of novel capacities
• Supports business teams in the use and understanding of the data and reporting solutions
• Develops data road map/information management strategies and corresponding technical solutions on integrating, transforming, and/or managing data
• Drives data-centric solution development focusing on complex data integration
• Adopts the Enterprise Data model in alignment with direction from the OCDO and other data & analytics functional groups
• Solicits, analyzes, and understands data requirements (i.e., using market research, requirements gathering, feature planning, user experience / design considerations, etc.) to enable development of information management solutions

Education & Experience:
• Undergraduate degree or Technical Certificate
• 5+ years of relevant experience from a business administration, statistical, mathematical, scientific or financial background
• Proficient knowledge of various data sources, tools and technologies used in preparing summaries and reports
• Analytical and problem solving skills are required to interpret data and draw conclusions
• Knowledge of current and emerging competitor and market trends
• Skill in using analytical software tools, data analysis methods and reporting techniques
• Skill in mentoring/coaching others
• Skill in using computer applications including MS Office
• Ability to communicate effectively in both oral and written form
• Ability to work collaboratively and build relationships
• Ability to work successfully as a member of a team and independently
• Ability to exercise sound judgement in making decisions
• Ability to analyze, organize and prioritize work while meeting multiple deadlines
• Ability to handle confidential information with discretion

Preferred Qualifications:
• Candidates with 2+ years of relevant data experience will be considered
• Experience within the Banking/Financial Services Industry (Consumer banking ""Credit Card"" product business knowledge strongly preferred)
• Experience with Data Risk Management, Data Quality, Data Risk Identification and controls, Data Governance, Data lineage (data mapping, data tracing end to end), Data Transformation, Metadata, etc.
• Familiarity and ability to understand technical architecture/ architecture blueprint and design documentation
• Knowledge of program/project delivery methodologies (Risk/Audit experience is helpful but not required)
• Familiar with business requirements and alignment to technical delivery solutions
• Familiar with Process Controls (identification or testing of controls)
• Communicate effectively with project stakeholders to understand their data needs, address concerns and provide insights
• Self-motivated and driven, forward thinking individual with ability to perform a task with minimal supervision
• MS Office Suite Skills (including Excel/PowerPoint)
• Ability to read SQL/Python or other programming languages
• Data Visualization/Dashboard Development Skills (Tableau/PowerBI)
• Cloud experience preferred (Databricks/Azure)
• Experience with Agile Methodologies a plus
• Experience with Jira/Confluence/ServiceNow

Customer Accountabilities:
• Analyzes and understands business and data requirements to develop complete business solutions, including data models (entity relationship diagrams, dimensional data models) and business rules, data life-cycle management, governance, lineage, metadata and reporting elements.
• Applies automation and innovation on data platforms and on-going on any new development projects / initiatives aligned to business or organizational strategies
• Designs and implements complex business data information management frameworks to provide a solution that meets business requirements
• Collaborates with technology and business partners to resolve issues and ensure requirements and established SLAs
• Works closely with various technology/project teams to understand business data and provide analysis and requirements to ensure the data design / development initiatives are in line with the planned design and standards

Shareholder Accountabilities:
• Works with other various partners/ stakeholders to ensure project success
• Develops business requirements by researching / analyzing and documenting business data requirements
• Provides expert guidance within projects and other various change initiatives to support data impact assessments and data risk mitigation
• Implements processes aligned to data information management standards and ensure data quality (e.g., rules / thresholds / assessments, etc.) and requirements are developed
• Develops and maintains knowledge of data available from upstream sources and data within various platforms
• Identifies critical data / critical data elements to support Business Segment data governance and/or data management frameworks / programs
• May be responsible to understand and utilize business information management data deliverables
• Ensures business data and information is retained and disposed in compliance with enterprise data standards, policies and guidelines
• Performs data profiling using TD tooling and ad hoc system query languages to validate data analysis
• Provides support throughout data lifecycle to resolve data issues and support user community by helping users interpret the data
• Leads the investigation of root causes for data issues and ensure data issues are resolved
• Identifies and/or define knowledge transfer and data expertise activities to support business teams using the information management solutions.
• Adheres to enterprise frameworks or methodologies that relate to data activities for business area
• Ensures business operations follow applicable internal and external requirements (e.g. financial controls, segregation of duties, transaction approvals and physical control of assets)
• Participates in cross-functional / enterprise / initiatives as a subject matter expert helping to identify risk / provide guidance for complex situations
• Conducts meaningful analysis at the functional or enterprise level using results to draw conclusions, make recommendations, assess the effectiveness of programs/ policies/ practices
• Keeps abreast of emerging issues, trends, and evolving regulatory requirements and assess potential impacts
• Maintains a culture of risk management and control, supported by effective processes in alignment with risk appetite

Employee/Team Accountabilities:
• Participates fully as a member of the team, support a positive work environment that promotes service to the business, quality, innovation and teamwork and ensure timely communication of issues/ points of interest
• Provides industry knowledge for own area of expertise and participate in knowledge transfer within the team and business unit
• Keeps current on emerging trends/ developments and grow knowledge of the business, related tools and techniques
• Participates in personal performance management and development activities, including cross training within own team
• Keeps others informed and up-to-date about the status / progress of projects and / or all relevant or useful information related to day-to-day activities
• Contributes to team development of skills and capabilities through mentorship of others, by sharing knowledge and experiences and leveraging best practices.
• Leads, motivates and develops relationships with internal and external business partners / stakeholders to develop productive working relationships.
• Contributes to a fair, positive and equitable environment that supports a diverse workforce
• Acts as a brand ambassador for your business area/function and the bank, both internally and/or externally

Physical Requirements:

Never: 0%; Occasional: 1-33%; Frequent: 34-66%; Continuous: 67-100%
• Domestic Travel - Occasional
• International Travel - Never
• Performing sedentary work - Continuous
• Performing multiple tasks - Continuous
• Operating standard office equipment - Continuous
• Responding quickly to sounds - Occasional
• Sitting - Continuous
• Standing - Occasional
• Walking - Occasional
• Moving safely in confined spaces - Occasional
• Lifting/Carrying (under 25 lbs.) - Occasional
• Lifting/Carrying (over 25 lbs.) - Never
• Squatting - Occasional
• Bending - Occasional
• Kneeling - Never
• Crawling - Never
• Climbing - Never
• Reaching overhead - Never
• Reaching forward - Occasional
• Pushing - Never
• Pulling - Never
• Twisting - Never
• Concentrating for long periods of time - Continuous
• Applying common sense to deal with problems involving standardized situations - Continuous
• Reading, writing and comprehending instructions - Continuous
• Adding, subtracting, multiplying and dividing - Continuous

The above statements are intended to describe the general nature and level of work being performed by people assigned to this job. They are not intended to be an exhaustive list of all responsibilities, duties and skills required. The listed or specified responsibilities & duties are considered essential functions for ADA purposes.

Who We Are:
TD is one of the world's leading global financial institutions and is the fifth largest bank in North America by branches/stores. Every day, we deliver legendary customer experiences to over 27 million households and businesses in Canada, the United States and around the world. More than 95,000 TD colleagues bring their skills, talent, and creativity to the Bank, those we serve, and the economies we support. We are guided by our vision to Be the Better Bank and our purpose to enrich the lives of our customers, communities and colleagues.

TD is de...",2025-07-21T00:00:00.000Z,2025-07-25,"['Requires expert level conceptual and practical knowledge for own area of specialty and knowledge of broader related areas', 'Advanced analytical and problem solving skills and fluent in one or two programming language', 'Lead projects of moderately to complex risk and resource requirements; may lead end-to-end processes or functional programs', 'In-depth experience working with very large datasets and familiarity with big data technologies', 'Keeps abreast of rapid business and technology innovation within business information management field', 'Familiar with visualization tools', 'Undergraduate degree or Technical Certificate', '5+ years of relevant experience from a business administration, statistical, mathematical, scientific or financial background', 'Proficient knowledge of various data sources, tools and technologies used in preparing summaries and reports', 'Analytical and problem solving skills are required to interpret data and draw conclusions', 'Knowledge of current and emerging competitor and market trends', 'Skill in using analytical software tools, data analysis methods and reporting techniques', 'Skill in mentoring/coaching others', 'Skill in using computer applications including MS Office', 'Ability to communicate effectively in both oral and written form', 'Ability to work collaboratively and build relationships', 'Ability to work successfully as a member of a team and independently', 'Ability to exercise sound judgement in making decisions', 'Ability to analyze, organize and prioritize work while meeting multiple deadlines', 'Ability to handle confidential information with discretion', 'Lifting/Carrying (under 25 lbs.)', 'Lifting/Carrying (over 25 lbs.)', 'Twisting - Never', 'Concentrating for long periods of time - Continuous', 'Applying common sense to deal with problems involving standardized situations - Continuous']","['Works independently as a senior lead and may manage and direct activities related to analysis, design and support of business data management solutions on various projects ranging up to larger projects', 'This position will support the US DMO (Data Management Office) in executing on the Initiative Data Management team\'s mandate for the Consumer Banking ""Credit Card"" Portfolios:', 'Work on complex business information management initiatives for a key business/functional area that may have enterprise wide scope', 'Provide expertise within the specialized field and/or other data management functions that support business needs', 'Work closely with cross functional teams to ensure the implementation of data management processes and enforce data governance policies to meet specific project needs, regulatory requirements and best practices', 'Support the development of presentations /communications of data quality results', 'Understand department objectives and contribute by supporting data management activities', 'Support the management of data in accordance with the Enterprise Data Policy, Standards and Strategy/ Enterprise Data Management Office (EDMO) Standards', 'Support data related activities and analysis on business projects and initiatives', 'Data mapping, understanding flow of data from source to target systems, Well versed with process flows', 'Assess current capabilities and high-level business requirements and apply technical background/understanding in the development of system requirements and functional documents', 'Work in close partnership with business partners / technology / project teams and stakeholders to plan, elicit, analyze, document, communicate and manage detailed functional specifications', 'Expert level professional role, considered subject matter expert with in-depth knowledge / expertise in own domain / field of specialty and working knowledge of broader related areas', 'Works autonomously on a range of tasks and may be relied upon to coach / educate others', 'Analyzes, designs, develops data repositories, warehouses and marts, data movement, data wrangling, data mapping and transformation (ETL) processes', 'Supports solutions, applications, platforms, and/or tools that are leveraged across all functional groups (e.g., Data Scientists, Business Insights & Analytics, etc.)', 'May also be responsible for developing sophisticated data preparation frameworks and architecture to create or modify data features for consumption by Data Scientists', 'Supports data modeling capabilities in order to structure business data to be consumed / translated into a variety of novel capacities', 'Supports business teams in the use and understanding of the data and reporting solutions', 'Develops data road map/information management strategies and corresponding technical solutions on integrating, transforming, and/or managing data', 'Drives data-centric solution development focusing on complex data integration', 'Adopts the Enterprise Data model in alignment with direction from the OCDO and other data & analytics functional groups', 'Solicits, analyzes, and understands data requirements (i.e., using market research, requirements gathering, feature planning, user experience / design considerations, etc.)', 'to enable development of information management solutions', 'Analyzes and understands business and data requirements to develop complete business solutions, including data models (entity relationship diagrams, dimensional data models) and business rules, data life-cycle management, governance, lineage, metadata and reporting elements', 'Applies automation and innovation on data platforms and on-going on any new development projects / initiatives aligned to business or organizational strategies', 'Designs and implements complex business data information management frameworks to provide a solution that meets business requirements', 'Collaborates with technology and business partners to resolve issues and ensure requirements and established SLAs', 'Works closely with various technology/project teams to understand business data and provide analysis and requirements to ensure the data design / development initiatives are in line with the planned design and standards', 'Works with other various partners/ stakeholders to ensure project success', 'Develops business requirements by researching / analyzing and documenting business data requirements', 'Provides expert guidance within projects and other various change initiatives to support data impact assessments and data risk mitigation', 'Implements processes aligned to data information management standards and ensure data quality (e.g., rules / thresholds / assessments, etc.) and requirements are developed', 'Develops and maintains knowledge of data available from upstream sources and data within various platforms', 'Identifies critical data / critical data elements to support Business Segment data governance and/or data management frameworks / programs', 'May be responsible to understand and utilize business information management data deliverables', 'Ensures business data and information is retained and disposed in compliance with enterprise data standards, policies and guidelines', 'Performs data profiling using TD tooling and ad hoc system query languages to validate data analysis', 'Provides support throughout data lifecycle to resolve data issues and support user community by helping users interpret the data', 'Leads the investigation of root causes for data issues and ensure data issues are resolved', 'Identifies and/or define knowledge transfer and data expertise activities to support business teams using the information management solutions', 'Adheres to enterprise frameworks or methodologies that relate to data activities for business area', 'Ensures business operations follow applicable internal and external requirements (e.g. financial controls, segregation of duties, transaction approvals and physical control of assets)', 'Participates in cross-functional / enterprise / initiatives as a subject matter expert helping to identify risk / provide guidance for complex situations', 'Conducts meaningful analysis at the functional or enterprise level using results to draw conclusions, make recommendations, assess the effectiveness of programs/ policies/ practices', 'Keeps abreast of emerging issues, trends, and evolving regulatory requirements and assess potential impacts', 'Maintains a culture of risk management and control, supported by effective processes in alignment with risk appetite', 'Participates fully as a member of the team, support a positive work environment that promotes service to the business, quality, innovation and teamwork and ensure timely communication of issues/ points of interest', 'Provides industry knowledge for own area of expertise and participate in knowledge transfer within the team and business unit', 'Keeps current on emerging trends/ developments and grow knowledge of the business, related tools and techniques', 'Participates in personal performance management and development activities, including cross training within own team', 'Keeps others informed and up-to-date about the status / progress of projects and / or all relevant or useful information related to day-to-day activities', 'Contributes to team development of skills and capabilities through mentorship of others, by sharing knowledge and experiences and leveraging best practices', 'Leads, motivates and develops relationships with internal and external business partners / stakeholders to develop productive working relationships', 'Contributes to a fair, positive and equitable environment that supports a diverse workforce', 'Acts as a brand ambassador for your business area/function and the bank, both internally and/or externally', 'Never: 0%; Occasional: 1-33%; Frequent: 34-66%; Continuous: 67-100%', 'Performing sedentary work - Continuous', 'Performing multiple tasks - Continuous', 'Operating standard office equipment - Continuous', 'Responding quickly to sounds - Occasional', 'Sitting - Continuous', 'Standing - Occasional', 'Walking - Occasional', 'Moving safely in confined spaces - Occasional', 'Occasional', 'Squatting - Occasional', 'Bending - Occasional', 'Kneeling - Never', 'Reading, writing and comprehending instructions - Continuous', 'Adding, subtracting, multiplying and dividing - Continuous']",True,[],,"['Data Management', 'Data Analysis', 'Data Modeling', 'ETL (Extract, Transform, Load)', 'Data Visualization', 'SQL', 'Python', 'Big Data Technologies', 'Data Governance', 'Data Integration', 'Data Preparation', 'Data Roadmap and Strategy', 'Business Intelligence (BI) Tools', 'Agile Methodologies', 'Data Risk Management', 'Data Lifecycle Management', 'Data Profiling', 'Metadata Management', 'Process Flows and Data Mapping', 'Cloud Platforms', 'Programming Languages', 'Data Repositories and Warehouses']","Data Management: Supports and leads business data management initiatives including data governance, data quality, data risk management, data lineage, metadata management, and data lifecycle management to meet regulatory requirements and business needs.; Data Analysis: Performs data profiling, data analysis, and interpretation using various tools and methods to validate data quality, draw conclusions, and support business projects and initiatives.; Data Modeling: Develops and supports data models such as entity relationship diagrams and dimensional data models to structure business data for consumption and reporting.; ETL (Extract, Transform, Load): Designs, develops, and supports data movement, data wrangling, data mapping, and transformation processes to integrate and prepare data for business use.; Data Visualization: Utilizes visualization tools like Tableau and Power BI to develop dashboards and reporting solutions that support business insights and data understanding.; SQL: Reads and writes SQL queries to extract, manipulate, and analyze data from various data sources as part of data profiling and reporting activities.; Python: Uses Python programming language for data analysis, scripting, and supporting data preparation frameworks for data scientists.; Big Data Technologies: Has familiarity with big data technologies and works with very large datasets to support data management and analytics solutions.; Data Governance: Implements and enforces data governance policies, standards, and controls to ensure data quality, compliance, and risk mitigation.; Data Integration: Drives data-centric solution development focusing on complex data integration across multiple systems and platforms.; Data Preparation: Develops sophisticated data preparation frameworks and architectures to create or modify data features for consumption by data scientists.; Data Roadmap and Strategy: Develops data roadmaps and information management strategies aligned with enterprise data policies and standards.; Business Intelligence (BI) Tools: Supports business teams in the use and understanding of BI tools and reporting solutions to enable data-driven decision making.; Agile Methodologies: Familiar with Agile project delivery methodologies to support data and analytics projects.; Data Risk Management: Provides expert guidance on data risk identification, mitigation, and controls within data management frameworks.; Data Lifecycle Management: Ensures business data and information are retained and disposed of in compliance with enterprise data standards and policies.; Data Profiling: Performs data profiling using proprietary tooling and ad hoc query languages to validate and assess data quality.; Metadata Management: Manages metadata to support data governance, lineage, and reporting requirements.; Process Flows and Data Mapping: Understands and documents data flow from source to target systems, including process flows and data mapping for lineage and transformation.; Cloud Platforms: Experience with cloud platforms such as Databricks and Azure to support data management and analytics solutions.; Programming Languages: Fluent in one or two programming languages, including Python and SQL, to support data analysis and solution development.; Data Repositories and Warehouses: Analyzes, designs, and develops data repositories, warehouses, and marts to support business data storage and access."
t0BTf0IG5_6cNstRAAAAAA==,Senior Financial Data Analyst,"Welcome to Koch Industries, one of the largest privately held companies in the world. We are seeking a highly skilled and experienced Senior Financial Data Analyst to join our dynamic team. As a Senior Financial Data Analyst at Koch Industries, you will play a crucial role in analyzing and interpreting financial data to support our strategic decision-making. This is a unique opportunity to utilize your expertise and contribute to the success of a global company. We are looking for a dedicated individual with a strong financial background and a passion for data analysis. If you are a detail-oriented, analytical thinker with excellent communication skills, we encourage you to apply for this exciting position.
Conduct financial data analysis to identify trends, patterns, and insights to support strategic decision-making.
Utilize various data analysis tools and techniques to extract, clean, and transform complex financial data.
Collaborate with cross-functional teams to understand business objectives and provide financial insights and recommendations.
Develop and maintain financial reports and dashboards for senior leadership and stakeholders.
Conduct in-depth financial research and analysis on market trends, competitors, and industry benchmarks.
Monitor and track key performance indicators (KPIs) to identify potential risks and opportunities.
Identify and implement process improvements to enhance the accuracy and efficiency of financial data analysis.
Communicate complex financial information in a clear and concise manner to non-financial stakeholders.
Stay updated on industry trends, regulations, and best practices related to financial data analysis.
Provide training and mentorship to junior analysts to enhance their skills and knowledge.
Collaborate with IT teams to ensure data integrity and security.
Participate in financial planning and forecasting activities to support long-term strategic planning.
Prepare presentations and reports for executive leadership, board of directors, and investors.
Manage multiple projects and prioritize tasks to meet deadlines and deliver high-quality work.
Adhere to ethical and professional standards in all financial data analysis and reporting.

Koch Industries is an Equal Opportunity Employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. We do not discriminate based upon race, religion, color, national origin, sex, sexual orientation, gender identity, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.",,2025-07-25,"['If you are a detail-oriented, analytical thinker with excellent communication skills, we encourage you to apply for this exciting position']","['Conduct financial data analysis to identify trends, patterns, and insights to support strategic decision-making', 'Utilize various data analysis tools and techniques to extract, clean, and transform complex financial data', 'Collaborate with cross-functional teams to understand business objectives and provide financial insights and recommendations', 'Develop and maintain financial reports and dashboards for senior leadership and stakeholders', 'Conduct in-depth financial research and analysis on market trends, competitors, and industry benchmarks', 'Monitor and track key performance indicators (KPIs) to identify potential risks and opportunities', 'Identify and implement process improvements to enhance the accuracy and efficiency of financial data analysis', 'Communicate complex financial information in a clear and concise manner to non-financial stakeholders', 'Stay updated on industry trends, regulations, and best practices related to financial data analysis', 'Provide training and mentorship to junior analysts to enhance their skills and knowledge', 'Collaborate with IT teams to ensure data integrity and security', 'Participate in financial planning and forecasting activities to support long-term strategic planning', 'Prepare presentations and reports for executive leadership, board of directors, and investors', 'Manage multiple projects and prioritize tasks to meet deadlines and deliver high-quality work', 'Adhere to ethical and professional standards in all financial data analysis and reporting']",False,,,,
c65hTLkZsP0-LLNjAAAAAA==,Analyst - Leadership & Change Analytics (LCA),"Company:
Oliver Wyman

Description:

Job specification

Job title: Analyst - Leadership & Change Analytics (LCA)

Department: Oliver Wyman Mergers & Acquisitions

Office/region: Boston, MA

Eligibility: Permanent US work authorization

About Oliver Wyman

Oliver Wyman is a global leader in management consulting. With offices in 60 cities across 29 countries, Oliver Wyman combines deep industry knowledge with specialized expertise in strategy, operations, risk management, and organization transformation. The firm has more than 5,000 professionals around the world who work with clients to optimize their business, improve their operations and risk profile, and accelerate their organizational performance to seize the most attractive opportunities. Oliver Wyman is a wholly owned subsidiary of Marsh & McLennan Companies [NYSE: MMC]. For more information, visit www.oliverwyman.com

Team overview:

Oliver Wyman's Leadership and Change Analytics unit is an innovative, fast-growing team of data scientists and organizational change specialists. Organized as part of our cross-industry Mergers and Acquisitions (M&A) practice, we bring sophisticated expertise in behavioral science and people analytics capabilities to bear on business-critical problems for our clients that span industries.

Clients hire us for our depth of insight and expertise; expertise that comes from a combination of specialized domain knowledge in organizational behavior and deep data science and engineering capabilities. We combine analytical rigor and rapid innovation with a relentless focus on client impact. We are passionate about developing our people and support your career progression, including a path to partner. We are looking for candidates who are excited to work in a collaborative, entrepreneurial, and learning-oriented environment, focused on delivering impact through analytics.

The role:

Working with us offers excellent career and growth opportunities for highly motivated early career and college graduates from quantitative disciplines with some exposure to data engineering, business analytics, and/or quantitative social science.

This role offers a mix of research and asset innovation as well as client-facing, project-based analytics. Some travel to client sites is to be expected as part of building client relationships and setting projects on a solid foundation, but most of our work can be conducted from Boston. We will make flexible working hours and market leading work life balance a priority considering your individual needs, however, we require all employees to work in person with their colleagues for a part of each week.

The ideal candidates will possess strong technical skills, capability to work in teams, a strong learning orientation, the ability deliver work efficiently and under high quality standards and have an open and flexible mindset. Must be based in Boston, MA.

Responsibilities will include:
• You will work as part of our small, fast-growing team, in coordination with other Oliver Wyman teams and clients across the globe
• You will work with large and complex datasets producing customized analyses and advanced models using statistical techniques for the client's needs
• You will be given ownership of the model and application development or validation from start to finish with guidance from experienced managers
• You will work on summarizing, presenting and documenting the performed analyses and features of the developed solutions in client-ready formats

Required skills and experience:
• A Bachelor's or Master's degree in a quantitative discipline, e.g. Business Analytics, Data Engineering, Data Science, Computer Science or Engineering, Mathematics, or Statistics
• Strong engineering, analytics, problem solving, and communication skills
• Experience in advanced analytics and data manipulation - e.g. R, SQL, Python preferred
• Experience to work effectively and collaboratively in a team, while being sufficiently self-directed to meet deadlines and produce high-quality output when working independently
• Be able to find innovative, practical and creative solutions to organizational and business issues
• Excellent command of English language (verbal and written)

Compensation: $80,000 annually

Master's student: $85,000 annually

Oliver Wyman, a business of Marsh McLennan (NYSE: MMC), is a management consulting firm combining deep industry knowledge with specialized expertise to help clients optimize their business, improve operations and accelerate performance. Marsh McLennan is a global leader in risk, strategy and people, advising clients in 130 countries across four businesses: Marsh, Guy Carpenter, Mercer and Oliver Wyman. With annual revenue of $24 billion and more than 90,000 colleagues, Marsh McLennan helps build the confidence to thrive through the power of perspective. For more information, visit oliverwyman.com, or follow on LinkedIn and X.

Marsh McLennan is committed to embracing a diverse, inclusive and flexible work environment. We aim to attract and retain the best people and embrace diversity of age background, disability, ethnic origin, family duties, gender orientation or expression, marital status, nationality, parental status, personal or social status, political affiliation, race, religion and beliefs, sex/gender, sexual orientation or expression, skin color, veteran status (including protected veterans), or any other characteristic protected by applicable law. If you have a need that requires accommodation, please let us know by contacting reasonableaccommodations@mmc.com.

Marsh McLennan is committed to hybrid work, which includes the flexibility of working remotely and the collaboration, connections and professional development benefits of working together in the office. All Marsh McLennan colleagues are expected to be in their local office or working onsite with clients at least three days per week. Office-based teams will identify at least one ""anchor day"" per week on which their full team will be together in person.",2025-07-10T00:00:00.000Z,2025-07-25,"['Clients hire us for our depth of insight and expertise; expertise that comes from a combination of specialized domain knowledge in organizational behavior and deep data science and engineering capabilities', 'The ideal candidates will possess strong technical skills, capability to work in teams, a strong learning orientation, the ability deliver work efficiently and under high quality standards and have an open and flexible mindset', 'Must be based in Boston, MA', ""A Bachelor's or Master's degree in a quantitative discipline, e.g. Business Analytics, Data Engineering, Data Science, Computer Science or Engineering, Mathematics, or Statistics"", 'Strong engineering, analytics, problem solving, and communication skills', 'Experience to work effectively and collaboratively in a team, while being sufficiently self-directed to meet deadlines and produce high-quality output when working independently', 'Be able to find innovative, practical and creative solutions to organizational and business issues', 'Excellent command of English language (verbal and written)']","['Working with us offers excellent career and growth opportunities for highly motivated early career and college graduates from quantitative disciplines with some exposure to data engineering, business analytics, and/or quantitative social science', 'This role offers a mix of research and asset innovation as well as client-facing, project-based analytics', 'Some travel to client sites is to be expected as part of building client relationships and setting projects on a solid foundation, but most of our work can be conducted from Boston', 'We will make flexible working hours and market leading work life balance a priority considering your individual needs, however, we require all employees to work in person with their colleagues for a part of each week', 'You will work as part of our small, fast-growing team, in coordination with other Oliver Wyman teams and clients across the globe', ""You will work with large and complex datasets producing customized analyses and advanced models using statistical techniques for the client's needs"", 'You will be given ownership of the model and application development or validation from start to finish with guidance from experienced managers', 'You will work on summarizing, presenting and documenting the performed analyses and features of the developed solutions in client-ready formats']",True,[],,"['Statistical Techniques', 'Data Engineering', 'Business Analytics', 'Python', 'R', 'SQL']","Statistical Techniques: Used to produce customized analyses and advanced models tailored to client needs involving large and complex datasets.; Data Engineering: Involves working with data pipelines and managing data infrastructure as part of the role's exposure and responsibilities.; Business Analytics: Applied to analyze organizational and business issues, supporting client-facing project-based analytics and research innovation.; Python: Preferred programming language for advanced analytics and data manipulation tasks within the role.; R: Preferred programming language for advanced analytics and data manipulation tasks within the role.; SQL: Preferred programming language for advanced analytics and data manipulation tasks within the role."
ZDb9DQ2dBOAn6CYzAAAAAA==,Senior Level Data Analyst​/Shipping Logistics​/Sigma Computing​/SQL​/dbt,"Senior Level Data Analyst / Shipping Logistics / Sigma Computing / SQL / dbt

Join to apply for the Senior Level Data Analyst / Shipping Logistics / Sigma Computing / SQL / dbt role at Motion Recruitment
Senior Level Data Analyst / Shipping Logistics / Sigma Computing / SQL / dbt

Join to apply for the Senior Level Data Analyst / Shipping Logistics / Sigma Computing / SQL / dbt role at Motion Recruitment

Our client is a leader in shipping & logistics specializing in container freight and supply chain solutions. Based in Culver City, CA, they provide innovative and efficient freight forwarding services to global clients. As they continue to scale their data infrastructure, they are seeking a skilled Data Analyst with expertise in SQL, DBT and Sigma Computing to join their team. If you’re passionate about data, logistics, and optimizing product development to improve business operations, they invite you to be a part of their growing team!

We’re looking for a Data Analyst with strong business and product acumen to join our growing team. This role is ideal for someone who thrives on uncovering insights that shape product direction, inform operations, and enhance customer experience. You will be instrumental in converting complex logistics data into clear, actionable recommendations, enabling better decisions across product, operations, and business strategy.

Required Skills & Experience
• 3+ years in a Data Analyst or Product Analyst role, preferably in logistics, supply chain, transportation, or tech
• Proficient in SQL for complex data exploration and transformation
• Hands-on experience with dbt for building modular, version-controlled data pipelines
• Strong experience using Sigma Computing to build and manage dashboards
• Demonstrated ability to turn ambiguous problems into clear analytical questions and actionable insights
• Deep understanding of how product features and operational processes impact performance
• Excellent communication skills with the ability to translate data into stories for both technical and non-technical audiences
What You Will Be Doing Tech Breakdown
• 100% Data Analyst (SQL, dbt, Sigma Computing, and Snowflake)
Daily Responsibilities
• Collaborate cross-functionally with Product, Operations, and Engineering teams to identify key business questions and deliver data-driven insights
• Analyze logistics and operational data to evaluate performance, identify inefficiencies, and recommend improvements
• Design, build, and maintain robust data models using dbt to enable scalable, trusted analytics
• Write advanced SQL queries to explore trends in real-time shipment data, driver behavior, and port performance
• Create dynamic dashboards and visualizations in Sigma Computing to communicate findings and monitor KPIs across the organization
• Partner with product managers to design experiments, evaluate feature performance, and support roadmap planning with data
• Proactively surface insights that help the business optimize throughput, reduce dwell time, and improve service reliability
The Offer You Will Receive The Following Benefits
• Medical, Dental, and Vision Insurance
• Unlimited PTO
• Equity
Applicants must be currently authorized to work in the US on a full-time basis now and in the future.

Posted By: Connor Hart Seniority level
• Seniority level

Mid-Senior level
Employment type
• Employment type

Full-time
Job function
• Job function

Information Technology
• Industries Staffing and Recruiting

Referrals increase your chances of interviewing at Motion Recruitment by 2x
Sign in to set job alerts for “Senior Data Analyst” roles.

IT Business Analyst - Data Analysis & Reporting Business Data Analyst - Ambulatory Admin - Full Time 8 Hour Days (Exempt) (Non-Union)
Senior Level Data Analyst / Shipping Logistics / Sigma Computing / SQL / dbt Business Intelligence Analyst, Trust & Safety - USDS

Los Angeles, CA $-$ 2 weeks ago
Senior Level Data Analyst / Shipping Logistics / Sigma Computing / SQL / dbt

Los Angeles, CA $95,000.00-$ 2 weeks ago
Business Analyst, Creator Partnerships, You Tube Business Data Analyst - MSO Clinical Ops - Full Time 8 Hour Days (Exempt) (Non-Union)
Senior Business Systems Analyst (Workday)

Los Angeles Metropolitan Area $-$ 2 weeks ago
Business Analyst II, Prime Video Global Operations Business Analyst IT (Logistics & Supply Chain)
Senior Business Analyst, Workday Adaptive Planning

Los Angeles Metropolitan Area $90,000.00-$ 2 weeks ago
Business Analyst II (ALD) - Health Equity

Los Angeles, CA $77,265.00-$ 3 weeks ago
Senior Analyst, Disputes & eDiscovery - (Hybrid)

We’re unlocking community knowledge in a new way. Experts add insights directly into each article, started with the help of AI.
#J-18808-Ljbffr",2025-07-17T00:00:00.000Z,2025-07-25,"['3+ years in a Data Analyst or Product Analyst role, preferably in logistics, supply chain, transportation, or tech', 'Proficient in SQL for complex data exploration and transformation', 'Hands-on experience with dbt for building modular, version-controlled data pipelines', 'Strong experience using Sigma Computing to build and manage dashboards', 'Demonstrated ability to turn ambiguous problems into clear analytical questions and actionable insights', 'Deep understanding of how product features and operational processes impact performance', 'Excellent communication skills with the ability to translate data into stories for both technical and non-technical audiences', 'Applicants must be currently authorized to work in the US on a full-time basis now and in the future', 'IT Business Analyst - Data Analysis & Reporting Business Data Analyst - Ambulatory Admin - Full Time 8 Hour Days (Exempt) (Non-Union)', 'Senior Level Data Analyst / Shipping Logistics / Sigma Computing / SQL / dbt Business Intelligence Analyst, Trust & Safety - USDS', 'Senior Level Data Analyst / Shipping Logistics / Sigma Computing / SQL / dbt']","['This role is ideal for someone who thrives on uncovering insights that shape product direction, inform operations, and enhance customer experience', 'You will be instrumental in converting complex logistics data into clear, actionable recommendations, enabling better decisions across product, operations, and business strategy', 'What You Will Be Doing Tech Breakdown', '100% Data Analyst (SQL, dbt, Sigma Computing, and Snowflake)', 'Collaborate cross-functionally with Product, Operations, and Engineering teams to identify key business questions and deliver data-driven insights', 'Analyze logistics and operational data to evaluate performance, identify inefficiencies, and recommend improvements', 'Design, build, and maintain robust data models using dbt to enable scalable, trusted analytics', 'Write advanced SQL queries to explore trends in real-time shipment data, driver behavior, and port performance', 'Create dynamic dashboards and visualizations in Sigma Computing to communicate findings and monitor KPIs across the organization', 'Partner with product managers to design experiments, evaluate feature performance, and support roadmap planning with data', 'Proactively surface insights that help the business optimize throughput, reduce dwell time, and improve service reliability']",True,[],,"['SQL', 'dbt', 'Sigma Computing', 'Data Modeling', 'Data Analysis', 'Business Intelligence Dashboards', 'Experiment Design and Evaluation']","SQL: Used for complex data exploration and transformation, including writing advanced queries to analyze real-time shipment data, driver behavior, and port performance.; dbt: Used to design, build, and maintain modular, version-controlled data pipelines and robust data models that enable scalable and trusted analytics.; Sigma Computing: Used to build and manage dynamic dashboards and visualizations that communicate findings and monitor KPIs across the organization.; Data Modeling: Involves designing and maintaining robust data models using dbt to support scalable and trusted analytics.; Data Analysis: Includes analyzing logistics and operational data to evaluate performance, identify inefficiencies, and recommend improvements that inform product direction, operations, and business strategy.; Business Intelligence Dashboards: Creation and management of dashboards in Sigma Computing to visualize data insights and monitor key performance indicators.; Experiment Design and Evaluation: Partnering with product managers to design experiments, evaluate feature performance, and support roadmap planning using data-driven insights."
