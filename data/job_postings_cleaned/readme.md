# Data Outputs – Job Postings Cleaned

This folder contains all processed datasets generated by the pipeline.  
They are the **final CSV files** consumed directly by the Streamlit app, updated automatically each month by the GitHub Actions workflow.

---

## Files and Their Purpose

### 1. `data_scientist_us.csv`
- **Purpose:** Master dataset containing all job postings that passed the LLM classification as true Data Analyst or Data Scientist roles.
- **How it is generated:**
  1. **Fetching:** Job postings are retrieved via the JSearch API for multiple queries targeting DS/DA roles in the US.
  2. **Deduplication:** TF-IDF vectorization + cosine similarity (threshold ≥ 0.9) is used to remove near-duplicates, even if they have different `job_id`.
  3. **Classification:** An OpenRouter LLM determines if the posting truly fits a DS/DA scope, excluding roles like *Financial Analyst* or *Marketing Analyst* unless they involve data science/analytics tasks.
  4. **Enrichment:** AI/Data term extraction is applied to valid postings.
- **Usage:** Base dataset for any analysis. The app uses it to build both the AI mentions trends and the clustering.

---

### 2. `data_scientist_us_ai_enriched.csv`
- **Purpose:** Stores only the AI/Data mentions and details for valid DS/DA job postings.
- **How it is generated:**
  1. Subset of the valid jobs from `data_scientist_us.csv`.
  2. For each posting, the LLM detects:
     - **Data Mentions:** Traditional DS/ML/analytics stack (SQL, Pandas, regression models, etc.).
     - **AI Mentions:** Modern AI stack (LLMs, RAG, prompt engineering, transformers, etc.).
  3. Terms are **normalized** (e.g., “RAG pipelines” → “Retrieval-Augmented Generation”) and **deduplicated**.
  4. Explanations are merged to avoid redundant phrasing.
- **Usage:** Used by the AI Mentions Analysis tab to display:
  - % of postings mentioning AI
  - Top AI terms and their evolution
  - Context-specific explanations for each term

---

### 3. `data_scientist_us_classified.csv`
- **Purpose:** Binary classification results of whether a posting is a true DS/DA role.
- **How it is generated:**
  1. Each fetched job is sent to the classification LLM with title, description, qualifications, and responsibilities.
  2. Returns `true` if it fits DS/DA criteria, `false` otherwise.
  3. Saved separately so classification results can be reused without re-running the LLM.
- **Usage:** Allows tracking classification performance and debugging false positives/negatives without reprocessing the full dataset.

---

### 4. `df_result_base.csv`
- **Purpose:** Incremental dataset of **all valid jobs** after classification and enrichment, kept up to date with each monthly run.
- **How it is generated:**
  1. Combines historical valid postings with newly fetched valid postings.
  2. Ensures no duplicates by checking `job_id`.
  3. Includes all enrichment fields (AI/Data mentions and details).
- **Usage:** Direct source for AI Mentions Analysis in the Streamlit app.

---

### 5. `df_result_clusters.csv`
- **Purpose:** Clustered dataset of valid jobs with embeddings and cluster metadata.
- **How it is generated:**
  1. Filters valid jobs from `df_result_base.csv`.
  2. Combines Data and AI mentions into a feature string.
  3. Embeds the feature string using `all-MiniLM-L6-v2` from Hugging Face.
  4. Selects optimal *k* for KMeans clustering using silhouette score.
  5. Assigns cluster IDs, names, and descriptions generated by the LLM.
  6. Calculates the percentage share of each cluster.
- **Usage:** Powers the Job Cluster Explorer tab in the Streamlit app, including UMAP projections and cluster summaries.

---

## Update Cycle

All CSVs in this folder are regenerated or appended by:

    python utils/generate_all_datasets.py

This script is triggered by the monthly GitHub Actions run on the **28th**, aligned with the reset of the JSearch API free quota.  
Once updated, the Streamlit app reads these files directly without needing to re-run the pipeline.

---

## Notes

- Percentages shown in the app are **relative to the number of postings in the dataset**, not absolute counts from the job market, due to JSearch API monthly free limits.
- The AI/Data term extraction logic ensures that terms are context-specific to the role described, rather than generic definitions.
- Clustering metadata is stable across updates unless re-clustering logic is explicitly triggered.

---

