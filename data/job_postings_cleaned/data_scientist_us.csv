job_id,job_title,job_description,job_posted_at_datetime_utc,extraction_date,job_highlights.Qualifications,job_highlights.Responsibilities,is_valid_job,ai_mentions,ai_details,data_mentions,data_details
nFB7ISC3OFcsdxK7AAAAAA==,"Senior Manager, Data Science - US Card (Resiliency Intelligence)","Senior Manager, Data Science - US Card (Resiliency Intelligence)

Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making.

As a Data Scientist at Capital One, you’ll be part of a team that’s leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives.

Team Description

The Resiliency Intelligence team helps our customers regain financial stability and drive business value through personalized solutions at scale. This is crucially important for customers that encounter financial hardship and need personalized resources to resolve outstanding balances.

To achieve this, we use supervised and reinforcement learning models to predict customer needs and recommend optimal solutions. We write custom Python libraries and use open-source ML libraries like XGBoost, scikit-learn, and statsmodels. Our models define the treatment for millions of customers on a daily basis and your code will run in analytical and production environments.

Our team’s ML solutions meaningfully impact the income of the US Card business and are a key value generator for the company.

Role Description

In this role, you will:
• Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love
• Leverage a broad stack of technologies — Python, Kubernetes, AWS, H2O, Spark, and more — to reveal the insights hidden within huge volumes of numeric and textual data
• Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation
• Flex your interpersonal skills to translate the complexity of your work into tangible business goals

The Ideal Candidate is:
• Customer first. You love the process of analyzing and creating, but also share our passion to do the right thing. You know at the end of the day it’s about making the right decision for our customers.
• Creative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You’re not afraid to share a new idea.
• A leader. You challenge conventional thinking and work with stakeholders to identify and improve the status quo. You’re passionate about talent development for your own team and beyond.
• Technical. You’re comfortable with open-source languages and are passionate about developing further. You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms.

Basic Qualifications:
• Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:
• A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 7 years of experience performing data analytics
• A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 5 years of experience performing data analytics
• A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 2 years of experience performing data analytics
• At least 2 years of experience leveraging open source programming languages for large scale data analysis
• At least 2 years of experience working with machine learning
• At least 2 years of experience utilizing relational databases

Preferred Qualifications:
• PhD in “STEM” field (Science, Technology, Engineering, or Mathematics) plus 4 years of experience in data analytics
• At least 1 year of experience working with AWS
• At least 1 year of experience managing people
• At least 5 years’ experience in Python, Scala, or R for large scale data analysis
• At least 5 years’ experience with machine learning

Capital One will consider sponsoring a new qualified applicant for employment authorization for this position.

The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.

Cambridge, MA: $225,400 - $257,200 for Sr Mgr, Data Science

Chicago, IL: $204,900 - $233,800 for Sr Mgr, Data Science

McLean, VA: $225,400 - $257,200 for Sr Mgr, Data Science

New York, NY: $245,900 - $280,600 for Sr Mgr, Data Science

Richmond, VA: $204,900 - $233,800 for Sr Mgr, Data Science

Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate’s offer letter.

This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.

Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.

This role is expected to accept applications for a minimum of 5 business days.

No agencies please. Capital One is an equal opportunity employer (EOE, including disability/vet) committed to non-discrimination in compliance with applicable federal, state, and local laws. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",2025-07-23T00:00:00.000Z,2025-07-25,"['Customer first', 'You thrive on bringing definition to big, undefined problems', 'You love asking questions and pushing hard to find answers', 'You’re passionate about talent development for your own team and beyond', 'Technical', 'You’re comfortable with open-source languages and are passionate about developing further', 'You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms', 'Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:', ""A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 7 years of experience performing data analytics"", ""A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 5 years of experience performing data analytics"", 'A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 2 years of experience performing data analytics', 'At least 2 years of experience leveraging open source programming languages for large scale data analysis', 'At least 2 years of experience working with machine learning', 'At least 2 years of experience utilizing relational databases']","['This is crucially important for customers that encounter financial hardship and need personalized resources to resolve outstanding balances', 'To achieve this, we use supervised and reinforcement learning models to predict customer needs and recommend optimal solutions', 'We write custom Python libraries and use open-source ML libraries like XGBoost, scikit-learn, and statsmodels', 'Our models define the treatment for millions of customers on a daily basis and your code will run in analytical and production environments', 'Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love', 'Leverage a broad stack of technologies — Python, Kubernetes, AWS, H2O, Spark, and more — to reveal the insights hidden within huge volumes of numeric and textual data', 'Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation', 'Flex your interpersonal skills to translate the complexity of your work into tangible business goals', 'You challenge conventional thinking and work with stakeholders to identify and improve the status quo']",True,[],,"['Supervised Learning', 'Reinforcement Learning', 'Python', 'XGBoost', 'scikit-learn', 'statsmodels', 'Relational Databases', 'AWS', 'Kubernetes', 'H2O', 'Spark', 'Machine Learning']","Supervised Learning: Used to build predictive models that forecast customer needs and recommend optimal financial solutions.; Reinforcement Learning: Applied to develop models that optimize treatment strategies for customers facing financial hardship.; Python: Primary programming language used for developing custom data science libraries and machine learning models.; XGBoost: An open-source machine learning library used for building gradient boosting models in predictive analytics.; scikit-learn: Open-source ML library utilized for implementing various machine learning algorithms and model evaluation.; statsmodels: Library used for statistical modeling and hypothesis testing within the data science workflows.; Relational Databases: Used to manage and query large volumes of structured customer data for analysis and modeling.; AWS: Cloud computing platform leveraged to support scalable data processing and model deployment.; Kubernetes: Technology used to orchestrate containerized applications, including data science models in production.; H2O: Machine learning platform employed to build and deploy scalable predictive models.; Spark: Big data processing framework used to handle and analyze large-scale numeric and textual datasets.; Machine Learning: Core methodology for developing models that drive personalized financial solutions and business value."
XdrEhkRRuZAndmnAAAAAAA==,Sr. Data Scientist,"Job#: 2082495

Job Description:

REQUIRED QUALIFICATIONS
• Ability to read, write, speak and understand English
• Expert-level skills and experience with python, SQL, ESRI, Alteryx, Tableau, and/or other data visualization tools
• Advanced-level skills with one or more scripting, analysis, or ETL languages and ability to rapidly learn new languages or techniques
• Familiarity with modern machine learning technology and tools in order to produce model scoring code.
• Expert-level logical and analytic skills
• Broad experience and solid theoretical foundation of the properties of the major families of machine learning models (regression, decision trees, clustering, SVMs, neural networks).
• Command of advanced mathematical concepts including calculus, PDEs, probability, and statistics, and the ability to independently learn any necessary additional concepts
• Strong synthesis and presentation skills
• Ability to communicate results and recommendations to a wide variety of audiences
• Basic understanding of data architecture, data warehouse and data marts
• Demonstrated ability and desire to continually expand skill set, and learn from and teach others
• Extensive experience with large data sets and the tools to obtain, transform, and store data on Big Data and streaming services

Education
• Bachelors degree in computer science, statistics, operations research and/or equivalent combination of education and experience.

Related Work Experience Number of Years
• Data manipulation and statistical modeling as a Scientist, Consultant,
• Architect, DBA, or Engineer - 5+
• SQL/R/SAS Programming - 5+

PREFERRED QUALIFICATIONS
• Experience in the telecommunications industry, or two other consumer-based industries
• Experience applying various data analysis techniques across various languages, databases, and data sources.
• Operations-research background, in particular focused on large labor operations such as field ops, technical support, and sales
• Background with Cable systems and operations
• Experience with Hadoop, particularly HIVE and Spark
• Knowledge of other relevant tools such as SAS, SPSS, Alteryx, Linux
• Alteryx Certification is very desirable.
• Knowledge of other relevant techniques such as text analysis and text mining
• Familiarity with the open-source ecosystems surrounding R (CRAN), Python (PyPi), and/or Hadoop

EEO Employer

Apex Systems is an equal opportunity employer. We do not discriminate or allow discrimination on the basis of race, color, religion, creed, sex (including pregnancy, childbirth, breastfeeding, or related medical conditions), age, sexual orientation, gender identity, national origin, ancestry, citizenship, genetic information, registered domestic partner status, marital status, disability, status as a crime victim, protected veteran status, political affiliation, union membership, or any other characteristic protected by law. Apex will consider qualified applicants with criminal histories in a manner consistent with the requirements of applicable law. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation in using our website for a search or application, please contact our Employee Services Department at or .

Apex Systems is a world-class IT services company that serves thousands of clients across the globe. When you join Apex, you become part of a team that values innovation, collaboration, and continuous learning. We offer quality career resources, training, certifications, development opportunities, and a comprehensive benefits package. Our commitment to excellence is reflected in many awards, including ClearlyRated's Best of Staffing in Talent Satisfaction in the United States and Great Place to Work in the United Kingdom and Mexico.

Apex Benefits Overview: Apex offers a range of supplemental benefits, including medical, dental, vision, life, disability, and other insurance plans that offer an optional layer of financial protection. We offer an ESPP (employee stock purchase program) and a 401K program which allows you to contribute typically within 30 days of starting, with a company match after 12 months of tenure. Apex also offers a HSA (Health Savings Account on the HDHP plan), a SupportLinc Employee Assistance Program (EAP) with up to 8 free counseling sessions, a corporate discount savings program and other discounts. In terms of professional development, Apex hosts an on-demand training program, provides access to certification prep and a library of technical and leadership courses/books/seminars once you have 6+ months of tenure, and certification discounts and other perks to associations that include CompTIA and IIBA. Apex has a dedicated customer service team for our Consultants that can address questions around benefits and other resources, as well as a certified Career Coach. You can access a full list of our benefits, programs, support teams and resources within our 'Welcome Packet' as well, which an Apex team member can provide.",2025-07-22T00:00:00.000Z,2025-07-25,"['Ability to read, write, speak and understand English', 'Expert-level skills and experience with python, SQL, ESRI, Alteryx, Tableau, and/or other data visualization tools', 'Advanced-level skills with one or more scripting, analysis, or ETL languages and ability to rapidly learn new languages or techniques', 'Familiarity with modern machine learning technology and tools in order to produce model scoring code', 'Expert-level logical and analytic skills', 'Broad experience and solid theoretical foundation of the properties of the major families of machine learning models (regression, decision trees, clustering, SVMs, neural networks)', 'Command of advanced mathematical concepts including calculus, PDEs, probability, and statistics, and the ability to independently learn any necessary additional concepts', 'Strong synthesis and presentation skills', 'Ability to communicate results and recommendations to a wide variety of audiences', 'Basic understanding of data architecture, data warehouse and data marts', 'Demonstrated ability and desire to continually expand skill set, and learn from and teach others', 'Extensive experience with large data sets and the tools to obtain, transform, and store data on Big Data and streaming services', 'Bachelors degree in computer science, statistics, operations research and/or equivalent combination of education and experience', 'Related Work Experience Number of Years', 'Data manipulation and statistical modeling as a Scientist, Consultant,', 'Architect, DBA, or Engineer - 5+', 'SQL/R/SAS Programming - 5+']",,True,[],,"['Python', 'SQL', 'ESRI', 'Alteryx', 'Tableau', 'Scripting and ETL languages', 'Machine learning models', 'Advanced mathematics', 'Data architecture and warehousing', 'Big Data and streaming services', 'Hadoop ecosystem', 'R programming', 'SAS and SPSS', 'Text analysis and text mining']","Python: Used as a primary programming language for data manipulation, analysis, and building machine learning models.; SQL: Utilized for querying and managing data within relational databases.; ESRI: Applied for geographic information system (GIS) data analysis and spatial data visualization.; Alteryx: Used for data preparation, blending, and advanced analytics workflows.; Tableau: Employed to create interactive data visualizations and dashboards for communicating insights.; Scripting and ETL languages: Used to automate data extraction, transformation, and loading processes.; Machine learning models: Experience with regression, decision trees, clustering, support vector machines, and neural networks for predictive modeling and data analysis.; Advanced mathematics: Applied calculus, partial differential equations, probability, and statistics to support modeling and analysis.; Data architecture and warehousing: Understanding of data warehouses, data marts, and data storage structures to support analytics.; Big Data and streaming services: Experience handling large datasets and using tools to obtain, transform, and store data in big data environments.; Hadoop ecosystem: Utilized Hadoop tools such as Hive and Spark for distributed data processing and analytics.; R programming: Used for statistical analysis and data science tasks within the open-source ecosystem.; SAS and SPSS: Applied for statistical analysis and data management.; Text analysis and text mining: Techniques used to extract insights from unstructured text data."
vikyPvnmOOVrMK3UAAAAAA==,Senior Data Scientist,"Job Number: R0221820

Data Scientist, Senior
The Opportunity:

As a data scientist, you're excited at the prospect of unlocking the secrets held by a data set, and you're fascinated by the possibilities presented by IoT, machine learning, and artificial intelligence. In an increasingly connected world, massive amounts of structured and unstructured data open new opportunities. As a data scientist at Booz Allen, you can help turn these complex data sets into useful information to solve global challenges. Across private and public sectors-from fraud detection to cancer research to national intelligence-we need you to help find the answers in the data.

On our team, you'll use your leadership skills and data science expertise to create real-world impact. You'll work closely with clients to understand their questions and needs, and then dig into their data-rich environments to find the pieces of their information puzzle. You'll guide teammates and lead the development of algorithms and systems. You'll use the right combination of tools and frameworks to turn sets of disparate data points into objective answers to advise your clients as they make informed decisions. Ultimately, you'll provide a deep understanding of the data, what it all means, and how it can be used.

Work with us as we use data science for good.

Join us. The world can't wait.

You Have:
• 5+ years of experience developing and deploying AI/ML models in enterprise or government environments
• Experience fine-tuning and applying Large Language Models (LLMs), such as GPT, LLaMA, or Claude for NLP and generative tasks
• Experience programming in Python and with ML frameworks, such as PyTorch, TensorFlow, or Scikit-learn
• Experience with data analytics, feature engineering, and building end-to-end ML pipelines
• Experience integrating AI/ML models into secure or cloud-hosted environments, such as AWS or Azure
• Knowledge of vector databases and retrieval-augmented generation (RAG) pipelines
• Knowledge of RMF, STIGs, and DoD cybersecurity compliance practices
• Secret clearance
• Bachelor's degree
• CompTIA Security+ CE certification

Nice If You Have:
• 5+ years of experience in Cloud deployments
• 5+ years of experience in solutions architecture
• Experience working in an Agile environment
• Possession of excellent collaboration and oral and written communication skills, including documentation
• Master's degree

Clearance:

Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required.

Compensation

At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen's benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.

Salary at Booz Allen is determined by various factors, including but not limited to location, the individual's particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $99,000.00 to $225,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen's total compensation package for employees. This posting will close within 90 days from the Posting Date.

Identity Statement

As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud.

Work Model
Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.
• If this position is listed as remote or hybrid, you'll periodically work from a Booz Allen or client site facility.
• If this position is listed as onsite, you'll work with colleagues and clients in person, as needed for the specific role.

Commitment to Non-Discrimination

All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law.",2025-07-21T00:00:00.000Z,2025-07-25,"['5+ years of experience developing and deploying AI/ML models in enterprise or government environments', 'Experience fine-tuning and applying Large Language Models (LLMs), such as GPT, LLaMA, or Claude for NLP and generative tasks', 'Experience programming in Python and with ML frameworks, such as PyTorch, TensorFlow, or Scikit-learn', 'Experience with data analytics, feature engineering, and building end-to-end ML pipelines', 'Experience integrating AI/ML models into secure or cloud-hosted environments, such as AWS or Azure', 'Knowledge of vector databases and retrieval-augmented generation (RAG) pipelines', 'Knowledge of RMF, STIGs, and DoD cybersecurity compliance practices', 'Secret clearance', ""Bachelor's degree"", 'CompTIA Security+ CE certification', '5+ years of experience in Cloud deployments', '5+ years of experience in solutions architecture', 'Experience working in an Agile environment', 'Possession of excellent collaboration and oral and written communication skills, including documentation', ""Master's degree"", 'Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required']","[""On our team, you'll use your leadership skills and data science expertise to create real-world impact"", ""You'll work closely with clients to understand their questions and needs, and then dig into their data-rich environments to find the pieces of their information puzzle"", ""You'll guide teammates and lead the development of algorithms and systems"", ""You'll use the right combination of tools and frameworks to turn sets of disparate data points into objective answers to advise your clients as they make informed decisions"", ""Ultimately, you'll provide a deep understanding of the data, what it all means, and how it can be used"", ""If this position is listed as remote or hybrid, you'll periodically work from a Booz Allen or client site facility"", ""If this position is listed as onsite, you'll work with colleagues and clients in person, as needed for the specific role""]",True,"['Large Language Models', 'Generative AI', 'Retrieval-Augmented Generation', 'Prompt Engineering']","Large Language Models: Fine-tuned and applied for natural language processing and generative AI tasks to enhance client solutions.; Generative AI: Leveraged for creating AI-driven content and solutions, including NLP and other generative tasks.; Retrieval-Augmented Generation: Implemented to improve generative AI outputs by integrating external knowledge through retrieval mechanisms.; Prompt Engineering: Used to design effective prompts for interacting with LLMs to optimize AI model responses.","['Feature Engineering', 'Data Analytics', 'Machine Learning Pipelines', 'Python Programming', 'Scikit-learn', 'XGBoost', 'PyTorch', 'TensorFlow', 'Cloud Platforms (AWS, Azure)', 'Data Pipelines', 'Vector Databases']","Feature Engineering: Used to transform raw data into meaningful features for building predictive models and improving model performance.; Data Analytics: Applied to analyze complex data sets to extract insights and support decision-making for clients.; Machine Learning Pipelines: Built end-to-end pipelines to automate data processing, model training, and deployment in enterprise environments.; Python Programming: Used as the primary programming language for data manipulation, model development, and integration.; Scikit-learn: Employed as a machine learning framework for developing traditional ML models and algorithms.; XGBoost: Referenced indirectly as part of ML model development experience, commonly used for gradient boosting models.; PyTorch: Utilized as an ML framework for model development, including deep learning applications.; TensorFlow: Used as an ML framework for building and deploying machine learning models.; Cloud Platforms (AWS, Azure): Used to deploy and integrate AI/ML models securely in cloud-hosted environments.; Data Pipelines: Constructed to manage data flow and processing for machine learning and analytics tasks.; Vector Databases: Used to store and query vector embeddings, supporting advanced data retrieval techniques."
KOEcsjTne8KUqX0sAAAAAA==,Senior Data Scientist (U.S. Citizen/Security Clearance Required) Jobs,"Task Force Talent is seeking a senior Data Scientist with an active TS/SCI FSP security clearance to support a unique government contract. Our client for this role is a small company with both commercial and government sector customers. They work on very interesting, usually highly technical roles in cybersecurity, software development, data science, and related areas for well-known companies and government organizations. They have a high bar; however, they also have top compensation, benefits, and a strong company culture not found at larger firms. This is rewarding work that cannot be done elsewhere.

The primary responsibility of this role is developing technical capabilities that can produce insights from large, complex data sets. Further details will be provided to qualified candidates after an initial interview.

Target salary range is $180k - $205k, depending on experience level.

All positions are full-time, in-office, usually in a SCIF.

If you apply but this company is not a fit, we will consider you for other available positions as well. We have several clients seeking very similar skill sets.

Not your dream job, but perfect for a friend? You can submit a referral and get a check for $2000 or more: https://www.taskforcetalent.com/referral/
(Terms and conditions apply.)

_______________________________________________________________________________________________________________________________________________

Qualifications
• U.S. citizen with active TS/SCI FSP security clearance. (Sorry, we are unable to sponsor or upgrade clearances for this role.)
• 10+ years of relevant experience, including
• data modeling and visualization
• developing, managing, and exploiting various types of databases
• ETL
• assessing data quality and integrity
• building/maintaining CI/CD pipelines
• Experience with:
• Python, SQL, and NiFI
• AWS or Azure cloud
• Git/GitHub

____________________________________________________________________________________________________________________________________

Interview Process

The process typically involves an initial phone screen followed by technical interviews. Contigent offers are usually made quickly, within a week or two. Depending on the level of experience and terms of the contract, additional interviews may be required with a prime contractor/partners or the end customer.

_____________________________________________________________________________________________________________________________________

About us:

Task Force Talent is a specialized recruiting firm for science, engineering, and security careers. Our clients include seed to Series B startups working on AI, cybersecurity, quantum computing, and other novel technologies. We also work with small to medium size government contractors, and we help leading venture capital firms find talent for their portfolio companies. We have hundreds of jobs available and consider all applicants for all roles, now and in the future. Our goal is to find the best fit for you!

If you don't see the perfect fit, simply use our general application at: https://taskforcetalent.breezy.hr/p/5bbc3c44433e-single-application-for-all-jobs-general",2025-07-22T00:00:00.000Z,2025-07-25,"['U.S. citizen with active TS/SCI FSP security clearance', '10+ years of relevant experience, including', 'data modeling and visualization', 'ETL', 'Python, SQL, and NiFI', 'AWS or Azure cloud', 'Depending on the level of experience and terms of the contract, additional interviews may be required with a prime contractor/partners or the end customer']","['The primary responsibility of this role is developing technical capabilities that can produce insights from large, complex data sets', 'developing, managing, and exploiting various types of databases', 'assessing data quality and integrity', 'building/maintaining CI/CD pipelines']",True,[],,"['Data Modeling', 'Data Visualization', 'ETL (Extract, Transform, Load)', 'Python', 'SQL', 'NiFi', 'AWS Cloud', 'Azure Cloud', 'CI/CD Pipelines', 'Data Quality and Integrity Assessment', 'Database Management', 'Git/GitHub']","Data Modeling: Used to structure and organize large, complex data sets for analysis and insight generation.; Data Visualization: Applied to represent data insights visually to support decision-making and communication.; ETL (Extract, Transform, Load): Processes used to collect, clean, and prepare data from various sources for analysis.; Python: Programming language utilized for data analysis, scripting, and building data pipelines.; SQL: Language used for querying and managing relational databases involved in data exploitation.; NiFi: Tool for automating and managing data flows and pipelines within the data infrastructure.; AWS Cloud: Cloud platform used to host data storage, processing, and analytics services.; Azure Cloud: Cloud platform leveraged for data storage, processing, and analytics capabilities.; CI/CD Pipelines: Continuous integration and deployment pipelines built and maintained to automate data workflows and software delivery.; Data Quality and Integrity Assessment: Processes to ensure accuracy, consistency, and reliability of data used for analysis.; Database Management: Developing, managing, and exploiting various types of databases to support data science tasks.; Git/GitHub: Version control tools used to manage code and collaborate on data science projects."
0vkoqsWaaHsrLgRiAAAAAA==,"Senior Manager, Data Science - US Card (Resiliency Intelligence)","Senior Manager, Data Science - US Card (Resiliency Intelligence)

Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making.

As a Data Scientist at Capital One, you'll be part of a team that's leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives.

Team Description

The Resiliency Intelligence team helps our customers regain financial stability and drive business value through personalized solutions at scale. This is crucially important for customers that encounter financial hardship and need personalized resources to resolve outstanding balances.

To achieve this, we use supervised and reinforcement learning models to predict customer needs and recommend optimal solutions. We write custom Python libraries and use open-source ML libraries like XGBoost, scikit-learn, and statsmodels. Our models define the treatment for millions of customers on a daily basis and your code will run in analytical and production environments.

Our team's ML solutions meaningfully impact the income of the US Card business and are a key value generator for the company.

Role Description

In this role, you will:
• Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love
• Leverage a broad stack of technologies - Python, Kubernetes, AWS, H2O, Spark, and more - to reveal the insights hidden within huge volumes of numeric and textual data
• Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation
• Flex your interpersonal skills to translate the complexity of your work into tangible business goals

The Ideal Candidate is:
• Customer first. You love the process of analyzing and creating, but also share our passion to do the right thing. You know at the end of the day it's about making the right decision for our customers.
• Creative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You're not afraid to share a new idea.
• A leader. You challenge conventional thinking and work with stakeholders to identify and improve the status quo. You're passionate about talent development for your own team and beyond.
• Technical. You're comfortable with open-source languages and are passionate about developing further. You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms.

Basic Qualifications:
• Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:
• A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 7 years of experience performing data analytics
• A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 5 years of experience performing data analytics
• A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 2 years of experience performing data analytics
• At least 2 years of experience leveraging open source programming languages for large scale data analysis
• At least 2 years of experience working with machine learning
• At least 2 years of experience utilizing relational databases

Preferred Qualifications:
• PhD in ""STEM"" field (Science, Technology, Engineering, or Mathematics) plus 4 years of experience in data analytics
• At least 1 year of experience working with AWS
• At least 1 year of experience managing people
• At least 5 years' experience in Python, Scala, or R for large scale data analysis
• At least 5 years' experience with machine learning

Capital One will consider sponsoring a new qualified applicant for employment authorization for this position.

The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.

Cambridge, MA: $225,400 - $257,200 for Sr Mgr, Data Science

Chicago, IL: $204,900 - $233,800 for Sr Mgr, Data Science

McLean, VA: $225,400 - $257,200 for Sr Mgr, Data Science

New York, NY: $245,900 - $280,600 for Sr Mgr, Data Science

Richmond, VA: $204,900 - $233,800 for Sr Mgr, Data Science

Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate's offer letter.

This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.

Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at theCapital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.

This role is expected to accept applications for a minimum of 5 business days.

No agencies please. Capital One is an equal opportunity employer (EOE, including disability/vet) committed to non-discrimination in compliance with applicable federal, state, and local laws. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City's Fair Chance Act; Philadelphia's Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",2025-07-24T00:00:00.000Z,2025-07-25,"['Customer first', 'You thrive on bringing definition to big, undefined problems', 'You love asking questions and pushing hard to find answers', ""You're passionate about talent development for your own team and beyond"", 'Technical', ""You're comfortable with open-source languages and are passionate about developing further"", 'You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms', 'Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:', ""A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 7 years of experience performing data analytics"", ""A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 5 years of experience performing data analytics"", 'A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 2 years of experience performing data analytics', 'At least 2 years of experience leveraging open source programming languages for large scale data analysis', 'At least 2 years of experience working with machine learning', 'At least 2 years of experience utilizing relational databases']","['This is crucially important for customers that encounter financial hardship and need personalized resources to resolve outstanding balances', 'To achieve this, we use supervised and reinforcement learning models to predict customer needs and recommend optimal solutions', 'We write custom Python libraries and use open-source ML libraries like XGBoost, scikit-learn, and statsmodels', 'Our models define the treatment for millions of customers on a daily basis and your code will run in analytical and production environments', 'Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love', 'Leverage a broad stack of technologies - Python, Kubernetes, AWS, H2O, Spark, and more - to reveal the insights hidden within huge volumes of numeric and textual data', 'Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation', 'Flex your interpersonal skills to translate the complexity of your work into tangible business goals', 'You challenge conventional thinking and work with stakeholders to identify and improve the status quo']",True,[],,"['Supervised Learning', 'Reinforcement Learning', 'Python', 'XGBoost', 'scikit-learn', 'statsmodels', 'Relational Databases', 'AWS', 'Kubernetes', 'H2O', 'Spark', 'Machine Learning']",Supervised Learning: Used to build predictive models that forecast customer needs and recommend optimal financial solutions.; Reinforcement Learning: Applied to develop models that optimize decision-making for personalized customer treatments.; Python: Primary programming language used for developing custom data science libraries and machine learning models.; XGBoost: An open-source machine learning library used for building gradient boosting models in predictive analytics.; scikit-learn: Open-source ML library utilized for implementing various machine learning algorithms and model evaluation.; statsmodels: Library used for statistical modeling and hypothesis testing within data science workflows.; Relational Databases: Used for managing and querying large volumes of structured customer data to support analytics.; AWS: Cloud computing platform leveraged to scale data processing and machine learning model deployment.; Kubernetes: Container orchestration tool used to manage deployment and scaling of data science applications.; H2O: Open-source platform used for scalable machine learning and data analysis.; Spark: Big data processing engine employed to handle large-scale numeric and textual data analytics.; Machine Learning: Core technology applied to develop models that impact business decisions and customer financial outcomes.
g2BI_dwhDGqBZXgcAAAAAA==,"Senior Associate, Data Scientist","Senior Associate, Data Scientist

Senior Associate, Data Scientist - US Card Bureau Data Strategy Team

Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making.

As a Data Scientist at Capital One, you’ll be part of a team that’s leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives.

Team Description

Credit bureau data is at the heart of underwriting decisions at US Card. The Bureau Data Strategy team produces one of the most highly-used datasets in all of Capital One from raw credit bureau data. The team is responsible for generating insights, extracting value from Bureau Data and shaping the future of how credit bureau data is used in underwriting at Capital One. The team also owns the monitoring solution to promptly alert users to potential production errors with these features.

Role Description

In this role, you will:
• Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love
• Leverage a broad stack of technologies — Python, Conda, AWS, H2O, Spark, and more — to reveal the insights hidden within huge volumes of numeric and textual data
• Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation
• Flex your interpersonal skills to translate the complexity of your work into tangible business goals

The Ideal Candidate is:
• Innovative. You continually research and evaluate emerging technologies. You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them.
• Creative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You’re not afraid to share a new idea.
• Technical. You’re comfortable with open-source languages and are passionate about developing further. You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms.
• Statistically-minded. You’ve built models, validated them, and backtested them. You know how to interpret a confusion matrix or a ROC curve. You have experience with clustering, classification, sentiment analysis, time series, and deep learning.
• A data guru. “Big data” doesn’t faze you. You have the skills to retrieve, combine, and analyze data from a variety of sources and structures. You know understanding the data is often the key to great data science.

Basic Qualifications:
• Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:
• A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 2 years of experience performing data analytics
• A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration

Preferred Qualifications:
• Master’s Degree in “STEM” field (Science, Technology, Engineering, or Mathematics), or PhD in “STEM” field (Science, Technology, Engineering, or Mathematics)
• Experience working with PySpark
• At least 2 years’ experience in Python, Scala, or R
• At least 2 years’ experience with machine learning
• At least 2 years’ experience with SQL

Capital One will consider sponsoring a new qualified applicant for employment authorization for this position.

The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.

McLean, VA: $133,000 - $151,800 for Sr Assoc, Data Science

New York, NY: $145,100 - $165,600 for Sr Assoc, Data Science

Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate’s offer letter.

This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.

Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.

This role is expected to accept applications for a minimum of 5 business days.

No agencies please. Capital One is an equal opportunity employer (EOE, including disability/vet) committed to non-discrimination in compliance with applicable federal, state, and local laws. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",2025-07-16T00:00:00.000Z,2025-07-25,"['You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them', 'You thrive on bringing definition to big, undefined problems', 'You love asking questions and pushing hard to find answers', 'You’re comfortable with open-source languages and are passionate about developing further', 'You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms', 'Statistically-minded', 'You know how to interpret a confusion matrix or a ROC curve', 'You have experience with clustering, classification, sentiment analysis, time series, and deep learning', 'A data guru', 'You have the skills to retrieve, combine, and analyze data from a variety of sources and structures', 'You know understanding the data is often the key to great data science', 'Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:', ""A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 2 years of experience performing data analytics"", ""A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration""]","['The team is responsible for generating insights, extracting value from Bureau Data and shaping the future of how credit bureau data is used in underwriting at Capital One', 'The team also owns the monitoring solution to promptly alert users to potential production errors with these features', 'Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love', 'Leverage a broad stack of technologies — Python, Conda, AWS, H2O, Spark, and more — to reveal the insights hidden within huge volumes of numeric and textual data', 'Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation', 'Flex your interpersonal skills to translate the complexity of your work into tangible business goals', 'You continually research and evaluate emerging technologies', 'You’ve built models, validated them, and backtested them']",True,[],,"['Statistical Modeling', 'Relational Databases', 'Python', 'Conda', 'AWS', 'H2O', 'Spark', 'Machine Learning', 'Clustering', 'Classification', 'Sentiment Analysis', 'Time Series Analysis', 'Deep Learning', 'Confusion Matrix and ROC Curve Interpretation', 'PySpark', 'Scala', 'R', 'SQL']","Statistical Modeling: Used to personalize credit card offers and generate insights from credit bureau data for underwriting decisions.; Relational Databases: Employed to manage and query structured credit bureau data critical for underwriting.; Python: A primary programming language used for data analysis, model building, and working with large datasets.; Conda: Used as a package and environment management system to support data science workflows.; AWS: Cloud computing platform leveraged to handle large-scale data processing and storage.; H2O: An open-source machine learning platform used for building and deploying machine learning models.; Spark: Big data processing engine used to analyze huge volumes of numeric and textual data efficiently.; Machine Learning: Applied throughout model development phases including design, training, evaluation, validation, and implementation.; Clustering: Used as an unsupervised learning technique to identify patterns within credit bureau data.; Classification: Employed to categorize data points, such as credit risk levels, within underwriting models.; Sentiment Analysis: Applied to textual data to extract insights relevant to credit decisions.; Time Series Analysis: Used to analyze temporal data trends within credit bureau datasets.; Deep Learning: Utilized for advanced modeling techniques to improve predictive accuracy on complex data.; Confusion Matrix and ROC Curve Interpretation: Skills required to evaluate and validate classification model performance.; PySpark: Used to write Spark applications in Python for big data processing.; Scala: Programming language experience preferred for big data and Spark-related tasks.; R: Statistical programming language experience preferred for data analysis and modeling.; SQL: Used to retrieve and manipulate data from relational databases."
18oCPxMqXOGheocuAAAAAA==,"Data Scientist Assoc., Mid. and Sr. Jobs","Overview

Iron EagleX (IEX), a wholly owned subsidiary of General Dynamics Information Technology, delivers agile IT and Intelligence solutions. Combining small-team flexibility with global scale, IEX leverages emerging technologies to provide innovative, user-focused solutions that empower organizations and end users to operate smarter, faster, and more securely in dynamic environments.

Responsibilities

We are looking for Associate, Mid level and Senior Level Data Scientists to support a customer onsite in Arlington, Virginia.

These positions are contingent upon the award of a contract. Work is expected to begin in August 2025.

Job Description:
• Design, develop, and implement data models, algorithms, and machine learning pipelines to solve complex defense-related problems.
• Analyze large, structured and unstructured datasets from multiple sources, including sensor data, signals intelligence, satellite imagery, and operational reports.
• Collaborate with analysts, engineers, and military subject matter experts to define problems, collect requirements, and deliver insights in support of strategic and tactical decisions.
• Build dashboards, data visualizations, and interactive tools to communicate analytical findings to non-technical audiences and senior leadership.
• Conduct data quality assessments and recommend enhancements to existing data systems and processes.
• Participate in research and development of AI/ML capabilities applicable to defense and intelligence missions.

Qualifications

Required Skills & Experience:
• Experience applying data science techniques in a professional setting, preferably within the DoD or Intelligence Community.
• Proficiency in Python, R, or similar programming languages.
• Experience with SQL and NoSQL databases, and data processing frameworks (e.g., Spark, Hadoop).
• Familiarity with machine learning libraries (e.g., Scikit-learn, TensorFlow, PyTorch).
• Strong understanding of statistical modeling, predictive analytics, and data mining techniques.
• Experience supporting military or national security missions.
• Familiarity with DoD data platforms and cloud environments (e.g., AWS GovCloud, Azure Government).
• Due to U.S. Government contract requirements, only U.S. citizens are eligible for this role.

Education & Certifications:
• Bachelor's or Master's degree in Data Science, Computer Science, Statistics, Mathematics, Engineering, or related field.

Security Clearance:
• TS/SCI clearance is required

Benefits:
• National Health, vision, and dental plans
• 20 days of PTO and 11 paid holidays
• Life Insurance
• Short - and long-term disability plans
• 401(K) retirement plans
• Incentive and recognition programs
• Relocation opportunities

Equal Opportunity Employer / Individuals with Disabilities / Protected Veterans",2025-07-17T00:00:00.000Z,2025-07-25,"['Experience applying data science techniques in a professional setting, preferably within the DoD or Intelligence Community', 'Proficiency in Python, R, or similar programming languages', 'Experience with SQL and NoSQL databases, and data processing frameworks (e.g., Spark, Hadoop)', 'Familiarity with machine learning libraries (e.g., Scikit-learn, TensorFlow, PyTorch)', 'Strong understanding of statistical modeling, predictive analytics, and data mining techniques', 'Experience supporting military or national security missions', 'Familiarity with DoD data platforms and cloud environments (e.g., AWS GovCloud, Azure Government)', 'Due to U.S. Government contract requirements, only U.S. citizens are eligible for this role', ""Bachelor's or Master's degree in Data Science, Computer Science, Statistics, Mathematics, Engineering, or related field"", 'TS/SCI clearance is required']","['We are looking for Associate, Mid level and Senior Level Data Scientists to support a customer onsite in Arlington, Virginia', 'Design, develop, and implement data models, algorithms, and machine learning pipelines to solve complex defense-related problems', 'Analyze large, structured and unstructured datasets from multiple sources, including sensor data, signals intelligence, satellite imagery, and operational reports', 'Collaborate with analysts, engineers, and military subject matter experts to define problems, collect requirements, and deliver insights in support of strategic and tactical decisions', 'Build dashboards, data visualizations, and interactive tools to communicate analytical findings to non-technical audiences and senior leadership', 'Conduct data quality assessments and recommend enhancements to existing data systems and processes', 'Participate in research and development of AI/ML capabilities applicable to defense and intelligence missions']",True,[],,"['Data Modeling', 'Machine Learning Pipelines', 'Structured and Unstructured Data Analysis', 'Dashboards and Data Visualization', 'Data Quality Assessment', 'Python', 'R', 'SQL', 'NoSQL Databases', 'Spark', 'Hadoop', 'Scikit-learn', 'TensorFlow', 'PyTorch', 'Statistical Modeling', 'Predictive Analytics', 'Data Mining', 'Cloud Environments']","Data Modeling: Designing and implementing data models to represent complex defense-related problems.; Machine Learning Pipelines: Developing end-to-end workflows for machine learning to analyze defense data and generate insights.; Structured and Unstructured Data Analysis: Analyzing diverse datasets including sensor data, signals intelligence, satellite imagery, and operational reports.; Dashboards and Data Visualization: Building interactive tools and visualizations to communicate analytical findings to leadership and non-technical audiences.; Data Quality Assessment: Evaluating and recommending improvements to data systems and processes to ensure data integrity.; Python: Using Python programming language for data science tasks and model development.; R: Applying R programming language for statistical analysis and data modeling.; SQL: Querying and managing structured data in relational databases.; NoSQL Databases: Handling unstructured or semi-structured data using NoSQL database technologies.; Spark: Utilizing Apache Spark for large-scale data processing and analytics.; Hadoop: Employing Hadoop ecosystem tools for distributed data storage and processing.; Scikit-learn: Using Scikit-learn library for implementing traditional machine learning algorithms.; TensorFlow: Applying TensorFlow for machine learning model development, including neural networks.; PyTorch: Leveraging PyTorch for building and training machine learning models.; Statistical Modeling: Applying statistical techniques to model and interpret defense-related data.; Predictive Analytics: Using data-driven models to forecast outcomes relevant to defense and intelligence missions.; Data Mining: Extracting patterns and insights from large defense datasets.; Cloud Environments: Working with DoD-specific cloud platforms like AWS GovCloud and Azure Government for data storage and processing."
Gbav3WbCOvLIce_kAAAAAA==,Sr. Data Scientist,"Knowledge Management, Inc. (KMI) has the leadership and experience to deliver innovative technology, logistics and management solutions to meet real mission requirements. KMI is a Minority Business Enterprise (MBE) and Small Disadvantage Business (SDB) that specializes in Logistics, Warehouse Services, Distance Learning/Training, Enterprise Solutions, Financial Management Support, Program Management, Intelligence Analysis & Threat Assessment, and Data Analytics/Operations Research. Since 1998, our solutions and services have helped our clients improve performance, drive cost and operational effectives, and map technology needs for tomorrow's requirements.

Title: Sr. Data Scientist

Location: Pentagon (onsite)

Positions: 1

Duration: Multi-year contract

Start date: Around September 15

Security Clearance: Minimum of a DOD Secret clearance

Salary: Please provide your salary requirement

Education/Experience: Minimum of 8 years of experience with U.S. Marine Corps logistics systems (12 years without degree)

Job Description: Knowledge Management, Inc. is seeking an experienced Sr. Data Scientist who is intimately familiar with Marine Corps logistics systems and Operational Research & Statistical Analysis methods to support the U.S. Marine Corps customer. This position will focus on analyzing and interpreting complex logistics data, building effective data visualization tools, and developing logistics documentation, plans, and briefs to support attainment of the highest levels of equipment readiness in the most cost-effective manner.

Key Responsibilities:
• Analyze and interpret U.S. Marine Corps logistics data
• Develop metrics and data visualization tools
• Identify and recommend logistics strategies to optimize supply chain and logistics operations.
• Collaborating with cross-functional teams
• Support continuous improvement initiatives

Minimum Qualifications:
• Bachelor's degree in business, operations research, Data Analytics, Computer Science, or a similar field.
• Minimum of 8 years of experience with U.S. Marine Corps logistics systems (12 years without degree)
• Strong analytical and problem-solving skills, with a focus on logistics and supply chain management.
• Must hold an active DoD Secret security clearance.

Desired Qualifications:
• Ability to work independently and meet deadlines in a robust work environment.

Security Clearance:
• Active DoD Secret security clearance required.

Work Environment:
• Onsite in Pentagon working spaces

Availability

This position is anticipated to be available on or about 15 September 2025

Benefits: All full-time employees are eligible to participate in our benefits programs:
• Health, dental, and vision insurance
• 401(k) retirement plan
• Paid time off (PTO) and holidays
• Group Term Life and Accidental Death and Dismemberment Insurance
• Voluntary Term Life Insurance
• Short and Long-term disability insurance

Equal Employment Opportunity Statement. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

E-Verify Statement. Knowledge Management, Inc. participates in E-Verify and will provide the federal government with your Form I-9 information to confirm that you are authorized to work in the U.S. If E-Verify cannot confirm that you are authorized to work, KMI is required to give you written instructions and an opportunity to contact Department of Homeland Security (DHS) or Social Security Administration (SSA) so you can begin to resolve the issue before the employer can take any action against you, including terminating your employment. Employers can only use E-Verify once you have accepted a job offer and completed the Form I-9.

Pay Transparency Non-Discrimination Provision. Knowledge Management, Inc. will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor's legal duty to furnish information. 41 CFR 60-1.35(c)

Disability Statement. If you have a disability and need reasonable accommodation or assistance at any point in the application or onboarding process, please email us at .",2025-07-15T00:00:00.000Z,2025-07-25,"['Security Clearance: Minimum of a DOD Secret clearance', 'Education/Experience: Minimum of 8 years of experience with U.S. Marine Corps logistics systems (12 years without degree)', 'Job Description: Knowledge Management, Inc. is seeking an experienced Sr', 'Data Scientist who is intimately familiar with Marine Corps logistics systems and Operational Research & Statistical Analysis methods to support the U.S. Marine Corps customer', ""Bachelor's degree in business, operations research, Data Analytics, Computer Science, or a similar field"", 'Minimum of 8 years of experience with U.S. Marine Corps logistics systems (12 years without degree)', 'Strong analytical and problem-solving skills, with a focus on logistics and supply chain management', 'Must hold an active DoD Secret security clearance', 'Active DoD Secret security clearance required']","['This position will focus on analyzing and interpreting complex logistics data, building effective data visualization tools, and developing logistics documentation, plans, and briefs to support attainment of the highest levels of equipment readiness in the most cost-effective manner', 'Analyze and interpret U.S. Marine Corps logistics data', 'Develop metrics and data visualization tools', 'Identify and recommend logistics strategies to optimize supply chain and logistics operations', 'Collaborating with cross-functional teams', 'Support continuous improvement initiatives', 'Onsite in Pentagon working spaces']",True,[],,"['Operational Research', 'Statistical Analysis', 'Data Visualization', 'Logistics Data Analysis']",Operational Research: Used to apply analytical methods to support logistics and supply chain decision-making for the U.S. Marine Corps.; Statistical Analysis: Employed to analyze and interpret complex logistics data to improve equipment readiness and operational efficiency.; Data Visualization: Developed metrics and visualization tools to communicate logistics data insights effectively to stakeholders.; Logistics Data Analysis: Focused on analyzing Marine Corps logistics data to optimize supply chain and logistics operations.
j0D1iMNi9cjZUJ6cAAAAAA==,Senior Data Scientist (OBI Advanced Analytic Method Augmentation Jobs,"Senior Data Scientist (OBI Advanced Analytic Method Augmentation) - OBIQUA

Location Virginia, Reston

Department BUSINESS DEVELOPMENT

Employment Duration Full Time

Celestar Corporation is seeking a Senior Data Scientist (OBI Advanced Analytic Method Augmentation) to support The Defense Intelligence Agency ( DIA) under the Object Based Intelligence and Quality Assurance (OBIQUA) task order. The primary place of performance will be at DIA Facilities across the National Capital Region (NCR). If interested and meet the qualifications, we encourage you to apply for this rewarding and impactful opportunity.

ANTICIPATED AWARD: December 2025/ January 2026
ANTICIPATED START: February/March 2026
PERIOD OF PERFORMANCE:1 Base Year + 3 Option Years
LOCATION: DIA Facilities across the National Capital Region (NCR)

CLEARANCE REQUIREMENT: Active TS/SCI with a Current CI Poly

About Us:

Celestar, a proud Veteran-Owned company, offers highly competitive salaries and benefits. Our comprehensive benefits package includes company-paid employee and family dental insurance, employee health insurance, life insurance, and disability coverage. Additionally, we provide a 401(k)-retirement plan with company matching, paid holidays, and personal time off.

Responsibilities:

This opportunity will support multiple DIA initiatives, including the Machine-Assisted Rapid-Repository System (MARS), Object Management Services (OMS), and Object-Based Intelligence (OBI).

• The Senior Data Scientist (OBI Advanced Analytic Method Augmentation), Conducts data analytics, data engineering, data mining, exploratory analysis, predictive analysis, and statistical analysis, and uses scientific techniques to correlate data into graphical, written, visual and verbal narrative products, enabling more informed analytic decisions.

• Proactively retrieves information from various sources, analyzes it for better understanding about the data set, and builds AI tools that automate certain processes.

• Duties typically include: creating various ML-based tools or processes, such as recommendation engines or automated lead scoring systems.

• Performs statistical analysis, applies data mining techniques, and builds high quality prediction systems.

• Should be skilled in data visualization and use of graphical applications, including Microsoft Office (Power BI) and Tableau; major data science languages, such as Rand Python; managing and merging of disparate data sources, preferably through R, Python, or SQL; statistical analysis; and data mining algorithms.

• Should have prior experience with large data multi-INT analytics, ML, and automated predictive analytics.

• Designs, develops, and evaluates leading-edge algorithmic intelligence concepts, practices, and technologies for implementation into all-source analysis tradecraft, assessments, production, and dissemination.

• Proposes advanced statistical or mathematical techniques and methodology that may permit identification and evaluation of alternatives, assists in model formulation or experimental test design, and shares jointly in team responsibility for development of advanced analytic techniques and assessments.

• Evaluates data science, artificial intelligence, and other advanced analytic methods for risks, biases, and limitations that would distort conclusions.

• Conducts continuous independent research on methods of analysis in government, industry, and academia to keep abreast of the state of the art, keeps senior leadership apprised of the advances and applicability to programs.

• Utilizes in-depth knowledge of relevant theories, techniques, procedures and processes to investigate, prototype, and evaluate technologies to improve all-source intelligence analysis.

• Provides technical input into and participates in the development of software and computer graphics systems.

• Performs research studies to understand the process of augmenting or automating all source analytic processes using various computer models.

• Provides incremental enhancements to tools, capabilities, processes, and methods.

• Possesses in-depth knowledge and experience in using data analytics, data engineering, data mining, exploratory analysis, predictive analysis, and statistical analysis, and scientific techniques to correlate data into graphical, written, visual and verbal narrative products, enabling more informed analytic decisions.

• Writes either R or Python scripts to drive data science workflows, have experience using SQL, and managing and merging of disparate data sources, preferably through R, Python, or SQL; statistical analysis; and data mining algorithms.

• Possesses prior experience with large data, spatial data, multi-INT analytics, ML, and automated predictive analytics.

• Works with ambiguous information, deconstruct key questions, leverage spatial data, exploit application programming interfaces, suggest methodologies, develop data schemas to structure observations. This requires working knowledge of coding and scripting, information science, mathematics, machine learning, visual analytic modeling tools, and relevant Standard Operating Procedures (SOPs) to create repeatable, widely applicable procedures to support all-source intelligence analysis and production.

• Creates and works in distributed analytic environments, scaling algorithms to work on increasingly large and complex datasets that are larger than RAM.

• Serves as the primary POC for data science expertise, ensuring tradecraft compliance and analytic standards as it relates to data science techniques on the contract.

• Provides advice on emerging data science methods, tools, algorithms, training, or requirements to advance DIA's analytic edge in its use of data science.

• Works with DIA vendors and the software developers to implement distributed algorithms to work on increasingly large and complex data sets.

• Review and evaluate OBI documentation submitted by advanced analytic (AA) owners to ensure compliance with tradecraft standards and adherence to best practices in AI system development and deployment.

• Assess OBI documentation for completeness, accuracy, and thoroughness, and provide detailed feedback to owners and developers.

• Provide consultation and guidance to data and AA owners, developers, and stakeholders on OBI governance and knowledge modeling, including best practices for system development, testing, and deployment.

• Assist analytic methodologists and AA owners in translating technical documentation into analytic tradecraft compliant language.

• Collaborate with stakeholders to develop, implement, and refine best practices for translating technical documentation into tradecraft compliant language

• Review and edit translated documentation to ensure accuracy, completeness, and adherence to tradecraft standards.

• Collaborate with the Computer Scientist to develop and implement testing methodologies for system validation and evaluation.

• Conduct audits to ensure compliant use of systems for approved use-cases in all source analysis.

• Develop and maintain a repository of audit findings and recommendations to facilitate knowledge sharing and best practices across the organization.

• Design and execute TEVV protocols to evaluate the performance, robustness, and fairness of systems in all source analysis contexts.

• Develop and apply statistical models and methods to analyze TEVV results and identify areas for improvement.

• Collaborate with stakeholders to develop and implement corrective actions to address TEVV findings.

• Develop and track performance metrics to evaluate the effectiveness of systems in all source analysis.

• Analyze and interpret performance metrics to identify trends, patterns, and areas for improvement.

• Collaborate with stakeholders to develop and implement data-driven decision-making processes to inform system development and improvement.

• Develop and refine methodologies for evaluating system performance, robustness, and fairness in all source analysis contexts.

• Collaborate with stakeholders to develop and implement best practices for system development, testing, and deployment.

• Supports capability development by contributing, editing, and storing code in Government owned/controlled source version control repositories.

Required qualifications/skills:

• Minimum 12 years of experience related to the specific labor category with at least a portion of the experience within the last 2 years with a master's degree.

-OR-

• A minimum of 17 years of experience related to the specific labor category with at least a portion of the experience within the last 2 years with a bachelor's degree.

• Possesses a professional or graduate certificate in data science from a university, major online learning platform (all business for Data Scientists at any experience level).

• Demonstrates ability to work independently and with minimal oversight.

Come on board with a company that Values its Employees!

Celestar Corporation is an Equal Opportunity Employer. The Celestar Corporation prohibits discrimination, harassment, and retaliation in employment based on race; color; religion; genetic information; national origin; sex (including same-sex); sexual orientation; gender identity; pregnancy, childbirth, or related medical conditions; age; disability or handicap; citizenship status; marital status; service member/protected veteran status; or any other category protected by federal, state, or local law.",2025-07-18T00:00:00.000Z,2025-07-25,"['CLEARANCE REQUIREMENT: Active TS/SCI with a Current CI Poly', 'Should be skilled in data visualization and use of graphical applications, including Microsoft Office (Power BI) and Tableau; major data science languages, such as Rand Python; managing and merging of disparate data sources, preferably through R, Python, or SQL; statistical analysis; and data mining algorithms', 'Should have prior experience with large data multi-INT analytics, ML, and automated predictive analytics', 'Writes either R or Python scripts to drive data science workflows, have experience using SQL, and managing and merging of disparate data sources, preferably through R, Python, or SQL; statistical analysis; and data mining algorithms', 'Possesses prior experience with large data, spatial data, multi-INT analytics, ML, and automated predictive analytics', 'This requires working knowledge of coding and scripting, information science, mathematics, machine learning, visual analytic modeling tools, and relevant Standard Operating Procedures (SOPs) to create repeatable, widely applicable procedures to support all-source intelligence analysis and production', ""Minimum 12 years of experience related to the specific labor category with at least a portion of the experience within the last 2 years with a master's degree"", ""A minimum of 17 years of experience related to the specific labor category with at least a portion of the experience within the last 2 years with a bachelor's degree"", 'Possesses a professional or graduate certificate in data science from a university, major online learning platform (all business for Data Scientists at any experience level)', 'Demonstrates ability to work independently and with minimal oversight']","['This opportunity will support multiple DIA initiatives, including the Machine-Assisted Rapid-Repository System (MARS), Object Management Services (OMS), and Object-Based Intelligence (OBI)', 'The Senior Data Scientist (OBI Advanced Analytic Method Augmentation), Conducts data analytics, data engineering, data mining, exploratory analysis, predictive analysis, and statistical analysis, and uses scientific techniques to correlate data into graphical, written, visual and verbal narrative products, enabling more informed analytic decisions', 'Proactively retrieves information from various sources, analyzes it for better understanding about the data set, and builds AI tools that automate certain processes', 'Duties typically include: creating various ML-based tools or processes, such as recommendation engines or automated lead scoring systems', 'Performs statistical analysis, applies data mining techniques, and builds high quality prediction systems', 'Designs, develops, and evaluates leading-edge algorithmic intelligence concepts, practices, and technologies for implementation into all-source analysis tradecraft, assessments, production, and dissemination', 'Proposes advanced statistical or mathematical techniques and methodology that may permit identification and evaluation of alternatives, assists in model formulation or experimental test design, and shares jointly in team responsibility for development of advanced analytic techniques and assessments', 'Evaluates data science, artificial intelligence, and other advanced analytic methods for risks, biases, and limitations that would distort conclusions', 'Conducts continuous independent research on methods of analysis in government, industry, and academia to keep abreast of the state of the art, keeps senior leadership apprised of the advances and applicability to programs', 'Utilizes in-depth knowledge of relevant theories, techniques, procedures and processes to investigate, prototype, and evaluate technologies to improve all-source intelligence analysis', 'Provides technical input into and participates in the development of software and computer graphics systems', 'Performs research studies to understand the process of augmenting or automating all source analytic processes using various computer models', 'Provides incremental enhancements to tools, capabilities, processes, and methods', 'Possesses in-depth knowledge and experience in using data analytics, data engineering, data mining, exploratory analysis, predictive analysis, and statistical analysis, and scientific techniques to correlate data into graphical, written, visual and verbal narrative products, enabling more informed analytic decisions', 'Works with ambiguous information, deconstruct key questions, leverage spatial data, exploit application programming interfaces, suggest methodologies, develop data schemas to structure observations', 'Creates and works in distributed analytic environments, scaling algorithms to work on increasingly large and complex datasets that are larger than RAM', 'Serves as the primary POC for data science expertise, ensuring tradecraft compliance and analytic standards as it relates to data science techniques on the contract', ""Provides advice on emerging data science methods, tools, algorithms, training, or requirements to advance DIA's analytic edge in its use of data science"", 'Works with DIA vendors and the software developers to implement distributed algorithms to work on increasingly large and complex data sets', 'Review and evaluate OBI documentation submitted by advanced analytic (AA) owners to ensure compliance with tradecraft standards and adherence to best practices in AI system development and deployment', 'Assess OBI documentation for completeness, accuracy, and thoroughness, and provide detailed feedback to owners and developers', 'Provide consultation and guidance to data and AA owners, developers, and stakeholders on OBI governance and knowledge modeling, including best practices for system development, testing, and deployment', 'Assist analytic methodologists and AA owners in translating technical documentation into analytic tradecraft compliant language', 'Collaborate with stakeholders to develop, implement, and refine best practices for translating technical documentation into tradecraft compliant language', 'Review and edit translated documentation to ensure accuracy, completeness, and adherence to tradecraft standards', 'Collaborate with the Computer Scientist to develop and implement testing methodologies for system validation and evaluation', 'Conduct audits to ensure compliant use of systems for approved use-cases in all source analysis', 'Develop and maintain a repository of audit findings and recommendations to facilitate knowledge sharing and best practices across the organization', 'Design and execute TEVV protocols to evaluate the performance, robustness, and fairness of systems in all source analysis contexts', 'Develop and apply statistical models and methods to analyze TEVV results and identify areas for improvement', 'Collaborate with stakeholders to develop and implement corrective actions to address TEVV findings', 'Develop and track performance metrics to evaluate the effectiveness of systems in all source analysis', 'Analyze and interpret performance metrics to identify trends, patterns, and areas for improvement', 'Collaborate with stakeholders to develop and implement data-driven decision-making processes to inform system development and improvement', 'Develop and refine methodologies for evaluating system performance, robustness, and fairness in all source analysis contexts', 'Collaborate with stakeholders to develop and implement best practices for system development, testing, and deployment', 'Supports capability development by contributing, editing, and storing code in Government owned/controlled source version control repositories']",True,[],,"['Data Analytics', 'Data Engineering', 'Data Mining', 'Exploratory Data Analysis', 'Predictive Analytics', 'Statistical Analysis', 'Machine Learning', 'Recommendation Engines', 'R Programming', 'Python Programming', 'SQL', 'Data Visualization', 'Power BI', 'Tableau', 'Spatial Data Analytics', 'Multi-INT Analytics', 'Distributed Analytics', 'Data Mining Algorithms', 'Statistical Modeling', 'Performance Metrics Analysis', 'Data-Driven Decision Making', 'Version Control']","Data Analytics: Used to analyze and interpret complex datasets to support informed analytic decisions in intelligence contexts.; Data Engineering: Involves managing and merging disparate data sources to prepare data for analysis and modeling.; Data Mining: Applied to extract patterns and insights from large multi-INT and spatial datasets for predictive analytics.; Exploratory Data Analysis: Used to understand data characteristics and relationships before building predictive models.; Predictive Analytics: Building automated predictive systems such as recommendation engines and lead scoring to support intelligence analysis.; Statistical Analysis: Applied to evaluate data, develop models, and assess system performance and robustness.; Machine Learning: Used to create ML-based tools and automated predictive analytics for intelligence data processing.; Recommendation Engines: Developed as ML-based tools to automate lead scoring and other decision support processes.; R Programming: Used for scripting data science workflows, statistical analysis, and managing data sources.; Python Programming: Used for scripting, data engineering, and building data science workflows and predictive models.; SQL: Used to query and manage large and disparate data sources for analysis.; Data Visualization: Utilized tools like Power BI and Tableau to create graphical representations of data for analytic decisions.; Power BI: Used as a data visualization tool to support intelligence analysis reporting.; Tableau: Employed for creating interactive dashboards and visual analytics for data interpretation.; Spatial Data Analytics: Applied to leverage geographic and spatial information in multi-INT intelligence analysis.; Multi-INT Analytics: Integrates multiple intelligence sources to enhance analytic insights and predictive modeling.; Distributed Analytics: Scaling algorithms to process large datasets exceeding RAM capacity in distributed computing environments.; Data Mining Algorithms: Used to extract meaningful patterns and build high-quality prediction systems.; Statistical Modeling: Developed and applied to analyze TEVV results and evaluate system performance and fairness.; Performance Metrics Analysis: Analyzing system effectiveness and trends to inform improvements in intelligence analytic tools.; Data-Driven Decision Making: Collaborating with stakeholders to implement processes informed by analytic results for system development.; Version Control: Contributing and managing code in government-controlled repositories to support capability development."
e3bHDqC3T7JHo0tUAAAAAA==,Sr Staff Data Scientist,"Job Description Summary
As a Sr Staff Data Scientist, you will lead and work within teams as a technical domain expert addressing statistical, machine learning, and artificial intelligence problems in a commercial technology and consultancy development environment. You will be part of a data science or cross-disciplinary team driving AI business solutions involving large, complex data sets. Potential application areas include time series forecasting, machine learning regression and classification, root cause analysis (RCA), simulation and optimization, large language models, and computer vision. The ideal candidate will be responsible for developing and deploying machine learning models in production environments. This role requires a strong technical background, excellent problem-solving skills, and the ability to work collaboratively with data engineers, analysts, and other stakeholders.

Job Description

Roles and Responsibilities:
• Understand business problems and identify opportunities to implement data science solutions.
• Develop, verify, and validate analytics to address customer needs and opportunities.
• Design, develop, and deploy machine learning models and algorithms
• Work in technical teams on the development, deployment, and application of applied analytics, predictive analytics, and prescriptive analytics.
• Develop and maintain pipelines for Retrieval-Augmented Generation (RAG) and Large Language Models (LLM).
• Collaborate with data scientists to optimize RAG and LLM pipelines for performance and accuracy.
• Utilize semantic and ontology technologies to enhance data integration and retrieval. Ensure data is semantically enriched to support advanced analytics and machine learning models.
• Interact with cloud services and develop and deploy models within cloud environments such as AWS, Azure, Google Cloud, and Databricks
• Perform exploratory and targeted data analyses using descriptive statistics and other methods.
• Work with data engineers on data quality assessment, data cleansing, data analytics, and model productionization
• Generate reports, annotated code, and other projects artifacts to document, archive, and communicate your work and outcomes.
• Communicate methods, findings, and hypotheses with stakeholders.
• Mentor colleagues in technical areas and drive standardization across the analytics enterprise
• Review data science/AI projects for technical rigor

Minimum Qualifications:
• Bachelor’s degree from accredited university or college with minimum of 6 years of professional experience OR associates degree with minimum of 8 years of professional experience
• 4 years proficiency in Python (mandatory)
• 3 years demonstrated expertise in cloud platforms (e.g. AWS, Azure, Google Cloud, Databricks) and their machine learning services
• 3 years demonstrated expertise working and leading in team settings in various roles
• Note: Military experience is equivalent to professional experience

Eligibility Requirement:
• Legal authorization to work in the U.S. is required. We will not sponsor individuals for employment visas, now or in the future, for this job.

Desired Characteristics:
• Demonstrated skill in defining and delivering customer value.
• Demonstrated expertise communicating complex information to executive stakeholders
• Demonstrated expertise in critical thinking and problem-solving methods
• Demonstrated experience deploying and managing CI/CD pipelines
• Demonstrated skill in data management methods and analytic scaling
• Demonstrated skill in prescriptive analytics and analytic prototyping.
• Demonstrated skill in solutions integration
• Demonstrated skill in serving as a change agent.
• Demonstrated skill in working in ambiguous environments.

Note:

To comply with US immigration and other legal requirements, it is necessary to specify the minimum number of years' experience required for any role based within the USA. For roles outside of the USA, to ensure compliance with applicable legislation, the JDs should focus on the substantive level of experience required for the role and a minimum number of years should NOT be used.

This Job Description is intended to provide a high level guide to the role. However, it is not intended to amend or otherwise restrict/expand the duties required from each individual employee as set out in their respective employment contract and/or as otherwise agreed between an employee and their manager.

Additional Job Description

Compensation Grade

SPB3

This role requires access to U.S. export-controlled information. If applicable, final offers will be contingent on ability to obtain authorization for access to U.S. export-controlled information from the U.S. Government.

Additional Information

GE Aerospace offers a great work environment, professional development, challenging careers, and competitive compensation. GE Aerospace is an Equal Opportunities Employer. Employment decisions are made without regard to race, color, religion, national or ethnic origin, sex, sexual orientation, gender identity or expression, age, disability, protected veteran status or other characteristics protected by law.

GE Aerospace will only employ those who are legally authorized to work in the United States for this opening.

Relocation Assistance Provided: Yes",2025-07-23T00:00:00.000Z,2025-07-25,"['This role requires a strong technical background, excellent problem-solving skills, and the ability to work collaboratively with data engineers, analysts, and other stakeholders', 'Bachelor’s degree from accredited university or college with minimum of 6 years of professional experience OR associates degree with minimum of 8 years of professional experience', '4 years proficiency in Python (mandatory)', '3 years demonstrated expertise in cloud platforms (e.g', 'AWS, Azure, Google Cloud, Databricks) and their machine learning services', '3 years demonstrated expertise working and leading in team settings in various roles', 'Note: Military experience is equivalent to professional experience', 'Legal authorization to work in the U.S. is required', ""To comply with US immigration and other legal requirements, it is necessary to specify the minimum number of years' experience required for any role based within the USA"", 'For roles outside of the USA, to ensure compliance with applicable legislation, the JDs should focus on the substantive level of experience required for the role and a minimum number of years should NOT be used']","['As a Sr Staff Data Scientist, you will lead and work within teams as a technical domain expert addressing statistical, machine learning, and artificial intelligence problems in a commercial technology and consultancy development environment', 'You will be part of a data science or cross-disciplinary team driving AI business solutions involving large, complex data sets', 'Potential application areas include time series forecasting, machine learning regression and classification, root cause analysis (RCA), simulation and optimization, large language models, and computer vision', 'The ideal candidate will be responsible for developing and deploying machine learning models in production environments', 'Understand business problems and identify opportunities to implement data science solutions', 'Develop, verify, and validate analytics to address customer needs and opportunities', 'Design, develop, and deploy machine learning models and algorithms', 'Work in technical teams on the development, deployment, and application of applied analytics, predictive analytics, and prescriptive analytics', 'Develop and maintain pipelines for Retrieval-Augmented Generation (RAG) and Large Language Models (LLM)', 'Collaborate with data scientists to optimize RAG and LLM pipelines for performance and accuracy', 'Utilize semantic and ontology technologies to enhance data integration and retrieval', 'Ensure data is semantically enriched to support advanced analytics and machine learning models', 'Interact with cloud services and develop and deploy models within cloud environments such as AWS, Azure, Google Cloud, and Databricks', 'Perform exploratory and targeted data analyses using descriptive statistics and other methods', 'Work with data engineers on data quality assessment, data cleansing, data analytics, and model productionization', 'Generate reports, annotated code, and other projects artifacts to document, archive, and communicate your work and outcomes', 'Communicate methods, findings, and hypotheses with stakeholders', 'Mentor colleagues in technical areas and drive standardization across the analytics enterprise', 'Review data science/AI projects for technical rigor']",True,"['Large Language Models', 'Retrieval-Augmented Generation', 'Computer Vision']",Large Language Models: Involved in developing and maintaining advanced AI models for natural language understanding and generation.; Retrieval-Augmented Generation: Developed and optimized pipelines combining retrieval techniques with generative AI models to enhance performance.; Computer Vision: Applied AI techniques for image and video analysis as part of business solutions.,"['Time Series Forecasting', 'Regression Models', 'Classification Models', 'Root Cause Analysis', 'Simulation and Optimization', 'Machine Learning Model Development and Deployment', 'Applied Analytics', 'Predictive Analytics', 'Prescriptive Analytics', 'Semantic and Ontology Technologies', 'Exploratory Data Analysis', 'Data Quality Assessment and Cleansing', 'Data Analytics', 'Model Productionization', 'Python Programming', 'Cloud Platforms and Machine Learning Services', 'CI/CD Pipelines']","Time Series Forecasting: Used as a potential application area for predicting future values based on historical data trends.; Regression Models: Applied for modeling relationships between variables to predict continuous outcomes.; Classification Models: Used to categorize data points into predefined classes as part of machine learning tasks.; Root Cause Analysis: Employed to identify underlying causes of issues within data or processes.; Simulation and Optimization: Applied to model complex systems and improve decision-making through optimization techniques.; Machine Learning Model Development and Deployment: Involves designing, building, and operationalizing machine learning models in production environments.; Applied Analytics: Focuses on practical use of data analytics to solve business problems.; Predictive Analytics: Used to forecast future events based on historical data patterns.; Prescriptive Analytics: Provides recommendations for decision-making based on data analysis.; Semantic and Ontology Technologies: Utilized to enhance data integration and retrieval by enriching data with semantic context.; Exploratory Data Analysis: Performed using descriptive statistics to understand data characteristics and inform modeling.; Data Quality Assessment and Cleansing: Ensures accuracy and reliability of data before analysis and model deployment.; Data Analytics: General analysis of data to extract insights and support decision-making.; Model Productionization: Process of deploying and maintaining models in operational environments.; Python Programming: Primary programming language used for data science and machine learning tasks.; Cloud Platforms and Machine Learning Services: Utilized AWS, Azure, Google Cloud, and Databricks for developing and deploying machine learning models.; CI/CD Pipelines: Implemented continuous integration and deployment pipelines to automate model deployment and updates."
Ovm-G7mZRL8v1phBAAAAAA==,Senior Data Scientist 451 Jobs,"Description: NSI requires a Senior Data Scientist to support an upcoming Naval Air Warfare Center Aircraft Division Lakehurst Mission Operations & Integration (MO&I) Department Contractor Support Services Program Office. The Senior Data Scientist will develop and implement data strategies that align with business objectives, ensuring effective utilization of data assets across the organization. Collaborate with cross-functional teams, including engineering, product development, and business stakeholders, to understand their needs and deliver data-driven solutions. Overseeing data collection, storage, and maintenance, you will ensure data integrity and security and enforce data governance policies. Staying current with advancements in data science and machine learning, drive innovation and continuous improvement within the team. Additionally, communicate findings and recommendations to senior management and other stakeholders, translating complex technical concepts into actionable business insights. Utilizing advanced analytics tools and technologies, you will enhance data processing and analysis capabilities, ensuring the scalability and efficiency of data solutions.

Location: Lakehurst, NJ

Education: BS in Computer Science, Mathematics, Statistics, Data Science or related scientific /technical discipline.

Experience: Requires a minimum of ten (10) years of data science experience; over five (5) years of programming experience (e.g., C++, JAVA) of the most current generation.

Security Clearance: Secret Clearance is required. Must be a U.S. citizen.

Special Notes/Instructions: NSI is a privately held, small but quickly growing company with headquarters in Lexington Park, Maryland within 5 miles of the Patuxent River Naval Air Station. Established in 2004, we are now celebrating 21 years of excellence in providing quality products and services to the Department of Defense. Our benefits package includes medical, dental, vision, Long Term Disability, Life Insurance, Short Term Disability, paid time off, paid holidays, flexible spending account, employee assistance program, tuition assistance program, 401k Plan with company match as well as a fun and enthusiastic work environment!

To Apply: NSI offers a team-oriented work environment and competitive compensation and employee benefits package. If you have a commitment to excellence and want to join our team of top caliber professionals, we invite you to submit your resume electronically by visiting our careers website at: https://n-s-i.us/careers/apply/.

Quality, Integrity, Teamwork, Success - that's NSI!

NSI is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status.",2025-07-24T00:00:00.000Z,2025-07-25,"['Education: BS in Computer Science, Mathematics, Statistics, Data Science or related scientific /technical discipline', 'Experience: Requires a minimum of ten (10) years of data science experience; over five (5) years of programming experience (e.g., C++, JAVA) of the most current generation', 'Security Clearance: Secret Clearance is required', 'Must be a U.S. citizen']","['Description: NSI requires a Senior Data Scientist to support an upcoming Naval Air Warfare Center Aircraft Division Lakehurst Mission Operations & Integration (MO&I) Department Contractor Support Services Program Office', 'The Senior Data Scientist will develop and implement data strategies that align with business objectives, ensuring effective utilization of data assets across the organization', 'Collaborate with cross-functional teams, including engineering, product development, and business stakeholders, to understand their needs and deliver data-driven solutions', 'Overseeing data collection, storage, and maintenance, you will ensure data integrity and security and enforce data governance policies', 'Staying current with advancements in data science and machine learning, drive innovation and continuous improvement within the team', 'Additionally, communicate findings and recommendations to senior management and other stakeholders, translating complex technical concepts into actionable business insights', 'Utilizing advanced analytics tools and technologies, you will enhance data processing and analysis capabilities, ensuring the scalability and efficiency of data solutions']",True,[],,"['Data Strategy Development', 'Data Governance', 'Advanced Analytics', 'Data Collection and Storage', 'Machine Learning', 'Programming (C++, Java)', 'Cross-functional Collaboration', 'Communication of Technical Insights']","Data Strategy Development: Developing and implementing data strategies to align with business objectives and optimize data asset utilization.; Data Governance: Enforcing policies to ensure data integrity, security, and proper management of data assets.; Advanced Analytics: Using advanced analytics tools and technologies to enhance data processing and analysis capabilities.; Data Collection and Storage: Overseeing the collection, storage, and maintenance of data to support organizational needs.; Machine Learning: Applying machine learning techniques to drive innovation and continuous improvement within the data science team.; Programming (C++, Java): Utilizing programming skills in C++ and Java to support data science tasks and solutions.; Cross-functional Collaboration: Working with engineering, product development, and business stakeholders to deliver data-driven solutions.; Communication of Technical Insights: Translating complex technical concepts into actionable business insights for senior management and stakeholders."
xR4raTaIOb_Gja9mAAAAAA==,Senior Data Scientist,"An exciting career awaits you

At MPC, we're committed to being a great place to work - one that welcomes new ideas, encourages diverse perspectives, develops our people, and fosters a collaborative team environment.

Position Summary

We are seeking a highly skilled and experienced Sr. Data Scientist to join our dynamic Data Science and AI team. In this role, you will be instrumental in transforming data into actionable insights and innovative solutions, driving forward our business strategy. You will leverage advanced machine learning, statistical techniques, and analytical prowess to solve complex business challenges, collaborating closely with cross-functional teams to design, develop, and deploy scalable AI-driven models and algorithms.
This position belongs to a family of jobs with increasing responsibility, competency, and skill level. Actual position title and pay grade will be based on the selected candidate's experience and qualifications.

Key Responsibilities
• Leads multiple data science projects ensuring alignment with business goals.
• Develops predictive models and integrates them with Business Intelligence tools.
• Develops and maintains data pipelines for efficient data retrieval and processing. Collaborates with applications and data engineering teams for deploying models at scale.
• Mentors junior data scientists in model development and data handling.
• Engages with Senior Leadership to inform strategic decisions using business intelligence insights.
• Researches and adopts cutting-edge technologies and methodologies in data science.
• Manages stakeholder expectations and delivers actionable solutions.
• Oversees data processing pipelines ensuring data quality and consistency.
• Drives ethical considerations in model deployment and data utilization.
• Collaborates with external partners, research institutions, and subject matter experts to gather domain-specific knowledge and datasets.
• Performs exploratory data analysis to identify patterns, insights, and communicate findings.
• Engage in the ideation and prototyping of new solutions to meet emerging business requirements.
• Utilize advanced machine learning techniques (e.g., deep learning, NLP, computer vision, reinforcement learning) to create innovative solutions.

Education and Experience
• Bachelor's Degree in Information Technology or related field required.
• Master's or Ph.D. in Computer Science, Statistics, Mathematics, or a related field preferred
• 5+ years of relevant experience required.
• Expertise in Python and proficiency in ML frameworks (TensorFlow, PyTorch, scikit-learn).
• Deep understanding of ML algorithms (supervised, unsupervised learning, and deep learning) and their applications.
• Strong problem-solving, critical thinking, and analytical capabilities.

Skills
• Artificial Intelligence (AI) and Machine Learning (ML) - Understanding of AI/ML concepts, algorithms, and platforms to design architectures that support intelligent systems and enable AI-driven applications.
• Business Domain Knowledge - Understanding of business processes, industry trends, and market dynamics to provide relevant and actionable insights for strategic decision-making.
• Communication and Collaboration - Excellent communication skills to effectively interact with stakeholders, gather requirements, present architectural proposals, and collaborate with cross-functional teams.
• Data Analysis - The process of measuring and managing organizational data, identifying methodological best practices, and conducting statistical analyses.
• Data Ethics & Responsible Innovation - Knowledge of ethical considerations related to data usage, data-driven technologies, and strategies to mitigate biases in data-driven decision-making.
• Data Mining and Extraction - Data mining is sorting through data to identify patterns and establish relationships. Data mining parameters include: Association - looking for patterns where one event is connected to another event Sequence or path analysis - looking for patterns where one event leads to another later event Classification - looking for new patterns [May result in a change in the way the data is organized but that's ok] Clustering - finding and visually documenting groups of facts not previously known Forecasting - discovering patterns in data that can lead to reasonable predictions about the future Data mining techniques are used in mathematics, cybernetics, and genetics. Web mining, a type of data mining used in customer relationship management [CRM], takes advantage of the huge amount of information gathered by a Web site to look for patterns in user behavior.
• Data Monetization and Data Science - Familiarity with data monetization strategies and techniques, such as data commercialization, data marketplaces, and data value realization.
• Natural Language Processing - Proficiency in analyzing and extracting insights from unstructured text data, including sentiment analysis, topic modeling, and language understanding.
• Problem-Solving and Analytical Thinking - Strong problem-solving skills to identify architectural challenges, analyze requirements, evaluate options, and propose effective solutions.
• Reporting and Dashboarding - The ability to access information from databases, forms, and other sources, and prepare reports according to requirements.
• Statistical Analysis - Statistical Analysis is used in support of decision-making and includes fundamental principles such as data collection and sampling, random variable types and probability distributions, sampling, and population distributions, making estimations from samples, hypothesis testing, and statistical process control.

As an energy industry leader, our career opportunities fuel personal and professional growth.

Location:
San Antonio, Texas

Job Requisition ID:
00017703

Pay Min/Max:
$104,300.00 - $179,800.00 Salary

Grade:
11 - 12

Location Address:
19100 Ridgewood Pkwy

Additional locations:
Denver CO, Findlay, Ohio

Education:
Bachelors: Information Technology (Required)

Employee Group:
Full time

Employee Subgroup:
Regular

Marathon Petroleum Company LP is an Equal Opportunity Employer and gives consideration for employment to qualified applicants without discrimination on the basis of race, color, religion, creed, sex, gender (including pregnancy, childbirth, breastfeeding or related medical conditions), sexual orientation, gender identity, gender expression, reproductive health decision-making, age, mental or physical disability, medical condition or AIDS/HIV status, ancestry, national origin, genetic information, military, veteran status, marital status, citizenship or any other status protected by applicable federal, state, or local laws. If you would like more information about your EEO rights as an applicant, click here .

If you need a reasonable accommodation for any part of the application process at Marathon Petroleum LP, please contact our Human Resources Department at . Please specify the reasonable accommodation you are requesting, along with the job posting number in which you may be interested. A Human Resources representative will review your request and contact you to discuss a reasonable accommodation. Marathon Petroleum offers a total rewards program which includes, but is not limited to, access to health, vision, and dental insurance, paid time off, 401k matching program, paid parental leave, and educational reimbursement. Detailed benefit information is available at mympcbenefits.com . The hired candidate will also be eligible for a discretionary company-sponsored annual bonus program.

Equal Opportunity Employer: Veteran / Disability

We will consider all qualified Applicants for employment, including those with arrest or conviction records, in a manner consistent with the requirements of applicable state and local laws. In reviewing criminal history in connection with a conditional offer of employment, Marathon will consider the key responsibilities of the role.",2025-07-17T00:00:00.000Z,2025-07-25,"['We are seeking a highly skilled and experienced Sr', ""Bachelor's Degree in Information Technology or related field required"", '5+ years of relevant experience required', 'Expertise in Python and proficiency in ML frameworks (TensorFlow, PyTorch, scikit-learn)', 'Deep understanding of ML algorithms (supervised, unsupervised learning, and deep learning) and their applications', 'Strong problem-solving, critical thinking, and analytical capabilities', 'Artificial Intelligence (AI) and Machine Learning (ML) - Understanding of AI/ML concepts, algorithms, and platforms to design architectures that support intelligent systems and enable AI-driven applications', 'Business Domain Knowledge - Understanding of business processes, industry trends, and market dynamics to provide relevant and actionable insights for strategic decision-making', 'Communication and Collaboration - Excellent communication skills to effectively interact with stakeholders, gather requirements, present architectural proposals, and collaborate with cross-functional teams', 'Data Analysis - The process of measuring and managing organizational data, identifying methodological best practices, and conducting statistical analyses', 'Data Ethics & Responsible Innovation - Knowledge of ethical considerations related to data usage, data-driven technologies, and strategies to mitigate biases in data-driven decision-making', 'Data Monetization and Data Science - Familiarity with data monetization strategies and techniques, such as data commercialization, data marketplaces, and data value realization', 'Natural Language Processing - Proficiency in analyzing and extracting insights from unstructured text data, including sentiment analysis, topic modeling, and language understanding', 'Problem-Solving and Analytical Thinking - Strong problem-solving skills to identify architectural challenges, analyze requirements, evaluate options, and propose effective solutions', 'Reporting and Dashboarding - The ability to access information from databases, forms, and other sources, and prepare reports according to requirements', 'Bachelors: Information Technology (Required)']","['In this role, you will be instrumental in transforming data into actionable insights and innovative solutions, driving forward our business strategy', 'You will leverage advanced machine learning, statistical techniques, and analytical prowess to solve complex business challenges, collaborating closely with cross-functional teams to design, develop, and deploy scalable AI-driven models and algorithms', 'This position belongs to a family of jobs with increasing responsibility, competency, and skill level', 'Leads multiple data science projects ensuring alignment with business goals', 'Develops predictive models and integrates them with Business Intelligence tools', 'Develops and maintains data pipelines for efficient data retrieval and processing', 'Collaborates with applications and data engineering teams for deploying models at scale', 'Mentors junior data scientists in model development and data handling', 'Engages with Senior Leadership to inform strategic decisions using business intelligence insights', 'Researches and adopts cutting-edge technologies and methodologies in data science', 'Manages stakeholder expectations and delivers actionable solutions', 'Oversees data processing pipelines ensuring data quality and consistency', 'Drives ethical considerations in model deployment and data utilization', 'Collaborates with external partners, research institutions, and subject matter experts to gather domain-specific knowledge and datasets', 'Performs exploratory data analysis to identify patterns, insights, and communicate findings', 'Engage in the ideation and prototyping of new solutions to meet emerging business requirements', 'Utilize advanced machine learning techniques (e.g., deep learning, NLP, computer vision, reinforcement learning) to create innovative solutions', 'Data Mining and Extraction - Data mining is sorting through data to identify patterns and establish relationships', ""Data mining parameters include: Association - looking for patterns where one event is connected to another event Sequence or path analysis - looking for patterns where one event leads to another later event Classification - looking for new patterns [May result in a change in the way the data is organized but that's ok] Clustering - finding and visually documenting groups of facts not previously known Forecasting - discovering patterns in data that can lead to reasonable predictions about the future Data mining techniques are used in mathematics, cybernetics, and genetics"", 'Web mining, a type of data mining used in customer relationship management [CRM], takes advantage of the huge amount of information gathered by a Web site to look for patterns in user behavior', 'Statistical Analysis - Statistical Analysis is used in support of decision-making and includes fundamental principles such as data collection and sampling, random variable types and probability distributions, sampling, and population distributions, making estimations from samples, hypothesis testing, and statistical process control']",True,"['Deep Learning', 'Natural Language Processing with AI', 'Computer Vision', 'Reinforcement Learning', 'TensorFlow', 'PyTorch']",Deep Learning: Employs deep learning techniques to build advanced AI-driven models for complex problem solving.; Natural Language Processing with AI: Applies NLP techniques within AI frameworks to extract insights and build intelligent applications.; Computer Vision: Uses computer vision methods as part of AI solutions to interpret and analyze visual data.; Reinforcement Learning: Implements reinforcement learning algorithms to develop AI models that learn optimal actions through interaction.; TensorFlow: Utilizes TensorFlow framework for building and deploying neural network-based AI models.; PyTorch: Employs PyTorch framework for developing and training deep learning models in AI applications.,"['Predictive Modeling', 'Business Intelligence Tools', 'Data Pipelines', 'Exploratory Data Analysis', 'Data Mining', 'Statistical Analysis', 'Natural Language Processing', 'Data Ethics', 'Data Monetization', 'Reporting and Dashboarding', 'Machine Learning', 'Python', 'Scikit-learn']","Predictive Modeling: Develops predictive models to forecast outcomes and support business decision-making.; Business Intelligence Tools: Integrates predictive models with BI tools to provide actionable business insights.; Data Pipelines: Develops and maintains data pipelines for efficient data retrieval, processing, and ensuring data quality.; Exploratory Data Analysis: Performs exploratory data analysis to identify patterns and communicate findings to stakeholders.; Data Mining: Applies data mining techniques such as association, sequence analysis, classification, clustering, and forecasting to discover patterns and relationships in data.; Statistical Analysis: Uses statistical methods including sampling, hypothesis testing, and process control to support data-driven decision-making.; Natural Language Processing: Analyzes and extracts insights from unstructured text data, including sentiment analysis and topic modeling.; Data Ethics: Drives ethical considerations in data usage and model deployment to mitigate biases and ensure responsible innovation.; Data Monetization: Familiarity with strategies for data commercialization and realizing data value.; Reporting and Dashboarding: Prepares reports and dashboards by accessing and aggregating data from various sources to meet business requirements.; Machine Learning: Leverages machine learning algorithms including supervised and unsupervised learning to solve complex business challenges.; Python: Uses Python programming language for data analysis, model development, and deployment.; Scikit-learn: Utilizes scikit-learn library for implementing traditional machine learning algorithms."
hiPwBaWcFXanqlFtAAAAAA==,"Data Scientist, Senior Jobs","Job Number: R0221333

Data Scientist, Senior

The Opportunity:

Are you intrigued by the power of machine learning and generative AI to solve real-world challenges? In today's data-driven world, we are seeking professionals ready to architect, develop, and deploy scalable, production-ready analytics solutions that transform massive volumes of structured and unstructured data into actionable insights. Join our team to apply your skills in data science, visualization, and UI / UX design to mission-critical intelligence work.

You'll work side by side with mission partners to understand their objectives and navigate data rich environments. As a key contributor, you will design and operationalize machine learning models, predictive analytics, and web-based tools using both streaming and batch data pipelines. You'll bring intelligence analysis into the future through agile collaboration and by building interactive visual interfaces that translate the results of advanced AI models into meaningful decisions. We emphasize end-to-end development from rapid prototyping to deployment in cloud-based environments ensuring that your solutions are aligned with current architecture while remaining adaptable for future innovation.

Join us. The world can't wait.

You Have:
• 6+ years of experience in data science, analytics, or machine learning
• Experience with Python for data wrangling, modeling, and visualization, including Pandas, NumPy, Matplotlib, and Seaborn
• Experience crafting prompts for Gen AI Large Language Models (LLM)
• Experience developing UI / UX solutions using JavaScript, HTML5, and CSS3
• Experience in object-oriented languages such as Python, Java, C++, or C#
• Experience with machine learning frameworks such as TensorFlow, PyTorch, or scikit-learn
• Knowledge of cloud platforms such as AWS, Azure, or GCP, including model hosting and containerization such as Docker and Kubernetes
• Ability to build and deploy production-grade models and analytics tools
• TS/SCI clearance with a polygraph
• HS diploma or GED

Nice If You Have:
• Experience working with streaming data technologies such as Apache Kafka and Flink, and distributed systems such as Hadoop and Spark
• Experience with Agile methodologies, automated testing, and DevOps practices
• Experience in open-source databases such as MySQL, PostgreSQL, or SQLite
• Knowledge of USINDOPACOM area of responsibility
• Knowledge of intelligence analysis frameworks, operational systems, and tools
• Knowledge of data-centric architecture, including security, scalability, and data governance
• Ability to move analytic prototypes into fully operational mission environments
• Bachelor's degree in a Science, Technology, Engineering, or Mathematics (STEM) field such as CS or Data Science preferred; Master's degree in a STEM field such as CS or Data Science a plus

Clearance:

Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information ; TS/SCI clearance with polygraph is required.

Compensation

At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen's benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.

Salary at Booz Allen is determined by various factors, including but not limited to location, the individual's particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $99,000.00 to $225,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen's total compensation package for employees. This posting will close within 90 days from the Posting Date.

Identity Statement

As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud.

Work Model

Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.
• If this position is listed as remote or hybrid, you'll periodically work from a Booz Allen or client site facility.
• If this position is listed as onsite, you'll work with colleagues and clients in person, as needed for the specific role.

Commitment to Non-Discrimination

All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law.",2025-07-19T00:00:00.000Z,2025-07-25,"['6+ years of experience in data science, analytics, or machine learning', 'Experience with Python for data wrangling, modeling, and visualization, including Pandas, NumPy, Matplotlib, and Seaborn', 'Experience crafting prompts for Gen AI Large Language Models (LLM)', 'Experience developing UI / UX solutions using JavaScript, HTML5, and CSS3', 'Experience in object-oriented languages such as Python, Java, C++, or C#', 'Experience with machine learning frameworks such as TensorFlow, PyTorch, or scikit-learn', 'Knowledge of cloud platforms such as AWS, Azure, or GCP, including model hosting and containerization such as Docker and Kubernetes', 'Ability to build and deploy production-grade models and analytics tools', 'TS/SCI clearance with a polygraph', 'HS diploma or GED', 'Experience working with streaming data technologies such as Apache Kafka and Flink, and distributed systems such as Hadoop and Spark', 'Experience with Agile methodologies, automated testing, and DevOps practices', 'Experience in open-source databases such as MySQL, PostgreSQL, or SQLite', 'Knowledge of USINDOPACOM area of responsibility', 'Knowledge of intelligence analysis frameworks, operational systems, and tools', 'Knowledge of data-centric architecture, including security, scalability, and data governance', 'Ability to move analytic prototypes into fully operational mission environments', 'Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information ; TS/SCI clearance with polygraph is required']","['Join our team to apply your skills in data science, visualization, and UI / UX design to mission-critical intelligence work', ""You'll work side by side with mission partners to understand their objectives and navigate data rich environments"", 'As a key contributor, you will design and operationalize machine learning models, predictive analytics, and web-based tools using both streaming and batch data pipelines', ""You'll bring intelligence analysis into the future through agile collaboration and by building interactive visual interfaces that translate the results of advanced AI models into meaningful decisions"", ""If this position is listed as remote or hybrid, you'll periodically work from a Booz Allen or client site facility"", ""If this position is listed as onsite, you'll work with colleagues and clients in person, as needed for the specific role""]",True,"['Generative AI', 'Large Language Models', 'Prompt Engineering', 'TensorFlow', 'PyTorch']",Generative AI: Crafting prompts and leveraging Large Language Models to solve real-world challenges and enhance intelligence analysis.; Large Language Models: Using LLMs as part of generative AI capabilities to generate insights and support decision-making.; Prompt Engineering: Designing effective prompts to interact with generative AI models for improved output quality.; TensorFlow: Applied as a deep learning framework for building neural network models within AI workflows.; PyTorch: Used as a deep learning framework for developing and deploying neural network-based AI models.,"['Machine Learning', 'Python', 'Pandas', 'NumPy', 'Matplotlib', 'Seaborn', 'Scikit-learn', 'TensorFlow', 'PyTorch', 'Streaming Data Pipelines', 'Batch Data Pipelines', 'Apache Kafka', 'Apache Flink', 'Hadoop', 'Spark', 'SQL Databases', 'Data Visualization', 'Cloud Platforms', 'Containerization', 'Agile Methodologies', 'DevOps Practices']","Machine Learning: Designing and operationalizing predictive models and analytics solutions to extract insights from data.; Python: Used for data wrangling, modeling, and visualization with libraries such as Pandas, NumPy, Matplotlib, and Seaborn.; Pandas: A Python library used for data manipulation and analysis in the role.; NumPy: A Python library used for numerical computations and array operations in data processing.; Matplotlib: A Python library used for creating static, animated, and interactive visualizations.; Seaborn: A Python visualization library based on Matplotlib, used for statistical graphics.; Scikit-learn: A machine learning framework used for building and deploying traditional ML models.; TensorFlow: A machine learning framework used for building and deploying models, including deep learning.; PyTorch: A machine learning framework used for building and deploying models, including deep learning.; Streaming Data Pipelines: Using technologies like Apache Kafka and Flink to process real-time data streams.; Batch Data Pipelines: Processing large volumes of data in batches using distributed systems such as Hadoop and Spark.; Apache Kafka: A streaming data platform used to build real-time data pipelines and streaming apps.; Apache Flink: A stream processing framework used for real-time analytics and data processing.; Hadoop: A distributed storage and processing framework used for batch data processing.; Spark: A distributed computing system used for big data processing and analytics.; SQL Databases: Using open-source relational databases like MySQL, PostgreSQL, and SQLite for data storage and querying.; Data Visualization: Creating interactive visual interfaces to translate data and model results into actionable insights.; Cloud Platforms: Utilizing AWS, Azure, or GCP for hosting models, data storage, and scalable analytics solutions.; Containerization: Using Docker and Kubernetes to deploy and manage scalable, production-grade models and analytics tools.; Agile Methodologies: Applying agile practices for iterative development and collaboration in data science projects.; DevOps Practices: Incorporating automated testing and deployment pipelines to ensure reliable delivery of analytics solutions."
jWxFAP0iymu5r3AzAAAAAA==,"Senior Data Scientist, AI Foundations","Senior Data Scientist, AI Foundations

Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making.

As a Data Scientist at Capital One, you’ll be part of a team that’s leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives.

Team Description

AI Foundations Specialist Models Data Science team builds and ships state of the art scalable architecture, AI/ML solutions for Capital One’s award-winning mobile app. We partner with product, tech and design teams to deliver app features that delight customers with dynamic and personalized experiences, enable them to chat with Capital One’s digital assistant Eno, or search for useful contents. You will be the driving force to experiment, innovate and create next generation experiences powered by the latest emerging generative AI technologies.

In this role, you will:
• Partner with a cross-functional team of data scientists, software engineers, machine learning engineers and product managers to deliver AI powered products that change how customers interact with their money.
• Leverage a broad stack of technologies — Pytorch, AWS Ultraclusters, Hugging Face, LangChain, Lightning, VectorDBs, and more — to reveal the insights hidden within huge volumes of numeric and textual data.
• Be the expert in Natural Language Processing (NLP) to harness the power of Large Language Models (LLMs), adapt and finetune them for customer facing applications and features.
• Build machine learning and NLP models through all phases of development, from design through training, evaluation, and validation; partnering with engineering teams to operationalize them in scalable and resilient production systems that serve 80+ million customers.
• Flex your interpersonal skills to translate the complexity of your work into tangible business goals.

The Ideal Candidate is:
• Customer first. You love the process of analyzing and creating, but also share our passion to do the right thing. You know at the end of the day it’s about making the right decision for our customers.
• Innovative. You continually research and evaluate emerging technologies. You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them.
• Creative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You’re not afraid to share a new idea.
• A leader. You challenge conventional thinking and work with stakeholders to identify and improve the status quo. You're passionate about talent development for your own team and beyond.
• Technical. You’re comfortable with advanced ML and DL technologies including language models and are passionate about developing further. You have hands-on experience working with LLMs and solutions using open-source tools and cloud computing platforms.
• Influential. You are passionate about AI/ML and can bring along a cross functional team in breakthrough innovations. You communicate clearly and effectively to share your findings with non-technical audiences.
• You are experienced in training language models or large computer vision models as well as have expertise in one or more key subdomains such as: training optimization, self-supervised learning, explainability, RLHF.
• You have an engineering mindset as shown by a track record of delivering models at scale both in training data and inference volumes. You have experience in delivering libraries, platforms, or solution level code to existing products.

Basic Qualifications:
• Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:
• A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 2 years of experience performing data analytics
• A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration

Preferred Qualifications:
• Master’s Degree in “STEM” field (Science, Technology, Engineering, or Mathematics), or PhD in “STEM” field (Science, Technology, Engineering, or Mathematics)
• Experience working with AWS
• At least 2 years’ experience in Python, Scala, or R
• At least 2 years’ experience with machine learning
• At least 2 years’ experience with SQL

Capital One will consider sponsoring a new qualified applicant for employment authorization for this position.

The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.

New York, NY: $145,100 - $165,600 for Sr Assoc, Data Science

San Jose, CA: $145,100 - $165,600 for Sr Assoc, Data Science

Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate’s offer letter.

This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.

Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.

This role is expected to accept applications for a minimum of 5 business days.

No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",2025-07-20T00:00:00.000Z,2025-07-25,"['Customer first', 'You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them', 'You thrive on bringing definition to big, undefined problems', 'You love asking questions and pushing hard to find answers', ""You're passionate about talent development for your own team and beyond"", 'Technical', 'You’re comfortable with advanced ML and DL technologies including language models and are passionate about developing further', 'You have hands-on experience working with LLMs and solutions using open-source tools and cloud computing platforms', 'Influential', 'You are passionate about AI/ML and can bring along a cross functional team in breakthrough innovations', 'You communicate clearly and effectively to share your findings with non-technical audiences', 'You are experienced in training language models or large computer vision models as well as have expertise in one or more key subdomains such as: training optimization, self-supervised learning, explainability, RLHF', 'You have an engineering mindset as shown by a track record of delivering models at scale both in training data and inference volumes', 'You have experience in delivering libraries, platforms, or solution level code to existing products', 'Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:', ""A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 2 years of experience performing data analytics"", ""A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration""]","['You will be the driving force to experiment, innovate and create next generation experiences powered by the latest emerging generative AI technologies', 'Partner with a cross-functional team of data scientists, software engineers, machine learning engineers and product managers to deliver AI powered products that change how customers interact with their money', 'Leverage a broad stack of technologies — Pytorch, AWS Ultraclusters, Hugging Face, LangChain, Lightning, VectorDBs, and more — to reveal the insights hidden within huge volumes of numeric and textual data', 'Be the expert in Natural Language Processing (NLP) to harness the power of Large Language Models (LLMs), adapt and finetune them for customer facing applications and features', 'Build machine learning and NLP models through all phases of development, from design through training, evaluation, and validation; partnering with engineering teams to operationalize them in scalable and resilient production systems that serve 80+ million customers', 'Flex your interpersonal skills to translate the complexity of your work into tangible business goals', 'You continually research and evaluate emerging technologies', 'You challenge conventional thinking and work with stakeholders to identify and improve the status quo']",True,"['Large Language Models', 'Generative AI', 'PyTorch', 'Hugging Face', 'LangChain', 'Lightning', 'Vector Databases', 'Reinforcement Learning with Human Feedback']","Large Language Models: Central to building and fine-tuning customer-facing NLP applications and digital assistants.; Generative AI: Used to create next-generation personalized experiences and AI-powered features.; PyTorch: Deep learning framework employed for developing and training neural network models.; Hugging Face: Open-source platform used for accessing and fine-tuning pre-trained language models.; LangChain: Framework for building applications with language models, enabling integration and orchestration.; Lightning: Tool for simplifying and scaling deep learning model training and deployment.; Vector Databases: Used to store and retrieve high-dimensional embeddings for efficient similarity search.; Reinforcement Learning with Human Feedback: Applied to improve model alignment and performance in AI systems.","['Machine Learning', 'Natural Language Processing', 'Training Optimization', 'Self-Supervised Learning', 'Explainability', 'Reinforcement Learning with Human Feedback', 'Python', 'Scala', 'R', 'SQL', 'AWS']","Machine Learning: Used to build predictive models and AI-powered products that improve customer financial interactions.; Natural Language Processing: Applied to develop and fine-tune models for customer-facing applications like digital assistants.; Training Optimization: Expertise required to efficiently train large language and computer vision models at scale.; Self-Supervised Learning: Used as a key subdomain technique for improving model performance without labeled data.; Explainability: Important for interpreting model decisions and communicating findings to stakeholders.; Reinforcement Learning with Human Feedback: Applied to enhance model behavior and alignment through feedback mechanisms.; Python: Programming language used for data analytics, machine learning, and model development.; Scala: Programming language experience preferred for data processing and analytics.; R: Used for statistical analysis and data science tasks.; SQL: Used for querying and managing relational databases containing customer data.; AWS: Cloud platform leveraged for scalable computing and data storage."
M_MpaS5ifiBn0kjBAAAAAA==,Senior Data Scientist Jobs,"ManTech seeks a motivated, career and customer-oriented Senior Data Scientist to join our team in Doral, FL.

Responsibilities include but are not limited to:
• Develop and implement data strategies and frameworks
• Identify data requirements, establish comprehensive data governance policies, and ensure data quality and integrity across the organization
• Design and implement data collection, storage, and retrieval processes to optimize data management and accessibility and conduct complex data analysis and modeling to derive valuable insights and recommendations for program management and decision-making
• Use advanced statistical techniques, data mining, and machine learning algorithms to uncover patterns, trends, and correlations within the data
• Provide actionable insights that drive strategic initiatives and enhance overall program performance. Create advanced reports, dashboards, and visualizations to effectively communicate program performance, KPIs, and trends. Leverage data visualization tools, such as Tableau or Power BI, to present complex data in a clear and concise manner, enabling stakeholders to make informed decisions
• Contribute to the development and implementation of data-driven initiatives, stay up-to-date with the latest advancements in data analytics, emerging technologies, and industry best practices, and ensure the organization remains at the forefront of data management and analysis
• Provide technical expertise in data analytics. Provide direction and mentorship to subordinate staff

Minimum Qualifications:
• Bachelor's degree in relevant field and a minimum of 9 years of relevant experience OR a Master's degree and 7 years of experience OR PhD and 5 years of experience.
• High School diploma and 4 years of additional experience or Associate's Degree and 2 years of additional experience may be exchanged in lieu of a required Bachelor's degree
• Experience in data science, data analysis, or a related field, with a proven track record of successfully developing and implementing data-driven solutions.
• Strong understanding of statistical modeling, machine learning algorithms, and data mining techniques. Proficiency in data analysis tools and languages (e.g., Python with pandas, scikit-learn, R, SQL). Experience with data visualization tools (e.g., Tableau, Power BI) and knowledge of data warehousing and data lake concepts.
• Experience with Big Data technologies (e.g., Hadoop, Spark).
• Experience in developing and implementing data strategies and frameworks. Understanding of data governance principles and best practices. Ability to identify data requirements and ensure data quality and integrity. Experience with data collection, storage, and retrieval processes. Strong analytical and problem-solving skills, with the ability to extract insights from complex data sets. Ability to identify patterns, trends, and correlations in data. Ability to translate data insights into actionable recommendations.
• DoD 8570.01-M IAT Level II certification.

Preferred Qualifications:
• PhD, Master's degree OR Bachelor's degree in Data Science, Information Technology, Cybersecurity, Computer Science, or related field.
• Experience supporting DoD programs and with cloud-based technologies, Risk Management Framework, and Zero Trust Architecture.
• Knowledge of data security and privacy regulations. Experience with data storytelling and presentation skills.
• Experience with advanced analytics techniques (e.g., deep learning, natural language processing). Specialized skills including cloud-based data platforms (e.g., AWS, Azure, GCP). Relevant certifications in data science or data analytics (e.g., Certified Analytics Professional (CAP)).ITIL certification.
• Experience at a DoD Combatant Command (e.g., SOUTHCOM, NORTHCOM, CENTCOM, CYBERCOM, INDOPACOM, EUCOM, AFRICOM, STRATCOM, TRANSCOM, SOCOM, SPACECOM) or a component is desired.

Clearance Requirements:
• Must possess an interim Secret clearance with the ability to obtain a Secret clearance

Physical Requirements:
• The person in this position must be able to remain in a stationary position 50% of the time. Occasionally move about inside the office to access file cabinets, office machinery, or to communicate with co-workers, management, and customers, via email, phone, and or virtual communication, which may involve delivering presentations.",2025-07-19T00:00:00.000Z,2025-07-25,"[""Bachelor's degree in relevant field and a minimum of 9 years of relevant experience OR a Master's degree and 7 years of experience OR PhD and 5 years of experience"", ""High School diploma and 4 years of additional experience or Associate's Degree and 2 years of additional experience may be exchanged in lieu of a required Bachelor's degree"", 'Experience in data science, data analysis, or a related field, with a proven track record of successfully developing and implementing data-driven solutions', 'Strong understanding of statistical modeling, machine learning algorithms, and data mining techniques', 'Proficiency in data analysis tools and languages (e.g., Python with pandas, scikit-learn, R, SQL)', 'Experience with data visualization tools (e.g., Tableau, Power BI) and knowledge of data warehousing and data lake concepts', 'Experience with Big Data technologies (e.g., Hadoop, Spark)', 'Experience in developing and implementing data strategies and frameworks', 'Understanding of data governance principles and best practices', 'Ability to identify data requirements and ensure data quality and integrity', 'Experience with data collection, storage, and retrieval processes', 'Strong analytical and problem-solving skills, with the ability to extract insights from complex data sets', 'Ability to identify patterns, trends, and correlations in data', 'Ability to translate data insights into actionable recommendations', 'DoD 8570.01-M IAT Level II certification', 'Experience with data storytelling and presentation skills', 'Experience with advanced analytics techniques (e.g., deep learning, natural language processing)', 'Specialized skills including cloud-based data platforms (e.g., AWS, Azure, GCP)', 'Relevant certifications in data science or data analytics (e.g., Certified Analytics Professional (CAP)).ITIL certification', 'Must possess an interim Secret clearance with the ability to obtain a Secret clearance', 'The person in this position must be able to remain in a stationary position 50% of the time']","['Develop and implement data strategies and frameworks', 'Identify data requirements, establish comprehensive data governance policies, and ensure data quality and integrity across the organization', 'Design and implement data collection, storage, and retrieval processes to optimize data management and accessibility and conduct complex data analysis and modeling to derive valuable insights and recommendations for program management and decision-making', 'Use advanced statistical techniques, data mining, and machine learning algorithms to uncover patterns, trends, and correlations within the data', 'Provide actionable insights that drive strategic initiatives and enhance overall program performance', 'Create advanced reports, dashboards, and visualizations to effectively communicate program performance, KPIs, and trends', 'Leverage data visualization tools, such as Tableau or Power BI, to present complex data in a clear and concise manner, enabling stakeholders to make informed decisions', 'Contribute to the development and implementation of data-driven initiatives, stay up-to-date with the latest advancements in data analytics, emerging technologies, and industry best practices, and ensure the organization remains at the forefront of data management and analysis', 'Provide technical expertise in data analytics', 'Provide direction and mentorship to subordinate staff', 'Occasionally move about inside the office to access file cabinets, office machinery, or to communicate with co-workers, management, and customers, via email, phone, and or virtual communication, which may involve delivering presentations']",True,"['Deep Learning', 'Natural Language Processing']",Deep Learning: Using neural network-based models to perform complex data analysis as part of advanced analytics.; Natural Language Processing: Applying computational techniques to analyze and interpret human language data.,"['Data Strategies and Frameworks', 'Data Governance', 'Data Collection, Storage, and Retrieval', 'Advanced Statistical Techniques', 'Data Mining', 'Machine Learning Algorithms', 'Python with pandas', 'scikit-learn', 'R', 'SQL', 'Data Visualization Tools', 'Data Warehousing and Data Lakes', 'Big Data Technologies', 'Data Storytelling', 'Advanced Analytics Techniques', 'Cloud-Based Data Platforms']","Data Strategies and Frameworks: Developing and implementing organizational approaches to manage and utilize data effectively.; Data Governance: Establishing policies to ensure data quality, integrity, and compliance across the organization.; Data Collection, Storage, and Retrieval: Designing processes to optimize how data is gathered, stored, and accessed for analysis.; Advanced Statistical Techniques: Applying sophisticated statistical methods to analyze data and uncover insights.; Data Mining: Extracting patterns and correlations from large datasets to inform decision-making.; Machine Learning Algorithms: Using algorithms to model data patterns and make predictions or classifications.; Python with pandas: Utilizing Python programming language and pandas library for data manipulation and analysis.; scikit-learn: Employing this Python library for implementing machine learning models and algorithms.; R: Using the R programming language for statistical computing and data analysis.; SQL: Querying and managing relational databases to extract and manipulate data.; Data Visualization Tools: Creating reports and dashboards using tools like Tableau and Power BI to communicate data insights.; Data Warehousing and Data Lakes: Knowledge of centralized repositories and storage systems for large-scale data management.; Big Data Technologies: Experience with platforms like Hadoop and Spark for processing and analyzing large datasets.; Data Storytelling: Presenting data insights effectively to stakeholders to support decision-making.; Advanced Analytics Techniques: Applying sophisticated methods such as deep learning and natural language processing to analyze data.; Cloud-Based Data Platforms: Utilizing cloud services like AWS, Azure, and GCP for scalable data storage and processing."
2GNIxKQ51Ih345PyAAAAAA==,STE - Senior Data Analyst Jobs,"Description

BlueForce Inc. is seeking a Senior Data Analyst in support of HQ USAF Sponsored or Supported Wargaming The Senior Data Analyst will conduct activities to plan, execute, manage, and analyze throughout all phases of HQ USAF wargames including concept development, objective analysis, assessment planning, game design, event planning, management and execution, and post-game analysis. Primary locations are Joint Base Andrews, MD, Joint Base Anacostia-Bolling and The Pentagon.
• **Position is Subject to Contract Award***

Duties and Responsibilities :
• Develops and implements software and database applications to support wargame design, execution, and analysis.
• Manages wargame CoP (e.g. ForceTracker) and coordinates, compiles and updates data (e.g., Operational Order of Battle, Facilities, Installations, etc.) from wargame participants and external data providers (e.g., intelligence community) to ensure accurate representation for wargames.
• Advises principal engineer when updates to software and database applications are required.
• Assists pre-game, concurrent, and/or post-game analysis.

Qualifications

Minimum Qualifications:
• Active TS/SCI security clearance.
• Master's degree or above with a minimum of ten (10) years of experience in modeling, simulations, or operations research analysis.
• Experience developing wargame tools and in providing wargame or operational analysis.
• Excellent communication skills in terms of writing and presenting briefings.

Desired Qualifications:
• Military wargame experience.",2025-07-25T02:00:00.000Z,2025-07-25,"['Active TS/SCI security clearance', ""Master's degree or above with a minimum of ten (10) years of experience in modeling, simulations, or operations research analysis"", 'Experience developing wargame tools and in providing wargame or operational analysis', 'Excellent communication skills in terms of writing and presenting briefings']","['BlueForce Inc. is seeking a Senior Data Analyst in support of HQ USAF Sponsored or Supported Wargaming The Senior Data Analyst will conduct activities to plan, execute, manage, and analyze throughout all phases of HQ USAF wargames including concept development, objective analysis, assessment planning, game design, event planning, management and execution, and post-game analysis', 'Develops and implements software and database applications to support wargame design, execution, and analysis', 'Manages wargame CoP (e.g. ForceTracker) and coordinates, compiles and updates data (e.g., Operational Order of Battle, Facilities, Installations, etc.) from wargame participants and external data providers (e.g., intelligence community) to ensure accurate representation for wargames', 'Advises principal engineer when updates to software and database applications are required', 'Assists pre-game, concurrent, and/or post-game analysis']",False,[],,"['Data Management', 'Operational Analysis', 'Database Applications', 'Modeling and Simulations']","Data Management: Managing and coordinating data from wargame participants and external providers to ensure accurate representation for analysis.; Operational Analysis: Providing analysis throughout all phases of wargames including concept development, objective analysis, and post-game assessment.; Database Applications: Developing and implementing software and database tools to support wargame design, execution, and analysis.; Modeling and Simulations: Applying modeling and simulation techniques as part of wargame tool development and operational research analysis."
OLbn6rBegU2ASEx_AAAAAA==,"Cleared Data Scientists in MD, to 175k - FS Poly Jobs","Who We Are
Stanley Reid is your one-stop shop for connecting with top contractors and exciting IC/DoD opportunities. We're a team of experts who go beyond just finding jobs, providing personalized guidance to match your unique skills and goals to the perfect fit. Our focus? A stress-free job search for you. Let's chat and unlock your career potential!

About Our Client
Forget typical data science firms obsessed with deploying models, our client thrives on unconventional solutions to real-world problems, using massive datasets and open-ended exploration like a research lab. More than technical whizzes, their team values creativity, engagement, and understanding your organization. They prioritize attracting and developing highly skilled minds. With many holding advanced degrees, they foster a culture of continuous learning and encourage pushing boundaries, staying at the forefront of their field. With competitive benefits, a vibrant culture, and multiple locations (including options with TELEWORK), they're ideal for passionate data scientists seeking to collaborate with the best. They don't just analyze, they predict the future - if you want to push boundaries and make a real impact, this might be your perfect match.

The Role
As a Senior Data Scientist, you'll lead research initiatives, proving and implementing groundbreaking solutions to advanced AI problems. Recognized as an expert within the field, you'll spearhead the exploration of new technologies, pushing boundaries and driving impact.

Responsibilities include:
Design and execute cutting-edge research programs.
Develop and demonstrate innovative solutions to complex AI challenges.
Lead a team of engineers/scientists in solution implementation.

What You'll Bring
15+ years of experience in Engineering, Computer Science, or STEM field (or equivalent with advanced degrees).
Proven track record of leading & delivering innovative solutions.
Deep expertise in AI technologies and methodologies.
Exceptional leadership and communication skills.

Clearance Requirements
TS/SCI with FS Polygraph (no clearance upgrades or CCAs). Please note, YOU MUST have the required clearance for consideration.

Location
Fort Meade, MD

Ready for next steps?
Apply online at https://careers.stanleyreid.com/, or contact our MD team for more info: mwhitford@stanleyreid.com, asmith@stanleyreid.com.

We look forward to exploring opportunities with you!

Please note: We are constantly expanding our network of opportunities and do our best to keep our openings current as they open and close. We encourage you to apply and connect with us even if a directly matching role isn't currently listed (or available), as new opportunities arise frequently. Due to the large volume of applications we receive daily, we are not able to individually follow-up to confirm receipt of submitted information or provide other status updates. You will hear from us if there is a match!

Reviewed & reposted (03/12/2025)",2025-07-24T00:00:00.000Z,2025-07-25,"['15+ years of experience in Engineering, Computer Science, or STEM field (or equivalent with advanced degrees)', 'Proven track record of leading & delivering innovative solutions', 'Deep expertise in AI technologies and methodologies', 'Exceptional leadership and communication skills', 'TS/SCI with FS Polygraph (no clearance upgrades or CCAs)', 'Please note, YOU MUST have the required clearance for consideration']","['More than technical whizzes, their team values creativity, engagement, and understanding your organization', 'They prioritize attracting and developing highly skilled minds', ""As a Senior Data Scientist, you'll lead research initiatives, proving and implementing groundbreaking solutions to advanced AI problems"", ""Recognized as an expert within the field, you'll spearhead the exploration of new technologies, pushing boundaries and driving impact"", 'Design and execute cutting-edge research programs', 'Develop and demonstrate innovative solutions to complex AI challenges', 'Lead a team of engineers/scientists in solution implementation']",True,['Advanced Artificial Intelligence'],Advanced Artificial Intelligence: Applying deep expertise in AI technologies and methodologies to solve complex AI challenges and develop groundbreaking solutions.,['Data Science Research'],Data Science Research: Leading research initiatives to explore and develop innovative data-driven solutions using massive datasets.
bU7z1i-Xp3rNeGmeAAAAAA==,Lead Data Science With LLM and NLP,"Title-Lead Data Science With LLM and NLP

Location-Mason OH

Mode Of Hire- Contract

Mode Of Work- onsite

Role Summary:

We are hiring a Senior Data Scientist with deep expertise in AI agent architectures, LLMs, NLP, and hands-on development experience with AXA Protocols and Model Context Protocols (MCP).

This role is integral in building interoperable, context-aware, and self-improving agents that interact across clinical, administrative, and benefits platforms.

We are looking for Senior Data Scientist with XX+ Years

Skill X X+ Yers Exp - AI agent architectures, LLMs, NLP developing A2A Protocols and Model Context Protocols (MCP)
Skill X - X+ Yers Exp - LLMs and NLP models (e.g., medical BERT, BioGPT)
SKill X - X+ Yers Exp - retrieval-augmented generation (RAG)
Skill X X+ Yers Exp - coding experience in Python, with proficiency in ML/NLP libraries
Skill X - X+ Yers Exp - healthcare data standards like FHIR, HLX, ICD/CPT, X1X EDI formats.
Skill X - X+ Yers Exp - AWS, Azure, or Google Cloud Platform including Kubernetes, Docker, and CI/CD

Preferred Qualifications
Deep understanding of MCP + VectorDB integration for dynamic agent memory and retrieval.
Prior work on LLM-based agents in production systems or large-scale healthcare operations.
Experience with voice AI, automated care navigation, or AI triage tools.
Published research or patents in agent systems, LLM architectures, or contextual AI frameworks.",2025-07-24T00:00:00.000Z,2025-07-25,"['We are looking for Senior Data Scientist with XX+ Years', 'Skill X X+ Yers Exp - AI agent architectures, LLMs, NLP developing A2A Protocols and Model Context Protocols (MCP)', 'Skill X - X+ Yers Exp - LLMs and NLP models (e.g., medical BERT, BioGPT)', 'SKill X - X+ Yers Exp - retrieval-augmented generation (RAG)', 'Skill X X+ Yers Exp - coding experience in Python, with proficiency in ML/NLP libraries', 'Skill X - X+ Yers Exp - healthcare data standards like FHIR, HLX, ICD/CPT, X1X EDI formats', 'Skill X - X+ Yers Exp - AWS, Azure, or Google Cloud Platform including Kubernetes, Docker, and CI/CD', 'Deep understanding of MCP + VectorDB integration for dynamic agent memory and retrieval', 'Prior work on LLM-based agents in production systems or large-scale healthcare operations', 'Experience with voice AI, automated care navigation, or AI triage tools', 'Published research or patents in agent systems, LLM architectures, or contextual AI frameworks']","['We are hiring a Senior Data Scientist with deep expertise in AI agent architectures, LLMs, NLP, and hands-on development experience with AXA Protocols and Model Context Protocols (MCP)', 'This role is integral in building interoperable, context-aware, and self-improving agents that interact across clinical, administrative, and benefits platforms']",True,"['Large Language Models', 'Natural Language Processing', 'AI Agent Architectures', 'Model Context Protocols', 'Retrieval-Augmented Generation', 'Vector Databases', 'Voice AI']","Large Language Models: Expertise in LLMs like medical BERT and BioGPT is required for developing advanced NLP applications in healthcare.; Natural Language Processing: Applied specifically to AI-driven language models and agent architectures for clinical and administrative platforms.; AI Agent Architectures: Designing and building interoperable, context-aware, and self-improving AI agents for healthcare operations.; Model Context Protocols: Used for managing context and interactions within AI agents, critical for dynamic and context-aware systems.; Retrieval-Augmented Generation: Applied to enhance LLM capabilities by integrating external knowledge retrieval for improved AI agent responses.; Vector Databases: Integrated with MCP to support dynamic agent memory and efficient retrieval in AI systems.; Voice AI: Experience with voice-based AI applications such as automated care navigation and AI triage tools.","['Python', 'ML/NLP libraries', 'Healthcare data standards', 'Cloud Platforms and DevOps']","Python: Used for coding and implementing machine learning and NLP models in the data science role.; ML/NLP libraries: Proficiency required for developing and deploying machine learning and natural language processing models.; Healthcare data standards: Knowledge of FHIR, HL7, ICD/CPT, and EDI formats is essential for handling and integrating healthcare data.; Cloud Platforms and DevOps: Experience with AWS, Azure, Google Cloud, Kubernetes, Docker, and CI/CD for managing data infrastructure and pipelines."
54AX23B3l6L8myBvAAAAAA==,Senior Technology Consultant- Data Science - CTJ- Poly Jobs,"We are looking to hire a Senior Technology Consultant - Data Science to join Microsoft Federal.

Microsoft is on a mission to empower every person and every organization on the planet to achieve more. Our culture is centered on embracing a growth mindset, a theme of inspiring excellence, and encouraging teams and leaders to bring their best each day. Growth mindset encourages each of us to lean in and learn what matters most to our customers, to create the foundational knowledge that enables us to make customer-first decisions in everything we do. In doing so, we create life-changing innovations that impact billions of lives around the world. You can help us achieve our mission.

The Microsoft Federal organization was established to address the unique mission, legal/regulatory requirements, and procurement rules and processes of the United States Government (USG). Microsoft Federal is committed to ensuring its resources - including appropriately qualified, experienced, and certified personnel (with necessary security clearances or otherwise) are available as needed to meet USG evolving needs. To that end, Microsoft embraces, as a mission-critical philosophy, flexibility in the recruiting, hiring, and workforce assignment of Microsoft Federal personnel. Microsoft Federal personnel can expect to serve in various roles in the Microsoft Federal organization during the course of their career to meet evolving USG needs, regardless of segment - Civilian, Defense, or intelligence community.

Are you ready to seize and opportunity to build advanced Artificial Intelligence (AI) and Machine Learning (ML) solutions leveraging the robust capabilities of the Microsoft Azure cloud? Do you thrive on taking a customer's vision from brainstorming on a white board to operational capability that drives Digital Transformation? If so, then the Delivery Data Scientist role in Microsoft Consulting is the right career for you!

Responsibilities

Our Delivery Data Scientists work within a team of project managers, solution architects and consultants to deliver Azure cloud AI/ML consulting engagements; typical responsibilities include:
• Educating our customers and partners on the power of AI/ML using the Azure Cloud
• Interacting with senior executives and key stakeholders in our customers to formulate AI/ML solutions that address challenges facing their organizations
• Developing and maintaining a high level of technical proficiency in Azure AI/ML cloud services
• Creating and sharing IP that leverages AI/ML Azure cloud services
• Other
• Embody our culture and values

Qualifications

Required/Minimum Qualifications:
• Bachelor's Degree in Computer Science , Engineering, Finance, Business, or related field AND 3+ years leadership experience in relevant area of business
• OR equivalent experience.

Other Requirements:

Security Clearance Requirements: Candidates must be able to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings:
• The successful candidate must have an active U.S. Government Top Secret Clearance with access to Sensitive Compartmented Information (SCI) based on a Single Scope Background Investigation (SSBI) with Polygraph. Ability to meet Microsoft, customer and/or government security screening requirements are required for this role. Failure to maintain or obtain the appropriate U.S. Government clearance and/or customer screening requirements may result in employment action up to and including termination.
• Clearance Verification: This position requires successful verification of the stated security clearance to meet federal government customer requirements. You will be asked to provide clearance verification information prior to an offer of employment.
• Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter.
• Citizenship & Citizenship Verification: This position requires verification of U.S. citizenship due to citizenship-based legal restrictions. Specifically, this position supports United States federal, state, and/or local United States government agency customer and is subject to certain citizenship-based restrictions where required or permitted by applicable law. To meet this legal requirement, citizenship will be verified via a valid passport, or other approved documents, or verified US government Clearance

Additional/Preferred Qualifications:
• Microsoft Development Experience such as C# Software development, .NET framework, Power Shell, SQL Server, JavaScript/HTML, Active Directory, Identity Management, Code troubleshooting
• Technical certifications based on domain (e.g., Azure, SharePoint).M365/O365, SharePoint, CoPilot, Teams
• Azure (Networking, Infrastructure, App Dev, Identity, Active Directory, Azure Stack, etc.)
• Business Applications (Dynamics 365, CRM, etc.)
• Data & AI (SQL, Azure SQL, Azure Data Factory, PowerBI, etc.)
• Identity & Networking (Azure, MIM, O365, etc.)
• Infrastructure (Win10, WVD, MECM, SCCM, etc.)
• Intelligent Communications (Teams, Exchange, Skype for Business, etc.)
• Modern Service Management/Adoption Change Management (MSM/ACM)
• PowerApps/Power Platform
• Project (Project Server Customization, Test, and Implementation)
• UX/UI & Accessibility
• Security & Identity (Sentinel, Azure Security Center, Microsoft Defender for Cloud)

Technology Consulting IC4 - The typical base pay range for this role across the U.S. is USD $100,000 - $193,800 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $126,100 - $204,000 per year.

Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here: https://careers.microsoft.com/us/en/us-corporate-pay

Microsoft will accept applications for the role until July 28th, 2025.

Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form .

Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.

#MCAPSA",2025-07-17T00:00:00.000Z,2025-07-25,"[""Bachelor's Degree in Computer Science , Engineering, Finance, Business, or related field AND 3+ years leadership experience in relevant area of business"", 'OR equivalent experience', 'Security Clearance Requirements: Candidates must be able to meet Microsoft, customer and/or government security screening requirements are required for this role', 'The successful candidate must have an active U.S. Government Top Secret Clearance with access to Sensitive Compartmented Information (SCI) based on a Single Scope Background Investigation (SSBI) with Polygraph', 'Ability to meet Microsoft, customer and/or government security screening requirements are required for this role', 'Failure to maintain or obtain the appropriate U.S. Government clearance and/or customer screening requirements may result in employment action up to and including termination', 'Clearance Verification: This position requires successful verification of the stated security clearance to meet federal government customer requirements', 'You will be asked to provide clearance verification information prior to an offer of employment', 'Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter', 'Citizenship & Citizenship Verification: This position requires verification of U.S. citizenship due to citizenship-based legal restrictions', 'Specifically, this position supports United States federal, state, and/or local United States government agency customer and is subject to certain citizenship-based restrictions where required or permitted by applicable law', 'To meet this legal requirement, citizenship will be verified via a valid passport, or other approved documents, or verified US government Clearance']","['Our Delivery Data Scientists work within a team of project managers, solution architects and consultants to deliver Azure cloud AI/ML consulting engagements; typical responsibilities include:', 'Educating our customers and partners on the power of AI/ML using the Azure Cloud', 'Interacting with senior executives and key stakeholders in our customers to formulate AI/ML solutions that address challenges facing their organizations', 'Developing and maintaining a high level of technical proficiency in Azure AI/ML cloud services', 'Creating and sharing IP that leverages AI/ML Azure cloud services', 'Embody our culture and values']",True,"['Azure AI Services', 'Artificial Intelligence', 'Machine Learning Operations']","Azure AI Services: Central to delivering AI solutions on the Azure cloud, enabling the development and deployment of AI/ML models.; Artificial Intelligence: Focus of the role to build advanced AI solutions that drive digital transformation for customers.; Machine Learning Operations: Involves managing and operationalizing machine learning models within Azure cloud environments.","['Azure SQL', 'SQL Server', 'Azure Data Factory', 'Power BI', 'Machine Learning', 'Data Science', 'SQL']","Azure SQL: Used as a cloud-based relational database service for managing and querying structured data within Microsoft Azure.; SQL Server: Employed for managing and querying relational databases, supporting data analytics and reporting tasks.; Azure Data Factory: Utilized to build and orchestrate data pipelines for data integration and transformation in the Azure cloud environment.; Power BI: Applied for creating business intelligence dashboards and visualizations to support data-driven decision making.; Machine Learning: Leveraged to develop predictive models and AI/ML solutions that address customer challenges using Azure cloud services.; Data Science: Core discipline involved in analyzing data and building models to deliver insights and AI/ML solutions for clients.; SQL: Used for querying and managing data within relational databases as part of data analytics and pipeline development."
ZLVc42U-lOpMGFNIAAAAAA==,Senior Data Analyst Jobs,"JANUS Research Group is seeking a Senior Data Analyst in support of HQ USAF Sponsored or Supported Wargaming The Senior Data Analyst will conduct activities to plan, execute, manage, and analyze throughout all phases of HQ USAF wargames including concept development, objective analysis, assessment planning, game design, event planning, management and execution, and post-game analysis. Primary locations are Joint Base Andrews, MD, Joint Base Anacostia-Bolling and The Pentagon.
• **Position is Subject to Contract Award***

Duties and Responsibilities:
• Develops and implements software and database applications to support wargame design, execution, and analysis.
• Manages wargame CoP (e.g. ForceTracker) and coordinates, compiles and updates data (e.g., Operational Order of Battle, Facilities, Installations, etc.) from wargame participants and external data providers (e.g., intelligence community) to ensure accurate representation for wargames.
• Advises principal engineer when updates to software and database applications are required.
• Assists pre-game, concurrent, and/or post-game analysis.

Qualifications

Minimum Qualifications:
• Active TS/SCI security clearance.
• Master's degree or above with a minimum of ten (10) years of experience in modeling, simulations, or operations research analysis.
• Experience developing wargame tools and in providing wargame or operational analysis.
• Excellent communication skills in terms of writing and presenting briefings.

Desired Qualifications:
• Military wargame experience.

Benefits: 401(k), Paid Time Off (PTO), Paid Holidays, Medical and Dental Plans, Life and Disability insurance, Education Assistance (and more).

JANUS strives to provide opportunities for career growth through training and development. We also offer an attractive comprehensive benefit package to include health and welfare plans and financial products. As part of a total rewards program, employees can benefit from our referral bonus program, and other various employee awards. JANUS Research Group takes pride in our benefit package and rewards program which has earned us the certification of a Great Place to Work™

JANUS Research Group provides reasonable accommodation so that qualified applicants with a disability may participate in the selection process. Please advise us of any accommodations you request to express interest in a position by e-mailing: Alisha Pollard, Director of Human Resources at alisha.pollard@janusresearch.com or calling (706) 364-9100. Please state your request for assistance in your message. Only reasonable accommodation requests related to applying for a specific position within JANUS Research Group will be reviewed at the e-mail address and phone number supplied. Thank you for considering a career with JANUS Research Group.

JANUS Research Group participates in the Electronic Employment Verification Program. Please click the E-Verify link below for more information.

E-Verify

JANUS Research Group is an equal opportunity/ affirmative action employer. It is company policy to provide equal opportunity in all areas of employment practice without regard to race, color, religion, sex, sexual orientation, national origin, age, marital status, veteran status, citizenship, or disability.

This contractor and subcontractor shall abide by the requirements of 41 CFR 60-1.4(a), 60-300.5(a) and 60-741.5(a). These regulations prohibit discrimination against qualified individuals based on their status as protected veterans or individuals with disabilities and prohibit discrimination against all individuals based on their race, color, religion, sex, or national origin. Moreover, these regulations require that covered prime contractors and subcontractors take affirmative action to employ and advance in employment qualified individuals without regard to race, color, religion, sex, national origin, protected veteran status or disability.",2025-07-22T00:00:00.000Z,2025-07-25,"['Active TS/SCI security clearance', ""Master's degree or above with a minimum of ten (10) years of experience in modeling, simulations, or operations research analysis"", 'Experience developing wargame tools and in providing wargame or operational analysis', 'Excellent communication skills in terms of writing and presenting briefings']","['JANUS Research Group is seeking a Senior Data Analyst in support of HQ USAF Sponsored or Supported Wargaming The Senior Data Analyst will conduct activities to plan, execute, manage, and analyze throughout all phases of HQ USAF wargames including concept development, objective analysis, assessment planning, game design, event planning, management and execution, and post-game analysis', 'Develops and implements software and database applications to support wargame design, execution, and analysis', 'Manages wargame CoP (e.g. ForceTracker) and coordinates, compiles and updates data (e.g., Operational Order of Battle, Facilities, Installations, etc.) from wargame participants and external data providers (e.g., intelligence community) to ensure accurate representation for wargames', 'Advises principal engineer when updates to software and database applications are required', 'Assists pre-game, concurrent, and/or post-game analysis']",False,[],,"['Data Management and Integration', 'Operational Analysis', 'Simulation and Modeling', 'Software and Database Development']","Data Management and Integration: Managing and compiling diverse operational and intelligence data to ensure accurate representation in wargames.; Operational Analysis: Conducting objective analysis and assessment planning throughout all phases of wargames to support decision-making.; Simulation and Modeling: Applying modeling and simulation techniques to develop and analyze wargame scenarios and outcomes.; Software and Database Development: Developing and implementing software and database applications to support wargame design, execution, and analysis."
7rVkGrihy04aQlXdAAAAAA==,Senior Data Scientist (Risk & Compliance),"Description:
• *100% Remote**

Our client, an industry leader in financial services and money transfers, has an excellent opportunity for a Senior Data Scientist (Risk & Compliance) to work on a 6+ month contract opportunity. Work will be remote, candidates local to Denver preferred. The Senior Data Scientist will manage the entire lifecycle of data science projects, from conception to deployment, while also mentoring junior team members and collaborating with other departments. You are responsible for developing and implementing advanced statistical and machine learning models, creating reports and presentations, and communicating findings to stakeholders. You will also play a key role in driving data-informed decision-making and contributing to the strategic direction of the organization.

Due to client requirement, applicants must be willing and able to work on a w2 basis. For our w2 consultants, we offer a great benefits package that includes Medical, Dental, and Vision benefits, 401k with company matching, and life insurance.

Rate: $75 - $87 / hr. w2

Responsibilities:
• Project Management: Leading and managing end to end data science projects, defining objectives, define requirements, and ensuring timely delivery.
• Model Development & Implementation: Developing and validating machine learning and statistical models, implementing predictive models, and optimizing existing ones.
• Data Analysis & Insights: Analyzing large datasets, identifying trends and patterns, and extracting actionable insights to inform business decisions.
• Collaboration & Communication: Working with cross-functional teams and stakeholders, including engineering, product, and business stakeholders, to translate complex data into actionable strategies.
• Mentorship & Guidance: Providing guidance and mentorship to junior data scientists, sharing expertise, and fostering their professional growth.
• Staying Updated: Keeping abreast of the latest advancements in data science and AI, exploring new tools and techniques, and identifying opportunities for innovation.
• Strategic Input: Contributing to the development of data-driven strategies and providing input on technical approaches for projects.

Experience Requirements:
• 5+ years of industry experience in applied machine learning, with 2+ years focused on deep learning and neural network applications.
• Experience in Banking, Payments or Financial Services leading in detecting and preventing digital fraud, scams and social engineering.
• Able to quickly understand our current Risk Models with the goal of building a flexible AI solution that partners with our current risk tools to maintains our high standards for Risk Prevention and Compliance while providing flexibility to effectively run our business.
• Expertise in statistical modeling, machine learning algorithms, and data mining techniques.
• Experience navigating difficult scenarios developing and implementing execution ideas with minimal guidance.
• Proficiency in programming languages like Python or R.

Education Requirements:
• Bachelor's degree in Computer Science, Statistics, Applied Math, or related field (Master's or PhD strongly preferred).

Skills, experience, and other compensable factors will be considered when determining pay rate. The pay range provided in this posting reflects a W2 hourly rate; other employment options may be available that may result in pay outside of the provided range.

W2 employees of Eliassen Group who are regularly scheduled to work 30 or more hours per week are eligible for the following benefits: medical (choice of 3 plans), dental, vision, pre-tax accounts, other voluntary benefits including life and disability insurance, 401(k) with match, and sick time if required by law in the worked-in state/locality.
Please be advised- If anyone reaches out to you about an open position connected with Eliassen Group, please confirm that they have an Eliassen.com email address and never provide personal or financial information to anyone who is not clearly associated with Eliassen Group. If you have any indication of fraudulent activity, please contact

About Eliassen Group:

Eliassen Group is a leading strategic consulting company for human-powered solutions. For over 30 years, Eliassen has helped thousands of companies reach further and achieve more with their technology solutions, financial, risk & compliance, and advisory solutions, and clinical solutions. With offices from coast to coast and throughout Europe, Eliassen provides a local community presence, balanced with international reach. Eliassen Group strives to positively impact the lives of their employees, clients, consultants, and the communities in which they operate.

Eliassen Group is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.

Don't miss out on our referral program! If we hire a candidate that you refer us to then you can be eligible for a $1,000 referral check!",2025-07-14T00:00:00.000Z,2025-07-25,"['Due to client requirement, applicants must be willing and able to work on a w2 basis', '5+ years of industry experience in applied machine learning, with 2+ years focused on deep learning and neural network applications', 'Experience in Banking, Payments or Financial Services leading in detecting and preventing digital fraud, scams and social engineering', 'Able to quickly understand our current Risk Models with the goal of building a flexible AI solution that partners with our current risk tools to maintains our high standards for Risk Prevention and Compliance while providing flexibility to effectively run our business', 'Expertise in statistical modeling, machine learning algorithms, and data mining techniques', 'Experience navigating difficult scenarios developing and implementing execution ideas with minimal guidance', 'Proficiency in programming languages like Python or R']","['Work will be remote, candidates local to Denver preferred', 'The Senior Data Scientist will manage the entire lifecycle of data science projects, from conception to deployment, while also mentoring junior team members and collaborating with other departments', 'You are responsible for developing and implementing advanced statistical and machine learning models, creating reports and presentations, and communicating findings to stakeholders', 'You will also play a key role in driving data-informed decision-making and contributing to the strategic direction of the organization', 'Project Management: Leading and managing end to end data science projects, defining objectives, define requirements, and ensuring timely delivery', 'Model Development & Implementation: Developing and validating machine learning and statistical models, implementing predictive models, and optimizing existing ones', 'Data Analysis & Insights: Analyzing large datasets, identifying trends and patterns, and extracting actionable insights to inform business decisions', 'Collaboration & Communication: Working with cross-functional teams and stakeholders, including engineering, product, and business stakeholders, to translate complex data into actionable strategies', 'Mentorship & Guidance: Providing guidance and mentorship to junior data scientists, sharing expertise, and fostering their professional growth', 'Staying Updated: Keeping abreast of the latest advancements in data science and AI, exploring new tools and techniques, and identifying opportunities for innovation', 'Strategic Input: Contributing to the development of data-driven strategies and providing input on technical approaches for projects']",True,[],,"['Statistical Modeling', 'Machine Learning', 'Deep Learning', 'Predictive Models', 'Data Analysis', 'Data Mining', 'Python', 'R']","Statistical Modeling: Used to develop and validate models for risk and compliance in financial services.; Machine Learning: Applied to build predictive models for detecting fraud, scams, and social engineering.; Deep Learning: Focused on neural network applications to enhance risk detection capabilities.; Predictive Models: Implemented and optimized to forecast risk and compliance issues.; Data Analysis: Analyzing large datasets to identify trends and extract actionable insights for business decisions.; Data Mining: Techniques used to discover patterns relevant to risk prevention and compliance.; Python: Programming language used for developing machine learning and statistical models.; R: Programming language used for statistical analysis and model development."
FhX3tdkq7XTgImwEAAAAAA==,Sr Data Scientist - Merchandise Scaling (Applied ML),"The pay range is $95,000.00 - $171,000.00

Pay is based on several factors which vary based on position. These include labor markets and in some instances may include education, work experience and certifications. In addition to your pay, Target cares about and invests in you as a team member, so that you can take care of yourself and your family. Target offers eligible team members and their dependents comprehensive health benefits and programs, which may include medical, vision, dental, life insurance and more, to help you and your family take care of your whole selves. Other benefits for eligible team members include 401(k), employee discount, short term disability, long term disability, paid sick leave, paid national holidays, and paid vacation. Find competitive benefits from financial and education to well-being and beyond at ;br>
JOIN TARGET AS A SENIOR DATA SCIENTIST - MERCH SCALING

About us:

Working at Target means helping all families discover the joy of everyday life. We bring that vision to life through our values and culture. Learn more about Target here.

A role with Target Data Sciences means the chance to help develop and manage state of the art predictive algorithms that use data at scale to automate and optimize decisions at scale. Whether you join our Statistics, Optimization or Machine Learning teams, you'll be challenged to harness Target's impressive data breadth to build the algorithms that power solutions our partners in Marketing, Supply Chain Optimization, Network Security and Personalization rely on.

Every Scientist on Target's Data Sciences team can expect modeling and data science, software/product development of highly performant code for Model Performance, to elevate Target's culture, and apply retail domain knowledge.

As Sr Data Scientist, you will join a Target Tech team responsible for Merchandising Assortment Data Science products. You will collaborate with Product, Tech, and business partners to solve retail challenges at scale for our merchandising organization. You will design, develop, deploy, and maintain data science models and tools. You'll work closely with data scientists, engineers, and business partners to continuously learn and address evolving business needs. You'll also collaborate with product and engineering partners on peer teams to build and productionize enterprise merchandising solutions.

Core responsibilities of this job are articulated within this job description. Job duties may change at any time due to business needs.

About you:
• PhD/MS/BS in Applied Mathematics, Statistics, Operations Research, Industrial Engineering, Physics, Computer Science or related quantitative field
• 3 plus years of experience cleaning, transforming and analyzing large datasets for insights leading to business improvements
• Experience developing, testing, and maintaining large codebases in a collaborative environment while meeting industry best practices
• Demonstrated knowledge of mathematical and statistical concepts, data structures, algorithm design, data analysis, optimization, simulations and visualizations applied to business problems
• Good working knowledge of Python for machine learning - including supervised and unsupervised methods and their applications
• Experience deploying solutions with large-scale business impact
• Self-driven and results-oriented, with the ability to meet tight timelines
• Strong team player with the ability to collaborate across geographies/time zones
• Excellent written and verbal communication skills

This position will operate as a Hybrid/Flex for Your Day work arrangement based on Target's needs. A Hybrid/Flex for Your Day work arrangement means the team member's core role will need to be performed both onsite at the Target HQ MN location the role is assigned to and virtually, depending upon what your role, team and tasks require for that day. Work duties cannot be performed outside of the country of the primary work location, unless otherwise prescribed by Target. Click here if you are curious to learn more about Minnesota.

Benefits Eligibility
Please paste this url into your preferred browser to learn about benefits eligibility for this role: _D

Americans with Disabilities Act (ADA)

In compliance with state and federal laws, Target will make reasonable accommodations for applicants with disabilities. If a reasonable accommodation is needed to participate in the job application or interview process, please reach out to

Application deadline is : 09/28/2025",2025-07-11T00:00:00.000Z,2025-07-25,"['PhD/MS/BS in Applied Mathematics, Statistics, Operations Research, Industrial Engineering, Physics, Computer Science or related quantitative field', '3 plus years of experience cleaning, transforming and analyzing large datasets for insights leading to business improvements', 'Experience developing, testing, and maintaining large codebases in a collaborative environment while meeting industry best practices', 'Demonstrated knowledge of mathematical and statistical concepts, data structures, algorithm design, data analysis, optimization, simulations and visualizations applied to business problems', 'Good working knowledge of Python for machine learning - including supervised and unsupervised methods and their applications', 'Experience deploying solutions with large-scale business impact', 'Self-driven and results-oriented, with the ability to meet tight timelines', 'Strong team player with the ability to collaborate across geographies/time zones', 'Excellent written and verbal communication skills', ""This position will operate as a Hybrid/Flex for Your Day work arrangement based on Target's needs""]","['A role with Target Data Sciences means the chance to help develop and manage state of the art predictive algorithms that use data at scale to automate and optimize decisions at scale', ""Whether you join our Statistics, Optimization or Machine Learning teams, you'll be challenged to harness Target's impressive data breadth to build the algorithms that power solutions our partners in Marketing, Supply Chain Optimization, Network Security and Personalization rely on"", ""Every Scientist on Target's Data Sciences team can expect modeling and data science, software/product development of highly performant code for Model Performance, to elevate Target's culture, and apply retail domain knowledge"", 'As Sr Data Scientist, you will join a Target Tech team responsible for Merchandising Assortment Data Science products', 'You will collaborate with Product, Tech, and business partners to solve retail challenges at scale for our merchandising organization', 'You will design, develop, deploy, and maintain data science models and tools', ""You'll work closely with data scientists, engineers, and business partners to continuously learn and address evolving business needs"", ""You'll also collaborate with product and engineering partners on peer teams to build and productionize enterprise merchandising solutions"", 'Core responsibilities of this job are articulated within this job description', 'Job duties may change at any time due to business needs', ""A Hybrid/Flex for Your Day work arrangement means the team member's core role will need to be performed both onsite at the Target HQ MN location the role is assigned to and virtually, depending upon what your role, team and tasks require for that day""]",True,[],,"['Predictive Modeling', 'Supervised Learning', 'Unsupervised Learning', 'Data Cleaning and Transformation', 'Statistical Analysis', 'Algorithm Design', 'Optimization', 'Simulations', 'Data Visualization', 'Python for Machine Learning', 'Collaborative Software Development']","Predictive Modeling: Developing and managing predictive algorithms to automate and optimize business decisions at scale in merchandising and other retail domains.; Supervised Learning: Applying supervised machine learning methods using Python to build models that predict outcomes based on labeled data.; Unsupervised Learning: Using unsupervised machine learning techniques in Python to identify patterns and insights from unlabeled merchandising data.; Data Cleaning and Transformation: Processing and preparing large datasets for analysis to generate actionable business insights in merchandising.; Statistical Analysis: Applying mathematical and statistical concepts to analyze data and support decision-making in retail merchandising.; Algorithm Design: Designing algorithms to solve retail business problems related to merchandising assortment and optimization.; Optimization: Using optimization techniques to improve merchandising assortment and supply chain decisions.; Simulations: Employing simulations to model and evaluate merchandising scenarios and their potential business impact.; Data Visualization: Creating visual representations of data to communicate insights and support merchandising decisions.; Python for Machine Learning: Utilizing Python programming language to develop, test, and maintain machine learning models for merchandising applications.; Collaborative Software Development: Developing and maintaining large codebases collaboratively to ensure scalable and maintainable data science solutions."
msyDjsdH77JYpdO3AAAAAA==,"Principal Associate, Data Scientist, Model Risk Office","Principal Associate, Data Scientist, Model Risk Office

Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making. As a Data Scientist at Capital One, you’ll be part of a team that’s leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives.

In Capital One’s Model Risk Office, we defend the company against model failures and find new ways of making better decisions with models. We use our statistics, software engineering, and business expertise to drive the best outcomes in both Risk Management and the Enterprise. We understand that we can’t prepare for tomorrow by focusing on today, so we invest in the future: investing in new skills, building better tools, and maintaining a network of trusted partners. We learn from past mistakes, and develop increasingly powerful techniques to avoid their repetition.

In this role, you will:
• Partner with a cross-functional team of data scientists, software engineers, and product managers to identify and quantify risks associated with models
• Leverage a broad stack of technologies — Python, Conda, AWS, Spark, and more — to reveal the insights hidden within data
• Build statistical/machine learning models to challenge “champion models” that are deployed in production today
• Contribute to the model governance of the next generation of machine learning models
• Flex your interpersonal skills to present how model risks could impact the business to executives

The Ideal Candidate is:
• Innovative. You continually research and evaluate emerging technologies. You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them.
• Creative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You’re not afraid to share a new idea.
• Technical. You’re comfortable with open-source languages and are passionate about developing further. You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms.
• Statistically-minded. You’ve built models, validated them, and backtested them. You know how to interpret a confusion matrix or a ROC curve. You have experience with clustering, classification, sentiment analysis, time series, and deep learning.
• A data guru. “Big data” doesn’t faze you. You have the skills to retrieve, combine, and analyze data from a variety of sources and structures. You know understanding the data is often the key to great data science.

Basic Qualifications:
• Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:
• A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 5 years of experience performing data analytics
• A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 3 years of experience performing data analytics
• A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field)

Preferred Qualifications:
• Master’s Degree in “STEM” field (Science, Technology, Engineering, or Mathematics) plus 3 years of experience in data analytics, or PhD in “STEM” field (Science, Technology, Engineering, or Mathematics)
• At least 1 year of experience working with AWS
• At least 3 years’ experience in Python, Scala, or R
• At least 3 years’ experience with machine learning
• At least 3 years’ experience with SQL

Capital One will consider sponsoring a new qualified applicant for employment authorization for this position.

This role is Hybrid, with associates expected to consistently spend three days per week in the office.

The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.

McLean, VA: $158,600 - $181,000 for Princ Associate, Data Science

Richmond, VA: $144,200 - $164,600 for Princ Associate, Data Science

Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate’s offer letter.

This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.

Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.

This role is expected to accept applications for a minimum of 5 business days.

No agencies please. Capital One is an equal opportunity employer (EOE, including disability/vet) committed to non-discrimination in compliance with applicable federal, state, and local laws. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",2025-07-07T00:00:00.000Z,2025-07-25,"['You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them', 'You thrive on bringing definition to big, undefined problems', 'You love asking questions and pushing hard to find answers', 'You’re comfortable with open-source languages and are passionate about developing further', 'You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms', 'Statistically-minded', 'You know how to interpret a confusion matrix or a ROC curve', 'You have experience with clustering, classification, sentiment analysis, time series, and deep learning', 'A data guru', 'You have the skills to retrieve, combine, and analyze data from a variety of sources and structures', 'You know understanding the data is often the key to great data science', 'Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:', ""A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 5 years of experience performing data analytics"", ""A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 3 years of experience performing data analytics"", 'A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field)', 'Capital One will consider sponsoring a new qualified applicant for employment authorization for this position']","['Partner with a cross-functional team of data scientists, software engineers, and product managers to identify and quantify risks associated with models', 'Leverage a broad stack of technologies — Python, Conda, AWS, Spark, and more — to reveal the insights hidden within data', 'Build statistical/machine learning models to challenge “champion models” that are deployed in production today', 'Contribute to the model governance of the next generation of machine learning models', 'Flex your interpersonal skills to present how model risks could impact the business to executives', 'You continually research and evaluate emerging technologies', 'You’ve built models, validated them, and backtested them', 'This role is Hybrid, with associates expected to consistently spend three days per week in the office']",True,[],,"['Statistical Modeling', 'Relational Databases', 'Python', 'Conda', 'AWS', 'Spark', 'Machine Learning', 'Model Governance', 'Clustering', 'Classification', 'Sentiment Analysis', 'Time Series Analysis', 'Deep Learning', 'Confusion Matrix', 'ROC Curve', 'SQL', 'Scala', 'Data Retrieval and Integration']","Statistical Modeling: Used to personalize credit card offers and assess model risks in financial decision-making.; Relational Databases: Employed to manage and query structured data relevant to credit card offers and risk models.; Python: A primary programming language used for data analysis, model building, and leveraging data science tools.; Conda: Used as a package and environment management system to support data science workflows.; AWS: Cloud computing platform utilized for data storage, processing, and scalable model deployment.; Spark: Big data processing framework used to handle large-scale data analytics and model training.; Machine Learning: Applied to build models that challenge existing production models and improve risk assessment.; Model Governance: Practices to oversee and manage the lifecycle and risks of machine learning models in production.; Clustering: Used as an unsupervised learning technique to identify patterns or groupings in data relevant to risk.; Classification: Applied to categorize data points, such as credit risk levels or customer segments.; Sentiment Analysis: Used to analyze textual data for insights, potentially related to customer feedback or risk indicators.; Time Series Analysis: Employed to analyze data points collected over time for forecasting and risk trend detection.; Deep Learning: Utilized for advanced modeling techniques, possibly to improve predictive accuracy in risk models.; Confusion Matrix: A statistical tool used to evaluate the performance of classification models.; ROC Curve: Used to assess the diagnostic ability of classification models in distinguishing between classes.; SQL: Used to retrieve and manipulate data from relational databases for analysis and modeling.; Scala: Programming language experience relevant for big data processing and analytics, often with Spark.; Data Retrieval and Integration: Skills to combine and analyze data from various sources and structures to support modeling."
L5wOvziyLx6DO_acAAAAAA==,Data Scientist,"Job Family:
Data Science Consulting

Travel Required:
None

Clearance Required:
Active Top Secret SCI (TS/SCI)

What You Will Do:

This Data Scientist role will work as part of a Data & AI consulting team to support data visualization, business analytics, data management, and digital engineering processes for major Program Executive Offices (PEOs) at the National Geospatial-Intelligence Agency (NGA). A strong understanding of data visualization is essential to help the PEOs understand how to effectively monitor their operations through reporting dashboards, tools, and the creation of data sets. This role will be located on client site and requires excellent communication skills to coordinate status updates and visualization or digital engineering initiatives. Seeking a candidate with the ability to proactively identify program needs and help the office mature its operational reporting, business analytics, and data processes in line with technology/data solutions advancement. Specific duties will include:
• Integrate, develop, and maintain analytic visualizations and tools to evaluate and communicate office statoperations.
• Work with multiple types of data sources, such as Jira, Excel, and SQL databases to develop visualizations; work with data at varying maturity levels and create relationships between disparate sources to maximize analyses.
• Interpret a wide range of data for the purpose of measuring a major technology program's performance and impact to mission. Help communicate that performance measurement to Senior leaders and inform decisions such as investment/divestment, prioritization, and operational strategies.
• Use storytelling and user interface design methods to develop/maintain Tableau dashboards to address program management needs, catered to specific audience groups. Design dashboards to be visually appealing, intuitive, and user friendly, containing a high volume of information in concise graphics/tables/metrics.
• Manage an inventory of implemented dashboards, other analytic products and current product backlog for implementation.
• Demoing visualizations/analytic products to Agency Senior and program leadership - utilize effective communication skills to convey purpose, use cases applicability, and impact, and solicit feedback for product enhancement.
• Understanding of effective data management and data visualization project documentation such as SOPs, data definitions/dictionaries, data process flows, Confluence pages
• Help evolve program analytics with automation, connecting to unstructured sources, and other Enterprise solutions (such as data format/process to support LLM)

What You Will Need:
• An ACTIVE and MAINTAINED TS/SCI Federal or DoD security clearance; must UPGRADE and MAINTAIN a TS/SCI with a COUNTERINTELLIGENCE (CI) polygraph
• Bachelor's Degree
• Minimum of EIGHT (8) years of working experience
• Demonstrated experience developing visualizations and conducting data analysis
• Demonstrated experience utilizing computer programs, software, or some coding language

What Would Be Nice To Have:
• Demonstrated experience developing visualizations in Tableau
• Demonstrated ability to proactively identify methods and approaches to expand and enhance the analytic capacity.
• Demonstrated experience working with commercial-off-the-shelf (COTS) statistical software or tools for data visualization (i.e., SPSS, SAS, MatLab, etc.).
• Demonstrated experience data mining, to include developing, manipulating, or maintaining databases.
• Experience with Python, MySQL, D3, SPSS, SAS, Visual Basic, or R to summarize statistical data and create documents, reports and presentations.
• Demonstrated experience effectively communicating with various partners, stakeholders, or customers on the value of statistical and data science methods.
• Demonstrated experience embracing and participating in a culture of knowledge sharing to broaden the understanding of advanced methods.
• Understanding and/or experience developing AI/ML or working with AI platform tools

What We Offer:

Guidehouse offers a comprehensive, total rewards package that includes competitive compensation and a flexible benefits package that reflects our commitment to creating a diverse and supportive workplace.

Benefits include:
• Medical, Rx, Dental & Vision Insurance
• Personal and Family Sick Time & Company Paid Holidays
• Position may be eligible for a discretionary variable incentive bonus
• Parental Leave and Adoption Assistance
• 401(k) Retirement Plan
• Basic Life & Supplemental Life
• Health Savings Account, Dental/Vision & Dependent Care Flexible Spending Accounts
• Short-Term & Long-Term Disability
• Student Loan PayDown
• Tuition Reimbursement, Personal Development & Learning Opportunities
• Skills Development & Certifications
• Employee Referral Program
• Corporate Sponsored Events & Community Outreach
• Emergency Back-Up Childcare Program
• Mobility Stipend

About Guidehouse

Guidehouse is an Equal Opportunity Employer-Protected Veterans, Individuals with Disabilities or any other basis protected by law, ordinance, or regulation.

Guidehouse will consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of applicable law or ordinance including the Fair Chance Ordinance of Los Angeles and San Francisco.

If you have visited our website for information about employment opportunities, or to apply for a position, and you require an accommodation, please contact Guidehouse Recruiting at 1- or via email at All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodation.

All communication regarding recruitment for a Guidehouse position will be sent from Guidehouse email domains including @guidehouse.com or Correspondence received by an applicant from any other domain should be considered unauthorized and will not be honored by Guidehouse. Note that Guidehouse will never charge a fee or require a money transfer at any stage of the recruitment process and does not collect fees from educational institutions for participation in a recruitment event. Never provide your banking information to a third party purporting to need that information to proceed in the hiring process.

If any person or organization demands money related to a job opportunity with Guidehouse, please report the matter to Guidehouse's Ethics Hotline. If you want to check the validity of correspondence you have received, please contact Guidehouse is not responsible for losses incurred (monetary or otherwise) from an applicant's dealings with unauthorized third parties.

Guidehouse does not accept unsolicited resumes through or from search firms or staffing agencies. All unsolicited resumes will be considered the property of Guidehouse and Guidehouse will not be obligated to pay a placement fee.",2025-07-20T00:00:00.000Z,2025-07-25,"['An ACTIVE and MAINTAINED TS/SCI Federal or DoD security clearance; must UPGRADE and MAINTAIN a TS/SCI with a COUNTERINTELLIGENCE (CI) polygraph', ""Bachelor's Degree"", 'Minimum of EIGHT (8) years of working experience', 'Demonstrated experience developing visualizations and conducting data analysis', 'Demonstrated experience utilizing computer programs, software, or some coding language', 'Demonstrated experience developing visualizations in Tableau', 'Demonstrated ability to proactively identify methods and approaches to expand and enhance the analytic capacity', 'Demonstrated experience working with commercial-off-the-shelf (COTS) statistical software or tools for data visualization (i.e., SPSS, SAS, MatLab, etc.)', 'Demonstrated experience data mining, to include developing, manipulating, or maintaining databases', 'Experience with Python, MySQL, D3, SPSS, SAS, Visual Basic, or R to summarize statistical data and create documents, reports and presentations', 'Demonstrated experience effectively communicating with various partners, stakeholders, or customers on the value of statistical and data science methods', 'Demonstrated experience embracing and participating in a culture of knowledge sharing to broaden the understanding of advanced methods', 'Understanding and/or experience developing AI/ML or working with AI platform tools']","['This Data Scientist role will work as part of a Data & AI consulting team to support data visualization, business analytics, data management, and digital engineering processes for major Program Executive Offices (PEOs) at the National Geospatial-Intelligence Agency (NGA)', 'A strong understanding of data visualization is essential to help the PEOs understand how to effectively monitor their operations through reporting dashboards, tools, and the creation of data sets', 'This role will be located on client site and requires excellent communication skills to coordinate status updates and visualization or digital engineering initiatives', 'Seeking a candidate with the ability to proactively identify program needs and help the office mature its operational reporting, business analytics, and data processes in line with technology/data solutions advancement', 'Integrate, develop, and maintain analytic visualizations and tools to evaluate and communicate office statoperations', 'Work with multiple types of data sources, such as Jira, Excel, and SQL databases to develop visualizations; work with data at varying maturity levels and create relationships between disparate sources to maximize analyses', ""Interpret a wide range of data for the purpose of measuring a major technology program's performance and impact to mission"", 'Help communicate that performance measurement to Senior leaders and inform decisions such as investment/divestment, prioritization, and operational strategies', 'Use storytelling and user interface design methods to develop/maintain Tableau dashboards to address program management needs, catered to specific audience groups', 'Design dashboards to be visually appealing, intuitive, and user friendly, containing a high volume of information in concise graphics/tables/metrics', 'Manage an inventory of implemented dashboards, other analytic products and current product backlog for implementation', 'Demoing visualizations/analytic products to Agency Senior and program leadership - utilize effective communication skills to convey purpose, use cases applicability, and impact, and solicit feedback for product enhancement', 'Understanding of effective data management and data visualization project documentation such as SOPs, data definitions/dictionaries, data process flows, Confluence pages', 'Help evolve program analytics with automation, connecting to unstructured sources, and other Enterprise solutions (such as data format/process to support LLM)']",True,"['Large Language Models', 'AI Platform Tools']",Large Language Models: Supporting data formats and processes to integrate with LLMs as part of evolving program analytics and automation.; AI Platform Tools: Experience working with AI/ML platforms to develop or support AI-related solutions within the data science consulting context.,"['Data Visualization', 'Business Analytics', 'Data Management', 'SQL', 'Python', 'Tableau', 'Statistical Software', 'Data Mining', 'Excel', 'Data Integration', 'Data Storytelling']","Data Visualization: Developing and maintaining dashboards and visual tools like Tableau to communicate program performance and operational metrics.; Business Analytics: Analyzing data to measure program performance and inform strategic decisions such as investment and prioritization.; Data Management: Handling data sources, maintaining data dictionaries, SOPs, and process flows to ensure data quality and accessibility.; SQL: Using SQL databases as a data source for analysis and visualization development.; Python: Utilizing Python for data mining, statistical summarization, and creating reports and presentations.; Tableau: Employing Tableau software to create interactive and user-friendly dashboards tailored to different audience groups.; Statistical Software: Using commercial-off-the-shelf tools like SPSS, SAS, and MatLab for data visualization and statistical analysis.; Data Mining: Developing, manipulating, and maintaining databases to extract useful information for analysis.; Excel: Working with Excel as a data source and tool for data manipulation and analysis.; Data Integration: Combining disparate data sources such as Jira, Excel, and SQL to maximize analytical insights.; Data Storytelling: Using storytelling and user interface design to effectively communicate data insights through visualizations."
bmNB0Pq_1UeBMrgkAAAAAA==,Data Scientist Jobs,"ASRC Federal is a leading government contractor furthering missions in space, public health and defense. As an Alaska Native owned corporation, our work helps secure an enduring future for our shareholders. Join our team and discover why we are a top veteran employer and Certified Great Place to Work™

ASRC Federal Business Innovation, LLC is a premier provider of systems engineering, software engineering, system integration and project management services for real-time, mission-critical defense systems. As an Alaska Native owned corporation, our work helps secure an enduring future for our shareholders. Join our team and discover why we are a top veteran employer and Certified Great Place to Work™ .

We are seeking a highly motivated Data Scientist to support our USAF contract on Robbins AFB, GA. This project is in support of the 402d Software Engineering Group (SWEG) at Robins Air Force Base, GA. The Data Scientist supports the 402d SWEG's mission by working closely with engineers, developers, administrators and other technical teams supporting a variety of weapon system platforms and airframes such as the F-15 and F-35 fighters, the B-1B bomber, the C-5 and C-130 cargo planes, the MQ-9 Reaper and the HH-60 Pave Hawk helicopter. All work will be performed on base.

This position offers a $5,000 Sign-On/Referral Bonus.

Responsibilities
• Design and develop sophisticated data models, machine learning algorithms, and AI solutions to address complex engineering and operational challenges within defense systems.
• Implement and integrate machine learning and AI models into production environments, enhancing system capabilities in areas such as predictive analytics, automation, and decision-making processes.
• Work closely with multidisciplinary teams, including software engineers and system architects, to understand requirements, ensure proper data usage, and develop solutions aligned with project goals.

Requirements
• Bachelor's degree or higher in Data Science, Computer Science, or a related field.
• Secret clearance or Interim Secret clearance required to start. ASRC is willing to consider candidates who do not yet have a clearance; however, candidates must obtain an Interim Secret clearance before beginning employment. U.S. citizenship (required).
• A minimum of 5 years of experience in Artificial Intelligence (AI) design, development, and maturation.
• Proven experience in implementing and training machine learning models, including the development and application of generative AI, advanced data analytics, and supervised and unsupervised learning models.
• Experience in deploying AI models to production environments.
• Proficiency in Python programming and experience developing models in a cloud-based environment.
• Ability to work independently at a Senior level, with minimal supervision or assistance from junior staff.

Schedule
• Facilities are open 6am-6pm - you can work with your customer leadership to set hours
• You can flex time during the 2 week pay cycle - avoid using PTO for appointments
• A compressed work schedule may be available at the discretion of work center leadership (i.e. 4/10 or 9/80)

Why ASRC?

As a wholly owned subsidiary of Arctic Slope Regional Corporation, an Alaska Native Corporation, we are inspired by the Iñupiat culture. We embrace stewardship and the idea of using every resource effectively; teamwork when striving to achieve goals and building a collaborative environment; integrity in adhering to high moral principles and professional standards; respect in welcoming and regarding the differing opinions, experiences, rights and traditions of others; accountability in that we meet our commitments and take responsibility for our results; and continuous improvement, always striving to make things better, raising the bar and staying humble.

Advantages of Working at ASRC Federal:
• Purpose-Driven Careers: Join a company recognized as a:
• Certified Great Place to Work
• Military Times' Best for Vets Employer
• Military.com's Top 25 Veteran Employer
• Comprehensive Benefits:
• Insurance Coverage: Comprehensive plans for medical, dental, vision, life insurance, and short-term/long-term disability
• Paid Leave: Inclusive policies for bereavement, military obligations, and parental needs, along with 11 paid holidays annually
• Retirement Savings: A 401(k) plan with a generous company match and immediate vesting to help secure your financial future
• Incentives: Employee referral bonuses to reward you for helping grow the ASRC Federal Family
• Learning and Development:
• After 90 days of employment, regular full-time employees are eligible for our professional development program. This includes annual funding for:
• Pursuing Associate's, Bachelor's, or Graduate Degrees
• Obtaining industry-standard professional certifications
• Participating in professional certificate programs
• Covering registration fees for professional conferences
• Centers of Excellence : We established the Centers of Excellence to build, leverage and grow our technological capabilities, best practices and offer professional development for our technical teams. They contain many Communities of Practice which are forums that offer a platform to share ideas, best practices, innovations, and to collaborate with technical peers.

Embark on a career with ASRC Federal Business Innovation, LLC, where your growth, purpose, and well-being are at the forefront of what we do!

We invest in the lives of our employees, both in and out of the workplace, by providing competitive pay and benefits packages. Benefits offered may include health care, dental, vision, life insurance; 401(k); education assistance; paid time off including PTO, holidays, and any other paid leave required by law.

EEO Statement

ASRC Federal and its Subsidiaries are Equal Opportunity employers. All qualified applicants will receive consideration for employment without regard to race, gender, color, age, sexual orientation, gender identification, national origin, religion, marital status, ancestry, citizenship, disability, protected veteran status, or any other factor prohibited by applicable law.",2025-07-25T02:00:00.000Z,2025-07-25,"[""Bachelor's degree or higher in Data Science, Computer Science, or a related field"", 'Secret clearance or Interim Secret clearance required to start', 'ASRC is willing to consider candidates who do not yet have a clearance; however, candidates must obtain an Interim Secret clearance before beginning employment', 'U.S. citizenship (required)', 'A minimum of 5 years of experience in Artificial Intelligence (AI) design, development, and maturation', 'Proven experience in implementing and training machine learning models, including the development and application of generative AI, advanced data analytics, and supervised and unsupervised learning models', 'Experience in deploying AI models to production environments', 'Proficiency in Python programming and experience developing models in a cloud-based environment', 'Ability to work independently at a Senior level, with minimal supervision or assistance from junior staff', ""Pursuing Associate's, Bachelor's, or Graduate Degrees"", 'Obtaining industry-standard professional certifications']","['Design and develop sophisticated data models, machine learning algorithms, and AI solutions to address complex engineering and operational challenges within defense systems', 'Implement and integrate machine learning and AI models into production environments, enhancing system capabilities in areas such as predictive analytics, automation, and decision-making processes', 'Work closely with multidisciplinary teams, including software engineers and system architects, to understand requirements, ensure proper data usage, and develop solutions aligned with project goals']",True,"['Generative AI', 'AI Model Deployment']",Generative AI: Developed and applied generative AI models to address complex engineering challenges in defense systems.; AI Model Deployment: Experience in integrating AI models into production environments to enhance system automation and decision-making.,"['Machine Learning', 'Supervised Learning', 'Unsupervised Learning', 'Advanced Data Analytics', 'Predictive Analytics', 'Python Programming', 'Cloud-Based Model Development']",Machine Learning: Used to design and develop algorithms and models for predictive analytics and automation in defense systems.; Supervised Learning: Applied in training models with labeled data to support operational challenges in defense platforms.; Unsupervised Learning: Used to identify patterns and insights from unlabeled data within defense system datasets.; Advanced Data Analytics: Employed to analyze complex datasets to enhance decision-making and system capabilities.; Predictive Analytics: Implemented to forecast outcomes and support automation in mission-critical defense systems.; Python Programming: Primary programming language used for developing machine learning and data models in a cloud environment.; Cloud-Based Model Development: Experience in building and deploying models within cloud infrastructure to support scalable AI and data solutions.
-1hEf6Rm6gqcogwzAAAAAA==,"Manager, Data Science - AI Foundations","Manager, Data Science - AI Foundations

Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making.

As a Data Scientist at Capital One, you’ll be part of a team that’s leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives.

Team Description

AI Foundations Specialist Models Data Science team builds and ships state of the art scalable architecture, AI/ML solutions for Capital One’s award-winning mobile app. We partner with product, tech and design teams to deliver app features that delight customers with dynamic and personalized experiences, enable them to chat with Capital One’s digital assistant Eno, or search for useful contents. You will be the driving force to experiment, innovate and create next generation experiences powered by the latest emerging generative AI technologies.

In this role, you will:
• Partner with a cross-functional team of data scientists, software engineers, machine learning engineers and product managers to deliver AI powered products that change how customers interact with their money.
• Leverage a broad stack of technologies — Pytorch, AWS Ultraclusters, Hugging Face, LangChain, Lightning, VectorDBs, and more — to reveal the insights hidden within huge volumes of numeric and textual data.
• Be the expert in Natural Language Processing (NLP) to harness the power of Large Language Models (LLMs), adapt and finetune them for customer facing applications and features.
• Build machine learning and NLP models through all phases of development, from design through training, evaluation, and validation; partnering with engineering teams to operationalize them in scalable and resilient production systems that serve 80+ million customers.
• Flex your interpersonal skills to translate the complexity of your work into tangible business goals.

The Ideal Candidate is:
• Customer first. You love the process of analyzing and creating, but also share our passion to do the right thing. You know at the end of the day it’s about making the right decision for our customers.
• Innovative. You continually research and evaluate emerging technologies. You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them.
• Creative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You’re not afraid to share a new idea.
• A leader. You challenge conventional thinking and work with stakeholders to identify and improve the status quo. You're passionate about talent development for your own team and beyond.
• Technical. You’re comfortable with advanced ML and DL technologies including language models and are passionate about developing further. You have hands-on experience working with LLMs and solutions using open-source tools and cloud computing platforms.
• Influential. You are passionate about AI/ML and can bring along a cross functional team in breakthrough innovations. You communicate clearly and effectively to share your findings with non-technical audiences.
• You are experienced in training language models or large computer vision models as well as have expertise in one or more key subdomains such as: training optimization, self-supervised learning, explainability, RLHF.
• You have an engineering mindset as shown by a track record of delivering models at scale both in training data and inference volumes. You have experience in delivering libraries, platforms, or solution level code to existing products.

Basic Qualifications:
• Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:
• A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 6 years of experience performing data analytics
• A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 4 years of experience performing data analytics
• A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 1 year of experience performing data analytics
• At least 1 year of experience leveraging open source programming languages for large scale data analysis
• At least 1 year of experience working with machine learning
• At least 1 year of experience utilizing relational databases

Preferred Qualifications:
• PhD in “STEM” field (Science, Technology, Engineering, or Mathematics)
• Experience working with AWS
• At least 4 years’ experience in Python, Scala, or R
• At least 4 years’ experience with machine learning
• At least 4 years’ experience with SQL

Capital One will consider sponsoring a new qualified applicant for employment authorization for this position.

The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.

McLean, VA: $193,400 - $220,700 for Mgr, Data Science

New York, NY: $211,000 - $240,800 for Mgr, Data Science

San Jose, CA: $211,000 - $240,800 for Mgr, Data Science

Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate’s offer letter.

This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.

Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.

This role is expected to accept applications for a minimum of 5 business days.

No agencies please. Capital One is an equal opportunity employer (EOE, including disability/vet) committed to non-discrimination in compliance with applicable federal, state, and local laws. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",2025-07-08T00:00:00.000Z,2025-07-25,"['Customer first', 'You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them', 'You thrive on bringing definition to big, undefined problems', 'You love asking questions and pushing hard to find answers', ""You're passionate about talent development for your own team and beyond"", 'Technical', 'You’re comfortable with advanced ML and DL technologies including language models and are passionate about developing further', 'You have hands-on experience working with LLMs and solutions using open-source tools and cloud computing platforms', 'Influential', 'You are passionate about AI/ML and can bring along a cross functional team in breakthrough innovations', 'You communicate clearly and effectively to share your findings with non-technical audiences', 'You are experienced in training language models or large computer vision models as well as have expertise in one or more key subdomains such as: training optimization, self-supervised learning, explainability, RLHF', 'You have an engineering mindset as shown by a track record of delivering models at scale both in training data and inference volumes', 'You have experience in delivering libraries, platforms, or solution level code to existing products', 'Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:', ""A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 6 years of experience performing data analytics"", ""A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 4 years of experience performing data analytics"", 'A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 1 year of experience performing data analytics', 'At least 1 year of experience leveraging open source programming languages for large scale data analysis', 'At least 1 year of experience working with machine learning', 'At least 1 year of experience utilizing relational databases']","['You will be the driving force to experiment, innovate and create next generation experiences powered by the latest emerging generative AI technologies', 'Partner with a cross-functional team of data scientists, software engineers, machine learning engineers and product managers to deliver AI powered products that change how customers interact with their money', 'Leverage a broad stack of technologies — Pytorch, AWS Ultraclusters, Hugging Face, LangChain, Lightning, VectorDBs, and more — to reveal the insights hidden within huge volumes of numeric and textual data', 'Be the expert in Natural Language Processing (NLP) to harness the power of Large Language Models (LLMs), adapt and finetune them for customer facing applications and features', 'Build machine learning and NLP models through all phases of development, from design through training, evaluation, and validation; partnering with engineering teams to operationalize them in scalable and resilient production systems that serve 80+ million customers', 'Flex your interpersonal skills to translate the complexity of your work into tangible business goals', 'You continually research and evaluate emerging technologies', 'You challenge conventional thinking and work with stakeholders to identify and improve the status quo']",True,"['Large Language Models', 'Generative AI', 'PyTorch', 'Hugging Face', 'LangChain', 'Lightning', 'Vector Databases', 'Training Optimization', 'Self-Supervised Learning', 'Explainability', 'Reinforcement Learning with Human Feedback', 'AWS Ultraclusters']","Large Language Models: Central to building customer-facing applications by adapting and fine-tuning LLMs for personalized digital assistant features.; Generative AI: Used to create next-generation customer experiences powered by emerging AI technologies.; PyTorch: Framework leveraged for developing and training deep learning models, including LLMs.; Hugging Face: Open-source platform and library used for accessing and fine-tuning transformer-based language models.; LangChain: Tool used to build applications that integrate LLMs with external data sources and workflows.; Lightning: Framework for scalable and efficient deep learning model training and deployment.; Vector Databases: Used to store and query vector embeddings for efficient retrieval in AI-powered search and recommendation systems.; Training Optimization: Techniques applied to improve the efficiency and effectiveness of training large AI models.; Self-Supervised Learning: A method used to train models on unlabeled data, enhancing model performance without extensive labeled datasets.; Explainability: Approaches to make AI model decisions interpretable and transparent for stakeholders.; Reinforcement Learning with Human Feedback: Technique used to fine-tune AI models by incorporating human feedback to improve model behavior.; AWS Ultraclusters: Cloud computing infrastructure used to scale training and deployment of large AI models.","['Statistical Modeling', 'Relational Databases', 'Machine Learning', 'Natural Language Processing', 'Model Training and Evaluation', 'Open Source Programming Languages', 'SQL', 'Data Analytics']","Statistical Modeling: Used historically and currently to personalize credit card offers and analyze customer data for decision-making.; Relational Databases: Utilized for managing and querying structured customer data to support analytics and machine learning workflows.; Machine Learning: Applied to build predictive models and scalable AI/ML solutions that enhance customer experiences and financial products.; Natural Language Processing: Employed to process and analyze textual data, enabling features like digital assistants and content search.; Model Training and Evaluation: Involves designing, training, validating, and operationalizing machine learning and NLP models for production use.; Open Source Programming Languages: Used for large scale data analysis and model development, including languages like Python, Scala, and R.; SQL: Used to query and manipulate data within relational databases as part of data analytics and model development.; Data Analytics: Core activity involving analyzing numeric and textual data to extract insights and inform business decisions."
Dj-wVQK6Iss0u5ovAAAAAA==,Senior Data Scientist - Product,"Job#: 2081102

Job Description:

Role Responsibilities:
• Design, build, and evaluate machine learning and deep learning models for classification, regression, recommendation, NLP, computer vision, and time-series forecasting.
• Apply deep learning techniques (e.g., CNNs, RNNs, LSTMs, Transformers) to solve complex, data-intensive problems.
• Lead the development of ML products, from model prototyping through production deployment, performance monitoring, and continuous improvement.
• Select appropriate architectures and hyperparameters, optimize model performance, and use proper evaluation metrics (e.g., AUC, F1, BLEU, IoU, perplexity) based on the use case.
• Collaborate with product managers and engineers to translate business challenges into deployable solutions using AI/ML.
• Design automated pipelines for data preprocessing, feature engineering, training, and inference (batch or real-time).
• Evaluate model drift, monitor performance post-deployment, and implement retraining pipelines as part of a production MLOps system.
• Mentor junior data scientists, contribute to code reviews, and lead technical discussions across the data science and engineering teams.

Role Requirements:
• Bachelor's degree in Computer Science, Statistics, Applied Math, or related field (Master's or PhD strongly preferred).
• 5+ years of industry experience in applied machine learning, with 2+ years focused on deep learning and neural network applications.
• Experience in Banking, Payments or Financial Services formulating AI data solutions that allow us to leverage our data to know our customers better and target our resources for better market penetration and focused attention and education.
• Proficiency in Python and ML libraries such as scikit-learn, XGBoost, TensorFlow, Keras, or PyTorch.
• Deep understanding of neural networks, model regularization, overfitting/underfitting prevention, and GPU-accelerated training.
• Experience with customer data enrichments.
• Proven track record of building, evaluating, and deploying machine learning models at scale in production environments.
• Experience with cloud platforms (AWS/Google Cloud Platform/Azure), containerization, and model serving technologies.
• Excellent communication skills, with the ability to present complex findings to both technical and non-technical stakeholders.
• Hands-on experience with real-world applications of deep learning, such as recommendation engines, fraud detection, customer segmentation, document summarization, image recognition, or speech processing.
• Familiarity with MLOps tools (e.g., MLflow, SageMaker, Airflow, Kubeflow).
• Experience with CI/CD for ML, feature stores, and real-time inference systems.
• Contributions to academic research, open-source ML projects, or ML/AI patents

EEO Employer

Apex Systems is an equal opportunity employer. We do not discriminate or allow discrimination on the basis of race, color, religion, creed, sex (including pregnancy, childbirth, breastfeeding, or related medical conditions), age, sexual orientation, gender identity, national origin, ancestry, citizenship, genetic information, registered domestic partner status, marital status, disability, status as a crime victim, protected veteran status, political affiliation, union membership, or any other characteristic protected by law. Apex will consider qualified applicants with criminal histories in a manner consistent with the requirements of applicable law. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation in using our website for a search or application, please contact our Employee Services Department at or .

Apex Systems is a world-class IT services company that serves thousands of clients across the globe. When you join Apex, you become part of a team that values innovation, collaboration, and continuous learning. We offer quality career resources, training, certifications, development opportunities, and a comprehensive benefits package. Our commitment to excellence is reflected in many awards, including ClearlyRated's Best of Staffing in Talent Satisfaction in the United States and Great Place to Work in the United Kingdom and Mexico.

Apex Benefits Overview: Apex offers a range of supplemental benefits, including medical, dental, vision, life, disability, and other insurance plans that offer an optional layer of financial protection. We offer an ESPP (employee stock purchase program) and a 401K program which allows you to contribute typically within 30 days of starting, with a company match after 12 months of tenure. Apex also offers a HSA (Health Savings Account on the HDHP plan), a SupportLinc Employee Assistance Program (EAP) with up to 8 free counseling sessions, a corporate discount savings program and other discounts. In terms of professional development, Apex hosts an on-demand training program, provides access to certification prep and a library of technical and leadership courses/books/seminars once you have 6+ months of tenure, and certification discounts and other perks to associations that include CompTIA and IIBA. Apex has a dedicated customer service team for our Consultants that can address questions around benefits and other resources, as well as a certified Career Coach. You can access a full list of our benefits, programs, support teams and resources within our 'Welcome Packet' as well, which an Apex team member can provide.",2025-07-21T00:00:00.000Z,2025-07-25,"['5+ years of industry experience in applied machine learning, with 2+ years focused on deep learning and neural network applications', 'Experience in Banking, Payments or Financial Services formulating AI data solutions that allow us to leverage our data to know our customers better and target our resources for better market penetration and focused attention and education', 'Proficiency in Python and ML libraries such as scikit-learn, XGBoost, TensorFlow, Keras, or PyTorch', 'Deep understanding of neural networks, model regularization, overfitting/underfitting prevention, and GPU-accelerated training', 'Experience with customer data enrichments', 'Proven track record of building, evaluating, and deploying machine learning models at scale in production environments', 'Experience with cloud platforms (AWS/Google Cloud Platform/Azure), containerization, and model serving technologies', 'Excellent communication skills, with the ability to present complex findings to both technical and non-technical stakeholders', 'Hands-on experience with real-world applications of deep learning, such as recommendation engines, fraud detection, customer segmentation, document summarization, image recognition, or speech processing', 'Familiarity with MLOps tools (e.g., MLflow, SageMaker, Airflow, Kubeflow)', 'Experience with CI/CD for ML, feature stores, and real-time inference systems', 'Contributions to academic research, open-source ML projects, or ML/AI patents']","['Design, build, and evaluate machine learning and deep learning models for classification, regression, recommendation, NLP, computer vision, and time-series forecasting', 'Apply deep learning techniques (e.g., CNNs, RNNs, LSTMs, Transformers) to solve complex, data-intensive problems', 'Lead the development of ML products, from model prototyping through production deployment, performance monitoring, and continuous improvement', 'Select appropriate architectures and hyperparameters, optimize model performance, and use proper evaluation metrics (e.g., AUC, F1, BLEU, IoU, perplexity) based on the use case', 'Collaborate with product managers and engineers to translate business challenges into deployable solutions using AI/ML', 'Design automated pipelines for data preprocessing, feature engineering, training, and inference (batch or real-time)', 'Evaluate model drift, monitor performance post-deployment, and implement retraining pipelines as part of a production MLOps system', 'Mentor junior data scientists, contribute to code reviews, and lead technical discussions across the data science and engineering teams']",True,"['Transformers', 'Convolutional Neural Networks', 'Recurrent Neural Networks', 'Deep Learning Frameworks']","Transformers: Using transformer architectures for advanced deep learning tasks such as NLP and computer vision.; Convolutional Neural Networks: Applying CNNs for image recognition and other spatial data problems.; Recurrent Neural Networks: Using RNNs and LSTMs for sequential data modeling like speech and time-series.; Deep Learning Frameworks: Employing TensorFlow, Keras, and PyTorch specifically for neural network and deep learning model development.","['Machine Learning', 'Deep Learning', 'Neural Networks', 'Feature Engineering', 'Model Evaluation Metrics', 'MLOps', 'Python', 'scikit-learn', 'XGBoost', 'TensorFlow', 'Keras', 'PyTorch', 'Time-Series Forecasting', 'Recommendation Engines', 'Fraud Detection', 'Customer Segmentation', 'Document Summarization', 'Image Recognition', 'Speech Processing', 'Cloud Platforms', 'Containerization', 'Model Serving Technologies', 'CI/CD for ML', 'Feature Stores', 'Real-Time Inference Systems', 'Customer Data Enrichment']","Machine Learning: Designing, building, and evaluating models for classification, regression, recommendation, and time-series forecasting.; Deep Learning: Applying neural network architectures such as CNNs, RNNs, LSTMs, and Transformers to solve complex data problems.; Neural Networks: Using deep learning models with architectures like CNNs, RNNs, and LSTMs for tasks including image recognition and speech processing.; Feature Engineering: Designing automated pipelines for data preprocessing and feature creation to improve model training and inference.; Model Evaluation Metrics: Using metrics such as AUC, F1, BLEU, IoU, and perplexity to assess model performance based on specific use cases.; MLOps: Implementing production pipelines for model deployment, monitoring, retraining, and continuous improvement using tools like MLflow and Kubeflow.; Python: Programming language used for developing machine learning and deep learning models.; scikit-learn: ML library used for building and evaluating traditional machine learning models.; XGBoost: Gradient boosting framework used for building high-performance predictive models.; TensorFlow: Library used for building and training deep learning models, including neural networks.; Keras: High-level neural networks API used with TensorFlow for deep learning model development.; PyTorch: Deep learning framework used for building and training neural network models.; Time-Series Forecasting: Modeling and predicting sequential data trends over time.; Recommendation Engines: Building models to suggest products or content based on user data.; Fraud Detection: Developing models to identify fraudulent activities using customer and transaction data.; Customer Segmentation: Using data to group customers for targeted marketing and resource allocation.; Document Summarization: Applying models to generate concise summaries from large text documents.; Image Recognition: Using deep learning models to identify and classify images.; Speech Processing: Applying neural networks to analyze and interpret speech data.; Cloud Platforms: Utilizing AWS, Google Cloud Platform, or Azure for scalable model training and deployment.; Containerization: Using container technologies to package and deploy machine learning models consistently.; Model Serving Technologies: Tools and frameworks used to deploy machine learning models for inference in production.; CI/CD for ML: Implementing continuous integration and deployment pipelines specifically for machine learning workflows.; Feature Stores: Centralized repositories for storing and managing features used in machine learning models.; Real-Time Inference Systems: Deploying models that provide predictions instantly as new data arrives.; Customer Data Enrichment: Enhancing customer datasets with additional information to improve model accuracy and insights."
QN_ILKZJ_sCHUaNrAAAAAA==,"Manager, Data Science","Manager, Data Science

Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making.

As a Data Scientist at Capital One, you'll be part of a team that's leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives.

Team Description

As a member of the Shopping ML & Data Engineering team, you'll be joining a growth-stage line of business with a startup mindset as we build technology to save our customers money.

As a startup minded line of business, you'll have the experience working in a fast-paced environment full of greenfield problem-solving. You'll collaborate with an Agile team dedicated to productionizing machine learning applications, models and systems at scale. You'll drive and deliver the development and implementation of machine learning models using existing and emerging technology platforms. You'll lead in researching our next generation of models and recommendation systems to deliver value to our customers. You will use tools like SQL, Python, Pytorch, Transformers, language models, and other statistical tools.

Role Description

In this role, you will:
• Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love
• Leverage a broad stack of technologies - Python, Conda, AWS, H2O, Spark, and more - to reveal the insights hidden within huge volumes of numeric and textual data
• Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation
• Flex your interpersonal skills to translate the complexity of your work into tangible business goals

The Ideal Candidate is:
• Customer first. You love the process of analyzing and creating, but also share our passion to do the right thing. You know at the end of the day it's about making the right decision for our customers.
• Innovative. You continually research and evaluate emerging technologies. You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them.
• Creative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You're not afraid to share a new idea.
• A data guru. ""Big data"" doesn't faze you. You have the skills to retrieve, combine, and analyze data from a variety of sources and structures. You know understanding the data is often the key to great data science.

Basic Qualifications:
• Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:
• A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 6 years of experience performing data analytics
• A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 4 years of experience performing data analytics
• A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 1 year of experience performing data analytics
• At least 1 year of experience leveraging open source programming languages for large scale data analysis
• At least 1 year of experience working with machine learning
• At least 1 year of experience utilizing relational databases

Preferred Qualifications:
• PhD in ""STEM"" field (Science, Technology, Engineering, or Mathematics) plus 3 years of experience in data analytics
• At least 1 year of experience working with AWS
• At least 4 years' experience in Python, Scala, or R for large scale data analysis
• At least 4 years' experience with machine learning
• At least 4 years' experience with SQL

Capital One will consider sponsoring a new qualified applicant for employment authorization for this position.

The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.

McLean, VA: $193,400 - $220,700 for Mgr, Data Science

New York, NY: $211,000 - $240,800 for Mgr, Data Science

Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate's offer letter.

This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.

Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.

This role is expected to accept applications for a minimum of 5 business days.

No agencies please. Capital One is an equal opportunity employer (EOE, including disability/vet) committed to non-discrimination in compliance with applicable federal, state, and local laws. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City's Fair Chance Act; Philadelphia's Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",2025-06-26T00:00:00.000Z,2025-07-25,"['Customer first', 'You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them', 'You thrive on bringing definition to big, undefined problems', 'You love asking questions and pushing hard to find answers', 'You have the skills to retrieve, combine, and analyze data from a variety of sources and structures', 'You know understanding the data is often the key to great data science', 'Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:', ""A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 6 years of experience performing data analytics"", ""A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 4 years of experience performing data analytics"", 'A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 1 year of experience performing data analytics', 'At least 1 year of experience leveraging open source programming languages for large scale data analysis', 'At least 1 year of experience working with machine learning', 'At least 1 year of experience utilizing relational databases']","[""As a startup minded line of business, you'll have the experience working in a fast-paced environment full of greenfield problem-solving"", ""You'll collaborate with an Agile team dedicated to productionizing machine learning applications, models and systems at scale"", ""You'll drive and deliver the development and implementation of machine learning models using existing and emerging technology platforms"", ""You'll lead in researching our next generation of models and recommendation systems to deliver value to our customers"", 'You will use tools like SQL, Python, Pytorch, Transformers, language models, and other statistical tools', 'Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love', 'Leverage a broad stack of technologies - Python, Conda, AWS, H2O, Spark, and more - to reveal the insights hidden within huge volumes of numeric and textual data', 'Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation', 'Flex your interpersonal skills to translate the complexity of your work into tangible business goals', 'You continually research and evaluate emerging technologies']",True,"['Transformers', 'Language Models', 'PyTorch']",Transformers: Used as a modern AI architecture for language models to enhance recommendation and prediction capabilities.; Language Models: Applied to process and analyze textual data for improved customer insights and product personalization.; PyTorch: Deep learning framework used to develop and train neural network models including transformers.,"['Statistical Modeling', 'Relational Databases', 'Machine Learning', 'SQL', 'Python', 'Spark', 'H2O', 'Data Engineering', 'Agile Methodology', 'Conda', 'Large Scale Data Analysis', 'Recommendation Systems']","Statistical Modeling: Used to personalize credit card offers and analyze customer data for decision-making.; Relational Databases: Utilized for storing and querying structured customer data to support analytics and model building.; Machine Learning: Applied to develop predictive models and recommendation systems at scale for customer savings.; SQL: Used to retrieve and manipulate large volumes of numeric and textual data from databases.; Python: Primary programming language for data analysis, model development, and pipeline implementation.; Spark: Employed for large-scale data processing and analytics on big data sets.; H2O: Used as a machine learning platform to build and deploy models efficiently.; Data Engineering: Involves building data pipelines and infrastructure to support machine learning and analytics.; Agile Methodology: Framework for collaborative and iterative development of machine learning applications.; Conda: Environment management tool used to manage dependencies for data science projects.; Large Scale Data Analysis: Handling and analyzing vast amounts of data to extract insights and build models.; Recommendation Systems: Developed to provide personalized product suggestions to customers."
0RyW4ivnA3vAdnu5AAAAAA==,Senior Data Scientist - Risk & Compliance,"Job#: 2081100

Job Description:

Role Responsibilities:
• Project Management: Leading and managing end to end data science projects, defining objectives, define requirements, and ensuring timely delivery.
• Model Development & Implementation: Developing and validating machine learning and statistical models, implementing predictive models, and optimizing existing ones.
• Data Analysis & Insights: Analyzing large datasets, identifying trends and patterns, and extracting actionable insights to inform business decisions.
• Collaboration & Communication: Working with cross-functional teams and stakeholders, including engineering, product, and business stakeholders, to translate complex data into actionable strategies.
• Mentorship & Guidance: Providing guidance and mentorship to junior data scientists, sharing expertise, and fostering their professional growth.
• Staying Updated: Keeping abreast of the latest advancements in data science and AI, exploring new tools and techniques, and identifying opportunities for innovation.
• Strategic Input: Contributing to the development of data-driven strategies and providing input on technical approaches for projects.

Role Requirements:
• Bachelor's degree in Computer Science, Statistics, Applied Math, or related field (Master's or PhD strongly preferred).
• 5+ years of industry experience in applied machine learning, with 2+ years focused on deep learning and neural network applications.
• Experience in Banking, Payments or Financial Services leading in detecting and preventing digital fraud, scams and social engineering.
• Able to quickly understand our current Risk Models with the goal of building a flexible AI solution that partners with our current risk tools to maintains our high standards for Risk Prevention and Compliance while providing flexibility to effectively run our business.
• Expertise in statistical modeling, machine learning algorithms, and data mining techniques.
• Experience navigating difficult scenarios developing and implementing execution ideas with minimal guidance.
• Proficiency in programming languages like Python or R.
• Ability to create clear and concise visualizations to communicate complex data.
• Ability to create clear and standard data models to communicate with the stakeholders and to capture the semantics of the data and the complex semi-structured content.
• Strong analytical and problem-solving skills, with the ability to tackle complex business challenges.
• Excellent communication and presentation skills to effectively convey findings to both technical and non-technical audiences.
• Experience and willingness to lead and mentor a team, providing guidance and support to junior members.

EEO Employer

Apex Systems is an equal opportunity employer. We do not discriminate or allow discrimination on the basis of race, color, religion, creed, sex (including pregnancy, childbirth, breastfeeding, or related medical conditions), age, sexual orientation, gender identity, national origin, ancestry, citizenship, genetic information, registered domestic partner status, marital status, disability, status as a crime victim, protected veteran status, political affiliation, union membership, or any other characteristic protected by law. Apex will consider qualified applicants with criminal histories in a manner consistent with the requirements of applicable law. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation in using our website for a search or application, please contact our Employee Services Department at or .

Apex Systems is a world-class IT services company that serves thousands of clients across the globe. When you join Apex, you become part of a team that values innovation, collaboration, and continuous learning. We offer quality career resources, training, certifications, development opportunities, and a comprehensive benefits package. Our commitment to excellence is reflected in many awards, including ClearlyRated's Best of Staffing in Talent Satisfaction in the United States and Great Place to Work in the United Kingdom and Mexico.

Apex Benefits Overview: Apex offers a range of supplemental benefits, including medical, dental, vision, life, disability, and other insurance plans that offer an optional layer of financial protection. We offer an ESPP (employee stock purchase program) and a 401K program which allows you to contribute typically within 30 days of starting, with a company match after 12 months of tenure. Apex also offers a HSA (Health Savings Account on the HDHP plan), a SupportLinc Employee Assistance Program (EAP) with up to 8 free counseling sessions, a corporate discount savings program and other discounts. In terms of professional development, Apex hosts an on-demand training program, provides access to certification prep and a library of technical and leadership courses/books/seminars once you have 6+ months of tenure, and certification discounts and other perks to associations that include CompTIA and IIBA. Apex has a dedicated customer service team for our Consultants that can address questions around benefits and other resources, as well as a certified Career Coach. You can access a full list of our benefits, programs, support teams and resources within our 'Welcome Packet' as well, which an Apex team member can provide.",2025-07-21T00:00:00.000Z,2025-07-25,"['5+ years of industry experience in applied machine learning, with 2+ years focused on deep learning and neural network applications', 'Experience in Banking, Payments or Financial Services leading in detecting and preventing digital fraud, scams and social engineering', 'Able to quickly understand our current Risk Models with the goal of building a flexible AI solution that partners with our current risk tools to maintains our high standards for Risk Prevention and Compliance while providing flexibility to effectively run our business', 'Expertise in statistical modeling, machine learning algorithms, and data mining techniques', 'Experience navigating difficult scenarios developing and implementing execution ideas with minimal guidance', 'Proficiency in programming languages like Python or R', 'Ability to create clear and concise visualizations to communicate complex data', 'Ability to create clear and standard data models to communicate with the stakeholders and to capture the semantics of the data and the complex semi-structured content', 'Strong analytical and problem-solving skills, with the ability to tackle complex business challenges', 'Excellent communication and presentation skills to effectively convey findings to both technical and non-technical audiences', 'Experience and willingness to lead and mentor a team, providing guidance and support to junior members']","['Project Management: Leading and managing end to end data science projects, defining objectives, define requirements, and ensuring timely delivery', 'Model Development & Implementation: Developing and validating machine learning and statistical models, implementing predictive models, and optimizing existing ones', 'Data Analysis & Insights: Analyzing large datasets, identifying trends and patterns, and extracting actionable insights to inform business decisions', 'Collaboration & Communication: Working with cross-functional teams and stakeholders, including engineering, product, and business stakeholders, to translate complex data into actionable strategies', 'Mentorship & Guidance: Providing guidance and mentorship to junior data scientists, sharing expertise, and fostering their professional growth', 'Staying Updated: Keeping abreast of the latest advancements in data science and AI, exploring new tools and techniques, and identifying opportunities for innovation', 'Strategic Input: Contributing to the development of data-driven strategies and providing input on technical approaches for projects']",True,[],,"['Machine Learning', 'Deep Learning', 'Statistical Modeling', 'Predictive Modeling', 'Data Analysis', 'Data Visualization', 'Data Modeling', 'Python', 'R']","Machine Learning: Developing and validating machine learning models to detect and prevent digital fraud and optimize risk models.; Deep Learning: Applying deep learning and neural network techniques for advanced risk and compliance modeling.; Statistical Modeling: Using statistical models to analyze data and support risk prevention and compliance strategies.; Predictive Modeling: Implementing predictive models to forecast risk and compliance outcomes.; Data Analysis: Analyzing large datasets to identify trends, patterns, and actionable insights for business decisions.; Data Visualization: Creating clear and concise visualizations to communicate complex data findings to stakeholders.; Data Modeling: Building clear and standard data models to capture data semantics and communicate with stakeholders.; Python: Using Python programming language for data science and machine learning tasks.; R: Utilizing R programming language for statistical analysis and modeling."
Rt-lAc6aN-1QgYeeAAAAAA==,Data Scientist - Fraud & Risk,"GA DHS - Data Scientist

Hybrid- GA

We are seeking a highly analytical and detail-oriented Data Scientist with experience in Risk and Fraud analytics to join our growing team. This role will focus on developing and deploying machine learning models, statistical methods, and data-driven strategies to detect risky behaviors and prevent fraudulent activities across our products and services.

Key Responsibilities
• Collect, clean, and analyze large, complex datasets from multiple sources.
• Develop predictive models and machine learning algorithms to support decision-making and improve business performance.
• Translatebusiness problems into data-driven solutions with measurable impact.
• Develop and deploy machine learning models to detect, predict, and prevent fraudulent transactions and behavior patterns.
• Analyze large volumes of structured and unstructured data from multiple sources to identify fraud trends and root causes.
• Collaborate with fraud operations, engineering, and compliance teams to implement real-time fraud detection solutions.
• Design and monitor KPIs to evaluate model performance and improve fraud detection systems over time.
• Conduct deep-dive investigations into fraud cases, creating detailed reports and actionable insights.
• Stay current with emerging fraud techniques, industry best practices, and data science tools.

Required Qualifications
• Bachelor s or master s degree in data science, Computer Science, Statistics, Mathematics, Economics or a related field.
• 10+ years of professional experience in data science
• Proficient in Python, SQL, SAS and machine learning techniques
• Experience in responsible use of AI if used in solution design
• Strong analytical skills and the ability to identify patterns and trends from data
• Experience working with large datasets and cloud platforms (e.g., AWS, Google Cloud Platform, Azure).
• Strong understanding of supervised and unsupervised fraud detection techniques, including anomaly detection, behavioral modeling, and network analysis.
• Experience with visualization tools like Tableau and Power BI.",2025-07-22T00:00:00.000Z,2025-07-25,"['Bachelor s or master s degree in data science, Computer Science, Statistics, Mathematics, Economics or a related field', '10+ years of professional experience in data science', 'Proficient in Python, SQL, SAS and machine learning techniques', 'Experience in responsible use of AI if used in solution design', 'Strong analytical skills and the ability to identify patterns and trends from data', 'Experience working with large datasets and cloud platforms (e.g., AWS, Google Cloud Platform, Azure)', 'Strong understanding of supervised and unsupervised fraud detection techniques, including anomaly detection, behavioral modeling, and network analysis', 'Experience with visualization tools like Tableau and Power BI']","['This role will focus on developing and deploying machine learning models, statistical methods, and data-driven strategies to detect risky behaviors and prevent fraudulent activities across our products and services', 'Collect, clean, and analyze large, complex datasets from multiple sources', 'Develop predictive models and machine learning algorithms to support decision-making and improve business performance', 'Translatebusiness problems into data-driven solutions with measurable impact', 'Develop and deploy machine learning models to detect, predict, and prevent fraudulent transactions and behavior patterns', 'Analyze large volumes of structured and unstructured data from multiple sources to identify fraud trends and root causes', 'Collaborate with fraud operations, engineering, and compliance teams to implement real-time fraud detection solutions', 'Design and monitor KPIs to evaluate model performance and improve fraud detection systems over time', 'Conduct deep-dive investigations into fraud cases, creating detailed reports and actionable insights', 'Stay current with emerging fraud techniques, industry best practices, and data science tools']",True,[],,"['Machine Learning', 'Predictive Modeling', 'Supervised Learning', 'Unsupervised Learning', 'Anomaly Detection', 'Behavioral Modeling', 'Network Analysis', 'Statistical Methods', 'Data Cleaning and Preparation', 'SQL', 'Python', 'SAS', 'Cloud Platforms', 'Data Visualization', 'KPI Monitoring']","Machine Learning: Used to develop and deploy models for detecting, predicting, and preventing fraudulent transactions and risky behaviors.; Predictive Modeling: Applied to support decision-making and improve business performance by forecasting fraud and risk patterns.; Supervised Learning: Employed in fraud detection techniques where labeled data is used to train models to identify fraudulent behavior.; Unsupervised Learning: Used for anomaly detection and behavioral modeling to identify unusual patterns without labeled data.; Anomaly Detection: A key technique for identifying unusual or suspicious transactions indicative of fraud.; Behavioral Modeling: Used to model user behavior patterns to detect deviations that may indicate fraud.; Network Analysis: Applied to analyze relationships and interactions within data to uncover fraud rings or collusion.; Statistical Methods: Utilized to analyze data and support the development of fraud detection models.; Data Cleaning and Preparation: Involves collecting and preprocessing large, complex datasets from multiple sources for analysis.; SQL: Used for querying and managing structured data from databases to support fraud analytics.; Python: Primary programming language for implementing machine learning models and data analysis.; SAS: Statistical software used for advanced analytics and fraud detection modeling.; Cloud Platforms: Platforms like AWS, Google Cloud, and Azure are used to handle large datasets and deploy models at scale.; Data Visualization: Tools like Tableau and Power BI are used to create dashboards and reports for monitoring fraud detection KPIs.; KPI Monitoring: Designing and tracking key performance indicators to evaluate and improve fraud detection system effectiveness."
UUkFI02qhxFHE3faAAAAAA==,Senior Data Analyst Jobs,"ManTech seeks a motivated, career- and customer-oriented Senior Data Analyst to join our innovative team in Ashburn, VA. This is a hybrid position with 2 days onsite and 3 days remote.

Each day U.S. Customs and Border Protection (CBP) oversees the massive flow of people, capital, and products that enter and depart the United States via air, land, sea, and cyberspace. The volume and complexity of both physical and virtual border crossings require the application of ""big data"" solutions to promote efficient trade and travel.

Responsibilities include but are not limited to:
• Perform exploratory data analysis using statistical techniques to identify significant trends, patterns, correlations, and anomalies.
• Independently identify solutions for assigned business problems, and routinely collaborate with enterprise/application architects, database architects, data scientists, and mission stakeholders.
• Extract, clean, and transform data associated within an identified problem space to help build predictive models as well as develop appropriate supporting documentation.
• Leverage knowledge of a variety of statistical and machine learning techniques.
• Execute projects including those intended to identify patterns and/or anomalies.
• Research information as necessary.
• Brief project management, technical design, and outcomes to both technical and non-technical audiences including senior stakeholders throughout the project lifecycle through written as well as virtual reporting.

Minimum Qualifications:
• HS Diploma/GED and 15-20 years, AS/AA and 13-18 years, BS/BA and 7-12 years, MS/MA/MBA, and 5-9 years, PhD/Doctorate and 3-7 years
• Proficiency using Python, R, Scala, or JavaScript and related packages for development and analysis.
• Experience working in field of entity resolution, analytics, data mining or name matching.
• Hands on experience with one or more relational database systems (e.g., Oracle, MySQL, Postgres)
• Hands on experience with SQL
• Strong written and verbal communication skills.

Preferred Qualifications:
• Bachelor's degree and 7 to 12 years of experience or a master's degree and 5 to 9 years of experience in business analytics, statistics, data science, information technology, economics, mathematics, statistics, computer science, physical science, engineering or a related field
• Proficiency in statistical modeling.
• A passion for low-level/embedded data/science analytics.
• Experience in cloud computing/cloud storage.
• Conceptual understanding of - and/or prior experiences related to - data profiling, fuzzy matching, entity resolution, and signal detection theory
• Prior National Targeting Center (NTC) experience, preferably with proficiency in operational data analysis.
• Experience working within an Agile development environment.

Clearance Requirements:
• Must be a U.S. citizen with the ability to obtain DHS CBP suitability prior to starting this position.

Physical Requirements:
• The person in this position needs to occasionally move about inside the office to access file cabinets, office machinery, or to communicate with coworkers, management, and customers, which may involve delivering presentations.",2025-07-19T00:00:00.000Z,2025-07-25,"['HS Diploma/GED and 15-20 years, AS/AA and 13-18 years, BS/BA and 7-12 years, MS/MA/MBA, and 5-9 years, PhD/Doctorate and 3-7 years', 'Proficiency using Python, R, Scala, or JavaScript and related packages for development and analysis', 'Experience working in field of entity resolution, analytics, data mining or name matching', 'Hands on experience with one or more relational database systems (e.g., Oracle, MySQL, Postgres)', 'Hands on experience with SQL', 'Strong written and verbal communication skills', 'Must be a U.S. citizen with the ability to obtain DHS CBP suitability prior to starting this position', 'The person in this position needs to occasionally move about inside the office to access file cabinets, office machinery, or to communicate with coworkers, management, and customers, which may involve delivering presentations']","['This is a hybrid position with 2 days onsite and 3 days remote', 'Each day U.S. Customs and Border Protection (CBP) oversees the massive flow of people, capital, and products that enter and depart the United States via air, land, sea, and cyberspace', 'The volume and complexity of both physical and virtual border crossings require the application of ""big data"" solutions to promote efficient trade and travel', 'Perform exploratory data analysis using statistical techniques to identify significant trends, patterns, correlations, and anomalies', 'Independently identify solutions for assigned business problems, and routinely collaborate with enterprise/application architects, database architects, data scientists, and mission stakeholders', 'Extract, clean, and transform data associated within an identified problem space to help build predictive models as well as develop appropriate supporting documentation', 'Leverage knowledge of a variety of statistical and machine learning techniques', 'Execute projects including those intended to identify patterns and/or anomalies', 'Research information as necessary', 'Brief project management, technical design, and outcomes to both technical and non-technical audiences including senior stakeholders throughout the project lifecycle through written as well as virtual reporting']",True,[],,"['Exploratory Data Analysis', 'Statistical Techniques', 'Predictive Modeling', 'Machine Learning Techniques', 'Data Extraction, Cleaning, and Transformation', 'Python', 'R', 'Scala', 'JavaScript', 'Entity Resolution', 'Data Mining', 'Name Matching', 'Relational Database Systems', 'SQL', 'Statistical Modeling', 'Cloud Computing/Cloud Storage', 'Data Profiling', 'Fuzzy Matching', 'Signal Detection Theory', 'Agile Development Environment']","Exploratory Data Analysis: Used to identify significant trends, patterns, correlations, and anomalies in large datasets relevant to border security and trade.; Statistical Techniques: Applied to analyze data and support decision-making in identifying patterns and anomalies.; Predictive Modeling: Building models to forecast outcomes and support operational decisions related to border crossings.; Machine Learning Techniques: Leveraged to enhance data analysis and predictive capabilities for complex business problems.; Data Extraction, Cleaning, and Transformation: Performed to prepare data for analysis and model building within the problem space.; Python: Used as a programming language for data analysis and development of analytical solutions.; R: Utilized for statistical analysis and modeling tasks.; Scala: Employed for data processing and analysis, likely in big data contexts.; JavaScript: Used for development and analysis, possibly in data visualization or web-based analytics.; Entity Resolution: Applied to identify and match entities across datasets, critical for data quality and analytics.; Data Mining: Used to discover patterns and insights from large datasets.; Name Matching: Implemented as part of entity resolution to accurately link records.; Relational Database Systems: Hands-on experience with Oracle, MySQL, and Postgres for data storage and querying.; SQL: Used to query and manipulate data within relational databases.; Statistical Modeling: Applied to analyze data and support predictive analytics.; Cloud Computing/Cloud Storage: Experience with cloud platforms to manage and store data for analytics projects.; Data Profiling: Used to assess data quality and characteristics before analysis.; Fuzzy Matching: Applied to improve entity resolution by matching similar but not identical data entries.; Signal Detection Theory: Conceptual understanding used to identify meaningful signals within noisy data.; Agile Development Environment: Experience working in iterative and collaborative project settings to deliver analytics solutions."
d2tLs81XH-GUTsjhAAAAAA==,"Principal Associate, Data Science - Model Risk Office","Principal Associate, Data Science - Model Risk Office

Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making.

As a Data Scientist at Capital One, you’ll be part of a team that’s leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives.

Team Description:

In Capital One’s Model Risk Office, we defend the company against model failures and find new ways of making better decisions with models. We use our statistics, software engineering, and business expertise to drive the best outcomes in both Risk Management and the Enterprise. We understand that we can’t prepare for tomorrow by focusing on today, so we invest in the future: investing in new skills, building better tools, and maintaining a network of trusted partners. We learn from past mistakes, and develop increasingly powerful techniques to avoid their repetition.

In this role, you will:
• Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love
• Leverage a broad stack of technologies — Python, Conda, AWS, H2O, Spark, and more — to reveal the insights hidden within huge volumes of numeric and textual data
• Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation
• Flex your interpersonal skills to translate the complexity of your work into tangible business goals
• Document your analyses and risk assessments in validation reports that are subject to audit and regulatory review

The Ideal Candidate is:
• Innovative. You continually research and evaluate emerging technologies. You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them.
• Creative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You’re not afraid to share a new idea.
• Technical. You’re comfortable with open-source languages and are passionate about developing further. You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms.
• Statistically-minded. You’ve built models, validated them, and backtested them. You know how to interpret a confusion matrix or a ROC curve. You have experience with clustering, classification, sentiment analysis, time series, and deep learning.
• A data guru. “Big data” doesn’t faze you. You have the skills to retrieve, combine, and analyze data from a variety of sources and structures. You know understanding the data is often the key to great data science.
• Detailed-oriented. You can understand and apply Capital One’s Model Policy while leveraging your technical expertise to assess potential model risks

Basic Qualifications:
• Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date :
• A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 5 years of experience performing data analytics
• A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 3 years of experience performing data analytics
• A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field)

Preferred Qualifications:
• Master’s Degree in “STEM” field (Science, Technology, Engineering, or Mathematics) plus 3 years of experience in data analytics, or PhD in “STEM” field (Science, Technology, Engineering, or Mathematics)
• At least 1 year of experience working with AWS
• At least 1 year of experience working with Generative AI
• At least 3 years’ experience in Python, Scala, or R for large scale data analysis
• At least 3 years’ experience with machine learning
• At least 3 years’ experience with SQL
• At least 3 years’ experience building or validating models to detect financial crimes

Capital One will consider sponsoring a new qualified applicant for employment authorization for this position.

The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.

McLean, VA: $158,600 - $181,000 for Princ Associate, Data Science

Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate’s offer letter.

This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.

Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.

This role is expected to accept applications for a minimum of 5 business days.

No agencies please. Capital One is an equal opportunity employer (EOE, including disability/vet) committed to non-discrimination in compliance with applicable federal, state, and local laws. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",2025-07-17T00:00:00.000Z,2025-07-25,"['You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them', 'You thrive on bringing definition to big, undefined problems', 'You love asking questions and pushing hard to find answers', 'You’re comfortable with open-source languages and are passionate about developing further', 'You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms', 'Statistically-minded', 'You know how to interpret a confusion matrix or a ROC curve', 'You have experience with clustering, classification, sentiment analysis, time series, and deep learning', 'A data guru', 'You have the skills to retrieve, combine, and analyze data from a variety of sources and structures', 'You know understanding the data is often the key to great data science', 'Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date :', ""A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 5 years of experience performing data analytics"", ""A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 3 years of experience performing data analytics"", 'A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field)']","['Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love', 'Leverage a broad stack of technologies — Python, Conda, AWS, H2O, Spark, and more — to reveal the insights hidden within huge volumes of numeric and textual data', 'Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation', 'Flex your interpersonal skills to translate the complexity of your work into tangible business goals', 'Document your analyses and risk assessments in validation reports that are subject to audit and regulatory review', 'You continually research and evaluate emerging technologies', 'You’ve built models, validated them, and backtested them', 'You can understand and apply Capital One’s Model Policy while leveraging your technical expertise to assess potential model risks']",True,['Generative AI'],"Generative AI: Experience with generative AI technologies is preferred, indicating use of modern AI methods beyond traditional machine learning.","['Statistical Modeling', 'Relational Databases', 'Python', 'Conda', 'AWS', 'H2O', 'Spark', 'Machine Learning', 'Model Validation and Backtesting', 'Clustering', 'Classification', 'Sentiment Analysis', 'Time Series Analysis', 'Deep Learning', 'SQL', 'Data Retrieval and Integration', 'Confusion Matrix and ROC Curve Interpretation']","Statistical Modeling: Used to personalize credit card offers and assess model risks in financial decision-making.; Relational Databases: Employed to manage and query structured data for credit card personalization and analytics.; Python: Primary programming language used for data analysis, model building, and implementation.; Conda: Environment and package management tool used to manage dependencies for data science projects.; AWS: Cloud computing platform used to handle large-scale data processing and model deployment.; H2O: Machine learning platform leveraged for building and validating predictive models.; Spark: Big data processing framework used to analyze huge volumes of numeric and textual data.; Machine Learning: Applied throughout model development phases including design, training, evaluation, validation, and implementation.; Model Validation and Backtesting: Techniques used to ensure model accuracy and reliability, especially in risk assessment.; Clustering: Unsupervised learning method used to identify patterns or groupings in data.; Classification: Supervised learning technique used for categorizing data, such as detecting financial crimes.; Sentiment Analysis: Analyzing textual data to extract sentiment, aiding in understanding customer feedback or risk signals.; Time Series Analysis: Used to analyze data points collected or sequenced over time for forecasting or trend detection.; Deep Learning: Applied to complex data modeling tasks, enhancing predictive capabilities.; SQL: Used for querying and managing structured data within relational databases.; Data Retrieval and Integration: Skills to combine and analyze data from diverse sources and structures for comprehensive insights.; Confusion Matrix and ROC Curve Interpretation: Statistical tools used to evaluate classification model performance."
IP3-YmuaqDpmJhu9AAAAAA==,"Sr Data Scientist (RAG systems, LLMs)","Hi,
The following requirement is open with our client.
Title : Sr Data Scientist (RAG systems, LLMs)
Client : Infovision
Duration : Long-term
Location : Dallas, TX - Onsite

Job Overview
We're looking for a highly skilled and experienced Data Scientist to help lead this transformation. If you're passionate about turning complex data into actionable insights, advancing the frontiers of anomaly detection, transformers, and Retrieval-Augmented Generation (RAG), and pushing the boundaries of what AI can do, this is your opportunity. Telecom experience is a must, but what matters most is your curiosity, creativity, and deep expertise in machine learning.

Job Requirements:
• 12+ Year of overall IT Experience
• Bachelor's degree in Computer Science, Data Science, AI/ML, or a related technical field from an accredited university, or equivalent work experience.
• Minimum 8 years of relevant work experience.
• Should have experience in Telcom Industry
• Strong experience in machine learning, deep learning, and AI frameworks (e.g., TensorFlow, PyTorch, Scikit-Learn).
• Hands-on experience with RAG systems, transformers, and NLP models.
• Expertise in anomaly detection techniques, including statistical and ML-based approaches.
• Strong background in data preprocessing, feature engineering, and model evaluation.
• Training/Pretraining/Fine-tuning LLMs and ML experience with large datasets.
• Excellent problem-solving and analytical skills.
• Networking technology background.

Preferred Qualifications:
• Advanced degree (MS/PhD) in Computer Science, Data Science, AI/ML, or a related field.
• Familiarity with graph databases and knowledge graphs for information retrieval.
• Contributions to research publications, open-source projects, or AI/ML communities.
• Understanding of AI governance and implementation.",2025-07-14T00:00:00.000Z,2025-07-25,"['Telecom experience is a must, but what matters most is your curiosity, creativity, and deep expertise in machine learning', '12+ Year of overall IT Experience', ""Bachelor's degree in Computer Science, Data Science, AI/ML, or a related technical field from an accredited university, or equivalent work experience"", 'Minimum 8 years of relevant work experience', 'Should have experience in Telcom Industry', 'Strong experience in machine learning, deep learning, and AI frameworks (e.g., TensorFlow, PyTorch, Scikit-Learn)', 'Hands-on experience with RAG systems, transformers, and NLP models', 'Expertise in anomaly detection techniques, including statistical and ML-based approaches', 'Strong background in data preprocessing, feature engineering, and model evaluation', 'Training/Pretraining/Fine-tuning LLMs and ML experience with large datasets', 'Excellent problem-solving and analytical skills', 'Networking technology background']","[""If you're passionate about turning complex data into actionable insights, advancing the frontiers of anomaly detection, transformers, and Retrieval-Augmented Generation (RAG), and pushing the boundaries of what AI can do, this is your opportunity""]",True,"['Retrieval-Augmented Generation', 'Large Language Models', 'Transformers', 'Deep Learning', 'TensorFlow', 'PyTorch', 'Natural Language Processing']","Retrieval-Augmented Generation: Implemented to enhance language models by integrating external knowledge retrieval for improved response generation.; Large Language Models: Trained, pretrained, and fine-tuned to handle complex NLP tasks within telecom data contexts.; Transformers: Used as the core architecture for NLP models and LLMs in the development of advanced AI solutions.; Deep Learning: Applied through frameworks like TensorFlow and PyTorch for building neural network models including LLMs.; TensorFlow: An AI framework used for developing and training deep learning models, especially neural networks.; PyTorch: An AI framework leveraged for building and fine-tuning deep learning models such as transformers and LLMs.; Natural Language Processing: Used in conjunction with transformers and LLMs to process and analyze telecom text data.","['Machine Learning', 'Anomaly Detection', 'Feature Engineering', 'Model Evaluation', 'Scikit-Learn']",Machine Learning: Used extensively for building predictive models and anomaly detection in telecom data.; Anomaly Detection: Applied to identify unusual patterns or outliers in telecom datasets using statistical and ML-based methods.; Feature Engineering: Involved in preprocessing and transforming telecom data to improve model performance.; Model Evaluation: Used to assess the performance and accuracy of machine learning models developed for telecom applications.; Scikit-Learn: A machine learning framework used for traditional ML model development and evaluation.
BKMzSlD6Rlg6w4-UAAAAAA==,Data Scientist (Data Scientist 3) 23033 Jobs,"Requisition Number: 23033

Required Travel: 0 - 10%

Employment Type: Full Time/Salaried/Exempt

Anticipated Salary Range: $109,269.00 - $140,000.00

Security Clearance: Secret

Level of Experience: Senior HI

This opportunity resides with All-Domain Operations (ADO), a business group within HII's Mission Technologies division. All-Domain Operations comprises multi-domain operations, platforms and logistics, and intelligence operations.

HII designs, develops, integrates and manages the sensors, systems and other assets necessary to support integrated ISR operations and accelerated decision-making. With data fusion and mission management capabilities for the Department of Defense, the combatant commands and the intelligence community, HII advances the mission around the globe.

Meet HII's Mission Technologies Division
Our team of more than 7,000 professionals worldwide delivers all-domain expertise and advanced technologies in service of mission partners across the globe. Mission Technologies is leading the next evolution of national defense - the data evolution - by accelerating a breadth of national security solutions for government and commercial customers. Our capabilities range from C5ISR, AI and Big Data, cyber operations and synthetic training environments to fleet sustainment, environmental remediation and the largest family of unmanned underwater vehicles in every class. Find the role that's right for you. Apply today. We look forward to meeting you.

To learn more about Mission Technologies, click here for a short video: https://vimeo.com/732533072

Summary:

HII Mission Technologies has been selected as one of Military.com's ""Top 25 Employers for Veterans in 2024"" and we are a Forbes Best Large Employer for 2021-2024!

Are you ready to take your career to the next level? We are seeking talented and motivated Data Scientists to join our team!

HII-Mission Technologies is seeking an experienced and innovative Data Scientist to join our team in Honolulu, Hawaii. The successful candidate will be responsible for the application of complex and advanced scientific theories, concepts, principles, and processes. Recognized within the company and the technical community as an authority in one or more scientific disciplines, you will play a critical role in developing and implementing cutting-edge solutions to address complex technical and business challenges.

#LI-SF1

What You Will Do:

As a leader in your field, you will contribute to the planning, oversight, execution, and evaluation of multiple advanced technical and scientific projects. You will work collaboratively with senior personnel, program managers, and external organizations, while maintaining a strong liaison with staff and customers.

Key Responsibilities
• Research & Development: Develop advanced concepts, techniques, and standards to address technical challenges and drive innovation.
• Thought Leadership: Publish professional and scientific papers and patents to establish and maintain thought leadership in the technical community.
• Application Development: Create and implement new applications based on professional principles and theories, enhancing the organization's capabilities.
• Collaboration: Partner with cross-functional teams to integrate innovative data solutions into broader organizational strategies.
• Problem Solving: Utilize advanced data analytics, machine learning, and statistical methods to deliver actionable insights for complex organizational challenges.
• Technology Implementation: Advocate for and implement state-of-the-art technologies to maintain the organization's competitive edge in data science.
• Project Oversight: Manage the planning and execution of multiple projects, ensuring alignment with organizational goals and stakeholder needs.
• Compliance & Ethics: Ensure adherence to ethical data handling practices and compliance with relevant data governance frameworks.

What We're Looking For:
• 5 years relevant experience with Bachelors in related field; 3 years relevant experience with Masters in related field; 0 years experience with PhD or Juris Doctorate in related field; or High School Diploma or equivalent and 9 years relevant experience.
• Exceptional problem-solving skills and the ability to derive insights from complex datasets.
• Excellent written and verbal communication skills, with experience presenting to technical audiences.
• Active DoD Secret level clearance

HII is more than a job - it's an opportunity to build a new future. We offer competitive benefits such as best-in-class medical, dental and vision plan choices; wellness resources; employee assistance programs; Savings Plan Options (401(k)); financial planning tools, life insurance; employee discounts; paid holidays and paid time off; tuition reimbursement; as well as early childhood and post-secondary education scholarships. Bonus/other non-recurrent compensation is occasionally offered for qualified positions, and if applicable to this role will be addressed by the recruiter at the screening phase of application.

Why HII
We build the world's most powerful, survivable naval ships and defense technology solutions that safeguard our seas, sky, land, space and cyber. Our workforce includes skilled tradespeople; artificial intelligence, machine learning (AI/ML) experts; engineers; technologists; scientists; logistics experts; and business administration professionals.

Recognized as one of America's top large company employers, we are a values and ethics driven organization that puts people's safety and well-being first. Regardless of your role or where you serve, at HII, you'll find a supportive and welcoming environment, competitive benefits, and valuable educational and training programs for continual career growth at every stage of your career.

Together we are working to ensure a future where everyone can be free and thrive.
All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, physical or mental disability, age, or veteran status or any other basis protected by federal, state, or local law.

Do You Need Assistance?
If you need a reasonable accommodation for any part of the employment process, please send an e-mail to buildyourcareer@hii-co.com and let us know the nature of your request and your contact information. Reasonable accommodations are considered on a case-by-case basis. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this email address. Additionally, you may also call 1-844-849-8463 for assistance. Press #3 for HII Mission Technologies.",2025-07-25T15:00:00.000Z,2025-07-25,"['The successful candidate will be responsible for the application of complex and advanced scientific theories, concepts, principles, and processes', '5 years relevant experience with Bachelors in related field; 3 years relevant experience with Masters in related field; 0 years experience with PhD or Juris Doctorate in related field; or High School Diploma or equivalent and 9 years relevant experience', 'Exceptional problem-solving skills and the ability to derive insights from complex datasets', 'Excellent written and verbal communication skills, with experience presenting to technical audiences', 'Active DoD Secret level clearance']","['All-Domain Operations comprises multi-domain operations, platforms and logistics, and intelligence operations', 'HII designs, develops, integrates and manages the sensors, systems and other assets necessary to support integrated ISR operations and accelerated decision-making', 'With data fusion and mission management capabilities for the Department of Defense, the combatant commands and the intelligence community, HII advances the mission around the globe', 'Recognized within the company and the technical community as an authority in one or more scientific disciplines, you will play a critical role in developing and implementing cutting-edge solutions to address complex technical and business challenges', 'As a leader in your field, you will contribute to the planning, oversight, execution, and evaluation of multiple advanced technical and scientific projects', 'You will work collaboratively with senior personnel, program managers, and external organizations, while maintaining a strong liaison with staff and customers', 'Research & Development: Develop advanced concepts, techniques, and standards to address technical challenges and drive innovation', 'Thought Leadership: Publish professional and scientific papers and patents to establish and maintain thought leadership in the technical community', ""Application Development: Create and implement new applications based on professional principles and theories, enhancing the organization's capabilities"", 'Collaboration: Partner with cross-functional teams to integrate innovative data solutions into broader organizational strategies', 'Problem Solving: Utilize advanced data analytics, machine learning, and statistical methods to deliver actionable insights for complex organizational challenges', ""Technology Implementation: Advocate for and implement state-of-the-art technologies to maintain the organization's competitive edge in data science"", 'Project Oversight: Manage the planning and execution of multiple projects, ensuring alignment with organizational goals and stakeholder needs', 'Compliance & Ethics: Ensure adherence to ethical data handling practices and compliance with relevant data governance frameworks']",True,[],,"['Advanced Data Analytics', 'Machine Learning', 'Statistical Methods', 'Data Fusion', 'Data Governance']",Advanced Data Analytics: Used to analyze complex datasets and derive actionable insights for organizational challenges.; Machine Learning: Applied to develop predictive models and solutions addressing technical and business problems.; Statistical Methods: Employed to support data-driven decision-making and analysis within projects.; Data Fusion: Integrated multiple data sources to support ISR operations and accelerate decision-making.; Data Governance: Ensures ethical data handling practices and compliance with relevant frameworks.
pz9qdlT5XuoksyxlAAAAAA==,Systems Engineer (SE1/SE2/SE3)  Data Science & Complex Systems,"CCS Global Tech is a rapidly growing Information Technology company with a diverse portfolio of technology products and services and a large network of industry partnerships. With over 22 years of being a successful business with a global talent pool and presence, CCS is a certified Microsoft Gold Partner and specializes in delivering expert Microsoft based solutions for technical and business needs. We have been recognized by Inc. 500 Magazine as one of the fastest growing small companies in the Unites States. we are a Tier 1 vendor for the City and County of San Francisco for Cloud Services, Staffing Services and Training Services. For this multi-year opportunity with a diverse set of needs to address, we are currently focusing on establishing partnerships with individuals as well as companies who can help us enhance our overall service portfolio, cut lead times, and ultimately help us deliver successfully. We currently hold sizable Government accounts in the San Francisco bay area including City and County of San Francisco, San Mateo County, and Santa Clara County. We take great pride in our global reach and local influence. Your experience alongside our highly skilled and talented internal team who guide you along the way, offers key insights into what helps you stand out in a competitive job market. If you are a partner company, please submit resumes with contact information of your own W2 Consultants only. Submitted consultants are expected to have excellent communication skills.

Overview:

We are seeking a Systems Engineer (SE1 SE3) with a strong foundation in complex systems-of-systems engineering and a passion for data science, natural language processing (NLP), and machine learning (ML). This role supports mission-critical efforts to extract, process, and analyze data from unstructured and semi-structured sources to drive strategic insights and operational effectiveness.

Application Process:

Interested candidates should submit their resume detailing their qualifications and experience.

Security Clearance Requirements:
• U.S. Citizenship required
• Active TS/SCI Security Clearance with Polygraph

Key Responsibilities:
• Apply systems engineering principles to design, analyze, and manage complex systems-of-systems architectures
• Extract and transform data from unstructured/semi-structured sources (e.g., PDFs, CONOPS, DoDAF artifacts) using tools such as Apache Tika and PDFMiner
• Develop and apply NLP and ML models to derive insights from textual and structured data
• Conduct qualitative analysis and present findings through data visualization and storytelling
• Collaborate with cross-functional teams to translate mission needs into technical solutions
• Develop and maintain scripts and tools using Python, R, and frameworks such as TensorFlow or PyTorch
• Support the development of system documentation, including requirements specifications, interface definitions, and test plans

Education & Experience Requirements:

Systems Engineer Level 1 (SE1):
• Bachelor's degree in System Engineering, Computer Science, Information Systems, Engineering Science, Engineering Management, or related discipline from an accredited college or university
• Seven (7) years of experience as a Systems Engineer in programs and contracts of similar scope, type, and complexity

Systems Engineer Level 2 (SE2):
• Bachelor's degree as stated above
• Fourteen (14) years of experience as a Systems Engineer in similar roles

Systems Engineer Level 3 (SE3):
• Bachelor's degree as stated above
• Twenty (20) years of experience as a Systems Engineer in similar roles

Note: Five (5) years of additional Systems Engineering experience may be substituted for a Bachelor's degree

Required Skills & Abilities:
• Experience in systems engineering for complex, multi-domain systems
• Proficiency with NLP and ML techniques and tools
• Expertise in data extraction from unstructured/semi-structured documents
• Programming in Python and/or R
• Experience with frameworks such as TensorFlow, PyTorch, Apache Tika, and PDFMiner
• Strong analytical and problem-solving skills with high attention to detail

Desired Skills:
• Familiarity with Department of Defense (DoD) systems, documentation standards, and mission environments
• Experience with data governance, metadata tagging, and schema alignment for enterprise analytics

Fringe Benefits:
• Health Insurance: Comprehensive medical, dental, and vision plans
• Retirement Plan: 401(k) with company match
• Paid Time Off: Generous PTO policy including vacation, sick leave, and holidays
• Professional Development: Opportunities for training, certifications, and career advancement
• Work-Life Balance: Flexible work schedules and remote work options
• Wellness Programs: Employee assistance programs, wellness initiatives, and gym membership discounts

Why Join Us?
• Impactful Work: Contribute to critical government projects that make a difference
• Career Growth: Take advantage of professional development and advancement opportunities
• Supportive Environment: Collaborate in a flexible, team-oriented workplace that values balance
• Competitive Compensation: Enjoy a competitive salary and comprehensive benefits package",2025-07-22T00:00:00.000Z,2025-07-25,"['Interested candidates should submit their resume detailing their qualifications and experience', 'U.S. Citizenship required', 'Active TS/SCI Security Clearance with Polygraph', ""Bachelor's degree in System Engineering, Computer Science, Information Systems, Engineering Science, Engineering Management, or related discipline from an accredited college or university"", 'Seven (7) years of experience as a Systems Engineer in programs and contracts of similar scope, type, and complexity', ""Bachelor's degree as stated above"", 'Fourteen (14) years of experience as a Systems Engineer in similar roles', ""Bachelor's degree as stated above"", 'Twenty (20) years of experience as a Systems Engineer in similar roles', ""Note: Five (5) years of additional Systems Engineering experience may be substituted for a Bachelor's degree"", 'Experience in systems engineering for complex, multi-domain systems', 'Proficiency with NLP and ML techniques and tools', 'Expertise in data extraction from unstructured/semi-structured documents', 'Programming in Python and/or R', 'Experience with frameworks such as TensorFlow, PyTorch, Apache Tika, and PDFMiner', 'Strong analytical and problem-solving skills with high attention to detail']","['Submitted consultants are expected to have excellent communication skills', 'This role supports mission-critical efforts to extract, process, and analyze data from unstructured and semi-structured sources to drive strategic insights and operational effectiveness', 'Apply systems engineering principles to design, analyze, and manage complex systems-of-systems architectures', 'Extract and transform data from unstructured/semi-structured sources (e.g., PDFs, CONOPS, DoDAF artifacts) using tools such as Apache Tika and PDFMiner', 'Develop and apply NLP and ML models to derive insights from textual and structured data', 'Conduct qualitative analysis and present findings through data visualization and storytelling', 'Collaborate with cross-functional teams to translate mission needs into technical solutions', 'Develop and maintain scripts and tools using Python, R, and frameworks such as TensorFlow or PyTorch', 'Support the development of system documentation, including requirements specifications, interface definitions, and test plans']",True,['Deep Learning'],Deep Learning: Utilized through frameworks like TensorFlow and PyTorch to develop neural network models for NLP and machine learning tasks.,"['Natural Language Processing', 'Machine Learning', 'Data Extraction from Unstructured Documents', 'Python', 'R', 'TensorFlow', 'PyTorch', 'Data Visualization', 'Systems Engineering']",Natural Language Processing: Used to extract and analyze data from unstructured and semi-structured textual sources to derive insights.; Machine Learning: Applied to develop models that analyze textual and structured data for strategic insights.; Data Extraction from Unstructured Documents: Involves using tools like Apache Tika and PDFMiner to transform data from PDFs and other semi-structured sources.; Python: Programming language used to develop scripts and tools for data processing and analysis.; R: Programming language used for statistical analysis and scripting in data science tasks.; TensorFlow: Framework used to build and apply machine learning models within the data science workflow.; PyTorch: Framework used to develop machine learning models for analyzing data.; Data Visualization: Used to present qualitative analysis findings and support storytelling of data insights.; Systems Engineering: Applied to design and manage complex systems-of-systems architectures that support data science efforts.
gcu5TL4WgQ8LDCeMAAAAAA==,"Data Scientist (Secret Clearance in Suffolk, VA) Jobs","Our Deloitte Cyber team understands the unique challenges and opportunities businesses face in cybersecurity. Join our team to deliver powerful solutions to help our clients navigate the ever-changing threat landscape. Through powerful solutions and managed services that simplify complexity, we enable our clients to operate with resilience, grow with confidence, and proactively manage to secure success.

Work You'll Do:

Provide and oversee system design, data systems analysis, and implementation of tools and technologies to meet our Client's mission and information needs. Support development and implementation of DON data strategies.

The Team:

Deloitte's Government and Public Services (GPS) practice - our people, ideas, technology and outcomes-is designed for impact. Serving federal, state, & local government clients as well as public higher education institutions, our team of over 15,000+ professionals brings fresh perspective to help clients anticipate disruption, reimagine the possible, and fulfill their mission promise.

Our Cyber Strategy & Transformation offering develops and transforms cyber programs in line with a client's strategic objectives, regulatory requirements, and risk appetite. It keeps the enterprise a step ahead of the evolving threat landscape and gives stakeholders confidence in the organization's cyber posture. Includes design of the cyber organization, governance, and risk assessments.

Qualifications:

Required:
• Bachelor's degree required.
• Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future.
• Active Secret required.
• Must be local to the Hampton Roads area and able to come onsite in Suffolk, VA for 5 days a week.
• At least 5+ years of experience developing software and databases using modern software tools and frameworks.
• 5+ years of the following experience:
• Established and maintained data pipelines using Python and SQL
• Delivered demonstrations at various professional symposiums
• Led requirements gathering engagements with stakeholders
• Led quality assurance reviews of projects

As used in this posting, ""Deloitte"" means Deloitte Transactions and Business Analytics LLP, a subsidiary of Deloitte LLP. Please see www.deloitte.com/us/about for a detailed description of the legal structure of Deloitte LLP and its subsidiaries.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.

Information for applicants with a need for accommodation: https://www2.deloitte.com/us/en/pages/careers/articles/join-deloitte-assistance-for-disabled-applicants.html",2025-07-22T00:00:00.000Z,2025-07-25,"[""Bachelor's degree required"", 'Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future', 'Active Secret required', 'Must be local to the Hampton Roads area and able to come onsite in Suffolk, VA for 5 days a week', 'At least 5+ years of experience developing software and databases using modern software tools and frameworks', '5+ years of the following experience:', 'Established and maintained data pipelines using Python and SQL', 'Led requirements gathering engagements with stakeholders', 'Led quality assurance reviews of projects']","[""Provide and oversee system design, data systems analysis, and implementation of tools and technologies to meet our Client's mission and information needs"", 'Support development and implementation of DON data strategies', ""It keeps the enterprise a step ahead of the evolving threat landscape and gives stakeholders confidence in the organization's cyber posture"", 'Includes design of the cyber organization, governance, and risk assessments', 'Delivered demonstrations at various professional symposiums']",True,[],,"['Data Pipelines', 'Python', 'SQL']",Data Pipelines: The role involves establishing and maintaining data pipelines using Python and SQL to support data flow and processing.; Python: Used as a programming language to develop software and manage data pipelines in the data systems.; SQL: Utilized for database development and querying to support data analysis and pipeline management.
MoTsdRVI_VQZ46nNAAAAAA==,Data Engineer Jobs,"Primary Senior Data Engineer Responsibilities:

Provide technical monitoring and oversight to multiple projects as they integrate data analysis & automation into their workflow

Guide technical development through assessment and evaluation of customized solutions that meet evolving project requirements

Oversee the development of data solutions to assist and accelerate government research and development

Conduct appropriate testing on all developed infrastructures

Senior Data Engineer Required Qualifications:

Must be a U.S. citizen with the ability to obtain/maintain a Top Secret security clearance

Bachelor’s degree in Computer Science, Information Technology, Operations Research, Mathematics, Physics along with a minimum of 5 to 7 years of relevant industry or academic experience

Remote work is approved for this role

Occasional Travel is required

Strong programming skills in Python and SQL, and experience with other languages (GO, C++, etc.)

Communicate complex quantitative matters in a clear, precise, and actionable manner

Strong sense of ownership and attention to detail

Senior Data Engineer Desired Qualifications:

Advanced degree in Computer Science, Information Technology, Operations Research, Mathematics, Physics or a related field

Related experience in cybersecurity and/or binary analysis

Strong willingness to expand the knowledge base

Acumen for autonomous work alongside a collaborative team",2025-07-24T00:00:00.000Z,2025-07-25,"['Must be a U.S. citizen with the ability to obtain/maintain a Top Secret security clearance', 'Bachelor’s degree in Computer Science, Information Technology, Operations Research, Mathematics, Physics along with a minimum of 5 to 7 years of relevant industry or academic experience', 'Remote work is approved for this role', 'Occasional Travel is required', 'Strong programming skills in Python and SQL, and experience with other languages (GO, C++, etc.)', 'Communicate complex quantitative matters in a clear, precise, and actionable manner', 'Strong sense of ownership and attention to detail', 'Advanced degree in Computer Science, Information Technology, Operations Research, Mathematics, Physics or a related field', 'Related experience in cybersecurity and/or binary analysis', 'Strong willingness to expand the knowledge base', 'Acumen for autonomous work alongside a collaborative team']","['Provide technical monitoring and oversight to multiple projects as they integrate data analysis & automation into their workflow', 'Guide technical development through assessment and evaluation of customized solutions that meet evolving project requirements', 'Oversee the development of data solutions to assist and accelerate government research and development', 'Conduct appropriate testing on all developed infrastructures']",False,[],,"['Python', 'SQL', 'Data Analysis', 'Data Automation']",Python: Used as a primary programming language for developing data solutions and automation workflows.; SQL: Utilized for querying and managing data within databases to support data analysis and infrastructure development.; Data Analysis: Integrated into project workflows to extract insights and support decision-making in government research.; Data Automation: Applied to streamline data processing and operational workflows across multiple projects.
76N88hiAX0Vi-aMyAAAAAA==,"Data Scientist II, Supply Chain Retail Technology","The salary range for this position is $121,000 - $132,000 per year. The base salary offered may vary depending on location, job-related knowledge, skills, and experience.

This is a hybrid-onsite role. Employees are expected to be in our Boston, MA office Tuesdays-Thursday, and work remotely Mondays and Fridays.

Who We Are

The Supply Chain Retail Technology Data Science team is dedicated to understanding and optimizing user interactions with our Supply Chain & Retail Technology suite of tools and products. SCRT Data Science is responsible for integrating analytics into the DNA of these growing tech teams, unlocking the insights that will guide the business in our quest for cost-efficient, perfect orders, at scale, with AI and data science techniques playing a crucial role in processing vast datasets and predicting optimal outcomes. We bring a multidisciplinary blend of analytical aptitude, technical expertise, business strategy, and stakeholder management. Moreover, we're a highly collaborative, supportive team that values learning, psychological safety, and intentional career development.

What You'll Do
• Own the insights that inform the SCRT product roadmap, including driving outcomes within Fulfillment, Transportation and Service Technology.
• Perform deep-dive analysis, including the application of advanced analytical techniques and data science models, to solve critical and complex business problems.
• Leverage AI-powered platforms and tools to enhance existing analytical frameworks, automate data discovery, identify hidden patterns, and generate prescriptive recommendations, accelerating the delivery of actionable insights to product and engineering teams.
• Collaborate with all facets of the organization including product management, engineering, and creative design to identify the most impactful ways for data and analytics to drive decision making.
• Become the subject matter expert for data, analytics, and testing for your area to ensure accurate and proper interpretation of core metrics and user behavior.
• Build machine learning proof-of-concepts by developing Python code to train models and visualize their outputs, in order to demonstrate the art of the possible to stakeholders.
• Develop data visualizations, including reports, dashboards, and analyses in Looker and GBQ to distribute data insights in an easily digestible manner.
• Stay abreast of the latest advancements in AI and machine learning, particularly as they apply to supply chain, logistics, and service technology, and advocate for their strategic adoption to maintain a competitive analytical edge.

What You'll Need
• Proficient knowledge of SQL and statistical programming language(s) such as Python, R, SAS, or SPSS (Python preferred)
• Expert at conducting quantitative analyses on large and complex data sets, including ability to explain techniques to both technical and non-technical stakeholders.
• Experience with experimental test design (e.g., A/B testing; Multivariate and Multi-Armed Bandit) and statistical analysis to drive business decision making.
• Experience in using AI-powered platforms to enhance and accelerate Data Science output (i.e. generating SQL and researching techniques using ChatGPT, analyzing text using Gemini Pro...)
• Experience with data visualization software (e.g. Google Looker Studio/Looker, Tableau, PowerBI).
• Experience applying data science techniques and partnering with business teams on agile model development.
• Strong written and verbal communication skills covering objectives, status, results, and recommendations.
• Bachelors in computer science, engineering, math, statistics, economics, Operations Research, Industrial engineering or other quantitative discipline; Masters preferred.
• 3+ years work experience in relevant field

About Wayfair Inc.

Wayfair is one of the world's largest online destinations for the home. Whether you work in our global headquarters in Boston, or in our warehouses or offices throughout the world, we're reinventing the way people shop for their homes. Through our commitment to industry-leading technology and creative problem-solving, we are confident that Wayfair will be home to the most rewarding work of your career. If you're looking for rapid growth, constant learning, and dynamic challenges, then you'll find that amazing career opportunities are knocking.

No matter who you are, Wayfair is a place you can call home. We're a community of innovators, risk-takers, and trailblazers who celebrate our differences, and know that our unique perspectives make us stronger, smarter, and well-positioned for success. We value and rely on the collective voices of our employees, customers, community, and suppliers to help guide us as we build a better Wayfair - and world - for all. Every voice, every perspective matters. That's why we're proud to be an equal opportunity employer. We do not discriminate on the basis of race, color, ethnicity, ancestry, religion, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, veteran status, genetic information, or any other legally protected characteristic.

Your personal data is processed in accordance with our Candidate Privacy Notice ( If you have any questions or wish to exercise your rights under applicable privacy and data protection laws, please contact us at",2025-07-19T00:00:00.000Z,2025-07-25,"['Expert at conducting quantitative analyses on large and complex data sets, including ability to explain techniques to both technical and non-technical stakeholders', 'Experience with experimental test design (e.g., A/B testing; Multivariate and Multi-Armed Bandit) and statistical analysis to drive business decision making', 'Experience in using AI-powered platforms to enhance and accelerate Data Science output (i.e. generating SQL and researching techniques using ChatGPT, analyzing text using Gemini Pro...)', 'Experience with data visualization software (e.g', 'Experience applying data science techniques and partnering with business teams on agile model development', 'Strong written and verbal communication skills covering objectives, status, results, and recommendations', '3+ years work experience in relevant field']","['Own the insights that inform the SCRT product roadmap, including driving outcomes within Fulfillment, Transportation and Service Technology', 'Perform deep-dive analysis, including the application of advanced analytical techniques and data science models, to solve critical and complex business problems', 'Leverage AI-powered platforms and tools to enhance existing analytical frameworks, automate data discovery, identify hidden patterns, and generate prescriptive recommendations, accelerating the delivery of actionable insights to product and engineering teams', 'Collaborate with all facets of the organization including product management, engineering, and creative design to identify the most impactful ways for data and analytics to drive decision making', 'Become the subject matter expert for data, analytics, and testing for your area to ensure accurate and proper interpretation of core metrics and user behavior', 'Build machine learning proof-of-concepts by developing Python code to train models and visualize their outputs, in order to demonstrate the art of the possible to stakeholders', 'Develop data visualizations, including reports, dashboards, and analyses in Looker and GBQ to distribute data insights in an easily digestible manner', 'Stay abreast of the latest advancements in AI and machine learning, particularly as they apply to supply chain, logistics, and service technology, and advocate for their strategic adoption to maintain a competitive analytical edge']",True,"['AI-Powered Platforms', 'ChatGPT', 'Gemini Pro']","AI-Powered Platforms: Used to enhance analytical frameworks, automate data discovery, and generate prescriptive recommendations accelerating insight delivery.; ChatGPT: Leveraged for generating SQL queries and researching techniques to accelerate data science output.; Gemini Pro: Used for analyzing text data as part of AI-powered data science workflows.","['SQL', 'Python', 'R', 'A/B Testing', 'Multivariate Testing', 'Multi-Armed Bandit', 'Data Visualization', 'Looker', 'Google BigQuery', 'Tableau', 'Power BI', 'Statistical Analysis', 'Machine Learning']","SQL: Used for querying and managing large and complex datasets to support data analysis and insights generation.; Python: Primary programming language for developing machine learning proof-of-concepts and performing data analysis.; R: Statistical programming language mentioned as an alternative for conducting quantitative analyses.; A/B Testing: Experimental test design technique used to evaluate business decisions and optimize outcomes.; Multivariate Testing: Advanced experimental design method to test multiple variables simultaneously for business insights.; Multi-Armed Bandit: Statistical method for adaptive experimentation to optimize decision-making processes.; Data Visualization: Creating reports, dashboards, and analyses using tools like Looker and Google BigQuery to communicate insights effectively.; Looker: BI tool used to develop dashboards and reports for distributing data insights.; Google BigQuery: Cloud data warehouse platform used for large-scale data analysis and visualization.; Tableau: Data visualization software used to create interactive dashboards and reports.; Power BI: Business intelligence tool for data visualization and reporting.; Statistical Analysis: Applied to drive business decision-making through quantitative evaluation of data.; Machine Learning: Developing predictive models and proof-of-concepts to solve complex business problems in supply chain and retail technology."
_gZKL81fh2RZAVeSAAAAAA==,Data Scientist/Engineer - Entry/Junior Level,"This a Full Remote job, the offer is available from: California (USA)

2024 is finally here and we hope the Job market improves however as per a resume builder survey based on response from more than 900 companies 4 out of 10 companies are planning to have layoffs in 2024 or have a hiring freeze. Almost 390,000 tech employees have been laid off since 2022 and it's still ongoing. The effect of this has led hundreds of thousands of laid off Tech employees competing with existing Jobseekers.

AI is replacing many normal jobs which were done by people. As per news reports Google is planning to Client off 30,000 employees in its ad sales who will be replaed by AI ad technology.

Entry level Job seekers struggle to get responses to their applications, are getting ghosted after interviews. In such a scenario the Job seekers need to differentiate themselves by ensuring to obtain exceptional skills and technologies so that they can wear multiple roles at a client as clients now would want to expand roles and responsibilities assigned to a particular job to save costs.

Since 2010 Synergisticit has helped Jobseekers differentiate themselves by providing candidates the requisite skills and experience to outperform at interviews and clients. Here at SynergisticIT We just don't focus on getting you a Job we make careers.

All Positions are open for all visas and US citizens

We are matchmakers we provide clients with candidates who can perform from day 1 of starting work. In this challenging economy every client wants to save $$$'s and they want the best value for their money. Jobseekers need to self-evaluate if they have the requisite skills to meet client requirements and needs as Clients now post covid can also hire remote workers which increases even more competition for jobseekers.

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart lab s etc to name a few.

We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.

We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

We also offer Skill and technology enhancement programs for candidates who are either missing skills or are lacking Industry/Client experience with Projects and skills. Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. If a Jobseeker is qualified with enough skills and have hands on project work at clients then they should be good to be submitted to clients. Shortlisting and selection are totally based on clients discretion not ours.

If you applied for a job and got emails from our skill enhancement team please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team.

please check the below links to see success outcomes of our candidates and our participation at different Tech industry events and how we are different from other organizations in helping Jobseekers secure Tech careers

https://www.synergisticit.com/candidate-outcomes/

We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please see us exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023

https://reg.rf.oracle.com/flow/oracle/cwoh23/OCWExhibitorCatalog/page/OCWexhibitorcatalog

https://youtu.be/Rfn8Y0gnfL8?si=p2V4KFv5HukJXTrn

https://youtu.be/-HkNN1ag6Zk?si=1NRfgsvL_HJMVb6Q

https://www.youtube.com/watch?v=NVBU9RYZ6UI

https://www.youtube.com/watch?v=EmO7NrWHkLM

https://www.youtube.com/watch?v=OAFOhcGy9Z8

For preparing for interviews please visit https://www.synergisticit.com/interview-questions/

We are looking for the right matching candidates for our clients

Please apply via the job posting

REQUIRED SKILLS For Java /Full stack/Software Programmer

· Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

· Highly motivated, self-learner, and technically inquisitive

· Experience in programming language Java and understanding of the software development life cycle

· Project work on the skills

· Knowledge of Core Java , javascript , C++ or software programming

· Spring boot, Microservices, Docker, Jenkins and REST API's experience

· Excellent written and verbal communication skills

For data Science/Machine learning Positions

REQUIRED SKILLS

· Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

· Project work on the technologies needed

· Highly motivated, self-learner, and technically inquisitive

· Experience in programming language Java and understanding of the software development life cycle

· Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools

· Excellent written and verbal communication skills

Preferred skills: NLP, Text mining, Tableau, PowerBI, SAS, Tensorflow

If you get emails from our skill enhancement team please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates

This offer from ""SynergisticIT"" has been enriched by Jobgether.com and got a 72% flex score.",2025-07-21T00:00:00.000Z,2025-07-25,"['Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry', 'Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio', 'If a Jobseeker is qualified with enough skills and have hands on project work at clients then they should be good to be submitted to clients', 'REQUIRED SKILLS For Java /Full stack/Software Programmer', 'Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT', 'Highly motivated, self-learner, and technically inquisitive', 'Experience in programming language Java and understanding of the software development life cycle', 'Project work on the skills', 'Knowledge of Core Java , javascript , C++ or software programming', ""Spring boot, Microservices, Docker, Jenkins and REST API's experience"", 'Excellent written and verbal communication skills', 'For data Science/Machine learning Positions', 'Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT', 'Project work on the technologies needed', 'Highly motivated, self-learner, and technically inquisitive', 'Experience in programming language Java and understanding of the software development life cycle', 'Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools', 'Excellent written and verbal communication skills']",,True,['TensorFlow'],"TensorFlow: Preferred framework for deep learning applications, indicating use of neural networks in AI-related tasks.","['Statistics', 'SAS', 'Python', 'Data Visualization Tools', 'Machine Learning', 'Computer Vision', 'NLP']","Statistics: Used as a foundational skill for data science roles to analyze and interpret data.; SAS: Mentioned as a preferred tool for statistical analysis and data processing in data science positions.; Python: Required programming language for data science and machine learning tasks, including data manipulation and analysis.; Data Visualization Tools: Tools like Tableau and PowerBI are preferred for creating dashboards and visualizing data insights.; Machine Learning: Relevant for positions involving predictive modeling and data-driven decision making.; Computer Vision: Listed as a knowledge area, indicating work with image data and related analytical techniques.; NLP: Preferred skill for text mining and natural language processing tasks within data science."
Jb1RDQ_HhaFRXyACAAAAAA==,Data Scientist/Senior Exploitation Specialist Jobs,"Overview

Iron EagleX (IEX), a wholly owned subsidiary of General Dynamics Information Technology, delivers agile IT and Intelligence solutions. Combining small-team flexibility with global scale, IEX leverages emerging technologies to provide innovative, user-focused solutions that empower organizations and end users to operate smarter, faster, and more securely in dynamic environments.

Responsibilities

Job Description:

The Senior Data Scientist will be responsible for querying, visualizing, aggregating, correlating, and analyzing big data across intel disciplines on-site at multiple NGA locations in Tampa, FL, St. Louis, MO or Springfield, VA optimizing existing databases to improve response time. The DS will also be required to script in Visual Basic, R, python and work with ArcGIS, Excel, SPSS, SAS, MatLab, R, etc. to maintain, access, and move data from databases and applications to include: SQL databases, ArcServer, NoSQL databases, Excel, and Tableau.

Job Duties Include (but not limited to):
• Develop methods for querying, visualizing, aggregating, correlating, and analyzing big data across intelligence disciplines.
• Optimize existing databases to speed up the query, input, export, and visualization of data.
• Work with AOS and NGA CENTCOM (AOB) teams to develop strategies for exposing new datasets and create migration plans for legacy datasets.
• Build custom solutions (tools, processes, etc.) to automate or assist analytic endeavors as submitted by AOS and AOB leadership and analytic units.
• Write scripts in Visual Basic, R, Python or other software for statistical models using large datasets to extract patterns, relationships, and anticipatory behaviors that are repeatable, efficient, hypothesis testing, and knowledge capture.
• Solve complex GEOINT analysis problem sets; understand concepts associated with structured data and relational databases.
• Maintain, move, and manipulate data between applications, using appropriate software; SQL databases, ArcServer, table data, relational/NoSQL DBMS, Microsoft EXCEL spreadsheets, ACCESS database management system, Tableau, Insights, ORACLE, and analyst provided data for ingest and cleaning.
• Develop tradecraft techniques, training solutions for discovery, preparation, manipulation and normalization of big data so that methods are repeatable and can be explained to users.

Qualifications

Required Skills & Experience:
• Must have a background with intelligence experience, including providing analysis and data science to an intelligence mission.
• Must be able to operate at a senior level and in an independent environment.
• These individuals will be some of the only data science support this office has ever received directly.
• Must be proficient at creating processes around large data sets to identify analytical discoveries.
• Must be able to take these discoveries and provide them through visualizations that are easily integrated into daily operations.
• Able to apply structured processes to enrich or manage data
• Able to apply GEOINT standards and quality.
• Able to communicate with clarity and accuracy both verbally and written.
• Due to U.S. Government contract requirements, only U.S. citizens are eligible for this role.

Education & Certifications:
• Bachelor's degree in Computer Science is preferred

Security Clearance:
• An active TS/SCI security clearance is Required

Benefits:
• National health, vision, and dental plans
• 20 days of PTO and 11 paid holidays
• Life Insurance
• Short- and long-term disability plans
• 401(K) retirement plan
• Incentive and recognition programs
• Relocation opportunities

Equal Opportunity Employer / Individuals with Disabilities / Protected Veterans",2025-07-21T00:00:00.000Z,2025-07-25,"['The DS will also be required to script in Visual Basic, R, python and work with ArcGIS, Excel, SPSS, SAS, MatLab, R, etc', 'to maintain, access, and move data from databases and applications to include: SQL databases, ArcServer, NoSQL databases, Excel, and Tableau', 'Must have a background with intelligence experience, including providing analysis and data science to an intelligence mission', 'Must be able to operate at a senior level and in an independent environment', 'These individuals will be some of the only data science support this office has ever received directly', 'Must be proficient at creating processes around large data sets to identify analytical discoveries', 'Must be able to take these discoveries and provide them through visualizations that are easily integrated into daily operations', 'Able to apply structured processes to enrich or manage data', 'Able to apply GEOINT standards and quality', 'Able to communicate with clarity and accuracy both verbally and written', 'Due to U.S. Government contract requirements, only U.S. citizens are eligible for this role', 'An active TS/SCI security clearance is Required']","['The Senior Data Scientist will be responsible for querying, visualizing, aggregating, correlating, and analyzing big data across intel disciplines on-site at multiple NGA locations in Tampa, FL, St. Louis, MO or Springfield, VA optimizing existing databases to improve response time', 'Develop methods for querying, visualizing, aggregating, correlating, and analyzing big data across intelligence disciplines', 'Optimize existing databases to speed up the query, input, export, and visualization of data', 'Work with AOS and NGA CENTCOM (AOB)', 'teams to develop strategies for exposing new datasets and create migration plans for legacy datasets', 'Build custom solutions (tools, processes, etc.)', 'to automate or assist analytic endeavors as submitted by AOS and AOB leadership and analytic units', 'Write scripts in Visual Basic, R, Python or other software for statistical models using large datasets to extract patterns, relationships, and anticipatory behaviors that are repeatable, efficient, hypothesis testing, and knowledge capture', 'Solve complex GEOINT analysis problem sets; understand concepts associated with structured data and relational databases', 'Maintain, move, and manipulate data between applications, using appropriate software; SQL databases, ArcServer, table data, relational/NoSQL DBMS, Microsoft EXCEL spreadsheets, ACCESS database management system, Tableau, Insights, ORACLE, and analyst provided data for ingest and cleaning', 'Develop tradecraft techniques, training solutions for discovery, preparation, manipulation and normalization of big data so that methods are repeatable and can be explained to users']",True,[],,"['Big Data Analytics', 'Data Visualization', 'SQL Databases', 'NoSQL Databases', 'Python', 'R', 'Visual Basic', 'ArcGIS', 'Tableau', 'SPSS', 'SAS', 'MATLAB', 'Excel', 'Access Database', 'Oracle Database', 'Data Ingestion and Cleaning', 'Statistical Modeling', 'Hypothesis Testing', 'Data Pipeline Automation', 'Geospatial Intelligence (GEOINT)', 'Data Normalization']","Big Data Analytics: Analyzing large and complex datasets across intelligence disciplines to extract meaningful insights and improve decision-making.; Data Visualization: Creating visual representations of data to communicate analytical discoveries effectively and integrate them into daily operations.; SQL Databases: Using structured query language databases to store, query, and manage relational data for intelligence analysis.; NoSQL Databases: Managing and querying non-relational databases to handle diverse and unstructured intelligence data.; Python: Scripting language used for statistical modeling, data manipulation, and automating analytic processes.; R: Statistical programming language employed for building statistical models and analyzing large datasets.; Visual Basic: Scripting language used to develop custom tools and automate data processing tasks.; ArcGIS: Geospatial analysis software used for geographic intelligence (GEOINT) data visualization and analysis.; Tableau: Business intelligence tool used to create interactive dashboards and visualizations for data insights.; SPSS: Statistical software used for data analysis and hypothesis testing within intelligence datasets.; SAS: Advanced analytics software applied for statistical modeling and data management.; MATLAB: Numerical computing environment used for data analysis and algorithm development.; Excel: Spreadsheet software used for data manipulation, analysis, and visualization.; Access Database: Database management system used to store and manage structured data for analysis.; Oracle Database: Enterprise-level relational database system used for managing large-scale intelligence data.; Data Ingestion and Cleaning: Processes to import, prepare, and normalize data from various sources to ensure quality and usability.; Statistical Modeling: Developing models to identify patterns, relationships, and predictive behaviors in intelligence data.; Hypothesis Testing: Applying statistical tests to validate assumptions and findings within data analysis.; Data Pipeline Automation: Building custom scripts and tools to automate repetitive data processing and analytic tasks.; Geospatial Intelligence (GEOINT): Applying geospatial data standards and analysis techniques to support intelligence missions.; Data Normalization: Standardizing data formats and structures to enable consistent analysis and reporting."
8YiP-FtLhRFLwhfuAAAAAA==,"Member of Technical Staff, Data Scientist, Copilot Memory and Personalization","Overview

As Microsoft continues to push the boundaries of AI, we are on the lookout for passionate individuals to work with us on the most interesting and challenging AI questions of our time. Our vision is bold and broad - to build systems that have true artificial intelligence across agents, applications, services, and infrastructure. It's also inclusive: we aim to make AI accessible to all - consumers, businesses, developers - so that everyone can realize its benefits.

Microsoft AI (MAI) is seeking experienced Data Scientists to help build Copilot memory and personalization - AI that remembers, evolves, and grows with each user. You'll work in a highly collaborative, fast-paced environment to develop systems that deepen memory with every interaction, personalize experiences to reflect each user's unique style and goals, and make interactions feel more like working with a trusted partner than using a tool.

Microsoft's mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.

By applying to this U.S. Mountain View, CA you are required to be local to the San Francisco area and in office 3 days a week.

Responsibilities

In this role, you will:
• Develop and improve evaluation methodologies to assess model output quality, for both machine eval and human eval metrics and coverage.
• Design and implement scalable data pipelines to extract, transform, and structure product logs for evaluation use cases.
• Stay current on the latest in LLM research on evaluation and prompting.
• Drive actionable product insights, opportunity analyses, and metric tracking to guide product direction and success.
• Drive new ways of instrumentation and measurement approach to evaluate new feature performance through experimentation.
• Design and maintain core data pipelines and conduct hands-on analysis of large-scale telemetry data using advanced algorithms and tools.
• Articulate insights, storyboard with data and communicate to influence leadership and other key decision makers.
• Stay current on the latest in LLM research on evaluation and prompting.
• Enjoy working in a fast-paced, design-driven, product development cycle.

Qualifications

Required Qualifications
• Doctorate in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 1+ year(s) data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results)
• OR Master's Degree in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 3+ years data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results)
• OR Bachelor's Degree in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 5+ years data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results)
• OR equivalent experience.
• 1+ year customer-facing, project-delivery experience, professional services, and/or consulting experience.

Preferred Qualifications
• Doctorate in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 5+ year(s) data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results)
• OR Master's Degree in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 7+ years data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results)
• OR Bachelor's Degree in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 10+ years data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results)
• OR equivalent experience.
• Experience in designing core data pipelines and conduct hands-on analysis of large-scale telemetry data using advanced algorithms and tools.
• Experience building or evaluating LLM applications in production.

Data Science IC4 - The typical base pay range for this role across the U.S. is USD $119,800 - $234,700 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $158,400 - $258,000 per year.

Data Science IC5 - The typical base pay range for this role across the U.S. is USD $139,900 - $274,800 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $188,000 - $304,200 per year.

Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here:

Microsoft will accept applications and processes offers for these roles on an ongoing basis.

#Copilot #MicrosoftAI",2025-06-29T00:00:00.000Z,2025-07-25,"['Doctorate in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 1+ year(s) data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results)', ""OR Master's Degree in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 3+ years data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results)"", ""OR Bachelor's Degree in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 5+ years data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results)"", 'OR equivalent experience', '1+ year customer-facing, project-delivery experience, professional services, and/or consulting experience']","[""You'll work in a highly collaborative, fast-paced environment to develop systems that deepen memory with every interaction, personalize experiences to reflect each user's unique style and goals, and make interactions feel more like working with a trusted partner than using a tool"", 'By applying to this U.S. Mountain View, CA you are required to be local to the San Francisco area and in office 3 days a week', 'Develop and improve evaluation methodologies to assess model output quality, for both machine eval and human eval metrics and coverage', 'Design and implement scalable data pipelines to extract, transform, and structure product logs for evaluation use cases', 'Stay current on the latest in LLM research on evaluation and prompting', 'Drive actionable product insights, opportunity analyses, and metric tracking to guide product direction and success', 'Drive new ways of instrumentation and measurement approach to evaluate new feature performance through experimentation', 'Design and maintain core data pipelines and conduct hands-on analysis of large-scale telemetry data using advanced algorithms and tools', 'Articulate insights, storyboard with data and communicate to influence leadership and other key decision makers', 'Stay current on the latest in LLM research on evaluation and prompting', 'Enjoy working in a fast-paced, design-driven, product development cycle']",True,"['Large Language Models', 'Prompt Engineering', 'Personalization AI']","Large Language Models: Staying current on research related to LLMs, including evaluation and prompting techniques, and building or evaluating LLM applications in production.; Prompt Engineering: Applying and researching prompting methods to improve LLM output quality and interaction.; Personalization AI: Developing AI systems that personalize user experiences by remembering and evolving with each user interaction.","['Data Pipelines', 'Evaluation Methodologies', 'Statistical Techniques', 'Telemetry Data Analysis', 'Experimentation and Metric Tracking', 'Product Insights and Opportunity Analysis']","Data Pipelines: Designing and implementing scalable pipelines to extract, transform, and structure product logs and telemetry data for evaluation and analysis.; Evaluation Methodologies: Developing and improving methods to assess model output quality using both machine and human evaluation metrics.; Statistical Techniques: Applying statistical methods to manage and analyze structured and unstructured data as part of data science responsibilities.; Telemetry Data Analysis: Conducting hands-on analysis of large-scale telemetry data using advanced algorithms and tools to derive actionable insights.; Experimentation and Metric Tracking: Driving new instrumentation and measurement approaches to evaluate feature performance through experimentation and tracking key metrics.; Product Insights and Opportunity Analysis: Using data-driven insights and analyses to guide product direction and measure success."
2p_CYDqO1K29DnsSAAAAAA==,Navy Sepass Geospatial Data Scientist Jobs,"Koniag IT Systems, LLC is seeking a Geospatial Data Scientist to provide enterprise-level geospatial intelligence (GEOINT) systems engineering support for the U.S. Navy. This senior-level position requires an individual who brings extensive expertise in GEOINT architectures, systems integration, and advanced geospatial analysis. The ideal candidate will serve as a technical leader and subject matter expert, providing guidance on complex GEOINT systems, enterprise architecture, and analytical methodologies. This position requires an active TS/SCI clearance.

We offer competitive compensation and an exceptional benefits package, including health, dental, and vision insurance, a 401 (k) with company matching, flexible spending accounts, paid holidays, three weeks of paid time off, and more.

Education and Experience:
• Bachelor of Science degree: 12-15 years of experience in a related field.
• Master of Science degree: 10-13 years of experience in a related field.
• PhD: 10+ years of experience in a related field

Essential responsibilities, Functions, & Duties
• The Data Scientist will provide advisory and assistance support by assessing enterprise geospatial technologies, workflows, processes, procedures, and products in use across the NSG community and providing systems analysis and recommendations to support the Surf Eagle Enterprise Geographic Information System (GIS) Strategy
• The Data Scientist will contribute to the Enterprise GIS Strategy, assist with implementing strategic initiatives, research future technologies, and provide documentation and recommendations to appropriately leverage technological advances and align program stakeholders to the Enterprise GIS Strategy.
• The Data Scientist will monitor resource allocation for SEP and provide resource tracking, resource leveling, and resource allocation assessments for the Surf Eagle development.
• The Data Scientist will perform the full spectrum of systems engineering activities to implement an efficient, cost-effective architecture for the SEP.
• The Data Scientist will prepare and maintain NAVOCEANO and FNMOC-specific architecture views to provide a foundational framework for representing Surf Eagle architecture across the program and determining interoperability within the organizations and across the NSG and DoD.
• The Data Scientist will document existing production processes to include performance metrics to ensure the architecture is adequately managing existing requirements.
• The Data Scientist will identify performance concerns and recommend solutions.
• The Data Scientist will propose infrastructure changes and review other proposed infrastructure changes to ensure the changes align with the approved architecture.
• The Data Scientist will provide support to and assist in COMNAVMETOCCOM's transition to the Intelligence Community Information Technology Enterprise.
• The Data Scientist will provide support in life cycle management, configuration management and change management.
• The Data Scientist will advise the SEP PM on strategic needs for program evolution, including detailed roadmaps for Information Technology infrastructure based on requirements and resulting capabilities of national standards
• The Data Scientist will attend and participate in forums as required by the COR.

Required Skills and Competencies:
• Work independently or as part of a team as needed.
• Strong analytical and problem-solving skills
• Excellent communication abilities

Our Equal Employment Opportunity Policy

The company is an equal opportunity employer. The company shall not discriminate against any employee or applicant because of race, color, religion, creed, ethnicity, sex, sexual orientation, gender or gender identity (except where gender is a bona fide occupational qualification), national origin or ancestry, age, disability, citizenship, military/veteran status, marital status, genetic information or any other characteristic protected by applicable federal, state, or local law. We are committed to equal employment opportunity in all decisions related to employment, promotion, wages, benefits, and all other privileges, terms, and conditions of employment.

The company is dedicated to seeking all qualified applicants. If you require an accommodation to navigate or apply for a position on our website, please get in touch with Heaven Wood via e-mail at [email protected] or by calling 703-488-9377 to request accommodations.

Koniag Government Services (KGS) is an Alaska Native Owned corporation supporting the values and traditions of our native communities through an agile employee and corporate culture that delivers Enterprise Solutions, Professional Services and Operational Management to Federal Government Agencies. As a wholly owned subsidiary of Koniag, we apply our proven commercial solutions to a deep knowledge of Defense and Civilian missions to provide forward leaning technical, professional, and operational solutions. KGS enables successful mission outcomes for our customers through solution-oriented business partnerships and a commitment to exceptional service delivery. We ensure long-term success with a continuous improvement approach while balancing the collective interests of our customers, employees, and native communities. For more information, please visit www.koniag-gs.com.

Equal Opportunity Employer/Veterans/Disabled. Shareholder Preference in accordance with Public Law 88-352.",2025-07-22T00:00:00.000Z,2025-07-25,"['This senior-level position requires an individual who brings extensive expertise in GEOINT architectures, systems integration, and advanced geospatial analysis', 'Bachelor of Science degree: 12-15 years of experience in a related field', 'Master of Science degree: 10-13 years of experience in a related field', 'PhD: 10+ years of experience in a related field', 'Work independently or as part of a team as needed', 'Strong analytical and problem-solving skills', 'Excellent communication abilities']","['The ideal candidate will serve as a technical leader and subject matter expert, providing guidance on complex GEOINT systems, enterprise architecture, and analytical methodologies', 'The Data Scientist will provide advisory and assistance support by assessing enterprise geospatial technologies, workflows, processes, procedures, and products in use across the NSG community and providing systems analysis and recommendations to support the Surf Eagle Enterprise Geographic Information System (GIS) Strategy', 'The Data Scientist will contribute to the Enterprise GIS Strategy, assist with implementing strategic initiatives, research future technologies, and provide documentation and recommendations to appropriately leverage technological advances and align program stakeholders to the Enterprise GIS Strategy', 'The Data Scientist will monitor resource allocation for SEP and provide resource tracking, resource leveling, and resource allocation assessments for the Surf Eagle development', 'The Data Scientist will perform the full spectrum of systems engineering activities to implement an efficient, cost-effective architecture for the SEP', 'The Data Scientist will prepare and maintain NAVOCEANO and FNMOC-specific architecture views to provide a foundational framework for representing Surf Eagle architecture across the program and determining interoperability within the organizations and across the NSG and DoD', 'The Data Scientist will document existing production processes to include performance metrics to ensure the architecture is adequately managing existing requirements', 'The Data Scientist will identify performance concerns and recommend solutions', 'The Data Scientist will propose infrastructure changes and review other proposed infrastructure changes to ensure the changes align with the approved architecture', ""The Data Scientist will provide support to and assist in COMNAVMETOCCOM's transition to the Intelligence Community Information Technology Enterprise"", 'The Data Scientist will provide support in life cycle management, configuration management and change management', 'The Data Scientist will advise the SEP PM on strategic needs for program evolution, including detailed roadmaps for Information Technology infrastructure based on requirements and resulting capabilities of national standards', 'The Data Scientist will attend and participate in forums as required by the COR']",False,[],,"['Geospatial Analysis', 'Enterprise GIS Strategy', 'Systems Engineering', 'Performance Metrics', 'Resource Allocation and Tracking', 'Configuration and Change Management', 'Systems Integration']","Geospatial Analysis: Used to analyze spatial data and provide intelligence insights within the Navy's GEOINT systems.; Enterprise GIS Strategy: Involves contributing to and implementing strategic initiatives for the Navy's Geographic Information System to support enterprise-level geospatial intelligence.; Systems Engineering: Applied to design and implement efficient, cost-effective architectures for geospatial intelligence programs.; Performance Metrics: Used to document and monitor production processes ensuring system architectures meet operational requirements.; Resource Allocation and Tracking: Involves monitoring and assessing resource distribution to support development efforts within the Surf Eagle program.; Configuration and Change Management: Supports lifecycle management of geospatial systems ensuring controlled updates and system integrity.; Systems Integration: Combines various geospatial technologies and workflows to create interoperable GEOINT systems."
K24fatQuZpsBE5vTAAAAAA==,Senior Business Analyst,"Summary

NiCE is seeking a Senior Business Analyst to join their team. This role focuses on data science and analysis, acting as a subject matter expert in applying statistics and machine learning to business operations. The Senior Business Analyst will conduct research, identify business insights to improve customer experience and operational efficiencies, and partner with cross-functional teams. Responsibilities include data analysis, prototyping, evaluating performance, and presenting findings to leadership. The role requires a versatile individual with strong relational database and core BI skills, with business ownership for Services Delivery and Support organizations. The ideal candidate will drive innovation in products, processes, and support by investigating AI opportunities.

Must Have
• Degree in data science, computer science, or related fields OR 3+ years of data science work experience
• Advanced knowledge of statistics
• Experience with data analysis tools and strong analytical skills
• Experience in researching and implementing algorithms using R, Python, Scala, Java or others
• Experience in data management & modeling, developing dashboards using BI tools like PowerBI, Tableau, Domo
• 4+ years of experience working with business teams to understand objectives and requirements
• Strong verbal and written communication, listening, and presentation skills
• Ability to work cross-functionally and communicate to all business levels
• Fluent English

Good To Have
• Experience with new and existing data analysis tools
• Ability to manipulate and analyze complex, high-volume, high-dimensionality data
• Experience exploring undefined business problems using structured and unstructured data
• Drive collection of new data and refinement of existing data sources
• Provide business improvement recommendations
• Analyze, report, and present on findings and behavioral trends
• Spur future product, process, and support innovation
• Investigate AI opportunities

At NiCE, we don’t limit our challenges. We challenge our limits. Always. We’re ambitious. We’re game changers. And we play to win. We set the highest standards and execute beyond them. And if you’re like us, we can offer you the ultimate career opportunity that will light a fire within you.

Location: Salt Lake City, UT (office based, hybrid work schedule)

The Senior Business Analyst will operate in the realm of data science/analysis and serve as subject matter experts on the application of statistics and machine learning into business operations.

This role will conduct research and analysis to identify business insights that seek to improve the Customer Experience and overall business efficiencies (productivity, cost, value).

In this role you will be analyzing data and partnering with cross functional teams to identify objectives, opportunities, and make business recommendations. Your work will be both analytical and experimental in nature and include prototyping of new analysis, investigating data, evaluating performance, and summarizing your findings back to key leaders for action.

You are expected to be a versatile individual with strong relational database and core BI skills. Business ownership related to the Services Delivery and Support organizations

Responsibilities:
• Research, design, and develop data analysis leveraging new and existing tools
• Manipulate and analyze complex, high-volume, high-dimensionality data from varying sources
• Explore high-level, undefined ideas and business problems using structured and unstructured data
• Drive the collection of new data and the refinement of existing data sources
• Provide business improvement recommendations through careful consideration of business value and data analysis
• Analyze, report, and present on findings and behavioral trends
• Spur future product, process, and support innovation
• Investigate AI opportunities to enhance the customer experience, reduce manual work, and/or automate remedial tasks

Requirements:
• Degree in data science, computer science, or related fields (or relative equivalent, 3+ years of data science work experience). Advanced knowledge of statistics
• Experience with data analysis tools and capabilities; strong analytical skills
• Experience in researching and implementing algorithms using R, Python, Scala, Java or others
• Experience in data management & modeling, developing dashboards and reports for target set of metrics; inclusive of calculated fields and dynamic dashboards using Industry grade BI Tools like PowerBI, Tableau, Domo, etc.
• 4 or more years of experience in working with business teams to understand objectives, requirements
• Strong verbal and written communication skills, listening skills, and effective presentation skills
• Ability to work cross functionally and communicate to all levels of the business
• Fluent English - a must

About NiCE

NICE Ltd. (NASDAQ: NICE) software products are used by 25,000+ global businesses, including 85 of the Fortune 100 corporations, to deliver extraordinary customer experiences, fight financial crime and ensure public safety. Every day, NiCE software manages more than 120 million customer interactions and monitors 3+ billion financial transactions.

Known as an innovation powerhouse that excels in AI, cloud and digital, NiCE is consistently recognized as the market leader in its domains, with over 8,500 employees across 30+ countries.

NiCE is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, age, sex, marital status, ancestry, neurotype, physical or mental disability, veteran status, gender identity, sexual orientation or any other category protected by law.",2025-07-10T00:00:00.000Z,2025-07-25,"['Degree in data science, computer science, or related fields OR 3+ years of data science work experience', 'Advanced knowledge of statistics', 'Experience with data analysis tools and strong analytical skills', 'Experience in researching and implementing algorithms using R, Python, Scala, Java or others', 'Experience in data management & modeling, developing dashboards using BI tools like PowerBI, Tableau, Domo', '4+ years of experience working with business teams to understand objectives and requirements', 'Strong verbal and written communication, listening, and presentation skills', 'Ability to work cross-functionally and communicate to all business levels', 'Fluent English', 'Experience with new and existing data analysis tools', 'Ability to manipulate and analyze complex, high-volume, high-dimensionality data', 'Experience exploring undefined business problems using structured and unstructured data', 'Drive collection of new data and refinement of existing data sources', 'Provide business improvement recommendations', 'Analyze, report, and present on findings and behavioral trends', 'Spur future product, process, and support innovation', 'You are expected to be a versatile individual with strong relational database and core BI skills', 'Business ownership related to the Services Delivery and Support organizations', 'Degree in data science, computer science, or related fields (or relative equivalent, 3+ years of data science work experience)', 'Advanced knowledge of statistics', 'Experience with data analysis tools and capabilities; strong analytical skills', 'Experience in researching and implementing algorithms using R, Python, Scala, Java or others', 'Experience in data management & modeling, developing dashboards and reports for target set of metrics; inclusive of calculated fields and dynamic dashboards using Industry grade BI Tools like PowerBI, Tableau, Domo, etc', '4 or more years of experience in working with business teams to understand objectives, requirements', 'Strong verbal and written communication skills, listening skills, and effective presentation skills', 'Ability to work cross functionally and communicate to all levels of the business', 'Fluent English - a must']","['This role focuses on data science and analysis, acting as a subject matter expert in applying statistics and machine learning to business operations', 'The Senior Business Analyst will conduct research, identify business insights to improve customer experience and operational efficiencies, and partner with cross-functional teams', 'Responsibilities include data analysis, prototyping, evaluating performance, and presenting findings to leadership', 'The role requires a versatile individual with strong relational database and core BI skills, with business ownership for Services Delivery and Support organizations', 'The ideal candidate will drive innovation in products, processes, and support by investigating AI opportunities', 'The Senior Business Analyst will operate in the realm of data science/analysis and serve as subject matter experts on the application of statistics and machine learning into business operations', 'This role will conduct research and analysis to identify business insights that seek to improve the Customer Experience and overall business efficiencies (productivity, cost, value)', 'In this role you will be analyzing data and partnering with cross functional teams to identify objectives, opportunities, and make business recommendations', 'Your work will be both analytical and experimental in nature and include prototyping of new analysis, investigating data, evaluating performance, and summarizing your findings back to key leaders for action', 'Research, design, and develop data analysis leveraging new and existing tools', 'Manipulate and analyze complex, high-volume, high-dimensionality data from varying sources', 'Explore high-level, undefined ideas and business problems using structured and unstructured data', 'Drive the collection of new data and the refinement of existing data sources', 'Provide business improvement recommendations through careful consideration of business value and data analysis', 'Analyze, report, and present on findings and behavioral trends', 'Spur future product, process, and support innovation', 'Investigate AI opportunities to enhance the customer experience, reduce manual work, and/or automate remedial tasks']",True,[],,"['Statistics', 'Machine Learning', 'Data Analysis', 'Relational Databases', 'Business Intelligence Tools', 'Data Management and Modeling', 'Algorithm Implementation', 'Prototyping', 'Structured and Unstructured Data Analysis']","Statistics: Used as a foundational method for analyzing business data and deriving insights to improve customer experience and operational efficiency.; Machine Learning: Applied to business operations to develop predictive models and algorithms that support decision-making and process improvements.; Data Analysis: Involves manipulating and examining complex, high-volume, and high-dimensional data to identify trends and business opportunities.; Relational Databases: Utilized for managing structured data and supporting data retrieval necessary for analysis and reporting.; Business Intelligence Tools: Tools like PowerBI, Tableau, and Domo are used to develop dashboards and reports that visualize key metrics and support business decisions.; Data Management and Modeling: Involves organizing, structuring, and refining data sources to enable effective analysis and reporting.; Algorithm Implementation: Researching and applying algorithms using programming languages such as R, Python, Scala, and Java to solve business problems.; Prototyping: Developing preliminary models or analyses to test hypotheses and evaluate potential business solutions.; Structured and Unstructured Data Analysis: Exploring both defined and undefined data types to address complex business problems and generate insights."
VfSdEFPB8XE0uiclAAAAAA==,Senior Cyber Data Scientist Jobs,"Description

SAIC is looking for a Cyber Data Scientist/Analyst Senior to support the Enterprise Security Operations Center (ESOC) at the National Nuclear Security Administration (NNSA) to monitor, detect, and respond to safeguard the Nuclear Security Enterprise (NSE) ensuring the integrity, confidentiality, and availability identifying, detecting, preventing, and coordinating the response and recovery efforts in response to cyber threats to protect the NNSA's critical production environments and information and operational technology systems. Work will be located at the customer facility in Las Vegas, NV, or Washington, DC and will require a Top Secret or DOEQ clearance to start.

This opportunity is contingent upon award.

Responsibilities and Duties:
• Deep understanding of cybersecurity principles, data science techniques, and machine learning.
• Ability to articulate technical concepts clearly to both technical and non-technical audiences.
• Strong analytical and problem-solving skills to handle security incidents and vulnerabilities.
• Ability to work effectively with other IT teams, stakeholders, and external partners.

Qualifications

Requirements and Skills
• Bachelor's degree in computer science, Information Security, Data Science, or a related field is required; OR Master's degree in Cybersecurity, Data Science, or a related field.
• A minimum of 7 years of experience in cybersecurity, data science is required.
• Proficiency in data analysis, machine learning, and cybersecurity principles.
• Experience in leading a team, managing projects, and providing technical guidance to junior team members is crucial.
• Strong analytical and problem-solving skills to handle security incidents and vulnerabilities.
• Ability to work effectively with other IT teams, stakeholders, and external partners.
• One of the following certifications is required: CISSP, CLDS, CADSAI-CYBER.
• A DOE Q or Top Secret level security clearance is required to start.
• Must be able to maintain a DOE Q level security clearance.",2025-07-22T00:00:00.000Z,2025-07-25,"[""Bachelor's degree in computer science, Information Security, Data Science, or a related field is required; OR Master's degree in Cybersecurity, Data Science, or a related field"", 'A minimum of 7 years of experience in cybersecurity, data science is required', 'Proficiency in data analysis, machine learning, and cybersecurity principles', 'Experience in leading a team, managing projects, and providing technical guidance to junior team members is crucial', 'Strong analytical and problem-solving skills to handle security incidents and vulnerabilities', 'Ability to work effectively with other IT teams, stakeholders, and external partners', 'One of the following certifications is required: CISSP, CLDS, CADSAI-CYBER', 'A DOE Q or Top Secret level security clearance is required to start', 'Must be able to maintain a DOE Q level security clearance']","['Work will be located at the customer facility in Las Vegas, NV, or Washington, DC and will require a Top Secret or DOEQ clearance to start', 'Deep understanding of cybersecurity principles, data science techniques, and machine learning', 'Ability to articulate technical concepts clearly to both technical and non-technical audiences', 'Strong analytical and problem-solving skills to handle security incidents and vulnerabilities', 'Ability to work effectively with other IT teams, stakeholders, and external partners']",True,[],,"['Cybersecurity Principles', 'Data Science Techniques', 'Machine Learning', 'Data Analysis']",Cybersecurity Principles: Used to safeguard critical production environments and operational technology systems by identifying and responding to cyber threats.; Data Science Techniques: Applied to analyze security data and detect vulnerabilities or incidents within the cybersecurity domain.; Machine Learning: Utilized to enhance detection and response capabilities for cyber threats by learning patterns from security data.; Data Analysis: Performed to interpret security-related data and support decision-making in incident handling and vulnerability management.
u9HcyQcPlAli2Oy1AAAAAA==,Data Scientist Jobs,"In support of XM30 Program Executive Office Ground Combat Systems (PEO GCS) at the Detroit Arsenal Amentum is currently seeking a qualified candidate to serve as a Data Scientist who is experienced working with a diverse team. Other duties may be assigned to support client and contract deliverables. Travel may be required but estimated at less than 10%. This position is currently onsite.

Essential Responsibilities:
• Apply data science principles, concepts, and practices to analyze systems, processes, and operational challenges using scientific methods and techniques
• Perform analytics on complex datasets to identify patterns, trends, and insights that support organizational decision-making
• Develop automated approaches leveraging artificial intelligence / machine learning (AI/ML) and natural language processing (NLP) to streamline the input of programs, processes, and reports for XM30
• Develop data visualization solutions to address operational problems
• Analyze, interpret, and apply data science methodologies in various situations, recommending solutions to senior analysts
• Prepare comprehensive reports, documentation, and correspondence that clearly communicate factual and procedural information
• Conduct minor phases of larger analytical assignments, ensuring quality and alignment with project objectives
• Analyze problems to identify significant factors, gather pertinent data, and develop practical, evidence-based solutions
• Collaborate effectively with team members and stakeholders across functional areas
• Plan and organize work to meet project deadlines and organizational priorities
• Continually expand knowledge of data science techniques and technologies to enhance analytical capabilities
Minimum Requirements:
• U.S. citizenship
• Secret Clearance
• Bachelor's degree and 5+ years experience in Data Science, Computer Science, Statistics, Mathematics, or related field; or a Master degree in Data Science
• Experience applying scientific methods to analyze systems, processes, and operational problems
• CADIQ
• Knowledge of mathematics and statistical analysis
• Demonstrated ability to prepare clear reports and documentation
• Experience analyzing and interpreting data to recommend practical solutions
• Strong problem-solving skills with ability to identify significant factors and gather relevant data
• Excellent collaboration and communication skills
• Ability to plan and organize work effectively
• Position will require occasional travel.
Preferred Qualifications:
• Active Public Trust designation
• Advanced degree in Data Science, Computer Science, Statistics, or related field
• Proficiency in programming languages such as Python, R, or SQL
• Knowledge of Logistics Data Analysis Center (LDAC)
• Enterprise Product Data Management (Windchill)
• Experience with data visualization tools (Tableau, Power BI, etc.)
• Knowledge of machine learning techniques and applications
• Background in big data technologies and cloud computing platforms
• General Experience or knowledge with Provisioning, Cataloging, Structure Content Development (RPSTL, etc)
• Maintenance planning either at a contractor or a user (soldier, etc)
• General Experience or knowledge with developing logistic support and maintenance actions affecting materiel readiness.

Amentum is proud to be an Equal Opportunity Employer. Our hiring practices provide equal opportunity for employment without regard to race, sex, sexual orientation, pregnancy (including pregnancy, childbirth, breastfeeding, or medical conditions related to pregnancy, childbirth, or breastfeeding), age, ancestry, United States military or veteran status, color, religion, creed, marital or domestic partner status, medical condition, genetic information, national origin, citizenship status, low-income status, or mental or physical disability so long as the essential functions of the job can be performed with or without reasonable accommodation, or any other protected category under federal, state, or local law. Learn more about your rights under Federal laws and supplemental language at Labor Laws Posters .",2025-07-25T02:00:00.000Z,2025-07-25,"['U.S. citizenship', 'Secret Clearance', ""Bachelor's degree and 5+ years experience in Data Science, Computer Science, Statistics, Mathematics, or related field; or a Master degree in Data Science"", 'Experience applying scientific methods to analyze systems, processes, and operational problems', 'CADIQ', 'Knowledge of mathematics and statistical analysis', 'Demonstrated ability to prepare clear reports and documentation', 'Experience analyzing and interpreting data to recommend practical solutions', 'Strong problem-solving skills with ability to identify significant factors and gather relevant data', 'Excellent collaboration and communication skills', 'Ability to plan and organize work effectively', 'Position will require occasional travel']","['Other duties may be assigned to support client and contract deliverables', 'Travel may be required but estimated at less than 10%', 'Apply data science principles, concepts, and practices to analyze systems, processes, and operational challenges using scientific methods and techniques', 'Perform analytics on complex datasets to identify patterns, trends, and insights that support organizational decision-making', 'Develop automated approaches leveraging artificial intelligence / machine learning (AI/ML) and natural language processing (NLP) to streamline the input of programs, processes, and reports for XM30', 'Develop data visualization solutions to address operational problems', 'Analyze, interpret, and apply data science methodologies in various situations, recommending solutions to senior analysts', 'Prepare comprehensive reports, documentation, and correspondence that clearly communicate factual and procedural information', 'Conduct minor phases of larger analytical assignments, ensuring quality and alignment with project objectives', 'Analyze problems to identify significant factors, gather pertinent data, and develop practical, evidence-based solutions', 'Collaborate effectively with team members and stakeholders across functional areas', 'Plan and organize work to meet project deadlines and organizational priorities', 'Continually expand knowledge of data science techniques and technologies to enhance analytical capabilities']",True,[],,"['Data Science Principles', 'Statistical Analysis', 'Data Analytics', 'Machine Learning', 'Natural Language Processing', 'Data Visualization', 'Programming Languages', 'Big Data Technologies', 'Reporting and Documentation']","Data Science Principles: Applying foundational data science concepts and scientific methods to analyze systems and operational challenges.; Statistical Analysis: Using mathematical and statistical techniques to interpret data and support decision-making.; Data Analytics: Performing analytics on complex datasets to identify patterns, trends, and insights for organizational decisions.; Machine Learning: Leveraging machine learning techniques to automate and improve processes and reporting within the XM30 program.; Natural Language Processing: Applying NLP methods to streamline input of programs, processes, and reports.; Data Visualization: Developing visualization solutions using tools like Tableau or Power BI to address operational problems.; Programming Languages: Using Python, R, and SQL for data manipulation, analysis, and building data-driven solutions.; Big Data Technologies: Utilizing big data platforms and cloud computing to handle and analyze large datasets.; Reporting and Documentation: Preparing clear and comprehensive reports and documentation to communicate data findings and recommendations."
WIxMPf-oM0kHz_ZkAAAAAA==,Data Scientist / Digital Commerce Marketing Analytics Consultant,"This role will focus on leveraging advanced analytics to drive insights and optimize digital commerce and retail media strategies. The ideal candidate will have a proven track record of working with digital commerce-related technologies and a strong background in data science, advanced analytics and data to drive business outcomes.

Key Responsibilities:
• Data Analysis and Modeling:
• Analyze digital commerce and retail media data to identify factors driving higher or lower conversion rates.
• Develop and implement predictive models to determine overarching insights and recommendations in order to optimize bids on keywords based on volume and profit driven by incremental share of voice.
• Utilize complex SQL logic to ETL disparate data tables and sources.
• Apply machine learning algorithms and statistical techniques to uncover hidden relationships and correlations within large first party datasets.
• Strategic Insights and Recommendations:
• Provide actionable recommendations to improve search spending and conversion rates.
• Present findings and insights to senior leadership and stakeholders using visualizations and interactive dashboards designed for non-technical audiences.
• Drive the development of strategic recommendations on analytics projects associated with business unit strategy in close collaboration with key leaders across the organization.
• Project Management and Collaboration:
• Handle end to end framing, execution and communication of advanced analytics projects to distill insights for senior business leaders in support of strategic business plans.
• Collaborate with cross-functional teams to integrate data-driven insights into strategic decision-making processes.
• Manage the engagement of advanced analytics projects, including external suppliers, to ensure projects are executed accurately, timely, and cost-efficiently.
• Proactively take on additional responsibilities and projects as needed to continuously improve performance.
• Data Management and QA:
• Act as an SME for first/zero party data sources, including evaluating data quality and completeness, identifying gaps, and determining ways to improve data utility.
• Partner with data management and stewards to maintain and enhance data quality by applying data governance policies and procedures, performing data validation and quality checks, and resolving data quality issues.
Qualifications:
• Ideal candidates should possess a strong familiarity with marketing terminology, including but not limited to: Customer Acquisition Cost (CAC), Impressions, Click-Through Rate (CTR), Conversion Rate, Glance Views, Return on Ad Spend (ROAS), Search Engine Optimization (SEO), Customer Lifetime Value (CLV), Attribution Modeling.
• Bachelor's or Master's degree in Data Science, Statistics, Computer Science, or a related field.
• 3+ years of experience in data science and advanced analytics, preferably in digital commerce or retail media.
• Proficiency in programming languages such as Python or R.
• Experience with data visualization tools like Tableau or Power BI.
• Strong analytical skills with the ability to interpret complex data sets and provide actionable insights.
• Excellent communication skills, with the ability to present complex information in a clear and concise manner.
• Experience with machine learning algorithms and statistical modeling techniques.
• Familiarity with digital marketing metrics and KPIs as stated above.
Preferred Qualifications:
• Experience working with large datasets and cloud-based data platforms (e.g., AWS, Azure).
• Knowledge of digital advertising platforms and tools (e.g., Amazon Marketing Cloud, Google Ads, Facebook Ads).
• Strong problem-solving skills and attention to detail.
• Ability to work independently and manage multiple projects simultaneously.
• CPG (Consumer Packaged Goods) analytics background preferred.
Kavaliro provides Equal Employment Opportunities to all employees and applicants. All qualified applicants will receive consideration for employment without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state, or local laws. Kavaliro is committed to the full inclusion of all qualified individuals. In keeping with our commitment, Kavaliro will take the steps to assure that people with disabilities are provided reasonable accommodations. Accordingly, if reasonable accommodation is required to fully participate in the job application or interview process, to perform the essential functions of the position, and/or to receive all other benefits and privileges of employment, please respond to this posting to connect with a company representative.",2025-06-28T00:00:00.000Z,2025-07-25,"['Ideal candidates should possess a strong familiarity with marketing terminology, including but not limited to: Customer Acquisition Cost (CAC), Impressions, Click-Through Rate (CTR), Conversion Rate, Glance Views, Return on Ad Spend (ROAS), Search Engine Optimization (SEO), Customer Lifetime Value (CLV), Attribution Modeling', ""Bachelor's or Master's degree in Data Science, Statistics, Computer Science, or a related field"", '3+ years of experience in data science and advanced analytics, preferably in digital commerce or retail media', 'Proficiency in programming languages such as Python or R', 'Experience with data visualization tools like Tableau or Power BI', 'Strong analytical skills with the ability to interpret complex data sets and provide actionable insights', 'Excellent communication skills, with the ability to present complex information in a clear and concise manner', 'Experience with machine learning algorithms and statistical modeling techniques', 'Familiarity with digital marketing metrics and KPIs as stated above']","['This role will focus on leveraging advanced analytics to drive insights and optimize digital commerce and retail media strategies', 'The ideal candidate will have a proven track record of working with digital commerce-related technologies and a strong background in data science, advanced analytics and data to drive business outcomes', 'Data Analysis and Modeling:', 'Analyze digital commerce and retail media data to identify factors driving higher or lower conversion rates', 'Develop and implement predictive models to determine overarching insights and recommendations in order to optimize bids on keywords based on volume and profit driven by incremental share of voice', 'Utilize complex SQL logic to ETL disparate data tables and sources', 'Apply machine learning algorithms and statistical techniques to uncover hidden relationships and correlations within large first party datasets', 'Strategic Insights and Recommendations:', 'Provide actionable recommendations to improve search spending and conversion rates', 'Present findings and insights to senior leadership and stakeholders using visualizations and interactive dashboards designed for non-technical audiences', 'Drive the development of strategic recommendations on analytics projects associated with business unit strategy in close collaboration with key leaders across the organization', 'Project Management and Collaboration:', 'Handle end to end framing, execution and communication of advanced analytics projects to distill insights for senior business leaders in support of strategic business plans', 'Collaborate with cross-functional teams to integrate data-driven insights into strategic decision-making processes', 'Manage the engagement of advanced analytics projects, including external suppliers, to ensure projects are executed accurately, timely, and cost-efficiently', 'Proactively take on additional responsibilities and projects as needed to continuously improve performance', 'Data Management and QA:', 'Act as an SME for first/zero party data sources, including evaluating data quality and completeness, identifying gaps, and determining ways to improve data utility', 'Partner with data management and stewards to maintain and enhance data quality by applying data governance policies and procedures, performing data validation and quality checks, and resolving data quality issues']",True,[],,"['Predictive Modeling', 'Machine Learning Algorithms', 'SQL', 'Data Visualization', 'Statistical Modeling', 'Feature Engineering', 'Data Quality Assurance', 'Advanced Analytics', 'Python', 'R', 'Marketing Analytics Metrics', 'Cloud Data Platforms']","Predictive Modeling: Developing models to predict outcomes such as keyword bid optimization based on volume and profit metrics.; Machine Learning Algorithms: Applying machine learning techniques to uncover hidden relationships and correlations within large first-party datasets.; SQL: Using complex SQL logic to extract, transform, and load (ETL) data from disparate tables and sources.; Data Visualization: Creating visualizations and interactive dashboards with tools like Tableau or Power BI to communicate insights to non-technical stakeholders.; Statistical Modeling: Employing statistical techniques to analyze digital commerce and retail media data for actionable insights.; Feature Engineering: Deriving relevant features from digital commerce and retail media data to improve model performance.; Data Quality Assurance: Evaluating and improving data quality, completeness, and utility through governance policies and validation checks.; Advanced Analytics: Leveraging advanced analytical methods to drive business outcomes and optimize digital commerce strategies.; Python: Using Python programming language for data analysis, modeling, and automation tasks.; R: Utilizing R programming language for statistical analysis and data science workflows.; Marketing Analytics Metrics: Analyzing key digital marketing KPIs such as CAC, CTR, Conversion Rate, ROAS, SEO, and Attribution Modeling to inform strategy.; Cloud Data Platforms: Experience with cloud-based data platforms like AWS and Azure for handling large datasets."
_n08oRCBfg_0HZYmAAAAAA==,Data Science & Operations Research Analyst - Senior Jobs,"Join our team at Core One! Our mission is to be at the forefront of devising analytical, operational and technical solutions to our Nation's most complex national security challenges. In order to achieve our mission, Core One values people first! We are committed to recruiting, nurturing, and retaining top talent! We offer a competitive total compensation package that sets us apart from our competition. Core One is a team-oriented, dynamic, and growing company that values exceptional performance!
• This position requires an active TS/SCI clearance.*
Responsibilities:
Provide data science (DS) and operations research (OR) capabilities on-site for a combatant command Operation Assessment Division. Design, develop, and apply a variety of data collection and decision analytics processes and applications, including the employment of mathematical, statistical, and other analytic methods. Identify effective, efficient, and innovative technical solutions for meeting Division data and automation requirements, including potential artificial intelligence (AI) and machine learning (ML) solutions. Develop automated applications, data visualizations, information displays, decision briefings, analytic papers, and facilitate senior leadership decisions with analytic products. Identify and develop data stream interfaces for authoritative data sources to support assessments and risk analysis. Integrate Division functions and products into the Command and Control of the Information Environment (C2IE) system, MAVEN Smart Systems, and/or Advana. Build digital solutions using programming applications (e.g., R, R/Shiny, Python) to digitalize and partially or fully automate data collection, analysis, and staff processes while accelerating the rate at which the Division can execute tasks. Develop and lead small teams in the development of real-time/near real-time data visualization and analysis methodologies and analytic tools. Participate in client operational planning processes in support of Joint planning. Support Knowledge Management and Information processes requirements.

Basic Qualifications:
• Possess a Bachelor's Degree and a Master of Arts or Master of Science degree, with one of the degrees being in a related technical field, such as operations research, data science, math, engineering, science, or computer science.
• 12 years of combined professional DS/OR experience, with a minimum of 5 years of related DS/OR experience at a Combatant Command staff, Joint or Combined Command Headquarters, or Defense Department equivalent.
• High levels of proficiency using the following applications: R, R-Shiny, Python, Python-Shiny, SQL/POSTRESQL, Microsoft Office applications, and Microsoft SharePoint
• Functional knowledge of MAVEN Smart Systems, C2IE, Advana, AI, ML, Git, and Large Learning Models
• Top Secret (TS)/Secure Compartmented Information (SCI) clearance is required. Applicants are subject to a security investigation and need to meet eligibility requirements for access to classified information.

Additional Qualifications:
• Ability to work independently or as the leader or member of a small team in conducting analysis in support of assessments with high visibility, unusual urgency or program criticality; requiring a variety of OR and DS techniques and tools.
• Possession of excellent oral and written communication skills with the ability to communicate, prepare correspondence, and make formal presentations at the 4-Star General Officer/Flag Officer level.
• Ability to develop and support new analytic capabilities as requirements evolve within the command for assessments.
• Knowledge of Joint Warfighting and Combatant Command functions.
Security Clearance:
• Active TS/SCI clearance is required

Core One is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, gender identity, sexual orientation, national origin, or protected veteran status and will not be discriminated against on the basis of disability.",2025-07-19T00:00:00.000Z,2025-07-25,"[""Possess a Bachelor's Degree and a Master of Arts or Master of Science degree, with one of the degrees being in a related technical field, such as operations research, data science, math, engineering, science, or computer science"", '12 years of combined professional DS/OR experience, with a minimum of 5 years of related DS/OR experience at a Combatant Command staff, Joint or Combined Command Headquarters, or Defense Department equivalent', 'High levels of proficiency using the following applications: R, R-Shiny, Python, Python-Shiny, SQL/POSTRESQL, Microsoft Office applications, and Microsoft SharePoint', 'Functional knowledge of MAVEN Smart Systems, C2IE, Advana, AI, ML, Git, and Large Learning Models', 'Top Secret (TS)/Secure Compartmented Information (SCI) clearance is required', 'Applicants are subject to a security investigation and need to meet eligibility requirements for access to classified information', 'Ability to work independently or as the leader or member of a small team in conducting analysis in support of assessments with high visibility, unusual urgency or program criticality; requiring a variety of OR and DS techniques and tools', 'Possession of excellent oral and written communication skills with the ability to communicate, prepare correspondence, and make formal presentations at the 4-Star General Officer/Flag Officer level', 'Ability to develop and support new analytic capabilities as requirements evolve within the command for assessments', 'Knowledge of Joint Warfighting and Combatant Command functions', 'Active TS/SCI clearance is required']","['Provide data science (DS) and operations research (OR) capabilities on-site for a combatant command Operation Assessment Division', 'Design, develop, and apply a variety of data collection and decision analytics processes and applications, including the employment of mathematical, statistical, and other analytic methods', 'Identify effective, efficient, and innovative technical solutions for meeting Division data and automation requirements, including potential artificial intelligence (AI) and machine learning (ML) solutions', 'Develop automated applications, data visualizations, information displays, decision briefings, analytic papers, and facilitate senior leadership decisions with analytic products', 'Identify and develop data stream interfaces for authoritative data sources to support assessments and risk analysis', 'Integrate Division functions and products into the Command and Control of the Information Environment (C2IE) system, MAVEN Smart Systems, and/or Advana', 'Build digital solutions using programming applications (e.g., R, R/Shiny, Python) to digitalize and partially or fully automate data collection, analysis, and staff processes while accelerating the rate at which the Division can execute tasks', 'Develop and lead small teams in the development of real-time/near real-time data visualization and analysis methodologies and analytic tools', 'Participate in client operational planning processes in support of Joint planning', 'Support Knowledge Management and Information processes requirements']",True,"['Large Language Models', 'Artificial Intelligence', 'Machine Learning']",Large Language Models: Functional knowledge of large learning models to explore potential AI solutions for operational assessments.; Artificial Intelligence: Identifying and applying AI techniques as part of innovative technical solutions to meet data and automation requirements.; Machine Learning: Employing machine learning methods to develop automated analytic applications and support decision-making processes.,"['Data Science', 'Operations Research', 'R', 'Python', 'SQL/PostgreSQL', 'Data Visualization', 'Data Pipelines', 'MLOps', 'Git', 'MAVEN Smart Systems', 'C2IE (Command and Control of the Information Environment)', 'Advana']","Data Science: Providing data science capabilities including data collection, analysis, and decision analytics to support operational assessments.; Operations Research: Applying mathematical, statistical, and analytic methods to optimize decision-making and operational processes.; R: Using R programming language and R-Shiny for building automated applications and data visualizations.; Python: Utilizing Python and Python-Shiny to develop digital solutions that automate data collection and analysis.; SQL/PostgreSQL: Employing SQL and PostgreSQL for managing and querying authoritative data sources to support assessments.; Data Visualization: Developing real-time and near real-time data visualization methodologies and analytic tools to facilitate leadership decisions.; Data Pipelines: Identifying and developing data stream interfaces to integrate authoritative data sources for risk analysis and assessments.; MLOps: Functional knowledge of machine learning operations to support AI and ML solutions within the division.; Git: Using Git for version control and collaboration in developing analytic and automation solutions.; MAVEN Smart Systems: Integrating division functions and products into MAVEN Smart Systems for operational data management.; C2IE (Command and Control of the Information Environment): Incorporating analytic products into the C2IE system to support command and control functions.; Advana: Utilizing Advana platform to support data integration and analytic capabilities for defense operations."
FtYf8CMHxr7yuuEPAAAAAA==,Data Scientist Jobs,"This is a U.S. based position. All of the programs we support require U.S. citizenship to be eligible for employment. All work must be conducted within the continental U.S.

Who we are:

Raft ( https://TeamRaft.com ) is a customer-obsessed non-traditional small business with a purposeful focus on Distributed Data Systems, Platforms at Scale, and Complex Application Development, with headquarters in McLean, VA. Our range of clients includes innovative federal and public agencies leveraging design thinking, cutting-edge tech stack, and cloud-native ecosystem. We build digital solutions that impact the lives of millions of Americans.

About the role:

As a Data Scientist, you will work in cross-functional teams with data at all stages of the analysis lifecycle to derive actionable insight while translating mission needs into an end-to-end analytical approach to achieve results. Your role involves performing pre-analytics areas of data collection and understanding, data cleansing and integration, and data storage and retrieval.

You will determine appropriate analytics based on data and desired outcomes using techniques including feature detection, statistics, data mining, predictive modeling, machine learning, natural language processing, and business intelligence. You'll interpret the validity of results and communicate the meaning of those results while following a scientific approach to generate value from data, verifying results at each step.

This role is contingent on contract award.

What we are looking for:
Associate: Bachelor's degree with 2+ years of related experience or Master's degree. Works on assignments requiring judgment and initiative under supervision. Develops solutions to technical problems of limited to moderate scope following established procedures.

Standard: Bachelor's degree with 5+ years of related experience, Master's degree with 3+ years of experience, or PhD. Works independently providing technical solutions to complex problems with considerable latitude in approaches.

Senior: Bachelor's degree with 9+ years of related experience, Master's degree with 7+ years of experience, or PhD with 4+ years of experience. Recognized authority providing innovative solutions to complex technical problems and leading advanced development efforts.

Experience with data wrangling, analytics, visualization software and programming languages, analytics methods for big data, machine learning, natural language processing, statistical analysis, and data mining techniques.

Highly preferred:
• Advanced degrees in data science, statistics, or related fields.
• Experience with big data platforms and tools.
• Knowledge of scientific research methodologies and result validation techniques.

Clearance Requirements:
• Active Top Secret with ability to obtain and maintain SCI

Work Type:
• Onsite in Colorado Springs, CO
• May require up to 10% travel

Salary Range:
• $115,000 - $180,000
• The determination of compensation is predicated upon a candidate's comprehensive experience, demonstrated skill, and proven abilities

What we will offer you:
• Highly competitive salary
• Fully covered healthcare, dental, and vision coverage
• 401(k) and company match
• Take as you need PTO + 11 paid holidays
• Education & training benefits
• Generous Referral Bonuses
• And More!

Our Vision Statement:

We bridge the gap between humans and data through radical transparency and our obsession with the mission.

Our Customer Obsession:

We will approach every deliverable like it's a product. We will adopt a customer-obsessed mentality. As we grow, and our footprint becomes larger, teams and employees will treat each other not only as teammates but customers. We must live the customer-obsessed mindset, always. This will help us scale and it will translate to the interactions that our Rafters have with their clients and other product teams that they integrate with. Our culture will enable our success and set us apart from other companies.

How do we get there?

Public-sector modernization is critical for us to live in a better world. We, at Raft, want to innovate and solve complex problems. And, if we are successful, our generation and the ones that follow us will live in a delightful, efficient, and accessible world where out-of-box thinking, and collaboration is a norm.

Raft's core philosophy is Ubuntu: I Am, Because We are. We support our ""nadi"" by elevating the other Rafters. We work as a hyper collaborative team where each team member brings a unique perspective, adding value that did not exist before. People make Raft special. We celebrate each other and our cognitive and cultural diversity. We are devoted to our practice of innovation and collaboration.

We're an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.",2025-07-25T15:00:00.000Z,2025-07-25,"[""Associate: Bachelor's degree with 2+ years of related experience or Master's degree"", ""Standard: Bachelor's degree with 5+ years of related experience, Master's degree with 3+ years of experience, or PhD"", 'Works independently providing technical solutions to complex problems with considerable latitude in approaches', ""Senior: Bachelor's degree with 9+ years of related experience, Master's degree with 7+ years of experience, or PhD with 4+ years of experience"", 'Recognized authority providing innovative solutions to complex technical problems and leading advanced development efforts', 'Experience with data wrangling, analytics, visualization software and programming languages, analytics methods for big data, machine learning, natural language processing, statistical analysis, and data mining techniques', 'Active Top Secret with ability to obtain and maintain SCI']","['As a Data Scientist, you will work in cross-functional teams with data at all stages of the analysis lifecycle to derive actionable insight while translating mission needs into an end-to-end analytical approach to achieve results', 'Your role involves performing pre-analytics areas of data collection and understanding, data cleansing and integration, and data storage and retrieval', 'You will determine appropriate analytics based on data and desired outcomes using techniques including feature detection, statistics, data mining, predictive modeling, machine learning, natural language processing, and business intelligence', ""You'll interpret the validity of results and communicate the meaning of those results while following a scientific approach to generate value from data, verifying results at each step"", 'Works on assignments requiring judgment and initiative under supervision', 'Develops solutions to technical problems of limited to moderate scope following established procedures', 'May require up to 10% travel']",True,[],,"['Data Wrangling', 'Feature Detection', 'Statistical Analysis', 'Data Mining', 'Predictive Modeling', 'Machine Learning', 'Natural Language Processing', 'Business Intelligence', 'Analytics Methods for Big Data', 'Data Storage and Retrieval', 'Data Collection and Understanding']",Data Wrangling: Involves cleaning and integrating data as part of the pre-analytics process to prepare datasets for analysis.; Feature Detection: Used to identify relevant attributes or variables from data to improve model performance and insights.; Statistical Analysis: Applied to interpret data validity and generate actionable insights through scientific methods.; Data Mining: Techniques employed to discover patterns and relationships within large datasets to inform decision-making.; Predictive Modeling: Building models to forecast outcomes based on historical data to support mission objectives.; Machine Learning: Utilized to develop models that learn from data for predictive and analytical purposes.; Natural Language Processing: Applied to analyze and extract information from text data as part of the analytical approach.; Business Intelligence: Used to create dashboards and visualizations that communicate insights to stakeholders.; Analytics Methods for Big Data: Techniques and tools designed to handle and analyze large-scale datasets relevant to the role.; Data Storage and Retrieval: Managing how data is stored and accessed efficiently to support analysis workflows.; Data Collection and Understanding: Initial stages of the data lifecycle involving gathering and comprehending data relevant to mission needs.
rTGWz-jOqmLvvZ1EAAAAAA==,"Member of Technical Staff, Experimentation Data Scientist","At Microsoft, we are committed to advancing the frontiers of artificial intelligence in ways that are bold, responsible, and inclusive. Our vision is to build intelligent systems-spanning agents, applications, services, and infrastructure-that empower every person and organization on the planet to achieve more. We believe AI should be accessible to all: consumers, businesses, and developers alike.

The Microsoft AI (MAI) team is looking for an Experimentation Data Scientist to help shape the next generation of personal AI experiences through Copilot. This role involves managing and analyzing experiments to provide actionable insights that drive product improvements and user experience enhancements.

Key Responsibilities:
• Experimentation Management: Collaborate with feature teams to design, implement, and debug experiments. Conduct ad hoc analysis to understand metrics and user behavior changes.
• Statistical Analysis: Perform power analysis and experimental inference to ensure the validity and reliability of experiments.
• Data Analysis: Utilize SQL and Python to pull and analyze data quickly, providing insights into user behavior and experiment outcomes.
• Collaboration: Work closely with partners to ensure robust telemetry and instrumentation and with feature teams to design and implement experiments.

Qualifications
• Bachelor's Degree in Statistics, Econometrics, Computer Science, Electrical or Computer Engineering, or related field AND 6+ years related experience (e.g., statistics, predictive analytics, research)
• OR Master's Degree in Statistics, Econometrics, Computer Science, Electrical or Computer Engineering, or related field AND 4+ years related experience (e.g., statistics, predictive analytics, research)
• OR Doctorate in Statistics, Econometrics, Computer Science, Electrical or Computer Engineering, or related field AND 3+ years related experience (e.g., statistics, predictive analytics, research)
• OR equivalent experience.
• Strong background in statistics, economics, or a related field.
• Proficiency in SQL and Python.
• Experience with online A/B testing.
• Ability to conduct power analysis and experimental inference.
• Strong problem-solving skills and attention to detail.
• Excellent communication and collaboration skills.

Preferred Qualifications:
• Experience in a similar role within a data science or analytics team.
• Familiarity with telemetry and instrumentation frameworks.

Data Science IC5 - The typical base pay range for this role across the U.S. is USD $139,900 - $274,800 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $188,000 - $304,200 per year.

Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here:

Microsoft will accept applications for the role until Month Day, Year.

Microsoft's mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.

#MAI Copilot",2025-07-12T00:00:00.000Z,2025-07-25,"[""Bachelor's Degree in Statistics, Econometrics, Computer Science, Electrical or Computer Engineering, or related field AND 6+ years related experience (e.g., statistics, predictive analytics, research)"", ""OR Master's Degree in Statistics, Econometrics, Computer Science, Electrical or Computer Engineering, or related field AND 4+ years related experience (e.g., statistics, predictive analytics, research)"", 'OR Doctorate in Statistics, Econometrics, Computer Science, Electrical or Computer Engineering, or related field AND 3+ years related experience (e.g., statistics, predictive analytics, research)', 'OR equivalent experience', 'Strong background in statistics, economics, or a related field', 'Proficiency in SQL and Python', 'Experience with online A/B testing', 'Ability to conduct power analysis and experimental inference', 'Strong problem-solving skills and attention to detail', 'Excellent communication and collaboration skills']","['This role involves managing and analyzing experiments to provide actionable insights that drive product improvements and user experience enhancements', 'Experimentation Management: Collaborate with feature teams to design, implement, and debug experiments', 'Conduct ad hoc analysis to understand metrics and user behavior changes', 'Statistical Analysis: Perform power analysis and experimental inference to ensure the validity and reliability of experiments', 'Data Analysis: Utilize SQL and Python to pull and analyze data quickly, providing insights into user behavior and experiment outcomes', 'Collaboration: Work closely with partners to ensure robust telemetry and instrumentation and with feature teams to design and implement experiments']",True,['Copilot'],"Copilot: The role supports AI-driven personal assistant experiences, specifically related to Microsoft's Copilot AI product.","['Experimentation Management', 'Statistical Analysis', 'SQL', 'Python', 'Online A/B Testing', 'Telemetry and Instrumentation']","Experimentation Management: Designing, implementing, and debugging experiments to analyze user behavior and product metrics.; Statistical Analysis: Performing power analysis and experimental inference to validate and ensure reliability of experiments.; SQL: Using SQL to extract and manipulate data for analysis of experiment outcomes and user behavior.; Python: Utilizing Python for data analysis and quick extraction of insights from experimental data.; Online A/B Testing: Conducting controlled experiments to compare different product features and measure their impact on users.; Telemetry and Instrumentation: Ensuring robust data collection frameworks to support accurate experimentation and analysis."
YqXeVDPZnyloL4yhAAAAAA==,"Technical Data Analyst with Healthcare / Okemos, MI","We are seeking a highly skilled data science/analytics contractor with hands-on experience in SQL, DBT, and Tableau, and a strong understanding of Medicaid and Medicare dental data. This individual will help drive insights, automation, and model development in support of utilization-based scoring, claims optimization, and policy evaluation initiatives. Primary Job Responsibilities:
• Design and maintain DBT models within a medallion data architecture
• Write performant SQL to transform and analyze large datasets (primarily in Snowflake)
• Build Tableau dashboards for executive and operational stakeholders, focused on dental claims, utilization trends, and benefit impact
• Interpret Medicaid/Medicare dental data for care progression, cost modeling, and policy scenarios
• Collaborate across data science, actuarial, and operations teams to deliver insights
• Ensure data quality, validation, and documentation for auditability
Must have Technical Skills:
• Strong SQL skills and experience with cloud data warehouses (Snowflake preferred)
• Proficiency with DBT for modular data modeling, testing, and documentation
• Expertise in Tableau for building visually compelling, user-friendly dashboards
• Experience working with Medicaid and/or Medicare dental data (e.g., CDT codes, utilization patterns, benefit design)
• Strong understanding of healthcare claims data structures and dental domain terminology
• Excellent problem-solving and stakeholder communication skills
Nice to have technical skills:
• Exposure to benefit expansion analysis, or dental claims optimization
• Familiarity with Git, CI/CD workflows.
• Python skills for data transformation or ML support",2025-07-09T00:00:00.000Z,2025-07-25,"['We are seeking a highly skilled data science/analytics contractor with hands-on experience in SQL, DBT, and Tableau, and a strong understanding of Medicaid and Medicare dental data', 'Proficiency with DBT for modular data modeling, testing, and documentation', 'Expertise in Tableau for building visually compelling, user-friendly dashboards', 'Experience working with Medicaid and/or Medicare dental data (e.g., CDT codes, utilization patterns, benefit design)', 'Strong understanding of healthcare claims data structures and dental domain terminology', 'Excellent problem-solving and stakeholder communication skills', 'Exposure to benefit expansion analysis, or dental claims optimization', 'Familiarity with Git, CI/CD workflows', 'Python skills for data transformation or ML support']","['This individual will help drive insights, automation, and model development in support of utilization-based scoring, claims optimization, and policy evaluation initiatives', 'Design and maintain DBT models within a medallion data architecture', 'Write performant SQL to transform and analyze large datasets (primarily in Snowflake)', 'Build Tableau dashboards for executive and operational stakeholders, focused on dental claims, utilization trends, and benefit impact', 'Interpret Medicaid/Medicare dental data for care progression, cost modeling, and policy scenarios', 'Collaborate across data science, actuarial, and operations teams to deliver insights', 'Ensure data quality, validation, and documentation for auditability']",True,[],,"['SQL', 'DBT', 'Tableau', 'Snowflake', 'Python', 'Data Quality and Validation', 'Healthcare Claims Data Analysis', 'Benefit and Claims Optimization', 'Data Modeling', 'Git and CI/CD']","SQL: Used to write performant queries for transforming and analyzing large healthcare datasets in Snowflake.; DBT: Employed for modular data modeling, testing, and documentation within a medallion data architecture.; Tableau: Used to build dashboards for executive and operational stakeholders to visualize dental claims and utilization trends.; Snowflake: Cloud data warehouse platform where large datasets are stored and queried.; Python: Applied for data transformation tasks and supporting machine learning model development.; Data Quality and Validation: Ensuring accuracy and auditability of healthcare claims data through validation and documentation.; Healthcare Claims Data Analysis: Interpreting Medicaid and Medicare dental data for care progression, cost modeling, and policy evaluation.; Benefit and Claims Optimization: Driving insights and automation to optimize dental claims and benefit design.; Data Modeling: Designing and maintaining data models to support utilization-based scoring and policy evaluation.; Git and CI/CD: Familiarity with version control and continuous integration/continuous deployment workflows to support data projects."
cD4EfZ4utwJ23pWwAAAAAA==,Data Analyst Jobs,"Overview

We are looking for you to join our team as a Senior Data Analyst. This position focuses on data analysis for law enforcement support, requiring a combination of investigative data expertise, analytical skills, and the ability to work under high-pressure, mission-critical environments. This role will involve working with diverse data sets, ensuring accuracy and integrity while supporting ongoing criminal and civil investigations.

Our ideal candidate has a blend of technical acumen, attention to detail, and the ability to engage with law enforcement agencies. We are looking for more than just a ""Data Analyst""-this role requires a technologist with excellent communication skills, customer service, and a passion for data and problem-solving.

Contributions

Key Responsibilities:
• Data Analysis and Trend Recognition: Compile and analyze data from multiple sources, identifying trends across various data sets, locations, and targets.
• Data Accuracy and Assessment: Monitor data for accuracy, integrity, authenticity, and relevancy. Identify intelligence gaps and assess data viability for investigative purposes.
• Investigative Support: Collaborate with teams to examine data gathered from criminal and civil investigations, developing methodologies to exploit investigative information.
• Quality Control & Reporting: Participate in the development of work products, conducting periodic progress reviews and ensuring quality control of findings. Regularly report findings to lead personnel.
• Data Entry: Perform data entry from both hard and soft copies into large-scale data processing systems, utilizing tools like optical character readers, scanners, and digital cameras as appropriate.
• Law Enforcement Support: Provide critical law enforcement support, interacting with various agencies through multiple channels of communication, while managing data under tight timelines in a high-pressure environment.
• Data Visualization and Tools: Leverage MS Excel, Power BI, or similar tools to design and build formulas, charts, pivot tables, and manipulate unstructured data from different platforms.
• You will be part of our Data Exploitation Practice!

Qualifications

Required:
• Ability to hold a position of SECRET clearance level with the US government.
• Bachelor's Degree and 1 year of work experience OR 5 years of work experience and no degree.
• 3+ years of experience in SQL and Python
• 5+ years of experience using data analytic/visualization tools such as MS Excel, Power BI, or others to design charts, create formulas, and analyze unstructured data (can be job or education-based).
• 2+ years of experience manipulating unstructured data from different platforms; and experience in IT, statistics, computer information systems, auditing, investigative, mathematics, and units of measure
• Skilled at multi-tasking in a fast-paced environment while maintaining clear communications with stakeholders.
• Must be local to El, Paso TX or willing to drive on site 5 days a week.
• Applicants selected will be subject to a Government background investigation and must meet eligibility and suitability requirements.

Preferred:
• Experience providing support to a 24/7 law enforcement operations unit.
• Military or law enforcement background or exposure.
• Law enforcement/drug data desired.
• Ability to manage multiple tasks in a high-paced environment, including collaboration
with various teams.
• Strong analytical skills for identifying trends, gaps, and ensuring data accuracy and
• Experience with documenting processes and developing SOPs for data handling and
• Demonstrated experience in reverse engineering and validation of data processes.
• Ability to communicate findings and updates effectively during briefings and team

About steampunk

Steampunk relies on several factors to determine salary, including but not limited to geographic location, contractual requirements, education, knowledge, skills, competencies, and experience. The projected compensation range for this position is $50,000 to $115,000. The estimate displayed represents a typical annual salary range for this position. Annual salary is just one aspect of Steampunk's total compensation package for employees. Learn more about additional Steampunk benefits here.

Identity Statement

As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud.

Steampunk is a Change Agent in the Federal contracting industry, bringing new thinking to clients in the Homeland, Federal Civilian, Health and DoD sectors. Through our Human-Centered delivery methodology, we are fundamentally changing the expectations our Federal clients have for true shared accountability in solving their toughest mission challenges. As an employee owned company, we focus on investing in our employees to enable them to do the greatest work of their careers - and rewarding them for outstanding contributions to our growth. If you want to learn more about our story, visit http://www.steampunk.com .

We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law. Steampunk participates in the E-Verify program.",2025-07-25T01:00:00.000Z,2025-07-25,"['Our ideal candidate has a blend of technical acumen, attention to detail, and the ability to engage with law enforcement agencies', 'We are looking for more than just a ""Data Analyst""-this role requires a technologist with excellent communication skills, customer service, and a passion for data and problem-solving', 'Ability to hold a position of SECRET clearance level with the US government', ""Bachelor's Degree and 1 year of work experience OR 5 years of work experience and no degree"", '3+ years of experience in SQL and Python', '5+ years of experience using data analytic/visualization tools such as MS Excel, Power BI, or others to design charts, create formulas, and analyze unstructured data (can be job or education-based)', '2+ years of experience manipulating unstructured data from different platforms; and experience in IT, statistics, computer information systems, auditing, investigative, mathematics, and units of measure', 'Skilled at multi-tasking in a fast-paced environment while maintaining clear communications with stakeholders', 'Must be local to El, Paso TX or willing to drive on site 5 days a week', 'Applicants selected will be subject to a Government background investigation and must meet eligibility and suitability requirements', 'with various teams', 'Strong analytical skills for identifying trends, gaps, and ensuring data accuracy and', 'Experience with documenting processes and developing SOPs for data handling and', 'Demonstrated experience in reverse engineering and validation of data processes', 'Ability to communicate findings and updates effectively during briefings and team']","['This position focuses on data analysis for law enforcement support, requiring a combination of investigative data expertise, analytical skills, and the ability to work under high-pressure, mission-critical environments', 'This role will involve working with diverse data sets, ensuring accuracy and integrity while supporting ongoing criminal and civil investigations', 'Data Analysis and Trend Recognition: Compile and analyze data from multiple sources, identifying trends across various data sets, locations, and targets', 'Data Accuracy and Assessment: Monitor data for accuracy, integrity, authenticity, and relevancy', 'Identify intelligence gaps and assess data viability for investigative purposes', 'Investigative Support: Collaborate with teams to examine data gathered from criminal and civil investigations, developing methodologies to exploit investigative information', 'Quality Control & Reporting: Participate in the development of work products, conducting periodic progress reviews and ensuring quality control of findings', 'Regularly report findings to lead personnel', 'Data Entry: Perform data entry from both hard and soft copies into large-scale data processing systems, utilizing tools like optical character readers, scanners, and digital cameras as appropriate', 'Law Enforcement Support: Provide critical law enforcement support, interacting with various agencies through multiple channels of communication, while managing data under tight timelines in a high-pressure environment', 'Data Visualization and Tools: Leverage MS Excel, Power BI, or similar tools to design and build formulas, charts, pivot tables, and manipulate unstructured data from different platforms', 'You will be part of our Data Exploitation Practice!']",True,[],,"['SQL', 'Python', 'Data Visualization Tools', 'Unstructured Data Manipulation', 'Data Accuracy and Integrity Assessment', 'Trend Analysis', 'Quality Control and Reporting', 'Data Entry and Processing Systems', 'Investigative Data Methodologies']","SQL: Used for querying and managing structured data from multiple sources to support investigative data analysis.; Python: Applied for data manipulation, analysis, and scripting to handle diverse datasets in law enforcement investigations.; Data Visualization Tools: Includes MS Excel and Power BI, leveraged to create charts, pivot tables, and formulas for visualizing trends and patterns in investigative data.; Unstructured Data Manipulation: Handling and analyzing unstructured data from various platforms to extract relevant investigative insights.; Data Accuracy and Integrity Assessment: Monitoring and ensuring the authenticity, relevancy, and quality of data used in criminal and civil investigations.; Trend Analysis: Identifying patterns and trends across multiple datasets, locations, and targets to support law enforcement decision-making.; Quality Control and Reporting: Conducting periodic reviews and reporting findings to maintain high standards in data analysis outputs.; Data Entry and Processing Systems: Utilizing tools like optical character readers and scanners to input data into large-scale processing systems for investigative use.; Investigative Data Methodologies: Developing and applying specialized methods to exploit data gathered from criminal and civil investigations."
vKkHH38qQ79zzWC2AAAAAA==,"Data Scientist__ Detroit, MI (Onsite)","Hi,

Hope you are doing well!

Please have a look below JD * if you are interested, please confirm your best salary ?

Role- Data Scientist

Location- Detroit, MI

Role- Only Fulltime

Salary- $120K

Description:
• Demonstrated ability to deal with and process data from real-world sources.
• Experience performing Exploratory Data Analysis (EDA).
• Experience with model development (statistical modeling, machine learning).
• Familiarity with the process of deploying models into production or working alongside teams that do.
• Proven ability to translate business questions into data-driven problems.
• Ability to translate data analysis results and model insights into clear, business-oriented solutions.
• Proficiency in at least one major programming language used in data science (e.g., Python, R).

Skills Preferred:
• Experience working with cloud computing platforms, particularly Google Cloud Platform (Google Cloud Platform).
• Experience with specific machine learning frameworks (e.g., scikit-learn, TensorFlow, PyTorch).

Experience Required:
• Experience with data manipulation and analysis libraries/tools (e.g., Pandas, SQL).

Experience Preferred:
• Experience in Auto Industry

Education Required:
• PhD in Statistics, Mathematics, Computer Science, or a closely related quantitative field.
• Additional Safety Training/Licensing/Personal Protection Requirements:

Additional Information
• Hybrid now, but it can be changed to onsite if corporate requires. 1 day a week now, but it can be changed.

Ravi Kumar

Desk: |Cell-",2025-07-09T00:00:00.000Z,2025-07-25,"['Demonstrated ability to deal with and process data from real-world sources', 'Experience performing Exploratory Data Analysis (EDA)', 'Experience with model development (statistical modeling, machine learning)', 'Familiarity with the process of deploying models into production or working alongside teams that do', 'Proven ability to translate business questions into data-driven problems', 'Ability to translate data analysis results and model insights into clear, business-oriented solutions', 'Proficiency in at least one major programming language used in data science (e.g., Python, R)', 'Experience with data manipulation and analysis libraries/tools (e.g., Pandas, SQL)', 'PhD in Statistics, Mathematics, Computer Science, or a closely related quantitative field', 'Additional Safety Training/Licensing/Personal Protection Requirements:']",,True,"['TensorFlow', 'PyTorch']","TensorFlow: A deep learning framework mentioned as a preferred skill, indicating potential use of neural networks.; PyTorch: A deep learning framework preferred for building and training neural network models.","['Exploratory Data Analysis', 'Statistical Modeling', 'Machine Learning', 'Model Deployment', 'Python', 'R', 'Pandas', 'SQL', 'Google Cloud Platform', 'Scikit-learn']","Exploratory Data Analysis: Used to understand and summarize the main characteristics of data from real-world sources in this data scientist role.; Statistical Modeling: Applied for developing predictive or descriptive models as part of the model development process.; Machine Learning: Used for building models to solve data-driven business problems and improve decision-making.; Model Deployment: Involves deploying models into production or collaborating with teams responsible for production deployment.; Python: A primary programming language used for data manipulation, analysis, and model development.; R: A programming language used for statistical analysis and data science tasks.; Pandas: A data manipulation and analysis library used to process and analyze data efficiently.; SQL: Used for querying and managing structured data from databases.; Google Cloud Platform: Cloud computing platform used to support data science workflows and model deployment.; Scikit-learn: A machine learning framework used for building and evaluating models."
hY9Ds7YI15ZaREFdAAAAAA==,Data Engineer Jobs,"Position: Data Engineer
Location: Centennial, CO
Clearance: TS/SCI Required

Grey Matters Defense Solutions stands at the forefront of developing advanced software solutions tailored to support the mission of the U.S. warfighter. With a commitment to excellence, we foster a culture grounded in a growth mindset, empowering our team to drive progress through bold actions, integrity, collaboration, and innovation. Our employees are dedicated to these core values, and together, we create impactful, mission-critical solutions that redefine the cutting-edge of defense technology. Join us at Grey Matters Defense Solutions, where your work has purpose, and your contributions fuel the future of national security.

Must have a TS/SCI for all positions

Grey Matters Defense Solutions is seeking a talented and dedicated Data Engineer

About the job:
• The position of Data Engineer for the Talon Ark Program is responsible for maintaining and designing new features for the data pipeline. The pipeline end-to-end goes from our Analyst to our Data Scientist on the program. This position is responsible for maintaining the collection of data from various sources, presenting data to the analyst, gathering and curating the inputs from the analyst, and producing the vehicle through which the Data Scientist can use the data created. This position requires a high level of problem-solving skills, and the ability to research using vast amounts of resources to arrive at a solution. The position works closely with the Analyst and Data Scientist on the program to create a viable solution for the customer. What is produced in this position is mainly for the sake of serving the Analyst and Data Scientist. However, creating and maintaining good data is a key factor in making this program successful.
Key Responsibilities:
• Collect data for analysis
• Filter data prior to showing it to analyst based on needs of models
• Provide Analyst with platform to make annotations to data
• Collect and curate annotations from Analyst
• Maintain database where annotations and their related metadata is stored
• Provide and maintain Data Scientist's access to database for the purpose of making datasets

About you:
• Python [ Pandas, NumPy, PyTorch, Ultralytics]
• Docker
• Understanding of python data manipulation packages [Pandas, NumPy, PyTorch, Dask]
• Use of APIs (some that are documented and not documented)
• Understanding of relational database design and maintenance
• Understanding of Software Design Patterns and their implementations
• Ability to do own research and implement new solutions

Preferred Skills:
• Python big data manipulation libraries (ex. PyArrow)
• Python distributed processing libraries (ex. Ray)
• Continuous Integration/Continuous Development (CICD)
• Scaling pipeline architecture

Join our team of exceptional developers, architects, and data scientists!

All qualified applicants will receive consideration for employment regardless of race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Salary Range: $125,000 - $165,000 + 25% SEP

Grey Matters Defense Solutions offer a comprehensive benefits package including medical, dental, vision, life insurance, short-term and long-term disability.

Additional Benefits:
• SEP IRA 25% of base salary
• PTO Six weeks
• IBA 12.5%
• Employee assistance program
• Employee discount
• Flexible spending account
• Health savings account
• Referral program

Grey Matters Defense Solutions' most valuable assets are the more than 60 employees, consisting of data scientists, custom software developers, and analysts/subject matter experts, with senior-level personnel formerly from DIA, NRO, NSA and the US Armed Forces. Our employees have a depth of analytical knowledge which provides them with deep understanding of managing and delivering products within government systems. Grey Matters Defense Solutions provides transformational leadership building award-winning teams and products.

Join our team of exceptional developers, architects and data scientists!

Visit us at www.greymattersdefense.com
https://www.linkedin.com/company/grey-matters-defense-solutions/
""Know Your Rights: Workplace Discrimination is Illegal""
Questions contact: [email protected]",2025-07-24T00:00:00.000Z,2025-07-25,"['Grey Matters Defense Solutions is seeking a talented and dedicated Data Engineer', 'This position requires a high level of problem-solving skills, and the ability to research using vast amounts of resources to arrive at a solution', 'Python [ Pandas, NumPy, PyTorch, Ultralytics]', 'Understanding of python data manipulation packages [Pandas, NumPy, PyTorch, Dask]', 'Use of APIs (some that are documented and not documented)', 'Understanding of relational database design and maintenance', 'Understanding of Software Design Patterns and their implementations', 'Ability to do own research and implement new solutions', 'Python distributed processing libraries (ex']","['This position is responsible for maintaining the collection of data from various sources, presenting data to the analyst, gathering and curating the inputs from the analyst, and producing the vehicle through which the Data Scientist can use the data created', 'The position works closely with the Analyst and Data Scientist on the program to create a viable solution for the customer', 'What is produced in this position is mainly for the sake of serving the Analyst and Data Scientist', 'However, creating and maintaining good data is a key factor in making this program successful', 'Collect data for analysis', 'Filter data prior to showing it to analyst based on needs of models', 'Provide Analyst with platform to make annotations to data', 'Collect and curate annotations from Analyst', 'Maintain database where annotations and their related metadata is stored', ""Provide and maintain Data Scientist's access to database for the purpose of making datasets"", 'Continuous Integration/Continuous Development (CICD)', 'Scaling pipeline architecture']",False,[],,"['Data Pipelines', 'Python', 'Pandas', 'NumPy', 'Dask', 'PyArrow', 'Ray', 'Relational Database Design', 'APIs', 'Continuous Integration/Continuous Development (CI/CD)', 'Data Annotation Platforms', 'Software Design Patterns', 'Docker', 'PyTorch']","Data Pipelines: Responsible for designing and maintaining end-to-end data pipelines that collect, filter, and curate data for analysts and data scientists.; Python: Used extensively for data manipulation and processing with libraries such as Pandas, NumPy, Dask, and PyArrow.; Pandas: A key Python library used for data manipulation and analysis within the data pipeline.; NumPy: Used for numerical data processing and manipulation as part of the data engineering tasks.; Dask: Employed for scalable and distributed data processing to handle large datasets.; PyArrow: Used for big data manipulation and efficient in-memory columnar data processing.; Ray: A Python distributed processing library used to scale data processing tasks across multiple nodes.; Relational Database Design: Maintaining and designing databases to store annotations and metadata for data scientists and analysts.; APIs: Utilized to collect data from various sources, including both documented and undocumented APIs.; Continuous Integration/Continuous Development (CI/CD): Applied to automate and streamline the deployment and scaling of data pipeline architectures.; Data Annotation Platforms: Providing platforms for analysts to annotate data, which is then curated and stored for data scientists.; Software Design Patterns: Understanding and implementing design patterns to build maintainable and scalable data engineering solutions.; Docker: Used for containerizing applications to ensure consistent environments for data pipeline components.; PyTorch: Mentioned as part of Python data manipulation packages, likely for data processing or integration with machine learning workflows."
u17_iIJaFDOi1TxNAAAAAA==,Data Analyst Jobs,"Overview

Iron EagleX (IEX), a wholly owned subsidiary of General Dynamics Information Technology, delivers agile IT and Intelligence solutions. Combining small-team flexibility with global scale, IEX leverages emerging technologies to provide innovative, user-focused solutions that empower organizations and end users to operate smarter, faster, and more securely in dynamic environments.

Responsibilities

Contract Overview:

The Data Technical Support (DTS) contract provides data science professionals to the United States Special Operations Command's (USSOCOM) Intelligence Data Science Team (IDST) and Special Operations Forces Acquisitions, Technology & Logistics (SOF AT&L).

The IDST is a government-led team focused on data analytics efforts within the USSOCOM Directorate of Intelligence (J2) and its subordinate command's intelligence lines of effort. The IDST helps USSOCOM intelligence analysts by turning the Command's data into actionable information. The IDST team may also engage with the USSOCOM Chief Digital and Artificial Intelligence Office (CDAO), Knowledge Management (KM), and other HQ entities.

The DTS contract provides permanently assigned data science professionals to the USSOCOM Headquarters, Theater Special Operations Commands, and Component Commands. Additionally, the DTS contract may provide temporary support (Temporary Duty / deployment) to worldwide Special Operations Joint Task Forces, Combined Joint Special Operations Task Forces, Special Operations Task Forces, and Special Operations Command Forward Elements.

Job Description:

Data Analyst - Data Analysts support the IDST by using technology to mine complex, voluminous, and different varieties of data from various sources and platforms to collect, analyze, and compile data to meet customer needs.

This position is in SOCSOUTH, Homestead, FL.

Job Duties Include (but are not limited to):
• Identify new sources of data and methods to improve data collection, analysis, and reporting
• Collect customer requirements
• Determine technical issues
• Design algorithms and data manipulation capabilities using R, Python, C++, JavaScript, Go, and other known programming languages.
• Build data solutions, tools, and capabilities to enable self-service frameworks for data consumers to monitor and report on data.
• Improve the quality of data use and usability by driving an understanding and adherence to the principles of data quality management including metadata, lineage, and business definitions
• Work collaboratively with Intelligence and Data analysis teams to produce qualitative and quantitative data that support Intelligence products.

Qualifications

Required Skills & Experience:
• Experience providing services similar in required tasks, scope, and complexity.
• Due to US Government Contract Requirements, only US Citizens are eligible for this role.

Education & Certifications:
• Possess a minimum of a bachelor's degree in computer science discipline or equivalent.

Security Clearance:
• Current Top-Secret clearance with SCI eligibility is required

Benefits:
• National health, vision, and dental plans
• 20 days of PTO and 11 paid holidays
• Life Insurance
• Short- and long-term disability plans
• 401(K) retirement plan
• Incentive and recognition programs
• Relocation opportunities

Equal Opportunity Employer / Individuals with Disabilities / Protected Veterans",2025-07-23T00:00:00.000Z,2025-07-25,"['Experience providing services similar in required tasks, scope, and complexity', 'Due to US Government Contract Requirements, only US Citizens are eligible for this role', ""Possess a minimum of a bachelor's degree in computer science discipline or equivalent"", 'Current Top-Secret clearance with SCI eligibility is required']","[""The Data Technical Support (DTS) contract provides data science professionals to the United States Special Operations Command's (USSOCOM) Intelligence Data Science Team (IDST) and Special Operations Forces Acquisitions, Technology & Logistics (SOF AT&L)"", ""The IDST helps USSOCOM intelligence analysts by turning the Command's data into actionable information"", 'The IDST team may also engage with the USSOCOM Chief Digital and Artificial Intelligence Office (CDAO), Knowledge Management (KM), and other HQ entities', 'The DTS contract provides permanently assigned data science professionals to the USSOCOM Headquarters, Theater Special Operations Commands, and Component Commands', 'Additionally, the DTS contract may provide temporary support (Temporary Duty / deployment) to worldwide Special Operations Joint Task Forces, Combined Joint Special Operations Task Forces, Special Operations Task Forces, and Special Operations Command Forward Elements', 'Data Analyst - Data Analysts support the IDST by using technology to mine complex, voluminous, and different varieties of data from various sources and platforms to collect, analyze, and compile data to meet customer needs', 'Identify new sources of data and methods to improve data collection, analysis, and reporting', 'Collect customer requirements', 'Determine technical issues', 'Design algorithms and data manipulation capabilities using R, Python, C++, JavaScript, Go, and other known programming languages', 'Build data solutions, tools, and capabilities to enable self-service frameworks for data consumers to monitor and report on data', 'Improve the quality of data use and usability by driving an understanding and adherence to the principles of data quality management including metadata, lineage, and business definitions', 'Work collaboratively with Intelligence and Data analysis teams to produce qualitative and quantitative data that support Intelligence products']",True,[],,"['Data Mining', 'Data Collection', 'Data Analysis', 'Algorithm Design', 'Data Quality Management', 'Self-Service Data Frameworks', 'Programming Languages']","Data Mining: Used to extract complex and voluminous data from various sources to support intelligence analysis.; Data Collection: Identifying new data sources and improving methods to gather data for analysis and reporting.; Data Analysis: Analyzing collected data to compile actionable intelligence and meet customer needs.; Algorithm Design: Designing algorithms and data manipulation capabilities using programming languages like R, Python, C++, JavaScript, and Go.; Data Quality Management: Ensuring data usability and quality by managing metadata, lineage, and business definitions.; Self-Service Data Frameworks: Building tools and capabilities that enable data consumers to monitor and report on data independently.; Programming Languages: Utilizing languages such as R, Python, C++, JavaScript, and Go for data manipulation and solution development."
ujHBqekAy1MAOLjvAAAAAA==,Data Engineer (Multi-levels Mid-Senior) Jobs,"Overview

Credence is one of the largest privately held technologies services company in the country, repeatedly recognized as a top place to work, and have been on the Inc. 5000 Fastest Growing Private Companies list for the last 12 years. We practice servant leadership and believe that by focusing on the success of our clients, team members, and partners, we all achieve greater success.

At Credence, we support our clients' mission-critical needs, powered by technology. We provide cutting-edge solutions, including AI/ML, enterprise modernization, and advanced intelligence capabilities, to the largest defense and health federal organizations. Through partnership and trust, we increase mission success for warfighters and secure our nation for a better future.

We value innovation, integrity, and continuous learning-and we are committed to investing in the next generation of tech talent.

This is an upcoming opportunity in late 2025 for highly motivated Data Engineer(s) to join our growing team. In this role, you will leverage your hands-on experience with foundational code for data pipelines and data base migrations to design, develop, and implement AI models and machine learning algorithms to support a variety of high-impact projects. This position is ideal for an engineer ready to deepen their expertise in AI/ML and automation, taking on exciting technical challenges at the Mid and Senior levels at multiple locations
Responsibilities include, but are not limited to the duties listed below
• Must have demonstrated experience deploying solutions and production experience with applications
• Experience supporting designing, developing, and deploying machine learning models and AI-driven solutions will be key for the successful candidate in this role.
• Collaborate with cross-functional teams, including data scientists, software engineers, product managers, and client stakeholders to understand, evaluate and deliver AI solutions that meet the requirements.
• Conduct data preparation, feature engineering, model selection, training and optimization to ensure optimal performance from the AI models.
• Design and implement AI solutions using the latest Generative AI technologies and foundation models / large-language models (LLMs).
• Develop automation scripts for MLOps pipelines in cloud using Infrastructure as Code (IaC) for ML model deployment in model inferencing workflows, following best practices of model versioning and CI/CD deployments.
• Manage AI model performance post-deployment and support AI tool development and best practices
• Stay updated on AI & ML trends and write clean, maintainable and well-documented code following industry standards
Education, Requirements and Qualifications
• Bachelor's or Master's degree in Computer Science, Artificial Intelligence, Machine Learning, or a related field.
• US citizenship with the ability to obtain successful DoD TOP SECRET security clearance required.
• Mid-Level Data Scientist 3-7 years of hands-on experience in AI/ML development & deployments of AI projects and/or
• Senior Level Data Scientist 10+ years of hands-on experience in AI/ML development & deployments of AI projects.
• Strong knowledge of AI/ML techniques, including supervised, unsupervised, and reinforcement learning, with expertise in Python, AI/ML key libraries, and basic LLM concepts
• Experience with cloud platforms (AWS, GCP, or Azure) and containerization tools (Docker, Kubernetes).
• Experience using ML frameworks and tools in the cloud, such as Amazon Sagemaker.
• Strong problem-solving skills and the ability to work both independently and as part of a team.
• Excellent communication skills, with the ability to convey complex technical concepts to non-technical stakeholders.
Working Conditions and Physical Requirements

Please join us, as together we build a better world one mission at a time powered by Technology and its People!

Locations:

HQ- McLean VA - Tyson's Corner - Hybrid

Dayton OH, Wright Patterson AFB - On-site

Warner Robbins GA, Robins AFB - On-site

Hampton VA, Langley AFB - On-site

Sumter SC, Shaw AFB - On-site

#LI-Hybrid

#veteranemployment #militaryspouse #milspouse #hireavet #militaryveteran #militaryfriendly #transitioningmilitary #veterans #militarytransition #militaryfamilies #msep #militarytocivilian #military #federalcontractingjobs #defensecontracting #defenseindustryjobs",2025-07-25T02:00:00.000Z,2025-07-25,"[""Bachelor's or Master's degree in Computer Science, Artificial Intelligence, Machine Learning, or a related field"", 'US citizenship with the ability to obtain successful DoD TOP SECRET security clearance required', 'Mid-Level Data Scientist 3-7 years of hands-on experience in AI/ML development & deployments of AI projects and/or', 'Senior Level Data Scientist 10+ years of hands-on experience in AI/ML development & deployments of AI projects', 'Strong knowledge of AI/ML techniques, including supervised, unsupervised, and reinforcement learning, with expertise in Python, AI/ML key libraries, and basic LLM concepts', 'Experience with cloud platforms (AWS, GCP, or Azure) and containerization tools (Docker, Kubernetes)', 'Experience using ML frameworks and tools in the cloud, such as Amazon Sagemaker', 'Strong problem-solving skills and the ability to work both independently and as part of a team', 'Excellent communication skills, with the ability to convey complex technical concepts to non-technical stakeholders']","['In this role, you will leverage your hands-on experience with foundational code for data pipelines and data base migrations to design, develop, and implement AI models and machine learning algorithms to support a variety of high-impact projects', 'This position is ideal for an engineer ready to deepen their expertise in AI/ML and automation, taking on exciting technical challenges at the Mid and Senior levels at multiple locations', 'Must have demonstrated experience deploying solutions and production experience with applications', 'Experience supporting designing, developing, and deploying machine learning models and AI-driven solutions will be key for the successful candidate in this role', 'Collaborate with cross-functional teams, including data scientists, software engineers, product managers, and client stakeholders to understand, evaluate and deliver AI solutions that meet the requirements', 'Conduct data preparation, feature engineering, model selection, training and optimization to ensure optimal performance from the AI models', 'Design and implement AI solutions using the latest Generative AI technologies and foundation models / large-language models (LLMs)', 'Develop automation scripts for MLOps pipelines in cloud using Infrastructure as Code (IaC) for ML model deployment in model inferencing workflows, following best practices of model versioning and CI/CD deployments', 'Manage AI model performance post-deployment and support AI tool development and best practices', 'Stay updated on AI & ML trends and write clean, maintainable and well-documented code following industry standards']",True,"['Generative AI', 'Large Language Models', 'Infrastructure as Code', 'Model Inferencing Workflows', 'CI/CD for AI Models', 'AI Model Performance Management', 'AI/ML Key Libraries']",Generative AI: Designing and implementing AI solutions using the latest generative AI technologies.; Large Language Models: Working with foundation models and large language models (LLMs) to build AI-driven solutions.; Infrastructure as Code: Applying Infrastructure as Code (IaC) to automate deployment of AI/ML models in cloud environments.; Model Inferencing Workflows: Managing AI model inferencing workflows post-deployment to ensure performance and reliability.; CI/CD for AI Models: Implementing continuous integration and continuous deployment pipelines specifically for AI model lifecycle management.; AI Model Performance Management: Monitoring and supporting AI model performance after deployment to maintain effectiveness.; AI/ML Key Libraries: Utilizing specialized AI/ML libraries in Python to develop and deploy AI models.,"['Data Pipelines', 'Database Migrations', 'Machine Learning Models', 'Supervised Learning', 'Unsupervised Learning', 'Reinforcement Learning', 'Feature Engineering', 'Model Selection', 'Model Training and Optimization', 'Python', 'Cloud Platforms', 'Containerization Tools', 'Amazon SageMaker', 'MLOps']","Data Pipelines: Building foundational code for data pipelines to support data flow and processing in AI/ML projects.; Database Migrations: Handling database migrations to ensure data availability and integrity for machine learning model development.; Machine Learning Models: Designing, developing, and deploying machine learning models to support high-impact projects.; Supervised Learning: Applying supervised learning techniques as part of AI/ML model development.; Unsupervised Learning: Utilizing unsupervised learning methods in AI/ML solutions.; Reinforcement Learning: Employing reinforcement learning techniques within AI/ML projects.; Feature Engineering: Conducting feature engineering to improve model performance.; Model Selection: Selecting appropriate machine learning models to optimize AI solution outcomes.; Model Training and Optimization: Training and optimizing machine learning models to ensure optimal performance.; Python: Using Python programming language for AI/ML development and automation.; Cloud Platforms: Leveraging cloud platforms such as AWS, GCP, or Azure for deploying and managing machine learning models.; Containerization Tools: Utilizing Docker and Kubernetes for containerizing and orchestrating AI/ML applications.; Amazon SageMaker: Using Amazon SageMaker as a cloud-based machine learning framework for model development and deployment.; MLOps: Developing automation scripts and pipelines for machine learning operations including model versioning and CI/CD deployments."
5uF80EeGMYCqCMh2AAAAAA==,"Senior Associate, Data Scientist","Senior Associate, Data Scientist

Senior Associate,Data Scientist - US Card Bureau Data Strategy Team

Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making.

As a Data Scientist at Capital One, you'll be part of a team that's leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives.

Team Description

Credit bureau data is at the heart of underwriting decisions at US Card. The Bureau Data Strategy team produces one of the most highly-used datasets in all of Capital One from raw credit bureau data. The team is responsible for generating insights, extracting value from Bureau Data and shaping the future of how credit bureau data is used in underwriting at Capital One. The team also owns the monitoring solution to promptly alert users to potential production errors with these features.

Role Description

In this role, you will:
• Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love
• Leverage a broad stack of technologies - Python, Conda, AWS, H2O, Spark, and more - to reveal the insights hidden within huge volumes of numeric and textual data
• Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation
• Flex your interpersonal skills to translate the complexity of your work into tangible business goals

The Ideal Candidate is:
• Innovative. You continually research and evaluate emerging technologies. You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them.
• Creative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You're not afraid to share a new idea.
• Technical. You're comfortable with open-source languages and are passionate about developing further. You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms.
• Statistically-minded. You've built models, validated them, and backtested them. You know how to interpret a confusion matrix or a ROC curve. You have experience with clustering, classification, sentiment analysis, time series, and deep learning.
• A data guru. ""Big data"" doesn't faze you. You have the skills to retrieve, combine, and analyze data from a variety of sources and structures. You know understanding the data is often the key to great data science.

Basic Qualifications:
• Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:
• A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 2 years of experience performing data analytics
• A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration

Preferred Qualifications:
• Master's Degree in ""STEM"" field (Science, Technology, Engineering, or Mathematics), or PhD in ""STEM"" field (Science, Technology, Engineering, or Mathematics)
• Experience working with PySpark
• At least 2 years' experience in Python, Scala, or R
• At least 2 years' experience with machine learning
• At least 2 years' experience with SQL

Capital One will consider sponsoring a new qualified applicant for employment authorization for this position.

The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.

McLean, VA: $133,000 - $151,800 for Sr Assoc, Data Science

New York, NY: $145,100 - $165,600 for Sr Assoc, Data Science

Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate's offer letter.

This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.

Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at theCapital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.

This role is expected to accept applications for a minimum of 5 business days.

No agencies please. Capital One is an equal opportunity employer (EOE, including disability/vet) committed to non-discrimination in compliance with applicable federal, state, and local laws. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City's Fair Chance Act; Philadelphia's Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",2025-07-17T00:00:00.000Z,2025-07-25,"['You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them', 'You thrive on bringing definition to big, undefined problems', 'You love asking questions and pushing hard to find answers', ""You're comfortable with open-source languages and are passionate about developing further"", 'You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms', 'Statistically-minded', 'You know how to interpret a confusion matrix or a ROC curve', 'You have experience with clustering, classification, sentiment analysis, time series, and deep learning', 'A data guru', 'You have the skills to retrieve, combine, and analyze data from a variety of sources and structures', 'You know understanding the data is often the key to great data science', 'Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:', ""A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 2 years of experience performing data analytics"", ""A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration""]","['The team is responsible for generating insights, extracting value from Bureau Data and shaping the future of how credit bureau data is used in underwriting at Capital One', 'The team also owns the monitoring solution to promptly alert users to potential production errors with these features', 'Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love', 'Leverage a broad stack of technologies - Python, Conda, AWS, H2O, Spark, and more - to reveal the insights hidden within huge volumes of numeric and textual data', 'Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation', 'Flex your interpersonal skills to translate the complexity of your work into tangible business goals', 'You continually research and evaluate emerging technologies', ""You've built models, validated them, and backtested them""]",True,[],,"['Statistical Modeling', 'Relational Databases', 'Python', 'Conda', 'AWS', 'H2O', 'Apache Spark', 'Machine Learning', 'Clustering', 'Classification', 'Sentiment Analysis', 'Time Series Analysis', 'Deep Learning', 'Model Validation and Backtesting', 'Confusion Matrix and ROC Curve Interpretation', 'SQL', 'PySpark']","Statistical Modeling: Used to personalize credit card offers and generate insights from credit bureau data for underwriting decisions.; Relational Databases: Used to store and manage credit bureau data critical for underwriting and data analysis.; Python: A primary programming language used for data analysis, model building, and working with large datasets.; Conda: An environment and package management system used to manage dependencies for data science projects.; AWS: Cloud computing platform leveraged to handle large-scale data processing and storage.; H2O: An open-source machine learning platform used to build and deploy machine learning models.; Apache Spark: Used for big data processing and analytics, including working with PySpark for distributed data processing.; Machine Learning: Applied to build predictive models for underwriting and customer insights, covering all phases from design to implementation.; Clustering: Used as an unsupervised learning technique to identify patterns or groupings in credit bureau data.; Classification: Applied to categorize data points, such as credit risk levels, within underwriting models.; Sentiment Analysis: Used to analyze textual data possibly related to customer feedback or credit bureau textual information.; Time Series Analysis: Used to analyze data points collected or recorded at specific time intervals, relevant for financial data trends.; Deep Learning: Employed for advanced modeling techniques, potentially to improve predictive accuracy on complex data.; Model Validation and Backtesting: Processes to ensure the reliability and accuracy of predictive models before deployment.; Confusion Matrix and ROC Curve Interpretation: Techniques used to evaluate classification model performance.; SQL: Used to query and manipulate structured data stored in relational databases.; PySpark: Python API for Apache Spark used for distributed data processing and analytics."
KfyGieO3W0E2DuJeAAAAAA==,Data Scientist Jobs,"Description
• Supporting to the Combat Plans Division (CPD) of the 616th Operations Center in execution of the 16th Air Force's mission located in San Antonio, Texas
• Using mathematical and statistical expertise, along with natural curiosity to identify statistical trends and anomalies
• While mining, interpreting, and cleaning data, this person will be relied on to ask questions, connect the dots, and uncover hidden opportunities for the customer and subordinate units
• Being part of a team of multi-discipline specialists and planners, the data scientist will coordinate with internal and external customers to mine, analyze, and turn the data into finished planning, intelligence and/or assessment products through various big data analytic methods
• Working closely with operational and all-source intelligence information, and specifically with OSINT

FILLING THIS POSITION IS CONTINGENT UPON AWARD

#LI-DG1

Requirements
• Knowledge of software for data analysis
• Experience in military writing and graphics display tools
• Ability to work in a team of diverse specialties
• Briefing and oration skills
• Knowledge of major geopolitical issues and major areas of responsibility (AOR)
• Experience data mining from multiple sources
• Understanding of Open-Source Intelligence (OSINT) and its operational application

Desired Skills
• Familiarity with Intelligence support to air and/or cyber tasking order (ATO/CTO) cycle and construction; ability to read and understand these formats
• Prior experience working in a NAF or MAJCOM air operations center, multinational Combined AOC, joint/other Service equivalent
• Working knowledge of Joint and USAF doctrine, specifically cyber and ISR employment
• Diverse understanding of cultures, languages outside of the U.S.
• Basic understanding of programming languages, such as Python

Clearance Information

SRC IS A CONTRACTOR FOR THE U.S. GOVERNMENT, THIS POSITION WILL REQUIRE U.S. CITIZENSHIP AS WELL AS, A U.S. GOVERNMENT SECURITY CLEARANCE AT THE TOP SECRET / SCI LEVEL

Travel Requirements
• Required, 10%.

About Us

Scientific Research Corporation is an advanced information technology and engineering company that provides innovative products and services to government and private industry, as well as independent institutions. At the core of our capabilities is a seasoned team of highly skilled engineers and scientists with multidisciplinary backgrounds. This team is challenged daily to provide cutting edge technology solutions to our clients.

SRC offers a generous benefit package, including medical, dental, and vision plans, 401(k) with a company match, life insurance, vacation and sick paid time off accruals starting at 10 days of vacation and 5 days of sick leave annually, 11 paid holidays, tuition reimbursement, and a work environment that encourages excellence and more. For positions requiring a security clearance, selected applicants will be subject to a government security investigation and must meet eligibility requirements for access to classified information.

EEO

Scientific Research Corporation is an equal opportunity employer that does not discriminate in employment.

All qualified applicants will receive consideration for employment without regard to their race, color, religion, sex, age, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other protected characteristic under federal, state or local law.

Scientific Research Corporation endeavors to make www.scires.com accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact jobs@scires.com for assistance. This contact information is for accommodation requests only and cannot be used to inquire about the status of applications.",2025-07-25T16:00:00.000Z,2025-07-25,"['Knowledge of software for data analysis', 'Experience in military writing and graphics display tools', 'Ability to work in a team of diverse specialties', 'Briefing and oration skills', 'Knowledge of major geopolitical issues and major areas of responsibility (AOR)', 'Experience data mining from multiple sources', 'Understanding of Open-Source Intelligence (OSINT) and its operational application', 'CITIZENSHIP AS WELL AS, A U.S. GOVERNMENT SECURITY CLEARANCE AT THE TOP SECRET / SCI LEVEL', 'Required, 10%']","[""Supporting to the Combat Plans Division (CPD) of the 616th Operations Center in execution of the 16th Air Force's mission located in San Antonio, Texas"", 'Using mathematical and statistical expertise, along with natural curiosity to identify statistical trends and anomalies', 'While mining, interpreting, and cleaning data, this person will be relied on to ask questions, connect the dots, and uncover hidden opportunities for the customer and subordinate units', 'Being part of a team of multi-discipline specialists and planners, the data scientist will coordinate with internal and external customers to mine, analyze, and turn the data into finished planning, intelligence and/or assessment products through various big data analytic methods', 'Working closely with operational and all-source intelligence information, and specifically with OSINT']",True,[],,"['Statistical Analysis', 'Data Mining', 'Data Cleaning', 'Big Data Analytics', 'Open-Source Intelligence (OSINT)', 'Python Programming']","Statistical Analysis: Used to identify statistical trends and anomalies in data to support intelligence and operational planning.; Data Mining: Extracting and interpreting data from multiple sources to uncover hidden opportunities and insights for customers and subordinate units.; Data Cleaning: Processing and preparing data to ensure accuracy and usability for analysis and intelligence products.; Big Data Analytics: Applying advanced analytic methods to large and complex datasets to produce finished planning, intelligence, and assessment products.; Open-Source Intelligence (OSINT): Utilizing publicly available information sources as part of intelligence analysis and operational support.; Python Programming: Basic programming skills used for data analysis and possibly automating data processing tasks."
IkHCXIwwAbWdvnuvAAAAAA==,Data Analyst/Scientist (ES4),"Epsilon C5I (, a division of Epsilon Systems Solutions, is a 100 percent employee-owned company founded in 1998 with more than 20 locations serving the Department of Defense, Department of Energy, Department of Homeland Security, non-profit and commercial customers. The Dayton division has recently been named as one of only five prime awardees for the 10-year, $4.7 billion NOVASTAR contract supporting the National Air and Space Intelligence Center (NASIC), WPAFB, Ohio.

The Dayton division is currently searching for a Data Analyst/Scientist (ES4). Candidate will provide in-depth analytical support for NASIC focusing on long-term trends and campaign planning. Additionally, the candidate shall leverage Python, R, SQL, and/or MATLAB to analyze large datasets, employing statistical modeling, data visualization, and forecasting. A key part of your role involves automating workflows with tools like MIST, Excel, Pandas, and NumPy, and developing scripts for efficient data handling. Your daily work will involve creating reports, databases, and interactive dashboards to inform operational decisions and capability assessments.

Candidates must be able to work independently and as part of a technical team and have effective oral and written communication skills. Successful candidates will have strong problem solving and critical thinking skills.

Most of the work supports the Scientific and Technical Intelligence community. This challenging position requires a diverse set of technical and task management skills and allows for the opportunity to contribute immediately to important, meaningful work. Desire an active TS/SCI clearance. Work is performed onsite in the Dayton, Ohio area.

Duties and Responsibilities:

Needs to be able to collect, clean, preprocess, and consolidate unfiltered, unstructured datasets from data feeds such as MIST/FADE & thresher

Familiarity with csv, json, txt, APIs, Python, R, SQL, and MATLAB.

Experience with Application Programming Interfaces (APIs) and develop scripts or lightweight applications to streamline data extraction, transformation, and loading (ETL) processes.

Background knowledge on Unmanned Aerial Systems (UAS) (Bonus)

Background knowledge or experience primarily in INDOPACOM, but also EUCOM and CENTCOM AORs.

Provide in-depth analytical support for long-term trending assessments and production focused on Unmanned Aerial Systems (UAS) scenario-based campaign planning and execution.

Creating and executing data-driven analyses using advanced computational methods to identify trends, patterns, and strategic implications in UAS activity.

Utilizing data science tools and programming languages- including but not limited to Python, R, SQL, and MATLAB-to collect, process, and analyze large structured and unstructured datasets. To include statistical modeling, data visualization, geospatial analysis, and time-series forecasting techniques.

Integrate and automate workflows utilizing IC tools such as the Multi-Intelligence Spatial Temporal Tool (MIST), and create custom analytics solutions leveraging Excel, Pandas, NumPy, and other data manipulation libraries.

Required Qualifications:

Bachelor's degree in Electrical Engineering, Physical Sciences, Computer Engineering, Data Science, Computer Science, Software Engineering, or other closely related fields.

10+ years of relevant experience in engineering, science, or mathematics.

Applicant must have an active DoD Top Secret Security Clearance, with SCI eligibility.

Applicant must reside within commuting distance to WPAFB, OH or willing to relocate to the area.

Technical leadership experience.

Must have strong written communication skills, possess good people skills, demonstrate strong attention to detail and have the desire to work on a highly focused technical team of engineers, analysts, and scientists.

Possess effective communication and be able to collaborate with Customers, and cross-functional teams, document technical processes, and present solutions to stakeholders.

Must be able to prioritize tasks effectively, manage deadlines, and handle multiple projects simultaneously.

Excellent organizational skills and keen attention to detail, with the ability to multitask and prioritize effectively in a fast-paced, dynamic work environment.

Enthusiasm for learning and adapting to new technologies and methodologies.

Preferred Qualifications:

All Source intelligence experience

Demonstrated ability to drive technological innovation within an organization.

Recognized expert technologist with 10+ year experience in analytic solution development related to signal processing, data science, machine learning, or other similar technology.

Familiarity with AI/ML models to process and analyze large datasets.

Previous IC or DoD program/project work experience.

ADA Notations:
• Regular communication (hearing/speaking).
• Noise conditions range from very quiet to very noisy.
• Prolonged use of computer (typing/keyboarding).
• Frequently required to sit for long periods of time, stand, and walk.
• Ability to travel by car, air or other means of transportation, if required.

Epsilon Systems Solutions, Inc. is an equal opportunity employer. Qualified candidates will be considered without regard to legally protected characteristics.",2025-06-26T00:00:00.000Z,2025-07-25,"['Candidates must be able to work independently and as part of a technical team and have effective oral and written communication skills', 'Successful candidates will have strong problem solving and critical thinking skills', 'Most of the work supports the Scientific and Technical Intelligence community', 'This challenging position requires a diverse set of technical and task management skills and allows for the opportunity to contribute immediately to important, meaningful work', 'Desire an active TS/SCI clearance', 'Familiarity with csv, json, txt, APIs, Python, R, SQL, and MATLAB', 'Experience with Application Programming Interfaces (APIs) and develop scripts or lightweight applications to streamline data extraction, transformation, and loading (ETL) processes', 'Background knowledge on Unmanned Aerial Systems (UAS) (Bonus)', 'Background knowledge or experience primarily in INDOPACOM, but also EUCOM and CENTCOM AORs', ""Bachelor's degree in Electrical Engineering, Physical Sciences, Computer Engineering, Data Science, Computer Science, Software Engineering, or other closely related fields"", '10+ years of relevant experience in engineering, science, or mathematics', 'Applicant must have an active DoD Top Secret Security Clearance, with SCI eligibility', 'Applicant must reside within commuting distance to WPAFB, OH or willing to relocate to the area', 'Technical leadership experience', 'Must have strong written communication skills, possess good people skills, demonstrate strong attention to detail and have the desire to work on a highly focused technical team of engineers, analysts, and scientists', 'Possess effective communication and be able to collaborate with Customers, and cross-functional teams, document technical processes, and present solutions to stakeholders', 'Must be able to prioritize tasks effectively, manage deadlines, and handle multiple projects simultaneously', 'Excellent organizational skills and keen attention to detail, with the ability to multitask and prioritize effectively in a fast-paced, dynamic work environment', 'Enthusiasm for learning and adapting to new technologies and methodologies', 'All Source intelligence experience', 'Demonstrated ability to drive technological innovation within an organization', 'Recognized expert technologist with 10+ year experience in analytic solution development related to signal processing, data science, machine learning, or other similar technology', 'Familiarity with AI/ML models to process and analyze large datasets', 'Previous IC or DoD program/project work experience', 'Prolonged use of computer (typing/keyboarding)', 'Frequently required to sit for long periods of time, stand, and walk', 'Ability to travel by car, air or other means of transportation, if required']","['Candidate will provide in-depth analytical support for NASIC focusing on long-term trends and campaign planning', 'Additionally, the candidate shall leverage Python, R, SQL, and/or MATLAB to analyze large datasets, employing statistical modeling, data visualization, and forecasting', 'A key part of your role involves automating workflows with tools like MIST, Excel, Pandas, and NumPy, and developing scripts for efficient data handling', 'Your daily work will involve creating reports, databases, and interactive dashboards to inform operational decisions and capability assessments', 'Needs to be able to collect, clean, preprocess, and consolidate unfiltered, unstructured datasets from data feeds such as MIST/FADE & thresher', 'Provide in-depth analytical support for long-term trending assessments and production focused on Unmanned Aerial Systems (UAS) scenario-based campaign planning and execution', 'Creating and executing data-driven analyses using advanced computational methods to identify trends, patterns, and strategic implications in UAS activity', 'Utilizing data science tools and programming languages- including but not limited to Python, R, SQL, and MATLAB-to collect, process, and analyze large structured and unstructured datasets', 'To include statistical modeling, data visualization, geospatial analysis, and time-series forecasting techniques', 'Integrate and automate workflows utilizing IC tools such as the Multi-Intelligence Spatial Temporal Tool (MIST), and create custom analytics solutions leveraging Excel, Pandas, NumPy, and other data manipulation libraries']",True,[],,"['Python', 'R', 'SQL', 'MATLAB', 'Statistical Modeling', 'Data Visualization', 'Time-Series Forecasting', 'Pandas', 'NumPy', 'Excel', 'ETL (Extract, Transform, Load)', 'APIs', 'Data Cleaning and Preprocessing', 'Geospatial Analysis', 'Multi-Intelligence Spatial Temporal Tool (MIST)', 'Data Pipelines Automation', 'Machine Learning']","Python: Used as a primary programming language for data analysis, scripting, and automation of workflows.; R: Employed for statistical modeling, data visualization, and advanced data analysis tasks.; SQL: Utilized for querying, managing, and consolidating large structured datasets.; MATLAB: Applied for numerical computing, statistical modeling, and data analysis.; Statistical Modeling: Used to analyze large datasets and identify trends and patterns relevant to long-term assessments.; Data Visualization: Creating visual representations of data to inform operational decisions and capability assessments.; Time-Series Forecasting: Applied to predict trends and patterns over time, particularly for campaign planning.; Pandas: A Python library used for data manipulation and analysis, especially for handling tabular data.; NumPy: Used for numerical operations and efficient handling of large datasets in Python.; Excel: Utilized for data manipulation, reporting, and creating custom analytics solutions.; ETL (Extract, Transform, Load): Processes automated via scripting to streamline data extraction, transformation, and loading from various sources.; APIs: Used to extract and integrate data from multiple sources for analysis.; Data Cleaning and Preprocessing: Essential for consolidating unfiltered and unstructured datasets to prepare for analysis.; Geospatial Analysis: Applied to analyze spatial data relevant to Unmanned Aerial Systems (UAS) activities.; Multi-Intelligence Spatial Temporal Tool (MIST): An IC tool integrated into workflows for spatial-temporal data analysis and automation.; Data Pipelines Automation: Developing scripts and workflows to automate data handling and processing tasks.; Machine Learning: Familiarity with AI/ML models to process and analyze large datasets, supporting analytic solution development."
B20-wXs7f5F0FLLRAAAAAA==,Data Scientist Jobs,"ManTech seeks a motivated, career and customer oriented Senior Data Scientist SME to join our team in Ashburn, Virginia. This position is onsite two days a week.

Each day U.S. Customs and Border Protection (CBP) oversees the massive flow of people, capital, and products that enter and depart the United States via air, land, sea, and cyberspace. The volume and complexity of both physical and virtual border crossings require the application of solutions to promote efficient trade and travel.

Responsibilities include but are not limited to:
• Lead and perform hands-on data and threat/intel analysis leading to development of analytics solutions (e.g. predictive models, visual analytics reports), to support CBP users conduct law enforcement mission critical activities.
• Demonstrate proficiency in extracting, cleaning, and transforming CBP transactional and associated data sets within an identified problem space to build predictive models as well as develop appropriate supporting documentation.
• Leverage knowledge of a variety of statistical and machine learning techniques to develop, evaluate, and deploy new predictive analytical models that directly inform mission decisions.
• Utilize and explore variety of statistical/modeling tools and languages to compare and assess best performing Machine Learning results.
• Execute projects including those intended to identify patterns and/or anomalies in large datasets; perform automated text/data classification and categorization as well as entity recognition, resolution and extraction; and named entity matching.

Minimum Qualifications:
• HS Diploma/GED and 20+ years or AS/AA and 18+ years or BS/BA and 12+ years or MS/MA/MBA and 9+ years or PhD/Doctorate and 7+ years
• Experience in full-lifecycle development, deployment and monitoring of machine learning models to multiple platforms (on-prem/cloud etc.) and applying advanced analytics solutions to solve complex business problems
• Experience with programming languages including R, Python, Scala, Java, SQL/Spark
• Experience constructing and executing queries to extract data in support of EDA and model development
• Experience with evaluating, implementing and optimizing AI/ML algorithms to address constraints with large and imbalanced datasets.
• Experience with entity resolution (e.g., record linking, named entity matching, deduplication/ disambiguation)
• Experience with unsupervised and supervised machine learning techniques and methods
• Experience/Proficiency in conducting development and integration activities to deploy, assess and update AI/ML models into applications for end-user use and evaluation.

Preferred Qualifications:
• Proficiency with Unsupervised Machine Learning methods including Cluster Analysis (e.g., K-means, K-nearest Neighbor, Hierarchical, Deep Belief Networks, Principal Component Analysis), Segmentation, etc.
• Proficiency with Auto ML tools and platforms, such as AWS Sagemaker, DataRobot or DataBricks
• Experience with big data technologies (e.g., Hadoop, HIVE, HDFS, HBase, MapReduce, Spark, Kafka, Sqoop)
• Master's Degree in mathematics, statistics, computer science/engineering, or other related technical fields with equivalent practical experience

Clearance Requirements:
• Must be a US Citizen and able to obtain and maintain a U.S. Customs and Border Protection (CBP) suitability.
• Must be eligible to obtain and maintain a Top Secret

Physical Requirements:
• Must be able to be in a stationary position more than 50% of the time.
• Must be able to communicate, converse, and exchange information with peers and senior personnel.
• Constantly operates a computer and other office productivity machinery, such as a computer.",,2025-07-25,,,True,[],,"['Predictive Modeling', 'Data Extraction and Transformation', 'Statistical and Machine Learning Techniques', 'Exploratory Data Analysis (EDA)', 'Entity Resolution', 'Supervised and Unsupervised Learning', 'Cluster Analysis', 'AutoML Platforms', 'Big Data Technologies', 'Programming Languages for Data Science', 'Machine Learning Model Lifecycle Management', 'Text/Data Classification and Categorization']","Predictive Modeling: Used to develop analytics solutions that support law enforcement mission-critical activities by forecasting outcomes based on CBP transactional data.; Data Extraction and Transformation: Involves extracting, cleaning, and transforming CBP transactional and associated datasets to prepare data for model development.; Statistical and Machine Learning Techniques: Applied to develop, evaluate, and deploy predictive analytical models that inform mission decisions.; Exploratory Data Analysis (EDA): Performed through constructing and executing queries to extract data supporting model development and understanding data patterns.; Entity Resolution: Techniques such as record linking, named entity matching, and deduplication used to identify and merge related data records.; Supervised and Unsupervised Learning: Utilized to identify patterns and anomalies in large datasets, including classification and clustering methods.; Cluster Analysis: Includes methods like K-means, K-nearest Neighbor, Hierarchical clustering, and Principal Component Analysis for segmentation and pattern discovery.; AutoML Platforms: Tools such as AWS Sagemaker, DataRobot, and DataBricks used to automate machine learning model development and deployment.; Big Data Technologies: Technologies like Hadoop, HIVE, HDFS, HBase, MapReduce, Spark, Kafka, and Sqoop used to handle and process large-scale datasets.; Programming Languages for Data Science: Languages including R, Python, Scala, Java, and SQL/Spark used for data manipulation, analysis, and model development.; Machine Learning Model Lifecycle Management: Experience in full lifecycle development, deployment, and monitoring of machine learning models across platforms.; Text/Data Classification and Categorization: Automated methods applied to classify and categorize text and data for threat and intelligence analysis."
GUK-1LrCOzXGi2q7AAAAAA==,Sr Data Scientist,"Job#: 2080195

Job Description:

Job Title: Sr. Data Scientist

Job Location: Columbus, OH (Onsite)

Pay Range: $56/hr-$66/hr

Contract Length: 3 Months (Contract-to-hire)

JOB DESCRIPTION

Job Title

Senior Data Scientist

Overview:

Our Enterprise Data and Analytics team is growing, and were looking for an outstanding Senior Data Scientist to join our team. In this role, you will leverage machine learning, segmentation, and statistical inference on huge data sets to improve how we understand our customers and the communities we serve. We need data and analytics to meet our goals.

As we advance our data science and analytics capabilities, we want experts in modeling complex business problems and discovering business insights using statistical, algorithmic, mining, and visualization techniques. The Senior Data Scientist contributes to building and developing the organization's data infrastructure and supports the senior leadership with insights, management reports, and analysis for decision-making processes.

Responsibilities:

Performs advanced analytics methods to extract value from business data

Performs large-scale experimentation and build data-driven models to answer business questions

Conducts research on cutting-edge techniques and tools in machine learning/deep learning/artificial intelligence

Determines requirements that will be used to train and evolve deep learning models and algorithms

Articulates a vision and roadmap for the exploitation of data as a valued corporate asset

Influences product teams through presentation of data-based recommendations

Evangelizes best practices to analytics and products teams

Owns the entire model development process, from identifying the business requirements, data sourcing, model fitting, presenting results, and production scoring

Skills:

Up-to-date knowledge of machine learning and data analytics tools and techniques

Strong knowledge in predictive modeling methodology

Experienced at leveraging both structured and unstructured data sources

Willingness and ability to learn new technologies on the job

Demonstrated ability to communicate complex results to technical and non-technical audiences

Demonstrated ability to work effectively in teams as well as independently across multiple tasks while meeting aggressive timelines

Strategic, intellectually curious thinker with focus on outcomes

Professional image with the ability to form relationships across functions

Strong experience with R/RStudio, Python, SAS, SQL, NoSQL
• Strong experience with Cloud Machine Learning technologies (e.g., AWS Sagemaker)
• Strong experience with machine learning environments (e.g., TensorFlow, scikit-learn, caret)

Strong understanding of statistical methods and skills such as Bayesian Networks Inference, linear and non-linear regression, hierarchical, mixed models/multi-level modeling

Financial Services background preferred

Experience:

1-3 years work and/or educational experience in machine learning or cloud computing, experience using statistics and machine learning to solve complex business problems, experience conducting statistical analysis with advanced statistical software, experience scripting languages, and packages, experience building and deploying predictive models, experience web scraping, and scalable data pipelines and experience with big data analysis tools and techniques.

Education:
• Master's degree in computer science, statistics, economics or related fields

EEO Employer

Apex Systems is an equal opportunity employer. We do not discriminate or allow discrimination on the basis of race, color, religion, creed, sex (including pregnancy, childbirth, breastfeeding, or related medical conditions), age, sexual orientation, gender identity, national origin, ancestry, citizenship, genetic information, registered domestic partner status, marital status, disability, status as a crime victim, protected veteran status, political affiliation, union membership, or any other characteristic protected by law. Apex will consider qualified applicants with criminal histories in a manner consistent with the requirements of applicable law. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation in using our website for a search or application, please contact our Employee Services Department at or .

Apex Systems is a world-class IT services company that serves thousands of clients across the globe. When you join Apex, you become part of a team that values innovation, collaboration, and continuous learning. We offer quality career resources, training, certifications, development opportunities, and a comprehensive benefits package. Our commitment to excellence is reflected in many awards, including ClearlyRated's Best of Staffing in Talent Satisfaction in the United States and Great Place to Work in the United Kingdom and Mexico.

Apex Benefits Overview: Apex offers a range of supplemental benefits, including medical, dental, vision, life, disability, and other insurance plans that offer an optional layer of financial protection. We offer an ESPP (employee stock purchase program) and a 401K program which allows you to contribute typically within 30 days of starting, with a company match after 12 months of tenure. Apex also offers a HSA (Health Savings Account on the HDHP plan), a SupportLinc Employee Assistance Program (EAP) with up to 8 free counseling sessions, a corporate discount savings program and other discounts. In terms of professional development, Apex hosts an on-demand training program, provides access to certification prep and a library of technical and leadership courses/books/seminars once you have 6+ months of tenure, and certification discounts and other perks to associations that include CompTIA and IIBA. Apex has a dedicated customer service team for our Consultants that can address questions around benefits and other resources, as well as a certified Career Coach. You can access a full list of our benefits, programs, support teams and resources within our 'Welcome Packet' as well, which an Apex team member can provide.",,2025-07-25,,,True,[],,"['Machine Learning', 'Statistical Inference', 'Segmentation', 'Predictive Modeling', 'Bayesian Networks', 'Regression Models', 'Hierarchical and Mixed Models', 'Data Pipelines', 'Web Scraping', 'Big Data Analysis Tools', 'R / RStudio', 'Python', 'SAS', 'SQL', 'NoSQL', 'Cloud Machine Learning Platforms', 'TensorFlow', 'Scikit-learn', 'Caret']","Machine Learning: Used to build predictive models and extract value from large business datasets to solve complex problems.; Statistical Inference: Applied to analyze data and derive insights for decision-making and business understanding.; Segmentation: Used to categorize customers or data points to improve understanding of customer groups and communities.; Predictive Modeling: Employed to forecast outcomes and support business decisions using historical data.; Bayesian Networks: Utilized for probabilistic modeling and inference within complex data relationships.; Regression Models: Applied linear and non-linear regression techniques to model relationships between variables.; Hierarchical and Mixed Models: Used multi-level modeling approaches to analyze data with nested or grouped structures.; Data Pipelines: Built scalable pipelines to process and prepare data for analysis and modeling.; Web Scraping: Collected unstructured data from web sources to augment datasets for analysis.; Big Data Analysis Tools: Leveraged tools and techniques to handle and analyze large-scale datasets.; R / RStudio: Used for statistical computing, data analysis, and visualization.; Python: Employed for scripting, data manipulation, and building machine learning models.; SAS: Utilized for advanced statistical analysis and data management.; SQL: Used to query and manage structured data in relational databases.; NoSQL: Applied to manage and query unstructured or semi-structured data.; Cloud Machine Learning Platforms: Used cloud services like AWS SageMaker to develop, train, and deploy machine learning models.; TensorFlow: Applied as a machine learning environment for building and training models.; Scikit-learn: Used as a machine learning library for model development and evaluation.; Caret: Utilized as an R package for streamlining the model training process."
PVL34lmAQd7hYR1QAAAAAA==,Senior Data Analyst Jobs,"Description

Data Analyst (Huntsville Alabama)

At B&A, we foster and embrace a distinct set of values that we live by and instill in all aspects of our organization: dedication, commitment, partnership, trust, and recognition. We have incorporated these values into successful delivery for our customers since 1988. B&A believes in ensuring its employees feel deeply connected to B&A, recognizing successes and hard work, and providing continuous opportunities to learn and grow. Our people are entrepreneurial thinkers that combine mindset, vision, and experience to drive value - not only to us as an organization, but to the clients we support. We promote a collaborative culture with our clients, and with each other, as one team working towards a common vision. We'd love for you to join our team!

Job Summary

B&A is looking for a Data Analyst to join a contract with a federal government client in support of an important mission with an Army project his position requires employees to be located in the Huntsville, AL area in order to report to work on-site at Redstone.

Responsibilities
• Provide highly complex data mining, statistical analysis, trend analysis, and causal analysis.
• Perform as a technical lead responsible for monitoring and providing monthly contract reports and deliverables.
• Responsible for integrating multiple disciplines in an operations research team and translating applicable methods into language and application understandable by operational managers throughout the organization.
• Review and provide quality control methods on products.
• Prepare and update training materials to ensure newly assigned personnel gain an understanding of key analytic tools, procedures, and methodologies used.
• Take structured and unstructured data and distill the information into a cohesive analytical product for a contracting functional business area audience.
• Support pattern analysis methods to formulate recommendations to operational managers based upon exploiting patterns in the past, current, and anticipated operational environment.

Education and Experience
• 8+ years in a technical field
• BA/BS in a relevant field is required.

Required Skills
• Must have a high proficiency in Power BI and have held a previous position as a Power BI Consultant.
• Have experience advising senior DoD decision makers on methodologies, results, and conclusions from applied operations research. The primary tools used for research services include, but are not limited to, Logistics Management Program, Vantage, Virtual Contracting Enterprise, General Fund Enterprise Business System (GFEBS), SAP Business Objects/Web Intelligence Reports, Microsoft SharePoint, Army-specific contract writing systems (Procurement Desktop Defense (PD2) and Procurement Automated Data and Document System (PADDS)), and various Government and Commercial business process automation systems.
• Personnel should have strong data manipulation and problem-solving skills.
• Must have strong technical skills in areas such as statistics, programming languages like R or Python, SQL (Structured Query Language), data visualization, and data cleaning and preparation
• Have good communication skills and problem-solving ability.

Security Clearance
• Active Secret clearance is required.

More About B&A:

Notable Clients
B&A has grown to be a company that is trusted by our clients for exceptional service, innovative solutions, and inspired employees. Our service extends through federal, state, and local Government, the private sector, and higher education. Some of our notable clients include Department of Homeland Security, U.S. Customs and Border Protection, U.S. Senate, U.S. Courts, U.S. Census Bureau, U.S. Navy, and more.

Benefits and Programs

B&A is proud to offer three robust individual and family medical plans to full time employees, including a Health Savings Account (HSA) option as well as two tiers of dental coverage, vision, life & AD&D, disability, accident, hospital indemnity, and critical illness insurance. In addition to these benefits, B&A employees enjoy paid time off, B&A sponsored trainings and certifications, pet insurance benefits, commuter transit benefits and a free subscription to a virtual exercise platform (NEOU). B&A's 401(k) plan is available to all employees and includes a company matching contribution.

B&A has launched several programs to focus on employee engagement, wellness, and assistance. These include:
• The B&A Cares program: 30/60/90-day wellness check ins, personal development, financial management, and stress management seminars, and more
• A formal mentorship program
• Job shadowing and cross training opportunities
• Brand Ambassador program
• Employee Assistance Program (EAP) - Access to various support resources to include counseling, legal guidance, financial planning, and more
• Monthly teambuilding events
• B&A Annual Wellness Challenges: #StepWithB&A, #WalkDuringLunchWithB&A, #VolunteeringWithB&A, #ExerciseDuringLunchWithB&A, and more

At B&A, we place significant importance on improving the communities and lives of citizens across the nation through our involvement, technology expertise, and employees. B&A puts an emphasis on charitable efforts in the Northern Virginia area, including Capital Area Food Bank pantry drives, book donations, Hope for Henry Foundation events, and many more. In recognition of all these efforts, B&A has been named a Companies as Responsive Employers (CARE) award recipient by Northern Virginia Family Services and nominated by the Northern Virginia Chamber of Commerce for Outstanding Corporate Citizenship Award.

EEO

B&A provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, disability, genetic information, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state and local laws. B&A complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities. This policy covers conduct occurring at B&A's offices, and other workplaces (including client sites) and all other locations where B&A is providing services, and to all work-related activities.

B&A participates in e-Verify. We provide the Social Security Administration (SSA) and, if necessary, the Department of Homeland Security (DHS) with information from each new employee's I-9 Form to confirm work authorization.",,2025-07-25,,,True,[],,"['Data Mining', 'Statistical Analysis', 'Trend Analysis', 'Causal Analysis', 'Operations Research Methods', 'Pattern Analysis', 'Power BI', 'Logistics Management Program', 'Vantage', 'Virtual Contracting Enterprise', 'General Fund Enterprise Business System (GFEBS)', 'SAP Business Objects/Web Intelligence Reports', 'Microsoft SharePoint', 'Procurement Desktop Defense (PD2)', 'Procurement Automated Data and Document System (PADDS)', 'Data Manipulation', 'Programming with R', 'Programming with Python', 'SQL', 'Data Visualization', 'Data Cleaning and Preparation']","Data Mining: Used to extract complex patterns and insights from large datasets to support the Army project mission.; Statistical Analysis: Applied to analyze trends and causal relationships in operational data for decision-making.; Trend Analysis: Performed to identify and interpret patterns over time relevant to operational environments.; Causal Analysis: Used to determine cause-effect relationships within operational data to inform recommendations.; Operations Research Methods: Integrated into analytics to support complex problem-solving and decision-making for DoD clients.; Pattern Analysis: Employed to detect meaningful patterns in structured and unstructured data for operational insights.; Power BI: Primary data visualization and reporting tool used to create dashboards and monthly contract reports.; Logistics Management Program: Used as a domain-specific tool for research and analysis in logistics and operations.; Vantage: Applied as a tool for data analysis and reporting within the federal government context.; Virtual Contracting Enterprise: Utilized for managing contracting data and supporting analytics in procurement processes.; General Fund Enterprise Business System (GFEBS): Used for financial and business data analysis in government operations.; SAP Business Objects/Web Intelligence Reports: Employed for business intelligence reporting and data visualization.; Microsoft SharePoint: Used for collaboration and document management related to data projects.; Procurement Desktop Defense (PD2): Applied as a contract writing system supporting data analysis in procurement.; Procurement Automated Data and Document System (PADDS): Used for managing procurement data and supporting analytics.; Data Manipulation: Critical skill for cleaning, transforming, and preparing data for analysis.; Programming with R: Used for statistical computing and advanced data analysis.; Programming with Python: Applied for data cleaning, analysis, and scripting within the analytics workflow.; SQL: Used to query and manage structured data from relational databases.; Data Visualization: Essential for communicating analytical results to stakeholders through visual formats.; Data Cleaning and Preparation: Performed to ensure data quality and readiness for analysis and reporting."
yI7QAjplPR6bzEDNAAAAAA==,Data Analyst - Senior Jobs,"Data Analyst - Senior

Job Category: Information Technology

Time Type: Full time

Minimum Clearance Required to Start: Secret

Employee Type: Regular

Percentage of Travel Required: Up to 10%

Type of Travel: Local
• * *

CACI is seeking an experienced Data A nalyst to support our customer, U.S. Southern Command (USSOUTHCOM), in Doral, Florida. This position is contingent upon award of the USSOUTHCOM Cyber Information Technology Enterprise Services (SCITES).

Key Responsibilities

Data Analyst S enior :
• Ability to partner with USSOUTHCOM to understand their questions and needs and then dig into their data-rich environments to find the pieces of their information puzzle
• P rovide a deep understanding of data and what the information means and how it can be used to make an impact helping USSOUTHCOM acquire cutting-edge capabilities
• Share your data analytics expertise with team members to support client and stakeholder relationships
• Research, develop, and test data methodologies, and generate cross-functional solutions through collection and analysis of data sets
• Lead impactful work and guide decision-making across multiple organizations
• Apply skills and analytical expertise by simplifying technical requirements and trends, based on audience
• Present data findings and recommendations to clients and stakeholders using your knowledge of databases, scripting languages, and Microsoft Office Suite
• Establish quantitative and qualitative metrics and key performance indicators to drive technical outcomes
• Apply data visualization through different formats

Required Skills :
• Batchelor's Degree in STEM and 5 years of experience
• DoD Secret security clearance with ability to obtain Top Secret
• Grow your communication and technical skills by merging data to create data-centric solutions

-
________________________________________________________________________________________

What You Can Expect:

A culture of integrity.

At CACI, we place character and innovation at the center of everything we do. As a valued team member, you'll be part of a high-performing group dedicated to our customer's missions and driven by a higher purpose - to ensure the safety of our nation.

An environment of trust.

CACI values the unique contributions that every employee brings to our company and our customers - every day. You'll have the autonomy to take the time you need through a unique flexible time off benefit and have access to robust learning resources to make your ambitions a reality.

A focus on continuous growth.

Together, we will advance our nation's most critical missions, build on our lengthy track record of business success, and find opportunities to break new ground - in your career and in our legacy.

Your potential is limitless. So is ours.

Learn more about CACI here.

________________________________________________________________________________________

Pay Range: There are a host of factors that can influence final salary including, but not limited to, geographic location, Federal Government contract labor categories and contract wage rates, relevant prior work experience, specific skills and competencies, education, and certifications. Our employees value the flexibility at CACI that allows them to balance quality work and their personal lives. We offer competitive compensation, benefits and learning and development opportunities. Our broad and competitive mix of benefits options is designed to support and protect employees and their families. At CACI, you will receive comprehensive benefits such as; healthcare, wellness, financial, retirement, family support, continuing education, and time off benefits. Learn more here .

The proposed salary range for this position is:
$90,300-$189,600

CACI is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, age, national origin, disability, status as a protected veteran, or any other protected characteristic.",,2025-07-25,,,True,[],,"['Data Analysis', 'Data Methodologies', 'Data Visualization', 'Databases', 'Scripting Languages', 'Key Performance Indicators', 'Microsoft Office Suite']","Data Analysis: The role involves analyzing data-rich environments to extract meaningful insights and support decision-making for USSOUTHCOM.; Data Methodologies: Researching, developing, and testing data methodologies to generate cross-functional solutions through data collection and analysis.; Data Visualization: Applying data visualization techniques in various formats to present findings and recommendations to clients and stakeholders.; Databases: Utilizing knowledge of databases to access and manipulate data for analysis and reporting.; Scripting Languages: Using scripting languages to support data analysis tasks and automate processes.; Key Performance Indicators: Establishing quantitative and qualitative metrics and KPIs to drive technical outcomes and measure success.; Microsoft Office Suite: Leveraging Microsoft Office tools to communicate data findings and support stakeholder engagement."
yoVv58rWQmBHm6H6AAAAAA==,"Senior Data Analyst, Management Data Analysis","About us

National Grid is hiring a Senior Data Analyst for our NY Electric and Data Systems department in Syracuse, NY.

Every day we deliver safe and secure energy to homes, communities, and businesses. We are there when people need us the most. We connect people to the energy they need for the lives they live.

The pace of change in society and our industry is accelerating and our expertise and track record puts us in an unparalleled position to shape the sustainable future of our industry. To be successful we must anticipate the needs of our customers, reducing the cost of energy delivery today and pioneering the flexible energy systems of tomorrow. This requires us to deliver on our promises and always look for new opportunities to grow, both ourselves and our business.

Job Purpose

National Grid is committed to Digital Transformation and is building a best-in-class utility of the future. The NY Electric Data and Systems team is responsible for delivering solutions which support a data driven organization and advance National Grid toward our digital future.

The core function of this role is to help the organization utilize data to facilitate sound decisions that deliver safe, reliable, clean and affordable electric power to our customers.

This analyst will work closely with business teams in Operations, Asset Management and Engineering, as well as IT, digital product and platform teams. This analyst will bring the capability to create data insights form data sets, reports and dashboards; conduct analysis independently and in partnership with business teams; assist in the enhancement of existing digital products and the design of new ones; and help close the quality gaps by defining logic and requirements that meet our business needs. Tasks will include solution delivery, data and process mapping, and data change management to secure the reliability and safety of National Grids information.

Key Accountabilities

Support National Grids data transformation activities, this includes but is not limited to:
• Conducting rigorous analysis of data quality and analytics use cases, collaboration with subject matter experts and performing comprehensive technical evaluations.
• Constructing reports and data visualizations which support the business processes.
• Identifying, evaluating, presenting and recommending options to all levels of leadership(along with effort/impact/risk of each).
• Develop and apply domain knowledge and work as a fully engaged member of the NY Electric Data & Systems team.
• Provide data guidance and support to digital projects and initiatives.
• Support preparation of materials for communications, training and key stakeholder readouts.
• Ability to quickly understand business and data processes, identify customer pain points and help translate business needs into solutions.
• Ability to take a roughly defined approach or hypotheses, identify core intentions and ramifications, and use these insights to refine business assumptions.
• Ability to perform data analytics (including SQL knowledge) and creation of reports/dashboards to communicate meaningful insights.
• Ability to assist with change management and product rollout plans, including presentating materials to senior stakeholders, training material development, and communications plans.
• Ability to manage competing priorities and meet deadlines.
• Ability to effectively partner with stakeholders and build relationships.

Conduct data quality assements and root cause analysis of data issues. Work with business and IT stakeholders to implement necessary changes and improvements.
• Develop details data process maps and documentation (current and to-be state) for NY Electric workflows and projects.

Supervisory/Interpersonal- Experience Required
• Ability to communicate to stakeholders at all levels in the organization.
• Work well in a team.

Qualifications
• Bachelors degree in a STEM discipline with 4 years of related experience, however candidates with equivalent experience will be considered.
• Practical experience with data models, relational databases and development of SQL series.
• Experience conducting structured business analysis and generation of well defined requirements.
• Experience with complete data flows and relationship to business process.
• Knowledge of digital product implementation fundamentals, digital ways of working, and Agile methodologies.
• Demonstrated effectiveness communicating with both technical and non-technical audiences.
• Experience implementing change within an organization.

More Information

Salary: $97,000 - $107,000

This position has a career path which provides for advancement opportunities within and across bands as you develop and evolve in the position; gaining experience, expertise and acquiring and applying technical skills. Internal candidates will be assessed and provided offers against the minimum qualifications of this role and their individual experience.

National Grid is an equal opportunity employer that values a broad diversity of talent, knowledge, experience and expertise. We foster a culture of inclusion that drives employee engagement to deliver superior performance to the communities we serve. National Grid is proud to be an affirmative action employer. We encourage minorities, women, individuals with disabilities and protected veterans to join the National Grid team.

#LI-KC1",,2025-07-25,,,True,[],,"['SQL', 'Data Visualization', 'Data Quality Assessment', 'Data Process Mapping', 'Business Analysis', 'Data Models', 'Agile Methodologies']",SQL: Used for performing data analytics and querying relational databases to support report and dashboard creation.; Data Visualization: Constructing reports and dashboards to communicate meaningful insights to business teams and leadership.; Data Quality Assessment: Conducting rigorous analysis of data quality and root cause analysis of data issues to improve data reliability.; Data Process Mapping: Developing detailed documentation of current and future state data workflows to support NY Electric projects.; Business Analysis: Performing structured business analysis and generating well-defined requirements to translate business needs into data solutions.; Data Models: Applying knowledge of data models to understand and manage data relationships within business processes.; Agile Methodologies: Utilizing Agile ways of working to support digital product implementation and data transformation initiatives.
l0WHl7tPrmnuo4TaAAAAAA==,Senior Data Analyst Jobs,"Description

Job Description

The Company:

ICF is a mission-driven company filled with people who care deeply about improving the lives of others and making the world a better place. Our core values include Embracing Difference; we seek candidates who are passionate about building a culture that encourages, embraces, and hires dimensions of difference.

The Team:

Our Health Engineering Solutions (HES) team works side by side with customers to articulate a vision for success, and then make it happen. We know success doesn't happen by accident. It takes the right team of people, working together on the right solutions for the customer. We are looking for a seasoned Senior Backend Engineer who will be a key driver to make this happen.

The Work:

ICF is seeking a SeniorData Analystto support our Health Engineering Solutions (HES) CMS client team. This role is ideal for a detail-oriented professional with a strong background in data quality assessment, data augmentation, and migration planning. The Senior Data Analyst will work closely with cross-functional teams to ensure the integrity, completeness, and readiness of data for advanced analytics and system integration.

Key Responsibilities:
• Support data collection and augmentation efforts to prepare datasets for downstream analysis and reporting.
• Implement data quality and completeness checks to assess the state of new data files and related resources.
• Identify discrepancies, duplications, and anomalies through pre-validation checks on incoming data types.
• Document known data integrity and quality issues, and collaborate with relevant teams to support remediation planning.
• Load and evaluate sample datasets in the WODD backend system to assess data volume, format, and quality issues.
• Assist in forecasting and planning data migration efforts, including estimating data readiness and transformation needs.
• Collaborate with program implementation, and reporting teams to ensure high-quality data is available for analytics.
• Present findings and recommendations to stakeholders in a clear and actionable format.

Qualifications:
• 6+ years of experience as a data analyst and a Bachelor's degree (Computer Science, Data Science, Math, or equivalent)
• 4+ years of experience with Python and SQL
• 2+ year of experience working with large and complex datasets.
• Must reside in the U.S. and have lived and worked in the U.S. for 3 of the last 5 years.
• Must be able to obtain and maintain a Public Trust clearance.

Professional Skills:
• Strong attention to detail and thoroughness in data validation and documentation.
• Flexibility and adaptability to respond to evolving data requirements and project needs.
• Excellent interpersonal skills and a collaborative, professional attitude.
• Strong analytical, problem-solving, and decision-making capabilities.

Preferred Skills:
• Experience in the healthcare industry and/or federal government contracting.
• Prior experience working remotely in a full-time capacity
• Working at ICF
• ICF is a global advisory and technology services provider, but we're not your typical consultants. We combine unmatched expertise with cutting-edge technology to help clients solve their most complex challenges, navigate change, and shape the future.
• We can only solve the world's toughest challenges by building an inclusive workplace that allows everyone to thrive. We are an equal opportunity employer, committed to hiring regardless of any protected characteristic, such as race, ethnicity, national origin, color, sex, gender identity/expression, sexual orientation, religion, age, disability status, or military/veteran status.
• Together, our employees are empowered to share their expertise and collaborate with others to achieve personal and professional goals. For more information, please read our EEO & AA policy.
• Reasonable Accommodations are available, including, but not limited to, for disabled veterans, individuals with disabilities, and individuals with sincerely held religious beliefs, in all phases of the application and employment process. To request an accommodation please email icfcareercenter@icf.com and we will be happy to assist. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.
• Read more about workplace discrimination rights, the Pay Transparency Statement, or our benefit offerings which are included in the Transparency in (Benefits) Coverage Act.

Working at ICF
ICF is a global advisory and technology services provider, but we're not your typical consultants. We combine unmatched expertise with cutting-edge technology to help clients solve their most complex challenges, navigate change, and shape the future.

We can only solve the world's toughest challenges by building a workplace that allows everyone to thrive. We are an equal opportunity employer . Together, our employees are empowered to share their expertise and collaborate with others to achieve personal and professional goals. For more information, please read our EEO policy.

Reasonable Accommodations are available, including, but not limited to, for disabled veterans, individuals with disabilities, and individuals with sincerely held religious beliefs, in all phases of the application and employment process. To request an accommodation, please email Candidateaccommodation@icf.com and we will be happy to assist . All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

Read more about workplacediscriminationrigh t s or our benefit offerings which are included in the Transparency in (Benefits) Coverage Act.

Candidate AI Usage Policy

At ICF, we are committed to ensuring a fair interview process for all candidates based on their own skills and knowledge. As part of this commitment, the use of artificial intelligence (AI) tools to generate or assist with responses during interviews (whether in-person or virtual) is not permitted . This policy is in place to maintain the integrity and authenticity of the interview process.

However, we understand that some candidates may require accommodation that involves the use of AI. If such an accommodation is needed, candidates are instructed to contact us in advance at candidateaccommodation@icf.com . We are dedicated to providing the necessary support to ensure that all candidates have an equal opportunity to succeed.

Pay Range - There are multiple factors that are considered in determining final pay for a position, including, but not limited to, relevant work experience, skills, certifications and competencies that align to the specified role, geographic location, education and certifications as well as contract provisions regarding labor categories that are specific to the position.

The pay range for this position based on full-time employment is :
$73,722.00 - $125,327.00

Nationwide Remote Office (US99)",2025-07-24T00:00:00.000Z,2025-07-25,"[""6+ years of experience as a data analyst and a Bachelor's degree (Computer Science, Data Science, Math, or equivalent)"", '4+ years of experience with Python and SQL', '2+ year of experience working with large and complex datasets', 'Must reside in the U.S. and have lived and worked in the U.S. for 3 of the last 5 years', 'Must be able to obtain and maintain a Public Trust clearance', 'Strong attention to detail and thoroughness in data validation and documentation', 'Flexibility and adaptability to respond to evolving data requirements and project needs', 'Excellent interpersonal skills and a collaborative, professional attitude', 'Strong analytical, problem-solving, and decision-making capabilities']","['This role is ideal for a detail-oriented professional with a strong background in data quality assessment, data augmentation, and migration planning', 'The Senior Data Analyst will work closely with cross-functional teams to ensure the integrity, completeness, and readiness of data for advanced analytics and system integration', 'Support data collection and augmentation efforts to prepare datasets for downstream analysis and reporting', 'Implement data quality and completeness checks to assess the state of new data files and related resources', 'Identify discrepancies, duplications, and anomalies through pre-validation checks on incoming data types', 'Document known data integrity and quality issues, and collaborate with relevant teams to support remediation planning', 'Load and evaluate sample datasets in the WODD backend system to assess data volume, format, and quality issues', 'Assist in forecasting and planning data migration efforts, including estimating data readiness and transformation needs', 'Collaborate with program implementation, and reporting teams to ensure high-quality data is available for analytics', 'Present findings and recommendations to stakeholders in a clear and actionable format']",True,[],,"['Data Quality Assessment', 'Data Augmentation', 'Data Migration Planning', 'Data Validation', 'Python', 'SQL', 'Data Reporting', 'Data Loading and Evaluation']","Data Quality Assessment: Used to evaluate the integrity, completeness, and accuracy of datasets to ensure reliable analytics and reporting.; Data Augmentation: Applied to enhance datasets by adding or modifying data to improve downstream analysis and reporting.; Data Migration Planning: Involves forecasting and preparing for the transfer and transformation of data between systems to maintain data readiness.; Data Validation: Performed through checks for discrepancies, duplications, and anomalies to maintain data integrity before analysis.; Python: Used as a programming language for data manipulation, analysis, and scripting tasks within the data analyst role.; SQL: Utilized for querying and managing large and complex datasets stored in relational databases.; Data Reporting: Involves preparing and presenting data findings and recommendations to stakeholders in a clear and actionable manner.; Data Loading and Evaluation: Loading sample datasets into backend systems to assess data volume, format, and quality issues."
6cU9Z12IdFtIzkGiAAAAAA==,"Data Scientist, Mid Jobs","Job Number: R0223031

Data Scientist, Mid

The Opportunity:

As a data scientist, you're excited at the prospect of unlocking the secrets held by a data set, and you're fascinated by the possibilities presented by IoT, machine learning, and artificial intelligence. In an increasingly connected world, massive amounts of structured and unstructured data open new opportunities. As a data scientist at Booz Allen, you can help turn these complex data sets into useful information to solve global challenges. Across private and public sectors-from fraud detection to cancer research to national intelligence-we need you to help find the answers in the data.

On our team, you'll use your analytical skills and data science knowledge to create real-world impact. You'll work closely with your clients to understand their questions and needs, and then dig into their data-rich environments to find the pieces of their information puzzle. You'll develop algorithms and systems and use the right combination of tools and frameworks to turn sets of disparate data points into objective answers to help clients make informed decisions. Ultimately, you'll provide a deep understanding of the data, what it all means, and how it can be used.

Work with us as we use data science for good.

Join us. The world can't wait.

You Have:
• 2+ years of experience with data exploration, data cleaning, data analysis, data visualization, or data mining
• 2+ years of experience with statistical and general-purpose programming languages for data analysis
• Experience analyzing structured and unstructured data sources
• Experience developing predictive data models, quantitative analyses and visualization of targeted data sources
• Experience working with Palantir Foundry Envision
• Experience working effectively in teams and interfacing with clients
• Experience developing visually compelling PowerPoint decks and products to support client delivery
• Knowledge of text mining or machine learning (ML) techniques, artificial intelligence (AI), or natural language processing (NLP)
• Secret clearance
• Bachelor's degree

Nice If You Have:
• 2+ years of experience in the development of algorithms leveraging R, Python, or SQL/NoSQL
• 2+ years of experience with distributed data and computing tools, including MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL
• 2+ years of experience with ML, AI or NLP
• Experience with visualization packages, including Plotly, Seaborn, or ggplot2
• Experience working with Advana or Vault
• Possession of strong verbal and written communication skills
• TS/SCI clearance
• Master's degree

Clearance:

Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required.

Compensation

At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen's benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.

Salary at Booz Allen is determined by various factors, including but not limited to location, the individual's particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $77,600.00 to $176,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen's total compensation package for employees. This posting will close within 90 days from the Posting Date.

Identity Statement

As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud.

Work Model

Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.
• If this position is listed as remote or hybrid, you'll periodically work from a Booz Allen or client site facility.
• If this position is listed as onsite, you'll work with colleagues and clients in person, as needed for the specific role.

Commitment to Non-Discrimination

All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law.",2025-07-23T00:00:00.000Z,2025-07-25,"['2+ years of experience with data exploration, data cleaning, data analysis, data visualization, or data mining', '2+ years of experience with statistical and general-purpose programming languages for data analysis', 'Experience analyzing structured and unstructured data sources', 'Experience developing predictive data models, quantitative analyses and visualization of targeted data sources', 'Experience working with Palantir Foundry Envision', 'Experience working effectively in teams and interfacing with clients', 'Experience developing visually compelling PowerPoint decks and products to support client delivery', 'Knowledge of text mining or machine learning (ML) techniques, artificial intelligence (AI), or natural language processing (NLP)', 'Secret clearance', ""Bachelor's degree"", '2+ years of experience in the development of algorithms leveraging R, Python, or SQL/NoSQL', '2+ years of experience with distributed data and computing tools, including MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL', '2+ years of experience with ML, AI or NLP', 'Experience with visualization packages, including Plotly, Seaborn, or ggplot2', 'Experience working with Advana or Vault', 'Possession of strong verbal and written communication skills', 'TS/SCI clearance', ""Master's degree"", 'Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required']","[""On our team, you'll use your analytical skills and data science knowledge to create real-world impact"", ""You'll work closely with your clients to understand their questions and needs, and then dig into their data-rich environments to find the pieces of their information puzzle"", ""You'll develop algorithms and systems and use the right combination of tools and frameworks to turn sets of disparate data points into objective answers to help clients make informed decisions"", ""Ultimately, you'll provide a deep understanding of the data, what it all means, and how it can be used"", ""If this position is listed as remote or hybrid, you'll periodically work from a Booz Allen or client site facility"", ""If this position is listed as onsite, you'll work with colleagues and clients in person, as needed for the specific role""]",True,[],,"['Data Exploration', 'Data Cleaning', 'Data Analysis', 'Data Visualization', 'Data Mining', 'Statistical Programming', 'Predictive Modeling', 'Text Mining', 'Machine Learning', 'Natural Language Processing', 'Palantir Foundry', 'R', 'Python', 'SQL/NoSQL', 'Distributed Computing Tools', 'Gurobi', 'MySQL', 'Data Visualization Libraries', 'Advana', 'Vault']","Data Exploration: Used to investigate and understand data sets to uncover initial insights and patterns.; Data Cleaning: Applied to prepare and preprocess data by removing inconsistencies and errors for accurate analysis.; Data Analysis: Performed to extract meaningful information from structured and unstructured data sources.; Data Visualization: Used to create visual representations of data to support client delivery and decision-making.; Data Mining: Employed to discover patterns and relationships within large data sets.; Statistical Programming: Utilized for performing statistical analyses and modeling using languages like R and Python.; Predictive Modeling: Developed to forecast outcomes and support quantitative analyses for targeted data sources.; Text Mining: Applied to extract useful information from unstructured text data.; Machine Learning: Used to develop algorithms that learn from data to make predictions or classifications.; Natural Language Processing: Employed to analyze and interpret human language data as part of data analysis tasks.; Palantir Foundry: A platform used for integrating, managing, and analyzing complex data sets.; R: A programming language used for statistical computing and algorithm development.; Python: A general-purpose programming language used for data analysis, algorithm development, and scripting.; SQL/NoSQL: Database query languages used to manage and retrieve structured and semi-structured data.; Distributed Computing Tools: Technologies like MapReduce, Hadoop, Hive, EMR, Kafka, and Spark used to process large-scale data efficiently.; Gurobi: An optimization solver used for developing algorithms involving mathematical programming.; MySQL: A relational database management system used for storing and querying structured data.; Data Visualization Libraries: Tools such as Plotly, Seaborn, and ggplot2 used to create compelling visual data representations.; Advana: A data platform used for analytics and data integration in client environments.; Vault: A tool used for secure data storage and management."
fT5VGjF4Q3RHr25lAAAAAA==,Data Scientist Jobs,"Data Scientist

Job Category: Information Technology

Time Type: Full time

Minimum Clearance Required to Start: TS/SCI with Polygraph

Employee Type: Regular

Percentage of Travel Required: None

Type of Travel: None
• * *

The Opportunity:

Are you a curious intrinsically motivated person looking to work in an entrepreneurial IC office? If so, we are seeking an experienced Senior Data Scientist to join our innovative analytics team. The ideal candidate will have a strong background in multi-cloud environments, machine learning, and scalable data solutions, with the ability to design and implement cutting-edge analytics capabilities.

Responsibilities
• Design and implement data science frameworks across multi-cloud environments
• Develop machine learning models for data analysis and automation, including building RAG models for AWS Bedrock
• Automate analytic solutions and build scalable analytics capabilities
• Collaborate with the Mission team to gather requirements across various teams
• Assess and implement new technologies and tools to enhance data capabilities
• Support data webforms (SQL databases) and processes for API connections, including drag-and-drop data functionality
• Lead complex data science projects from conception to implementation
• Develop real-time data processing solutions and data solutions at scale
• Integrate AI/ML with applications and systems
• Mentor junior data scientists and contribute to the overall growth of the data science team
• Communicate findings and recommendations to both technical and non-technical stakeholders

Qualifications
Required:
• Degree in Computer Science, Statistics, Mathematics, or related field
• 7+ years of experience in data science or related field, plus additional 3+ years' experience in a complimentary function
• Strong programming skills in Python, SCALA, and/or UNIX shell scripting
• Expertise in machine learning techniques and statistical analysis
• Proficiency in SQL and NoSQL databases
• Experience with big data platforms such as Hadoop, Spark, and Kafka
• Cloud computing expertise across AWS, Azure, and other
• Experience in designing and implementing real-time data processing solutions
• Strong understanding of AI/ML applications in systems and software
• Excellent problem-solving and communication skills
• Experience with data visualization tools (e.g., Tableau, PowerBI)

Desired:
• Experience in IC
• Familiarity with drag-and-drop data tools and API integrations

-
________________________________________________________________________________________

What You Can Expect:

A culture of integrity.

At CACI, we place character and innovation at the center of everything we do. As a valued team member, you'll be part of a high-performing group dedicated to our customer's missions and driven by a higher purpose - to ensure the safety of our nation.

An environment of trust.

CACI values the unique contributions that every employee brings to our company and our customers - every day. You'll have the autonomy to take the time you need through a unique flexible time off benefit and have access to robust learning resources to make your ambitions a reality.

A focus on continuous growth.

Together, we will advance our nation's most critical missions, build on our lengthy track record of business success, and find opportunities to break new ground - in your career and in our legacy.

Your potential is limitless. So is ours.

Learn more about CACI here.

________________________________________________________________________________________

Pay Range: There are a host of factors that can influence final salary including, but not limited to, geographic location, Federal Government contract labor categories and contract wage rates, relevant prior work experience, specific skills and competencies, education, and certifications. Our employees value the flexibility at CACI that allows them to balance quality work and their personal lives. We offer competitive compensation, benefits and learning and development opportunities. Our broad and competitive mix of benefits options is designed to support and protect employees and their families. At CACI, you will receive comprehensive benefits such as; healthcare, wellness, financial, retirement, family support, continuing education, and time off benefits. Learn more here .

The proposed salary range for this position is:
$120,800 - $265,800

CACI is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, age, national origin, disability, status as a protected veteran, or any other protected characteristic.",2025-07-23T00:00:00.000Z,2025-07-25,"['Minimum Clearance Required to Start: TS/SCI with Polygraph', 'If so, we are seeking an experienced Senior Data Scientist to join our innovative analytics team', 'The ideal candidate will have a strong background in multi-cloud environments, machine learning, and scalable data solutions, with the ability to design and implement cutting-edge analytics capabilities', 'Degree in Computer Science, Statistics, Mathematics, or related field', ""7+ years of experience in data science or related field, plus additional 3+ years' experience in a complimentary function"", 'Strong programming skills in Python, SCALA, and/or UNIX shell scripting', 'Expertise in machine learning techniques and statistical analysis', 'Proficiency in SQL and NoSQL databases', 'Experience with big data platforms such as Hadoop, Spark, and Kafka', 'Cloud computing expertise across AWS, Azure, and other', 'Experience in designing and implementing real-time data processing solutions', 'Strong understanding of AI/ML applications in systems and software', 'Excellent problem-solving and communication skills', 'Experience with data visualization tools (e.g., Tableau, PowerBI)']","['Design and implement data science frameworks across multi-cloud environments', 'Develop machine learning models for data analysis and automation, including building RAG models for AWS Bedrock', 'Automate analytic solutions and build scalable analytics capabilities', 'Collaborate with the Mission team to gather requirements across various teams', 'Assess and implement new technologies and tools to enhance data capabilities', 'Support data webforms (SQL databases) and processes for API connections, including drag-and-drop data functionality', 'Lead complex data science projects from conception to implementation', 'Develop real-time data processing solutions and data solutions at scale', 'Integrate AI/ML with applications and systems', 'Mentor junior data scientists and contribute to the overall growth of the data science team', 'Communicate findings and recommendations to both technical and non-technical stakeholders']",True,"['Retrieval-Augmented Generation', 'AI/ML Integration']",Retrieval-Augmented Generation: Building RAG models on AWS Bedrock to enhance machine learning with retrieval-based generative AI capabilities.; AI/ML Integration: Integrating AI and machine learning models with applications and systems to enable intelligent automation.,"['Machine Learning', 'SQL', 'NoSQL', 'Big Data Platforms', 'Data Visualization Tools', 'Real-Time Data Processing', 'Data Science Frameworks', 'Statistical Analysis', 'Python', 'Scala', 'Unix Shell Scripting', 'Cloud Computing', 'API Integration']","Machine Learning: Developing and applying machine learning models for data analysis and automation within scalable data solutions.; SQL: Supporting SQL databases and data webforms, essential for managing structured data and API connections.; NoSQL: Utilizing NoSQL databases to handle unstructured or semi-structured data as part of data storage solutions.; Big Data Platforms: Experience with Hadoop, Spark, and Kafka to process and analyze large-scale data efficiently.; Data Visualization Tools: Using tools like Tableau and PowerBI to create dashboards and visual analytics for communicating insights.; Real-Time Data Processing: Designing and implementing solutions for processing data streams in real time to support timely analytics.; Data Science Frameworks: Designing and implementing frameworks to support data science workflows across multi-cloud environments.; Statistical Analysis: Applying statistical methods to analyze data and support machine learning model development.; Python: Programming language used for data science, machine learning, and automation tasks.; Scala: Programming language often used with big data platforms like Spark for data processing.; Unix Shell Scripting: Scripting skills to automate data workflows and manage data processing tasks.; Cloud Computing: Expertise in AWS, Azure, and other cloud platforms to deploy and scale data science and analytics solutions.; API Integration: Supporting API connections to enable data exchange and integration with other systems."
lREO_Gvf-mqPGqOtAAAAAA==,Data Scientist - 3313719 Jobs,"Computer Technologies Consultants (CTC) is seeking a Data Scientist to support the Defense Intelligence Agency (DIA) in Washington, DC.

With offices in Washington DC and San Diego, CA, CTC is a leading technology company providing lifecycle IT, data analytics, cloud managed hosting services, agile software development, DevOps, Test Automation, Cyber Security, and infrastructure solutions. Additionally, we provide Professional Talent Acquisition Services as we proudly support the unique needs of U.S. Defense, Intelligence, and Federal Civilian agencies as well as Fortune 1000 companies.

Got the Government Contractor Blues? Looking for a company that cares and goes beyond just filling another contract billet? Well look no further! Experience this family-oriented company who takes pride in you and will help you grow where your passions lie. Holding many Defense & Federal government contracts around the globe, with our client you have the opportunity to take on new and evolving challenges, aim beyond what you think you are capable of and work in collaborative, dynamic, and high-tempo environments. Our clients' employees are their most valued asset and they invest in their people because they are in it for the long term. They are committed to your success and well-being and offer competitive benefits packages, salaries, bonus/award programs, and a high potential for professional growth and job opportunities world-wide.

Why Should You Be Interested ?
• Direct hire full-time position
• Competitive base salary and comprehensive benefits
• Mid-size company with room for growth

Position Title : Data Scientist

Position Location : This position is full time, on-site in the National Capital Region

Daily Responsibilities:
• Oversee data normalization, building tables, moving data, writing data scripts, installation, configuration, and data integration.
• Responsibility for discovery, service mapping, configuration management, and event management using MID Servers and best practices.
• Maintain and update the data dictionary, metadata, and SOPs for data-related tasks, ensuring compliance with DIA security and configuration standards.
• Collaborate with platform teams to design scalable, efficient data architectures that enable dashboarding, KPI reporting, and Configuration Management Database (CMDB) health monitoring.
• Participate in data validation, DR/COOP testing, platform upgrades, and ensure data integrity across environments (dev, test, prod).
• Monitor data pipelines for errors or anomalies and propose continuous improvements.
• Ensure all activities align with ATO, NIST 800-53, and DoDIIS data handling guidance.

Required Years of Experience (min) :
• Five (5) years of experience in ServiceNow or a related field.

Required Degree/Certifications :
• Bachelor's degree in Computer Science, Statistics, Mathematics, a related field, or equivalent related professional experience.
• ServiceNow Certified Implementation Specialist (CIS) for Discovery or Service Mapping (required).

Required Experience & Expertise in the following areas :
• Hands-on experience with data scripting, ETL, and data integration tools in enterprise environments.
• Strong understanding of ServiceNow Discovery, Service Mapping, CMDB, and Event Management.
• Proven experience in data modeling, normalization, and database design.
• Familiarity with scripting languages such as JavaScript, Python, or PowerShell.
• Knowledge of IT infrastructure, systems management, and service dependency mapping.
• Ability to troubleshoot and resolve data-related issues quickly and efficiently.
• Strong analytical and problem-solving skills, with the ability to communicate technical findings to non-technical audiences.

Required Clearance :
• Must be eligible for a TS/SCI clearance with CI polygraph (active clearance preferred)

Pay Information

Full-Time Salary Range: TBD

Please note: This range is based on our market pay structures. However, individual salaries are determined by a variety of factors including, but not limited to: business considerations, local market conditions, and internal equity, as well as candidate qualifications, such as skills, education, and experience.

Computer Technologies Consultants, Inc. is an Equal Opportunity Employer that provides employment opportunities for all qualified applicants without regard to race, color, religion, gender identity and/or expression, sexual orientation, age, mental or sensory differing abilities, protected veteran status, sex, national origin, or any other characteristic protected by applicable law. Computer Technologies Consultants, Inc. is devoted to diversity, equity, and inclusion.",2025-07-24T00:00:00.000Z,2025-07-25,"['Five (5) years of experience in ServiceNow or a related field', ""Bachelor's degree in Computer Science, Statistics, Mathematics, a related field, or equivalent related professional experience"", 'ServiceNow Certified Implementation Specialist (CIS) for Discovery or Service Mapping (required)', 'Required Experience & Expertise in the following areas :', 'Hands-on experience with data scripting, ETL, and data integration tools in enterprise environments', 'Strong understanding of ServiceNow Discovery, Service Mapping, CMDB, and Event Management', 'Proven experience in data modeling, normalization, and database design', 'Familiarity with scripting languages such as JavaScript, Python, or PowerShell', 'Knowledge of IT infrastructure, systems management, and service dependency mapping', 'Ability to troubleshoot and resolve data-related issues quickly and efficiently', 'Strong analytical and problem-solving skills, with the ability to communicate technical findings to non-technical audiences']","['Position Location : This position is full time, on-site in the National Capital Region', 'Oversee data normalization, building tables, moving data, writing data scripts, installation, configuration, and data integration', 'Responsibility for discovery, service mapping, configuration management, and event management using MID Servers and best practices', 'Maintain and update the data dictionary, metadata, and SOPs for data-related tasks, ensuring compliance with DIA security and configuration standards', 'Collaborate with platform teams to design scalable, efficient data architectures that enable dashboarding, KPI reporting, and Configuration Management Database (CMDB) health monitoring', 'Participate in data validation, DR/COOP testing, platform upgrades, and ensure data integrity across environments (dev, test, prod)', 'Monitor data pipelines for errors or anomalies and propose continuous improvements', 'Ensure all activities align with ATO, NIST 800-53, and DoDIIS data handling guidance']",False,[],,"['Data Normalization', 'Data Scripting', 'ETL (Extract, Transform, Load)', 'Data Integration', 'ServiceNow Discovery', 'ServiceNow Service Mapping', 'Configuration Management Database (CMDB)', 'Event Management', 'Data Modeling', 'Database Design', 'Data Pipelines', 'Data Dictionary and Metadata Management', 'Dashboarding and KPI Reporting', 'Data Validation and Integrity Testing', 'Scripting Languages']","Data Normalization: Involved in standardizing data formats and structures to ensure consistency and quality across datasets.; Data Scripting: Writing scripts to manipulate, move, and integrate data within enterprise environments.; ETL (Extract, Transform, Load): Hands-on experience with processes and tools to extract data from sources, transform it, and load into target systems.; Data Integration: Combining data from different sources to provide a unified view for analysis and reporting.; ServiceNow Discovery: Using ServiceNow tools to automatically identify and map IT infrastructure components.; ServiceNow Service Mapping: Mapping relationships between IT services and infrastructure to support configuration management.; Configuration Management Database (CMDB): Maintaining a database of IT assets and their relationships to support service management and monitoring.; Event Management: Monitoring and managing IT events to detect and respond to issues proactively.; Data Modeling: Designing data structures and schemas to support efficient storage and retrieval.; Database Design: Creating and optimizing database schemas to support application and reporting needs.; Data Pipelines: Monitoring and improving workflows that move and process data across systems.; Data Dictionary and Metadata Management: Maintaining documentation and definitions of data elements to ensure clarity and compliance.; Dashboarding and KPI Reporting: Designing and enabling visual reports and key performance indicators for monitoring business metrics.; Data Validation and Integrity Testing: Ensuring accuracy and consistency of data across development, testing, and production environments.; Scripting Languages: Using JavaScript, Python, or PowerShell to automate data tasks and integrations."
jP9DTA35CxtBFLhCAAAAAA==,Data Scientist Jobs,"Job Type

Full-time

Description

Data Scientist

Primary Location: Washington D.C. Metropolitan Area

Clearance: Top Secret

Must be a US Citizen

This position is contingent on contract award.

Job Summary

Obsidian Solutions Group (OSG) is seeking an Exploitation Specialist / Analytic Methodologist to join the Team!

Supporting National Geospatial-Intelligence Agency (NGA) providing and sustaining support that promotes mission excellence through applied modernized analytic techniques, data sciences, modeling, and automation that optimized service performance and innovation.

Specific Responsibilities

· Develop methods for querying, visualizing, aggregating, correlating, and analyzing big data across intelligence disciplines

· Optimize existing databases to speed up the query, input, export, and visualization of data.

· Work with teams in NGA Analysis Operations (AO) Regional, Functional and Agency/CCMD Liaison Offices (collectively referred to as ""AO Offices"") to develop strategies for exposing new datasets and create migration plans for legacy datasets.

· Build custom solutions (tools, processes, etc.) to automate or assist analytic endeavors as submitted by applicable AO Office leadership and analytic units.

· Write scripts in Visual Basic, R, Python or other software for statistical models using large datasets to extract patterns, relationships, and anticipatory behaviors that are repeatable, efficient, hypothesis testing, and knowledge capture.

· Use mathematical concepts and techniques to solve complex GEOINT analysis problem sets; understand concepts associated with structured data and relational databases

· Use tools, such as Arc GIS, Excel, SPSS, SAS, Matlab, R, or other statistical packages, to analyze and visualize operational data; visualize data both temporally and spatially

Requirements

· Possess a Bachelor's Degree or higher in math or a science related field or possess at least 7 years of relevant experience in lieu of a Bachelor's Degree.

· Experience applying multidisciplinary mathematical and statistical models via programming language to large datasets to extract patterns, relationships and anticipatory behavioral likelihoods that may not be apparent using traditional single discipline means

· Experience in developing tradecraft techniques and training solutions for discovery, preparation, manipulation and normalization of big data so that methods are repeatable and can be explained to analysts

· Experience using mathematical concepts and techniques to solve complex GEOINT analysis problem sets; understand concepts associated with structured data and relational databases

· Experience understanding and explaining the relationship between the data collected for a real world problem and the required structure of a relational database to help solve that problem

· Experience conceptualizing the relationship between a database structure and the requirements for analyzing and visualizing those data both temporally and spatially

· Experience writing scripts in Visual Basic, R, Python, Java, Javascript, C++ or other software for modeling processes, with a focus on repeatability, efficiency, knowledge capture, and hypothesis testing

· Experience using tools, such as ArcGIS, Excel, Python, SPSS, R, or other statistical packages, to analyze and visualize data; visualize data both temporally and spatially to assist in data integrity checks, ask the next question, and display analytical assessments

· Experience maintaining, moving and manipulating data between applications, using appropriate software and/or Extract-Transform-Load (ELT) procedures: Microsoft EXCEL spreadsheets, ACCESS database management system and/or ORACLE, Postgresql, or SQL Server and importing and cleaning analyst-provided datasets (Excel, geospatial data, etc.)

· Experience using statistical software (SPSS, SAS, Matlab etc.), desktop software (MS Office and Access), and the Windows operating environment. Of importance is software packages used for advanced statistical analysis of operational data

· Experience using GOTS data and analytics capabilities (MIST, INTELBOOK, LINX and WATCHBOX)

· Knowledge of intelligence operations and GEOINT phenomenology.

· Data Visualization Experience which may include Matrix Analytics, Network Analytics, Graphing Data.

· Knowledge and experience using 1) ABI tools and tradecraft to include MIST, 2) SOM tools and SOM-C, GOWK, CEDALLION, and ATLAS, and 3) OBP tools.

Physical Requirements and Work Environment

Normal Office environment

Travel

Occasional Long Distance

Company Description

Obsidian Solutions Group LLC (OSG) is a fast-growing professional services firm based in Fredericksburg, VA. We create value for our customers by delivering technology-enabled & mission-oriented technical solutions that solve complex problems, protecting people, information, and assets. Our core capabilities are in providing Enterprise IT, Intelligence Analysis, Production & Development and Knowledge-Based Professional Services Solutions that enable the customer's mission. Obsidian Solutions Group LLC is a certified 8(a), service-disabled, veteran-owned small business.

A career at Obsidian Solutions Group means you can put your expertise, credentials, and talents to great use working with customers in the DOD and Intelligence Community, while enjoying the excitement of working in a fast-growing organization committed to making a difference for our customers and in our community. Contribute independently and collaboratively alongside our amazing team of doers and thinkers. Obsidian Solutions Group is small enough to offer a family atmosphere yet large enough to deliver a highly competitive compensation package. We hire and retain the best in the industry, offering exceptional benefits that protect the well-being of our employees, their spouses and domestic partners, and their families.

Our corporate philosophy is centered on hiring and retaining employees with the requisite skills, professional experience, personal commitment, and ethical standards necessary to foster a culture of operational excellence necessary to surpass our customer's expectations.

Disclaimer

The above information on this description has been designed to indicate the general nature and level of work performed by employees within this classification. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities, and qualifications required of employees assigned to this job.

Obsidian Solutions Group is an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex (including pregnancy and gender identity), national origin, political affiliation, sexual orientation, marital status, disability, genetic information, age, membership in an employee organization, parental status, protected veteran status, and any other non-merit factor, or any other characteristic protected by law.",2025-07-25T00:00:00.000Z,2025-07-25,"['Must be a US Citizen', ""Possess a Bachelor's Degree or higher in math or a science related field or possess at least 7 years of relevant experience in lieu of a Bachelor's Degree"", 'Experience applying multidisciplinary mathematical and statistical models via programming language to large datasets to extract patterns, relationships and anticipatory behavioral likelihoods that may not be apparent using traditional single discipline means', 'Experience in developing tradecraft techniques and training solutions for discovery, preparation, manipulation and normalization of big data so that methods are repeatable and can be explained to analysts', 'Experience using mathematical concepts and techniques to solve complex GEOINT analysis problem sets; understand concepts associated with structured data and relational databases', 'Experience understanding and explaining the relationship between the data collected for a real world problem and the required structure of a relational database to help solve that problem', 'Experience conceptualizing the relationship between a database structure and the requirements for analyzing and visualizing those data both temporally and spatially', 'Experience writing scripts in Visual Basic, R, Python, Java, Javascript, C++ or other software for modeling processes, with a focus on repeatability, efficiency, knowledge capture, and hypothesis testing', 'Experience using tools, such as ArcGIS, Excel, Python, SPSS, R, or other statistical packages, to analyze and visualize data; visualize data both temporally and spatially to assist in data integrity checks, ask the next question, and display analytical assessments', 'Experience maintaining, moving and manipulating data between applications, using appropriate software and/or Extract-Transform-Load (ELT) procedures: Microsoft EXCEL spreadsheets, ACCESS database management system and/or ORACLE, Postgresql, or SQL Server and importing and cleaning analyst-provided datasets (Excel, geospatial data, etc.)', 'Experience using statistical software (SPSS, SAS, Matlab etc.), desktop software (MS Office and Access), and the Windows operating environment', 'Of importance is software packages used for advanced statistical analysis of operational data', 'Experience using GOTS data and analytics capabilities (MIST, INTELBOOK, LINX and WATCHBOX)', 'Knowledge of intelligence operations and GEOINT phenomenology', 'Data Visualization Experience which may include Matrix Analytics, Network Analytics, Graphing Data', 'Knowledge and experience using 1) ABI tools and tradecraft to include MIST, 2) SOM tools and SOM-C, GOWK, CEDALLION, and ATLAS, and 3) OBP tools', 'Physical Requirements and Work Environment']","['Supporting National Geospatial-Intelligence Agency (NGA) providing and sustaining support that promotes mission excellence through applied modernized analytic techniques, data sciences, modeling, and automation that optimized service performance and innovation', 'Develop methods for querying, visualizing, aggregating, correlating, and analyzing big data across intelligence disciplines', 'Optimize existing databases to speed up the query, input, export, and visualization of data', 'Work with teams in NGA Analysis Operations (AO) Regional, Functional and Agency/CCMD Liaison Offices (collectively referred to as ""AO Offices"") to develop strategies for exposing new datasets and create migration plans for legacy datasets', 'Build custom solutions (tools, processes, etc.)', 'to automate or assist analytic endeavors as submitted by applicable AO Office leadership and analytic units', 'Write scripts in Visual Basic, R, Python or other software for statistical models using large datasets to extract patterns, relationships, and anticipatory behaviors that are repeatable, efficient, hypothesis testing, and knowledge capture', 'Use mathematical concepts and techniques to solve complex GEOINT analysis problem sets; understand concepts associated with structured data and relational databases', 'Use tools, such as Arc GIS, Excel, SPSS, SAS, Matlab, R, or other statistical packages, to analyze and visualize operational data; visualize data both temporally and spatially']",True,[],,"['Big Data Analytics', 'Relational Databases', 'Extract-Transform-Load (ETL)', 'Statistical Modeling', 'Data Visualization', 'Programming Languages for Data Science', 'Statistical Software Packages', 'Data Cleaning and Preparation', 'Geospatial Intelligence (GEOINT) Analysis', 'Matrix and Network Analytics', 'Government Off-The-Shelf (GOTS) Tools', 'ABI and SOM Tools', 'SQL and Database Management Systems']","Big Data Analytics: Developing methods to query, visualize, aggregate, correlate, and analyze large datasets across intelligence disciplines.; Relational Databases: Optimizing and understanding structured data storage and querying using relational database concepts to support analysis and visualization.; Extract-Transform-Load (ETL): Maintaining, moving, and manipulating data between applications using ETL procedures to prepare data for analysis.; Statistical Modeling: Writing scripts in languages like R, Python, Visual Basic to build statistical models for pattern extraction, hypothesis testing, and knowledge capture.; Data Visualization: Using tools such as ArcGIS, Excel, SPSS, SAS, Matlab, and R to visualize data temporally and spatially to support operational analysis.; Programming Languages for Data Science: Utilizing languages including Python, R, Visual Basic, Java, Javascript, and C++ for scripting and modeling large datasets.; Statistical Software Packages: Employing software like SPSS, SAS, Matlab, and R for advanced statistical analysis of operational data.; Data Cleaning and Preparation: Importing and cleaning analyst-provided datasets such as Excel and geospatial data to ensure data integrity.; Geospatial Intelligence (GEOINT) Analysis: Applying mathematical and statistical techniques to solve complex geospatial intelligence problems and visualize spatial-temporal data.; Matrix and Network Analytics: Using matrix and network analysis methods to visualize and analyze relationships within data.; Government Off-The-Shelf (GOTS) Tools: Utilizing specialized intelligence community tools like MIST, INTELBOOK, LINX, and WATCHBOX for data analytics.; ABI and SOM Tools: Applying ABI tools (including MIST) and SOM tools (SOM-C, GOWK, CEDALLION, ATLAS) for intelligence data analysis.; SQL and Database Management Systems: Using database systems such as Oracle, PostgreSQL, SQL Server, and Access for data storage, querying, and management."
jC4mf5O0NpszvA_FAAAAAA==,Data Scientist-RS3 Prog and Data Analytics Jobs,"Description

Position Title : Data Scientist

Location : Arlington, VA (Remote)

Clearance Level : Secret

Responsibilities will include, but are not limited to :
• Serve as a primary facilitator for preparation, execution and follow up for all Planning, Programming, and Budgeting Committee - Guard (PPBC-G) forums (General Officer / Strategic Level forums), to include Resourcing Council of Colonels (RCoC), Resource Integration Steering Committee (RISC). Coordinates across Army National Guard Bureau staffs to develop topics, products, and presentations for submission to the PPBC-G process.
• Support the design, development, and execution of all data analytic efforts led by the GS-13 Data Scientist as directed by the DAG-R Division Chief/Deputy Division Chief in support of the Chief Financial Officer's analytic agenda.
• Provide expertise on ARNG Roles, Missions, Authorities and Army strategic guidance and key planning efforts such as The Army Plan (TAP), Total Army Analysis (TAA), the Army Equipment Modernization Strategy (AEMS), and the Long-Range Investment Requirements Analysis (LIRA).
• Develop and enhance websites, applications, and secure access to databases based upon requirements for analytic efforts as approved by the COR. Customers include the CFO, ARNG G-8, DAG-R, ARNG Directorate Office of Primary Responsibility (OPR) for program portfolio's, and National-level Program Managers (NPMs).

Qualifications

Required qualifications
• Bachelor's Degree in related field of study or equivalent experience.
• Minimum of four years of experience, two within the DoD working with big-data systems and developing production-level data models .
• Possess skills and expertise in machine learning tools to select features, create, and optimize classifiers.
• Possess demonstrable collegiate-level writing skills, demonstrated familiarity with the U.S. Army organization and regulations, and strong organization and communication skills.
• Demonstrate practical experience substantiating equivalent skills such as Structured Query Language, Microsoft Excel, R or Python statistical programming, Data Visualization, and Presentation Skills.
• Prior knowledge of Power BI, Tableau, and Advana data science is preferred",2025-07-25T13:00:00.000Z,2025-07-25,"[""Bachelor's Degree in related field of study or equivalent experience"", 'Minimum of four years of experience, two within the DoD working with big-data systems and developing production-level data models ', 'Possess skills and expertise in machine learning tools to select features, create, and optimize classifiers', 'Possess demonstrable collegiate-level writing skills, demonstrated familiarity with the U.S. Army organization and regulations, and strong organization and communication skills', 'Demonstrate practical experience substantiating equivalent skills such as Structured Query Language, Microsoft Excel, R or Python statistical programming, Data Visualization, and Presentation Skills']","['Serve as a primary facilitator for preparation, execution and follow up for all Planning, Programming, and Budgeting Committee - Guard (PPBC-G) forums (General Officer / Strategic Level forums), to include Resourcing Council of Colonels (RCoC), Resource Integration Steering Committee (RISC)', 'Coordinates across Army National Guard Bureau staffs to develop topics, products, and presentations for submission to the PPBC-G process', ""Support the design, development, and execution of all data analytic efforts led by the GS-13 Data Scientist as directed by the DAG-R Division Chief/Deputy Division Chief in support of the Chief Financial Officer's analytic agenda"", 'Provide expertise on ARNG Roles, Missions, Authorities and Army strategic guidance and key planning efforts such as The Army Plan (TAP), Total Army Analysis (TAA), the Army Equipment Modernization Strategy (AEMS), and the Long-Range Investment Requirements Analysis (LIRA)', 'Develop and enhance websites, applications, and secure access to databases based upon requirements for analytic efforts as approved by the COR', ""Customers include the CFO, ARNG G-8, DAG-R, ARNG Directorate Office of Primary Responsibility (OPR) for program portfolio's, and National-level Program Managers (NPMs)""]",True,[],,"['Machine Learning', 'Structured Query Language (SQL)', 'Python Statistical Programming', 'R Statistical Programming', 'Data Visualization', 'Power BI', 'Tableau', 'Advana Data Science Platform', 'Microsoft Excel']","Machine Learning: Used to select features, create, and optimize classifiers for production-level data models in support of analytic efforts.; Structured Query Language (SQL): Applied for querying and managing big-data systems as part of data analytic tasks.; Python Statistical Programming: Utilized for statistical analysis and data modeling within the data science workflow.; R Statistical Programming: Used for statistical programming and data visualization to support analytic efforts.; Data Visualization: Employed to create visual representations of data to aid in presentations and decision-making.; Power BI: Preferred business intelligence tool for developing dashboards and visual analytics.; Tableau: Preferred BI tool for creating interactive data visualizations and reports.; Advana Data Science Platform: Preferred platform for data science initiatives within the Department of Defense context.; Microsoft Excel: Used for data manipulation, analysis, and presentation in support of analytic tasks."
q6-tTQUn2Sr0Hg9vAAAAAA==,Data Scientist Jobs,"Title
Data Scientist
Full-Time/Part-Time Full-Time Description
Cyber Intelligence Alliance (CIA) Joint Venture (JV) is seeking a Data Scientist (contingent upon award) to support federal client in serving as a primary facilitator for preparation, execution and follow up for all Planning, Programming, and Budgeting Committee (PPBC-G) forms. Supports analytic efforts of the client and validates accuracy and appropriate analysis for presentation in forums. Provides primary oversight and tracking of issues/topics for development, staffing in the PPBC-G. Prefer some working knowledge of Power BI and/or Tableau.
• Candidate shall possess skills and expertise in machine learning tools to select features, create, and optimize classifiers.
• Candidate shall possess demonstrable collegiate-level writing skills, demonstrated familiarity with the U.S. Army organization and regulations, and strong organization and communication skills.
• Candidate shall have the ability to communicate complex technical findings to a variety of audiences.
• Candidate should have the ability to demonstrate practical experience substantiating equivalent skills such as Structured Query Language, Microsoft Excel, R or Python statistical programming, Data Visualization, and Presentation Skills.
Requirements for this position shall include:
• Bachelor's degree or higher in related field of study or equivalent experience
• Minimum of four (4) years of experience, two within DoD, working with big-data systems and developing production-level data models
• Secret Security Clearance Required
• Prior knowledge of Power BI, Tableau, and Advana data science is preferred.
About the Organization Established in 2008, RiVidium, Inc. (dba TripleCyber) is a VA-Verified SDVOSB and an SBA-Certified 8(a) company. To prepare our clients for the future, RiVidium has balanced all parts of our organization to attract the finest employees in order to 'Strive to be the missing element defining tomorrow's technology'. RiVidium keeps pace and surpasses its competitors by meeting challenges of advancements in Logistics, Human Capital, Cyber, Intelligence & Technology. EOE Statement We are an equal employment opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status or any other characteristic protected by law. If you need a reasonable accommodation for any part of the employment process, please contact Human Resources (HR) at hr@rividium.com.
This position is currently accepting applications.",2025-07-25T00:00:00.000Z,2025-07-25,"['Prefer some working knowledge of Power BI and/or Tableau', 'Candidate shall possess skills and expertise in machine learning tools to select features, create, and optimize classifiers', 'Candidate shall possess demonstrable collegiate-level writing skills, demonstrated familiarity with the U.S. Army organization and regulations, and strong organization and communication skills', 'Candidate shall have the ability to communicate complex technical findings to a variety of audiences', 'Candidate should have the ability to demonstrate practical experience substantiating equivalent skills such as Structured Query Language, Microsoft Excel, R or Python statistical programming, Data Visualization, and Presentation Skills', ""Bachelor's degree or higher in related field of study or equivalent experience"", 'Minimum of four (4) years of experience, two within DoD, working with big-data systems and developing production-level data models', 'Secret Security Clearance Required', 'About the Organization Established in 2008, RiVidium, Inc']","['Cyber Intelligence Alliance (CIA) Joint Venture (JV) is seeking a Data Scientist (contingent upon award) to support federal client in serving as a primary facilitator for preparation, execution and follow up for all Planning, Programming, and Budgeting Committee (PPBC-G) forms', 'Supports analytic efforts of the client and validates accuracy and appropriate analysis for presentation in forums', 'Provides primary oversight and tracking of issues/topics for development, staffing in the PPBC-G']",True,[],,"['Machine Learning', 'Feature Selection', 'Classification', 'SQL', 'Python', 'R', 'Data Visualization', 'Power BI', 'Tableau', 'Big Data Systems', 'Production-Level Data Models', 'Microsoft Excel']","Machine Learning: Used to select features, create, and optimize classifiers for analytic efforts supporting the federal client.; Feature Selection: Applied as part of machine learning tools to improve classifier performance in data modeling.; Classification: Developed and optimized classifiers to support analytic tasks and data-driven decision making.; SQL: Used for querying and managing big-data systems as part of production-level data model development.; Python: Utilized for statistical programming and data analysis in support of data science tasks.; R: Employed for statistical programming and data analysis relevant to the job's analytic efforts.; Data Visualization: Implemented through tools like Power BI and Tableau to present complex data insights effectively.; Power BI: Preferred tool for creating dashboards and visualizing data to support client presentations.; Tableau: Preferred tool for data visualization and dashboard creation to aid analytic presentations.; Big Data Systems: Experience required in working with large-scale data environments to develop production-level models.; Production-Level Data Models: Developed and maintained models that support operational analytic needs within the DoD context.; Microsoft Excel: Used for data manipulation, analysis, and presentation as part of the data science workflow."
dLAcy4VGzii_2vfPAAAAAA==,"Data Scientist - Tysons Corner, VA - Top Secret Clearance Jobs","Data Scientist needed for an opportunity with SOC's client to work in Tysons Corner, Virginia.

Active Top Secret Clearance is required!

Responsibilities
• Collaborate with data and subject matter experts from Customer and its customer teams to seek, understand, validate, interpret, and correctly use data and business insights
• MLOps, Model Engineering, Training on time series data.
• After few weeks training on Customer's AI platform, develop AI-based applications using Customer's platform for operational cloud-deployed and secure lab deployed AI-based applications.
• Develop candidate models that are promoted to active models when their performance meets threshold.
• Train, validate and deploy machine learning pipelines
• Test, troubleshoot, and enhance customer AI-based applications based on feedback.
• Manage individual project deliverables
• Identify application performance bottlenecks and implement optimizations
• Write application specifications and documentation
• Articulate methodologies, experiments, and findings clearly in actionable way.
• Work in a fast-paced environment.
• This is NOT a data analytics role using Tableau or PowerBI.
• This is NOT an ETL & SQL role.
• This is NOT a R&D role prototyping at low TRL.
Qualifications
• Bachelor's degree in a Science, Technology, Engineering or Mathematics (STEM), or comparable area of study. No experience in lieu of.
• 5+ years of Data Science development experience using Python
• Proficiency in data science, machine learning, and analytics, including statistical data analysis, model and feature evaluations.
• Strong proficiency in numpy & pandas.
• Demonstrated skills with Jupyter Notebook or comparable environments
• Practical experience in solving complex problems in an applied environment, and proficiency in critical thinking.
• Candidates require a TS to start. TS/SCI with Polygraph preferred
PREFERRED Qualifications
• Degree in Data Science, Machine Learning, Computer Science, Engineering, Statistics, or equivalent fields
• Strong mathematical background (linear algebra, calculus, probability & statistics)
• Experience with machine learning model training and analysis through open-source frameworks (Pytorch, Tensorflow, Sklearn)
• Experience crafting, conducting, analyzing, and interpreting experiments and investigations.
• Experience with modern software development tools and practices (Git, pull requests)
• Experience analyzing model performance with relevant metrics and optimizing.
• Familiarity with AI agent frameworks
• Ability to drive a project and work both independently and in a team
• Smart, motivated, can-do attitude, and seeks to make a difference
• Excellent English communication and collaboration skills, particularly in multidisciplinary teams with data scientists, software engineers, product owners, & solution architects.
Employment Pre-requisites
The following requirements must be met to be eligible for this position: Successful completion of a background investigation, and d rug urinalysis.
SOC, a Day & Zimmermann company, is an Equal Opportunity Employer,EOE AA M/F/Vet/Disability.

#INDSOC

Estimated Min Rate: $56.00
Estimated Max Rate: $80.00",2025-07-25T01:00:00.000Z,2025-07-25,"['Active Top Secret Clearance is required!', ""Bachelor's degree in a Science, Technology, Engineering or Mathematics (STEM), or comparable area of study"", 'No experience in lieu of', '5+ years of Data Science development experience using Python', 'Proficiency in data science, machine learning, and analytics, including statistical data analysis, model and feature evaluations', 'Strong proficiency in numpy & pandas', 'Demonstrated skills with Jupyter Notebook or comparable environments', 'Practical experience in solving complex problems in an applied environment, and proficiency in critical thinking', 'Candidates require a TS to start', 'The following requirements must be met to be eligible for this position: Successful completion of a background investigation, and d rug urinalysis']","['Collaborate with data and subject matter experts from Customer and its customer teams to seek, understand, validate, interpret, and correctly use data and business insights', 'MLOps, Model Engineering, Training on time series data', ""After few weeks training on Customer's AI platform, develop AI-based applications using Customer's platform for operational cloud-deployed and secure lab deployed AI-based applications"", 'Develop candidate models that are promoted to active models when their performance meets threshold', 'Train, validate and deploy machine learning pipelines', 'Test, troubleshoot, and enhance customer AI-based applications based on feedback', 'Manage individual project deliverables', 'Identify application performance bottlenecks and implement optimizations', 'Write application specifications and documentation', 'Articulate methodologies, experiments, and findings clearly in actionable way', 'Work in a fast-paced environment', 'This is NOT a data analytics role using Tableau or PowerBI', 'This is NOT an ETL & SQL role', 'This is NOT a R&D role prototyping at low TRL']",True,"['AI Platform Development', 'AI Agent Frameworks']","AI Platform Development: Developing AI-based applications on a proprietary AI platform for cloud and secure lab deployment.; AI Agent Frameworks: Familiarity with frameworks that support autonomous AI agents, indicating involvement with modern AI systems.","['Time-Series Modeling', 'MLOps', 'Machine Learning Pipelines', 'Python', 'NumPy', 'Pandas', 'Jupyter Notebook', 'Statistical Data Analysis', 'Model Evaluation and Optimization', 'Open-Source Machine Learning Frameworks']","Time-Series Modeling: Used for training and analyzing models on sequential time-dependent data as part of the machine learning pipelines.; MLOps: Involved in managing machine learning model lifecycle including training, validation, deployment, and monitoring.; Machine Learning Pipelines: Developing, training, validating, and deploying end-to-end machine learning workflows.; Python: Primary programming language used for data science development and model engineering.; NumPy: Used for numerical computations and array operations essential in data processing and model development.; Pandas: Utilized for data manipulation and analysis within the data science workflows.; Jupyter Notebook: Environment for interactive development, experimentation, and documentation of data science projects.; Statistical Data Analysis: Applied for evaluating models and features through statistical methods to ensure performance and validity.; Model Evaluation and Optimization: Analyzing model performance metrics and implementing improvements to meet operational thresholds.; Open-Source Machine Learning Frameworks: Experience with frameworks like PyTorch, TensorFlow, and scikit-learn for model training and analysis."
vmRyubn28ldCTWSXAAAAAA==,Data Scientist Development Program (DSDP) - Entry to Mid Level ( Jobs,"Duties
Help

Data science at the National Security Agency (NSA) is a multi-disciplinary field that uses elements of mathematics, statistics, computer science, and application-specific knowledge to gather, make, and communicate principled conclusions from data. Data Science is a broad field and a team effort, spanning all the expertise needed to derive value from data. It encompasses AI Engineering, Data Engineering, ML Ops Engineering, and Human Perception and Cognition Engineering in addition to the traditional applications of data science.

Data science is present in every aspect of the mission. NSA Data Scientists tackle challenging real-world problems leveraging big data, high-performance computing, machine learning, and a breadth of other methodologies. We are looking for critical thinkers, problem solvers, and motivated individuals who are enthusiastic about data and believe that answers to hard questions lie in the yet-to-be-told story of diverse, complicated data sets. You will employ your mathematical science, computer science, and quantitative analysis skills to develop solutions to complex data problems and take full advantage of NSA's capabilities to tackle the highest priority foreign intelligence and cybersecurity challenges.

As a Data Scientist, your responsibilities may include:
- Exploratory data analysis and exploratory model-fitting to reveal data features of interest
- Machine-learned predictive modeling
- Identifying and analyzing anomalous data (including metadata)
- Lead or contribute to cross-functional teams to develop and implement Al (including generative AI) that can help solve some of our most challenging problems.
- Apply modern engineering techniques to develop decision support software prototypes.
- Propose and execute novel, cutting-edge research in Al-enhanced decision systems.
- Designing and developing analytics and techniques for analysis
- Analyzing data using mathematical and statistical methods
- Implement ML pipeline and workflows
- Leverage skills in modern data architecture, cloud engineering, data transformation, and management of structured and unstructured data sources.
- Build continuous integration and delivery pipelines for ML applications.
- Construct usable data sets from multiple sources to meet customer needs
- Developing conceptual design and models to address mission requirements
- Developing qualitative and quantitative methods for characterizing datasets in various states.
- Performing analytic modeling, scripting, and/or programming
- Working collaboratively and iteratively throughout the data-science lifecycle
- Communicate with a team of data scientists, data engineers, AI engineers, ML-Ops engineers, and stakeholders.
- Evaluating, documenting, and communicating research processes, analyses, and results to customers, peers, and leadership
- Creating interpretable visualizations.
- Work with mission owners to design, develop, and deploy new architectures for ML and automation applications such as ELT functions, HPC/compute infrastructure, AWS/Azure solutions, database solutions, and optimization of DevOps procedures.

Requirements
Help
Conditions of employment
• Employment is contingent upon successful completion of a security background investigation and polygraph.
Qualifications

The qualifications listed are the minimum acceptable to be considered for the position.

Applicants who meet minimum qualifications may be asked to complete the Data Science Examination (DSE) evaluating their knowledge of statistics, mathematics, and computer science topics that pertain to data science work. Passing this examination is a requirement in order to be considered for selection into a data scientist position.

Degree must be in Mathematics, Applied Mathematics, Statistics, Applied Statistics, Machine Learning, Data Science, Operations Research, or Computer Science. A degree in a related field (e.g., Computer Information Systems, Engineering), a degree in the physical/hard sciences (e.g. physics, chemistry, biology, astronomy), or other science disciplines (i.e., behavioral, social, library, and life) may be considered if it includes a concentration of coursework (typically 5 or more courses) in advanced mathematics (typically 200 level or higher; such as calculus, differential equations, discrete mathematics, linear algebra, and calculus based statistics) and/or computer science (e.g., algorithms, programming, data structures, data mining, artificial intelligence). College-level Algebra or other math courses intended to meet a basic college level requirement, or upper level math courses designated as elementary or basic do not count.

Note: Degrees in related fields will be considered if accompanied by a Certificate in Data Science from an accredited college/university.

ENTRY/DEVELOPMENTAL
Entry is with a Bachelor's degree and no experience. An Associate's degree plus 2 years of relevant experience may be considered for individuals with in-depth experience that is clearly related to the position. Relevant experience must be in one or more of the following: designing/implementing machine learning, data mining, advanced analytical algorithms, programming, data science, advanced statistical analysis, artificial intelligence, computational science, software engineering, or data engineering.

FULL PERFORMANCE
Entry is with a Bachelor's degree plus 3 years of relevant experience or a Master's degree plus 1 year of relevant experience or a Doctoral degree and no experience. An Associate's degree plus 5 years of relevant experience may be considered for individuals with in-depth experience that is clearly related to the position. Relevant experience must be in two or more of the following: designing/implementing machine learning, data mining, advanced analytical algorithms, programming, data science, advanced statistical analysis, artificial intelligence, computational science, software engineering, or data engineering.

Education

Degree must be in Mathematics, Applied Mathematics, Statistics, Applied Statistics, Machine Learning, Data Science, Operations Research, or Computer Science. A degree in a related field (e.g., Computer Information Systems, Engineering), a degree in the physical/hard sciences (e.g. physics, chemistry, biology, astronomy), or other science disciplines (i.e., behavioral, social, library, and life) may be considered if it includes a concentration of coursework (typically 5 or more courses) in advanced mathematics (typically 200 level or higher; such as calculus, differential equations, discrete mathematics, linear algebra, and calculus based statistics) and/or computer science (e.g., algorithms, programming, data structures, data mining, artificial intelligence). College-level Algebra or other math courses intended to meet a basic college level requirement, or upper level math courses designated as elementary or basic do not count.

Note: Degrees in related fields will be considered if accompanied by a Certificate in Data Science from an accredited college/university.

Additional information

Pay: Salary offers are based on candidates' education level and years of experience relevant to the position and also take into account information provided by the hiring manager/organization regarding the work level for the position.

Salary Range: $86,498 - $151,570 (Entry/Developmental, Full Performance)
Salary range varies by location, work level, and relevant experience to the position.

Training will be provided based on the selectee's needs and experience.

Benefits:
NSA offers a comprehensive benefits package. Work Schedule: This is a full-time position, Monday - Friday, with basic 8hr/day work requirement between 6:00 a.m. and 6:00 p.m. (flexible).",2025-07-21T00:00:00.000Z,2025-07-25,"['Employment is contingent upon successful completion of a security background investigation and polygraph', 'The qualifications listed are the minimum acceptable to be considered for the position', 'Applicants who meet minimum qualifications may be asked to complete the Data Science Examination (DSE) evaluating their knowledge of statistics, mathematics, and computer science topics that pertain to data science work', 'Passing this examination is a requirement in order to be considered for selection into a data scientist position', 'Degree must be in Mathematics, Applied Mathematics, Statistics, Applied Statistics, Machine Learning, Data Science, Operations Research, or Computer Science', 'A degree in a related field (e.g., Computer Information Systems, Engineering), a degree in the physical/hard sciences (e.g. physics, chemistry, biology, astronomy), or other science disciplines (i.e., behavioral, social, library, and life) may be considered if it includes a concentration of coursework (typically 5 or more courses) in advanced mathematics (typically 200 level or higher; such as calculus, differential equations, discrete mathematics, linear algebra, and calculus based statistics) and/or computer science (e.g., algorithms, programming, data structures, data mining, artificial intelligence)', 'College-level Algebra or other math courses intended to meet a basic college level requirement, or upper level math courses designated as elementary or basic do not count', 'Note: Degrees in related fields will be considered if accompanied by a Certificate in Data Science from an accredited college/university', ""Entry is with a Bachelor's degree and no experience"", ""An Associate's degree plus 2 years of relevant experience may be considered for individuals with in-depth experience that is clearly related to the position"", 'Relevant experience must be in one or more of the following: designing/implementing machine learning, data mining, advanced analytical algorithms, programming, data science, advanced statistical analysis, artificial intelligence, computational science, software engineering, or data engineering', ""Entry is with a Bachelor's degree plus 3 years of relevant experience or a Master's degree plus 1 year of relevant experience or a Doctoral degree and no experience"", ""An Associate's degree plus 5 years of relevant experience may be considered for individuals with in-depth experience that is clearly related to the position"", 'Relevant experience must be in two or more of the following: designing/implementing machine learning, data mining, advanced analytical algorithms, programming, data science, advanced statistical analysis, artificial intelligence, computational science, software engineering, or data engineering', 'Degree must be in Mathematics, Applied Mathematics, Statistics, Applied Statistics, Machine Learning, Data Science, Operations Research, or Computer Science', 'A degree in a related field (e.g., Computer Information Systems, Engineering), a degree in the physical/hard sciences (e.g. physics, chemistry, biology, astronomy), or other science disciplines (i.e., behavioral, social, library, and life) may be considered if it includes a concentration of coursework (typically 5 or more courses) in advanced mathematics (typically 200 level or higher; such as calculus, differential equations, discrete mathematics, linear algebra, and calculus based statistics) and/or computer science (e.g., algorithms, programming, data structures, data mining, artificial intelligence)', 'College-level Algebra or other math courses intended to meet a basic college level requirement, or upper level math courses designated as elementary or basic do not count', 'Note: Degrees in related fields will be considered if accompanied by a Certificate in Data Science from an accredited college/university', ""Training will be provided based on the selectee's needs and experience""]","['It encompasses AI Engineering, Data Engineering, ML Ops Engineering, and Human Perception and Cognition Engineering in addition to the traditional applications of data science', ""You will employ your mathematical science, computer science, and quantitative analysis skills to develop solutions to complex data problems and take full advantage of NSA's capabilities to tackle the highest priority foreign intelligence and cybersecurity challenges"", 'Exploratory data analysis and exploratory model-fitting to reveal data features of interest', 'Machine-learned predictive modeling', 'Identifying and analyzing anomalous data (including metadata)', 'Lead or contribute to cross-functional teams to develop and implement Al (including generative AI) that can help solve some of our most challenging problems', 'Apply modern engineering techniques to develop decision support software prototypes', 'Propose and execute novel, cutting-edge research in Al-enhanced decision systems', 'Designing and developing analytics and techniques for analysis', 'Analyzing data using mathematical and statistical methods', 'Implement ML pipeline and workflows', 'Leverage skills in modern data architecture, cloud engineering, data transformation, and management of structured and unstructured data sources', 'Build continuous integration and delivery pipelines for ML applications', 'Construct usable data sets from multiple sources to meet customer needs', 'Developing conceptual design and models to address mission requirements', 'Developing qualitative and quantitative methods for characterizing datasets in various states', 'Performing analytic modeling, scripting, and/or programming', 'Working collaboratively and iteratively throughout the data-science lifecycle', 'Communicate with a team of data scientists, data engineers, AI engineers, ML-Ops engineers, and stakeholders', 'Evaluating, documenting, and communicating research processes, analyses, and results to customers, peers, and leadership', 'Creating interpretable visualizations', 'Work with mission owners to design, develop, and deploy new architectures for ML and automation applications such as ELT functions, HPC/compute infrastructure, AWS/Azure solutions, database solutions, and optimization of DevOps procedures']",True,"['Generative AI', 'AI-Enhanced Decision Systems', 'AI Engineering', 'ML-Ops Engineering for AI']",Generative AI: Developing and implementing generative AI solutions to address challenging problems as part of AI engineering.; AI-Enhanced Decision Systems: Proposing and executing research in AI-driven systems that enhance decision-making capabilities.; AI Engineering: Collaborating with AI engineers to develop AI models and systems integrated with data science workflows.; ML-Ops Engineering for AI: Working with ML-Ops engineers to build and maintain AI model deployment and lifecycle management pipelines.,"['Exploratory Data Analysis', 'Predictive Modeling', 'Anomaly Detection', 'Mathematical and Statistical Methods', 'Machine Learning Pipelines', 'Data Architecture and Cloud Engineering', 'Continuous Integration and Delivery for ML', 'Data Integration', 'Analytic Modeling and Programming', 'Data Visualization', 'Machine Learning', 'Data Mining', 'Advanced Statistical Analysis', 'Algorithms and Data Structures', 'High-Performance Computing', 'ELT (Extract, Load, Transform) Functions', 'DevOps Optimization']","Exploratory Data Analysis: Used to reveal data features of interest and understand data characteristics as part of the data science process.; Predictive Modeling: Applying machine-learned models to predict outcomes based on data, a core responsibility in the role.; Anomaly Detection: Identifying and analyzing anomalous data including metadata to detect irregularities or outliers.; Mathematical and Statistical Methods: Used for analyzing data and developing quantitative models to support decision-making.; Machine Learning Pipelines: Implementing workflows and pipelines to automate machine learning model development and deployment.; Data Architecture and Cloud Engineering: Leveraging modern data architectures and cloud platforms like AWS and Azure for data transformation and management.; Continuous Integration and Delivery for ML: Building CI/CD pipelines to support machine learning application deployment and updates.; Data Integration: Constructing usable datasets from multiple structured and unstructured data sources to meet customer needs.; Analytic Modeling and Programming: Performing scripting, programming, and analytic modeling to develop data-driven solutions.; Data Visualization: Creating interpretable visualizations to communicate data insights effectively.; Machine Learning: Designing and implementing machine learning models and algorithms to solve complex data problems.; Data Mining: Extracting patterns and knowledge from large datasets as part of the data science workflow.; Advanced Statistical Analysis: Applying advanced statistical techniques to analyze and interpret complex datasets.; Algorithms and Data Structures: Utilizing computer science fundamentals such as algorithms and data structures in data science solutions.; High-Performance Computing: Using HPC infrastructure to process and analyze large-scale data efficiently.; ELT (Extract, Load, Transform) Functions: Designing and deploying ELT processes for data ingestion and transformation in data pipelines.; DevOps Optimization: Optimizing DevOps procedures to support data science and machine learning workflows."
3BV0mxleNgf3IRb0AAAAAA==,Data Scientist- TS Clearance Jobs,"This position requires an active Top Secret Clearance. Candidates who do not hold this clearance are not eligible for hire.

Solidus is searching for a Data Scientist. This position is on- site at Tyson's, VA..

Day in the life:
• MLOps, Model Engineering, Training on time series data
• After few weeks training on Customer's AI platform, develop AI-based applications using Customer's platform for operational cloud-deployed and secure lab deployed AI-based applications
• Develop candidate models that are promoted to active models when their performance meets threshold
• Train, validate and deploy machine learning pipelines
• Test, troubleshoot, and enhance customer AI-based applications based on feedback
• Manage individual project deliverables
• Identify application performance bottlenecks and implement optimizations
• Write application specifications and documentation
• Articulate methodologies, experiments, and findings clearly in actionable way
• Work in a fast-paced environment
Required Qualifications:
• US Citizen with an active Top Secret Clearance
• Undergo a comprehensive background investigation
• Bachelor's degree in a Science, Technology, Engineering or Mathematics (STEM), or comparable area of study. No experience in lieu of
• 5+ years of Data Science development experience using Python
• Proficiency in data science, machine learning, and analytics, including statistical data analysis, model and feature evaluations
• Strong proficiency in numpy & pandas
• Demonstrated skills with Jupyter Notebook or comparable environments
• Practical experience in solving complex problems in an applied environment, and proficiency in critical thinking

Important Note:
• This is NOT a data analytics role using Tableau or PowerBI.
• This is NOT an ETL & SQL role.

• This is NOT a R&D role prototyping at low TRL.

Preferred Qualifications:
• Degree in Data Science, Machine Learning, Computer Science, Engineering, Statistics, or equivalent fields
• Strong mathematical background (linear algebra, calculus, probability & statistics)
• Experience with machine learning model training and analysis through open-source frameworks (Pytorch, Tensorflow, Sklearn)
• Experience crafting, conducting, analyzing, and interpreting experiments and investigations.
• Experience with modern software development tools and practices (Git, pull requests)
• Experience analyzing model performance with relevant metrics and optimizing.
• Familiarity with AI agent frameworks
• Ability to drive a project and work both independently and in a team
• Smart, motivated, can do attitude, and seeks to make a difference
• Excellent communication and collaboration skills, particularly in multidisciplinary teams with data scientists, software engineers, product owners, & solution architects.
• TS/SCI with Polygraph preferred

What we will bring:
Solidus offers you an exciting opportunity to tackle the nation's greatest challenges applying innovation and expertise to produce cutting-edge results that have a long-lasting impact. We offer outstanding benefits, including comprehensive health, vision, and dental insurance, generous PTO, and much more! Apply today to learn why Solidus has a 4.9/5 Star rating on Glassdoor!

Benefit selection, customer contractual specifications, relevant work experience, skills, competencies, certifications, and clearance status will influence the final salary.
Full benefits: $98,000 to $153,000 annually
Reduced benefits (no medical, dental, vision): Up to $165,000 annually

Req ID: 4959

Solidus is an Equal Opportunity Employer and provides equal employment opportunities regarding all terms and conditions of employment to all employees and qualified applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. The Company will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application and interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request an accommodation.

Federal Job Notices for Job Applicants

Please Note: Solidus does not accept applications from agencies, 3rd party vendors, or applications with incomplete information.",2025-07-25T00:00:00.000Z,2025-07-25,"['US Citizen with an active Top Secret Clearance', 'Undergo a comprehensive background investigation', ""Bachelor's degree in a Science, Technology, Engineering or Mathematics (STEM), or comparable area of study"", 'No experience in lieu of', '5+ years of Data Science development experience using Python', 'Proficiency in data science, machine learning, and analytics, including statistical data analysis, model and feature evaluations', 'Strong proficiency in numpy & pandas', 'Demonstrated skills with Jupyter Notebook or comparable environments', 'Practical experience in solving complex problems in an applied environment, and proficiency in critical thinking', 'This is NOT a data analytics role using Tableau or PowerBI', 'This is NOT an ETL & SQL role', 'This is NOT a R&D role prototyping at low TRL']","['MLOps, Model Engineering, Training on time series data', ""After few weeks training on Customer's AI platform, develop AI-based applications using Customer's platform for operational cloud-deployed and secure lab deployed AI-based applications"", 'Develop candidate models that are promoted to active models when their performance meets threshold', 'Train, validate and deploy machine learning pipelines', 'Test, troubleshoot, and enhance customer AI-based applications based on feedback', 'Manage individual project deliverables', 'Identify application performance bottlenecks and implement optimizations', 'Write application specifications and documentation', 'Articulate methodologies, experiments, and findings clearly in actionable way', 'Work in a fast-paced environment']",True,"['AI Platform Development', 'AI Agent Frameworks']",AI Platform Development: Developing AI-based applications on a customer’s AI platform for cloud and secure lab deployment indicates working with modern AI systems.; AI Agent Frameworks: Familiarity with AI agent frameworks suggests involvement with autonomous or semi-autonomous AI systems.,"['Time-Series Modeling', 'Machine Learning Pipelines', 'MLOps', 'Python Data Science Libraries', 'Jupyter Notebooks', 'Statistical Data Analysis', 'Open-Source Machine Learning Frameworks', 'Model Performance Evaluation', 'Feature Engineering']","Time-Series Modeling: The role involves training models specifically on time series data, indicating the use of temporal data analysis techniques.; Machine Learning Pipelines: Responsibilities include training, validating, and deploying machine learning pipelines to operationalize predictive models.; MLOps: The job requires managing machine learning operations to ensure model deployment, monitoring, and lifecycle management.; Python Data Science Libraries: Strong proficiency in numpy and pandas is required for data manipulation and analysis within Python.; Jupyter Notebooks: Experience with Jupyter Notebook or similar environments is necessary for interactive data science development and experimentation.; Statistical Data Analysis: The role involves statistical analysis and evaluation of models and features to ensure robust data-driven insights.; Open-Source Machine Learning Frameworks: Experience with frameworks such as PyTorch, TensorFlow, and scikit-learn is preferred for model training and analysis.; Model Performance Evaluation: Analyzing and optimizing model performance using relevant metrics is a key responsibility.; Feature Engineering: Evaluating and engineering features is part of the model development and validation process."
hjhpBIewfePGk7gFAAAAAA==,"Part time - Principal Data Scientist at Davita Inc. Mc Lean, VA","Part time - Principal Data Scientist job at Davita Inc.. Mc Lean, VA.

Overview

Principal Data Scientist

Data Scientist - Community Impact and Investment Team

Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making.

As a Data Scientist at Capital One, you'll be part of a team that's leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and reduce stress in their financial lives.

Team Description
The Community Impact and Investment team develops tools and insights to support our philanthropic investment and product decisions with data-driven understanding of the communities we serve. In addition to internal decision-making, we conduct research on community impact topics that often lead to externally published articles. Our team is constantly exploring creative approaches using secondary data sources to generate meaningful insights on relevant community impact issues.

Responsibilities
Partner with a cross-functional team of data scientists, software engineers, and business leaders to develop insights that drive community investments and financial well-being.
Leverage a broad stack of technologies—Python, R, Conda, AWS, H2O, Spark, and more—to collect, clean, and analyze data from diverse sources.
Develop and validate causal inference models to assess the social impact of internal community initiatives and relevant public programs.
Solve data challenges creatively by sourcing and integrating alternative datasets, including government reports, survey data, and financial transaction data.
Translate complex findings into clear, actionable recommendations for internal stakeholders and external partners.

The Ideal Candidate is:
Mission-Driven: Passionate about leveraging data to make a positive social impact and believe in using insights to drive better decision-making.
Innovative: Stay on top of the latest research in causal inference, machine learning, and data collection methodologies—and love applying them to real-world problems.
Creative: Thrive in ambiguity, enjoy tackling undefined problems, and love finding novel data sources to enrich analysis.
Statistically-Minded: Experience with causal inference methods (RCTs, regression discontinuity, propensity score matching, difference-in-differences) and interpreting results from statistical models.
Technical: Proficient in R and Python, comfortable working with large-scale datasets in cloud environments like AWS.
Data Guru: Skilled in retrieving, combining, and analyzing structured and unstructured data from various sources.

Basic Qualifications:
Bachelor's Degree plus 5 years of experience in data analytics, or Master's Degree plus 3 years, or PhD in a quantitative field.
At least 1 year of experience with open-source programming languages for large-scale data analysis.
At least 1 year of experience with machine learning.
At least 1 year of experience with research or data analysis.
At least 1 year of experience with relational databases.

Preferred Qualifications:
Master's Degree in STEM field plus 3 years of experience in data analytics, or PhD in STEM.
At least 1 year of experience working with AWS.
At least 3 years of experience in R, Python, or Scala.
At least 3 years of experience with machine learning.
At least 3 years of experience with SQL.

Salary and Benefits
The minimum and maximum full-time annual salaries for this role are listed below, by location. Salaries for part-time roles will be prorated based on hours worked.
McLean, VA (Hybrid): $158,600 - $181,000
Chicago, IL (Hybrid): $153,900 - $188,500
Other locations will have different pay ranges. This role is eligible for performance-based incentives, including bonuses and long-term incentives.
Capital One offers comprehensive benefits supporting total well-being. Learn more at the Capital One Careers website.
Additional Information This role is open for applications for at least 5 business days. No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion. For accommodations during the application process, contact Recruiting at 1-800-304-9102 or RecruitingAccommodation@capitalone.com. For technical support, email Careers@capitalone.com.

#J-18808-Ljbffr Davita Inc.",2025-07-16T00:00:00.000Z,2025-07-25,"['Mission-Driven: Passionate about leveraging data to make a positive social impact and believe in using insights to drive better decision-making', 'Innovative: Stay on top of the latest research in causal inference, machine learning, and data collection methodologies—and love applying them to real-world problems', 'Statistically-Minded: Experience with causal inference methods (RCTs, regression discontinuity, propensity score matching, difference-in-differences) and interpreting results from statistical models', 'Technical: Proficient in R and Python, comfortable working with large-scale datasets in cloud environments like AWS', 'Data Guru: Skilled in retrieving, combining, and analyzing structured and unstructured data from various sources', ""Bachelor's Degree plus 5 years of experience in data analytics, or Master's Degree plus 3 years, or PhD in a quantitative field"", 'At least 1 year of experience with open-source programming languages for large-scale data analysis', 'At least 1 year of experience with machine learning', 'At least 1 year of experience with research or data analysis', 'At least 1 year of experience with relational databases', ""Master's Degree in STEM field plus 3 years of experience in data analytics, or PhD in STEM"", 'At least 1 year of experience working with AWS', 'At least 3 years of experience in R, Python, or Scala', 'At least 3 years of experience with machine learning', 'At least 3 years of experience with SQL']","['Partner with a cross-functional team of data scientists, software engineers, and business leaders to develop insights that drive community investments and financial well-being', 'Leverage a broad stack of technologies—Python, R, Conda, AWS, H2O, Spark, and more—to collect, clean, and analyze data from diverse sources', 'Develop and validate causal inference models to assess the social impact of internal community initiatives and relevant public programs', 'Solve data challenges creatively by sourcing and integrating alternative datasets, including government reports, survey data, and financial transaction data', 'Translate complex findings into clear, actionable recommendations for internal stakeholders and external partners', 'Creative: Thrive in ambiguity, enjoy tackling undefined problems, and love finding novel data sources to enrich analysis']",True,[],,"['Causal Inference', 'Regression Discontinuity', 'Propensity Score Matching', 'Difference-in-Differences', 'Machine Learning', 'Python', 'R', 'SQL', 'AWS', 'H2O', 'Spark', 'Conda', 'Relational Databases', 'Data Integration']","Causal Inference: Used to develop and validate models assessing social impact of community initiatives and public programs.; Regression Discontinuity: A statistical method applied within causal inference to interpret results from community impact analyses.; Propensity Score Matching: A technique used to reduce bias in observational studies for evaluating social programs.; Difference-in-Differences: A statistical approach employed to measure the effect of interventions on community outcomes.; Machine Learning: Applied to analyze large-scale datasets and generate insights for community investments and financial well-being.; Python: Programming language used for data collection, cleaning, and analysis from diverse sources.; R: Statistical programming language utilized for data analysis and modeling in community impact research.; SQL: Used to query and manage relational databases containing structured data relevant to the analyses.; AWS: Cloud environment supporting large-scale data storage and processing for analytics workflows.; H2O: Machine learning platform leveraged for scalable model development and validation.; Spark: Big data processing framework used to handle and analyze large datasets efficiently.; Conda: Package and environment management system facilitating reproducible data science workflows.; Relational Databases: Data storage systems used to organize and retrieve structured data for analysis.; Data Integration: Combining structured and unstructured data from multiple sources including government reports and surveys to enrich analysis."
jnQ35lpZQpqxX-EJAAAAAA==,Data Scientist Jobs,"Paradyme, a CATHEXIS Company is hiring a Data Scientist /ML Engineer to support mission critical programs.

Responsibilities:

The Data Scientist /ML Engineer will work directly with data scientists, software engineers, and subject matter experts in the definition of new analytics capabilities able to provide our federal customers with the information they need to make proper decisions and enable their digital transformation. Duties include:

- Research, design, implement, and deploy Machine Learning algorithms for enterprise applications.

- Assist and enable federal customers to build their own applications.

- Contribute to the design and implementation of new features.

Qualifications:

- Master's degree in Computer Science, Electrical Engineering, Statistics, or equivalent fields or Bachelor's degree in Computer Science, Electrical Engineering, Statistics, or equivalent fields with one year of relevant work experience.

- Excellent programming skills in Python.

- Applied Machine Learning experience (regression and classification, supervised, and unsupervised learning).

- Strong mathematical background (linear algebra, calculus, probability, and statistics).

- Experience with scalable ML (MapReduce, streaming).

- Ability to drive a project and work both independently and in a team.

- Smart, motivated, can-do attitude, and seeks to make a difference.

- Excellent verbal and written communication.

- Ability to obtain a U.S. security clearance preferred.

Nice to Have:

- MS or PhD in Computer Science, Electrical Engineering, Statistics, or equivalent fields.

- Real passion for developing team-oriented solutions to complex engineering problems.

- Thrive in an autonomous, empowering and exciting environment.

- Great verbal and written communication skills to collaborate multi-functionally and improve scalability.

- Interest in committing to a fun, friendly, expansive, and intellectually stimulating environment.

- Hands-on experience deploying and operating applications using IaaS and PaaS on major cloud providers, such as Amazon AWS, Microsoft Azure, or Google Cloud Services.

- Experience with deep learning, natural language processing, computer vision, or reinforcement learning.

- Conveys highly technical concepts and information in written form to technical and non-technical audiences.

- The ability to work on multiple concurrent projects is essential. Strong self -motivation and the ability to work with minimal supervision.

- Must be a team-oriented individual, energetic, result & delivery oriented, with a keen interest on quality and the ability to meet deadlines.

- Ability to work in an agile environment",2025-07-24T00:00:00.000Z,2025-07-25,"[""Master's degree in Computer Science, Electrical Engineering, Statistics, or equivalent fields or Bachelor's degree in Computer Science, Electrical Engineering, Statistics, or equivalent fields with one year of relevant work experience"", 'Excellent programming skills in Python', 'Applied Machine Learning experience (regression and classification, supervised, and unsupervised learning)', 'Strong mathematical background (linear algebra, calculus, probability, and statistics)', 'Experience with scalable ML (MapReduce, streaming)', 'Ability to drive a project and work both independently and in a team', 'Smart, motivated, can-do attitude, and seeks to make a difference', 'Excellent verbal and written communication', 'MS or PhD in Computer Science, Electrical Engineering, Statistics, or equivalent fields', 'Real passion for developing team-oriented solutions to complex engineering problems', 'Thrive in an autonomous, empowering and exciting environment', 'Great verbal and written communication skills to collaborate multi-functionally and improve scalability', 'Interest in committing to a fun, friendly, expansive, and intellectually stimulating environment', 'Hands-on experience deploying and operating applications using IaaS and PaaS on major cloud providers, such as Amazon AWS, Microsoft Azure, or Google Cloud Services', 'Experience with deep learning, natural language processing, computer vision, or reinforcement learning', 'Conveys highly technical concepts and information in written form to technical and non-technical audiences', 'The ability to work on multiple concurrent projects is essential', 'Strong self -motivation and the ability to work with minimal supervision', 'Must be a team-oriented individual, energetic, result & delivery oriented, with a keen interest on quality and the ability to meet deadlines', 'Ability to work in an agile environment']","['The Data Scientist /ML Engineer will work directly with data scientists, software engineers, and subject matter experts in the definition of new analytics capabilities able to provide our federal customers with the information they need to make proper decisions and enable their digital transformation', 'Research, design, implement, and deploy Machine Learning algorithms for enterprise applications', 'Assist and enable federal customers to build their own applications', 'Contribute to the design and implementation of new features']",True,"['Deep Learning', 'Natural Language Processing', 'Computer Vision', 'Reinforcement Learning']",Deep Learning: Experience with deep learning techniques applied to complex data problems such as computer vision and natural language processing.; Natural Language Processing: Applying NLP methods to analyze and interpret human language data as part of AI-related tasks.; Computer Vision: Using AI techniques to enable machines to interpret and process visual information.; Reinforcement Learning: Applying reinforcement learning algorithms for decision-making and autonomous agent development.,"['Machine Learning', 'Regression Models', 'Classification', 'Supervised Learning', 'Unsupervised Learning', 'Scalable Machine Learning', 'Python Programming', 'Mathematical Foundations', 'Cloud Computing Platforms', 'Agile Methodologies']","Machine Learning: Designing, implementing, and deploying machine learning algorithms including regression, classification, supervised, and unsupervised learning for enterprise applications.; Regression Models: Applied as part of machine learning experience to model relationships between variables for predictive analytics.; Classification: Used in supervised learning tasks to categorize data points into predefined classes.; Supervised Learning: Developing models trained on labeled data to make predictions or classifications.; Unsupervised Learning: Applying algorithms to find patterns or groupings in unlabeled data.; Scalable Machine Learning: Experience with scalable ML techniques such as MapReduce and streaming to handle large datasets efficiently.; Python Programming: Using Python as the primary programming language for implementing machine learning models and data analysis.; Mathematical Foundations: Strong background in linear algebra, calculus, probability, and statistics to support algorithm development and data analysis.; Cloud Computing Platforms: Deploying and operating applications using Infrastructure as a Service (IaaS) and Platform as a Service (PaaS) on AWS, Azure, or Google Cloud.; Agile Methodologies: Working in an agile environment to manage multiple concurrent projects and iterative development."
KoxF5LmD7llmq8RcAAAAAA==,Data Scientist - TS/SCI w/Poly Jobs,"The Data Scientist will deploy, fine-tune, and monitor production machine learning models in a production environment. Additionally, they will provide support in the areas of data extraction, transformation and load (ETL), data mapping, analytics, operations, databases, and maintenance of data and associated systems. As a member of the team, candidate will work in a multi-tasking, quick-paced, dynamic, process-improvement environment that requires experience with the principles of data science, data modeling, data mapping, data testing, data quality, and documentation preparation. This is a mission focused role requiring experience with deploying models in a production environment against real-time collection.

HOW A DATA SCIENTIST WILL MAKE AN IMPACT:
• Create and maintain custody of production machine learning models across a variety of tasks, including but not limited to audio extraction, object recognition, Natural Language Processing (NLP), and other generic classification tasks
• Optimize existing machine learning services to better utilize current GPU capabilities and assist with road mapping future GPU requirements
• Deploy machine learning models against streaming data, designed to provide near-real time analytics to augment decision making
• Improve data architecture decisions with data engineers to better stage data for continuous training models in production
• Provide support in the areas of data extraction, transformation and load (ETL), data mapping, analytics, operations, databases, and maintenance of data and associated systems

REQUIRED TECHNICAL SKILLS:
• Demonstrated experience with the following: Python, Cuda, Kubernetes, CI/CD. Apache Kafka, REST architecture, Open-AI, LLMs, NLP, YOLO/Object Recognition, Whisper/Audio processing
• Demonstrated experience translating data insights into tools or analytic capabilities that inform operational decisions and/or improve processes
• Demonstrated experience with relational databases (SQL, Oracle) and NoSQL databases (Elasticsearch, Neo4J, Redis)
• Demonstrated experience with GPU processing
• Demonstrated experience applying machine learning methodologies to build high-quality prediction models
• Familiar with servers operating systems; Windows, Linux, Distributed Computing, Blade Centers, and cloud infrastructure
• Familiar with database methodologies
• Familiar with Source code management and integration (ex - GitHub/GitLab, Jenkins, RunDeck)
• Familiar with Data Science frameworks such as Keras, Tensorflow, or Theano
• Ability to work well in a fast-paced, constantly evolving work environment with a focus on continual process improvement and a proactive approach to problem solving

WHAT YOU'LL NEED TO SUCCEED:
• The position requires an active TS/SCI with Polygraph security clearance
• The position requires fifteen (15+) years of related data science/statistical experience and three (3+) years of software engineering or data engineering experience
• The position requires Bachelor's or Technology degree in Engineering or a related specialized area/field, OR equivalent four (4) additional years job-related experience
• Excellent organizational, coordination, interpersonal and team building skills
• The position is on customer site

GDIT IS YOUR PLACE:
• 401K with company match
• Comprehensive health and wellness packages
• Internal mobility team dedicated to helping you own your career
• Professional growth opportunities including paid education and certifications
• Cutting-edge technology you can learn from
• Rest and recharge with paid vacation and holidays

#OpportunityOwned

#GDITCareers

#WeAreGDIT

#JET

#GDITEnhanced2025

Work Requirements",2025-07-25T17:00:00.000Z,2025-07-25,"['Demonstrated experience with the following: Python, Cuda, Kubernetes, CI/CD', 'Apache Kafka, REST architecture, Open-AI, LLMs, NLP, YOLO/Object Recognition, Whisper/Audio processing', 'Demonstrated experience translating data insights into tools or analytic capabilities that inform operational decisions and/or improve processes', 'Demonstrated experience with relational databases (SQL, Oracle) and NoSQL databases (Elasticsearch, Neo4J, Redis)', 'Demonstrated experience with GPU processing', 'Demonstrated experience applying machine learning methodologies to build high-quality prediction models', 'Familiar with servers operating systems; Windows, Linux, Distributed Computing, Blade Centers, and cloud infrastructure', 'Familiar with database methodologies', 'Familiar with Source code management and integration (ex - GitHub/GitLab, Jenkins, RunDeck)', 'Familiar with Data Science frameworks such as Keras, Tensorflow, or Theano', 'Ability to work well in a fast-paced, constantly evolving work environment with a focus on continual process improvement and a proactive approach to problem solving', 'The position requires an active TS/SCI with Polygraph security clearance', 'The position requires fifteen (15+) years of related data science/statistical experience and three (3+) years of software engineering or data engineering experience', ""The position requires Bachelor's or Technology degree in Engineering or a related specialized area/field, OR equivalent four (4) additional years job-related experience"", 'Excellent organizational, coordination, interpersonal and team building skills', 'The position is on customer site']","['The Data Scientist will deploy, fine-tune, and monitor production machine learning models in a production environment', 'Additionally, they will provide support in the areas of data extraction, transformation and load (ETL), data mapping, analytics, operations, databases, and maintenance of data and associated systems', 'As a member of the team, candidate will work in a multi-tasking, quick-paced, dynamic, process-improvement environment that requires experience with the principles of data science, data modeling, data mapping, data testing, data quality, and documentation preparation', 'This is a mission focused role requiring experience with deploying models in a production environment against real-time collection', 'Create and maintain custody of production machine learning models across a variety of tasks, including but not limited to audio extraction, object recognition, Natural Language Processing (NLP), and other generic classification tasks', 'Optimize existing machine learning services to better utilize current GPU capabilities and assist with road mapping future GPU requirements', 'Deploy machine learning models against streaming data, designed to provide near-real time analytics to augment decision making', 'Improve data architecture decisions with data engineers to better stage data for continuous training models in production', 'Provide support in the areas of data extraction, transformation and load (ETL), data mapping, analytics, operations, databases, and maintenance of data and associated systems']",True,"['Large Language Models', 'Natural Language Processing', 'Generative AI (OpenAI)', 'Object Recognition (YOLO)', 'Audio Processing (Whisper)', 'CUDA']",Large Language Models: Utilizing LLMs for natural language processing tasks such as text classification and audio transcription.; Natural Language Processing: Applying AI techniques to process and analyze human language data within machine learning models.; Generative AI (OpenAI): Incorporating OpenAI technologies to enhance AI capabilities in language and audio processing.; Object Recognition (YOLO): Using AI-based computer vision models to identify and classify objects in images or video.; Audio Processing (Whisper): Applying AI models for audio extraction and transcription tasks.; CUDA: Programming GPU acceleration specifically for deep learning and AI model optimization.,"['Machine Learning Models', 'Data Extraction, Transformation, and Load (ETL)', 'Data Mapping', 'Data Analytics', 'Relational Databases (SQL, Oracle)', 'NoSQL Databases (Elasticsearch, Neo4J, Redis)', 'GPU Processing', 'Data Science Frameworks (Keras, TensorFlow, Theano)', 'Data Modeling', 'Data Quality and Testing', 'Streaming Data Analytics', 'Python', 'Apache Kafka', 'CI/CD', 'Kubernetes', 'REST Architecture', 'Source Code Management (GitHub/GitLab, Jenkins, RunDeck)']","Machine Learning Models: Building, deploying, and fine-tuning predictive models to support classification and analytics tasks in production.; Data Extraction, Transformation, and Load (ETL): Supporting data workflows by extracting, transforming, and loading data to prepare it for analysis and model training.; Data Mapping: Ensuring data consistency and integration by mapping data between different systems and formats.; Data Analytics: Analyzing data to generate insights that inform operational decisions and improve processes.; Relational Databases (SQL, Oracle): Using structured query language databases to store and query structured data relevant to analytics and modeling.; NoSQL Databases (Elasticsearch, Neo4J, Redis): Utilizing non-relational databases for flexible data storage and retrieval in support of analytics and real-time applications.; GPU Processing: Leveraging GPU hardware to accelerate machine learning model training and inference.; Data Science Frameworks (Keras, TensorFlow, Theano): Employing frameworks to develop and deploy machine learning models efficiently.; Data Modeling: Designing data structures and schemas to support analytics and machine learning workflows.; Data Quality and Testing: Ensuring the accuracy and reliability of data used for analytics and model training.; Streaming Data Analytics: Deploying models to process and analyze data in near real-time from streaming sources.; Python: Primary programming language used for data manipulation, model development, and deployment.; Apache Kafka: Used for managing real-time data streams to support continuous model training and analytics.; CI/CD: Implementing continuous integration and deployment pipelines to automate model updates and delivery.; Kubernetes: Orchestrating containerized applications including machine learning models in production environments.; REST Architecture: Designing APIs to enable communication between machine learning services and other systems.; Source Code Management (GitHub/GitLab, Jenkins, RunDeck): Managing code repositories and automating build and deployment processes for data science projects."
qysGugpRKcn6GQU8AAAAAA==,Data Analyst Jobs,"Title
Data Analyst
Full-Time/Part-Time Full-Time Description
Cyber Intelligence Alliance (CIA) Joint Venture (JV) is seeking a Data Analyst (contingent upon award) to support federal client in supporting analysis of military operational data to identify trends, patterns and anomalies that can inform strategic decision-making. Activities and support includes preprocessing large datasets related to Army operations, logistics, personnel and intelligence for analysis. Tasks include conducting statistical analysis and data modeling to assess combat effectiveness, force readiness, and mission performance as well as developing dashboards and reports to visualize key performance indicators and metrics for leadership. Candidate will utilize machine learning algorithms for predictive modeling in areas such as threat assessment and risk analysis.
• Candidate shall possess skills and expertise in machine learning tools to select features, create, and optimize classifiers.
• Candidate shall possess demonstrable collegiate-level writing skills, demonstrated familiarity with the U.S. Army organization and regulations, and strong organization and communication skills.
• Candidate shall have the ability to communicate complex technical findings to a variety of audiences.
• Candidate shall possess demonstrate practical experience substantiating equivalent skills such as Structured Query Language, Microsoft Excel, R or Python statistical programming, Data Visualization, and Presentation Skills.
Requirements for this position shall include:
• Bachelor's degree or higher in a related field of study or equivalent experience
• Minimum of three (3) years of experience, one within DoD, working with big-data systems and developing production-level data models
• Secret Security Clearance Required
• Prior knowledge of Power BI, Tableau and Advana data science is preferred.
About the Organization Established in 2008, RiVidium, Inc. (dba TripleCyber) is a VA-Verified SDVOSB and an SBA-Certified 8(a) company. To prepare our clients for the future, RiVidium has balanced all parts of our organization to attract the finest employees in order to 'Strive to be the missing element defining tomorrow's technology'. RiVidium keeps pace and surpasses its competitors by meeting challenges of advancements in Logistics, Human Capital, Cyber, Intelligence & Technology. EOE Statement We are an equal employment opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status or any other characteristic protected by law. If you need a reasonable accommodation for any part of the employment process, please contact Human Resources (HR) at hr@rividium.com.
This position is currently accepting applications.",2025-07-25T00:00:00.000Z,2025-07-25,"['Candidate shall possess skills and expertise in machine learning tools to select features, create, and optimize classifiers', 'Candidate shall possess demonstrable collegiate-level writing skills, demonstrated familiarity with the U.S. Army organization and regulations, and strong organization and communication skills', 'Candidate shall have the ability to communicate complex technical findings to a variety of audiences', 'Candidate shall possess demonstrate practical experience substantiating equivalent skills such as Structured Query Language, Microsoft Excel, R or Python statistical programming, Data Visualization, and Presentation Skills', ""Bachelor's degree or higher in a related field of study or equivalent experience"", 'Minimum of three (3) years of experience, one within DoD, working with big-data systems and developing production-level data models', 'Secret Security Clearance Required', 'About the Organization Established in 2008, RiVidium, Inc']","['Activities and support includes preprocessing large datasets related to Army operations, logistics, personnel and intelligence for analysis', 'Tasks include conducting statistical analysis and data modeling to assess combat effectiveness, force readiness, and mission performance as well as developing dashboards and reports to visualize key performance indicators and metrics for leadership', 'Candidate will utilize machine learning algorithms for predictive modeling in areas such as threat assessment and risk analysis']",True,[],,"['Data Preprocessing', 'Statistical Analysis', 'Data Modeling', 'Dashboards and Data Visualization', 'Machine Learning', 'Feature Selection', 'Classification Algorithms', 'SQL', 'Python', 'R', 'Power BI', 'Tableau', 'Big Data Systems']","Data Preprocessing: Involves cleaning and preparing large datasets related to Army operations, logistics, personnel, and intelligence for analysis.; Statistical Analysis: Used to assess combat effectiveness, force readiness, and mission performance through quantitative evaluation.; Data Modeling: Developing models to represent and analyze military operational data for strategic insights.; Dashboards and Data Visualization: Creating visual reports and dashboards to display key performance indicators and metrics for leadership decision-making.; Machine Learning: Applying machine learning algorithms for predictive modeling in threat assessment and risk analysis.; Feature Selection: Selecting relevant features to improve classifier performance in machine learning models.; Classification Algorithms: Building and optimizing classifiers to categorize data for predictive purposes.; SQL: Using Structured Query Language to query and manage large datasets.; Python: Utilizing Python for statistical programming and data analysis.; R: Employing R for statistical computing and data modeling.; Power BI: Using Power BI to develop interactive dashboards and reports.; Tableau: Leveraging Tableau for data visualization and dashboard creation.; Big Data Systems: Experience working with large-scale data systems within the Department of Defense environment."
xeT0sK51fE3pdAz4AAAAAA==,Data Scientist :::: Video / F2F (maybe) Prefer face to face ::: Local in MD,"Data Scientist

Columbia, MD

12+ Months

Technical Skills & Qualifications:
• Bachelor s or Master s degree in Data Science, Statistics, Computer Science, Transportation Engineering, or a related quantitative field.
• 3-5 years of experience working as a data scientist or data analyst, preferably in a transit, transportation, or public sector environment.
• Strong proficiency in Python or R for data analysis, statistical modeling, and machine learning.
• Experience with SQL for database querying, manipulation, and data extraction.
• Familiarity with transit data standards such as GTFS, AVL/CAD, APC (Automated Passenger Counters), and AVA systems.
• Experience with data visualization tools such as Power BI, or equivalent.",2025-07-02T00:00:00.000Z,2025-07-25,"['12+ Months', 'Bachelor s or Master s degree in Data Science, Statistics, Computer Science, Transportation Engineering, or a related quantitative field', '3-5 years of experience working as a data scientist or data analyst, preferably in a transit, transportation, or public sector environment', 'Strong proficiency in Python or R for data analysis, statistical modeling, and machine learning', 'Experience with SQL for database querying, manipulation, and data extraction', 'Familiarity with transit data standards such as GTFS, AVL/CAD, APC (Automated Passenger Counters), and AVA systems', 'Experience with data visualization tools such as Power BI, or equivalent']",,True,[],,"['Python', 'R', 'SQL', 'Statistical Modeling', 'Machine Learning', 'Power BI', 'Transit Data Standards']","Python: Used for data analysis, statistical modeling, and machine learning tasks in the transit and transportation domain.; R: Applied for statistical modeling and data analysis relevant to transportation data.; SQL: Utilized for querying, manipulating, and extracting data from databases related to transit systems.; Statistical Modeling: Employed to analyze transit data and build predictive or descriptive models.; Machine Learning: Applied to develop models that support data-driven decision making in transportation.; Power BI: Used for creating data visualizations and dashboards to communicate insights from transit data.; Transit Data Standards: Knowledge of GTFS, AVL/CAD, APC, and AVA systems to handle and interpret transportation data effectively."
4WuacWaNPYl9yRqIAAAAAA==,"Data Scientist - Computer Vision, WWPS ProServe Jobs","DESCRIPTION

The Amazon Web Services (AWS) US Federal Professional Services team is looking for a passionate and talented Computer Vision Data Scientist who will collaborate with other scientists and engineers to develop computer vision and remote sensing capabilities to address customer use-cases at enterprise scale. If you are excited to work with massive amounts of data and computer vision models to solve real world challenges, this is the position for you! We work directly with public sector entities, medical centers, and non-profits to achieve their mission goals through the adoption of Machine Learning (ML) methods. We apply computer vision to numerous imagery and sensor types, such as satellite imagery, medical imaging, aerial video, synthetic aperture radar, X-Ray, and more! Amazon has been investing in Machine Learning for decades, and by joining AWS you'll join a community of scientists and engineers developing leading edge solutions for enterprise-scale data science applications.

In this customer facing position, you will architect and implement innovative, AWS Cloud-native ML solutions, providing direct and immediate impact for your customers. You will take the lead in planning, designing, and running experiments, researching new algorithms, and will work closely with talented data scientists and engineers to put algorithms and models into practice to help solve our customers' most challenging problems. You will also guide teams in the development of new solutions and aid customers in adopting AWS ML capabilities.

This position may involve local travel up to 25%.

This position requires that the candidate selected must currently possess and maintain an active TS/SCI security clearance. The position further requires that, after start, the selected candidate have the ability to obtain and maintain an active TS/SCI security clearance with polygraph or commensurate clearance for each government agency for which they perform AWS work.

Key job responsibilities
As an experienced technology professional, you will be responsible for:
- Engage directly with customers to understand their business problems and aid them in implementing their ML solutions.
- Deliver Machine Learning projects from beginning to end. This includes understanding the business need, planning the project, aggregating & exploring data, building & validating predictive models, and deploying completed ML capabilities on the AWS Cloud to deliver business impact for the customer.
- Use Deep Learning frameworks like PyTorch and Tensorflow to help our customers build computer vision models.
- Work on TB scale datasets, creating scalable, robust and accurate computer vision systems in versatile application fields.
- Work with other Professional Services Data Scientists and Machine Learning Engineers to help our customers operationalize ML capabilities
- Collaborate with Cloud Architects to build secure, robust, and easy-to-deploy cloud-native machine learning solutions.
- Work closely with customer account teams, scientific research teams and product engineering teams to optimize model implementations and deploy internal algorithms for your customers.
- Assist customers with Machine Learning Operations (MLOps) workflows such as model deployment, retraining, testing, and performance monitoring.
- Experience applying best practices from core Software Development activities to Machine Learning (deployability, unit testing, well structured extensible software, etc.)

About the team
Diverse Experiences - AWS values diverse experiences. Even if you do not meet all of the preferred qualifications and skills listed in the job below, we encourage candidates to apply. If your career is just starting, hasn't followed a traditional path, or includes alternative experiences, don't let it stop you from applying.

Why AWS? - Amazon Web Services (AWS) is the world's most comprehensive and broadly adopted cloud platform. We pioneered cloud computing and never stopped innovating - that's why customers from the most successful startups to Global 500 companies trust our robust suite of products and services to power their businesses.

Inclusive Team Culture - Here at AWS, it's in our nature to learn and be curious. Our employee-led affinity groups foster a culture of inclusion that empower us to be proud of our differences. Ongoing events and learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (diversity) conferences, inspire us to never stop embracing our uniqueness.

Mentorship & Career Growth - We're continuously raising our performance bar as we strive to become Earth's Best Employer. That's why you'll find endless knowledge-sharing, mentorship and other career-advancing resources here to help you develop into a better-rounded professional.

Work/Life Balance - We value work-life harmony. Achieving success at work should never come at the expense of sacrifices at home, which is why we strive for flexibility as part of our working culture. When we feel supported in the workplace and at home, there's nothing we can't achieve in the cloud.

BASIC QUALIFICATIONS

- Bachelor's degree in Computer Science, Engineering, related field, or equivalent experience
- 3+ years of data scientist experience, data querying languages (e.g. SQL), scripting languages (e.g. Python) or statistical/mathematical software (e.g. R, SAS, Matlab, etc.) experience
- 3+ years of machine learning/statistical modeling data analysis tools and techniques, and parameters that affect their performance experience
- Experience applying theoretical models in an applied environment
- Current, active US Government Security Clearance of TS/SCI or above

PREFERRED QUALIFICATIONS

- 3+ years of experience handling terabyte-scale datasets
- AWS Certifications, for example AWS Solution Architect Associate/Professional, ML Specialty, or Developer Associate
- Experience working with at least one of the following industry standard formats in an imagery domain: Satellite Imagery (NITF, GeoTIFF, SICD, etc.), Motion Imagery (commercial and USG FMV specs), or medical imagery (e.g. DICOM)
- Hands-on experience with state-of-the-art object detection approaches
- Experience managing multiple AWS and ML Environments through Infrastructure as code (Cloudformation, Cloud Development Kit, Terraform, Pulumi, etc.)
- Experience containerizing/deploying computer vision models, specifically neural networks, into production environments

Amazon is an equal opportunity employer and does not discriminate on the basis of protected veteran status, disability, or other legally protected status.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you're applying in isn't listed, please contact your Recruiting Partner.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $125,500/year in our lowest geographic market up to $212,800/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits . This position will remain posted until filled. Applicants should apply via our internal or external career site.",2025-07-20T00:00:00.000Z,2025-07-25,"['This position requires that the candidate selected must currently possess and maintain an active TS/SCI security clearance', 'The position further requires that, after start, the selected candidate have the ability to obtain and maintain an active TS/SCI security clearance with polygraph or commensurate clearance for each government agency for which they perform AWS work', ""Bachelor's degree in Computer Science, Engineering, related field, or equivalent experience"", '3+ years of data scientist experience, data querying languages (e.g. SQL), scripting languages (e.g. Python) or statistical/mathematical software (e.g. R, SAS, Matlab, etc.) experience', '3+ years of machine learning/statistical modeling data analysis tools and techniques, and parameters that affect their performance experience', 'Experience applying theoretical models in an applied environment', 'Current, active US Government Security Clearance of TS/SCI or above', 'Experience managing multiple AWS and ML Environments through Infrastructure as code (Cloudformation, Cloud Development Kit, Terraform, Pulumi, etc.)', 'Experience containerizing/deploying computer vision models, specifically neural networks, into production environments']","[""You will take the lead in planning, designing, and running experiments, researching new algorithms, and will work closely with talented data scientists and engineers to put algorithms and models into practice to help solve our customers' most challenging problems"", 'You will also guide teams in the development of new solutions and aid customers in adopting AWS ML capabilities', 'This position may involve local travel up to 25%', 'Engage directly with customers to understand their business problems and aid them in implementing their ML solutions', 'Deliver Machine Learning projects from beginning to end', 'This includes understanding the business need, planning the project, aggregating & exploring data, building & validating predictive models, and deploying completed ML capabilities on the AWS Cloud to deliver business impact for the customer', 'Use Deep Learning frameworks like PyTorch and Tensorflow to help our customers build computer vision models', 'Work on TB scale datasets, creating scalable, robust and accurate computer vision systems in versatile application fields', 'Work with other Professional Services Data Scientists and Machine Learning Engineers to help our customers operationalize ML capabilities', 'Collaborate with Cloud Architects to build secure, robust, and easy-to-deploy cloud-native machine learning solutions', 'Work closely with customer account teams, scientific research teams and product engineering teams to optimize model implementations and deploy internal algorithms for your customers', 'Assist customers with Machine Learning Operations (MLOps) workflows such as model deployment, retraining, testing, and performance monitoring', 'Experience applying best practices from core Software Development activities to Machine Learning (deployability, unit testing, well structured extensible software, etc.)', 'Hands-on experience with state-of-the-art object detection approaches']",True,[],,"['Computer Vision', 'Machine Learning', 'Deep Learning Frameworks', 'Predictive Modeling', 'Data Querying Languages', 'Scripting Languages', 'Statistical/Mathematical Software', 'Handling Terabyte-Scale Datasets', 'Object Detection', 'Machine Learning Operations (MLOps)', 'Infrastructure as Code', 'Cloud-Native Machine Learning Solutions', 'Model Deployment']","Computer Vision: Used to develop models that analyze imagery and sensor data such as satellite and medical images to solve customer problems.; Machine Learning: Applied to build predictive models and solutions for enterprise-scale data science applications.; Deep Learning Frameworks: PyTorch and TensorFlow are used to build and train computer vision models for customers.; Predictive Modeling: Involves building and validating models to predict outcomes based on large datasets.; Data Querying Languages: SQL is used to aggregate and explore data for analysis and model building.; Scripting Languages: Python is used for data manipulation, analysis, and model development.; Statistical/Mathematical Software: Tools like R, SAS, and Matlab are used for statistical modeling and data analysis.; Handling Terabyte-Scale Datasets: Experience working with very large datasets to build scalable and robust computer vision systems.; Object Detection: Applied state-of-the-art methods to identify and locate objects within images.; Machine Learning Operations (MLOps): Involves workflows such as model deployment, retraining, testing, and performance monitoring.; Infrastructure as Code: Tools like CloudFormation, Cloud Development Kit, Terraform, and Pulumi are used to manage AWS and ML environments.; Cloud-Native Machine Learning Solutions: Building and deploying ML models on AWS cloud infrastructure for scalability and security.; Model Deployment: Containerizing and deploying computer vision models, including neural networks, into production environments."
XBzYIxr04OGMaO3bAAAAAA==,Data Engineer,"Description

About Us:

eSimplicity is modern digital services company that work across government, partnering with our clients to improve the lives and ensure the security of all Americans—from soldiers and veteran to kids and the elderly, and defend national interests on the battlefield. Our engineers, designers and strategist cut through complexity to create intuitive products and services that equip Federal agencies with solutions to courageously transform today for a better tomorrow for all Americans.

This position is contingent upon award.

Role Overview:

We are seeking a highly skilled Data Engineer III to help evaluate and design robust data integration solutions for large-scale, disparate datasets spanning multiple platforms and infrastructure types, including cloud-based and potentially undefined or evolving environments. This role is critical in identifying optimal data ingestion, normalization, and transformation strategies while collaborating with cross-functional teams to ensure data accessibility, reliability, and security across systems.

Responsibilities:
• Assess, design, and implement solutions for integrating large-scale datasets from disparate systems, including unknown or undefined data environments.
• Collaborate with end users and data stakeholders to understand requirements and educate them on Spark-based processing in Databricks, using SQL, Python, and/or R.
• Partner with data engineers and data scientists to extract and transform data from external sources using APIs, Kafka, or Kinesis, and build automated, resilient data pipelines.
• Write comprehensive unit, integration, and functional tests for critical data workflows.
• Create and deliver clear, concise technical presentations and documentation to both technical and non-technical audiences.
• Stay informed on the latest cloud technologies, data integration patterns, and industry best practices to drive innovation and process improvements.
• Manage deliverables and project timelines, ensuring high-quality outcomes.
• Provide timely updates to leadership and contribute to planning and prioritization discussions.

Required Qualifications:
• All candidates must pass public trust clearance through the U.S. Federal Government. This requires candidates to either be U.S. citizens or pass clearance through the Foreign National Government System which will require that candidates have lived within the United States for at least 3 out of the previous 5 years, have a valid and non-expired passport from their country of birth and appropriate VISA/work permit documentation.
• Bachelor’s degree in Computer Science, Software Engineering, Data Science, Statistics, or related technical field.
• 10+ years of experience in software/data engineering, including data pipelines, data modeling, data integration, and data management.
• Expertise in data lakes, data warehouses, data meshes, data modeling and data schemas (star, snowflake…).
• Strong expertise in SQL, Python, and/or R, with applied experience in Apache Spark and large-scale processing using PySpark or Sparklyr.
• Experience with Databricks in a production environment.
• Strong experience with AWS cloud-native data services, including S3, Glue, Athena, and Lambda.
• Strong proficiency with GitHub and GitHub Actions, including test-driven development.
• Proven ability to work with incomplete or ambiguous data infrastructure and design integration strategies.
• Excellent analytical, organizational, and problem-solving skills.
• Strong communication skills, with the ability to translate complex concepts across technical and business teams.
• Proven experience working with petabyte-level data systems.

Requirements

Desired Qualifications:
• Experience working with healthcare data, especially CMS (Centers for Medicare & Medicaid Services) datasets.
• CMS and Healthcare Expertise: In-depth knowledge of CMS regulations and experience with complex healthcare projects; in particular, data infrastructure related projects or similar.
• Demonstrated success providing support within the CMS OIT environment, ensuring alignment with organizational goals and technical standards.
• Demonstrated experience and familiarity with CMS OIT data systems (e.g. IDR-C, CCW, EDM, etc.)
• Experience with cloud platform services: AWS and Azure.
• Experience with streaming data (Kafka, Kinesis, Pub/Sub).
• Familiarity with data governance, metadata management, and data quality practices.

Working Environment:
eSimplicity supports a hybrid work environment operating within the Eastern time zone so we can work with and respond to our government clients. Expected hours are 9:00 AM to 5:00 PM Eastern unless otherwise directed by your manager.

Occasional travel for training and project meetings. It is estimated to be less than 25% per year.

Benefits:
We offer highly competitive salaries and full healthcare benefits.

Equal Employment Opportunity:
eSimplicity is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, religion, color, national origin, gender, age, status as a protected veteran, sexual orientation, gender identity, or status as a qualified individual with a disability.",2025-07-23T00:00:00.000Z,2025-07-25,"['All candidates must pass public trust clearance through the U.S. Federal Government', 'This requires candidates to either be U.S. citizens or pass clearance through the Foreign National Government System which will require that candidates have lived within the United States for at least 3 out of the previous 5 years, have a valid and non-expired passport from their country of birth and appropriate VISA/work permit documentation', 'Bachelor’s degree in Computer Science, Software Engineering, Data Science, Statistics, or related technical field', '10+ years of experience in software/data engineering, including data pipelines, data modeling, data integration, and data management', 'Expertise in data lakes, data warehouses, data meshes, data modeling and data schemas (star, snowflake…)', 'Strong expertise in SQL, Python, and/or R, with applied experience in Apache Spark and large-scale processing using PySpark or Sparklyr', 'Experience with Databricks in a production environment', 'Strong experience with AWS cloud-native data services, including S3, Glue, Athena, and Lambda', 'Strong proficiency with GitHub and GitHub Actions, including test-driven development', 'Proven ability to work with incomplete or ambiguous data infrastructure and design integration strategies', 'Excellent analytical, organizational, and problem-solving skills', 'Strong communication skills, with the ability to translate complex concepts across technical and business teams', 'Proven experience working with petabyte-level data systems', 'IDR-C, CCW, EDM, etc.)', 'Experience with cloud platform services: AWS and Azure', 'Experience with streaming data (Kafka, Kinesis, Pub/Sub)', 'Familiarity with data governance, metadata management, and data quality practices', 'It is estimated to be less than 25% per year']","['We are seeking a highly skilled Data Engineer III to help evaluate and design robust data integration solutions for large-scale, disparate datasets spanning multiple platforms and infrastructure types, including cloud-based and potentially undefined or evolving environments', 'This role is critical in identifying optimal data ingestion, normalization, and transformation strategies while collaborating with cross-functional teams to ensure data accessibility, reliability, and security across systems', 'Assess, design, and implement solutions for integrating large-scale datasets from disparate systems, including unknown or undefined data environments', 'Collaborate with end users and data stakeholders to understand requirements and educate them on Spark-based processing in Databricks, using SQL, Python, and/or R', 'Partner with data engineers and data scientists to extract and transform data from external sources using APIs, Kafka, or Kinesis, and build automated, resilient data pipelines', 'Write comprehensive unit, integration, and functional tests for critical data workflows', 'Create and deliver clear, concise technical presentations and documentation to both technical and non-technical audiences', 'Stay informed on the latest cloud technologies, data integration patterns, and industry best practices to drive innovation and process improvements', 'Manage deliverables and project timelines, ensuring high-quality outcomes', 'Provide timely updates to leadership and contribute to planning and prioritization discussions', 'Expected hours are 9:00 AM to 5:00 PM Eastern unless otherwise directed by your manager', 'Occasional travel for training and project meetings']",False,[],,"['Data Integration', 'Data Pipelines', 'Apache Spark', 'Databricks', 'SQL', 'Python', 'R', 'AWS Cloud Data Services', 'Data Lakes', 'Data Warehouses', 'Data Mesh', 'Data Modeling', 'Streaming Data', 'GitHub and GitHub Actions', 'Test-Driven Development', 'Data Governance', 'Healthcare Data (CMS Datasets)', 'Cloud Platforms (AWS and Azure)']","Data Integration: Designing and implementing solutions to combine large-scale datasets from disparate and evolving environments.; Data Pipelines: Building automated, resilient workflows to extract, transform, and load data from various sources including APIs, Kafka, and Kinesis.; Apache Spark: Using Spark-based processing in Databricks for large-scale data transformation and analysis.; Databricks: A cloud platform used for running Apache Spark workloads in production environments.; SQL: Querying and managing data within relational databases and data warehouses.; Python: Programming language used for data processing, scripting, and integration tasks.; R: Statistical programming language applied for data analysis and transformation.; AWS Cloud Data Services: Utilizing AWS services such as S3, Glue, Athena, and Lambda for cloud-native data storage, processing, and querying.; Data Lakes: Managing large-scale storage repositories that hold raw data in native formats.; Data Warehouses: Structured storage systems optimized for query and analysis of integrated data.; Data Mesh: A decentralized approach to data architecture promoting domain-oriented data ownership and governance.; Data Modeling: Designing data schemas such as star and snowflake to organize and structure data effectively.; Streaming Data: Processing real-time data streams using platforms like Kafka, Kinesis, and Pub/Sub.; GitHub and GitHub Actions: Version control and CI/CD tools used to manage code and automate testing and deployment.; Test-Driven Development: Writing unit, integration, and functional tests to ensure reliability of data workflows.; Data Governance: Practices to ensure data quality, metadata management, and compliance within data systems.; Healthcare Data (CMS Datasets): Experience working with complex healthcare datasets and regulatory requirements from CMS.; Cloud Platforms (AWS and Azure): Utilizing cloud infrastructure and services from AWS and Azure for data engineering tasks."
sddKJVxz0FQ33rHEAAAAAA==,Geospatial Data Scientist / Machine Learning Engineer (TS cleara Jobs,"Figure Eight Federal (F8F): Leading the Future of AI Training Data

Figure Eight Federal (F8F) provides accurate and reliable human annotated datasets that fuel AI and machine learning for some of the world's biggest brands. With more than 25 years of industry knowledge, F8F's technology powers many of the AI interactions we experience every day. Our solutions and expertise empower our clients to achieve their AI goals and make a significant impact in their industry.

We are seeking an exceptional Geospatial Data Scientist (GDS) to join our team at the cutting edge of data focused geospatial analytics. This role sits at the critical intersection of remote sensing, computer vision, machine learning, and data science. The ideal candidate will possess advanced knowledge of raster-level geospatial data, comprehensive understanding of collection metadata, and expertise in various sensing phenomenologies including Electro-Optical (EO), Infrared (IR), and Synthetic Aperture Radar (SAR). This position is pivotal in bridging the gap between geospatial data expertise and machine learning applications.

Responsibilities:
• Analyze and process complex geospatial datasets from multiple sensing modalities (EO, IR, SAR)
• Evaluate dataset quality, coverage, and metadata to determine suitability for ML applications
• Develop and implement innovative data preparation strategies for geospatial machine learning
• Design and execute validation methods for geospatial data quality assurance
• Develop automated processes for geospatial data integration and harmonization
• Generate comprehensive documentation of data characteristics, limitations, and potential biases
• Stay current with emerging trends and technologies in remote sensing and geospatial data science
• Provide technical consultation on remote sensing capabilities and limitations for project planning
• Other duties as assigned

Qualifications:
• Bachelor's degree in Remote Sensing, GIS, Computer Science, Geospatial Science, Data Science, or related field (additional years of experience may be substituted for degree)
• 3+ years of experience working with remote sensing data in analytical applications
• Demonstrable knowledge of EO, IR, and/or SAR sensing phenomenologies and their unique characteristics
• Strong programming skills in Python or R, with experience using geospatial libraries (e.g., GDAL, GeoPandas)
• Working knowledge of computer vision techniques applied to satellite/aerial imagery
• Proficiency with geospatial metadata standards and their importance in analysis
• Experience evaluating dataset suitability for ML training and deployment
• Experience with containerization (Docker) and workflow automation for geospatial pipelines
• Strong ability to visualize data for consumption by both technical and non-technical audiences
• Active Top Secret security clearance

Preferred Qualifications:
• Master's degree in Remote Sensing, Computer Science, Geospatial Science, Data Science, or related field
• Experience with machine learning frameworks (TensorFlow, PyTorch) and their application to geospatial data
• Experience with GIS tools such as QGIS, ArcGIS, etc.
• Knowledge of deep learning architectures specifically designed for remote sensing data
• Familiarity with hyperspectral and LiDAR data processing
• Experience with time-series analysis of satellite imagery
• Understanding of uncertainty quantification in geospatial data and propagation into ML models
• Experience with cloud-based geospatial computing (AWS, Google Earth Engine, Microsoft Planetary Computer)",2025-07-25T01:00:00.000Z,2025-07-25,"['The ideal candidate will possess advanced knowledge of raster-level geospatial data, comprehensive understanding of collection metadata, and expertise in various sensing phenomenologies including Electro-Optical (EO), Infrared (IR), and Synthetic Aperture Radar (SAR)', 'This position is pivotal in bridging the gap between geospatial data expertise and machine learning applications', ""Bachelor's degree in Remote Sensing, GIS, Computer Science, Geospatial Science, Data Science, or related field (additional years of experience may be substituted for degree)"", '3+ years of experience working with remote sensing data in analytical applications', 'Demonstrable knowledge of EO, IR, and/or SAR sensing phenomenologies and their unique characteristics', 'Strong programming skills in Python or R, with experience using geospatial libraries (e.g., GDAL, GeoPandas)', 'Working knowledge of computer vision techniques applied to satellite/aerial imagery', 'Proficiency with geospatial metadata standards and their importance in analysis', 'Experience evaluating dataset suitability for ML training and deployment', 'Experience with containerization (Docker) and workflow automation for geospatial pipelines', 'Strong ability to visualize data for consumption by both technical and non-technical audiences', 'Active Top Secret security clearance']","['This role sits at the critical intersection of remote sensing, computer vision, machine learning, and data science', 'Analyze and process complex geospatial datasets from multiple sensing modalities (EO, IR, SAR)', 'Evaluate dataset quality, coverage, and metadata to determine suitability for ML applications', 'Develop and implement innovative data preparation strategies for geospatial machine learning', 'Design and execute validation methods for geospatial data quality assurance', 'Develop automated processes for geospatial data integration and harmonization', 'Generate comprehensive documentation of data characteristics, limitations, and potential biases', 'Stay current with emerging trends and technologies in remote sensing and geospatial data science', 'Provide technical consultation on remote sensing capabilities and limitations for project planning', 'Other duties as assigned']",True,"['Deep Learning', 'Computer Vision']",Deep Learning: Using deep learning architectures and frameworks like TensorFlow and PyTorch to develop models for geospatial data analysis.; Computer Vision: Applying AI-driven computer vision techniques to interpret satellite and aerial imagery within geospatial contexts.,"['Geospatial Data Analysis', 'Remote Sensing', 'Machine Learning', 'Data Preparation and Validation', 'Geospatial Metadata Standards', 'Computer Vision', 'Python and R Programming', 'Containerization and Workflow Automation', 'Geospatial Data Visualization', 'Machine Learning Frameworks', 'GIS Tools', 'Deep Learning for Remote Sensing', 'Hyperspectral and LiDAR Data Processing', 'Time-Series Analysis', 'Uncertainty Quantification', 'Cloud-Based Geospatial Computing']","Geospatial Data Analysis: Analyzing and processing complex geospatial datasets from multiple sensing modalities such as Electro-Optical, Infrared, and Synthetic Aperture Radar.; Remote Sensing: Utilizing knowledge of remote sensing data and sensing phenomenologies to support analytical applications and machine learning.; Machine Learning: Applying machine learning techniques to geospatial data for training and deployment purposes.; Data Preparation and Validation: Developing data preparation strategies and validation methods to ensure geospatial data quality and suitability for ML applications.; Geospatial Metadata Standards: Using metadata standards to evaluate dataset quality, coverage, and to support data integration and harmonization.; Computer Vision: Applying computer vision techniques to satellite and aerial imagery within geospatial data contexts.; Python and R Programming: Employing Python or R programming languages with geospatial libraries such as GDAL and GeoPandas for data processing and analysis.; Containerization and Workflow Automation: Using Docker and automation tools to create reproducible and efficient geospatial data pipelines.; Geospatial Data Visualization: Visualizing geospatial data effectively for both technical and non-technical stakeholders.; Machine Learning Frameworks: Experience with frameworks like TensorFlow and PyTorch applied to geospatial data for model development.; GIS Tools: Utilizing GIS software such as QGIS and ArcGIS for geospatial data analysis and visualization.; Deep Learning for Remote Sensing: Applying deep learning architectures specifically designed for processing remote sensing data.; Hyperspectral and LiDAR Data Processing: Handling specialized geospatial data types like hyperspectral and LiDAR for enhanced analysis.; Time-Series Analysis: Analyzing temporal sequences of satellite imagery to extract trends and patterns.; Uncertainty Quantification: Assessing and propagating uncertainty in geospatial data through machine learning models.; Cloud-Based Geospatial Computing: Leveraging cloud platforms such as AWS, Google Earth Engine, and Microsoft Planetary Computer for scalable geospatial data processing."
sAtX1osX8LlDyT1_AAAAAA==,Data Scientist 3,"Are you VIGILANT about your career? RealmOne definitely is!

RealmOne was built on the principle that people matter first and foremost. We believe in providing a strong work/life balance by investing in our employees and encouraging professional and personal growth. We do this by offering exceptional benefits, flexible schedules, and the tools necessary to achieve success through paid training, mentoring, and the opportunity to work alongside top-notch security professionals.

Join us on this journey as we execute this new mission-critical contract providing Cybersecurity Expertise and Risk Management!

Your effort and expertise are crucial to the success and execution of this impactful mission that is critical in ensuring mission success through Data Scientists, Cryptologic Computer Scientists, Cryptanalytic Computer Scientists, Cryptologic Cyber Planners, Intrusion Analysts, Protocol Analysts, Signals Analysts and Reverse Engineers by improving, protecting, and defending our Nation's Security.

Job Description:

We are seeking a Data Scientist proficient in Python and experienced in automating workflows, data manipulation, and visualization using Jupyter Notebooks. This role involves leveraging Python expertise to streamline processes and create insightful visualizations for data-driven decision-making.

The Level 3 Data Scientist shall possess the following capabilities:
• Foundations: (Mathematical, Computational, Statistical)
• Data Processing: (Data management and curation, data description and visualization, workflow and reproducibility)
• Modeling, Inference, and Prediction: (Data modeling and assessment, domain-specific considerations)
• Devise strategies for extracting meaning and value from large datasets. Make and communicate principled conclusions from data using elements of mathematics, statistics, computer science, and application specific knowledge. Through analytic modeling, statistical analysis, programming, and/or another appropriate scientific method, develop and implement qualitative and quantitative methods for characterizing, exploring, and assessing large datasets in various states of organization, cleanliness, and structure that account for the unique features and limitations inherent in DOD data holdings. Translate practical mission needs and analytic questions related to large datasets into technical requirements and, conversely, assist others with drawing appropriate conclusions from the analysis of such data. Effectively communicate complex technical information to non-technical audiences. Make informed recommendations regarding competing technical solutions by maintaining awareness of the constantly shifting DOD collection, processing, storage and analytic capabilities and limitations.

Qualifications:
• Bachelor's Degree with 10 years of relevant experience
• Associates degree with 12 years of relevant experience
• Bachelor'sDegree must be in Mathematics, Applied Mathematics Statistics, Applied Statistics, Machine learning, Data Science, Operations Research, or Computer Science or a degree in a related field (Computer Information Systems, Engineering), a degree in the physical/hard sciences (e.g. physics, chemistry, biology, astronomy), or other science disciplines with a substantial computational component (i.e. behavioral, social, or life) may be considered if it included a concentration of coursework (5 or more courses) in advanced Mathematics (typically 300 level or higher, such as linear algebra, probability and statistics, machine learning) and/or computer science (e.g. algorithms, programming, , data structures, data mining, artificial intelligence). College-level requirement, or upper-level math courses designated as elementary or basic do not count. Note: A broader range of degrees will be considered if accompanied by a Certificate in Data Science from an accredited college/university.
• Relevant experience must be in designing/implementing machine learning, data science, advanced analytical algorithms, programming (skill in at least one high-level language (e.g. Python)), statistical analysis (e.g. variability, sampling error, inference, hypothesis testing, EDA, application of linear models), data management (e.g. data cleaning and transformation), data mining, data modeling and assessment, artificial intelligence, and/or software engineering. Experience in more than one area is strongly preferred.

Position requires active Security Clearance with appropriate Polygraph",2025-06-26T00:00:00.000Z,2025-07-25,"['We are seeking a Data Scientist proficient in Python and experienced in automating workflows, data manipulation, and visualization using Jupyter Notebooks', 'Foundations: (Mathematical, Computational, Statistical)', 'Data Processing: (Data management and curation, data description and visualization, workflow and reproducibility)', 'Modeling, Inference, and Prediction: (Data modeling and assessment, domain-specific considerations)', 'Devise strategies for extracting meaning and value from large datasets', ""Bachelor's Degree with 10 years of relevant experience"", 'Associates degree with 12 years of relevant experience', ""Bachelor'sDegree must be in Mathematics, Applied Mathematics Statistics, Applied Statistics, Machine learning, Data Science, Operations Research, or Computer Science or a degree in a related field (Computer Information Systems, Engineering), a degree in the physical/hard sciences (e.g. physics, chemistry, biology, astronomy), or other science disciplines with a substantial computational component (i.e. behavioral, social, or life) may be considered if it included a concentration of coursework (5 or more courses) in advanced Mathematics (typically 300 level or higher, such as linear algebra, probability and statistics, machine learning) and/or computer science (e.g. algorithms, programming, , data structures, data mining, artificial intelligence)"", 'College-level requirement, or upper-level math courses designated as elementary or basic do not count', 'Note: A broader range of degrees will be considered if accompanied by a Certificate in Data Science from an accredited college/university', 'Relevant experience must be in designing/implementing machine learning, data science, advanced analytical algorithms, programming (skill in at least one high-level language (e.g. Python)), statistical analysis (e.g. variability, sampling error, inference, hypothesis testing, EDA, application of linear models), data management (e.g. data cleaning and transformation), data mining, data modeling and assessment, artificial intelligence, and/or software engineering', 'Position requires active Security Clearance with appropriate Polygraph']","['This role involves leveraging Python expertise to streamline processes and create insightful visualizations for data-driven decision-making', 'Make and communicate principled conclusions from data using elements of mathematics, statistics, computer science, and application specific knowledge', 'Through analytic modeling, statistical analysis, programming, and/or another appropriate scientific method, develop and implement qualitative and quantitative methods for characterizing, exploring, and assessing large datasets in various states of organization, cleanliness, and structure that account for the unique features and limitations inherent in DOD data holdings', 'Translate practical mission needs and analytic questions related to large datasets into technical requirements and, conversely, assist others with drawing appropriate conclusions from the analysis of such data', 'Effectively communicate complex technical information to non-technical audiences', 'Make informed recommendations regarding competing technical solutions by maintaining awareness of the constantly shifting DOD collection, processing, storage and analytic capabilities and limitations']",True,[],,"['Python', 'Jupyter Notebooks', 'Mathematics', 'Statistics', 'Data Management', 'Data Visualization', 'Machine Learning', 'Data Mining', 'Data Modeling and Assessment', 'Statistical Inference', 'Exploratory Data Analysis (EDA)', 'Programming', 'Analytic Modeling']","Python: Used for automating workflows, data manipulation, and creating visualizations to support data-driven decision-making.; Jupyter Notebooks: Utilized as an interactive environment for data analysis, visualization, and workflow automation.; Mathematics: Foundational knowledge applied for analytic modeling, statistical analysis, and deriving insights from data.; Statistics: Employed for statistical analysis including variability, sampling error, inference, hypothesis testing, and exploratory data analysis.; Data Management: Involves data cleaning, transformation, curation, and handling large datasets with varying organization and quality.; Data Visualization: Creating visual representations of data to communicate insights effectively to technical and non-technical audiences.; Machine Learning: Designing and implementing predictive models and advanced analytical algorithms to extract value from data.; Data Mining: Techniques used to explore and assess large datasets to identify patterns and relationships.; Data Modeling and Assessment: Developing models to represent data and assess their performance in domain-specific contexts.; Statistical Inference: Applying methods to draw conclusions from data samples relevant to mission-critical decisions.; Exploratory Data Analysis (EDA): Analyzing datasets to summarize their main characteristics often with visual methods.; Programming: Skill in at least one high-level language, specifically Python, to implement data science and machine learning solutions.; Analytic Modeling: Developing qualitative and quantitative models to characterize and explore data for mission needs."
NHWgeUB0JB527teXAAAAAA==,Senior Data Analyst Jobs,"Responsibilities

Noblis ESI is seeking an experienced Senior Data Analyst to support our Intelligence Community program in Bethesda, Maryland.

Responsibilities Include:
• Enterprise Architecture: Contribute to the design and evolution of our client's enterprise cloud and data architecture, ensuring interoperability, security, and alignment with business goals. Foster a culture of innovation and continuous improvement.
• Strategic Thinking: Develop data strategies that consider long-term implications, anticipating future needs and trends. Decompose complex problems and develop an analytic approach.
• Collaboration: Collaborate with multiple stakeholders to drive data integration initiatives and foster a data-driven culture.
• Compliance: Analyze current practices to ensure compliance with relevant regulations.
• Data Integrity: Analyze the current data structure, tagging, and quality standards to discover and address anomalies.
• Responsibilities will span multiple areas, including strategic planning, data security, data compliance, and data integrity to enhance our customer's data ecosystem.

Required Qualifications
• Active TS/SCI with Counterintelligence (CI) Polygraph.
• Bachelors degree and 5 to 8 years of prior relevant experience OR Masters degree with 3 to 6 years of prior relevant experience.
• Proven experience as a Data Scientist, with a focus on complex data environments.
• Experience with data science tools and languages, such as Python, R, and Scala, in various data science environments.
• Experience with data visualization tools (e.g., Tableau, MS PowerBI) to deliver data analysis solutions and visualizations.
• Proficiency in data manipulation and analysis.
• US Citizenship is required.

Desired Qualifications
• Doctorate degree in technical domain.
• Five or more years of experience working with or in the Intelligence Community (IC).
• Cloud-based data science experience.
• Experience producing executive-level products.
• Excellent communication skills, with the ability to translate technical insights into actionable recommendations and present them orally or in writing.
• Passion for staying up to date with industry trends and advancements.

Overview

Noblis and our wholly owned subsidiaries, Noblis ESI , and Noblis MSD tackle the nation's toughest problems and apply advanced solutions to our clients' most critical missions. We bring the best of scientific thought, management, and engineering expertise together in an environment of independence and objectivity to deliver enduring impact on federal missions. Noblis works with a wide range of government clients in the defense, intelligence and federal civil sectors. Learn more at Noblis -About Us

Why work at a Noblis company?

Our employees find greater meaning in their work and balance the other things in life that matter to them. Our people are our greatest asset. They are exceptionally skilled, knowledgeable, team-oriented, and mission-driven individuals who want to do work that matters and benefits the public. Noblis has won numerous workplace awards . Noblis maintains a drug-free workplace.
• Remote/hybrid status is subject to change based on Noblis and/or government requirements

Commitment to Non-Discrimination

All qualified applicants will receive consideration for employment without regard to race, color, ethnicity, sex, age, national origin, religion, physical or mental disability, pregnancy/childbirth and related medical conditions, veteran or military status, or any other characteristics protected by applicable federal, state, or local law.

If reasonable accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment, please contact us .

EEO is the Law | E-Verify | Right to Work

Total Rewards

At Noblis we recognize and reward your contributions, provide you with growth opportunities, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, and work-life programs. Our award programs acknowledge employees for exceptional performance and superior demonstration of our service standards. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in our benefit programs. Other offerings may be provided for employees not within this category. We encourage you to learn more about our total benefits by visiting the Benefits page on our Careers site.

Compensation at Noblis is determined by various factors, including but not limited to, the combination of education, certifications, knowledge, skills, competencies, and experience, internal and external equity, location, clearance level, as well as contract-specific affordability, organizational requirements and applicable employment laws. The projected compensation range for this position is based on full time status. For part time or on-call staff, compensation is proportionately adjusted based on hours worked. While monetary compensation is important, it's just one component of Noblis' total compensation package.

Posted Salary Range

USD $117,800.00 - USD $184,100.00 /Yr.",2025-07-25T13:00:00.000Z,2025-07-25,"['Active TS/SCI with Counterintelligence (CI) Polygraph', 'Bachelors degree and 5 to 8 years of prior relevant experience OR Masters degree with 3 to 6 years of prior relevant experience', 'Proven experience as a Data Scientist, with a focus on complex data environments', 'Experience with data science tools and languages, such as Python, R, and Scala, in various data science environments', 'Experience with data visualization tools (e.g., Tableau, MS PowerBI) to deliver data analysis solutions and visualizations', 'Proficiency in data manipulation and analysis', 'US Citizenship is required', 'Remote/hybrid status is subject to change based on Noblis and/or government requirements', 'All qualified applicants will receive consideration for employment without regard to race, color, ethnicity, sex, age, national origin, religion, physical or mental disability, pregnancy/childbirth and related medical conditions, veteran or military status, or any other characteristics protected by applicable federal, state, or local law']","['Noblis ESI is seeking an experienced Senior Data Analyst to support our Intelligence Community program in Bethesda, Maryland', ""Enterprise Architecture: Contribute to the design and evolution of our client's enterprise cloud and data architecture, ensuring interoperability, security, and alignment with business goals"", 'Foster a culture of innovation and continuous improvement', 'Strategic Thinking: Develop data strategies that consider long-term implications, anticipating future needs and trends', 'Decompose complex problems and develop an analytic approach', 'Collaboration: Collaborate with multiple stakeholders to drive data integration initiatives and foster a data-driven culture', 'Compliance: Analyze current practices to ensure compliance with relevant regulations', 'Data Integrity: Analyze the current data structure, tagging, and quality standards to discover and address anomalies', ""Responsibilities will span multiple areas, including strategic planning, data security, data compliance, and data integrity to enhance our customer's data ecosystem""]",True,[],,"['Python', 'R', 'Scala', 'Tableau', 'Power BI', 'Data Strategy Development', 'Data Integration', 'Data Quality and Integrity Analysis', 'Enterprise Cloud and Data Architecture', 'Data Compliance and Security', 'Analytic Problem Decomposition']","Python: Used as a primary programming language for data manipulation and analysis in various data science environments.; R: Employed for statistical analysis and data science tasks within complex data environments.; Scala: Utilized for data science workflows, particularly in scalable and complex data processing contexts.; Tableau: Applied as a data visualization tool to deliver insightful data analysis solutions and visualizations.; Power BI: Used for creating interactive dashboards and visualizations to support data-driven decision making.; Data Strategy Development: Involves creating long-term data strategies to anticipate future needs and trends for the organization.; Data Integration: Collaborating with stakeholders to drive initiatives that combine data from multiple sources into a unified view.; Data Quality and Integrity Analysis: Analyzing data structures, tagging, and quality standards to identify and address anomalies.; Enterprise Cloud and Data Architecture: Contributing to the design and evolution of cloud-based data architectures ensuring interoperability and security.; Data Compliance and Security: Ensuring data practices comply with relevant regulations and maintain security standards.; Analytic Problem Decomposition: Breaking down complex problems to develop effective analytic approaches."
-_klp8UWVhrJmWAwAAAAAA==,ME00432-Data Scientist 4 Jobs,"Momentum Engineering, Inc., a Woman-Owned Small Business (WOSB), fosters an employee-centric culture. Our strength lies in our people. With a high percentage of employees holding advanced degrees in engineering, computer science, and related disciplines, we bring deep technical expertise to every mission. Our team includes professionals with security clearances and full-scope polygraphs, ensuring trusted, secure support for the most sensitive national security initiatives. Additionally, our workforce is equipped with industry-leading certifications, demonstrating a commitment to continuous learning and excellence. Most importantly, our exceptional employee retention rate reflects a culture of professional growth, mission focus, and dedication-ensuring long-term stability and expertise for our customers' critical needs.

Job Summary
• The ideal candidate will be involved in full spectrum analytic technical support to mission operations and the intelligence lifecycle: requirements collection and refinement, translating user requirements into technical requirements, environment configuration, exploratory data analysis, model development, selection, and evaluation, identifying insights from analytic products and then communicating those results to a nontechnical audience
• Candidate will work with cross-functional teams to identify relevant and permissible data sources, access available infrastructure, and to develop analytic products tailored to mission user requirements

Primary Responsibilities
• Establish advanced analysis and data visualization methodologies, models, and tools to derive intelligence outcomes and impacts
• Design and deliver infographics across a range of media platforms
• Identify and process raw data, trends, analysis, and assessments in order to aggregate disparate information, leveraging both analytic and visualization tools
• Leverage knowledge of databases and methodologies to determine appropriate sources, determine indicators and relationships, and generate intelligence support packages
• Provide tailored communications to innovation stakeholders in meetings, demos, and other customer engagements, as well as support analytic innovation, development, and data analytics activities to customers and stakeholders
• Brief customers on assessments and prepare briefings based on finished analysis, including preparing daily briefings for senior policy and operational decision makers
• Develop machine learning models with attention to model accuracy
• Draft technical methodologies and participate in architectural reviews
• Document processes and solutions that serve as communication findings for both technical and non-technical stakeholder

Required Qualifications
• Must have active Top Secret/SCI clearance
• Bachelor's degree or equivalent practical experience
• 4 - 6+ years of experience in computer science, data science, and data analytics
• Experience executing data science methods using Python libraries for Data Cleaning/Wrangling, Exploratory Data Analysis (EDA), Statistical Analysis, Data Visualization
• Strong proficiency in programming languages such as Python
• Agile development experience along with related technologies (e.g., Jira)
• Strong communication and interpersonal skills

Desired Qualifications
• Familiarity and experience with the Intelligence Community (IC), and the intel cycle
• Familiarity and experience with the Department of Homeland Security (DHS)
• Ability, openness, and eagerness to learn

Exempt hourly position. 11 paid holidays, minimum of 3 weeks PTO, company sponsored group medical plan, company paid dental, vision, life insurance, and STD/LTD plans. Salary is dependent upon the candidate's experience and qualifications.",2025-07-19T00:00:00.000Z,2025-07-25,"['Must have active Top Secret/SCI clearance', ""Bachelor's degree or equivalent practical experience"", '4 - 6+ years of experience in computer science, data science, and data analytics', 'Experience executing data science methods using Python libraries for Data Cleaning/Wrangling, Exploratory Data Analysis (EDA), Statistical Analysis, Data Visualization', 'Strong proficiency in programming languages such as Python', 'Agile development experience along with related technologies (e.g., Jira)', 'Strong communication and interpersonal skills']","['The ideal candidate will be involved in full spectrum analytic technical support to mission operations and the intelligence lifecycle: requirements collection and refinement, translating user requirements into technical requirements, environment configuration, exploratory data analysis, model development, selection, and evaluation, identifying insights from analytic products and then communicating those results to a nontechnical audience', 'Candidate will work with cross-functional teams to identify relevant and permissible data sources, access available infrastructure, and to develop analytic products tailored to mission user requirements', 'Establish advanced analysis and data visualization methodologies, models, and tools to derive intelligence outcomes and impacts', 'Design and deliver infographics across a range of media platforms', 'Identify and process raw data, trends, analysis, and assessments in order to aggregate disparate information, leveraging both analytic and visualization tools', 'Leverage knowledge of databases and methodologies to determine appropriate sources, determine indicators and relationships, and generate intelligence support packages', 'Provide tailored communications to innovation stakeholders in meetings, demos, and other customer engagements, as well as support analytic innovation, development, and data analytics activities to customers and stakeholders', 'Brief customers on assessments and prepare briefings based on finished analysis, including preparing daily briefings for senior policy and operational decision makers', 'Develop machine learning models with attention to model accuracy', 'Draft technical methodologies and participate in architectural reviews', 'Document processes and solutions that serve as communication findings for both technical and non-technical stakeholder']",True,[],,"['Exploratory Data Analysis', 'Data Cleaning and Wrangling', 'Statistical Analysis', 'Data Visualization', 'Machine Learning', 'Python Programming', 'Agile Development', 'Databases and Data Sources']","Exploratory Data Analysis: Used to analyze and summarize data sets to identify patterns and insights relevant to mission operations and intelligence lifecycle.; Data Cleaning and Wrangling: Applied to prepare raw data for analysis by correcting or removing errors and transforming data into usable formats.; Statistical Analysis: Employed to interpret data trends and support intelligence assessments through quantitative methods.; Data Visualization: Used to create infographics and visual representations of data to communicate intelligence outcomes effectively.; Machine Learning: Developed models with attention to accuracy to support analytic products and intelligence insights.; Python Programming: Primary programming language used for implementing data science methods including data cleaning, analysis, and model development.; Agile Development: Utilized to manage and deliver data science projects efficiently, often involving tools like Jira.; Databases and Data Sources: Knowledge leveraged to identify appropriate data sources and indicators for generating intelligence support packages."
9-w0Jz3GtdfwWvO4AAAAAA==,Data Scientist Jobs,"NewGen Technologies is seeking a versatile Data Scientist with a TS/SCI and poly to join a high paced team working on cutting-edge AI/ML and networking technology. As the Data Scientist will be part of a small agile team building a big data pipeline, AI/ML-based analytics capabilities, and user interfaces for government customers. This project includes highly innovative work focused on leveraging AI/ML to discover patterns and develop insights across multiple networks and devices to include IoT and 5G. Work is conducted in conjunction with world-renowned scientist and engineers at IBM Research. The team is fast-paced, collaborative, and cohesive, and depends on team members to communicate openly and to design solutions and deliver quality models on a regular, aggressive clip.

You will have the opportunity to choose W2 (with or without benefits) or 1099 employment options.

Required:
• Demonstrated experience with Python, Jupyter
• demonstrated experience with Machine Learning, including model development, evaluation and optimization using tools and packages such as: sklearn, NumPy, PyTorch, or TensorFlow
• Exposure to/understanding of network data analysis (IP traffic)using Bro/Zeek, TShark/PyShark, or other network analysis tools
Desired:
• Demonstrated experience with one or more of the following: Spark, MLFlow, Docker, AWS, Linux/CentOS, bash scripting.
• Demonstrated experience with Agile software development, Scrum, Git/GitHub and software development lifecycle (SDLC).
• Bachelor's degree in computer science, engineering, or related technical field.
Technical and Professional Expertise:
• Ability to apply, evaluate, and modify machine learning algorithms against various data sources and use cases
• Design and develop methods, processes, and systems to consolidate and analyze structured and unstructured, diverse sources including big data sources.
• Concentrate on the AI discipline of Machine Learning - in data, pattern identification and analysis. As such will be evaluate capabilities and analysis in Natural Language Processing, Machine Learning, predictive modeling, statistical analysis and hypothesis testing
• Develops and uses advanced software programs, algorithms, query techniques, model complex business problems, and automated processes to cleanse, integrate, and evaluate datasets.
About Us:
NewGen is a technology consulting services company solving some of the public and private sectors' toughest challenges across Enterprise Management, Cyber Security and DevOps. We know that to find and hire the best fit, we must offer interesting work at the best rate possible. By partnering with us, you will find opportunities that leverage and grow your technical abilities and offer you the flexibility you require. Join our talent network today. #CJ",2025-07-25T14:00:00.000Z,2025-07-25,"['Demonstrated experience with Python, Jupyter', 'demonstrated experience with Machine Learning, including model development, evaluation and optimization using tools and packages such as: sklearn, NumPy, PyTorch, or TensorFlow', 'Exposure to/understanding of network data analysis (IP traffic)using Bro/Zeek, TShark/PyShark, or other network analysis tools', 'Ability to apply, evaluate, and modify machine learning algorithms against various data sources and use cases', 'Concentrate on the AI discipline of Machine Learning - in data, pattern identification and analysis', 'Develops and uses advanced software programs, algorithms, query techniques, model complex business problems, and automated processes to cleanse, integrate, and evaluate datasets']","['As the Data Scientist will be part of a small agile team building a big data pipeline, AI/ML-based analytics capabilities, and user interfaces for government customers', 'This project includes highly innovative work focused on leveraging AI/ML to discover patterns and develop insights across multiple networks and devices to include IoT and 5G', 'Design and develop methods, processes, and systems to consolidate and analyze structured and unstructured, diverse sources including big data sources', 'As such will be evaluate capabilities and analysis in Natural Language Processing, Machine Learning, predictive modeling, statistical analysis and hypothesis testing']",True,"['Deep Learning', 'Natural Language Processing']",Deep Learning: Utilized through frameworks like PyTorch and TensorFlow for developing neural network models within AI/ML analytics.; Natural Language Processing: Evaluated as part of AI capabilities to analyze unstructured text data within the project scope.,"['Python', 'Jupyter', 'Machine Learning', 'Scikit-learn', 'NumPy', 'Network Data Analysis', 'Big Data Pipelines', 'Predictive Modeling', 'Statistical Analysis', 'Data Cleansing and Integration']","Python: Used as a primary programming language for data manipulation, analysis, and model development.; Jupyter: Utilized as an interactive environment for developing and documenting data science workflows and experiments.; Machine Learning: Applied for model development, evaluation, optimization, and pattern identification across diverse data sources.; Scikit-learn: Employed as a key library for implementing traditional machine learning algorithms and model evaluation.; NumPy: Used for numerical computing and handling large datasets efficiently during data processing and analysis.; Network Data Analysis: Involves analyzing IP traffic data using tools like Bro/Zeek and TShark/PyShark to extract insights from network data.; Big Data Pipelines: Developed to consolidate and process large volumes of structured and unstructured data from multiple sources.; Predictive Modeling: Used to forecast outcomes and identify patterns within network and IoT data.; Statistical Analysis: Applied for hypothesis testing and validating insights derived from data.; Data Cleansing and Integration: Automated processes to prepare and unify diverse datasets for analysis and modeling."
YdYVExrltznEb7kIAAAAAA==,"Principal Data Scientist, AI Foundations at Capital One Mc Lean, VA","Principal Data Scientist, AI Foundations job at Capital One. Mc Lean, VA.

Principal Data Scientist, AI Foundations
Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making.

As a Data Scientist at Capital One, you’ll be part of a team that’s leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives.
Team Description
AI Foundations Specialist Models Data Science team builds and ships state of the art scalable architecture, AI/ML solutions for Capital One’s award-winning mobile app. We partner with product, tech and design teams to deliver app features that delight customers with dynamic and personalized experiences, enable them to chat with Capital One’s digital assistant Eno, or search for useful contents. You will be the driving force to experiment, innovate and create next generation experiences powered by the latest emerging generative AI technologies.
In this role, you will:
Partner with a cross-functional team of data scientists, software engineers, machine learning engineers and product managers to deliver AI powered products that change how customers interact with their money.
Leverage a broad stack of technologies — Pytorch, AWS Ultraclusters, Hugging Face, LangChain, Lightning, VectorDBs, and more — to reveal the insights hidden within huge volumes of numeric and textual data.
Be the expert in Natural Language Processing (NLP) to harness the power of Large Language Models (LLMs), adapt and finetune them for customer facing applications and features.
Build machine learning and NLP models through all phases of development, from design through training, evaluation, and validation; partnering with engineering teams to operationalize them in scalable and resilient production systems that serve 80+ million customers.
Flex your interpersonal skills to translate the complexity of your work into tangible business goals.
The Ideal Candidate is:
Customer first. You love the process of analyzing and creating, but also share our passion to do the right thing. You know at the end of the day it’s about making the right decision for our customers.
Innovative. You continually research and evaluate emerging technologies. You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them.
Creative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You’re not afraid to share a new idea.
A leader. You challenge conventional thinking and work with stakeholders to identify and improve the status quo. You're passionate about talent development for your own team and beyond.
Technical. You’re comfortable with advanced ML and DL technologies including language models and are passionate about developing further. You have hands-on experience working with LLMs and solutions using open-source tools and cloud computing platforms.
Influential. You are passionate about AI/ML and can bring along a cross functional team in breakthrough innovations. You communicate clearly and effectively to share your findings with non-technical audiences.
You are experienced in training language models or large computer vision models as well as have expertise in one or more key subdomains such as: training optimization, self-supervised learning, explainability, RLHF.
You have an engineering mindset as shown by a track record of delivering models at scale both in training data and inference volumes. You have experience in delivering libraries, platforms, or solution level code to existing products.
Basic Qualifications:
Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:
A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 5 years of experience performing data analytics
A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 3 years of experience performing data analytics
A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field)
Preferred Qualifications:
Master’s Degree in “STEM” field (Science, Technology, Engineering, or Mathematics), or PhD in “STEM” field (Science, Technology, Engineering, or Mathematics)
Experience working with AWS
At least 3 years’ experience in Python, Scala, or R
At least 3 years’ experience with machine learning
At least 3 years’ experience with SQL
Capital One will consider sponsoring a new qualified applicant for employment authorization for this position.
The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.
McLean, VA: $158,600 - $181,000 for Princ Associate, Data Science
New York, NY: $173,000 - $197,400 for Princ Associate, Data Science
San Jose, CA: $173,000 - $197,400 for Princ Associate, Data Science
Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate’s offer letter.
This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.
Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website . Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.
This role is expected to accept applications for a minimum of 5 business days. No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

#J-18808-Ljbffr Capital One",2025-07-03T00:00:00.000Z,2025-07-25,"['You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them', 'You thrive on bringing definition to big, undefined problems', 'You love asking questions and pushing hard to find answers', 'You challenge conventional thinking and work with stakeholders to identify and improve the status quo', ""You're passionate about talent development for your own team and beyond"", 'You’re comfortable with advanced ML and DL technologies including language models and are passionate about developing further', 'You have hands-on experience working with LLMs and solutions using open-source tools and cloud computing platforms', 'Influential', 'You are passionate about AI/ML and can bring along a cross functional team in breakthrough innovations', 'You communicate clearly and effectively to share your findings with non-technical audiences', 'You are experienced in training language models or large computer vision models as well as have expertise in one or more key subdomains such as: training optimization, self-supervised learning, explainability, RLHF', 'You have an engineering mindset as shown by a track record of delivering models at scale both in training data and inference volumes', 'You have experience in delivering libraries, platforms, or solution level code to existing products', 'Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:', ""A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 5 years of experience performing data analytics"", ""A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 3 years of experience performing data analytics"", 'A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field)', 'Master’s Degree in “STEM” field (Science, Technology, Engineering, or Mathematics), or PhD in “STEM” field (Science, Technology, Engineering, or Mathematics)', 'Experience working with AWS', 'At least 3 years’ experience in Python, Scala, or R', 'At least 3 years’ experience with machine learning', 'At least 3 years’ experience with SQL']","['You will be the driving force to experiment, innovate and create next generation experiences powered by the latest emerging generative AI technologies', 'Partner with a cross-functional team of data scientists, software engineers, machine learning engineers and product managers to deliver AI powered products that change how customers interact with their money', 'Leverage a broad stack of technologies — Pytorch, AWS Ultraclusters, Hugging Face, LangChain, Lightning, VectorDBs, and more — to reveal the insights hidden within huge volumes of numeric and textual data', 'Be the expert in Natural Language Processing (NLP) to harness the power of Large Language Models (LLMs), adapt and finetune them for customer facing applications and features', 'Build machine learning and NLP models through all phases of development, from design through training, evaluation, and validation; partnering with engineering teams to operationalize them in scalable and resilient production systems that serve 80+ million customers', 'Flex your interpersonal skills to translate the complexity of your work into tangible business goals', 'You continually research and evaluate emerging technologies']",True,"['Large Language Models', 'Generative AI', 'PyTorch', 'Hugging Face', 'LangChain', 'Lightning', 'Vector Databases', 'Training Large Computer Vision Models']",Large Language Models: Central to developing customer-facing AI features by adapting and fine-tuning these models for personalized interactions.; Generative AI: Used to create next-generation customer experiences powered by emerging AI technologies.; PyTorch: Deep learning framework employed to build and train neural network models including LLMs.; Hugging Face: Open-source platform and library used for accessing and fine-tuning pre-trained transformer models.; LangChain: Framework used to build applications that integrate LLMs with external data and APIs.; Lightning: A PyTorch-based framework used to streamline deep learning model training and deployment.; Vector Databases: Specialized databases used to store and query vector embeddings for efficient similarity search in AI applications.; Training Large Computer Vision Models: Experience required for developing and scaling deep learning models in computer vision domains.,"['Machine Learning', 'Natural Language Processing', 'Python', 'Scala', 'R', 'SQL', 'AWS', 'Training Optimization', 'Self-Supervised Learning', 'Explainability', 'Reinforcement Learning from Human Feedback']","Machine Learning: Used to build predictive models and data-driven solutions that improve customer experiences and financial decision-making.; Natural Language Processing: Applied to analyze and extract insights from large volumes of textual data to support customer-facing applications.; Python: Programming language used for data analytics, model development, and integration with machine learning pipelines.; Scala: Programming language experience required for data processing and analytics tasks.; R: Used for statistical analysis and data science tasks within the team.; SQL: Used to query and manage relational databases containing customer and transactional data.; AWS: Cloud platform used for scalable data storage, processing, and machine learning model deployment.; Training Optimization: Techniques applied to improve the efficiency and effectiveness of training machine learning models at scale.; Self-Supervised Learning: A machine learning approach used to leverage unlabeled data for model training.; Explainability: Methods used to interpret and explain machine learning model decisions to stakeholders.; Reinforcement Learning from Human Feedback: Applied to improve model performance by incorporating human feedback during training."
bOjFjfYsAwA58iRxAAAAAA==,Data Scientist Jobs,"Overview

DATA SCIENTIST (ARDAP):

Bowhead is seeking a Data Scientist for the upcomming Army Data and Analytics Platform (ARDAP) effort located at Fort Belvoir, VA. This is a fast paced job managing subject matter experts and IT professionals advising executive level personnel on financial, technical, and other high-level policy areas.

Responsibilities
• Lead development and implementation of analytics solutions to solve business problems and optimize mission execution.
• Define and develop techniques to integrate, consolidate, and structure data for analytical use.
• Research, analyze, and document technical approaches for desired outcomes.
• Provide guidance in applying appropriate algorithms, solutions, and data science techniques.
• Develop and implement a set of techniques or analytics applications to transform massive-scale data into actionable and meaningful information.
• Lead development, testing, and demonstration of analytics products.
• Design scalable algorithms utilizing large amounts of data and apply data mining, cluster analysis, statistical models, visualization, and machine learning to power data driven products and tools and provide useful insights.
• Enable automation of queries and build tools. Design and develop piping and processing of massive data streams to facilitate analysis.
• Develop graphical analysis to analyze and interpret data, update existing programs to reflect new business rules or policy changes, and develop customizable reports.
• Write scripts to integrate data, conduct exploratory data analysis to discover patterns, and apply machine learning to train predictive models.
• Have experience formulating recommendations and briefings and easily communicate complex ideas to high-level commanders/executives.
• Have experience serving as a data scientist on complex technology implementations, and experience in large data environments with an understanding of scaling algorithms between differing environments.

Qualifications
• MA/MS in Computer Science, Engineering, Mathematics, or related discipline or Equivalent
• Ten (10+) years of experience with programming languages such as Python and R; and querying languages such as SQL required
• Intermediate to advanced level skills in Microsoft Office software suite - Word, Excel, Outlook, PowerPoint
• Ability to communicate effectively with all levels of employees and outside contacts
• Strong interpersonal skills and good judgment with the ability to work alone or as part of a team

Physical Demands:
• Must be able to lift up to 25 pounds
• Must be able to stand and walk for prolonged amounts of time
• Must be able to twist, bend and squat periodically

SECURITY CLEARANCE REQUIREMENTS: Must currently hold a security clearance at the Secret level. US Citizenship is a requirement for Secret clearance at this location.

#LI-KC1",2025-07-25T01:00:00.000Z,2025-07-25,"['Have experience formulating recommendations and briefings and easily communicate complex ideas to high-level commanders/executives', 'Have experience serving as a data scientist on complex technology implementations, and experience in large data environments with an understanding of scaling algorithms between differing environments', 'MA/MS in Computer Science, Engineering, Mathematics, or related discipline or Equivalent', 'Ten (10+) years of experience with programming languages such as Python and R; and querying languages such as SQL required', 'Intermediate to advanced level skills in Microsoft Office software suite - Word, Excel, Outlook, PowerPoint', 'Ability to communicate effectively with all levels of employees and outside contacts', 'Strong interpersonal skills and good judgment with the ability to work alone or as part of a team', 'Must be able to lift up to 25 pounds', 'Must be able to stand and walk for prolonged amounts of time', 'Must be able to twist, bend and squat periodically', 'SECURITY CLEARANCE REQUIREMENTS: Must currently hold a security clearance at the Secret level', 'US Citizenship is a requirement for Secret clearance at this location']","['This is a fast paced job managing subject matter experts and IT professionals advising executive level personnel on financial, technical, and other high-level policy areas', 'Lead development and implementation of analytics solutions to solve business problems and optimize mission execution', 'Define and develop techniques to integrate, consolidate, and structure data for analytical use', 'Research, analyze, and document technical approaches for desired outcomes', 'Provide guidance in applying appropriate algorithms, solutions, and data science techniques', 'Develop and implement a set of techniques or analytics applications to transform massive-scale data into actionable and meaningful information', 'Lead development, testing, and demonstration of analytics products', 'Design scalable algorithms utilizing large amounts of data and apply data mining, cluster analysis, statistical models, visualization, and machine learning to power data driven products and tools and provide useful insights', 'Enable automation of queries and build tools', 'Design and develop piping and processing of massive data streams to facilitate analysis', 'Develop graphical analysis to analyze and interpret data, update existing programs to reflect new business rules or policy changes, and develop customizable reports', 'Write scripts to integrate data, conduct exploratory data analysis to discover patterns, and apply machine learning to train predictive models']",True,[],,"['Python', 'R', 'SQL', 'Data Mining', 'Cluster Analysis', 'Statistical Models', 'Visualization', 'Machine Learning', 'Exploratory Data Analysis', 'Data Pipelines']","Python: Used as a primary programming language for data analysis, scripting, and implementing machine learning models.; R: Utilized for statistical analysis and data science tasks within the role.; SQL: Employed for querying and managing large-scale data environments to support analytics.; Data Mining: Applied to extract patterns and insights from massive-scale data to inform decision-making.; Cluster Analysis: Used to group data points for identifying meaningful patterns and structures in data.; Statistical Models: Implemented to analyze data and support predictive analytics and decision-making.; Visualization: Developed graphical analyses to interpret data and communicate insights effectively.; Machine Learning: Applied to train predictive models and power data-driven products and tools.; Exploratory Data Analysis: Conducted to discover patterns and understand data characteristics before modeling.; Data Pipelines: Designed and developed to automate data processing and facilitate analysis of massive data streams."
W2DDfF5JErG6iCPKAAAAAA==,Data Scientist Jobs,"Title: Data Scientist
Location: Reston, Virginia
• Clearance: *Active TS/SCI w/ Polygraph needed to apply *

Company Overview:

Cornerstone Defense, in partnership with our military, intelligence, and civil government customers, supports U.S. operations worldwide through the use of many different types of intelligence, satellite, and cyber technologies. Cornerstone's Intelligence Sector provides solutions to the United States Government for information collection, operations, exploitation and dissemination, and research activities. Our Team specializes in software development, cloud architecture, systems and network engineering, systems integration, agile management, as well as targeting operations and intelligence analysis. Our support to our mission customers includes cyber network operations, exploitation and defense, signals intelligence, human intelligence, and critical missions and networks.

Job Description
Seeking a Data Scientist responsible for working closely with Client's Customer Engagement project teams to provide the customer with business analysis expertise, dashboard design in a tactical capacity, evaluate internal and external client requirements, and implement effective solutions in a timely manner.
The selected candidate will leverage their analytical skills and expertise in predictive analytics to extract insights from complex datasets and drive data-driven decision-making within our client's user community. They will collaborate closely with cross-functional teams to develop predictive models, uncover actionable insights, and solve challenging business problems.
Job Requirements:
• Must have an Active TS/SCI with polygraph ONLY all others need not apply.
• Analyze large, complex datasets to identify trends, patterns, and relationships.
• Conduct exploratory data analysis (EDA) to gain insights and formulate hypotheses.
• Utilize statistical methods and data visualization techniques to communicate findings effectively.
• Ability to consolidate, interpret, and present data in reports/dashboards for Executives, Team Leads, and Individual End Users focused on Acquisition and Financial Information.
• An analytical mindset that allows you to look at the data available and drive into meaningful insights for the end user(s).
• Ability to produce reports and dashboards using Microsoft Power BI, SSRS, and other data tools.
• Experience using SQL to create queries and general knowledge of SQL database structure/relational databases
• Ability to define and document customer business processes and report/dashboard content needs, including business process diagrams, data maps, and data modeling.
• Consult with project team members and customer stakeholders to identify, define, and document business needs and objectives, current reporting capabilities, and challenges related to the business functions, such as those supporting the Federal Acquisition Lifecycle.
• Collaborate with the Client project manager, technical analysts, and customer end-users in the analysis, design, configuration, testing, and maintenance of the Business Intelligence module of Client's AEON Business Process Management Platform to ensure desired operational performance and capabilities.
• Design and conduct experiments to test hypotheses and validate model assumptions.
• Implement A/B testing frameworks to evaluate the impact of changes and interventions.
• Analyze experimental results and provide recommendations for further optimization.
• Track and document changes for functional and business specifications; write detailed, universally understood procedures for testing use cases, knowledge capture, and training purposes.
• Achieve proficiency in all significant Client Reporting/Analytic products, including the AEON software suite, through internal staffing training, self-guided tutorials, and daily exposure to individual product feature sets.
• Provide support for various meetings, demonstrations, and program activities related to Business Intelligence.
• Test reports/dashboard projects following business and functional design following best practices for quality assurance.
• Record and track defects uncovered during test execution and assist in defect resolution (troubleshooting and researching).
• Comprehension of change management processes.
• Other duties as assigned.
Required Experience.
• 3+ years prior data scientist experience.
• Proven experience in data science, machine learning, or predictive analytics roles.
• Proficiency in programming languages commonly used in data science (e.g., SQL, Python, R, etc.).
• Ability to work in a team-oriented environment for a matrixed organization.
• Strong knowledge and experience with data reporting tools, including Microsoft PowerBI, SSRS, Tableau, etc.
• Strong knowledge of productivity tools like Microsoft Office (Word, Excel, Outlook).
• Experience with Agile and SCRUM processes and methodologies.
• Knowledge of software development life cycle (SDLC) practices, principles, and techniques as they apply to the Agile development process.
• Excellent verbal and written communication skills, proven ability to listen and relate to customers.
• Ability to effectively collaborate with internal and external customers.
• Demonstrated analytical and problem-solving capabilities.
• Proven ability to communicate technical details to a non-technical audience.
• Excellent organizational and time management skills.
• Strong team player who is always willing to help other team members.
Desired Experience :
• Bachelor's degree or relevant experience.
• Knowledge of SQL Databases and Query Creation
• Knowledge of the Federal Acquisition Lifecycle or commercial contracting.
• Knowledge of Federal financial systems or commercial accounting.
• Ability to develop and deploy predictive models using machine learning algorithms, optimize model performance, and evaluate model accuracy
• Experience with Federal government contracting and/or program office organization's business processes.",2025-07-25T13:00:00.000Z,2025-07-25,"['Must have an Active TS/SCI with polygraph ONLY all others need not apply', 'Ability to consolidate, interpret, and present data in reports/dashboards for Executives, Team Leads, and Individual End Users focused on Acquisition and Financial Information', 'An analytical mindset that allows you to look at the data available and drive into meaningful insights for the end user(s)', 'Ability to produce reports and dashboards using Microsoft Power BI, SSRS, and other data tools', 'Experience using SQL to create queries and general knowledge of SQL database structure/relational databases', 'Ability to define and document customer business processes and report/dashboard content needs, including business process diagrams, data maps, and data modeling', '3+ years prior data scientist experience', 'Proven experience in data science, machine learning, or predictive analytics roles', 'Proficiency in programming languages commonly used in data science (e.g., SQL, Python, R, etc.)', 'Ability to work in a team-oriented environment for a matrixed organization', 'Strong knowledge and experience with data reporting tools, including Microsoft PowerBI, SSRS, Tableau, etc', 'Strong knowledge of productivity tools like Microsoft Office (Word, Excel, Outlook)', 'Experience with Agile and SCRUM processes and methodologies', 'Knowledge of software development life cycle (SDLC) practices, principles, and techniques as they apply to the Agile development process', 'Excellent verbal and written communication skills, proven ability to listen and relate to customers', 'Ability to effectively collaborate with internal and external customers', 'Demonstrated analytical and problem-solving capabilities', 'Proven ability to communicate technical details to a non-technical audience', 'Excellent organizational and time management skills', 'Strong team player who is always willing to help other team members']","[""Seeking a Data Scientist responsible for working closely with Client's Customer Engagement project teams to provide the customer with business analysis expertise, dashboard design in a tactical capacity, evaluate internal and external client requirements, and implement effective solutions in a timely manner"", ""The selected candidate will leverage their analytical skills and expertise in predictive analytics to extract insights from complex datasets and drive data-driven decision-making within our client's user community"", 'They will collaborate closely with cross-functional teams to develop predictive models, uncover actionable insights, and solve challenging business problems', 'Analyze large, complex datasets to identify trends, patterns, and relationships', 'Conduct exploratory data analysis (EDA) to gain insights and formulate hypotheses', 'Utilize statistical methods and data visualization techniques to communicate findings effectively', 'Consult with project team members and customer stakeholders to identify, define, and document business needs and objectives, current reporting capabilities, and challenges related to the business functions, such as those supporting the Federal Acquisition Lifecycle', ""Collaborate with the Client project manager, technical analysts, and customer end-users in the analysis, design, configuration, testing, and maintenance of the Business Intelligence module of Client's AEON Business Process Management Platform to ensure desired operational performance and capabilities"", 'Design and conduct experiments to test hypotheses and validate model assumptions', 'Implement A/B testing frameworks to evaluate the impact of changes and interventions', 'Analyze experimental results and provide recommendations for further optimization', 'Track and document changes for functional and business specifications; write detailed, universally understood procedures for testing use cases, knowledge capture, and training purposes', 'Achieve proficiency in all significant Client Reporting/Analytic products, including the AEON software suite, through internal staffing training, self-guided tutorials, and daily exposure to individual product feature sets', 'Provide support for various meetings, demonstrations, and program activities related to Business Intelligence', 'Test reports/dashboard projects following business and functional design following best practices for quality assurance', 'Record and track defects uncovered during test execution and assist in defect resolution (troubleshooting and researching)', 'Comprehension of change management processes', 'Other duties as assigned']",True,[],,"['Predictive Analytics', 'Exploratory Data Analysis', 'Statistical Methods', 'A/B Testing', 'SQL', 'Data Visualization Tools', 'Business Intelligence', 'Data Modeling', 'Machine Learning', 'Programming Languages for Data Science', 'Agile and SCRUM Methodologies', 'Business Process Analysis', 'Data Reporting Tools']","Predictive Analytics: Used to extract insights from complex datasets and drive data-driven decision-making within the client's user community.; Exploratory Data Analysis: Conducted to gain insights and formulate hypotheses from large, complex datasets.; Statistical Methods: Applied to analyze data and communicate findings effectively through data visualization techniques.; A/B Testing: Implemented to evaluate the impact of changes and interventions and optimize business processes.; SQL: Used to create queries and manage relational database structures for data extraction and analysis.; Data Visualization Tools: Microsoft Power BI, SSRS, and Tableau are used to produce reports and dashboards for various stakeholders.; Business Intelligence: Involved in the design, configuration, testing, and maintenance of BI modules to ensure operational performance.; Data Modeling: Used to define and document customer business processes and report/dashboard content needs.; Machine Learning: Applied to develop and deploy predictive models, optimize model performance, and evaluate model accuracy.; Programming Languages for Data Science: Proficiency in SQL, Python, and R is required for data analysis and model development.; Agile and SCRUM Methodologies: Used to manage software development life cycle and project workflows in a team-oriented environment.; Business Process Analysis: Consulted to identify, define, and document business needs, objectives, and reporting capabilities.; Data Reporting Tools: Utilized to create and maintain dashboards and reports for executive and operational users."
yUD93sAbedo_NTVWAAAAAA==,Data Scientist (Senior) Jobs,"Data Scientist (Senior)

Location: Springfield, VA

TS/SCI REQUIRED

Position Responsibilities:
• Support NSG strategies through the creation of automated collection models, dynamic analytic models, workflow automations, and any other automation processes and products as assigned.
• Refine, enhance and improve the operational performance of any automated solution through the evaluation of performance data, regular customer interaction, and a standardized maintenance cycle.
• Apply data science and visual programming tradecraft to support and streamline analysis tasks as identified by stakeholders and the Government.
• Enhance technical solutions to problems related to IC intelligence integration, automated collections, tipping and cueing, information sharing, and visualization.
• Conduct extensive collections and analytic modeling, data processing,

Required Skills. Proficiency in common geospatial software applications and tools, such as visual programming (JEMA, FADE/MIST, ECO/ETAS), Python, SQL, Git, GIMS, AWS Sagemaker, AWS Cloud, ESRI ArcGIS, statistics (descriptive, Bayesian), Markov-Chain modelling, TensorFlow, Linear Algebra, R, SAS, NLP.",2025-07-25T01:00:00.000Z,2025-07-25,"['Proficiency in common geospatial software applications and tools, such as visual programming (JEMA, FADE/MIST, ECO/ETAS), Python, SQL, Git, GIMS, AWS Sagemaker, AWS Cloud, ESRI ArcGIS, statistics (descriptive, Bayesian), Markov-Chain modelling, TensorFlow, Linear Algebra, R, SAS, NLP']","['Support NSG strategies through the creation of automated collection models, dynamic analytic models, workflow automations, and any other automation processes and products as assigned', 'Refine, enhance and improve the operational performance of any automated solution through the evaluation of performance data, regular customer interaction, and a standardized maintenance cycle', 'Apply data science and visual programming tradecraft to support and streamline analysis tasks as identified by stakeholders and the Government', 'Enhance technical solutions to problems related to IC intelligence integration, automated collections, tipping and cueing, information sharing, and visualization', 'Conduct extensive collections and analytic modeling, data processing,']",True,"['TensorFlow', 'Natural Language Processing']",TensorFlow: Used specifically for deep learning model development within the intelligence analysis context.; Natural Language Processing: Implemented as an AI technique to process and analyze unstructured text data.,"['Automated Collection Models', 'Dynamic Analytic Models', 'Workflow Automations', 'Visual Programming', 'Geospatial Software', 'Python', 'SQL', 'Git', 'AWS SageMaker', 'AWS Cloud', 'Statistics', 'Markov Chain Modeling', 'TensorFlow', 'Linear Algebra', 'R', 'SAS', 'Natural Language Processing']","Automated Collection Models: Used to support NSG strategies by automating data collection processes for intelligence analysis.; Dynamic Analytic Models: Developed to create adaptable analytical solutions that respond to changing data and operational needs.; Workflow Automations: Implemented to streamline and automate repetitive analysis tasks and processes.; Visual Programming: Applied to support and streamline analysis tasks using tools like JEMA, FADE/MIST, and ECO/ETAS.; Geospatial Software: Utilized for intelligence integration and visualization, including ESRI ArcGIS and GIMS.; Python: Used for data processing, modeling, and automation within the data science workflow.; SQL: Employed for querying and managing structured data relevant to intelligence analysis.; Git: Used for version control of code and data science projects.; AWS SageMaker: Leveraged as a cloud platform for building, training, and deploying machine learning models.; AWS Cloud: Used as the cloud infrastructure supporting data storage, processing, and model deployment.; Statistics: Applied descriptive and Bayesian statistical methods for data analysis and model development.; Markov Chain Modeling: Used to model probabilistic transitions in data relevant to intelligence and collection processes.; TensorFlow: Utilized for building and deploying machine learning models, including neural networks.; Linear Algebra: Applied as a mathematical foundation for modeling and algorithm development.; R: Used for statistical analysis and data visualization.; SAS: Employed for advanced statistical analysis and data management.; Natural Language Processing: Applied to analyze and process textual data within intelligence workflows."
Z2Vx-hBADY9ZO7y6AAAAAA==,"Senior Manager, Data Science - Model Risk Office","Senior Manager, Data Science - Model Risk Office
Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making.
As a Data Scientist at Capital One, you'll be part of a team that's leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives.
In Capital One's Model Risk Office, we defend the company against model failures and find new ways of making better decisions with models. We use our statistics, software engineering, and business expertise to drive the best outcomes in both Risk Management and the Enterprise. We understand that we can't prepare for tomorrow by focusing on today, so we invest in the future: investing in new skills, building better tools, and maintaining a network of trusted partners. We learn from past mistakes and develop increasingly powerful techniques to avoid their repetition.
In this role, you will:
• Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love
• Distill the details of complex interconnected modeling systems to influence senior business leaders on model strategy, business use, and risks
• Assess, challenge, and at times defend state-of-the-art decision-making systems to internal and regulatory partners
• Shape our practice of building machine learning models, from design through training, evaluation, validation, and implementation
• Oversee development of benchmark and challenger models to stress test critical modeling decisions

The Ideal Candidate is:
• Innovative. You continually research and evaluate emerging technologies. You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them.
• Creative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You're not afraid to share a new idea.
• Technical. You're comfortable with open-source languages and are passionate about developing further. You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms.
• Statistically-minded. You've built models, validated them, and backtested them. You know how to interpret a confusion matrix or a ROC curve. You have experience with clustering, classification, sentiment analysis, time series, and deep learning.

Basic Qualifications:
• Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:
• A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 7 years of experience performing data analytics
• A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 5 years of experience performing data analytics
• A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 2 years of experience performing data analytics
• At least 2 years of experience leveraging open source programming languages for large scale data analysis
• At least 2 years of experience working with machine learning
• At least 2 years of experience utilizing relational databases

Preferred Qualifications:
• PhD in ""STEM"" field (Science, Technology, Engineering, or Mathematics) plus 4 years of experience in data analytics
• At least 5 years of experience in Python, Scala, or R for large scale data analysis
• At least 5 years of experience with machine learning
• At least 1 year of experience working with AWS
• At least 1 year of experience managing people

Capital One will consider sponsoring a new qualified applicant for employment authorization for this position.
The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.
Chicago, IL: $204,900 - $233,800 for Sr Mgr, Data Science
McLean, VA: $225,400 - $257,200 for Sr Mgr, Data Science
Plano, TX: $204,900 - $233,800 for Sr Mgr, Data Science
Richmond, VA: $204,900 - $233,800 for Sr Mgr, Data Science
Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate's offer letter.
This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.
Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website . Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.
This role is expected to accept applications for a minimum of 5 business days.
No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City's Fair Chance Act; Philadelphia's Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.
If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com . All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.
For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com
Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.
Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",2025-07-18T00:00:00.000Z,2025-07-25,"['You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them', 'You thrive on bringing definition to big, undefined problems', 'You love asking questions and pushing hard to find answers', ""You're comfortable with open-source languages and are passionate about developing further"", 'You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms', 'Statistically-minded', 'You know how to interpret a confusion matrix or a ROC curve', 'You have experience with clustering, classification, sentiment analysis, time series, and deep learning', 'Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:', ""A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 7 years of experience performing data analytics"", ""A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 5 years of experience performing data analytics"", 'A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 2 years of experience performing data analytics', 'At least 2 years of experience leveraging open source programming languages for large scale data analysis', 'At least 2 years of experience working with machine learning', 'At least 2 years of experience utilizing relational databases']","['Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love', 'Distill the details of complex interconnected modeling systems to influence senior business leaders on model strategy, business use, and risks', 'Assess, challenge, and at times defend state-of-the-art decision-making systems to internal and regulatory partners', 'Shape our practice of building machine learning models, from design through training, evaluation, validation, and implementation', 'Oversee development of benchmark and challenger models to stress test critical modeling decisions', 'You continually research and evaluate emerging technologies', ""You've built models, validated them, and backtested them""]",True,[],,"['Statistical Modeling', 'Relational Databases', 'Machine Learning', 'Model Validation and Backtesting', 'Classification', 'Clustering', 'Sentiment Analysis', 'Time Series Analysis', 'Deep Learning', 'Open-Source Programming Languages', 'Cloud Computing Platforms', 'Confusion Matrix and ROC Curve']","Statistical Modeling: Used to personalize credit card offers and assess model risk in financial decision-making.; Relational Databases: Utilized for managing and querying large-scale structured customer data.; Machine Learning: Applied to build, train, evaluate, validate, and implement predictive models for risk management.; Model Validation and Backtesting: Processes to ensure model accuracy and reliability in decision-making systems.; Classification: Used as a modeling technique to categorize data for risk assessment.; Clustering: Employed to identify patterns or groupings within customer data.; Sentiment Analysis: Applied to analyze textual data for insights relevant to model risk.; Time Series Analysis: Used to analyze temporal data trends impacting financial models.; Deep Learning: Implemented for advanced modeling techniques within the data science practice.; Open-Source Programming Languages: Languages like Python, Scala, or R used for large-scale data analysis and model development.; Cloud Computing Platforms: Platforms such as AWS leveraged to support scalable data science solutions.; Confusion Matrix and ROC Curve: Metrics used to interpret and evaluate classification model performance."
vELC56-lhnBwwds7AAAAAA==,Research Data Scientist,"APPLICATION INSTRUCTIONS:
• CURRENT PENN STATE EMPLOYEE (faculty, staff, technical service, or student), please login to Workday to complete the internal application process. Please do not apply here, apply internally through Workday.
• CURRENT PENN STATE STUDENT (not employed previously at the university) and seeking employment with Penn State, please login to Workday to complete the student application process. Please do not apply here, apply internally through Workday.
• If you are NOT a current employee or student, please click ""Apply"" and complete the application process for external applicants.

Approval of remote and hybrid work is not guaranteed regardless of work location. For additional information on remote work at Penn State, see Notice to Out of State Applicants.

This position is funded for 12 months; continuation past 12 months will be based on university need, performance, and/or availability of funding.

POSITION SPECIFICS

The Department of Biobehavioral Health in the College of Health and Human Development is seeking a Research Data Scientist. Under the direction of Dr. Idan Shalev, this position will work on federally funded projects and lead the development and execution of computational workflows to analyze longitudinal multi-omic data. This position will support the integration, quality control, and statistical analysis of transcriptomic, metabolomic, and epigenetic datasets across time, ensure methodological rigor in testing study hypotheses, and contribute to the generation of reproducible, high-quality research outputs.

What You'll Do:
• Develop and implement statistical models and data workflows for analysis of transcriptomic, metabolomic, and epigenetic data across three longitudinal timepoints.
• Conduct data integration and harmonization across multi-omic platforms, ensuring alignment with study protocols and cohort structures.
• Perform quality control and preprocessing of raw omics datasets, including normalization, batch correction, and outlier detection, generating usable datasets for future analyses.
• Generate publication-ready data visualizations and summary outputs for internal reporting, scientific publications, and grant progress updates.
• Contribute to manuscripts and conference abstracts by preparing methods and results sections in collaboration with the study team.
• Support onboarding and training of student researchers in computational methods and data management procedures.
• Document analytical pipelines and code to ensure reproducibility and adherence to open science best practices.

Skills You Have:
• Proficiency in statistical analysis and modeling, including longitudinal data analysis and mixed-effects models.
• Experience with multi-omic data analysis, including transcriptomic, metabolomic, and epigenetic datasets.
• Skill in data preprocessing, including normalization, batch correction, and outlier detection.
• Experience with data integration and harmonization across platforms and timepoints.
• Proficiency in programming languages commonly used in data science, such as R or Python.
• Ability to create publication-ready visualizations and summary outputs for diverse audiences.
• Experience contributing to scientific manuscripts and conference presentations, especially methods and results sections.
• Knowledge of reproducible research practices, including workflow documentation and version control (e.g., Git).
• Familiarity with research design and methodology, particularly in child development, maltreatment, or early life adversity.
• Strong problem-solving skills and ability to work independently within established research goals.
• Effective written and verbal communication skills for technical and collaborative work.
• Ability to train and support junior team members, including onboarding and mentoring student researchers.
• Experience working in interdisciplinary research teams.

Desired Qualifications:
• 1+ years of post-baccalaureate experience in statistical programming, bioinformatics, or data science, preferably in a research or academic setting.
• Demonstrated experience working with high-dimensional biological data such as transcriptomics, metabolomics, or epigenetics.
• Familiarity with longitudinal data analysis and reproducible research practices is expected.
• Experience working with data related to child development, child maltreatment, or early life adversity is strongly preferred.

Schedule:

This position is located on-site at the Pennsylvania State University in University Park, PA. Questions related to flexible work should be directed to the hiring manager during the interview process.

MINIMUM EDUCATION, WORK EXPERIENCE & REQUIRED CERTIFICATIONS
Bachelor's Degree1+ years of relevant experience; or an equivalent combination of education and experience acceptedRequired Certifications:None

Application Instructions

To apply, submit a cover letter, resume, and the contact information for three professional references. Review of applications will begin immediately and continue until the position is filled.

BACKGROUND CHECKS/CLEARANCES
Employment with the University will require successful completion of background check(s) in accordance with University policies.

Penn State does not sponsor or take over sponsorship of a staff employment Visa. Applicants must be authorized to work in the U.S.

SALARY & BENEFITS
The salary range for this position, including all possible grades, is $61,800.00 - $89,600.00.

Salary Structure - Information on Penn State's salary structure

Penn State provides a competitive benefits package for full-time employees designed to support both personal and professional well-being. In addition to comprehensive medical, dental, and vision coverage, employees enjoy robust retirement plans and substantial paid time off which includes holidays, vacation and sick time. One of the standout benefits is the generous 75% tuition discount, available to employees as well as eligible spouses and children. For more detailed information, please visit our Benefits Page.

CAMPUS SECURITY CRIME STATISTICS

Pursuant to the Jeanne Clery Disclosure of Campus Security Policy and Campus Crime Statistics Act and the Pennsylvania Act of 1988, Penn State publishes a combined Annual Security and Annual Fire Safety Report (ASR). The ASR includes crime statistics and institutional policies concerning campus security, such as those concerning alcohol and drug use, crime prevention, the reporting of crimes, sexual assault, and other matters. The ASR is available for review here.

EEO IS THE LAW

Penn State is an equal opportunity employer and is committed to providing employment opportunities to all qualified applicants without regard to race, color, religion, age, sex, sexual orientation, gender identity, national origin, disability or protected veteran status. If you are unable to use our online application process due to an impairment or disability, please contact .

The Pennsylvania State University is committed to and accountable for advancing equity, respect, and belonging. We embrace individual uniqueness, as well as a culture of belonging that supports equity initiatives, leverages the educational and institutional benefits of inclusion in society, and provides opportunities for engagement intended to help all members of the community thrive. We value belonging as a core strength and an essential element of the university's teaching, research, and service mission.

Federal Contractors Labor Law Poster

PA State Labor Law Poster

Penn State Policies

Copyright Information

Hotlines",2025-07-19T00:00:00.000Z,2025-07-25,"['This position is funded for 12 months; continuation past 12 months will be based on university need, performance, and/or availability of funding', 'Proficiency in statistical analysis and modeling, including longitudinal data analysis and mixed-effects models', 'Experience with multi-omic data analysis, including transcriptomic, metabolomic, and epigenetic datasets', 'Skill in data preprocessing, including normalization, batch correction, and outlier detection', 'Experience with data integration and harmonization across platforms and timepoints', 'Proficiency in programming languages commonly used in data science, such as R or Python', 'Ability to create publication-ready visualizations and summary outputs for diverse audiences', 'Experience contributing to scientific manuscripts and conference presentations, especially methods and results sections', 'Knowledge of reproducible research practices, including workflow documentation and version control (e.g., Git)', 'Familiarity with research design and methodology, particularly in child development, maltreatment, or early life adversity', 'Strong problem-solving skills and ability to work independently within established research goals', 'Effective written and verbal communication skills for technical and collaborative work', 'Ability to train and support junior team members, including onboarding and mentoring student researchers', 'Experience working in interdisciplinary research teams', 'Questions related to flexible work should be directed to the hiring manager during the interview process', 'MINIMUM EDUCATION, WORK EXPERIENCE & REQUIRED CERTIFICATIONS', ""Bachelor's Degree1+ years of relevant experience; or an equivalent combination of education and experience accepted"", 'Required Certifications:None', 'Employment with the University will require successful completion of background check(s) in accordance with University policies', 'Applicants must be authorized to work in the U.S']","['Under the direction of Dr. Idan Shalev, this position will work on federally funded projects and lead the development and execution of computational workflows to analyze longitudinal multi-omic data', 'This position will support the integration, quality control, and statistical analysis of transcriptomic, metabolomic, and epigenetic datasets across time, ensure methodological rigor in testing study hypotheses, and contribute to the generation of reproducible, high-quality research outputs', 'Develop and implement statistical models and data workflows for analysis of transcriptomic, metabolomic, and epigenetic data across three longitudinal timepoints', 'Conduct data integration and harmonization across multi-omic platforms, ensuring alignment with study protocols and cohort structures', 'Perform quality control and preprocessing of raw omics datasets, including normalization, batch correction, and outlier detection, generating usable datasets for future analyses', 'Generate publication-ready data visualizations and summary outputs for internal reporting, scientific publications, and grant progress updates', 'Contribute to manuscripts and conference abstracts by preparing methods and results sections in collaboration with the study team', 'Support onboarding and training of student researchers in computational methods and data management procedures', 'Document analytical pipelines and code to ensure reproducibility and adherence to open science best practices']",True,[],,"['Longitudinal Data Analysis', 'Mixed-Effects Models', 'Multi-Omic Data Integration', 'Data Preprocessing', 'Statistical Modeling', 'Data Visualization', 'Reproducible Research Practices', 'Programming in R and Python', 'Version Control (Git)']","Longitudinal Data Analysis: Used to analyze multi-omic data collected across multiple timepoints to understand changes over time.; Mixed-Effects Models: Applied for statistical modeling of longitudinal multi-omic datasets to account for both fixed and random effects.; Multi-Omic Data Integration: Combining transcriptomic, metabolomic, and epigenetic data across platforms and timepoints for comprehensive analysis.; Data Preprocessing: Includes normalization, batch correction, and outlier detection to prepare raw omics data for analysis.; Statistical Modeling: Developing and implementing models to test study hypotheses and analyze biological datasets.; Data Visualization: Creating publication-ready visual summaries and outputs for scientific reporting and grant updates.; Reproducible Research Practices: Documenting analytical pipelines and code to ensure reproducibility and adherence to open science standards.; Programming in R and Python: Using these languages to develop computational workflows and perform statistical analyses on multi-omic data.; Version Control (Git): Managing code and workflow documentation to support reproducibility and collaboration."
F595o4pTxLpOHPEbAAAAAA==,Data Scientist - Senior Jobs,"Job Description

Why Choose Royce Geo, A GRVTY Company

We're not your typical government contracting company, nor do we want to be. At Royce Geo, A GRVTY Company, we live for building durable and long-lasting relationships with our clients, providing exceptional service with a CAN'T QUIT / WON'T QUIT attitude. We are creating a culture of winning, optimism, FUN, and caring for the person next to you. If you want to work in a real team environment and share the wealth and satisfaction of providing real value to your customer, then this company may be just for you.

Royce Geo, A GRVTY Company, prides ourselves in our values-first approach. Our values of Accountability, Attitude, Communication, Innovation, and Leadership are integrated into how we approach problems, guide our interactions with others, and create the framework for our culture. We recognize and reward our team members that champion these attributes.

We offer a competitive benefit package that is designed to attract and retain exceptional talent. We take care of our team members from multiple facets including health, financial, and well-being programs:
• Robust health plan including medical, dental, and vision
• Health Savings Account with company contribution
• Annual Paid Time Off and Paid Holidays
• Paid Parental Leave
• 401k with generous company match
• Training and Development Opportunities
• Award Programs
• Variety of Company Sponsored Events
• **Requires an active TS/SCI Security Clearance****

Position Summary:

We are looking for a Senior Data Scientist, with experience processing and analyzing large datasets, who will use their technical knowledge, experience, and customer-centric focus to create and deliver world-class analytic processes, scripting solutions, and data modeling content. This is a mission-driven opportunity to support the DoD and Intelligence Community.

The Data Scientist will coordinate with our clients to understand questions and issues involving the client's datasets, then determine the best method and approach to create data-driven solutions within program guidelines. This position will be relied upon as a Subject Matter Expert (SME), and be expected to lead/assist in the development of automated processes, architect data science solutions, automated workflows, conduct analysis, use available tools to analyze data, remain adaptable to mission requirements, and identify patterns to help solve some of the complex problems that face the DoD and Intelligence Community (IC).

Responsibilities
• Work with large structured / unstructured data in a modeling and analytical environment to define and create streamline processes in the evaluation of unique datasets and solve challenging intelligence issues
• Lead and participate in the design of solutions and refinement of pre-existing processes
• Work with Customer Stakeholders, Program Managers, and Product Owners to translate road map features into components/tasks, estimate timelines, identify resources, suggest solutions, and recognize possible risks
• Use exploratory data analysis techniques to identify meaningful relationships, patterns, or trends from complex data
• Combine applied mathematics, programming skills, analytical techniques, and data to provide impactful insights for decision makers
• Research and implement optimization models, strategies, and methods to inform data management activities and analysis
• Apply big data analytic tools to large, diverse sets of data to deliver impactful insights and assessments
• Conduct peer reviews to improve quality of workflows, procedures, and methodologies
• Help build high-performing teams; mentor team members providing development opportunities to increase their technical skills and knowledge

Required Qualifications:
• Active TS/SCI Clearance with ability to obtain a CI Poly
• 10+ years of relevant experience. (A combination of years of experience & professional certifications/trainings can be used in lieu of years of experience)
• Experience supporting IC operations
• Possess expert level knowledge to manipulate and analyze structured/ unstructured data
• Demonstrated experience in data mining and developing/maintaining/manipulating databases
• Demonstrated experience in identifying potential systems enhancements, new capabilities, concept demonstrators, and capability business cases
• Demonstrated experience using GOTS data processing and analytics capabilities to modernize analytic methodologies
• Demonstrated experience using COTS statistical software (Map Large, Tableau, MatLab) for advanced statistical analysis of operational tools and data visualization which enables large datasets to be interrogated and allows for patterns, relationships, and anticipatory behavioral likelihoods that may not be apparent using traditional single discipline means
• Knowledge of advanced analytic methodologies, and experience in implementing and executing those methodologies to enable customer satisfaction
• Demonstrated experience in directing activities of highly skilled technical and analytical teams responsible for developing solutions to highly complex analytical/intelligence problems
• Experienced in conducting multi-INT and technology specific research to support mission operations
• Possess effective communications skills; capable of providing highlydetailed information in an easy-to-understand format

Desired Qualifications:
• Possess Master's degree in Data Scienceor related technical field
• Experience developing and working with Artificial Intelligence and Machine Learning (AI/ML)
• Demonstrated experience of advanced programming techniques, using one or more of the following: HTML 5/Javascript, ArcObjects, Python, Model Builder, Oracle, SQL, GIScience, GeospatiavAnalysis, Statistics, ArcGIS Desktop, ArcGIS Server, Arc SDE, ArcIMS.
• Experience using NET, Python, C++, and/or JAVA programming for web interface development and geodatabase development.
• Experience building and maintaining databases of GEOINT, SIGINT, or OSINT data related to the area of interest needs.
• Data Visualization Experience which may include Matrix Analytics, Network Analytics, Graphing Data that assist the analytical workforce in generating common operational pictures depicting fused intelligence and information to support informal assessments and finished products

EEO Statement

Royce Geo, A GRVTY Company, is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran and will not be discriminated against on the basis of disability.

Anyone requiring reasonable accommodations should email recruiting@grvty.com or call 703-544-7930 with requested details. A member of the HR team will respond to your request within 2 business days.

Know Your Rights: Workplace Discrimination is Illegal (eeoc.gov)

Datascientist2025

About Royce Geo

Established in 2015, Royce Geo has quickly evolved into a well-rounded, diverse, small business tackling some of the most complex issues for our Defense and Intelligence Community clients. We are an award-winning small business firm, providing vital support to our mission partners across four core areas: Geospatial Information Technology, Data Analytics, Intelligence, and Training.

Our team members are highly skilled subject matter experts, who listen and partner with our clients to accomplish the mission. We own the problem and find the solution while upholding the highest standards-to exceed expectations. We take risks and challenge the status quo to deliver innovative and cutting-edge solutions.

Our employee-centric company culture is everything. Even while we grow, our small company mentality continues to exist. We demand inspiration from our leadership, and accountability from all so that we can influence others through our actions. This is Royce Geo.",2025-07-25T00:00:00.000Z,2025-07-25,"['**Requires an active TS/SCI Security Clearance****', 'We are looking for a Senior Data Scientist, with experience processing and analyzing large datasets, who will use their technical knowledge, experience, and customer-centric focus to create and deliver world-class analytic processes, scripting solutions, and data modeling content', 'Active TS/SCI Clearance with ability to obtain a CI Poly', '10+ years of relevant experience', '(A combination of years of experience & professional certifications/trainings can be used in lieu of years of experience)', 'Experience supporting IC operations', 'Possess expert level knowledge to manipulate and analyze structured/ unstructured data', 'Demonstrated experience in data mining and developing/maintaining/manipulating databases', 'Demonstrated experience in identifying potential systems enhancements, new capabilities, concept demonstrators, and capability business cases', 'Demonstrated experience using GOTS data processing and analytics capabilities to modernize analytic methodologies', 'Demonstrated experience using COTS statistical software (Map Large, Tableau, MatLab) for advanced statistical analysis of operational tools and data visualization which enables large datasets to be interrogated and allows for patterns, relationships, and anticipatory behavioral likelihoods that may not be apparent using traditional single discipline means', 'Knowledge of advanced analytic methodologies, and experience in implementing and executing those methodologies to enable customer satisfaction', 'Demonstrated experience in directing activities of highly skilled technical and analytical teams responsible for developing solutions to highly complex analytical/intelligence problems', 'Experienced in conducting multi-INT and technology specific research to support mission operations', 'Possess effective communications skills; capable of providing highlydetailed information in an easy-to-understand format']","[""The Data Scientist will coordinate with our clients to understand questions and issues involving the client's datasets, then determine the best method and approach to create data-driven solutions within program guidelines"", 'This position will be relied upon as a Subject Matter Expert (SME), and be expected to lead/assist in the development of automated processes, architect data science solutions, automated workflows, conduct analysis, use available tools to analyze data, remain adaptable to mission requirements, and identify patterns to help solve some of the complex problems that face the DoD and Intelligence Community (IC)', 'Work with large structured / unstructured data in a modeling and analytical environment to define and create streamline processes in the evaluation of unique datasets and solve challenging intelligence issues', 'Lead and participate in the design of solutions and refinement of pre-existing processes', 'Work with Customer Stakeholders, Program Managers, and Product Owners to translate road map features into components/tasks, estimate timelines, identify resources, suggest solutions, and recognize possible risks', 'Use exploratory data analysis techniques to identify meaningful relationships, patterns, or trends from complex data', 'Combine applied mathematics, programming skills, analytical techniques, and data to provide impactful insights for decision makers', 'Research and implement optimization models, strategies, and methods to inform data management activities and analysis', 'Apply big data analytic tools to large, diverse sets of data to deliver impactful insights and assessments', 'Conduct peer reviews to improve quality of workflows, procedures, and methodologies', 'Help build high-performing teams; mentor team members providing development opportunities to increase their technical skills and knowledge']",True,[],,"['Exploratory Data Analysis', 'Data Mining', 'Data Modeling', 'Optimization Models', 'Big Data Analytics', 'Statistical Software', 'Data Visualization', 'SQL', 'Python', 'C++', 'Java', 'Geospatial Analysis', 'Machine Learning', 'Automated Workflows', 'Data Pipelines', 'Applied Mathematics', 'Data Mining and Database Management']","Exploratory Data Analysis: Used to identify meaningful relationships, patterns, or trends from complex datasets to support intelligence problem-solving.; Data Mining: Applied to extract useful information and patterns from large structured and unstructured datasets relevant to defense and intelligence operations.; Data Modeling: Creating data models to represent and analyze complex datasets for decision-making and operational insights.; Optimization Models: Researching and implementing mathematical optimization techniques to improve data management and analytical processes.; Big Data Analytics: Applying analytic tools to large, diverse datasets to generate impactful insights for the Department of Defense and Intelligence Community.; Statistical Software: Using commercial off-the-shelf tools like Tableau, MatLab, and Map Large for advanced statistical analysis and data visualization.; Data Visualization: Creating visual representations such as network analytics and graphing to support intelligence assessments and operational pictures.; SQL: Utilized for database development and manipulation of geospatial and intelligence-related data.; Python: Used for programming, scripting solutions, and data analysis within the data science workflows.; C++: Applied in programming for web interface and geodatabase development related to intelligence data.; Java: Used for web interface development and geodatabase management in intelligence data systems.; Geospatial Analysis: Analyzing GEOINT data using GIScience tools like ArcGIS Desktop, Server, and related technologies.; Machine Learning: Experience developing and working with ML techniques to support advanced data analytics in intelligence contexts.; Automated Workflows: Designing and implementing automated data processing and analytic workflows to streamline intelligence analysis.; Data Pipelines: Architecting data science solutions that include automated data ingestion and processing pipelines.; Applied Mathematics: Combining mathematical techniques with programming and analytics to derive insights from complex datasets.; Data Mining and Database Management: Developing, maintaining, and manipulating databases to support intelligence data needs."
JIwW_VAAwcd4PSYNAAAAAA==,Data Analyst Jobs,"Overview

We are looking for a Data Analyst to work with our team and our clients to architect and develop data models, data warehouses, lakes, and lakehouses, data governance, services, and pipelines. We are looking for more than just a ""Data Analyst"", but a technologist with excellent communication and customer service skills and a passion for data and problem solving.

Contributions
• Work on migration of data environments with performance and reliability
• Assess, understand, and document data sources
• Address technical inquiries concerning customization, integration, enterprise architecture and general feature / functionality of data products
• Experience working with database / data warehouse solutions in cloud (Preferably GCP. Alternatively Azure, AWS)
• Key must have skill sets - data modeling, data understanding
• You will be part of our Data Exploitation Practice!

Qualifications
• Ability to hold a position of public trust with the US government.
• Bachelor's degree in computer science, information systems, engineering, business, or a scientific or technical discipline
• 0-2 years of experience with data model and date warehouse design, including schema design and entity relationship diagrams
• 0-2 years of experience collaborating with management, personas, and engineers to support data quality efforts
• Experience with large-scale data migration
• Experience designing storage and retrieval solutions for both structured and unstructured data, in support of data science pipelines
• Experience designing data platforms for user consumption
• Experience supporting the development of related data artifacts
• Data Dictionary
• Entity Relationship Diagrams
• Data Flow Diagram
• Data Quality Plan
• Data Management Plan
• Data Asset Catalog
• Experience with relational SQL and NoSQL databases
• Familiarity with cloud technology, using AWS, Azure, or GCP. Knowledge of managed service offerings (e.g. AWS EC2, EMR, RDS, Redshift)
• Experience developing specifications for modern large-scale data repositories including development of specifications for cloud-based database solutions
• Familiarity with FIPS 140-2 compliant encryption to both stored data and data in motion
• Understand customer requirements and prioritize for maximum customer / user experience
• Experience working with software and data science teams to operationalize information
• Experience collaborating with staff, IT customers, and other technical and non-technical staff and contractors at all levels
• Experience working in an agile environment
• Experience working with BigQuery and Looker

About steampunk

Steampunk relies on several factors to determine salary, including but not limited to geographic location, contractual requirements, education, knowledge, skills, competencies, and experience. The projected compensation range for this position is $50,000 to $115,000. The estimate displayed represents a typical annual salary range for this position. Annual salary is just one aspect of Steampunk's total compensation package for employees. Learn more about additional Steampunk benefits here.

Identity Statement

As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud.

Steampunk is a Change Agent in the Federal contracting industry, bringing new thinking to clients in the Homeland, Federal Civilian, Health and DoD sectors. Through our Human-Centered delivery methodology, we are fundamentally changing the expectations our Federal clients have for true shared accountability in solving their toughest mission challenges. As an employee owned company, we focus on investing in our employees to enable them to do the greatest work of their careers - and rewarding them for outstanding contributions to our growth. If you want to learn more about our story, visit http://www.steampunk.com .

We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law. Steampunk participates in the E-Verify program.",2025-07-25T00:00:00.000Z,2025-07-25,"['We are looking for more than just a ""Data Analyst"", but a technologist with excellent communication and customer service skills and a passion for data and problem solving', 'Experience working with database / data warehouse solutions in cloud (Preferably GCP', 'Alternatively Azure, AWS)', 'Key must have skill sets - data modeling, data understanding', 'Ability to hold a position of public trust with the US government', ""Bachelor's degree in computer science, information systems, engineering, business, or a scientific or technical discipline"", '0-2 years of experience with data model and date warehouse design, including schema design and entity relationship diagrams', '0-2 years of experience collaborating with management, personas, and engineers to support data quality efforts', 'Experience with large-scale data migration', 'Experience designing storage and retrieval solutions for both structured and unstructured data, in support of data science pipelines', 'Experience designing data platforms for user consumption', 'Experience supporting the development of related data artifacts', 'Data Dictionary', 'Entity Relationship Diagrams', 'Data Flow Diagram', 'Data Quality Plan', 'Data Management Plan', 'Data Asset Catalog', 'Experience with relational SQL and NoSQL databases', 'Familiarity with cloud technology, using AWS, Azure, or GCP', 'Knowledge of managed service offerings (e.g', 'AWS EC2, EMR, RDS, Redshift)', 'Experience developing specifications for modern large-scale data repositories including development of specifications for cloud-based database solutions', 'Familiarity with FIPS 140-2 compliant encryption to both stored data and data in motion', 'Understand customer requirements and prioritize for maximum customer / user experience', 'Experience working with software and data science teams to operationalize information', 'Experience collaborating with staff, IT customers, and other technical and non-technical staff and contractors at all levels', 'Experience working in an agile environment', 'Experience working with BigQuery and Looker']","['We are looking for a Data Analyst to work with our team and our clients to architect and develop data models, data warehouses, lakes, and lakehouses, data governance, services, and pipelines', 'Work on migration of data environments with performance and reliability', 'Assess, understand, and document data sources', 'Address technical inquiries concerning customization, integration, enterprise architecture and general feature / functionality of data products', 'You will be part of our Data Exploitation Practice!']",True,[],,"['Data Modeling', 'Data Warehouses', 'Data Lakes and Lakehouses', 'Data Governance', 'Data Pipelines', 'Data Migration', 'Data Quality Management', 'Data Dictionary', 'Entity Relationship Diagrams', 'Data Flow Diagrams', 'Data Management Plan', 'Data Asset Catalog', 'Relational SQL Databases', 'NoSQL Databases', 'Cloud Data Platforms', 'Managed Cloud Services', 'FIPS 140-2 Encryption', 'Data Science Pipelines', 'BigQuery', 'Looker', 'Agile Methodology']","Data Modeling: Designing data models and schemas to structure data effectively for warehouses and lakes.; Data Warehouses: Developing and managing centralized repositories for structured data to support analytics.; Data Lakes and Lakehouses: Architecting storage solutions that handle both structured and unstructured data for flexible analytics.; Data Governance: Implementing policies and processes to ensure data quality, security, and compliance.; Data Pipelines: Building and maintaining data workflows to move and transform data for analysis.; Data Migration: Executing large-scale transfers of data environments with focus on performance and reliability.; Data Quality Management: Collaborating to support data quality efforts and maintain data integrity.; Data Dictionary: Documenting metadata to describe data elements and their meanings.; Entity Relationship Diagrams: Visualizing data relationships to support database and warehouse design.; Data Flow Diagrams: Mapping data movement and processing within systems.; Data Management Plan: Planning and documenting strategies for data handling and lifecycle.; Data Asset Catalog: Maintaining an inventory of data assets for discovery and governance.; Relational SQL Databases: Using structured query language to manage and query relational data.; NoSQL Databases: Working with non-relational databases to handle diverse data types.; Cloud Data Platforms: Utilizing cloud services like AWS, Azure, and GCP for scalable data storage and processing.; Managed Cloud Services: Leveraging cloud-managed offerings such as AWS EC2, EMR, RDS, and Redshift for data infrastructure.; FIPS 140-2 Encryption: Applying compliant encryption standards to secure data at rest and in transit.; Data Science Pipelines: Supporting data workflows that enable data science and analytics processes.; BigQuery: Using Google's cloud data warehouse for large-scale data analytics.; Looker: Developing business intelligence dashboards and reports for data visualization.; Agile Methodology: Working within agile frameworks to iteratively develop and deliver data solutions."
FSq23doT5Q3_l8m3AAAAAA==,Senior Data Scientist  Marketing Mix Modeling (MMM),"Job Title: Senior Data Scientist Marketing Mix Modeling (MMM)

Type: Contract
Work Hours: Must work in PST time zone
Location: Remote (Canada)

Role Overview

We are hiring two Senior Data Scientists with strong hands-on experience in Marketing Mix Modeling (MMM). The ideal candidate will have deep statistical expertise, solid Python and SQL skills, and the ability to translate modeling insights into business strategy. Experience working with large-scale retail or CPG marketing data is preferred.

Key Responsibilities
• Build, validate, and interpret MMM models to quantify channel effectiveness
• Develop actionable insights and present optimization recommendations to stakeholders
• Integrate internal and external data sources into unified MMM datasets
• Use Python for modeling and SQL for data extraction and transformation
• Collaborate closely with marketing, finance, and analytics teams

Required Qualifications
• 5 7+ years of experience in data science or marketing analytics
• Minimum 2 years of deep, hands-on MMM experience (Bayesian or Frequentist preferred)
• Proficient in Python (pandas, statsmodels, PyMC3 or similar)
• Strong SQL skills for querying and transforming large datasets
• Excellent communication and visualization skills to explain technical insights to business users
• Retail/media/CPG experience highly desirable",2025-07-09T00:00:00.000Z,2025-07-25,"['The ideal candidate will have deep statistical expertise, solid Python and SQL skills, and the ability to translate modeling insights into business strategy', '5 7+ years of experience in data science or marketing analytics', 'Proficient in Python (pandas, statsmodels, PyMC3 or similar)', 'Strong SQL skills for querying and transforming large datasets', 'Excellent communication and visualization skills to explain technical insights to business users']","['Work Hours: Must work in PST time zone', 'Build, validate, and interpret MMM models to quantify channel effectiveness', 'Develop actionable insights and present optimization recommendations to stakeholders', 'Integrate internal and external data sources into unified MMM datasets', 'Use Python for modeling and SQL for data extraction and transformation', 'Collaborate closely with marketing, finance, and analytics teams']",True,[],,"['Marketing Mix Modeling', 'Bayesian Modeling', 'Frequentist Modeling', 'Python', 'Pandas', 'Statsmodels', 'PyMC3', 'SQL']",Marketing Mix Modeling: Used to build and interpret models quantifying marketing channel effectiveness for business optimization.; Bayesian Modeling: Applied in MMM to incorporate prior knowledge and uncertainty in statistical modeling.; Frequentist Modeling: Used as an alternative statistical approach in MMM for hypothesis testing and parameter estimation.; Python: Primary programming language used for data modeling and analysis in MMM.; Pandas: Python library used for data manipulation and preparation of MMM datasets.; Statsmodels: Python package utilized for statistical modeling and inference in MMM.; PyMC3: Probabilistic programming framework used for Bayesian statistical modeling in MMM.; SQL: Used for querying and transforming large-scale marketing and retail datasets.
qpj3zaGyt6CCKKexAAAAAA==,"Director, Data Scientist – Apollo/Card Data","Director, Data Scientist - Apollo/Card Data Join to apply for the Director, Data Scientist - Apollo/Card Data role at Capital One Director, Data Scientist - Apollo/Card Data Join to apply for the Director, Data Scientist - Apollo/Card Data role at Capital One Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making. As a Data Scientist at Capital One, you’ll be part of a team that’s leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives. Team Description Apollo (part of Card DMDC) is Capital One’s one stop shop for authoritative, 360 degree information on US businesses. We are on a mission to build a market leading, business critical Business Data Product and Platform that gives our customers a competitive advantage through information. Our customers rely on Apollo’s data and capabilities to market, sell, verify, underwrite, serve, and protect business customers, often in real-time intelligent ways. Business data is a complex, multi-billion dollar problem that is poorly served by legacy providers. We are tackling this critical opportunity by acquiring and processing massive amounts of data, leveraging cutting-edge ML/AI to resolve identity and predict valuable features and architecting interfaces that allow our users to seamlessly integrate Apollo into their workflows Data Science is at the heart of Apollo and this role will have an opportunity to shape the next generation of capabilities. Role Description In this role, you will: Lead a team of data scientists and collaborate with machine learning engineers, data engineers, business analysts and product managers to deliver product(s) customers love. Lead machine learning and data science technical direction and execution (operations, governance, processes and practice) working closely with product management to craft a roadmap and success criterion. Lean on your deep technical background in graph-based machine learning, deep learning, software engineering and algorithm development to organize, grow and manage the ML/AI capabilities for the product. Flex your interpersonal skills to translate the complexity of your work into tangible business goals The Ideal Candidate is: Technical Innovator. You have a strong background in ML/AI and engineering practices with experience in Entity Resolution, Information Retrieval, Graph-based ML, LLM/Embeddings or Deep Learning. You have hands-on experience developing effective data science solutions, while pushing the envelope with state-of-the-art techniques. Customer-back. Product mindset. You are deeply curious about customer needs and bring a product mindset to drive business results, integrating ML/AI design, engineering and execution. You identify high-leverage efforts and the necessary trade-offs to shape a roadmap that balances transformative innovation with time-to-value and pragmatism. Empathetic People Leader. You establish a culture of inclusiveness, cooperation and candor. You’re passionate about talent development, provide frequent actionable feedback to team members, and promote innovation Strategic Thinker and Communicator. You love asking questions and pushing hard for answers. You challenge conventional thinking and work with stakeholders to identify and improve the status quo by bringing clarity to big, undefined problems.You set the team vision, and inspire your team and peers to execute towards it. Basic Qualifications: Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date : A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 9 years of experience performing data analytics A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 7 years of experience performing data analytics A PHD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 4 years of experience performing data analytics At least 4 years of experience leveraging open source programming languages for large scale data analysis At least 4 years of experience working with machine learning At least 4 years of experience utilizing relational databases Preferred Qualifications: PhD in “STEM” field (Science, Technology, Engineering, or Mathematics) plus 5 years of experience in data analytics At least 1 year of experience working with AWS At least 3 year of experience managing people At least 5 years of experience in Python, Scala, or R for large scale data analysis At least 5 years of experience with machine learning Capital One will consider sponsoring a new qualified applicant for employment authorization for this position. The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. McLean, VA: $263,900 - $301,200 for Dir, Data Science New York, NY: $287,800 - $328,500 for Dir, Data Science Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate’s offer letter. This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan. Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. This role is expected to accept applications for a minimum of 5 business days. No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC). Seniority level Seniority level Director Employment type Employment type Full-time Job function Job function Other Referrals increase your chances of interviewing at Capital One by 2x Get notified about new Director jobs in New York, NY . New York, NY $120,000.00-$170,000.00 3 weeks ago New York, NY $130,000.00-$160,000.00 1 month ago New York, NY $132,000.00-$152,000.00 2 weeks ago Brooklyn, NY $150,000.00-$180,000.00 1 week ago New York City Metropolitan Area $175,000.00-$200,000.00 1 week ago New York, NY $138,500.00-$200,800.00 1 week ago New York, NY $170,000.00-$190,000.00 4 days ago Fairfield, NJ $150,000.00-$170,000.00 2 weeks ago Marketing Director/Director of Commercial Brand Strategy Brooklyn, NY $150,000.00-$175,000.00 7 hours ago New York City Metropolitan Area $200,400.00-$333,960.00 2 days ago Manhattan, NY $149,133.00-$195,000.00 3 days ago New York, NY $130,000.00-$200,000.00 1 month ago New York, NY $189,600.00-$260,700.00 1 week ago New York, NY $173,432.42-$204,968.58 1 week ago New York, NY $200,000.00-$240,000.00 1 month ago New York, NY $189,600.00-$260,700.00 1 week ago New York, NY $170,000.00-$190,000.00 3 weeks ago New York, NY $160,000.00-$175,000.00 4 days ago General Manager / Center Director / Fitness Director / Personal East Rutherford, NJ $14,400.00-$90,000.00 1 month ago New York, NY $350,000.00-$385,000.00 1 week ago Director of Brand Marketing - Color & Conservation New York, NY $165,000.00-$180,000.00 4 days ago New York, NY $120,000.00-$220,000.00 1 year ago New York City Metropolitan Area $110,000.00-$115,000.00 1 week ago New York, NY $110,000.00-$130,000.00 6 days ago New York City Metropolitan Area $208,920.00-$348,000.00 2 weeks ago New York, NY $147,000.00-$205,000.00 2 weeks ago We’re unlocking community knowledge in a new way. Experts add insights directly into each article, started with the help of AI. #J-18808-Ljbffr",2025-07-16T00:00:00.000Z,2025-07-25,,,True,"['Large Language Models', 'Embeddings']",Large Language Models: Experience with LLMs and embeddings is required for advanced AI capabilities in the product.; Embeddings: Used alongside LLMs for representing data in vector space to improve AI-driven insights.,"['Statistical Modeling', 'Relational Databases', 'Machine Learning', 'Graph-based Machine Learning', 'Deep Learning', 'Entity Resolution', 'Information Retrieval', 'Data Analytics', 'Open Source Programming Languages', 'AWS']","Statistical Modeling: Used to personalize credit card offers and drive data-driven decision-making at scale.; Relational Databases: Employed for managing and querying large-scale structured business and customer data.; Machine Learning: Applied to analyze billions of customer records and unlock business opportunities.; Graph-based Machine Learning: Utilized for entity resolution and complex relationship modeling within business data.; Deep Learning: Used as part of advanced algorithm development and ML capabilities for the product.; Entity Resolution: Critical for identifying and linking business entities across datasets.; Information Retrieval: Applied to efficiently access and process relevant business data.; Data Analytics: Core activity involving large scale data analysis using programming languages like Python, Scala, or R.; Open Source Programming Languages: Languages such as Python, Scala, and R are used for large scale data analysis.; AWS: Cloud platform experience preferred for data storage, processing, and ML deployment."
rb-LZhza9xIgTYTaAAAAAA==,"Senior Data Scientist, AI Foundations","Senior Data Scientist, AI Foundations

Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making.

As a Data Scientist at Capital One, you’ll be part of a team that’s leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives.

Team Description

AI Foundations Specialist Models Data Science team builds and ships state of the art scalable architecture, AI/ML solutions for Capital One’s award-winning mobile app. We partner with product, tech and design teams to deliver app features that delight customers with dynamic and personalized experiences, enable them to chat with Capital One’s digital assistant Eno, or search for useful contents. You will be the driving force to experiment, innovate and create next generation experiences powered by the latest emerging generative AI technologies.

In this role, you will:
• Partner with a cross-functional team of data scientists, software engineers, machine learning engineers and product managers to deliver AI powered products that change how customers interact with their money.
• Leverage a broad stack of technologies — Pytorch, AWS Ultraclusters, Hugging Face, LangChain, Lightning, VectorDBs, and more — to reveal the insights hidden within huge volumes of numeric and textual data.
• Be the expert in Natural Language Processing (NLP) to harness the power of Large Language Models (LLMs), adapt and finetune them for customer facing applications and features.
• Build machine learning and NLP models through all phases of development, from design through training, evaluation, and validation; partnering with engineering teams to operationalize them in scalable and resilient production systems that serve 80+ million customers.
• Flex your interpersonal skills to translate the complexity of your work into tangible business goals.

The Ideal Candidate is:
• Customer first. You love the process of analyzing and creating, but also share our passion to do the right thing. You know at the end of the day it’s about making the right decision for our customers.
• Innovative. You continually research and evaluate emerging technologies. You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them.
• Creative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You’re not afraid to share a new idea.
• A leader. You challenge conventional thinking and work with stakeholders to identify and improve the status quo. You're passionate about talent development for your own team and beyond.
• Technical. You’re comfortable with advanced ML and DL technologies including language models and are passionate about developing further. You have hands-on experience working with LLMs and solutions using open-source tools and cloud computing platforms.
• Influential. You are passionate about AI/ML and can bring along a cross functional team in breakthrough innovations. You communicate clearly and effectively to share your findings with non-technical audiences.
• You are experienced in training language models or large computer vision models as well as have expertise in one or more key subdomains such as: training optimization, self-supervised learning, explainability, RLHF.
• You have an engineering mindset as shown by a track record of delivering models at scale both in training data and inference volumes. You have experience in delivering libraries, platforms, or solution level code to existing products.

Basic Qualifications:
• Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:
• A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 2 years of experience performing data analytics
• A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration

Preferred Qualifications:
• Master’s Degree in “STEM” field (Science, Technology, Engineering, or Mathematics), or PhD in “STEM” field (Science, Technology, Engineering, or Mathematics)
• Experience working with AWS
• At least 2 years’ experience in Python, Scala, or R
• At least 2 years’ experience with machine learning
• At least 2 years’ experience with SQL

Capital One will consider sponsoring a new qualified applicant for employment authorization for this position.

The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.

New York, NY: $145,100 - $165,600 for Sr Assoc, Data Science

San Jose, CA: $145,100 - $165,600 for Sr Assoc, Data Science

Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate’s offer letter.

This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.

Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.

This role is expected to accept applications for a minimum of 5 business days.

No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",2025-07-20T00:00:00.000Z,2025-07-25,"['Customer first', 'You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them', 'You thrive on bringing definition to big, undefined problems', 'You love asking questions and pushing hard to find answers', ""You're passionate about talent development for your own team and beyond"", 'Technical', 'You’re comfortable with advanced ML and DL technologies including language models and are passionate about developing further', 'You have hands-on experience working with LLMs and solutions using open-source tools and cloud computing platforms', 'Influential', 'You are passionate about AI/ML and can bring along a cross functional team in breakthrough innovations', 'You communicate clearly and effectively to share your findings with non-technical audiences', 'You are experienced in training language models or large computer vision models as well as have expertise in one or more key subdomains such as: training optimization, self-supervised learning, explainability, RLHF', 'You have an engineering mindset as shown by a track record of delivering models at scale both in training data and inference volumes', 'You have experience in delivering libraries, platforms, or solution level code to existing products', 'Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:', ""A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 2 years of experience performing data analytics"", ""A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration""]","['You will be the driving force to experiment, innovate and create next generation experiences powered by the latest emerging generative AI technologies', 'Partner with a cross-functional team of data scientists, software engineers, machine learning engineers and product managers to deliver AI powered products that change how customers interact with their money', 'Leverage a broad stack of technologies — Pytorch, AWS Ultraclusters, Hugging Face, LangChain, Lightning, VectorDBs, and more — to reveal the insights hidden within huge volumes of numeric and textual data', 'Be the expert in Natural Language Processing (NLP) to harness the power of Large Language Models (LLMs), adapt and finetune them for customer facing applications and features', 'Build machine learning and NLP models through all phases of development, from design through training, evaluation, and validation; partnering with engineering teams to operationalize them in scalable and resilient production systems that serve 80+ million customers', 'Flex your interpersonal skills to translate the complexity of your work into tangible business goals', 'You continually research and evaluate emerging technologies', 'You challenge conventional thinking and work with stakeholders to identify and improve the status quo']",True,"['Large Language Models', 'Generative AI', 'PyTorch', 'Hugging Face', 'LangChain', 'Lightning', 'Vector Databases', 'Reinforcement Learning with Human Feedback']","Large Language Models: Central to developing customer-facing AI features by adapting and fine-tuning these models.; Generative AI: Used to create next-generation personalized experiences and AI-powered products.; PyTorch: Deep learning framework employed for building and training neural network models.; Hugging Face: Open-source platform used for accessing and fine-tuning pre-trained language models.; LangChain: Framework used to build applications powered by language models, enabling complex AI workflows.; Lightning: Tool for simplifying and accelerating deep learning model training and deployment.; Vector Databases: Used to store and retrieve high-dimensional embeddings for AI applications like semantic search.; Reinforcement Learning with Human Feedback: Applied to improve AI model alignment and performance through iterative human feedback.","['Machine Learning', 'Natural Language Processing', 'Training Optimization', 'Self-Supervised Learning', 'Explainability', 'Reinforcement Learning with Human Feedback', 'Python', 'Scala', 'R', 'SQL', 'AWS']","Machine Learning: Used to build predictive models and AI-powered products that improve customer financial interactions.; Natural Language Processing: Applied to develop and fine-tune models that enable customer-facing applications like digital assistants and search features.; Training Optimization: Expertise required to efficiently train large language and computer vision models at scale.; Self-Supervised Learning: Used as a key subdomain technique for improving model training without extensive labeled data.; Explainability: Important for interpreting model decisions and ensuring transparency in AI/ML solutions.; Reinforcement Learning with Human Feedback: Applied to enhance model performance by incorporating human feedback during training.; Python: Programming language used for data analytics, machine learning, and model development.; Scala: Programming language experience preferred for data processing and analytics.; R: Used for statistical analysis and data analytics tasks.; SQL: Used for querying and managing large volumes of structured data.; AWS: Cloud platform leveraged for scalable computing resources and model deployment."
VzvO9O1Z2iE_TicQAAAAAA==,Data Scientist (Mid-Level) Jobs,"TITLE: Data Scientist (Mid-Level)

LOCATION: Marine Corps Intelligence Activity, Quantico VA

OVERVIEW: The Data Scientist (Mid-Level) will develop and implement data science solutions to support MCIA's intelligence analysis and production mission. The data scientist will apply expertise in machine learning, data mining, and predictive modeling to extract insights from large, complex datasets and enable data-driven decision-making.

RESPONSIBILITIES:
• Collaborate with analysts, collectors, and stakeholders to identify and prioritize data science requirements
• Perform data wrangling, data cleaning, and feature engineering to prepare data for analysis
• Design, train, and evaluate machine learning models for pattern recognition, anomaly detection, and prediction
• Conduct exploratory data analysis and statistical modeling to uncover trends, patterns, and relationships
• Develop data visualizations, dashboards, and reports to communicate insights to technical and non-technical audiences
• Implement data science pipelines and workflows to automate and scale analytic processes
• Stay current on emerging data science tools, techniques, and best practices relevant to MCIA mission

REQUIREMENTS:
• Bachelor's degree or equivalent experience in data science, computer science, applied mathematics, or related field
• Minimum 3 years of experience developing and implementing data science solutions in DoD/IC or similar environment
• Proficiency in data science programming languages (Python, R) and libraries (scikit-learn, pandas, TensorFlow)
• Experience with data manipulation, feature selection, model training/evaluation, and results interpretation
• Knowledge of statistics, probability, machine learning algorithms, and data visualization techniques
• Familiarity with big data processing tools (Hadoop, Spark) and cloud computing platforms (AWS, Azure)
• Active Top Secret/SCI security clearance

Excellent problem-solving, communication, and collaboration skills to work effectively in a multidisciplinary team

About Streamline

Streamline is a professional and technical solutions company focused on the U.S. Defense, Intelligence, and Special Operations communities. Our talented team of analyst, engineers, and military professionals support our clients most demanding missions. We offer an unmatched opportunity to grow and learn in an exciting and entrepreneurial environment. Highly motivated individuals will find a culture that values their individual input and compensates them well for their efforts.

Streamline provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.",2025-07-25T11:00:00.000Z,2025-07-25,"[""Bachelor's degree or equivalent experience in data science, computer science, applied mathematics, or related field"", 'Minimum 3 years of experience developing and implementing data science solutions in DoD/IC or similar environment', 'Proficiency in data science programming languages (Python, R) and libraries (scikit-learn, pandas, TensorFlow)', 'Experience with data manipulation, feature selection, model training/evaluation, and results interpretation', 'Knowledge of statistics, probability, machine learning algorithms, and data visualization techniques', 'Familiarity with big data processing tools (Hadoop, Spark) and cloud computing platforms (AWS, Azure)', 'Active Top Secret/SCI security clearance', 'Excellent problem-solving, communication, and collaboration skills to work effectively in a multidisciplinary team']","[""OVERVIEW: The Data Scientist (Mid-Level) will develop and implement data science solutions to support MCIA's intelligence analysis and production mission"", 'The data scientist will apply expertise in machine learning, data mining, and predictive modeling to extract insights from large, complex datasets and enable data-driven decision-making', 'Collaborate with analysts, collectors, and stakeholders to identify and prioritize data science requirements', 'Perform data wrangling, data cleaning, and feature engineering to prepare data for analysis', 'Design, train, and evaluate machine learning models for pattern recognition, anomaly detection, and prediction', 'Conduct exploratory data analysis and statistical modeling to uncover trends, patterns, and relationships', 'Develop data visualizations, dashboards, and reports to communicate insights to technical and non-technical audiences', 'Implement data science pipelines and workflows to automate and scale analytic processes', 'Stay current on emerging data science tools, techniques, and best practices relevant to MCIA mission']",True,[],,"['Machine Learning', 'Data Mining', 'Predictive Modeling', 'Data Wrangling', 'Feature Engineering', 'Exploratory Data Analysis', 'Statistical Modeling', 'Data Visualization', 'Data Science Pipelines', 'Python', 'R', 'Scikit-learn', 'Pandas', 'TensorFlow', 'Statistics', 'Probability', 'Big Data Processing Tools', 'Cloud Computing Platforms']","Machine Learning: Used to design, train, and evaluate models for pattern recognition, anomaly detection, and prediction in intelligence data.; Data Mining: Applied to extract insights from large, complex datasets to support intelligence analysis.; Predictive Modeling: Employed to forecast outcomes and enable data-driven decision-making in the intelligence context.; Data Wrangling: Performed to clean and prepare raw data for analysis and modeling.; Feature Engineering: Used to create relevant features from raw data to improve model performance.; Exploratory Data Analysis: Conducted to uncover trends, patterns, and relationships within intelligence datasets.; Statistical Modeling: Applied to analyze data and support inference in intelligence analysis.; Data Visualization: Developed dashboards and reports to communicate insights to both technical and non-technical stakeholders.; Data Science Pipelines: Implemented workflows to automate and scale analytic processes for intelligence missions.; Python: Programming language used for data science tasks including data manipulation and model development.; R: Programming language utilized for statistical analysis and data science.; Scikit-learn: Library used for implementing machine learning algorithms and model evaluation.; Pandas: Library employed for data manipulation and cleaning tasks.; TensorFlow: Used as a machine learning framework for model training and evaluation.; Statistics: Knowledge applied to analyze data and support modeling efforts.; Probability: Used to understand and model uncertainty in data and predictions.; Big Data Processing Tools: Tools like Hadoop and Spark used to handle and process large-scale datasets.; Cloud Computing Platforms: Platforms such as AWS and Azure used to deploy and scale data science solutions."
Luhjoi_lXJPh7xdSAAAAAA==,Data Scientist (TS/SCI + Poly) Jobs,"Description

The DarkStar Group, a GRVTY Company is seeking a Data Scientist with a TS/SCI + Poly clearance (applicable to this customer) to join one of our top projects in Chantilly, VA. Below is an overview of the project, as well as information on our company, our benefits, and our $25,000 referral program.

THE PROJECT

The DarkStar Group's team is charged with taking commercial and academic innovation high-side, in domains of Artificial Intelligence / Machine Learning (AI / ML) such as Computer Vision (Image and Video Processing), Natural Language Processing (NLP), and Audio Modeling. We also bring the best ideas, tools, and approaches in technology infrastructure (AWS, DevOps, etc.) to the IC. The tech stack used is extremely broad - anything cutting edge in the commercial market, the open source community, or the academic research community is likely involved: and if something isn't being looked at yet, you can make that happen.

This effort supports ALL missions of the Intelligence Community, including cyber-related data science missions. A seamless group of contractor and customer personnel work to create innovations that supply customer groups with the data sets, models, algorithms, software, and infrastructure they need to increase their mission success. Management is hands off, gives the team the freedom to explore new approaches, and markets the best ideas and results to all the other IC customers.

This project regularly needs various types of people - Data Scientists, Data / ETL Engineers, Analytic Software Engineers, Full Stack Developers, UI/UX Developers, and AWS/DevOps experts. We're particularly interested in people with any of the following experience:
• developing AI / ML models (neural networks, tree based algorithms, etc.);
• conducting data analysis in the fields of Computer Vision, NLP, or audio signal processing;
• doing data ingest and ETL into sponsor environments; or
• building data-analytic software systems.

Work on this program takes place throughout the Reston/Herndon/Chantilly, VA area (we cannot support remote work) and requires a TS/SCI + Poly clearance (acceptable to this customer).

The Role
• The data scientist will be working with several different types of cyber SME's to build a tool to help end users sift through data and find important information. We are looking for someone with great data science skills but also experience with adjacent skills i.e. data engineering (they might need to help with parsing raw data, etc.).

Required Skills
• Diverse data science skills (NLP, entity extraction, utilizing generative AI)
• Strong python programmer
• Data engineering experience
• Strong communication skills
• Must be able to comprehend requirements and effectively execute tasks accordingly
• Experience working with cyber data
About The DarkStar Group
Our Company

The DarkStar Group is a small business that solves BIG problems. We're one of the Inc. 5000 fastest-growing private companies in the US, and our engineers and scientists support the most critical national security missions in Virginia, Maryland, and elsewhere. Data Science, Software Engineering, Cloud/AWS Infrastructure, and Cyber/CNO are our core areas of expertise. We offer interesting and important work, job security, some of the best and most flexible benefits you'll find in the IC, and salaries so strong that they'll likely surprise you.

Our Benefits

The DarkStar Group offers exceptional compensation and benefits:
• very strong salaries;
• 100% company-paid medical, dental, and vision premiums for you and all dependents;
• the ability to get increased salary if you don't need medical/dental/vision;
• 100% company-paid disability and life insurance benefits;
• a generously-funded HSA;
• an 8% 401(k) contribution;
• 31 days of PTO/holidays to start (more with tenure);
• the ability to flex time across pay periods without using your PTO;
• a generous training budget;
• $25,000 employee referral bonuses;
• business development / growth incentives; and
• top notch company swag.
• * We have a huge growth opportunity, so we are offering up to a $25,000 reward for anyone new you refer whom we hire. **

The DarkStar Group, A GRVTY Company, is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran and will not be discriminated against on the basis of disability.

Anyone requiring reasonable accommodations should email ds_recruiting@grvty.comor call 703-544-7930 with requested details. A member of the HR team will respond to your request within 2 business days.

Know Your Rights: Workplace Discrimination is Illegal",2025-07-23T00:00:00.000Z,2025-07-25,"['developing AI / ML models (neural networks, tree based algorithms, etc.);', 'Work on this program takes place throughout the Reston/Herndon/Chantilly, VA area (we cannot support remote work) and requires a TS/SCI + Poly clearance (acceptable to this customer)', 'We are looking for someone with great data science skills but also experience with adjacent skills i.e. data engineering (they might need to help with parsing raw data, etc.)', 'Diverse data science skills (NLP, entity extraction, utilizing generative AI)', 'Strong python programmer', 'Data engineering experience', 'Strong communication skills', 'Must be able to comprehend requirements and effectively execute tasks accordingly', 'Experience working with cyber data']","[""The tech stack used is extremely broad - anything cutting edge in the commercial market, the open source community, or the academic research community is likely involved: and if something isn't being looked at yet, you can make that happen"", 'This effort supports ALL missions of the Intelligence Community, including cyber-related data science missions', 'This project regularly needs various types of people - Data Scientists, Data / ETL Engineers, Analytic Software Engineers, Full Stack Developers, UI/UX Developers, and AWS/DevOps experts', 'conducting data analysis in the fields of Computer Vision, NLP, or audio signal processing;', 'doing data ingest and ETL into sponsor environments; or', 'building data-analytic software systems', ""The data scientist will be working with several different types of cyber SME's to build a tool to help end users sift through data and find important information""]",True,['Generative AI'],Generative AI: Utilized for advanced AI capabilities including generating content or augmenting data analysis as part of the project.,"['Neural Networks', 'Tree-Based Algorithms', 'Natural Language Processing', 'Entity Extraction', 'Data Engineering', 'Python Programming', 'Data Ingest and ETL', 'Computer Vision', 'Audio Signal Processing']","Neural Networks: Used as part of AI/ML models to analyze complex data such as images, audio, and text in the project.; Tree-Based Algorithms: Applied in developing AI/ML models for classification or regression tasks within the data science work.; Natural Language Processing: Employed for analyzing and extracting information from text data as part of diverse data science skills required.; Entity Extraction: Used to identify and extract key entities from text data to support data analysis and information retrieval.; Data Engineering: Involves parsing raw data and building data pipelines to support data ingestion and preparation for analysis.; Python Programming: Primary programming language used for data science, AI/ML model development, and data engineering tasks.; Data Ingest and ETL: Processes for extracting, transforming, and loading data into sponsor environments to enable analysis and modeling.; Computer Vision: Applied in image and video processing tasks as part of the AI/ML models developed for the project.; Audio Signal Processing: Used to analyze audio data within the scope of data science and AI/ML model development."
zJn4GywD96dEf-_xAAAAAA==,"Senior Data Scientist, AI Foundations","Senior Data Scientist, AI Foundations

Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making.

As a Data Scientist at Capital One, you’ll be part of a team that’s leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives.

Team Description

AI Foundations Specialist Models Data Science team builds and ships state of the art scalable architecture, AI/ML solutions for Capital One’s award-winning mobile app. We partner with product, tech and design teams to deliver app features that delight customers with dynamic and personalized experiences, enable them to chat with Capital One’s digital assistant Eno, or search for useful contents. You will be the driving force to experiment, innovate and create next generation experiences powered by the latest emerging generative AI technologies.

In this role, you will:
• Partner with a cross-functional team of data scientists, software engineers, machine learning engineers and product managers to deliver AI powered products that change how customers interact with their money.
• Leverage a broad stack of technologies — Pytorch, AWS Ultraclusters, Hugging Face, LangChain, Lightning, VectorDBs, and more — to reveal the insights hidden within huge volumes of numeric and textual data.
• Be the expert in Natural Language Processing (NLP) to harness the power of Large Language Models (LLMs), adapt and finetune them for customer facing applications and features.
• Build machine learning and NLP models through all phases of development, from design through training, evaluation, and validation; partnering with engineering teams to operationalize them in scalable and resilient production systems that serve 80+ million customers.
• Flex your interpersonal skills to translate the complexity of your work into tangible business goals.

The Ideal Candidate is:
• Customer first. You love the process of analyzing and creating, but also share our passion to do the right thing. You know at the end of the day it’s about making the right decision for our customers.
• Innovative. You continually research and evaluate emerging technologies. You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them.
• Creative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You’re not afraid to share a new idea.
• A leader. You challenge conventional thinking and work with stakeholders to identify and improve the status quo. You're passionate about talent development for your own team and beyond.
• Technical. You’re comfortable with advanced ML and DL technologies including language models and are passionate about developing further. You have hands-on experience working with LLMs and solutions using open-source tools and cloud computing platforms.
• Influential. You are passionate about AI/ML and can bring along a cross functional team in breakthrough innovations. You communicate clearly and effectively to share your findings with non-technical audiences.
• You are experienced in training language models or large computer vision models as well as have expertise in one or more key subdomains such as: training optimization, self-supervised learning, explainability, RLHF.
• You have an engineering mindset as shown by a track record of delivering models at scale both in training data and inference volumes. You have experience in delivering libraries, platforms, or solution level code to existing products.

Basic Qualifications:
• Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:
• A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 2 years of experience performing data analytics
• A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration

Preferred Qualifications:
• Master’s Degree in “STEM” field (Science, Technology, Engineering, or Mathematics), or PhD in “STEM” field (Science, Technology, Engineering, or Mathematics)
• Experience working with AWS
• At least 2 years’ experience in Python, Scala, or R
• At least 2 years’ experience with machine learning
• At least 2 years’ experience with SQL

Capital One will consider sponsoring a new qualified applicant for employment authorization for this position.

The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.

New York, NY: $145,100 - $165,600 for Sr Assoc, Data Science

San Jose, CA: $145,100 - $165,600 for Sr Assoc, Data Science

Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate’s offer letter.

This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.

Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.

This role is expected to accept applications for a minimum of 5 business days.

No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",2025-07-20T00:00:00.000Z,2025-07-25,"['Customer first', 'You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them', 'You thrive on bringing definition to big, undefined problems', 'You love asking questions and pushing hard to find answers', ""You're passionate about talent development for your own team and beyond"", 'Technical', 'You’re comfortable with advanced ML and DL technologies including language models and are passionate about developing further', 'You have hands-on experience working with LLMs and solutions using open-source tools and cloud computing platforms', 'Influential', 'You are passionate about AI/ML and can bring along a cross functional team in breakthrough innovations', 'You communicate clearly and effectively to share your findings with non-technical audiences', 'You are experienced in training language models or large computer vision models as well as have expertise in one or more key subdomains such as: training optimization, self-supervised learning, explainability, RLHF', 'You have an engineering mindset as shown by a track record of delivering models at scale both in training data and inference volumes', 'You have experience in delivering libraries, platforms, or solution level code to existing products', 'Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:', ""A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 2 years of experience performing data analytics"", ""A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration""]","['You will be the driving force to experiment, innovate and create next generation experiences powered by the latest emerging generative AI technologies', 'Partner with a cross-functional team of data scientists, software engineers, machine learning engineers and product managers to deliver AI powered products that change how customers interact with their money', 'Leverage a broad stack of technologies — Pytorch, AWS Ultraclusters, Hugging Face, LangChain, Lightning, VectorDBs, and more — to reveal the insights hidden within huge volumes of numeric and textual data', 'Be the expert in Natural Language Processing (NLP) to harness the power of Large Language Models (LLMs), adapt and finetune them for customer facing applications and features', 'Build machine learning and NLP models through all phases of development, from design through training, evaluation, and validation; partnering with engineering teams to operationalize them in scalable and resilient production systems that serve 80+ million customers', 'Flex your interpersonal skills to translate the complexity of your work into tangible business goals', 'You continually research and evaluate emerging technologies', 'You challenge conventional thinking and work with stakeholders to identify and improve the status quo']",True,"['Large Language Models', 'Generative AI', 'PyTorch', 'Hugging Face', 'LangChain', 'Lightning', 'Vector Databases', 'Training Optimization', 'Self-Supervised Learning', 'Explainability', 'Reinforcement Learning from Human Feedback']","Large Language Models: Central to building and fine-tuning customer-facing NLP applications and digital assistant features.; Generative AI: Used to create next-generation personalized experiences and AI-powered products.; PyTorch: Framework employed for developing and training deep learning models including LLMs.; Hugging Face: Open-source platform leveraged for accessing and fine-tuning pre-trained language models.; LangChain: Tool used to build applications that integrate LLMs with external data and workflows.; Lightning: Framework to streamline and scale deep learning model training and deployment.; Vector Databases: Used to store and retrieve embeddings for efficient similarity search in AI applications.; Training Optimization: Techniques applied to improve efficiency and effectiveness of training large AI models.; Self-Supervised Learning: Advanced AI method for training models on unlabeled data, enhancing LLM capabilities.; Explainability: Critical for interpreting AI model outputs and ensuring trustworthiness in AI-powered features.; Reinforcement Learning from Human Feedback: Method to refine AI models by incorporating human preferences and feedback.","['Statistical Modeling', 'Machine Learning', 'Natural Language Processing', 'Python', 'SQL', 'Data Analytics', 'Model Training and Evaluation', 'Self-Supervised Learning', 'Explainability', 'Reinforcement Learning from Human Feedback', 'Cloud Computing (AWS)']","Statistical Modeling: Used historically and currently to personalize credit card offers and analyze customer data for decision-making.; Machine Learning: Applied to build predictive models and scalable AI/ML solutions for customer-facing financial products.; Natural Language Processing: Expertise required to process and analyze textual data for customer interactions and app features.; Python: Programming language used for data analytics and machine learning model development.; SQL: Used for querying and managing relational databases containing customer and transactional data.; Data Analytics: Performed to extract insights from large volumes of numeric and textual data to inform business decisions.; Model Training and Evaluation: Involves designing, training, validating, and operationalizing machine learning and NLP models.; Self-Supervised Learning: A key subdomain expertise for training models without extensive labeled data.; Explainability: Ensures transparency and understanding of model decisions in customer-facing applications.; Reinforcement Learning from Human Feedback: Used to improve model performance by incorporating human feedback during training.; Cloud Computing (AWS): Utilized for scalable data storage, processing, and model deployment in production environments."
SWC1sPoUrYiHb9W8AAAAAA==,ME00383-Data Scientist 3 Jobs,"Momentum Engineering, Inc., a Woman-Owned Small Business (WOSB), fosters an employee-centric culture. Our strength lies in our people. With a high percentage of employees holding advanced degrees in engineering, computer science, and related disciplines, we bring deep technical expertise to every mission. Our team includes professionals with security clearances and full-scope polygraphs, ensuring trusted, secure support for the most sensitive national security initiatives. Additionally, our workforce is equipped with industry-leading certifications, demonstrating a commitment to continuous learning and excellence. Most importantly, our exceptional employee retention rate reflects a culture of professional growth, mission focus, and dedication-ensuring long-term stability and expertise for our customers' critical needs.

Job Summary
• Seeking a highly motivated and detail-oriented Data Scientist to provide Cyber Tradecraft support
• The ideal candidate will have strong analytical and statistical skills, a deep understanding of machine learning and data modeling, and the ability to extract meaningful insights from complex data sets to support business objectives

Primary Responsibilities
• Perform anomaly detection
• Design, develop, and implement statistical models and machine learning algorithms
• Analyze large structured and unstructured datasets from various sources to uncover trends and patterns
• Communicate findings clearly through dashboards, visualizations, and reports
• Collaborate with stakeholders across engineering, product, and business teams to translate data into actionable insights

Required Qualifications
• Must have active Top Secret/SCI with NSA FSP
• Master's degree with 6 years of relevant experience, Bachelor's Degree with 8 years of relevant experience, or Associates degree with 10 years of in-depth relevant experience that is clearly related to the position
• Proficiency in programming languages such as Python
• Experience with customer tools and dataflow

Desired Qualifications
• Experience with data redundancy and optimization

Exempt hourly position. 11 paid holidays, minimum of 3 weeks PTO, company sponsored group medical plan, company paid dental, vision, life insurance, and STD/LTD plans. Salary is dependent upon the candidate's experience and qualifications.

The pay range for this role is:

130,000 - 175,000 USD per year ( Ft. Meade MD )",2025-07-25T14:00:00.000Z,2025-07-25,"['Seeking a highly motivated and detail-oriented Data Scientist to provide Cyber Tradecraft support', 'The ideal candidate will have strong analytical and statistical skills, a deep understanding of machine learning and data modeling, and the ability to extract meaningful insights from complex data sets to support business objectives', 'Must have active Top Secret/SCI with NSA FSP', ""Master's degree with 6 years of relevant experience, Bachelor's Degree with 8 years of relevant experience, or Associates degree with 10 years of in-depth relevant experience that is clearly related to the position"", 'Proficiency in programming languages such as Python', 'Experience with customer tools and dataflow']","['Perform anomaly detection', 'Design, develop, and implement statistical models and machine learning algorithms', 'Analyze large structured and unstructured datasets from various sources to uncover trends and patterns', 'Communicate findings clearly through dashboards, visualizations, and reports', 'Collaborate with stakeholders across engineering, product, and business teams to translate data into actionable insights']",True,[],,"['Anomaly Detection', 'Statistical Modeling', 'Machine Learning Algorithms', 'Data Analysis of Structured and Unstructured Data', 'Data Visualization and Dashboards', 'Python Programming', 'Dataflow and Customer Tools', 'Data Redundancy and Optimization']","Anomaly Detection: Used to identify unusual patterns or outliers in cybersecurity data to support threat detection.; Statistical Modeling: Designing and implementing statistical models to analyze complex data sets for insights relevant to cyber tradecraft.; Machine Learning Algorithms: Developing and applying machine learning techniques to model data and extract meaningful patterns for cybersecurity applications.; Data Analysis of Structured and Unstructured Data: Analyzing diverse data types from multiple sources to uncover trends and patterns critical for business and security objectives.; Data Visualization and Dashboards: Communicating analytical findings effectively through visual tools to support decision-making across teams.; Python Programming: Utilizing Python for data manipulation, modeling, and analysis tasks within the data science workflow.; Dataflow and Customer Tools: Experience with data pipelines and tools used by customers to manage and process data efficiently.; Data Redundancy and Optimization: Applying techniques to reduce data duplication and improve data processing efficiency."
XmlF2hnsr8waRqdGAAAAAA==,"Principal Data Scientist, AI Foundations","Principal Data Scientist, AI Foundations

Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making.

As a Data Scientist at Capital One, you’ll be part of a team that’s leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives.

Team Description

AI Foundations Specialist Models Data Science team builds and ships state of the art scalable architecture, AI/ML solutions for Capital One’s award-winning mobile app. We partner with product, tech and design teams to deliver app features that delight customers with dynamic and personalized experiences, enable them to chat with Capital One’s digital assistant Eno, or search for useful contents. You will be the driving force to experiment, innovate and create next generation experiences powered by the latest emerging generative AI technologies.

In this role, you will:
• Partner with a cross-functional team of data scientists, software engineers, machine learning engineers and product managers to deliver AI powered products that change how customers interact with their money.
• Leverage a broad stack of technologies — Pytorch, AWS Ultraclusters, Hugging Face, LangChain, Lightning, VectorDBs, and more — to reveal the insights hidden within huge volumes of numeric and textual data.
• Be the expert in Natural Language Processing (NLP) to harness the power of Large Language Models (LLMs), adapt and finetune them for customer facing applications and features.
• Build machine learning and NLP models through all phases of development, from design through training, evaluation, and validation; partnering with engineering teams to operationalize them in scalable and resilient production systems that serve 80+ million customers.
• Flex your interpersonal skills to translate the complexity of your work into tangible business goals.

The Ideal Candidate is:
• Customer first. You love the process of analyzing and creating, but also share our passion to do the right thing. You know at the end of the day it’s about making the right decision for our customers.
• Innovative. You continually research and evaluate emerging technologies. You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them.
• Creative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You’re not afraid to share a new idea.
• A leader. You challenge conventional thinking and work with stakeholders to identify and improve the status quo. You're passionate about talent development for your own team and beyond.
• Technical. You’re comfortable with advanced ML and DL technologies including language models and are passionate about developing further. You have hands-on experience working with LLMs and solutions using open-source tools and cloud computing platforms.
• Influential. You are passionate about AI/ML and can bring along a cross functional team in breakthrough innovations. You communicate clearly and effectively to share your findings with non-technical audiences.
• You are experienced in training language models or large computer vision models as well as have expertise in one or more key subdomains such as: training optimization, self-supervised learning, explainability, RLHF.
• You have an engineering mindset as shown by a track record of delivering models at scale both in training data and inference volumes. You have experience in delivering libraries, platforms, or solution level code to existing products.

Basic Qualifications:
• Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:
• A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 5 years of experience performing data analytics
• A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 3 years of experience performing data analytics
• A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field)

Preferred Qualifications:
• Master’s Degree in “STEM” field (Science, Technology, Engineering, or Mathematics), or PhD in “STEM” field (Science, Technology, Engineering, or Mathematics)
• Experience working with AWS
• At least 3 years’ experience in Python, Scala, or R
• At least 3 years’ experience with machine learning
• At least 3 years’ experience with SQL

Capital One will consider sponsoring a new qualified applicant for employment authorization for this position.

The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.

McLean, VA: $158,600 - $181,000 for Princ Associate, Data Science

New York, NY: $173,000 - $197,400 for Princ Associate, Data Science

San Jose, CA: $173,000 - $197,400 for Princ Associate, Data Science

Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate’s offer letter.

This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.

Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.

This role is expected to accept applications for a minimum of 5 business days.

No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",2025-07-20T00:00:00.000Z,2025-07-25,"['Customer first', 'You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them', 'You thrive on bringing definition to big, undefined problems', 'You love asking questions and pushing hard to find answers', ""You're passionate about talent development for your own team and beyond"", 'Technical', 'You’re comfortable with advanced ML and DL technologies including language models and are passionate about developing further', 'You have hands-on experience working with LLMs and solutions using open-source tools and cloud computing platforms', 'Influential', 'You are passionate about AI/ML and can bring along a cross functional team in breakthrough innovations', 'You communicate clearly and effectively to share your findings with non-technical audiences', 'You are experienced in training language models or large computer vision models as well as have expertise in one or more key subdomains such as: training optimization, self-supervised learning, explainability, RLHF', 'You have an engineering mindset as shown by a track record of delivering models at scale both in training data and inference volumes', 'You have experience in delivering libraries, platforms, or solution level code to existing products', 'Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:', ""A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 5 years of experience performing data analytics"", ""A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 3 years of experience performing data analytics"", 'A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field)']","['You will be the driving force to experiment, innovate and create next generation experiences powered by the latest emerging generative AI technologies', 'Partner with a cross-functional team of data scientists, software engineers, machine learning engineers and product managers to deliver AI powered products that change how customers interact with their money', 'Leverage a broad stack of technologies — Pytorch, AWS Ultraclusters, Hugging Face, LangChain, Lightning, VectorDBs, and more — to reveal the insights hidden within huge volumes of numeric and textual data', 'Be the expert in Natural Language Processing (NLP) to harness the power of Large Language Models (LLMs), adapt and finetune them for customer facing applications and features', 'Build machine learning and NLP models through all phases of development, from design through training, evaluation, and validation; partnering with engineering teams to operationalize them in scalable and resilient production systems that serve 80+ million customers', 'Flex your interpersonal skills to translate the complexity of your work into tangible business goals', 'You continually research and evaluate emerging technologies', 'You challenge conventional thinking and work with stakeholders to identify and improve the status quo']",True,"['Large Language Models', 'Natural Language Processing', 'Generative AI', 'PyTorch', 'Hugging Face', 'LangChain', 'Lightning', 'Vector Databases', 'Self-Supervised Learning', 'Reinforcement Learning from Human Feedback', 'Training Optimization', 'Explainability']","Large Language Models: Central to the role for building, adapting, and fine-tuning NLP models to power customer-facing AI features.; Natural Language Processing: Expertise required to harness LLMs for understanding and generating human language in applications like digital assistants.; Generative AI: Used to create next-generation personalized experiences and innovative AI-powered products.; PyTorch: Deep learning framework employed for training and fine-tuning neural network models including LLMs.; Hugging Face: Open-source platform and library used for accessing and deploying transformer-based models and LLMs.; LangChain: Framework for building applications with LLMs, enabling integration of language models into products.; Lightning: PyTorch Lightning used to streamline deep learning model training and experimentation.; Vector Databases: Specialized databases for storing and querying vector embeddings to support AI search and retrieval tasks.; Self-Supervised Learning: Advanced training technique mentioned as expertise area for improving model performance without labeled data.; Reinforcement Learning from Human Feedback: Technique used to optimize language models by incorporating human feedback to improve outputs.; Training Optimization: Expertise in improving efficiency and effectiveness of training large AI models at scale.; Explainability: Focus on making AI model decisions interpretable and transparent for stakeholders.","['Statistical Modeling', 'Machine Learning', 'Data Analytics', 'SQL', 'Python', 'Scala', 'R', 'AWS']","Statistical Modeling: Used historically and foundationally at the company to personalize credit card offers and drive data-driven decision-making.; Machine Learning: Applied broadly to build predictive models and scalable AI/ML solutions for customer-facing financial products.; Data Analytics: Core skill required for analyzing large volumes of numeric and textual data to extract insights and inform business decisions.; SQL: Used for querying and managing relational databases as part of data analytics and pipeline development.; Python: Primary programming language for data science, machine learning, and model development tasks.; Scala: Used as a programming language option for data processing and analytics.; R: Statistical programming language used for data analysis and modeling.; AWS: Cloud computing platform leveraged for scalable data storage, processing, and model deployment."
DDlYUr7BgyKaoURDAAAAAA==,Data Scientist 2 - 24016 Jobs,"Requisition Number: 24016

Required Travel: 11 - 25%

Employment Type: Full Time/Salaried/Exempt

Anticipated Salary Range: $79,534.00 - $110,000.00

Security Clearance: Ability to Obtain

Level of Experience: Mid

This opportunity resides with Global Security (GS). Mission Technologies' Global Security (GS) group comprises live, virtual, constructive (LVC) solutions; fleet sustainment; nuclear and environmental; and Australia business.

As a trusted partner to our military customers, HII designs, develops and operates the largest LVC enterprise that prepares warfighters for cross-domain battle. With advanced technologies to enable mission readiness, HII understands that preparation requires full coordination-not readiness in piece-parts.

For more than 40 years, the U.S. Navy has entrusted HII to maintain and modernize the vast majority of its fleet. With a holistic approach to life-cycle maritime defense systems-from small watercraft to submarines, surface combatants and aircraft carriers-HII ensures a high state of readiness.

HII supports the Department of Energy's national security mission through the management and operation of its sites, as well as the safe cleanup of legacy waste across the country. HII meets clients' toughest nuclear and environmental challenges.

Meet HII's Mission Technologies Division
Our team of more than 7,000 professionals worldwide delivers all-domain expertise and advanced technologies in service of mission partners across the globe. Mission Technologies is leading the next evolution of national defense - the data evolution - by accelerating a breadth of national security solutions for government and commercial customers. Our capabilities range from C5ISR, AI and Big Data, cyber operations and synthetic training environments to fleet sustainment, environmental remediation and the largest family of unmanned underwater vehicles in every class. Find the role that's right for you. Apply today. We look forward to meeting you.

To learn more about Mission Technologies, click here for a short video: https://vimeo.com/732533072

Job Description

HII Mission Technologies is seeking a Data Scientist 2 to support the Joint Training Synthetic Environment (JTSE) Joint Staff J7(JS J-7) contract at our Suffolk, VA Joint Staff Complex. This position is eligible for a hybrid work schedule.

Essential Job Responsibilities
• Designs, develops, and implements statistical and analytical methods.
• Examines processes and systems to consolidate and analyze diverse data sets including structured, semi-structured and unstructured.
• Develops and sources software programs, algorithms, dashboards, information tools, and queries to collect, clean, model, integrate and evaluate datasets.
• Documents workflows and processes employed to improve knowledge across the Data Science and Engineering team.
• Employs statistical concepts, linguistics and programming skills to develop related techniques and methods for analysis.
• Keeps abreast of new analytic methodologies and technologies.
• Collaborates with functional business units to drive solutions and directions, and interprets and presents findings to enable business decisions.

Minimum Qualifications
• 2 years relevant experience with Bachelors in related field; 0 years experience with Masters in related field; or High School Diploma or equivalent and 6 years relevant experience.
• Must have the ability to obtain, and be able to maintain, an active TS/SCI clearance.
• Excellent written and verbal communication skills.
• Ability to work both in a team and individually.
• Solid organizational skills, including attention to detail.
• Self-motivated and driven desire to succeed with minimal direction.

Preferred Requirements
• An active TS/SCI security clearance.
• Experience with the configuration and use of Superset in connecting to data sources and creating dashboards.
• Prior use of Talend and Qlik toolsets.
• Development and use of Apache Spark.
• Experience with developing data analytics and processing pipeline applications with Python.

HII is more than a job - it's an opportunity to build a new future. We offer competitive benefits such as best-in-class medical, dental and vision plan choices; wellness resources; employee assistance programs; Savings Plan Options (401(k)); financial planning tools, life insurance; employee discounts; paid holidays and paid time off; tuition reimbursement; as well as early childhood and post-secondary education scholarships. Bonus/other non-recurrent compensation is occasionally offered for qualified positions, and if applicable to this role will be addressed by the recruiter at the screening phase of application.

The listed salary range for this role is intended as a good faith estimate based on the role's location, expectations, and responsibilities. When extending an offer, HII's Mission Technologies division takes a variety of factors into consideration which include, but are not limited to, the role's function and a candidate's education or training, work experience, and key skills.

Why HII
We build the world's most powerful, survivable naval ships and defense technology solutions that safeguard our seas, sky, land, space and cyber. Our workforce includes skilled tradespeople; artificial intelligence, machine learning (AI/ML) experts; engineers; technologists; scientists; logistics experts; and business administration professionals.

Recognized as one of America's top large company employers, we are a values and ethics driven organization that puts people's safety and well-being first. Regardless of your role or where you serve, at HII, you'll find a supportive and welcoming environment, competitive benefits, and valuable educational and training programs for continual career growth at every stage of your career.

Together we are working to ensure a future where everyone can be free and thrive.
All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, physical or mental disability, age, or veteran status or any other basis protected by federal, state, or local law.

Do You Need Assistance?
If you need a reasonable accommodation for any part of the employment process, please send an e-mail to buildyourcareer@hii-co.com and let us know the nature of your request and your contact information. Reasonable accommodations are considered on a case-by-case basis. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this email address. Additionally, you may also call 1-844-849-8463 for assistance. Press #3 for HII Mission Technologies.",2025-07-24T00:00:00.000Z,2025-07-25,"['Security Clearance: Ability to Obtain', '2 years relevant experience with Bachelors in related field; 0 years experience with Masters in related field; or High School Diploma or equivalent and 6 years relevant experience', 'Must have the ability to obtain, and be able to maintain, an active TS/SCI clearance', 'Excellent written and verbal communication skills', 'Ability to work both in a team and individually', 'Solid organizational skills, including attention to detail', 'Self-motivated and driven desire to succeed with minimal direction']","['Required Travel: 11 - 25%', 'With advanced technologies to enable mission readiness, HII understands that preparation requires full coordination-not readiness in piece-parts', 'For more than 40 years, the U.S. Navy has entrusted HII to maintain and modernize the vast majority of its fleet', 'With a holistic approach to life-cycle maritime defense systems-from small watercraft to submarines, surface combatants and aircraft carriers-HII ensures a high state of readiness', 'Designs, develops, and implements statistical and analytical methods', 'Examines processes and systems to consolidate and analyze diverse data sets including structured, semi-structured and unstructured', 'Develops and sources software programs, algorithms, dashboards, information tools, and queries to collect, clean, model, integrate and evaluate datasets', 'Documents workflows and processes employed to improve knowledge across the Data Science and Engineering team', 'Employs statistical concepts, linguistics and programming skills to develop related techniques and methods for analysis', 'Keeps abreast of new analytic methodologies and technologies', 'Collaborates with functional business units to drive solutions and directions, and interprets and presents findings to enable business decisions']",True,[],,"['Statistical and Analytical Methods', 'Data Integration and Cleaning', 'Dashboards and BI Tools', 'Apache Spark', 'Python Programming', 'Data Pipelines']","Statistical and Analytical Methods: Used to design, develop, and implement techniques for analyzing diverse data sets to support decision-making.; Data Integration and Cleaning: Involves collecting, cleaning, modeling, and integrating structured, semi-structured, and unstructured data for analysis.; Dashboards and BI Tools: Creation of dashboards using tools like Superset and Qlik to visualize data and support business insights.; Apache Spark: Used for developing data analytics and processing pipeline applications to handle large-scale data.; Python Programming: Applied for developing data analytics, processing pipelines, and implementing algorithms.; Data Pipelines: Development and management of workflows and processes to streamline data collection, cleaning, and analysis."
mM64TjTRCvQvPUz3AAAAAA==,Cyber Data Science Engineer Jobs,"The Cyber Data Science Engineer provides support to the customer in the area of Cyber Security. Daily Tasks include, but are not limited to:

The Cyber Systems Engineer provides SETA support to the customer in the area of Cyber Security Operations. Daily tasks include, but are not limited to:
• Compile's information to develop the weekly, monthly, and annual customer ""Cyber Snapshot."" Reporting metrics on cases and incidents that have happened over the period as well as items of interest on Cyber Security that would be of interest to senior management.
• Verifies/validates systems with specific emphasis on network operations and cyber warfare tactics, techniques, and procedures focused on the threat to information networks.
• Assesses security performance using evaluation criteria and technical performance measures.
• Prepares assessments and cyber threat profiles of current and planned products based on sophisticated testing, research, and
• Participates in design reviews of components (hardware and software) to ensure applicability to the current system and traceability of requirements.
• Develops and maintains analytical procedures to meet changing requirements
• Produces high-quality papers, presentations, recommendations, and findings for senior US government intelligence and operations officials.
• Provide identification and classification of system and network vulnerabilities, providing mitigation and remediation recommendations.
• Analyzes policies and procedures against Federal laws and regulations and provides recommendations for closing gaps.
• Develops strategies to comply with privacy and risk management requirements.
• Prepare threat analysis reports.
• Create Indications of Compromise for new and existing malware.
• Participate in Cyber Defense Working Groups, forums, and IPTS. Provide cyber defense guidance.

Qualifications:

Required:
• Current U.S. Government Top Secret clearance with SCI eligibility.
• Favorably adjudicated Polygraph.
• Bachelor of Science Degree in Science, Technology, Engineering or Mathematics (STEM) or an advanced IA certification.
• DoD 8570 certification in IAT or IAM.
• Experience in security systems engineering involving various computer hardware and software operation systems and application solutions in both stand-alone and LAN/WAN configurations Experience with security features and/or vulnerability of various operating systems as defined by NIST, DISA (STIGs), and USCYBERCOM.
• Experience with networks and systems security administration, operation systems security configuration and account management best practices.
• Solid understanding of network intrusion detection methods and techniques.

Desired:
• Experience with SIEM technology and applications such as ArcSight or Splunk.
• Experience with FireEye or experience with an equivalent ""endpoint agent"" application Experience in responding to detected security incidents.
• Experience implementing RMF Process and NIST 800-53 technical controls, as well as developing and maintaining associated certification and accreditation documentation.
• Self-starter requiring limited direction and supervision.
• Experience working in a Network Security Operations Center.
• An understanding of satellite communication networks Experience briefing senior customer personnel.
• Ability to organize and prioritize numerous customer requests in a fast pace deadline driven environment.
• Familiarity with Amazon Web Services (AWS).
• Familiarity with customer's IA processes.
• Experience supporting IC or DoD in the Cyber Security Domain.Cyber Data",2025-07-25T00:00:00.000Z,2025-07-25,"['Current U.S. Government Top Secret clearance with SCI eligibility', 'Favorably adjudicated Polygraph', 'Bachelor of Science Degree in Science, Technology, Engineering or Mathematics (STEM) or an advanced IA certification', 'DoD 8570 certification in IAT or IAM', 'Experience in security systems engineering involving various computer hardware and software operation systems and application solutions in both stand-alone and LAN/WAN configurations Experience with security features and/or vulnerability of various operating systems as defined by NIST, DISA (STIGs), and USCYBERCOM', 'Experience with networks and systems security administration, operation systems security configuration and account management best practices', 'Solid understanding of network intrusion detection methods and techniques']","['The Cyber Data Science Engineer provides support to the customer in the area of Cyber Security', 'The Cyber Systems Engineer provides SETA support to the customer in the area of Cyber Security Operations', 'Compile\'s information to develop the weekly, monthly, and annual customer ""Cyber Snapshot."" Reporting metrics on cases and incidents that have happened over the period as well as items of interest on Cyber Security that would be of interest to senior management', 'Verifies/validates systems with specific emphasis on network operations and cyber warfare tactics, techniques, and procedures focused on the threat to information networks', 'Assesses security performance using evaluation criteria and technical performance measures', 'Prepares assessments and cyber threat profiles of current and planned products based on sophisticated testing, research, and', 'Participates in design reviews of components (hardware and software) to ensure applicability to the current system and traceability of requirements', 'Develops and maintains analytical procedures to meet changing requirements', 'Produces high-quality papers, presentations, recommendations, and findings for senior US government intelligence and operations officials', 'Provide identification and classification of system and network vulnerabilities, providing mitigation and remediation recommendations', 'Analyzes policies and procedures against Federal laws and regulations and provides recommendations for closing gaps', 'Develops strategies to comply with privacy and risk management requirements', 'Prepare threat analysis reports', 'Create Indications of Compromise for new and existing malware', 'Participate in Cyber Defense Working Groups, forums, and IPTS', 'Provide cyber defense guidance']",False,[],,"['Security Information and Event Management', 'Network Intrusion Detection', 'Threat Analysis', 'Vulnerability Assessment', 'Cybersecurity Metrics Reporting', 'Risk Management Framework', 'Security Systems Engineering', 'Network Security Administration', 'Analytical Procedures Development', 'Cyber Threat Intelligence', 'Indications of Compromise', 'Security Policy Analysis', 'Cloud Security Familiarity']","Security Information and Event Management: Experience with SIEM tools like ArcSight and Splunk to collect and analyze security event data for cyber threat detection.; Network Intrusion Detection: Understanding and applying methods to detect unauthorized network activities as part of cyber security operations.; Threat Analysis: Preparation of reports and profiles assessing cyber threats to inform security strategies and risk management.; Vulnerability Assessment: Identification and classification of system and network vulnerabilities to recommend mitigation and remediation.; Cybersecurity Metrics Reporting: Compiling and reporting metrics on cyber incidents and cases to provide situational awareness to senior management.; Risk Management Framework: Implementing RMF processes and NIST 800-53 controls to ensure compliance and security accreditation.; Security Systems Engineering: Design and validation of hardware and software components to meet cyber security requirements and standards.; Network Security Administration: Managing network and system security configurations, account management, and best practices.; Analytical Procedures Development: Creating and maintaining analytical methods to adapt to evolving cyber security requirements.; Cyber Threat Intelligence: Research and analysis of cyber warfare tactics, techniques, and procedures to support defense operations.; Indications of Compromise: Developing signatures and indicators to detect malware and cyber intrusions.; Security Policy Analysis: Evaluating policies against federal laws and regulations to identify and close security gaps.; Cloud Security Familiarity: Knowledge of Amazon Web Services (AWS) security features relevant to cyber defense."
3pUDR8Cr6LAiuPx6AAAAAA==,Software Engineer/Data Scientist Jobs,"Software Engineer/Data Scientist

Active Top Secret (TS/SCI) clearance with polygraph is required.

YOE Requirement: 8 yrs., B.S. in a technical discipline or 4 additional yrs. in place of B.S.

Description: As a data scientist specializing in graph analysis and algorithms, you will join a collaborative team building an entirely new graph analysis platform that, for the first time, will allow our mission customers to visualize, analyze, and traverse their expansive and complex mission data in graph format and in near-real-time. Your responsibilities will center around enhancing our graph data capabilities—designing, modeling, and optimizing complex graph structures and crafting performant database queries. While familiarity with Neo4j and its query language, Cypher, is beneficial, we welcome candidates with broader graph analysis experience who are eager to deepen their expertise. You may also develop and maintain data parsers using Python to support our ingestion pipelines and maintain comprehensive documentation of data models. Finally, you will work directly with mission analysts and operators to listen to their needs and address them through novel data models and graphing solutions.

Responsibilities:

• Develop and refine graph data models to accommodate new data sources and fulfill customer-driven feature requests.

• Design and optimize graph queries, with an expectation to learn and utilize Cypher for Neo4j.

• Build and maintain data parsers in Python, ensuring reliable data ingestion.

• Validate and analyze mission data to confirm accuracy, integrity, and optimal performance.

• Collaborate closely with analysts to understand and translate analytical requirements into practical graph-based solutions.

• Work alongside software developers to integrate efficient queries and data parsers into robust software components.

• Maintain clear, comprehensive documentation of graph schemas, data models, and related processes using tools such as Confluence.

• Engage directly with customers to understand operational challenges and propose effective technical solutions.

Skill Requirements:

• Experience or interest in graph databases, such as Neo4j, with a willingness to learn specific tools like Cypher.

• Strong Python programming skills, specifically for writing and maintaining data parsing scripts.

• Proven ability to translate customer requirements into implementable data-driven solutions.

• Excellent communication and interpersonal skills for effective collaboration with diverse stakeholders.

• Strong analytical thinking and problem-solving abilities.

• Solid understanding of measuring analytic performance - what queries run slow, what run fast.

• Strong communication skills (you talk to developers, you talk to senior leadership, you talk to users, etc).

• Experience with Angular, React, or Vue.

Nice to Haves:

• Previous experience with Neo4j or other graph databases.

• Knowledge of TCP/IP networking concepts.

• Understanding graph theory and algorithms.

• Familiarity with real-time data processing or streaming analytics.

• Experience with containerization technologies (Docker, Kubernetes).

• Understanding of ETL processes for large, complex datasets.

• Familiarity with SIGINT collection and analysis systems or similar mission environments.

• Knowledge of HTML, CSS, Sass, NPM, and using REST APIs.

• Experience developing single-page web apps.

• Familiarity with Git and Gitlab CI/CD.

Benefits:

• 12% Retirement Contribution (6% Employer Contribution + 6% Employer Match)

• 200 hours per annum of Paid Time Off (PTO) prorated to start date (PTO can be earned & negotiated)

• Straight Time can be earned on top of your Salary after meeting your required billable hours

• Flexible work hours

• 40 hours of New Parent Leave

• Medical, dental, & vision insurance for individuals and families (salaries can be negotiated for those who waive medical benefits)

• Life, AD&D, Short-Term Disability, & Long-Term Disability Insurance

• Bonuses for high performers, year-end, and referrals

• $5,000 Professional Development Allowance

• 40 hours of Training

• $5,250 Education Reimbursement

Salary range: $135,000 - $200,000

Disclaimer: Salary for this position, along with additional compensation options, will be determined on an individual basis following the interview process, considering various factors such as years of experience, skills, education/certifications, contract specifications, market conditions, etc.",2025-07-25T13:00:00.000Z,2025-07-25,"['Active Top Secret (TS/SCI) clearance with polygraph is required', 'YOE Requirement: 8 yrs., B.S. in a technical discipline or 4 additional yrs. in place of B.S', 'Experience or interest in graph databases, such as Neo4j, with a willingness to learn specific tools like Cypher', 'Strong Python programming skills, specifically for writing and maintaining data parsing scripts', 'Proven ability to translate customer requirements into implementable data-driven solutions', 'Excellent communication and interpersonal skills for effective collaboration with diverse stakeholders', 'Strong analytical thinking and problem-solving abilities', 'Solid understanding of measuring analytic performance - what queries run slow, what run fast', 'Strong communication skills (you talk to developers, you talk to senior leadership, you talk to users, etc)', 'Experience with Angular, React, or Vue', 'Previous experience with Neo4j or other graph databases', 'Knowledge of TCP/IP networking concepts', 'Understanding graph theory and algorithms', 'Familiarity with real-time data processing or streaming analytics', 'Experience with containerization technologies (Docker, Kubernetes)', 'Understanding of ETL processes for large, complex datasets', 'Familiarity with SIGINT collection and analysis systems or similar mission environments', 'Knowledge of HTML, CSS, Sass, NPM, and using REST APIs', 'Experience developing single-page web apps', 'Familiarity with Git and Gitlab CI/CD']","['Description: As a data scientist specializing in graph analysis and algorithms, you will join a collaborative team building an entirely new graph analysis platform that, for the first time, will allow our mission customers to visualize, analyze, and traverse their expansive and complex mission data in graph format and in near-real-time', 'Your responsibilities will center around enhancing our graph data capabilities—designing, modeling, and optimizing complex graph structures and crafting performant database queries', 'While familiarity with Neo4j and its query language, Cypher, is beneficial, we welcome candidates with broader graph analysis experience who are eager to deepen their expertise', 'You may also develop and maintain data parsers using Python to support our ingestion pipelines and maintain comprehensive documentation of data models', 'Finally, you will work directly with mission analysts and operators to listen to their needs and address them through novel data models and graphing solutions', 'Develop and refine graph data models to accommodate new data sources and fulfill customer-driven feature requests', 'Design and optimize graph queries, with an expectation to learn and utilize Cypher for Neo4j', 'Build and maintain data parsers in Python, ensuring reliable data ingestion', 'Validate and analyze mission data to confirm accuracy, integrity, and optimal performance', 'Collaborate closely with analysts to understand and translate analytical requirements into practical graph-based solutions', 'Work alongside software developers to integrate efficient queries and data parsers into robust software components', 'Maintain clear, comprehensive documentation of graph schemas, data models, and related processes using tools such as Confluence', 'Engage directly with customers to understand operational challenges and propose effective technical solutions']",True,[],,"['Graph Databases', 'Cypher Query Language', 'Python Data Parsers', 'Graph Theory and Algorithms', 'Data Modeling', 'Data Ingestion Pipelines', 'Real-Time Data Processing', 'ETL Processes', 'Performance Analytics', 'Confluence Documentation', 'Streaming Analytics']","Graph Databases: The job focuses on designing, modeling, and optimizing complex graph structures using graph databases like Neo4j to analyze mission data.; Cypher Query Language: Used for designing and optimizing graph queries within Neo4j to efficiently traverse and analyze graph data.; Python Data Parsers: Developing and maintaining Python scripts to parse and ingest data into the graph analysis platform.; Graph Theory and Algorithms: Applying graph theory concepts and algorithms to enhance graph data models and support complex data analysis.; Data Modeling: Creating and refining data models to accommodate new data sources and meet customer requirements for graph-based solutions.; Data Ingestion Pipelines: Building reliable pipelines to ingest mission data into the graph platform, supported by Python parsers.; Real-Time Data Processing: Handling near-real-time data streams to enable timely visualization and analysis of mission data.; ETL Processes: Understanding and managing extract, transform, and load processes for large and complex datasets.; Performance Analytics: Measuring and optimizing query performance to ensure efficient data retrieval and analysis.; Confluence Documentation: Maintaining comprehensive documentation of graph schemas, data models, and processes using Confluence.; Streaming Analytics: Familiarity with analyzing data streams in real-time to support mission-critical insights."
ThZVOMyrozHI7hKEAAAAAA==,Command and Control Data Scientist Jobs,"Overview

UIC Bowhead is seeking a mission-focused, policy-savvy C2 Data Scientist to support the Program Manager for Marine Air-Ground Task Force Command and Control (PM MAGTF C2) within a military acquisition program office. This role bridges traditional data science with strategic-level advisory functions. The successful candidate will operate at the intersection of data science, enterprise portfolio management, and tactical command and control (C2) systems. This position will directly contribute to shaping emerging DoD, Joint, and USMC data-centric policies and tactics, techniques, and procedures (TTPs), while ensuring that advanced analytics and AI/ML solutions align with both enterprise and operational warfighter needs.

Responsibilities

• Coordinate PM MAGTF C2's participation in developing DoD, Joint, and Marine Corps data strategies and TTPs related to integrated C2, mission command, Zero Trust, and data governance.
• Contribute to cross-functional working groups, shaping policy and strategy for data-centric operations at both tactical and enterprise levels.
• Perform and/or assess statistical and exploratory data analysis (EDA) on portfolio-level data to inform executive decisions and SAFe-aligned strategy execution.
• Drive the design and implementation of predictive models and machine learning techniques tailored for DDIL environments and tactical decision-making contexts.
• Develop and/or support the creation of dashboards and visualizations that support Lean Portfolio Management (LPM), strategic portfolio reviews, and operational alignment.
• Lead the development and coordination of PM MAGTF C2's data governance plan and tagging guidance, ensuring alignment with enterprise and mission needs.
• Drive the implementation of enterprise level data policies into the PM MAGTF C2 data strategy.
• Assess and recommend emerging data science, AI/ML tools, and architectures for integration into composable, tactical decision support platforms.
• Author and deliver technical reports and white papers on analytics strategies, governance frameworks, and model integration to support portfolio objectives.

Qualifications
• Master's degree in Data Science, Statistics, Systems Engineering, Computer Science, or a related field.
• 5+ years of experience applying data science in a defense, intelligence, or C2 domain.
• Familiarity with military acquisition processes and the DoD Data Strategy, including metadata standards, and AI/ML integration.
• Strong communication and collaboration skills to support policy development, stakeholder engagement, and cross-functional coordination.
• Strong understanding of the data science domain including trends, technologies, and toolsets.
• Proficiency in data platforms such as SQL and no SQL databases, big data, distributed data processing.
• Proficiency in Python, R, SQL, or other relevant data analysis languages.

Preferred:
• Active Top Secret DoD Secret clearance.
• Prior military service or experience supporting military C2 or tactical systems.
• Experience designing models for DDIL environments and edge computing.
• Exposure to tactical data mesh/data fabrics.
• Experience using JIRA, Confluence, and Agile frameworks

SECURITY CLEARANCE REQUIRED: Must currently hold a Secret security clearance. US Citizenship is required.

Physical Demands:
• Must be able to lift up to 25 pounds
• Must be able to stand and walk for prolonged amounts of time
• Must be able to twist, bend and squat periodically

#LI-DNI

MN1",2025-07-19T00:00:00.000Z,2025-07-25,"[""Master's degree in Data Science, Statistics, Systems Engineering, Computer Science, or a related field"", '5+ years of experience applying data science in a defense, intelligence, or C2 domain', 'Familiarity with military acquisition processes and the DoD Data Strategy, including metadata standards, and AI/ML integration', 'Strong communication and collaboration skills to support policy development, stakeholder engagement, and cross-functional coordination', 'Strong understanding of the data science domain including trends, technologies, and toolsets', 'Proficiency in data platforms such as SQL and no SQL databases, big data, distributed data processing', 'Proficiency in Python, R, SQL, or other relevant data analysis languages', 'SECURITY CLEARANCE REQUIRED: Must currently hold a Secret security clearance', 'US Citizenship is required', 'Must be able to lift up to 25 pounds', 'Must be able to stand and walk for prolonged amounts of time', 'Must be able to twist, bend and squat periodically']","['UIC Bowhead is seeking a mission-focused, policy-savvy C2 Data Scientist to support the Program Manager for Marine Air-Ground Task Force Command and Control (PM MAGTF C2) within a military acquisition program office', 'This role bridges traditional data science with strategic-level advisory functions', 'The successful candidate will operate at the intersection of data science, enterprise portfolio management, and tactical command and control (C2) systems', 'This position will directly contribute to shaping emerging DoD, Joint, and USMC data-centric policies and tactics, techniques, and procedures (TTPs), while ensuring that advanced analytics and AI/ML solutions align with both enterprise and operational warfighter needs', ""Coordinate PM MAGTF C2's participation in developing DoD, Joint, and Marine Corps data strategies and TTPs related to integrated C2, mission command, Zero Trust, and data governance"", 'Contribute to cross-functional working groups, shaping policy and strategy for data-centric operations at both tactical and enterprise levels', 'Perform and/or assess statistical and exploratory data analysis (EDA) on portfolio-level data to inform executive decisions and SAFe-aligned strategy execution', 'Drive the design and implementation of predictive models and machine learning techniques tailored for DDIL environments and tactical decision-making contexts', 'Develop and/or support the creation of dashboards and visualizations that support Lean Portfolio Management (LPM), strategic portfolio reviews, and operational alignment', ""Lead the development and coordination of PM MAGTF C2's data governance plan and tagging guidance, ensuring alignment with enterprise and mission needs"", 'Drive the implementation of enterprise level data policies into the PM MAGTF C2 data strategy', 'Assess and recommend emerging data science, AI/ML tools, and architectures for integration into composable, tactical decision support platforms', 'Author and deliver technical reports and white papers on analytics strategies, governance frameworks, and model integration to support portfolio objectives']",True,['AI/ML Integration'],AI/ML Integration: Assessment and recommendation of AI and machine learning tools and architectures for integration into tactical decision support platforms.,"['Exploratory Data Analysis', 'Predictive Modeling', 'Machine Learning', 'Dashboards and Data Visualization', 'Data Governance', 'SQL and NoSQL Databases', 'Big Data and Distributed Data Processing', 'Python and R Programming']","Exploratory Data Analysis: Used to perform statistical and exploratory analysis on portfolio-level data to inform executive decisions and strategy execution.; Predictive Modeling: Design and implementation of predictive models tailored for decision-making in deployed, disconnected, intermittent, and limited (DDIL) environments.; Machine Learning: Application of machine learning techniques to support tactical decision-making contexts within military command and control systems.; Dashboards and Data Visualization: Development and support of dashboards and visualizations to aid Lean Portfolio Management and strategic portfolio reviews.; Data Governance: Leading the development and coordination of data governance plans and tagging guidance aligned with enterprise and mission needs.; SQL and NoSQL Databases: Proficiency in querying and managing structured and unstructured data using SQL and NoSQL platforms.; Big Data and Distributed Data Processing: Experience with handling large-scale data and distributed processing systems relevant to military and tactical data environments.; Python and R Programming: Use of Python and R for data analysis, statistical modeling, and implementation of data science solutions."
Kivyrc7fiUv35ibSAAAAAA==,Cyber Data Science Engineer Jobs,"Program Description:

The program provides Systems Engineering and Technical Assistance (SETA) core and non-core support in the areas of Cyber Security and Management to improve the Information Assurance (IA) posture of a National customer. The contracts Core Capabilities are: IA Management, Federal Information Security Management Act (FISMA) coordination and reporting, Risk Management Framework (RMF) application, IA compliance measurements and metrics, Assessment and Authorization (A&A), Vulnerability Management, and Cyber Defense support.

Position Description:

The Cyber Data Science Engineer provides support to the customer in the area of Cyber Security. Daily Tasks include, but are not limited to:
• Utilize analytical, statistical, and programming skills to collect, analyze, and interpret large cybersecurity data sets
• Develop data-driven solutions
• Analyze data sets found in the customer's vulnerability scanning, authorization, and configuration management tools
• Import and transform data into usable sets for analysis tools used by the customer (e.g., Tableau)
• Provide analysis and graphical presentations of collected metrics for IA compliance status reporting
• Support legacy visualization and situational awareness tools based on Microsoft Excel
• Collaborate with the Heat Map team to investigate options to simplify and automate the current Heat Map

Job Requirements

Required:
• Current U.S. Government Top Secret clearance with SCI eligibility.
• Favorably adjudicated Polygraph.
• Bachelor of Science Degree in Science, Technology, Engineering or Mathematics (STEM) or an advanced IA certification (i.e., CISSP or CASP)
• DoD 8570 certification in IAT or IAM
• Deep understanding of statistics and analysis
• Skilled in artificial intelligence and machine learning (e.g., SageMaker)
• Ability to code in multiple languages, including Python
• Knowledge of databases, data structures, and data architectures
• Excellent communications skills - both verbal and non-verbal
• Office Automation Skills - MS Office, MS Project, Visio
• Self-starter requiring limited direction and supervision
• Strong attention to detail
• Ability to work in a team environment
• Experience with data visualization tools (e.g. Tableau, Infogram, Chartbloks)
• Experience with data transformation (structured data format/schema transformation) using common programming tools (e.g., Python, JSON, etc.)
• Experience applying statistical analysis to large data sets

Desired:
• Experience briefing senior customer personnel
• Experience with Tableau administration
• Ability to organize and prioritize numerous customer requests in a fast pace deadline driven environment
• Familiarity with Amazon Web Services (AWS)
• Familiarity with customer's IA processes
• Experience with ServiceNow and Splunk
• Experience supporting IC or DoD in the Cyber Security Domain
• Familiarity with the RMF process
• Experience with Relational Database Management System (RDMS)
• Experience with Apache Hadoop and the Hadoop Distributed File System
• Experience with Amazon Elastic MapReduce (EMR) and SageMaker
• Experience with Machine Learning or Artificial Intelligence

Travel

Security Clearance

Top Secret/SCI/CI Poly",2025-07-25T00:00:00.000Z,2025-07-25,"['Current U.S. Government Top Secret clearance with SCI eligibility', 'Favorably adjudicated Polygraph', 'Bachelor of Science Degree in Science, Technology, Engineering or Mathematics (STEM) or an advanced IA certification (i.e., CISSP or CASP)', 'DoD 8570 certification in IAT or IAM', 'Deep understanding of statistics and analysis', 'Skilled in artificial intelligence and machine learning (e.g., SageMaker)', 'Ability to code in multiple languages, including Python', 'Knowledge of databases, data structures, and data architectures', 'Excellent communications skills - both verbal and non-verbal', 'Office Automation Skills - MS Office, MS Project, Visio', 'Self-starter requiring limited direction and supervision', 'Strong attention to detail', 'Ability to work in a team environment', 'Experience with data visualization tools (e.g', 'Tableau, Infogram, Chartbloks)', 'Experience with data transformation (structured data format/schema transformation) using common programming tools (e.g., Python, JSON, etc.)', 'Experience applying statistical analysis to large data sets']","['The program provides Systems Engineering and Technical Assistance (SETA) core and non-core support in the areas of Cyber Security and Management to improve the Information Assurance (IA) posture of a National customer', 'The Cyber Data Science Engineer provides support to the customer in the area of Cyber Security', 'Utilize analytical, statistical, and programming skills to collect, analyze, and interpret large cybersecurity data sets', 'Develop data-driven solutions', ""Analyze data sets found in the customer's vulnerability scanning, authorization, and configuration management tools"", 'Import and transform data into usable sets for analysis tools used by the customer (e.g., Tableau)', 'Provide analysis and graphical presentations of collected metrics for IA compliance status reporting', 'Support legacy visualization and situational awareness tools based on Microsoft Excel', 'Collaborate with the Heat Map team to investigate options to simplify and automate the current Heat Map']",True,['Machine Learning'],Machine Learning: Specifically mentioned as a skill and applied method for developing AI-driven cybersecurity solutions using platforms like SageMaker.,"['Statistical Analysis', 'Data Transformation', 'Python Programming', 'Data Visualization', 'Databases and Data Architectures', 'Relational Database Management Systems', 'Apache Hadoop Ecosystem', 'Machine Learning', 'Amazon SageMaker', 'ServiceNow and Splunk']","Statistical Analysis: Used to analyze large cybersecurity data sets to interpret and derive insights for Information Assurance compliance.; Data Transformation: Involves converting structured data formats and schemas using programming tools like Python and JSON to prepare data for analysis.; Python Programming: Utilized for coding, data manipulation, and implementing data-driven solutions in cybersecurity contexts.; Data Visualization: Creating graphical presentations of cybersecurity metrics using tools such as Tableau, Infogram, Chartbloks, and Microsoft Excel.; Databases and Data Architectures: Knowledge applied to manage and structure cybersecurity data for analysis and reporting.; Relational Database Management Systems: Used to store and query structured cybersecurity data relevant to vulnerability and configuration management.; Apache Hadoop Ecosystem: Experience with Hadoop Distributed File System and Amazon EMR for processing large-scale cybersecurity data.; Machine Learning: Applied to develop predictive and analytical models supporting cybersecurity data analysis.; Amazon SageMaker: Used as a platform for building, training, and deploying machine learning models in cybersecurity applications.; ServiceNow and Splunk: Tools used for cybersecurity data collection, incident management, and analysis."
z1zA2HhCf8D6og4gAAAAAA==,"Senior Data Scientist, NLP","Senior Data Scientist - NLP

Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making.

As a Data Scientist at Capital One, you’ll be part of a team that’s leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives.

Team Description

AI Foundations Specialist Models Data Science team builds and ships state of the art scalable architecture, AI/ML solutions for Capital One’s award-winning mobile app. We partner with product, tech and design teams to deliver app features that delight customers with dynamic and personalized experiences, enable them to chat with Capital One’s digital assistant Eno, or search for useful contents. You will be the driving force to experiment, innovate and create next generation experiences powered by the latest emerging generative AI technologies.

In this role, you will:
• Partner with a cross-functional team of data scientists, software engineers, machine learning engineers and product managers to deliver AI powered products that change how customers interact with their money.
• Leverage a broad stack of technologies — Pytorch, AWS Ultraclusters, Hugging Face, LangChain, Lightning, VectorDBs, and more — to reveal the insights hidden within huge volumes of numeric and textual data.
• Be the expert in Natural Language Processing (NLP) to harness the power of Large Language Models (LLMs), adapt and finetune them for customer facing applications and features.
• Build machine learning and NLP models through all phases of development, from design through training, evaluation, and validation; partnering with engineering teams to operationalize them in scalable and resilient production systems that serve 80+ million customers.
• Flex your interpersonal skills to translate the complexity of your work into tangible business goals.

The Ideal Candidate is:
• Customer first. You love the process of analyzing and creating, but also share our passion to do the right thing. You know at the end of the day it’s about making the right decision for our customers.
• Innovative. You continually research and evaluate emerging technologies. You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them.
• Creative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You’re not afraid to share a new idea.
• A leader. You challenge conventional thinking and work with stakeholders to identify and improve the status quo. You're passionate about talent development for your own team and beyond.
• Technical. You’re comfortable with advanced ML and DL technologies including language models and are passionate about developing further. You have hands-on experience working with LLMs and solutions using open-source tools and cloud computing platforms.
• Influential. You are passionate about AI/ML and can bring along a cross functional team in breakthrough innovations. You communicate clearly and effectively to share your findings with non-technical audiences.
• You are experienced in training language models or large computer vision models as well as have expertise in one or more key subdomains such as: training optimization, self-supervised learning, explainability, RLHF.
• You have an engineering mindset as shown by a track record of delivering models at scale both in training data and inference volumes. You have experience in delivering libraries, platforms, or solution level code to existing products.

Basic Qualifications:
• Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:
• A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 2 years of experience performing data analytics
• A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration

Preferred Qualifications:
• Master’s Degree in “STEM” field (Science, Technology, Engineering, or Mathematics), or PhD in “STEM” field (Science, Technology, Engineering, or Mathematics)
• Experience working with AWS
• At least 2 years’ experience in Python, Scala, or R
• At least 2 years’ experience with machine learning
• At least 2 years’ experience with SQL

Capital One will consider sponsoring a new qualified applicant for employment authorization for this position.

The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.
McLean, VA: $133,000 - $151,800 for Sr Assoc, Data ScienceNew York, NY: $145,100 - $165,600 for Sr Assoc, Data ScienceSan Jose, CA: $145,100 - $165,600 for Sr Assoc, Data Science

Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate’s offer letter.
This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.

Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at theCapital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.
This role is expected to accept applications for a minimum of 5 business days.No agencies please. Capital One is an equal opportunity employer (EOE, including disability/vet) committed to non-discrimination in compliance with applicable federal, state, and local laws. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",2025-07-03T00:00:00.000Z,2025-07-25,"['Customer first', 'You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them', 'You thrive on bringing definition to big, undefined problems', 'You love asking questions and pushing hard to find answers', 'You challenge conventional thinking and work with stakeholders to identify and improve the status quo', ""You're passionate about talent development for your own team and beyond"", 'Technical', 'You’re comfortable with advanced ML and DL technologies including language models and are passionate about developing further', 'You have hands-on experience working with LLMs and solutions using open-source tools and cloud computing platforms', 'Influential', 'You are passionate about AI/ML and can bring along a cross functional team in breakthrough innovations', 'You communicate clearly and effectively to share your findings with non-technical audiences', 'You are experienced in training language models or large computer vision models as well as have expertise in one or more key subdomains such as: training optimization, self-supervised learning, explainability, RLHF', 'You have an engineering mindset as shown by a track record of delivering models at scale both in training data and inference volumes', 'You have experience in delivering libraries, platforms, or solution level code to existing products', 'Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:', ""A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 2 years of experience performing data analytics"", ""A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration""]","['You will be the driving force to experiment, innovate and create next generation experiences powered by the latest emerging generative AI technologies', 'Partner with a cross-functional team of data scientists, software engineers, machine learning engineers and product managers to deliver AI powered products that change how customers interact with their money', 'Leverage a broad stack of technologies — Pytorch, AWS Ultraclusters, Hugging Face, LangChain, Lightning, VectorDBs, and more — to reveal the insights hidden within huge volumes of numeric and textual data', 'Be the expert in Natural Language Processing (NLP) to harness the power of Large Language Models (LLMs), adapt and finetune them for customer facing applications and features', 'Build machine learning and NLP models through all phases of development, from design through training, evaluation, and validation; partnering with engineering teams to operationalize them in scalable and resilient production systems that serve 80+ million customers', 'Flex your interpersonal skills to translate the complexity of your work into tangible business goals', 'You continually research and evaluate emerging technologies']",True,"['Large Language Models', 'Generative AI', 'PyTorch', 'Hugging Face', 'LangChain', 'Lightning', 'Vector Databases', 'Self-Supervised Learning', 'Reinforcement Learning from Human Feedback', 'Explainability']","Large Language Models: Central to building and fine-tuning customer-facing NLP applications leveraging state-of-the-art AI.; Generative AI: Used to create next-generation personalized experiences and AI-powered products for customers.; PyTorch: Deep learning framework employed for training and fine-tuning neural network models including LLMs.; Hugging Face: Open-source platform and library used for accessing and fine-tuning transformer-based language models.; LangChain: Framework used to build applications powered by LLMs, enabling integration of language models with external data.; Lightning: PyTorch Lightning framework used to streamline deep learning model training and experimentation.; Vector Databases: Specialized databases used to store and query vector embeddings for efficient similarity search in AI applications.; Self-Supervised Learning: AI training technique used to improve model performance without requiring labeled data.; Reinforcement Learning from Human Feedback: Advanced AI method applied to optimize language model behavior based on human feedback.; Explainability: Techniques used to interpret and understand AI model decisions, important for transparency in AI-powered products.","['Natural Language Processing', 'Machine Learning', 'Data Analytics', 'SQL', 'Python', 'Scala', 'R', 'AWS']","Natural Language Processing: Used to analyze and process large volumes of textual data to build models that enhance customer-facing applications.; Machine Learning: Applied to develop predictive and NLP models through all phases from design to production serving millions of customers.; Data Analytics: Performed to extract insights from numeric and textual data to support data-driven decision-making.; SQL: Used for querying and managing relational databases as part of data analytics and model development.; Python: Programming language used for data science, machine learning, and NLP model development.; Scala: Programming language experience preferred for data processing and analytics tasks.; R: Programming language experience preferred for statistical analysis and data science.; AWS: Cloud computing platform used to support scalable data processing and machine learning model training."
VdFYXEyTnfhyWtOLAAAAAA==,Junior Data Engineer - 1129-P Jobs,"Location: Reston, VA

Clearance Requirement: TS w/ SCI Eligibility

Job Description and Responsibilities:

Come join the future of data-driven decision making! At Data Machines we leverage data analytics, DevSecOps, machine intelligence, and data science to engineer solutions for our Federal government, defense, and commercial sponsors to solve real-world, critical mission problems.

Data Machines is looking for a motivated and detail-oriented Junior Data Engineer to join our growing Data Engineering team. This is an exciting opportunity for someone early in their career to gain hands-on experience with modern data technologies, contribute to the development of data pipelines, and help drive data-driven decision-making across the organization. This position is full-time on site in Reston, VA.

Key Responsibilities:
• Assist in the design, development, and maintenance of scalable data pipelines and ETL processes
• Work with structured and unstructured data from various sources to ingest, clean, transform, and store in appropriate formats
• Support the creation and optimization of data models in data warehouses (e.g., Postgres)
• Monitor data pipeline performance and troubleshoot issues as needed
• Collaborate with data analysts, data scientists, and software engineers to understand data needs
• Ensure data quality, integrity, and consistency across all data systems
• Maintain documentation for data processes and pipelines
• Learn and adapt to new tools, technologies, and best practices in data engineering

Minimum Qualifications:
• Active TS Clearance with SCI Eligibility
• Bachelor's degree in Computer Science, Engineering, Information Systems, or a related field
• Proficiency in SQL and at least one programming language (e.g., Python)
• Familiarity with relational databases and data warehousing concepts
• Understanding of ETL concepts and tools
• Exposure to workflow orchestration tools like Apache Airflow, NiFi and Kafka
• Strong analytical and problem-solving skills
• Excellent communication and teamwork abilities
• Eagerness to learn and grow in a fast-paced environment
• Experience in Jupyter Notebooks, PostgreSQL.
• Experience with version control systems (e.g., Git)

Desired Qualifications:
• Knowledge of data lake technologies and big data tools (e.g., Spark)
• Familiarity with containerization tools like Docker",2025-07-25T01:00:00.000Z,2025-07-25,"['Active TS Clearance with SCI Eligibility', ""Bachelor's degree in Computer Science, Engineering, Information Systems, or a related field"", 'Proficiency in SQL and at least one programming language (e.g., Python)', 'Familiarity with relational databases and data warehousing concepts', 'Understanding of ETL concepts and tools', 'Exposure to workflow orchestration tools like Apache Airflow, NiFi and Kafka', 'Strong analytical and problem-solving skills', 'Excellent communication and teamwork abilities', 'Eagerness to learn and grow in a fast-paced environment', 'Experience in Jupyter Notebooks, PostgreSQL', 'Experience with version control systems (e.g., Git)']","['Assist in the design, development, and maintenance of scalable data pipelines and ETL processes', 'Work with structured and unstructured data from various sources to ingest, clean, transform, and store in appropriate formats', 'Support the creation and optimization of data models in data warehouses (e.g., Postgres)', 'Monitor data pipeline performance and troubleshoot issues as needed', 'Collaborate with data analysts, data scientists, and software engineers to understand data needs', 'Ensure data quality, integrity, and consistency across all data systems', 'Maintain documentation for data processes and pipelines', 'Learn and adapt to new tools, technologies, and best practices in data engineering']",False,[],,"['Data Pipelines', 'ETL Processes', 'SQL', 'Python', 'Relational Databases', 'Data Warehousing', 'Workflow Orchestration', 'Jupyter Notebooks', 'Version Control', 'Big Data Tools', 'Containerization']","Data Pipelines: Designing, developing, and maintaining scalable data pipelines to ingest, clean, transform, and store data from various sources.; ETL Processes: Implementing Extract, Transform, Load processes to prepare data for analysis and storage.; SQL: Using SQL for querying and managing relational databases such as PostgreSQL.; Python: Programming language used for data manipulation, scripting, and working with data engineering tools.; Relational Databases: Working with structured data stored in relational database systems like PostgreSQL.; Data Warehousing: Supporting the creation and optimization of data models within data warehouses.; Workflow Orchestration: Using tools like Apache Airflow, NiFi, and Kafka to automate and manage data workflows.; Jupyter Notebooks: Utilizing Jupyter Notebooks for data exploration, analysis, and prototyping.; Version Control: Employing version control systems such as Git to manage code and collaboration.; Big Data Tools: Familiarity with big data technologies like Apache Spark for processing large datasets.; Containerization: Using containerization tools like Docker to package and deploy data engineering applications."
7lTh6mDn6ETjNrFtAAAAAA==,Data Science SME Instructor Jobs,"Responsibilities:
• Provide training support to ensure operations personnel receive the necessary systems knowledge required to advance their knowledge and comprehension of Data Science and Advanced Data Analytics capabilities/tradecraft, either directly or with the assistance of Data Scientist or Domain Experts
• Provide insight into current/future course needs/development across the wide spectrum of Data Science and Advanced Data Analytics tradecraft.
• Perform the majority of course development, instruct high-level specialized courses, and identify/incorporate new data science/analytics techniques into course materials and offerings
• Provide mission areas with direct mentoring to assist customers with implementation of newly acquired/learned skills

Required Skills:
• Must be a U.S. Citizen
• Active TS/SCI clearance and polygraph required
• Preferred: Experience instructing NCU courses/NCU Adjunct Certified
• Minimum of four (4) years' experience performing data-analysis on massive amounts of collected information in order to pinpoint unique insight and intelligence opportunities within the data
• Must have experience with scripting/data analytics (Python, Perl, Bash, etc.)
• Must be highly proficient within at least two of the following skill areas:
• Mathematics/Statistics
• Computer Science
• Scripting
• Cloud Computing
• Data Mining, Metadata Analysis or Machine Learning
• Artificial Intelligence
• Data Visualization or Data Automation.
• Must have familiarity with relational capabilities integration, a wide variety of tools and tradecraft, as well as automation of analytic processes
• Must be an expert in understanding ""Big Data Analytics"" from the perspective of data management, data preparation, data governance and analytic development and production
• Must have in-depth experience with at least two of the following advanced scripting languages and tools; Python, R, SQL, Lucene, Jupyter, Pig, Scala, ELK Stack, Splunk, PowerBI, or Jupyter Notebooks

Compensation Range: $186,000 - $245,000

_____________________________________________________________________________________________________

Compensation ranges encompass a total compensation package and are a general guideline only and not intended as a guaranteed and/or implied final compensation or salary for this job opening. Determination of official compensation or salary relies on several different factors including, but not limited to: level of position, complexity of job responsibilities, geographic location, candidate's scope of relevant work experience, educational background, certifications, contract-specific affordability, organizational requirements and alignment with local market data.

Our compensation includes other indirect financial components designed to support employees' total well-being, which should be considered when evaluating our competitive benefits package. These monetary benefits include medical insurance, life insurance, disability, paid time off, maternity/paternity leave, 401(k) company match, training/education reimbursements and other work/life programs.

_____________________________________________________________________________________________________

IntelliGenesis is committed to providing equal opportunity to all employees and applicants for employment. The Company is an Equal Opportunity Employer (EOE), and as such, does not tolerate discrimination, retaliation, or harassment of its employees or applicants based upon race, color, religion, gender, sexual orientation, national origin, age, genetic information, disability, or any other protected characteristic under local, state, or federal law in any employment practice. Such employment practices include, but are not limited to: hiring, promotion, demotion, transfer, recruitment, or recruitment advertising, selection, disciplinary action layoff, termination, rates of pay, or other forms of compensation and selection of training.

IntelliGenesis is committed to the fair and equal employment of individuals with disabilities. It is the Company's policy to reasonably accommodate qualified individuals with disabilities unless the accommodation would impose an undue hardship on the organization. In accordance with the Americans with Disabilities Act (ADA) as amended, reasonable accommodations will be provided to qualified individuals with disabilities, when such accommodations are necessary, to enable them to perform the essential functions of their jobs or to enjoy the equal benefits and privileges of employment. This policy applies to all applicants for employment and all employees.",2025-07-22T00:00:00.000Z,2025-07-25,"['Must be a U.S. Citizen', 'Active TS/SCI clearance and polygraph required', ""Minimum of four (4) years' experience performing data-analysis on massive amounts of collected information in order to pinpoint unique insight and intelligence opportunities within the data"", 'Must have experience with scripting/data analytics (Python, Perl, Bash, etc.)', 'Must be highly proficient within at least two of the following skill areas:', 'Mathematics/Statistics', 'Computer Science', 'Scripting', 'Cloud Computing', 'Data Mining, Metadata Analysis or Machine Learning', 'Artificial Intelligence', 'Data Visualization or Data Automation', 'Must have familiarity with relational capabilities integration, a wide variety of tools and tradecraft, as well as automation of analytic processes', 'Must be an expert in understanding ""Big Data Analytics"" from the perspective of data management, data preparation, data governance and analytic development and production', 'Must have in-depth experience with at least two of the following advanced scripting languages and tools; Python, R, SQL, Lucene, Jupyter, Pig, Scala, ELK Stack, Splunk, PowerBI, or Jupyter Notebooks']","['Provide training support to ensure operations personnel receive the necessary systems knowledge required to advance their knowledge and comprehension of Data Science and Advanced Data Analytics capabilities/tradecraft, either directly or with the assistance of Data Scientist or Domain Experts', 'Provide insight into current/future course needs/development across the wide spectrum of Data Science and Advanced Data Analytics tradecraft', 'Perform the majority of course development, instruct high-level specialized courses, and identify/incorporate new data science/analytics techniques into course materials and offerings', 'Provide mission areas with direct mentoring to assist customers with implementation of newly acquired/learned skills']",True,['Artificial Intelligence'],Artificial Intelligence: Incorporated as a skill area indicating use of AI techniques within data science and analytics training.,"['Data Analysis', 'Python', 'Perl', 'Bash', 'Mathematics and Statistics', 'Computer Science', 'Cloud Computing', 'Data Mining', 'Metadata Analysis', 'Machine Learning', 'Data Visualization', 'Data Automation', 'Relational Database Integration', 'Big Data Analytics', 'R', 'SQL', 'Lucene', 'Jupyter Notebooks', 'Pig', 'Scala', 'ELK Stack', 'Splunk', 'Power BI']","Data Analysis: Performing analysis on large datasets to extract unique insights and intelligence opportunities.; Python: Used for scripting and data analytics tasks, including automation and data processing.; Perl: Scripting language employed for data analytics and automation.; Bash: Shell scripting used for automating analytic processes and data workflows.; Mathematics and Statistics: Core skill areas for developing and understanding data science and analytics techniques.; Computer Science: Fundamental knowledge area supporting data science methodologies and tool usage.; Cloud Computing: Utilized for scalable data storage, processing, and analytics infrastructure.; Data Mining: Extracting patterns and knowledge from large datasets as part of analytics tradecraft.; Metadata Analysis: Analyzing data about data to improve data management and analytic outcomes.; Machine Learning: Applying algorithms to build predictive models and automate data-driven decision making.; Data Visualization: Creating visual representations of data to communicate insights effectively.; Data Automation: Automating repetitive data processing and analytic tasks to improve efficiency.; Relational Database Integration: Incorporating relational database capabilities to manage and query structured data.; Big Data Analytics: Expertise in managing, preparing, governing, and developing analytics on large-scale datasets.; R: Advanced scripting language used for statistical computing and data analysis.; SQL: Language for querying and managing relational databases.; Lucene: Tool for text search and indexing, supporting data retrieval tasks.; Jupyter Notebooks: Interactive environment for developing and sharing data science code and visualizations.; Pig: Platform for analyzing large data sets using a high-level scripting language.; Scala: Programming language often used for big data processing frameworks.; ELK Stack: Collection of tools (Elasticsearch, Logstash, Kibana) for searching, analyzing, and visualizing data.; Splunk: Platform for searching, monitoring, and analyzing machine-generated big data.; Power BI: Business intelligence tool for creating dashboards and reports."
NZfkLG0Jg-Da5b3wAAAAAA==,DATA POLICY ANALYST - VIRGINIA -URGENT Jobs,"Job Number: 169

Job Category: GovTech

Job Title: DATA POLICY ANALYST - VIRGINIA -URGENT

Job Type: Full-time

Clearance Level: TS/SCI with POLY

Work Arrangement: On-site

Job Location: Tysons VA

Background
• Document data dictionaries and curation processes to deploy consistent understanding of data across Sponsor internal stakeholders and external product consumers
• Support Sponsor technical engagements with LNI Executive Agent, including communication of priorities for LNI technical development
• Enhance data quality models to address advanced data curation needs (e.g., classification analysis) and to integrate IC mission data to key parameters (e.g., NIPF, National Intelligence Program (NIP)
• Contribute to development of tools to automate data collection and enhance the data collection process
• Support Sponsor technical engagements with IC elements on data definition and quality issues, including bilateral conversations and IC-wide forums

Requirements
• Bachelor's degree in a relevant field (Business Information Systems, Library Science) or equivalent relevant experience
• 3+ years of experience developing data standards and/or operating data governance efforts within and across IC elements
• 3+ years of experience evaluating and monitoring data quality using database tools and data visualization techniques
• Demonstrated knowledge of IC reporting data standards and formats and knowledge of software tools for data governance and specification (e.g., Collibra)

Preferred
• Experience developing data standards and/or interfaces documentation as implemented in an international, IC or US Government specification",2025-07-25T11:00:00.000Z,2025-07-25,"[""Bachelor's degree in a relevant field (Business Information Systems, Library Science) or equivalent relevant experience"", '3+ years of experience developing data standards and/or operating data governance efforts within and across IC elements', '3+ years of experience evaluating and monitoring data quality using database tools and data visualization techniques', 'Demonstrated knowledge of IC reporting data standards and formats and knowledge of software tools for data governance and specification (e.g., Collibra)']","['Document data dictionaries and curation processes to deploy consistent understanding of data across Sponsor internal stakeholders and external product consumers', 'Support Sponsor technical engagements with LNI Executive Agent, including communication of priorities for LNI technical development', 'Enhance data quality models to address advanced data curation needs (e.g., classification analysis) and to integrate IC mission data to key parameters (e.g., NIPF, National Intelligence Program (NIP)', 'Contribute to development of tools to automate data collection and enhance the data collection process', 'Support Sponsor technical engagements with IC elements on data definition and quality issues, including bilateral conversations and IC-wide forums']",False,[],,"['Data Quality Models', 'Data Dictionaries', 'Data Curation', 'Data Governance', 'Data Visualization', 'Data Collection Automation', 'Data Standards', 'Collibra']",Data Quality Models: Used to enhance data curation and ensure the integrity of intelligence community mission data.; Data Dictionaries: Documented to provide consistent understanding of data across internal stakeholders and external consumers.; Data Curation: Processes applied to organize and maintain data quality and classification for intelligence data.; Data Governance: Efforts to develop and operate data standards and policies within and across intelligence community elements.; Data Visualization: Techniques used to evaluate and monitor data quality through database tools.; Data Collection Automation: Development of tools to automate and improve the data collection process.; Data Standards: Development and documentation of data standards and interfaces for intelligence community reporting.; Collibra: Software tool referenced for data governance and specification.
H9PUzNh9aNkfnKxvAAAAAA==,Senior AI/ML Cybersecurity Data Scientist Jobs,"Senior AI/ML Cybersecurity Data Scientist

Job Category: Science

Time Type: Full time

Minimum Clearance Required to Start: TS/SCI with Polygraph

Employee Type: Regular

Percentage of Travel Required: None

Type of Travel: None
• * *

The Opportunity:

CACI is seeking a Senior AI/ML Cybersecurity Data Scientist to be at the forefront of developing and securing cutting-edge machine learning solutions. This unique role combines advanced data science expertise with a focus on AI/ML security and compliance. You will have the opportunity to shape the future of secure AI systems, working on groundbreaking projects that require both analytical prowess and a deep understanding of cybersecurity frameworks. Join us in this exciting role where you will leverage your data science expertise to drive innovation while ensuring the security and compliance of critical AI/ML systems. Your work will directly impact the development of secure, cutting-edge machine learning solutions in high-stakes environments.

Responsibilities:
• Develop and implement machine learning, data mining, and graph-based algorithms for complex datasets
• Prototype and evaluate algorithms, selecting optimal models based on performance metrics • Generate insightful reports and visualizations to communicate data-driven insights
• Collaborate with subject matter experts to automate manual data analysis processes
• Secure and obtain authorization for AI/ML systems under the Risk Management Framework (RMF)
• Write and maintain System Security Plans (SSPs) for AI/ML projects
• Conduct risk assessments and ensure compliance of AI/ML systems
• Define security and performance requirements for AI/ML tools
• Manage secure deployment and configuration of AI/ML services
• Perform security reviews for AI/ML requests and implementations

Qualifications:

Required:
• Active TS/SCI w/ Polygraph
• Bachelor's degree in a quantitative discipline (e.g., statistics, mathematics, operations research, engineering, or computer science)
• 10+ years of experience analyzing datasets and developing analytics
• 10+ years of experience programming with data analysis software (e.g., R, Python, SAS, or MATLAB)
• Experience with AI/ML RMF SSP authorization
• Expertise in AI/ML services contracts and configurations
• Proficiency in conducting AI/ML request security reviews

Desired:
• Master's degree or PhD in a relevant field (can substitute for years of experience)
• Experience in software development and cloud environments
• Strong background in cybersecurity principles and practices
• Excellent communication skills to convey complex technical concepts
• Ability to work effectively in cross-functional teams
• Passion for staying current with the latest AI/ML and security trends

-
________________________________________________________________________________________

What You Can Expect:

A culture of integrity.

At CACI, we place character and innovation at the center of everything we do. As a valued team member, you'll be part of a high-performing group dedicated to our customer's missions and driven by a higher purpose - to ensure the safety of our nation.

An environment of trust.

CACI values the unique contributions that every employee brings to our company and our customers - every day. You'll have the autonomy to take the time you need through a unique flexible time off benefit and have access to robust learning resources to make your ambitions a reality.

A focus on continuous growth.

Together, we will advance our nation's most critical missions, build on our lengthy track record of business success, and find opportunities to break new ground - in your career and in our legacy.

Your potential is limitless. So is ours.

Learn more about CACI here.

________________________________________________________________________________________

Pay Range: There are a host of factors that can influence final salary including, but not limited to, geographic location, Federal Government contract labor categories and contract wage rates, relevant prior work experience, specific skills and competencies, education, and certifications. Our employees value the flexibility at CACI that allows them to balance quality work and their personal lives. We offer competitive compensation, benefits and learning and development opportunities. Our broad and competitive mix of benefits options is designed to support and protect employees and their families. At CACI, you will receive comprehensive benefits such as; healthcare, wellness, financial, retirement, family support, continuing education, and time off benefits. Learn more here .

The proposed salary range for this position is:
$131,800 - $290,000

CACI is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, age, national origin, disability, status as a protected veteran, or any other protected characteristic.",2025-07-23T00:00:00.000Z,2025-07-25,"['Minimum Clearance Required to Start: TS/SCI with Polygraph', 'You will have the opportunity to shape the future of secure AI systems, working on groundbreaking projects that require both analytical prowess and a deep understanding of cybersecurity frameworks', 'Active TS/SCI w/ Polygraph', ""Bachelor's degree in a quantitative discipline (e.g., statistics, mathematics, operations research, engineering, or computer science)"", '10+ years of experience analyzing datasets and developing analytics', '10+ years of experience programming with data analysis software (e.g., R, Python, SAS, or MATLAB)', 'Experience with AI/ML RMF SSP authorization', 'Expertise in AI/ML services contracts and configurations', 'Proficiency in conducting AI/ML request security reviews']","['Your work will directly impact the development of secure, cutting-edge machine learning solutions in high-stakes environments', 'Develop and implement machine learning, data mining, and graph-based algorithms for complex datasets', 'Prototype and evaluate algorithms, selecting optimal models based on performance metrics', 'Generate insightful reports and visualizations to communicate data-driven insights', 'Collaborate with subject matter experts to automate manual data analysis processes', 'Secure and obtain authorization for AI/ML systems under the Risk Management Framework (RMF)', 'Write and maintain System Security Plans (SSPs) for AI/ML projects', 'Conduct risk assessments and ensure compliance of AI/ML systems', 'Define security and performance requirements for AI/ML tools', 'Manage secure deployment and configuration of AI/ML services', 'Perform security reviews for AI/ML requests and implementations']",True,"['AI/ML Security and Compliance', 'AI/ML System Authorization', 'AI/ML Service Configuration and Deployment', 'AI/ML Risk Assessment']","AI/ML Security and Compliance: Ensuring security, risk management, and compliance of AI/ML systems under frameworks like RMF.; AI/ML System Authorization: Securing and obtaining authorization for AI/ML systems to operate within regulated cybersecurity environments.; AI/ML Service Configuration and Deployment: Managing secure deployment and configuration of AI/ML services in cybersecurity settings.; AI/ML Risk Assessment: Conducting risk assessments and security reviews specific to AI/ML implementations.","['Machine Learning', 'Data Mining', 'Graph-Based Algorithms', 'Algorithm Prototyping and Evaluation', 'Data Visualization', 'Data Analysis Software (R, Python, SAS, MATLAB)']","Machine Learning: Developing and implementing machine learning algorithms to analyze complex cybersecurity datasets.; Data Mining: Applying data mining techniques to extract meaningful patterns from cybersecurity data.; Graph-Based Algorithms: Using graph-based algorithms to analyze relationships and structures within cybersecurity data.; Algorithm Prototyping and Evaluation: Prototyping and selecting optimal models based on performance metrics for cybersecurity applications.; Data Visualization: Generating reports and visualizations to communicate data-driven insights in cybersecurity contexts.; Data Analysis Software (R, Python, SAS, MATLAB): Utilizing programming languages and tools for data analysis and algorithm development."
rr9tGrODdjuX6FdeAAAAAA==,Data Scientist III Jobs,"Overview

Falconwood is a woman-owned, veteran-owned company providing consultation and programmatic support to Department of Defense Information Technology (IT) initiatives and programs. We provide expert advice and consultation on a diverse range of IT subjects, focusing on acquisition, policy, cybersecurity, engineering, and process development.

The Data Scientist III will be responsible for leading advanced analytics and data science initiatives in support of the Commander, Naval Information Forces (NAVIFOR) N6 Directorate, with a focus on strategic data enablement across the Navy Information Warfare enterprise.

Responsibilities

This position provides oversight and direction for the implementation of data strategies, frameworks, and predictive analytics. The candidate will align data solutions with mission goals, lead cross-functional teams, and guide the adoption of enterprise-wide data governance, visualization, and analysis tools. This position is a hybrid role based in Suffolk, VA, with limited travel anticipated.

Responsibilities
• Lead the strategic development and execution of data science and analytics initiatives supporting NAVIFOR's Command Data Office (CDO)
• Oversee the implementation of the NAVIFOR CDO Data and Analytics Capability Maturity Implementation Plan (I-Plan)
• Apply advanced data science techniques including machine learning, AI, and statistical modeling to develop mission-aligned insights
• Coordinate enterprise data governance and strategy across diverse stakeholder groups
• Provide subject matter expertise in designing and optimizing Extract, Transform, Load (ETL) pipelines and data architecture
• Supervise and mentor junior data scientists, analysts, and engineers in best practices and methodologies
• Develop performance metrics, dashboards, and process improvement strategies using NPIER/DMAIC
• Author and present detailed white papers, briefs, and reports to Flag/SES-level stakeholders

Qualifications

Education: Master's degree in Analytics, Statistics, Computer Science, Information Systems, Engineering, Mathematics, or a related discipline

Experience: Minimum of 7 years of demonstrated experience in data strategy, data science, governance, and advanced analytics, preferably supporting DoD or Navy enterprise environments

Clearance: Active Secret Clearance required

Technical Skills:
• Expertise in statistical analysis, AI/ML frameworks, and advanced analytics tools
• Familiarity with data governance, Navy data strategies, and enterprise analytics
• Experience with Navy cloud platforms, data engineering tools, and collaboration tools such as Power BI, Jupyter, Confluence, and Jama

The candidate must:
• Be capable of performing effectively individually and as part of a team
• Have effective critical thinking and problem-solving skills
• Be self-motivated and able to successfully deliver with minimal supervision
• Be proficient in Microsoft Office Suite

Pay Range

Base pay is $135,000-$145,000, subject to skill level, qualifications, and location.

Benefits Highlights:

401k, Tuition Reimbursement, Health/Dental/Vision Insurance, PTO, Federal Holidays, Performance Increases, Reserve Duty Compensation and more!",2025-07-18T00:00:00.000Z,2025-07-25,"[""Education: Master's degree in Analytics, Statistics, Computer Science, Information Systems, Engineering, Mathematics, or a related discipline"", 'Experience: Minimum of 7 years of demonstrated experience in data strategy, data science, governance, and advanced analytics, preferably supporting DoD or Navy enterprise environments', 'Clearance: Active Secret Clearance required', 'Expertise in statistical analysis, AI/ML frameworks, and advanced analytics tools', 'Familiarity with data governance, Navy data strategies, and enterprise analytics', 'Experience with Navy cloud platforms, data engineering tools, and collaboration tools such as Power BI, Jupyter, Confluence, and Jama', 'Be capable of performing effectively individually and as part of a team', 'Have effective critical thinking and problem-solving skills', 'Be self-motivated and able to successfully deliver with minimal supervision', 'Be proficient in Microsoft Office Suite']","['The Data Scientist III will be responsible for leading advanced analytics and data science initiatives in support of the Commander, Naval Information Forces (NAVIFOR) N6 Directorate, with a focus on strategic data enablement across the Navy Information Warfare enterprise', 'This position provides oversight and direction for the implementation of data strategies, frameworks, and predictive analytics', 'The candidate will align data solutions with mission goals, lead cross-functional teams, and guide the adoption of enterprise-wide data governance, visualization, and analysis tools', 'This position is a hybrid role based in Suffolk, VA, with limited travel anticipated', ""Lead the strategic development and execution of data science and analytics initiatives supporting NAVIFOR's Command Data Office (CDO)"", 'Oversee the implementation of the NAVIFOR CDO Data and Analytics Capability Maturity Implementation Plan (I-Plan)', 'Apply advanced data science techniques including machine learning, AI, and statistical modeling to develop mission-aligned insights', 'Coordinate enterprise data governance and strategy across diverse stakeholder groups', 'Provide subject matter expertise in designing and optimizing Extract, Transform, Load (ETL) pipelines and data architecture', 'Supervise and mentor junior data scientists, analysts, and engineers in best practices and methodologies', 'Develop performance metrics, dashboards, and process improvement strategies using NPIER/DMAIC', 'Author and present detailed white papers, briefs, and reports to Flag/SES-level stakeholders']",True,"['Artificial Intelligence', 'AI/ML Frameworks']",Artificial Intelligence: Applied alongside machine learning and statistical modeling to develop mission-aligned insights.; AI/ML Frameworks: Expertise required to implement advanced analytics and AI-driven data science solutions.,"['Statistical Modeling', 'Machine Learning', 'Data Governance', 'Extract, Transform, Load (ETL) Pipelines', 'Data Strategy', 'Data Visualization', 'Power BI', 'Jupyter', 'Advanced Analytics', 'NPIER/DMAIC']","Statistical Modeling: Used to develop mission-aligned insights through advanced data science techniques.; Machine Learning: Applied as part of advanced data science techniques to support predictive analytics and insights.; Data Governance: Coordinated enterprise-wide to ensure data strategy alignment and compliance across diverse stakeholder groups.; Extract, Transform, Load (ETL) Pipelines: Designed and optimized to support data architecture and efficient data processing.; Data Strategy: Developed and executed to align data solutions with mission goals and enterprise-wide initiatives.; Data Visualization: Used to create dashboards and analysis tools for performance metrics and reporting.; Power BI: A BI tool utilized for developing dashboards and visualizing data insights.; Jupyter: Used as a collaboration and development environment for data science and analytics.; Advanced Analytics: Applied to support strategic data enablement and predictive analytics initiatives.; NPIER/DMAIC: Methodologies used for process improvement and developing performance metrics."
ipKOsWNirrArF9ziAAAAAA==,"Data Scientist, Mid Jobs","Job Number: R0222267

Data Scientist, Mid

The Opportunity:

Are you excited at the prospect of unlocking the secrets held by a data set? Are you fascinated by the possibilities presented by the IoT, machine learning, and artifi cia l intelligence advances? In an increasingly connected world, massive amounts of structured and unstructured data open-up new opportunities. As a data scientist, you can turn these complex data sets into useful information to solve global challenges. Across private and public sectors from fraud detection to cancer research, to national intelligence, you know the answers are in the data.

We have an opportunity for you to use your leadership and analytical skills to improve a client's data science capability. You'll work closely with your client to understand their questions and needs, and then dig into their data-rich environment to find the pieces of their information puzzle. You'll mentor teammates and use the right combination of tools and frameworks to turn that set of disparate data points into objective answers to help leadership make informed decisions. You'll provide your customer with a deep understanding of their data, what it all means, and how they can use it. Join us as we use data science for good in building this capability.

Join us. The world can't wait.

You Have:
• 3+ years of experience with programming in R, Python, or Java
• Experience with business analytics, including dashboarding in Power BI or Tableau, business process analysis, and defining and capturing metrics
• Experience with data engineering, including ETL and querying APIs
• Experience with VBA
• Ability to communicate and collaborate with senior DoD leadership
• Ability to experiment and solve complex open-ended client challenges
• TS / SCI clearance
• Bachelor's degree

Nice If You Have:
• Experience with foundational military intelligence or DoD intelligence processes
• Knowledge of Intelligence Community ( IC ) systems, policies , platforms, data types, and challenges
• TS/SCI clearance with a polygraph

Clearance:

Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information ; TS/SCI clearance is required.

Compensation

At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen's benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.

Salary at Booz Allen is determined by various factors, including but not limited to location, the individual's particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $77,500.00 to $176,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen's total compensation package for employees. This posting will close within 90 days from the Posting Date.

Identity Statement

As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud.

Work Model

Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.
• If this position is listed as remote or hybrid, you'll periodically work from a Booz Allen or client site facility.
• If this position is listed as onsite, you'll work with colleagues and clients in person, as needed for the specific role.

Commitment to Non-Discrimination

All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law.",2025-07-22T00:00:00.000Z,2025-07-25,"['3+ years of experience with programming in R, Python, or Java', 'Experience with business analytics, including dashboarding in Power BI or Tableau, business process analysis, and defining and capturing metrics', 'Experience with data engineering, including ETL and querying APIs', 'Experience with VBA', 'Ability to communicate and collaborate with senior DoD leadership', 'Ability to experiment and solve complex open-ended client challenges', 'TS / SCI clearance', ""Bachelor's degree"", 'Experience with foundational military intelligence or DoD intelligence processes', 'Knowledge of Intelligence Community ( IC ) systems, policies , platforms, data types, and challenges', 'TS/SCI clearance with a polygraph', 'Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information ; TS/SCI clearance is required']","[""We have an opportunity for you to use your leadership and analytical skills to improve a client's data science capability"", ""You'll work closely with your client to understand their questions and needs, and then dig into their data-rich environment to find the pieces of their information puzzle"", ""You'll mentor teammates and use the right combination of tools and frameworks to turn that set of disparate data points into objective answers to help leadership make informed decisions"", ""You'll provide your customer with a deep understanding of their data, what it all means, and how they can use it"", ""If this position is listed as remote or hybrid, you'll periodically work from a Booz Allen or client site facility"", ""If this position is listed as onsite, you'll work with colleagues and clients in person, as needed for the specific role""]",True,[],,"['R', 'Python', 'Java', 'Power BI', 'Tableau', 'ETL', 'API Querying', 'VBA', 'Business Process Analysis', 'Dashboarding']","R: Used as a programming language for statistical analysis and data science tasks in the role.; Python: Used as a programming language for data manipulation, analysis, and building data science solutions.; Java: Used as a programming language potentially for data processing or integration tasks.; Power BI: Employed for business analytics and dashboarding to visualize and communicate data insights.; Tableau: Used for creating interactive dashboards and business intelligence reporting.; ETL: Involved in data engineering processes to extract, transform, and load data for analysis.; API Querying: Used to retrieve data from external or internal sources as part of data engineering tasks.; VBA: Utilized for automating tasks and data processing within Microsoft Office applications.; Business Process Analysis: Applied to understand and improve business workflows and define relevant metrics.; Dashboarding: Creating visual representations of data to support decision-making by leadership."
_CsHNij4e3_2ocvEAAAAAA==,Mid Data Scientist Jobs,"Prescient Edge is seeking a Mid. Data Scientist to support a federal government client.

Benefits:

At Prescient Edge, we believe that acting with integrity and serving our employees is the key to everyone's success. To that end, we provide employees with a best-in-class benefits package that includes:
• A competitive salary with performance bonus opportunities.
• Comprehensive healthcare benefits, including medical, vision, dental, and orthodontia coverage.
• A substantial retirement plan with no vesting schedule.
• Career development opportunities, including on-the-job training, tuition reimbursement, and networking.
• A positive work environment where employees are respected, supported, and engaged.

Job Requirements

Experience:
• 3+ years of experience in one or more of the following: Business Analysis, Army Special Operations, Intelligence and/or Information Management/ Knowledge Management.
• 3+ years of Experience supporting the United States Military, preferably SOF elements.
• Certification or 2+ years of experience with a diverse set of analytical tools and suites to include Tableau and Alteryx and familiarity with Python, R, MATLAB or other coding platforms.

Education:
• BA/BS from an accredited institution, or former Officer, NCO or Warrant Officer with Military Experience or Intelligence/Knowledge Management background.

Security Clearance:
• Current DOD TS/SCI security clearance.

Location:
• Fort Bragg, NC.

Prescient Edge is a Veteran-Owned Small Business (VOSB) founded as a counterintelligence (CI) and Human Intelligence (HUMINT) company in 2008. We are a global operations and solutions integrator delivering full-spectrum intelligence analysis support, training, security, and RD&E support solutions to the Department of Defense and throughout the intelligence community. Prescient Edge is an Equal Opportunity Employer (EEO). All applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, or any other characteristic that is protected by law. We strive to foster equity and inclusion throughout our organization because we believe that diversity of thought is critical for creating a safe and engaging work environment while also enabling the organization's success.",2025-07-25T02:00:00.000Z,2025-07-25,"['3+ years of experience in one or more of the following: Business Analysis, Army Special Operations, Intelligence and/or Information Management/ Knowledge Management', '3+ years of Experience supporting the United States Military, preferably SOF elements', 'Certification or 2+ years of experience with a diverse set of analytical tools and suites to include Tableau and Alteryx and familiarity with Python, R, MATLAB or other coding platforms', 'BA/BS from an accredited institution, or former Officer, NCO or Warrant Officer with Military Experience or Intelligence/Knowledge Management background', 'Current DOD TS/SCI security clearance']",,True,[],,"['Tableau', 'Alteryx', 'Python', 'R', 'MATLAB']","Tableau: Used as a BI tool for creating dashboards and visualizing data to support intelligence analysis.; Alteryx: Employed for data preparation, blending, and advanced analytics to support analytical workflows.; Python: Familiarity with Python is required for scripting, data analysis, and possibly building analytical models.; R: Used for statistical analysis and data visualization in support of intelligence and knowledge management.; MATLAB: Applied for numerical computing and data analysis tasks relevant to intelligence and operational support."
HUITRzw7krG6o6tIAAAAAA==,Data Scientist (5010) Jobs,"GVI Inc., subsidiary of Three Saints Bay, LLC, and a Federal Government Contractor industry leader, is seeking a Data Scientist in Philadelphia, PA.

Position Requirement:
• Target Education: Bachelors degree in engineering or business from an accredited college or university.
• Target Experience: Five (5) years of experience in transforming raw data into meaningful insights through advanced data programming, statistical analysis, and visualization tools. This individual should demonstrate strong analytical skills, proficiency in scripting languages such as Python or R, and expertise in SQL for data extraction and integration. Key abilities include applying data mining, modeling, and machine learning techniques to analyze large datasets, as well as creating dynamic reports, dashboards, and visualizations.
• U.S. Citizen

Position is located in Philadelphia, PA.

VEVRAA Federal Contractor

Three Saints Bay, LLC and its subsidiaries offer a team-oriented working environment and the opportunity to work with exceptional, dedicated industry professionals. We offer our employees a comprehensive benefits package and the opportunity to take part in exciting projects with government and commercial clients, both domestic and international.

We are an Equal Opportunity Employer. We invite resumes from all interested parties without regard to race, color, sex, sexual preference, religion, creed, national origin, age, genetic information, marital or veteran status, disability, or any other category protected by federal, state, or local law.",2025-07-18T00:00:00.000Z,2025-07-25,"['Target Education: Bachelors degree in engineering or business from an accredited college or university', 'Target Experience: Five (5) years of experience in transforming raw data into meaningful insights through advanced data programming, statistical analysis, and visualization tools', 'This individual should demonstrate strong analytical skills, proficiency in scripting languages such as Python or R, and expertise in SQL for data extraction and integration', 'Key abilities include applying data mining, modeling, and machine learning techniques to analyze large datasets, as well as creating dynamic reports, dashboards, and visualizations', 'U.S. Citizen']",,True,[],,"['Python', 'R', 'SQL', 'Data Mining', 'Statistical Analysis', 'Machine Learning', 'Data Visualization', 'Data Modeling']","Python: Used as a scripting language for advanced data programming and analysis.; R: Used as a scripting language for statistical analysis and data programming.; SQL: Utilized for data extraction and integration from databases.; Data Mining: Applied to analyze large datasets and extract meaningful patterns.; Statistical Analysis: Used to transform raw data into insights through quantitative methods.; Machine Learning: Employed to model and analyze large datasets for predictive insights.; Data Visualization: Creation of dynamic reports, dashboards, and visualizations to communicate data insights.; Data Modeling: Used to represent data structures and relationships for analysis."
6rFMigrlJs0dAy89AAAAAA==,ML/Data Science Software Engineer (Onsite) Jobs,"Date Posted:
2025-07-18
Country:
United States of America
Location:
PA602: 302 Science Park Road, Bldg 5C 302 Science Park Road Building 5C, State College, PA, 16803-2214 USA
Position Role Type:
Onsite
U.S. Citizen, U.S. Person, or Immigration Status Requirements:
Active and transferable U.S. government issued security clearance is required prior to start date. U.S. citizenship is required, as only U.S. citizens are eligible for a security clearance
Security Clearance:
TS/SCI without Polygraph

At Raytheon, the foundation of everything we do is rooted in our values and a higher calling - to help our nation and allies defend freedoms and deter aggression. We bring the strength of more than 100 years of experience and renowned engineering expertise to meet the needs of today's mission and stay ahead of tomorrow's threat. Our team solves tough, meaningful problems that create a safer, more secure world.

In the ML/Data Science Software Engineering role, you will design, develop, and test AI/ML, Java and Python code in a Linux, Agile, DevOps environment. We are at the forefront of aerospace and defense technology. Our Satellite Ground Systems Team plays a pivotal role in ensuring communication, surveillance, and defense capabilities through cutting-edge satellite systems. We invite you to be part of a team that pushes the boundaries of what's possible. Due to the security clearance requirement, this is an onsite position in our State College, PA office.

What You Will Do
• Design, develop, and maintain advanced software applications for our Satellite Ground Systems.
• Collaborate closely with systems engineers, hardware designers, and other software engineers to deliver reliable and high-performance software solutions.
• Design, implement, and test AI, ML, Java and Python based applications and software components for satellite ground systems.
• Work in parallel with legacy platform teams to eventually migrate workloads onto your pipelines.
• Collaborate with cross-functional teams to define software requirements and specifications.
• Work with previously written code and make modifications as necessary.
• Ensure software performance, reliability, and scalability.
• Participate in software design reviews, code reviews, and system integration activities.
• Contribute to the completion of program and project milestones under the specific guidance of their immediate supervisor.
• Follow established Software processes and procedures, development, documentation and maintenance/management of operations concepts, requirements (system, element, segment level), external and internal interfaces, and other software engineering work products/artifacts.

Qualifications You Must Have
• Active and transferable U.S. government issued TS/SCI security clearance is required prior to start date. U.S. citizenship is required, as only U.S. citizens are eligible for a security clearance.
• Typically requires a degree in Science, Technology, Engineering or Mathematics (STEM) and two (2) years of Software Engineering experience.
• Experience in object-oriented software design and development using Java or Python in a Linux environment.
• Experience with unit testing tools (e.g., JUnit).
• Experience in Machine Learning and Data Science.
• Experience working with large datasets and performing data analysis.

Qualifications We Prefer
• Strong analytical skills and proactive problem-solving abilities, with a deep understanding of AI/ML technologies, cloud architecture, and enterprise software.
• Security+ certification.
• Experience with Git, Jenkins, Docker, Kubernetes.
• Experience with the Atlassian Tool Suite (e.g. JIRA, Confluence, BitBucket).
• Experience with cloud computing platform (e.g. AWS or Azure).
• Experience with satellite communication systems and protocols is highly preferred.
• Familiarity with secure coding practices, especially in a defense or aerospace setting.

What We Offer
• Whether you're just starting out on your career journey or are an experienced professional, we offer a total rewards package that goes above and beyond with compensation; healthcare, wellness, retirement, and work/life benefits; career development and recognition programs. Some of the benefits we offer include parental (including paternal) leave, flexible work schedules, achievement awards, educational assistance, and child/adult backup care.
• Relocation Eligibility - Relocation assistance is available.

Learn More & Apply Now!
• Please consider the following role type definition as you apply for this role. Onsite: Employees who are working in Onsite roles will work primarily onsite. This includes all production and maintenance employees, as they are essential to the development of our products.
• This position requires a security clearance. DCSA Consolidated Adjudication Services (DCSA) , an agency of the Department of Defense, handles and adjudicates the security clearance process. More information about Security Clearances can be found on the US Department of State government website here: https://www.state.gov/m/ds/clearances/c10978.htm
• State College, PA: https://careers.rtx.com/global/en/raytheon-state-college,-pa-location
• We Are RTX

#LI-Onsite

#LI-HS30

The salary range for this role is 66,000 USD - 130,000 USD. The salary range provided is a good faith estimate representative of all experience levels. RTX considers several factors when extending an offer, including but not limited to, the role, function and associated responsibilities, a candidate's work experience, location, education/training, and key skills.

Hired applicants may be eligible for benefits, including but not limited to, medical, dental, vision, life insurance, short-term disability, long-term disability, 401(k) match, flexible spending accounts, flexible work schedules, employee assistance program, Employee Scholar Program, parental leave, paid time off, and holidays. Specific benefits are dependent upon the specific business unit as well as whether or not the position is covered by a collective-bargaining agreement.

Hired applicants may be eligible for annual short-term and/or long-term incentive compensation programs depending on the level of the position and whether or not it is covered by a collective-bargaining agreement. Payments under these annual programs are not guaranteed and are dependent upon a variety of factors including, but not limited to, individual performance, business unit performance, and/or the company's performance.

This role is a U.S.-based role. If the successful candidate resides in a U.S. territory, the appropriate pay structure and benefits will apply.

RTX anticipates the application window closing approximately 40 days from the date the notice was posted. However, factors such as candidate flow and business necessity may require RTX to shorten or extend the application window.

RTX is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or veteran status, or any other applicable state or federal protected class. RTX provides affirmative action in employment for qualified Individuals with a Disability and Protected Veterans in compliance with Section 503 of the Rehabilitation Act and the Vietnam Era Veterans' Readjustment Assistance Act.

Privacy Policy and Terms:

Click on this link to read the Policy and Terms",2025-07-21T00:00:00.000Z,2025-07-25,"['Active and transferable U.S. government issued security clearance is required prior to start date', 'U.S. citizenship is required, as only U.S. citizens are eligible for a security clearance', 'TS/SCI without Polygraph', 'Active and transferable U.S. government issued TS/SCI security clearance is required prior to start date', 'U.S. citizenship is required, as only U.S. citizens are eligible for a security clearance', 'Typically requires a degree in Science, Technology, Engineering or Mathematics (STEM) and two (2) years of Software Engineering experience', 'Experience in object-oriented software design and development using Java or Python in a Linux environment', 'Experience with unit testing tools (e.g., JUnit)', 'Experience in Machine Learning and Data Science', 'Experience working with large datasets and performing data analysis', 'Qualifications We Prefer', 'Strong analytical skills and proactive problem-solving abilities, with a deep understanding of AI/ML technologies, cloud architecture, and enterprise software', 'Security+ certification', 'Experience with Git, Jenkins, Docker, Kubernetes', 'Experience with the Atlassian Tool Suite (e.g', 'JIRA, Confluence, BitBucket)', 'Experience with cloud computing platform (e.g', 'AWS or Azure)', 'Familiarity with secure coding practices, especially in a defense or aerospace setting']","['Design, develop, and maintain advanced software applications for our Satellite Ground Systems', 'Collaborate closely with systems engineers, hardware designers, and other software engineers to deliver reliable and high-performance software solutions', 'Design, implement, and test AI, ML, Java and Python based applications and software components for satellite ground systems', 'Work in parallel with legacy platform teams to eventually migrate workloads onto your pipelines', 'Collaborate with cross-functional teams to define software requirements and specifications', 'Work with previously written code and make modifications as necessary', 'Ensure software performance, reliability, and scalability', 'Participate in software design reviews, code reviews, and system integration activities', 'Contribute to the completion of program and project milestones under the specific guidance of their immediate supervisor', 'Follow established Software processes and procedures, development, documentation and maintenance/management of operations concepts, requirements (system, element, segment level), external and internal interfaces, and other software engineering work products/artifacts', 'Onsite: Employees who are working in Onsite roles will work primarily onsite', 'This includes all production and maintenance employees, as they are essential to the development of our products', 'This position requires a security clearance']",True,[],,"['Machine Learning', 'Data Science', 'Python', 'Java', 'Linux', 'Unit Testing', 'Data Analysis', 'Cloud Computing Platforms', 'DevOps Tools', 'Agile Methodology', 'Software Engineering']","Machine Learning: The role involves designing, implementing, and testing machine learning applications for satellite ground systems.; Data Science: Experience in data science is required, including working with large datasets and performing data analysis.; Python: Python is used for software development and implementing ML and data science applications in a Linux environment.; Java: Java is used for object-oriented software design and development in the satellite ground systems software.; Linux: The software development environment is Linux-based, supporting the deployment and testing of applications.; Unit Testing: Unit testing tools like JUnit are used to ensure software quality and reliability.; Data Analysis: Performing data analysis on large datasets is part of the responsibilities to support ML and software solutions.; Cloud Computing Platforms: Experience with cloud platforms such as AWS or Azure is preferred for scalable and enterprise software solutions.; DevOps Tools: Tools like Git, Jenkins, Docker, and Kubernetes are used to support software development, deployment, and pipeline management.; Agile Methodology: The development process follows Agile practices to enable iterative and collaborative software delivery.; Software Engineering: The role requires software engineering skills to design, develop, and maintain advanced applications for satellite systems."
JOSWFIuClsstn5gSAAAAAA==,Data Scientist - TS/SCI with Polygraph,"A career as a Data Scientist at GDIT means being a critical part of successful data outcomes. Here, your work can accelerate solutions for our clients while you accelerate your career. Own the opportunity to build your skills as you provide our clients with the data they need to turn insights and ideas into action.

At GDIT, people are our differentiator. As a Data Scientist supporting our client in Reston, you will help ensure today is safe and tomorrow is smarter. Our work depends on Data Scientist joining our team.

WHAT YOU’LL NEED TO SUCCEED:
• Education: Bachelor’s degree in Computer Science, Engineering, or a related technical discipline, or the equivalent combination of education, technical certifications or training, or work experience.
• Experience: 20+ years
• Technical skills:
• Demonstrated experience in software development using JAVA and python languages.
• Demonstrated experience in DevSecOps activities for large environments.
• Demonstrated experience in identifying and documenting technical risks.
• Demonstrated experience in managing large operational environment account management.
• Demonstrated experience using JIRA, Confluence, and GIT as part of an agile development environment.
• Demonstrated experience working with container orchestration technologies such as Kubernetes.
• Demonstrated experience and understanding of IT Service Management and common SLA measurements.
• Demonstrated experience performing security administration activities such as LDAP.
• Demonstrated experience creating and maintaining operating processes and procedures.
• Demonstrated experience resolving routine to highly complex inquiries.
• Demonstrated expertise with MS Outlook, Office, and working knowledge of standard operating tools and applications.
• Demonstrated experience providing high level customer service supporting users, managers, and staff.
• Demonstrated experience communicating complex technical material and translating into non-technical terms for broad audience
• Security clearance level: TS/SCI with Polygraph
• Desired skills and experience:
• Demonstrated knowledge of help desk processes and procedures.
• Demonstrated knowledge of tracking tools and governance processes.
• Demonstrated expertise in analytic and critical thinking.
• Demonstrated expertise in managing difficult situations with diplomacy, patience, and flexibility.
• Certifications such as:
• Certified Kubernetes Application Developer
• Microsoft Certified Solutions Developer
• AWS Certified Solutions Architect
• AWS Machine Learning Certification(s)
• Agile certification
• Security+
• GIAC Security Essentials Certification (GSEC)
• Location: Reston, VA (On Customer Site)
• US Citizenship required

GDIT IS YOUR PLACE:
• 401K with company match
• Comprehensive health and wellness packages
• Internal mobility team dedicated to helping you own your career
• Professional growth opportunities including paid education and certifications
• Cutting-edge technology you can learn from
• Rest and recharge with paid vacation and holidays

#OpportunityOwned
#GDITCareers
#WeAreGDIT
#JET
#GDITEnhanced2025",2025-07-23T00:00:00.000Z,2025-07-25,"['Education: Bachelor’s degree in Computer Science, Engineering, or a related technical discipline, or the equivalent combination of education, technical certifications or training, or work experience', 'Experience: 20+ years', 'Demonstrated experience in software development using JAVA and python languages', 'Demonstrated experience in DevSecOps activities for large environments', 'Demonstrated experience in identifying and documenting technical risks', 'Demonstrated experience in managing large operational environment account management', 'Demonstrated experience using JIRA, Confluence, and GIT as part of an agile development environment', 'Demonstrated experience working with container orchestration technologies such as Kubernetes', 'Demonstrated experience and understanding of IT Service Management and common SLA measurements', 'Demonstrated experience performing security administration activities such as LDAP', 'Demonstrated experience creating and maintaining operating processes and procedures', 'Demonstrated experience resolving routine to highly complex inquiries', 'Demonstrated expertise with MS Outlook, Office, and working knowledge of standard operating tools and applications', 'Demonstrated experience providing high level customer service supporting users, managers, and staff', 'Demonstrated experience communicating complex technical material and translating into non-technical terms for broad audience', 'Security clearance level: TS/SCI with Polygraph', 'Demonstrated knowledge of help desk processes and procedures', 'Demonstrated knowledge of tracking tools and governance processes', 'Demonstrated expertise in analytic and critical thinking', 'Demonstrated expertise in managing difficult situations with diplomacy, patience, and flexibility', 'Certifications such as:', 'Certified Kubernetes Application Developer', 'Microsoft Certified Solutions Developer', 'AWS Certified Solutions Architect', 'AWS Machine Learning Certification(s)', 'Agile certification', 'Security+', 'GIAC Security Essentials Certification (GSEC)', 'Location: Reston, VA (On Customer Site)', 'US Citizenship required']",,False,[],,"['Python', 'Java', 'DevSecOps', 'JIRA', 'Confluence', 'Git', 'Kubernetes', 'IT Service Management', 'LDAP', 'AWS Machine Learning Certification', 'Agile Methodology']",Python: Used as a programming language for software development and data-related tasks in the role.; Java: Used as a programming language for software development supporting data science activities.; DevSecOps: Applied to manage secure and efficient software development and deployment pipelines in large environments.; JIRA: Utilized as a project tracking and issue management tool within an agile development environment.; Confluence: Used for documentation and collaboration in agile software development processes.; Git: Version control system employed for managing code repositories in software and data projects.; Kubernetes: Container orchestration technology used to deploy and manage applications in scalable environments.; IT Service Management: Framework for managing IT services and ensuring SLA compliance relevant to operational data environments.; LDAP: Security administration protocol used for managing user access and authentication.; AWS Machine Learning Certification: Indicates knowledge of AWS machine learning services and tools relevant to building predictive models.; Agile Methodology: Applied for iterative and collaborative software and data project development.
HWijnsTESQt6covJAAAAAA==,Experienced Data Scientist - Fully Cleared,"Make an Impact Where It Matters Most

At Intelliforce, we’re redefining the boundaries of data-driven intelligence by building tools that empower mission partners to act with clarity and speed. As a Data Scientist specializing in graph analytics, you’ll be part of a transformative effort to revolutionize how analysts visualize, explore, and understand complex relationships in real-time mission data. Your work will directly influence how raw data becomes actionable intelligence—supporting the most critical national security operations.

Here’s What Your Day-to-Day Might Include
• Designing and optimizing graph data structures that adapt to dynamic mission needs
• Crafting scalable and performant queries for graph databases, with a focus on Neo4j and Cypher
• Writing and maintaining Python-based data parsers to support ingestion and streaming workflows
• Validating large datasets to ensure integrity, accuracy, and performance under operational constraints
• Translating analyst needs into graph-based technical solutions, collaborating closely with mission users
• Working with developers to integrate queries and ingestion logic into production systems
• Documenting data models, schemas, and pipelines using tools like Confluence
• Engaging directly with end users and mission stakeholders to understand pain points and recommend solutions

Minimum Qualifications
• Clearance: TS/SCI with Full Scope Polygraph
• Citizenship: U.S. Citizen
• Education & Experience:
• Bachelor’s degree in a technical field + 8 years of relevant experience
• OR 12 years of relevant experience in lieu of a degree

Required Skills
• Familiarity with graph databases (e.g., Neo4j) and an interest in mastering Cypher
• Strong Python development skills, particularly for parser creation and data manipulation
• Ability to analyze, model, and manipulate complex data structures
• Experience collaborating with both technical and non-technical stakeholders
• Solid communication skills and a user-focused mindset

Desired Qualifications
• Hands-on experience with Neo4j and the Cypher query language
• Understanding of graph theory and graph-specific algorithms
• Background in real-time data processing, ETL pipelines, or streaming architectures
• Familiarity with TCP/IP networking concepts
• Exposure to containerization tools like Docker and Kubernetes
• Experience working within SIGINT, cyber, or other mission-focused data environments

Compensation Range: $138,000.00 - $182,000.00
• The salary range provided reflects an estimate based on current market trends and may be adjusted based on factors such as the candidate's experience, skills, and qualifications. The final offer will be tailored after a thorough evaluation of the candidate’s background and suitability for the role. Please note that this range is intended as a guideline and is subject to flexibility

Why Intelliforce? Because you matter—your work, your growth, and your well-being.

At Intelliforce, we don’t just push the boundaries of technology—we partner with some of the most mission-driven teams in defense and beyond to solve challenges that truly matter. As a Systems Engineer here, you won’t just contribute to projects—you’ll help shape outcomes that make a real-world impact.

We also know that great work starts with a great environment. That’s why we invest in you:
• Ample PTO to rest and recharge—plus all federal holidays and your birthday off, just because.
• Multiple medical plan options, including ones with zero deductible or premium for employees.
• Generous 401(k) with immediate vesting—because your future matters now.
• Exciting bonus opportunities, from profit sharing to quarterly awards and President’s Club recognition.
• A culture of collaboration, connection, and fun, with regular team activities that go beyond the work.

Ready to grow with purpose?

At Intelliforce, your career will flourish in a place where innovation thrives and people come first. Join us—and let’s build something meaningful together. You can reach us at careers@intelliforce-itsg.com or schedule a call with our Director of Recruitment, just visit this link to view their calendar: https://calendly.com/amwolfe-intelliforce-itsg/30min .

Equal Opportunity Matters

Intelliforce-IT Solutions Group, LLC is proud to be an Equal Opportunity/Affirmative Action Employer. U.S. Citizenship is required for most positions.

Need accommodations during the application process? We’re happy to help. Reach out to us at Recruiting@intelliforce-itsg.com with your specific request.

Powered by JazzHR

nqqsNiJzj6",2025-07-23T00:00:00.000Z,2025-07-25,"['Clearance: TS/SCI with Full Scope Polygraph', 'Citizenship: U.S. Citizen', 'Bachelor’s degree in a technical field + 8 years of relevant experience', 'OR 12 years of relevant experience in lieu of a degree', 'Familiarity with graph databases (e.g., Neo4j) and an interest in mastering Cypher', 'Strong Python development skills, particularly for parser creation and data manipulation', 'Ability to analyze, model, and manipulate complex data structures', 'Experience collaborating with both technical and non-technical stakeholders', 'Solid communication skills and a user-focused mindset', 'U.S. Citizenship is required for most positions']","['As a Data Scientist specializing in graph analytics, you’ll be part of a transformative effort to revolutionize how analysts visualize, explore, and understand complex relationships in real-time mission data', 'Your work will directly influence how raw data becomes actionable intelligence—supporting the most critical national security operations', 'Designing and optimizing graph data structures that adapt to dynamic mission needs', 'Crafting scalable and performant queries for graph databases, with a focus on Neo4j and Cypher', 'Writing and maintaining Python-based data parsers to support ingestion and streaming workflows', 'Validating large datasets to ensure integrity, accuracy, and performance under operational constraints', 'Translating analyst needs into graph-based technical solutions, collaborating closely with mission users', 'Working with developers to integrate queries and ingestion logic into production systems', 'Documenting data models, schemas, and pipelines using tools like Confluence', 'Engaging directly with end users and mission stakeholders to understand pain points and recommend solutions']",True,[],,"['Graph Analytics', 'Graph Databases', 'Cypher Query Language', 'Python Data Parsers', 'Data Validation', 'Data Modeling', 'Data Pipelines', 'ETL Pipelines', 'Confluence']","Graph Analytics: Used to analyze and understand complex relationships in mission data to support actionable intelligence.; Graph Databases: Employing Neo4j to store and query graph-structured data for mission-critical applications.; Cypher Query Language: Used to craft scalable and performant queries for graph databases like Neo4j.; Python Data Parsers: Developed to support data ingestion and streaming workflows for real-time data processing.; Data Validation: Ensuring integrity, accuracy, and performance of large datasets under operational constraints.; Data Modeling: Designing and optimizing graph data structures and schemas to meet dynamic mission needs.; Data Pipelines: Building and maintaining ingestion and streaming workflows to process mission data efficiently.; ETL Pipelines: Experience with real-time data processing and extraction, transformation, and loading workflows.; Confluence: Used for documenting data models, schemas, and pipelines to support collaboration and knowledge sharing."
nY38LhTzSZJlXiKJAAAAAA==,"Principal Associate, Data Scientist - Data Scientist - Application Fraud Team","Principal Associate, Data Scientist - Data Scientist - Application Fraud Team

Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making.

As a Data Scientist at Capital One, you’ll be part of a team that’s leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives.

Team Description:

The Application Fraud data science team builds the machine learning models that help protect our customers and Capital One against fraudsters. We prevent fraud at the application stage using real-time models. We care deeply about doing things the right way, automating, and innovating to improve the customer experience and prevent fraud.

Role Description

In this role, you will:
• Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love
• Leverage a broad stack of technologies — Python, Conda, AWS, H2O, Spark, and more — to reveal the insights hidden within huge volumes of numeric and textual data
• Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation
• Flex your interpersonal skills to translate the complexity of your work into tangible business goals

The Ideal Candidate is:
• Customer first. You love the process of analyzing and creating, but also share our passion to do the right thing. You know at the end of the day it’s about making the right decision for our customers.
• Innovative. You continually research and evaluate emerging technologies. You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them.
• Creative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You’re not afraid to share a new idea.
• A leader. You challenge conventional thinking and work with stakeholders to identify and improve the status quo. You're passionate about talent development for your own team and beyond.
• Technical. You’re comfortable with open-source languages and are passionate about developing further. You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms.
• Statistically-minded. You’ve built models, validated them, and backtested them. You know how to interpret a confusion matrix or a ROC curve. You have experience with clustering, classification, sentiment analysis, time series, and deep learning.
• A data guru. “Big data” doesn’t faze you. You have the skills to retrieve, combine, and analyze data from a variety of sources and structures. You know understanding the data is often the key to great data science.

Basic Qualifications:
• Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:
• A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 5 years of experience performing data analytics
• A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 3 years of experience performing data analytics
• A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field)

Preferred Qualifications:
• Master’s Degree in “STEM” field (Science, Technology, Engineering, or Mathematics) plus 3 years of experience in data analytics, or PhD in “STEM” field (Science, Technology, Engineering, or Mathematics)
• At least 1 year of experience working with AWS
• At least 3 years’ experience in Python, Scala, or R
• At least 3 years’ experience with machine learning
• At least 3 years’ experience with SQL

Capital One will consider sponsoring a new qualified applicant for employment authorization for this position.

The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.

Chicago, IL: $144,200 - $164,600 for Princ Associate, Data Science

McLean, VA: $158,600 - $181,000 for Princ Associate, Data Science

New York, NY: $173,000 - $197,400 for Princ Associate, Data Science

Richmond, VA: $144,200 - $164,600 for Princ Associate, Data Science

Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate’s offer letter.

This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.

Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.

This role is expected to accept applications for a minimum of 5 business days.

No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",,2025-07-25,"['Customer first', 'You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them', 'You thrive on bringing definition to big, undefined problems', 'You love asking questions and pushing hard to find answers', ""You're passionate about talent development for your own team and beyond"", 'Technical', 'You’re comfortable with open-source languages and are passionate about developing further', 'You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms', 'Statistically-minded', 'You know how to interpret a confusion matrix or a ROC curve', 'You have experience with clustering, classification, sentiment analysis, time series, and deep learning', 'A data guru', 'You have the skills to retrieve, combine, and analyze data from a variety of sources and structures', 'You know understanding the data is often the key to great data science', 'Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:', ""A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 5 years of experience performing data analytics"", ""A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 3 years of experience performing data analytics"", 'A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field)']","['Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love', 'Leverage a broad stack of technologies — Python, Conda, AWS, H2O, Spark, and more — to reveal the insights hidden within huge volumes of numeric and textual data', 'Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation', 'Flex your interpersonal skills to translate the complexity of your work into tangible business goals', 'You continually research and evaluate emerging technologies', 'You challenge conventional thinking and work with stakeholders to identify and improve the status quo', 'You’ve built models, validated them, and backtested them']",True,[],,"['Statistical Modeling', 'Relational Databases', 'Machine Learning', 'Python', 'Conda', 'AWS', 'H2O', 'Spark', 'Model Development Lifecycle', 'Clustering', 'Classification', 'Sentiment Analysis', 'Time Series Analysis', 'Deep Learning', 'Confusion Matrix and ROC Curve Interpretation', 'SQL']","Statistical Modeling: Used to personalize credit card offers and analyze application fraud data.; Relational Databases: Employed to manage and query structured data relevant to fraud detection.; Machine Learning: Applied to build models that detect and prevent application fraud in real-time.; Python: Primary programming language used for data analysis and model development.; Conda: Used as an environment and package management system for data science workflows.; AWS: Cloud platform leveraged for scalable data storage, processing, and model deployment.; H2O: Machine learning platform used to build and deploy predictive models.; Spark: Big data processing framework used to handle large volumes of numeric and textual data.; Model Development Lifecycle: Involves design, training, evaluation, validation, and implementation of machine learning models.; Clustering: Used as an unsupervised learning technique to identify patterns in fraud data.; Classification: Applied to categorize transactions or applications as fraudulent or legitimate.; Sentiment Analysis: Used to analyze textual data possibly related to customer feedback or fraud indicators.; Time Series Analysis: Employed to analyze data trends over time for fraud detection.; Deep Learning: Utilized for advanced modeling techniques to improve fraud detection accuracy.; Confusion Matrix and ROC Curve Interpretation: Used to evaluate the performance of classification models in fraud detection.; SQL: Used to retrieve and manipulate data from relational databases."
GpF-f0pzvTLkJcBFAAAAAA==,Principal Data Scientist*,"Description

Leidos has a new and exciting opportunity for a Data Scientist in our National Security Sector's (NSS) Cyber & Analytics Business Area (CABA). Our talented team is at the forefront in Security Engineering, Computer Network Operations (CNO), Mission Software, Analytical Methods and Modeling, Signals Intelligence (SIGINT), and Cryptographic Key Management. At Leidos, we offer competitive benefits, including Paid Time Off, 11 paid Holidays, 401K with a 6% company match and immediate vesting, Flexible Schedules, Discounted Stock Purchase Plans, Technical Upskilling, Education and Training Support, Parental Paid Leave, and much more. Join us and make a difference in National Security!

Job Description

Design and develop methods, processes, and systems to extract raw data from Splunk and create reports and dashboards for data usage auditing. This role is primarily focused on Splunk SPL queries, reports, and dashboards with the need for additional processing and augmentation in Python. Strong interpersonal skills are needed as this role is customer facing.

Primary Responsibilities
• Create innovative solutions to meet the technical needs of customers.
• Work with data science teammates and the customer to create or refine recurring reports and ad-hoc reports.
• Development documentation.
• Conduct experimentation in various data science techniques, as well as developing, executing, and maintaining scripts and prototypes to analyze, interpret, visualize, and gain knowledge from numerous data sets individually or in combination to meet customer requirements.
• Proactively coordinate with customers, Scrum PMs, and cross-functional areas to communicate project statuses and initiatives.
• Analyze data to effectively coordinate, innovate, and implement process improvements to include current and new Splunk and Python reports and scripts.
• Communicate key project data to teammates to foster team cohesion and effectiveness and apply best practices and standard operating procedures.

Basic Qualifications
• 7+ years of expert knowledge in Splunk SPL and Splunk Enterprise systems.
• 5+ years of experience with Python, R, VBA or another object-oriented programming language.
• Experience using the statistical computer language Python to manipulate data and draw insights from large data sets.
• Extensive knowledge in one or more data science libraries, such as NumPy, Pandas, OpenPyXL, etc.
• Experience negotiating solutions to complex technical challenges and developing courses of action to resolve those challenges with predictable outcomes.
• Experience leading high-visibility projects that have organization-wide impact.
• Experience working collaboratively with developers and other data scientists.
• Must possess a Bachelor’s degree with 12+ years of relevant experience or a Master’s degree with 6+ years of relevant experience.
• Must have a TS/SCI with polygraph.

Preferred Qualifications
• 2+ years of experience with Visual Basic for Applications
• 5+ years of experience with SQL queries
• 5+ years of experience with MS Access
• Experience with MySQL
• Experience with SharePoint on-prem
• Experience with PowerShell
• Experience with Tableau

At Leidos, the opportunities are boundless. We challenge our staff with interesting assignments that allow them to thrive professionally and personally. For us, helping you grow your career is good business. We look forward to learning more about you – apply today.

CABARESTON

Original Posting:
May 27, 2025

For U.S. Positions: While subject to change based on business needs, Leidos reasonably anticipates that this job requisition will remain open for at least 3 days with an anticipated close date of no earlier than 3 days after the original posting date as listed above.

Pay Range:
Pay Range $126,100.00 - $227,950.00

The Leidos pay range for this job level is a general guideline only and not a guarantee of compensation or salary. Additional factors considered in extending an offer include (but are not limited to) responsibilities of the job, education, experience, knowledge, skills, and abilities, as well as internal equity, alignment with market data, applicable bargaining agreement (if any), or other law.",,2025-07-25,"['7+ years of expert knowledge in Splunk SPL and Splunk Enterprise systems', '5+ years of experience with Python, R, VBA or another object-oriented programming language', 'Experience using the statistical computer language Python to manipulate data and draw insights from large data sets', 'Extensive knowledge in one or more data science libraries, such as NumPy, Pandas, OpenPyXL, etc', 'Experience negotiating solutions to complex technical challenges and developing courses of action to resolve those challenges with predictable outcomes', 'Experience leading high-visibility projects that have organization-wide impact', 'Experience working collaboratively with developers and other data scientists', 'Must possess a Bachelor’s degree with 12+ years of relevant experience or a Master’s degree with 6+ years of relevant experience', 'Must have a TS/SCI with polygraph']","['Design and develop methods, processes, and systems to extract raw data from Splunk and create reports and dashboards for data usage auditing', 'This role is primarily focused on Splunk SPL queries, reports, and dashboards with the need for additional processing and augmentation in Python', 'Strong interpersonal skills are needed as this role is customer facing', 'Create innovative solutions to meet the technical needs of customers', 'Work with data science teammates and the customer to create or refine recurring reports and ad-hoc reports', 'Development documentation', 'Conduct experimentation in various data science techniques, as well as developing, executing, and maintaining scripts and prototypes to analyze, interpret, visualize, and gain knowledge from numerous data sets individually or in combination to meet customer requirements', 'Proactively coordinate with customers, Scrum PMs, and cross-functional areas to communicate project statuses and initiatives', 'Analyze data to effectively coordinate, innovate, and implement process improvements to include current and new Splunk and Python reports and scripts', 'Communicate key project data to teammates to foster team cohesion and effectiveness and apply best practices and standard operating procedures']",True,[],,"['Splunk SPL', 'Python', 'NumPy', 'Pandas', 'OpenPyXL', 'SQL', 'MySQL', 'MS Access', 'Tableau', 'VBA', 'PowerShell', 'Data Reporting and Dashboards', 'Data Experimentation and Prototyping']","Splunk SPL: Used for querying and extracting raw data from Splunk to create reports and dashboards for data usage auditing.; Python: Applied for additional data processing, augmentation, scripting, and prototyping to analyze and visualize data sets.; NumPy: A data science library used for numerical computations and data manipulation within Python scripts.; Pandas: Used for data manipulation and analysis to gain insights from large data sets.; OpenPyXL: Utilized for handling Excel files as part of data processing and reporting tasks.; SQL: Used for querying relational databases such as MySQL and MS Access to support data extraction and reporting.; MySQL: A relational database system used for managing and querying structured data.; MS Access: Used as a database tool for managing and querying data to support reporting and analysis.; Tableau: A BI tool employed to create dashboards and visualizations for data reporting.; VBA: Used for automating tasks and scripting within Microsoft Office applications to support data processing.; PowerShell: Utilized for scripting and automation to support data workflows and system integration.; Data Reporting and Dashboards: Creation and refinement of recurring and ad-hoc reports and dashboards to communicate data insights.; Data Experimentation and Prototyping: Conducting experiments with various data science techniques and developing prototypes to analyze and interpret data."
9jT5m8Bkw1Y_0r9gAAAAAA==,DS2 Data Scientist (Full-time & USD salary),", a US company headquartered in Los Angeles, is looking for remote Data Scientists to join and help work on machine learning problems (in the field of NLP) for unstructured data, large enterprise users, and to improve the suite of products that we offer. The ideal candidate should be helpful, responsive, dependable, and comfortable working remotely within a small team with tight deadlines. We value people who thrive working collaboratively in a distributed team and who are enthusiastic about the potential of machine learning.

Your primary responsibility is to independently identify and deliver business insights from very diverse data types and sources. Deliver production-ready code, CSVs, and compelling narrative visualizations.

Salary: $30,000 to $45,000 (in USD) depending on experience

Timezone: PST
Responsibilities
• Own and deliver projects starting with very diverse data and business targets
• Contribute to general features for the internal product library while delivering for specific clients
• Own report delivery for clients, and contribute to library documentation
• Explore and present datasets and narrative visualizations
• Build linguistic and statistical general models
• Translate business problems into specifications for computational tasks like classification or ranking

Requirements
• 2+ years writing queries in SQL or running models in Python/Jupyter
• 2+ years doing statistical analysis
• Write and speak clearly, communicate em-pathetically
• Highest standard of excellence for your work
• Impeccable attention to detail: spotting typos in variables, syntax errors in text and gremlins in data
• Ability to define evidence-based, quantifiable solutions to open-ended business problems
Bonus Points
• Familiar with a range of NLP techniques or computational linguistics
• Fluent data storyteller
• Github: pull, push, merge, PR, cherry-picking, issue tracking
• Regular Expressions
• PostgreSQL 12+
• An example where we can see your writing style (in English), ideally data-related

Benefits
• Paid Time Off
• Work From Home
• Training & Development
We are…

IV.AI is the world's leading language processing AI platform. We have grown fast, but aim to retain our scrappy nature that enabled us to build big AI models that outperform the industry standards. There are many companies right now that talk about the potential impact of AI while we hustle hard and have actually proven the benefits repeatedly.
Helpful

We help people become smarter by using AI or data generated by AI models - the increased human intelligence is driven via a polished AI product that makes sense of noisy social media data, documents, web data, podcasts, internal or external communications. IV.AI takes problems that were previously too complex to manage because of the scope of the research and tracking needed to solve them and makes them easy to solve via high-quality data, easy to use tools and experienced, helpful teams.
Inclusive

Our inclusive culture values people regardless of their background, education or upbringing. In order to train machines to act appropriately, we need builders and contributors who are representative of the entire population. AI is only as good as the teams working on it and the training they receive. AI is incredibly powerful and human bias in the training process can be equally harmful to the world if the technology is not being managed by teams of people who are diverse and considerate.
Hardworking

In just 5 years IV.AI has built a scalable platform with 100s of AI solutions for Fortune 500 companies including Sony, Walmart, Toyota, Netflix, Time Warner, Fox, Capital One, Estée Lauder, to name a few.
Professional

Being professional and respectful of clients and coworkers is of the utmost importance. We work with blue-chip clients and with very sensitive data that requires care and diligence via our focussed security systems and protocols.
Collaborative

Our employees are constantly problem-solving and assessing their own output to maximise delivery. It’s important that our team is always looking for the best way of addressing problems so we can manage customer expectations.

, a US company headquartered in Los Angeles, is looking for remote Data Scientists to join and help work on machine learning problems (in the field of NLP) for unstructured data, large enterprise users, and to improve the suite of products that we offer. The ideal candidate should be helpful, responsive, dependable, and comfortable working remotely within a small team with tight deadlines. We value people who thrive working collaboratively in a distributed team and who are enthusiastic about the potential of machine learning.

Your primary responsibility is to independently identify and deliver business insights from very diverse data types and sources. Deliver production-ready code, CSVs, and compelling narrative visualizations.

Salary: $30,000 to $45,000 (in USD) depending on experience

Timezone: PST
Responsibilities
• Own and deliver projects starting with very diverse data and business targets
• Contribute to general features for the internal product library while delivering for specific clients
• Own report delivery for clients, and contribute to library documentation
• Explore and present datasets and narrative visualizations
• Build linguistic and statistical general models
• Translate business problems into specifications for computational tasks like classification or ranking

Requirements
• 2+ years writing queries in SQL or running models in Python/Jupyter
• 2+ years doing statistical analysis
• Write and speak clearly, communicate em-pathetically
• Highest standard of excellence for your work
• Impeccable attention to detail: spotting typos in variables, syntax errors in text and gremlins in data
• Ability to define evidence-based, quantifiable solutions to open-ended business problems
Bonus Points
• Familiar with a range of NLP techniques or computational linguistics
• Fluent data storyteller
• Github: pull, push, merge, PR, cherry-picking, issue tracking
• Regular Expressions
• PostgreSQL 12+
• An example where we can see your writing style (in English), ideally data-related

Benefits
• Paid Time Off
• Work From Home
• Training & Development
We are…

IV.AI is the world's leading language processing AI platform. We have grown fast, but aim to retain our scrappy nature that enabled us to build big AI models that outperform the industry standards. There are many companies right now that talk about the potential impact of AI while we hustle hard and have actually proven the benefits repeatedly.
Helpful

We help people become smarter by using AI or data generated by AI models - the increased human intelligence is driven via a polished AI product that makes sense of noisy social media data, documents, web data, podcasts, internal or external communications. IV.AI takes problems that were previously too complex to manage because of the scope of the research and tracking needed to solve them and makes them easy to solve via high-quality data, easy to use tools and experienced, helpful teams.
Inclusive

Our inclusive culture values people regardless of their background, education or upbringing. In order to train machines to act appropriately, we need builders and contributors who are representative of the entire population. AI is only as good as the teams working on it and the training they receive. AI is incredibly powerful and human bias in the training process can be equally harmful to the world if the technology is not being managed by teams of people who are diverse and considerate.
Hardworking

In just 5 years IV.AI has built a scalable platform with 100s of AI solutions for Fortune 500 companies including Sony, Walmart, Toyota, Netflix, Time Warner, Fox, Capital One, Estée Lauder, to name a few.
Professional

Being professional and respectful of clients and coworkers is of the utmost importance. We work with blue-chip clients and with very sensitive data that requires care and diligence via our focussed security systems and protocols.
Collaborative

Our employees are constantly problem-solving and assessing their own output to maximise delivery. It’s important that our team is always looking for the best way of addressing problems so we can manage customer expectations.",2025-07-25T14:00:00.000Z,2025-07-25,"['The ideal candidate should be helpful, responsive, dependable, and comfortable working remotely within a small team with tight deadlines', 'We value people who thrive working collaboratively in a distributed team and who are enthusiastic about the potential of machine learning', '2+ years writing queries in SQL or running models in Python/Jupyter', '2+ years doing statistical analysis', 'Write and speak clearly, communicate em-pathetically', 'Highest standard of excellence for your work', 'Impeccable attention to detail: spotting typos in variables, syntax errors in text and gremlins in data', 'Ability to define evidence-based, quantifiable solutions to open-ended business problems', 'Familiar with a range of NLP techniques or computational linguistics', 'Fluent data storyteller', 'Github: pull, push, merge, PR, cherry-picking, issue tracking', 'Regular Expressions', 'PostgreSQL 12+', 'An example where we can see your writing style (in English), ideally data-related', 'Being professional and respectful of clients and coworkers is of the utmost importance', 'The ideal candidate should be helpful, responsive, dependable, and comfortable working remotely within a small team with tight deadlines', 'We value people who thrive working collaboratively in a distributed team and who are enthusiastic about the potential of machine learning', '2+ years writing queries in SQL or running models in Python/Jupyter', '2+ years doing statistical analysis', 'Write and speak clearly, communicate em-pathetically', 'Highest standard of excellence for your work', 'Impeccable attention to detail: spotting typos in variables, syntax errors in text and gremlins in data', 'Ability to define evidence-based, quantifiable solutions to open-ended business problems', 'Familiar with a range of NLP techniques or computational linguistics', 'Fluent data storyteller', 'Github: pull, push, merge, PR, cherry-picking, issue tracking', 'Regular Expressions', 'PostgreSQL 12+', 'An example where we can see your writing style (in English), ideally data-related', 'Being professional and respectful of clients and coworkers is of the utmost importance']","['Your primary responsibility is to independently identify and deliver business insights from very diverse data types and sources', 'Deliver production-ready code, CSVs, and compelling narrative visualizations', 'Own and deliver projects starting with very diverse data and business targets', 'Contribute to general features for the internal product library while delivering for specific clients', 'Own report delivery for clients, and contribute to library documentation', 'Explore and present datasets and narrative visualizations', 'Build linguistic and statistical general models', 'Translate business problems into specifications for computational tasks like classification or ranking', 'We work with blue-chip clients and with very sensitive data that requires care and diligence via our focussed security systems and protocols', 'Your primary responsibility is to independently identify and deliver business insights from very diverse data types and sources', 'Deliver production-ready code, CSVs, and compelling narrative visualizations', 'Own and deliver projects starting with very diverse data and business targets', 'Contribute to general features for the internal product library while delivering for specific clients', 'Own report delivery for clients, and contribute to library documentation', 'Explore and present datasets and narrative visualizations', 'Build linguistic and statistical general models', 'Translate business problems into specifications for computational tasks like classification or ranking']",True,"['Machine Learning', 'Natural Language Processing with Machine Learning']",Machine Learning: Applied to solve NLP problems on unstructured data and improve product offerings.; Natural Language Processing with Machine Learning: Use of machine learning techniques specifically for processing and understanding unstructured text data.,"['SQL', 'Python', 'Statistical Analysis', 'Narrative Visualization', 'Classification', 'Ranking', 'Natural Language Processing', 'Regular Expressions', 'PostgreSQL', 'Data Storytelling']","SQL: Used for writing queries to extract and manipulate data from relational databases like PostgreSQL.; Python: Used for running statistical models and data analysis, often within Jupyter notebooks.; Statistical Analysis: Applied to analyze data and build general statistical models to derive business insights.; Narrative Visualization: Creating compelling visual presentations of data to communicate insights effectively to stakeholders.; Classification: A computational task to categorize data points, used here to translate business problems into predictive models.; Ranking: A computational task to order items based on relevance or score, applied to business problem specifications.; Natural Language Processing: Techniques applied to analyze unstructured text data and build linguistic models.; Regular Expressions: Used for pattern matching and text processing within data cleaning or feature extraction.; PostgreSQL: A relational database system used to store and query structured data.; Data Storytelling: The skill of communicating data insights clearly and empathetically to stakeholders."
Z0h5S9trofVXMJTUAAAAAA==,"Business Data Scientist, Sales Insights","The application window will be open until at least July 31, 2025. This opportunity will remain online based on business needs which may be before or after the specified date.

This role may also be located in our Playa Vista, CA campus.

Applicants in the County of Los Angeles: Qualified applications with arrest or conviction records will be considered for employment in accordance with the Los Angeles County Fair Chance Ordinance for Employers and the California Fair Chance Act.

Note: By applying to this position you will have an opportunity to share your preferred working location from the following: New York, NY, USA; Chicago, IL, USA; Mountain View, CA, USA; San Bruno, CA, USA; San Francisco, CA, USA; Sunnyvale, CA, USA; Boulder, CO, USA; Los Angeles, CA, USA; Atlanta, GA, USA.Minimum qualifications:
• Master's degree in a quantitative discipline such as Statistics, Engineering, Sciences, or equivalent practical experience.
• 4 years of experience using analytics to solve product or business problems, coding (e.g., Python, R, SQL), querying databases or statistical analysis.

Preferred qualifications:
• 6 years of experience using analytics to solve product or business problems, coding (e.g., Python, R, SQL), querying databases or statistical analysis.
• Experience with causal inference techniques, including incrementality measurement, observational studies, quasi-experimental designs (e.g., Difference-in-Differences).
• Experience with A/B testing design, implementation, and analysis.

About the jobGoogle's leadership team hand-picks thorny business challenges, and members of BizOps work in small teams to find solutions. As part of this team you fully immerse yourself in data collection, draw insight from analysis, and then zoom out to develop compelling, synthesized recommendations. Taking strategy one step further, you also persuasively communicate your recommendations to senior-level executives, roll-up your sleeves to help drive implementation and check back-in to see the impact of your recommendations.

As a Business Data Scientist on this team, you will be a builder who will be responsible for designing, developing, and implementing advanced models and in-depth analysis to solve business problems. You will leverage various datasets including business behavior, product journeys, business tooling and training interventions to uncover actionable insights. Your work will directly contribute to understanding the drivers of business outcomes, identifying opportunities to increase business and efficiency, and ultimately demonstrating the incremental value and Return on Investment (ROI) of various business and activation levers. You will collaborate closely with data engineers, other analysts, and business stakeholders, translating findings into clear, impactful recommendations.

The US base salary range for this full-time position is $166,000-$244,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.

Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google .

Responsibilities
• Design, build, validate, and deploy statistical techniques (e.g., predictive models, causal inference models, segmentation models) to address key business questions across business activities and activation insights.
• Conduct data analysis to identify operational insights, transforming raw data into clear, actionable business recommendations.
• Design, develop and launch reporting/dashboard solutions to enable stakeholder teams to independently and consistently track and manage key metrics.
• Act as a thought partner to business stakeholders, understanding their issues, translating business questions into well-defined problems, and communicating methodologies and findings clearly and concisely to non-technical audiences to deliver informed decision-making.

Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .",2025-07-25T10:00:00.000Z,2025-07-25,"[""Master's degree in a quantitative discipline such as Statistics, Engineering, Sciences, or equivalent practical experience"", '4 years of experience using analytics to solve product or business problems, coding (e.g., Python, R, SQL), querying databases or statistical analysis']","['As part of this team you fully immerse yourself in data collection, draw insight from analysis, and then zoom out to develop compelling, synthesized recommendations', 'Taking strategy one step further, you also persuasively communicate your recommendations to senior-level executives, roll-up your sleeves to help drive implementation and check back-in to see the impact of your recommendations', 'As a Business Data Scientist on this team, you will be a builder who will be responsible for designing, developing, and implementing advanced models and in-depth analysis to solve business problems', 'You will leverage various datasets including business behavior, product journeys, business tooling and training interventions to uncover actionable insights', 'Your work will directly contribute to understanding the drivers of business outcomes, identifying opportunities to increase business and efficiency, and ultimately demonstrating the incremental value and Return on Investment (ROI) of various business and activation levers', 'You will collaborate closely with data engineers, other analysts, and business stakeholders, translating findings into clear, impactful recommendations', 'Design, build, validate, and deploy statistical techniques (e.g., predictive models, causal inference models, segmentation models) to address key business questions across business activities and activation insights', 'Conduct data analysis to identify operational insights, transforming raw data into clear, actionable business recommendations', 'Design, develop and launch reporting/dashboard solutions to enable stakeholder teams to independently and consistently track and manage key metrics', 'Act as a thought partner to business stakeholders, understanding their issues, translating business questions into well-defined problems, and communicating methodologies and findings clearly and concisely to non-technical audiences to deliver informed decision-making']",True,[],,"['Python', 'R', 'SQL', 'Causal Inference', 'Difference-in-Differences', 'A/B Testing', 'Predictive Modeling', 'Segmentation Modeling', 'Statistical Analysis', 'Dashboard and Reporting Solutions']","Python: Used as a primary coding language for analytics and statistical analysis to solve business problems.; R: Utilized for statistical computing and data analysis to support business insights and modeling.; SQL: Employed for querying databases to extract and manipulate data necessary for analysis.; Causal Inference: Applied to measure incrementality and understand cause-effect relationships in business interventions.; Difference-in-Differences: A quasi-experimental design technique used to evaluate the impact of business changes over time.; A/B Testing: Designed, implemented, and analyzed to test business hypotheses and measure the effectiveness of changes.; Predictive Modeling: Developed and deployed to forecast business outcomes and support decision-making.; Segmentation Modeling: Used to categorize customers or business units to tailor strategies and improve targeting.; Statistical Analysis: Conducted to transform raw data into actionable insights for business recommendations.; Dashboard and Reporting Solutions: Designed and launched to enable stakeholders to track key metrics and monitor business performance."
MRajmPeaHnLmvVeKAAAAAA==,Data Scientist 5,"Job Description
As a Lead Data Scientist, you'll shape next-gen AI capabilities for Clinical Data Exchange (CDeX)-where payers and providers collaborate seamlessly. You'll build models that power prior authorization, risk adjustment, claims adjudication, and more-making data work smarter across the healthcare ecosystem. You'll also help reduce the administrative burden on clinicians, using AI to automate documentation, extract insights, and deliver real-time intelligence when it matters most. From classical ML to generative models, you'll lead with purpose designing scalable, responsible AI for real-world impact.
Responsibilities
growth and leadership. Responsibilities
- Partner with Product Managers to turn ambitious product visions
into AI-powered solutions that reshape healthcare operations and
experiences.
- Collaborate closely with Clinical Terminologists to ensure models are
clinically sound and aligned with evolving healthcare standards and
vocabularies.
- Work hand-in-hand with UI Engineers and ML Engineers to bring AI
models to life in intuitive, responsive, and scalable products.
- Lead the full lifecycle of AI development-from ideation and research
to deployment and monitoring.
- Apply the latest advancements in machine learning, deep learning,
and generative AI to deliver innovation at scale.
- Architect high-quality, production-ready AI pipelines, ensuring
robustness, accuracy, and compliance with healthcare regulations.
- Develop clean, scalable code and drive best practices across the AI
engineering stack.
- Mentor and inspire a team of data scientists, fostering technical
growth and leadership.
- Contribute to planning, reviews, and retrospectives-driving
continuous improvement and cross-team alignment.
Anticipate and navigate technical and organizational risks to ensure
project success and sustained impact.
Qualifications and Experience
- Proven experience architecting and deploying scalable AI solutions
in production, with measurable impact across complex, real-world
healthcare or enterprise systems.
- Deep technical fluency in machine learning and deep learning
architectures, including Transformers and other neural network
frameworks-plus the intuition to choose the right tool for the right
problem.
- Hands-on expertise in Large Language Models (LLMs) and
generative AI, with experience in advanced prompt engineering,
instruction fine-tuning, and parameter-efficient tuning techniques.
- Proficiency in Python is a must, with experience applying it to build
and deploy AI/ML models and develop robust, scalable solutions.
- Strong foundation in clinical data, with the ability to extract meaning
from structured and unstructured sources and align with
interoperability standards such as FHIR, C-CDA, or HL7.
- Experience building models that support healthcare-critical
processes like prior authorization, risk adjustment, clinical
summarization, or claims adjudication is a major advantage.
- Experience in building a wide range of AI models-including
classical ML models, semantic search, and information retrieval
systems-to power intelligent, high-precision workflows.
- Familiarity with AI evaluation strategies, including data labeling,
annotation workflows, human-in-the-loop review, and longitudinal
model monitoring in high-stakes environments.
- A natural drive to stay ahead of the curve, with the curiosity to
explore cutting-edge research and the discipline to translate it into
resilient, production-ready systems.
- A track record of technical leadership, including mentoring junior
and senior scientists, championing innovation, and cultivating an
environment of curiosity and excellence.
- Bonus: a strong portfolio of patents, publications, or open source
contributions, reflecting thought leadership and a commitment to
pushing the field forward.
Preferred Qualifications:
- Strong understanding of the healthcare ecosystem and proven
experience delivering AI-driven solutions tailored to healthcare
applications, transforming patient care and operational efficiency.
- Familiarity with the latest advancements in Natural Language
Processing (NLP) and Generative AI, empowering you to create
advanced AI systems that interpret, generate, and interact with
complex healthcare data.
- Proven ability to design, deploy, and scale these solutions on cloud
platforms, with preference for OCI (Oracle Cloud Infrastructure),
though experience with AWS and Azure is also highly valued.
Education
- A PhD in Computer Science, Mathematics, Statistics, Physics, Linguistics, or a related discipline, with a deep dive into Machine Learning and Deep Learning through your dissertation or final project, coupled with 12+ years of hands-on experience, is highly valued-but not a dealbreaker, OR A master's or bachelor's degree in a relevant field, paired with 12+ years of practical, impactful experience in the field, will also make you a strong contender.
you a strong contender
Disclaimer:
Certain US customer or client-facing roles may be required to comply with applicable requirements, such as immunization and occupational health mandates.
Range and benefit information provided in this posting are specific to the stated locations only
US: Hiring Range in USD from: $109,200 to $223,400 per annum. May be eligible for bonus and equity.
Oracle maintains broad salary ranges for its roles in order to account for variations in knowledge, skills, experience, market conditions and locations, as well as reflect Oracle's differing products, industries and lines of business.
Candidates are typically placed into the range based on the preceding factors as well as internal peer equity.
Oracle US offers a comprehensive benefits package which includes the following:
- Medical, dental, and vision insurance, including expert medical opinion
- Short term disability and long term disability
- Life insurance and AD&D
- Supplemental life insurance (Employee/Spouse/Child)
- Health care and dependent care Flexible Spending Accounts
- Pre-tax commuter and parking benefits
- 401(k) Savings and Investment Plan with company match
- Paid time off: Flexible Vacation is provided to all eligible employees assigned to a salaried (non-overtime eligible) position. Accrued Vacation is provided to all other employees eligible for vacation benefits. For employees working at least 35 hours per week, the vacation accrual rate is 13 days annually for the first three years of employment and 18 days annually for subsequent years of employment. Vacation accrual is prorated for employees working between 20 and 34 hours per week. Employees working fewer than 20 hours per week are not eligible for vacation.
- 11 paid holidays
- Paid sick leave: 72 hours of paid sick leave upon date of hire. Refreshes each calendar year. Unused balance will carry over each year up to a maximum cap of 112 hours.
- Paid parental leave
- Adoption assistance
- Employee Stock Purchase Plan
- Financial planning and group legal
- Voluntary benefits including auto, homeowner and pet insurance
The role will generally accept applications for at least three calendar days from the posting date or as long as the job remains posted.
Career Level - IC4
About Us
As a world leader in cloud solutions, Oracle uses tomorrow's technology to tackle today's challenges. We've partnered with industry-leaders in almost every sector-and continue to thrive after 40+ years of change by operating with integrity.
We know that true innovation starts when everyone is empowered to contribute. That's why we're committed to growing an inclusive workforce that promotes opportunities for all.
Oracle careers open the door to global opportunities where work-life balance flourishes. We offer competitive benefits based on parity and consistency and support our people with flexible medical, life insurance, and retirement options. We also encourage employees to give back to their communities through our volunteer programs.
We're committed to including people with disabilities at all stages of the employment process. If you require accessibility assistance or accommodation for a disability at any point, let us know by emailing accommodation-request_mb@oracle.com or by calling +1 888 404 2494 in the United States.
Oracle is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability and protected veterans' status, or any other characteristic protected by law. Oracle will consider for employment qualified applicants with arrest and conviction records pursuant to applicable law.",2025-07-23T00:00:00.000Z,2025-07-25,"['Qualifications and Experience', 'Proven experience architecting and deploying scalable AI solutions', 'in production, with measurable impact across complex, real-world', 'Deep technical fluency in machine learning and deep learning', 'Hands-on expertise in Large Language Models (LLMs) and', 'generative AI, with experience in advanced prompt engineering,', 'Proficiency in Python is a must, with experience applying it to build', 'processes like prior authorization, risk adjustment, clinical', 'summarization, or claims adjudication is a major advantage', 'Experience in building a wide range of AI models-including', 'classical ML models, semantic search, and information retrieval', 'systems-to power intelligent, high-precision workflows', 'Familiarity with AI evaluation strategies, including data labeling,', 'A natural drive to stay ahead of the curve, with the curiosity to', 'explore cutting-edge research and the discipline to translate it into', 'Bonus: a strong portfolio of patents, publications, or open source', 'contributions, reflecting thought leadership and a commitment to', 'pushing the field forward', 'experience delivering AI-driven solutions tailored to healthcare', 'applications, transforming patient care and operational efficiency', 'Familiarity with the latest advancements in Natural Language', 'complex healthcare data', 'Proven ability to design, deploy, and scale these solutions on cloud', 'platforms, with preference for OCI (Oracle Cloud Infrastructure),', 'though experience with AWS and Azure is also highly valued', ""A PhD in Computer Science, Mathematics, Statistics, Physics, Linguistics, or a related discipline, with a deep dive into Machine Learning and Deep Learning through your dissertation or final project, coupled with 12+ years of hands-on experience, is highly valued-but not a dealbreaker, OR A master's or bachelor's degree in a relevant field, paired with 12+ years of practical, impactful experience in the field, will also make you a strong contender"", 'Certain US customer or client-facing roles may be required to comply with applicable requirements, such as immunization and occupational health mandates']","[""You'll build models that power prior authorization, risk adjustment, claims adjudication, and more-making data work smarter across the healthcare ecosystem"", ""You'll also help reduce the administrative burden on clinicians, using AI to automate documentation, extract insights, and deliver real-time intelligence when it matters most"", ""From classical ML to generative models, you'll lead with purpose designing scalable, responsible AI for real-world impact"", 'Partner with Product Managers to turn ambitious product visions', 'into AI-powered solutions that reshape healthcare operations and', 'Collaborate closely with Clinical Terminologists to ensure models are', 'clinically sound and aligned with evolving healthcare standards and', 'vocabularies', 'Work hand-in-hand with UI Engineers and ML Engineers to bring AI', 'models to life in intuitive, responsive, and scalable products', 'Lead the full lifecycle of AI development-from ideation and research', 'to deployment and monitoring', 'Apply the latest advancements in machine learning, deep learning,', 'and generative AI to deliver innovation at scale', 'Architect high-quality, production-ready AI pipelines, ensuring', 'robustness, accuracy, and compliance with healthcare regulations', 'Develop clean, scalable code and drive best practices across the AI', 'engineering stack', 'Mentor and inspire a team of data scientists, fostering technical', 'growth and leadership', 'Contribute to planning, reviews, and retrospectives-driving', 'continuous improvement and cross-team alignment', 'Anticipate and navigate technical and organizational risks to ensure', 'project success and sustained impact', 'architectures, including Transformers and other neural network', 'instruction fine-tuning, and parameter-efficient tuning techniques', 'and deploy AI/ML models and develop robust, scalable solutions', 'Strong foundation in clinical data, with the ability to extract meaning', 'from structured and unstructured sources and align with', 'interoperability standards such as FHIR, C-CDA, or HL7', 'Experience building models that support healthcare-critical', 'annotation workflows, human-in-the-loop review, and longitudinal', 'model monitoring in high-stakes environments', 'resilient, production-ready systems', 'A track record of technical leadership, including mentoring junior', 'Processing (NLP) and Generative AI, empowering you to create', 'advanced AI systems that interpret, generate, and interact with']",True,"['Generative AI', 'Large Language Models', 'Prompt Engineering', 'Instruction Fine-Tuning', 'Parameter-Efficient Tuning', 'Natural Language Processing with LLMs']","Generative AI: Applied to automate clinical documentation, extract insights, and deliver real-time intelligence in healthcare.; Large Language Models: Used for advanced natural language understanding and generation tasks within clinical data exchange and healthcare workflows.; Prompt Engineering: Techniques employed to optimize interactions with LLMs for improved AI model performance in healthcare applications.; Instruction Fine-Tuning: Method used to adapt LLMs to specific healthcare tasks and improve model accuracy and relevance.; Parameter-Efficient Tuning: Approach to fine-tune large AI models efficiently for healthcare-specific use cases.; Natural Language Processing with LLMs: Utilized to interpret, generate, and interact with complex healthcare data through advanced AI systems.","['Machine Learning', 'Deep Learning', 'Transformers', 'Semantic Search', 'Information Retrieval', 'Data Labeling and Annotation', 'Human-in-the-Loop Review', 'Longitudinal Model Monitoring', 'Clinical Data Standards (FHIR, C-CDA, HL7)', 'Python', 'Cloud Platforms (OCI, AWS, Azure)']","Machine Learning: Used to build predictive models for healthcare processes like prior authorization, risk adjustment, and claims adjudication.; Deep Learning: Applied to develop advanced neural network architectures for clinical data analysis and AI model development.; Transformers: Neural network architecture leveraged for processing complex healthcare data and powering AI models.; Semantic Search: Implemented to enhance information retrieval systems for intelligent, high-precision healthcare workflows.; Information Retrieval: Used to build systems that extract relevant clinical information from structured and unstructured data.; Data Labeling and Annotation: Employed in AI evaluation strategies to ensure high-quality training data and model accuracy in healthcare applications.; Human-in-the-Loop Review: Integrated into model monitoring workflows to maintain model performance and compliance in high-stakes healthcare environments.; Longitudinal Model Monitoring: Used to track AI model performance over time to ensure sustained accuracy and reliability in clinical settings.; Clinical Data Standards (FHIR, C-CDA, HL7): Standards followed to align data extraction and interoperability within healthcare systems.; Python: Primary programming language for building, deploying, and scaling AI and ML models in healthcare.; Cloud Platforms (OCI, AWS, Azure): Used to design, deploy, and scale AI-driven healthcare solutions in production environments."
qtg_xAHD7eRVhbCoAAAAAA==,"Manager, Data Scientist - Shopping Growth (Remote-Eligible)","Manager, Data Scientist - Shopping Growth (Remote-Eligible)

Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making.

As a Data Scientist at Capital One, you’ll be part of a team that’s leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives.

Team Description:

The Shopping Growth team is on a mission to bring our product to millions of new customers and help them unlock savings while also driving great value for our merchant partners. This is an opportunity to join that team’s mission and help supercharge progress through machine learning and advanced analytics.

Role Description:

In this role, you will:
• Be at the center of driving business decisions through leveraging vast datasets to understand customer value at various parts of the customer lifecycle to unlock game changing growth for an already rapidly growing business
• Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation
• Leverage a broad stack of technologies — Python, Conda, AWS, H2O, Spark, and more — to reveal the insights hidden within huge volumes of numeric and textual data
• Flex your interpersonal skills to translate the complexity of your work into tangible business goals

The Ideal Candidate is:
• Results Focused. You understand where the leverage is and desire making an impact to the business’ bottom line through driving high-quality work from start to finish efficiently
• A leader. You challenge conventional thinking and work with stakeholders to identify and improve the status quo. You’re passionate about talent development for your own team and beyond.
• Technical. You’re comfortable with open-source languages and are passionate about developing further. You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms.
• Statistically-minded. You’ve built models, validated them, and backtested them. You know how to interpret a confusion matrix or a ROC curve. You have experience with clustering, classification, sentiment analysis, time series, and deep learning.

Basic Qualifications:
• Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:
• A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 6 years of experience performing data analytics
• A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 4 years of experience performing data analytics
• A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 1 year of experience performing data analytics
• At least 1 year of experience leveraging open source programming languages for large scale data analysis
• At least 1 year of experience working with machine learning
• At least 1 year of experience utilizing relational databases

Preferred Qualifications:
• PhD in “STEM” field (Science, Technology, Engineering, or Mathematics) plus 3 years of experience in data analytics
• At least 1 year of experience working with AWS
• At least 4 years’ experience in Python, Scala, or R for large scale data analysis
• At least 4 years’ experience with machine learning
• At least 4 years’ experience with SQL

Capital One will consider sponsoring a new qualified applicant for employment authorization for this position.

Capital One is open to hiring a Remote Employee for this opportunity

The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.

Remote (Regardless of Location): $175,800 - $200,700 for Mgr, Data Science

McLean, VA: $193,400 - $220,700 for Mgr, Data Science

Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate’s offer letter.

This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.

Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.

This role is expected to accept applications for a minimum of 5 business days.

No agencies please. Capital One is an equal opportunity employer (EOE, including disability/vet) committed to non-discrimination in compliance with applicable federal, state, and local laws. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",,2025-07-25,"['You understand where the leverage is and desire making an impact to the business’ bottom line through driving high-quality work from start to finish efficiently', 'You’re passionate about talent development for your own team and beyond', 'Technical', 'You’re comfortable with open-source languages and are passionate about developing further', 'You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms', 'Statistically-minded', 'You know how to interpret a confusion matrix or a ROC curve', 'You have experience with clustering, classification, sentiment analysis, time series, and deep learning', 'Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:', ""A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 6 years of experience performing data analytics"", ""A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 4 years of experience performing data analytics"", 'A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 1 year of experience performing data analytics', 'At least 1 year of experience leveraging open source programming languages for large scale data analysis', 'At least 1 year of experience working with machine learning', 'At least 1 year of experience utilizing relational databases']","['This is an opportunity to join that team’s mission and help supercharge progress through machine learning and advanced analytics', 'Be at the center of driving business decisions through leveraging vast datasets to understand customer value at various parts of the customer lifecycle to unlock game changing growth for an already rapidly growing business', 'Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation', 'Leverage a broad stack of technologies — Python, Conda, AWS, H2O, Spark, and more — to reveal the insights hidden within huge volumes of numeric and textual data', 'Flex your interpersonal skills to translate the complexity of your work into tangible business goals', 'You challenge conventional thinking and work with stakeholders to identify and improve the status quo', 'You’ve built models, validated them, and backtested them']",True,[],,"['Machine Learning', 'Classification', 'Clustering', 'Sentiment Analysis', 'Time Series Analysis', 'Deep Learning', 'Python', 'Conda', 'AWS', 'H2O', 'Spark', 'Relational Databases', 'ROC Curve', 'Confusion Matrix', 'Backtesting']","Machine Learning: Used to build predictive models through all phases including design, training, evaluation, validation, and implementation to drive business growth.; Classification: Applied as a modeling technique to categorize data, relevant for understanding customer segments and behaviors.; Clustering: Used for unsupervised learning to group similar data points, aiding in customer segmentation and insights.; Sentiment Analysis: Employed to analyze textual data to understand customer opinions and feedback.; Time Series Analysis: Used to analyze data points collected or recorded at specific time intervals, important for forecasting and trend analysis.; Deep Learning: Applied as an advanced modeling technique for complex data patterns, enhancing predictive accuracy.; Python: Primary programming language used for data analysis, model development, and leveraging open-source data science tools.; Conda: Environment and package management system used to manage dependencies and libraries for data science projects.; AWS: Cloud computing platform used to handle large-scale data processing and model deployment.; H2O: Open-source machine learning platform used for building scalable and efficient predictive models.; Spark: Big data processing framework used to handle and analyze large volumes of numeric and textual data.; Relational Databases: Used for storing and querying structured data essential for analytics and model input.; ROC Curve: Statistical tool used to evaluate the performance of classification models.; Confusion Matrix: Used to assess the accuracy of classification models by comparing predicted and actual outcomes.; Backtesting: Process of validating models by testing them on historical data to ensure reliability."
8xLzY6gxrhSrqLmpAAAAAA==,Data Scientist (Hybrid/U.S. Citizens Only),"Task Force Talent is seeking data scientists for a very well-funded Series C company working on insider threat and supply chain security problems. Target salary range is 150k to 200k+, plus equity, depending on experience level and location.

Please note that although this is a data science position, the company is looking for skill sets much closer to software engineering. This is NOT a role focused on just on statistical analysis or building dashboards. Candidates will have to pass technical interviews similar to software engineering interviews.

The company is profitable and growing fast with approximately 150+ employees. Positions are available in Tysons Corner, VA, and Salt Lake City, UT, with a hybrid (typically 3 days/week in the office) schedule; however, those hours are flexible to accommodate family/childcare and traffic as the goal of in-office hours is to know your team better.

Benefits
• Company Equity Options and 401(k) Plan
• Unlimited PTO and Wellness Reimbursement
• U.S. Holidays
• Paid Parental Leave
• Comprehensive Insurance (Medical, Dental, and Vision)

This company is completely private sector, no security clearance required; however, employment is open to U.S. citizens only at this time.

____________________________________________________________________________________________________________________________________________

Qualifications
• MUST be a U.S. citizen (no permanent residents, no visa sponsorship); while no clearance is required, candidates must be clearance-eligible.
• AT LEAST 3+ years (ideally 5+ to be most competitive) of experience in data science and/or analytics
• MS or BS in an engineering (preferred) or quantitative field (Science, Economics, Statistics) with a background in programming.
• Strong proficiency in Python, SQL, R or comparable languages
• Experience with large-scale data analysis and statistical modeling
• Ability to transform complex data into actionable insights
• Strong project management and prioritization skills
• Experience with Elasticsearch preferred
• Proven ability to work independently and as part of a team
• Strong communication skills for technical and non-technical audiences

BONUS: Foreign language fluency, particularly languages associated with threat actors.

____________________________________________________________________________________________________________________________________________

Interview Process

This company typically has a phone screen, followed by a coding exercise, and then several in-person interviews. They usually move fast -- introduction to offer within two to three weeks.

About Us

Task Force Talent is a specialized recruiting firm for science, engineering, and security careers. Our clients include seed to Series C startups working on AI, cybersecurity, quantum computing, and other novel technologies. We also work with small to medium-sized government contractors, and we help leading venture capital firms find talent for their portfolio companies. We have hundreds of jobs available and consider all applicants for all roles, now and in the future. Our goal is to find the best fit for you!

____________________________________________________________________________________________________________________________________________

Not your dream job, but perfect for a friend? You can submit a referral and get a check for $2000 or more: https://www.taskforcetalent.com/referral/ (Terms and conditions apply.)

If you don't see the perfect fit, simply use our general application at: https://taskforcetalent.breezy.hr/p/5bbc3c44433e-single-application-for-all-jobs-general",,2025-07-25,"['Candidates will have to pass technical interviews similar to software engineering interviews', 'MUST be a U.S. citizen (no permanent residents, no visa sponsorship); while no clearance is required, candidates must be clearance-eligible', 'AT LEAST 3+ years (ideally 5+ to be most competitive) of experience in data science and/or analytics', 'Strong proficiency in Python, SQL, R or comparable languages', 'Experience with large-scale data analysis and statistical modeling', 'Ability to transform complex data into actionable insights', 'Strong project management and prioritization skills', 'Proven ability to work independently and as part of a team', 'Strong communication skills for technical and non-technical audiences', 'BONUS: Foreign language fluency, particularly languages associated with threat actors']",,True,[],,"['Python', 'SQL', 'R', 'Large-scale data analysis', 'Statistical modeling', 'Elasticsearch']","Python: Used as a primary programming language for data analysis and statistical modeling in the data science role.; SQL: Required for querying and managing large-scale data sets to support analysis and insight generation.; R: Mentioned as a comparable language for statistical modeling and data analysis tasks.; Large-scale data analysis: Experience with handling and analyzing extensive datasets to extract meaningful insights.; Statistical modeling: Applied to develop models that help understand and predict patterns relevant to insider threat and supply chain security.; Elasticsearch: Preferred tool for searching and analyzing large volumes of data, likely used to support security-related data queries."
UHRE_CDzNaBk8zTgAAAAAA==,"Senior Data Scientist - Full-Time, High-Impact Role","Help us build the future of supply chain intelligence.

We're a well-funded startup backed by prominent investors, founded by serial entrepreneurs who've previously raised hundreds of millions and built category-defining companies. We're building a next-generation supply chain AI platform that will transform how global commerce operates.

We are seeking a Senior Data Scientist with deep mathematical foundations who can translate cutting-edge research into production systems that scale.

What You'll Do:
• Design and implement advanced ML models for supply chain optimization
• Apply linear programming and optimization techniques to real-world problems
• Build and deploy deep learning models at production scale
• Own the MLOps pipeline for training and serving large models
• Write production-quality code that handles billions of data points
• Collaborate with engineering to integrate models into our platform
• Research and implement state-of-the-art techniques in forecasting and optimization
• Design experiments and analyze results to drive product decisions
• Build self-improving systems that learn from user interactions

You Should Have:
• Master's degree (or PhD) in Computer Science, Mathematics, Statistics, or related field
• Strong mathematical foundations (linear algebra, optimization, probability theory)
• Deep understanding of linear programming and combinatorial optimization
• Extensive experience with deep learning frameworks (PyTorch)
• Proven track record deploying ML models to production
• MLOps experience with large-scale model training and serving
• Proficiency in Python and software engineering best practices
• Experience with distributed computing and big data technologies
• Ability to translate complex research into practical solutions

Bonus Points
• PhD in a relevant field with published research
• Experience with supply chain optimization or operations research
• Built ML infrastructure for training models with billions of parameters
• Experience with real-time ML systems and edge deployment
• Track record at successful startups or top-tier tech companies

Why Join Us?
• Work with founders who've built category leading companies before
• Backed by prominent deep tech investors — we have runway and ambition
• Solve genuinely hard problems that impact global commerce
• Own the entire ML stack with resources to build it right
• Collaborate with a world-class team of engineers
• Competitive compensation with significant equity upside
• Join at the ground floor of what will be a category-defining company

To Apply

Share a production ML system you've built that required both mathematical sophistication and engineering excellence. We're especially interested in examples involving optimization, large-scale training, or systems that improved over time. Include metrics on model performance and system scale if possible.",2025-07-25T04:00:00.000Z,2025-07-25,"[""Master's degree (or PhD) in Computer Science, Mathematics, Statistics, or related field"", 'Strong mathematical foundations (linear algebra, optimization, probability theory)', 'Deep understanding of linear programming and combinatorial optimization', 'Extensive experience with deep learning frameworks (PyTorch)', 'Proven track record deploying ML models to production', 'MLOps experience with large-scale model training and serving', 'Proficiency in Python and software engineering best practices', 'Experience with distributed computing and big data technologies', 'Ability to translate complex research into practical solutions', 'PhD in a relevant field with published research', 'Experience with supply chain optimization or operations research', 'Built ML infrastructure for training models with billions of parameters', 'Experience with real-time ML systems and edge deployment', 'Track record at successful startups or top-tier tech companies', ""Share a production ML system you've built that required both mathematical sophistication and engineering excellence"", ""We're especially interested in examples involving optimization, large-scale training, or systems that improved over time""]","['Design and implement advanced ML models for supply chain optimization', 'Apply linear programming and optimization techniques to real-world problems', 'Build and deploy deep learning models at production scale', 'Own the MLOps pipeline for training and serving large models', 'Write production-quality code that handles billions of data points', 'Collaborate with engineering to integrate models into our platform', 'Research and implement state-of-the-art techniques in forecasting and optimization', 'Design experiments and analyze results to drive product decisions', 'Build self-improving systems that learn from user interactions', 'Include metrics on model performance and system scale if possible']",True,['PyTorch'],PyTorch: Using the PyTorch deep learning framework to build and deploy neural network models at production scale.,"['Machine Learning', 'Linear Programming', 'Optimization', 'Deep Learning', 'MLOps', 'Python', 'Distributed Computing', 'Forecasting', 'Experiment Design and Analysis', 'Feature Engineering']","Machine Learning: Designing and implementing advanced ML models for supply chain optimization and deploying them to production.; Linear Programming: Applying linear programming techniques to solve real-world supply chain optimization problems.; Optimization: Using optimization methods, including combinatorial optimization, to improve supply chain processes and model performance.; Deep Learning: Building and deploying deep learning models at production scale to enhance supply chain intelligence.; MLOps: Owning the MLOps pipeline for training and serving large-scale machine learning models.; Python: Using Python programming language and software engineering best practices to develop production-quality code.; Distributed Computing: Leveraging distributed computing and big data technologies to handle billions of data points efficiently.; Forecasting: Researching and implementing state-of-the-art forecasting techniques to drive product decisions.; Experiment Design and Analysis: Designing experiments and analyzing results to inform product and model improvements.; Feature Engineering: Building self-improving systems that learn from user interactions, implying feature extraction and model refinement."
FylOg5E7_94Psyu_AAAAAA==,John Snow Labs US-Based Healthcare Data Scientist,"Company Description

John Snow Labs is an award-winning AI and NLP company, accelerating progress in data science by providing state-of-the-art software, data, and models. Founded in 2015, it helps healthcare and life science companies build, deploy, and operate AI products and services. John Snow Labs is the winner of the 2018 AI Solution Provider of the Year Award, the 2019 AI Platform of the Year Award, the 2019 International Data Science Foundation Technology award, and the 2020 AI Excellence Award.

John Snow Labs is the developer of Spark NLP - the world’s most widely used NLP library in the enterprise - and is the world’s leading provider of state-of-the-art clinical NLP software, powering some of the world’s largest healthcare & pharma companies. John Snow Labs is a global team of specialists, of which 33% hold a Ph.D. or M.D. and 75% hold at least a Master’s degree in disciplines covering data science, medicine, software engineering, pharmacy, DevOps and SecOps.

Job Description

John Snow Labs is seeking a highly skilled and motivated Data Scientist to contribute to transformative initiatives within the healthcare industry. The ideal candidate will possess a strong background in developing and optimizing machine learning models, specifically within healthcare contexts. We are looking for a results-oriented individual proficient in training and fine-tuning models, building robust, production-ready model inference pipelines, and conducting comprehensive exploratory data analysis and data enrichment.

Qualifications

Key Responsibilities:
• Train, fine tune, and enhance LLM & NLP models using the open-source Python library ecosystem. Experience with LLMs, Generative AI, and deep learning is a significant advantage.
• Build data science and data engineering pipelines specific to analyzing clinical data, such as extracting information from medical text or images, or integrating uncertain information from multiple medical data sources.
• Collaborate with our team on customer-facing projects, utilizing your expertise to create advanced machine learning, deep learning, large language models, and time series forecasting pipelines tailored to address specific business needs.
• Ensure models are validated for issues like bias, overfitting, and concept drift to ensure reliability and effectiveness.
• Engage directly with customers, requiring strong oral and written communication skills to convey complex technical concepts clearly.

Mandatory Skills:
• Proven experience in consistently delivering real-world projects covering the key responsibilities. Knowledge that is limited to an academic setting, or to using existing APIs to building applications, is not sufficient for this role.
• Hands-on experience with OMOP, FHIR, clinical terminologies, and understanding of the patient journey.
• Strong background in healthcare-related fields such as medicine, pharma, bioinformatics, or biostatistics is highly beneficial.
• A PhD in a relevant field is preferred but not required if exceptional experience is demonstrated.
• Experience with John Snow Labs’ technology stack, such as Spark NLP or the medical language models, is a plus.

What We Offer:
• A chance to work on cutting-edge problems in healthcare and life sciences, contributing to meaningful projects that impact patient outcomes.
• Long-term freelancing contracts with a commitment of at least 30 hours per week. We are seeking individuals, not agencies or teams.
• The opportunity to grow your skills and knowledge, working with a team of big data and data science experts in a supportive, collaborative environment.

To apply, please include the words 'John Snow Labs' in your cover letter and detail why you believe you are the best fit for this role. This is more than just a contract — it's a chance to make a real difference.

Additional Information

Our Commitment to You

At John Snow Labs, we believe that diversity is the catalyst of innovation. We’re committed to empowering talented people from every background and perspective to thrive.

We are an award-winning global collaborative team focused on helping our customers put artificial intelligence to good use faster. Our website includes The Story of John Snow, and our Social Impact page details how purpose and giving back is part of our DNA. More at JohnSnowLabs.com
• We are a fully virtual company, collaborating across 28 countries.
• This is a contract opportunity, not a full-time employment role.
• This role requires the availability of at least 30-40 hours per week.",,2025-07-25,"['We are looking for a results-oriented individual proficient in training and fine-tuning models, building robust, production-ready model inference pipelines, and conducting comprehensive exploratory data analysis and data enrichment', 'Experience with LLMs, Generative AI, and deep learning is a significant advantage', 'Build data science and data engineering pipelines specific to analyzing clinical data, such as extracting information from medical text or images, or integrating uncertain information from multiple medical data sources', 'Ensure models are validated for issues like bias, overfitting, and concept drift to ensure reliability and effectiveness', 'Engage directly with customers, requiring strong oral and written communication skills to convey complex technical concepts clearly', 'Proven experience in consistently delivering real-world projects covering the key responsibilities', 'Knowledge that is limited to an academic setting, or to using existing APIs to building applications, is not sufficient for this role', 'Hands-on experience with OMOP, FHIR, clinical terminologies, and understanding of the patient journey', 'Strong background in healthcare-related fields such as medicine, pharma, bioinformatics, or biostatistics is highly beneficial']","['Train, fine tune, and enhance LLM & NLP models using the open-source Python library ecosystem', 'Collaborate with our team on customer-facing projects, utilizing your expertise to create advanced machine learning, deep learning, large language models, and time series forecasting pipelines tailored to address specific business needs', 'This role requires the availability of at least 30-40 hours per week']",True,"['Large Language Models', 'Generative AI', 'Prompt Engineering', 'Neural Networks']",Large Language Models: Trained and fine-tuned to enhance NLP capabilities for healthcare-specific applications.; Generative AI: Leveraged to develop advanced AI models that generate or augment clinical data insights.; Prompt Engineering: Implied in fine-tuning and training LLMs to optimize their performance on healthcare tasks.; Neural Networks: Used within deep learning frameworks to build sophisticated models for clinical data analysis.,"['Machine Learning', 'Deep Learning', 'Time Series Forecasting', 'Data Engineering Pipelines', 'Exploratory Data Analysis', 'Model Validation', 'OMOP', 'FHIR', 'Clinical Terminologies', 'Spark NLP']","Machine Learning: Used for developing and optimizing predictive models tailored to healthcare data and business needs.; Deep Learning: Applied to build advanced models including neural networks for clinical data analysis and time series forecasting.; Time Series Forecasting: Used to analyze temporal healthcare data and predict future trends relevant to patient outcomes.; Data Engineering Pipelines: Built to process and integrate clinical data from multiple sources such as medical text and images.; Exploratory Data Analysis: Conducted to understand and enrich clinical datasets before model development.; Model Validation: Ensures models are reliable by checking for bias, overfitting, and concept drift in healthcare applications.; OMOP: Used as a clinical data standard to structure and analyze healthcare information.; FHIR: Applied as a healthcare interoperability standard to manage and exchange clinical data.; Clinical Terminologies: Utilized to accurately interpret and process medical language within healthcare datasets.; Spark NLP: A key NLP library used for processing and extracting information from clinical text data."
D6Y9vrIo1mX-IXCqAAAAAA==,Senior Data Scientist,"DTE is one of the nation’s largest diversified energy companies. Our electric and gas companies have fueled our customer’s homes and Michigan’s progress for more than a century. And as Michigan’s largest source of renewable energy, we’re creating a cleaner, healthier environment to power our future. We’re also serving communities beyond Michigan, where our affiliated businesses offer renewable energy, emission control technologies, and energy services to industries in 19 states.

But we’re more than a leading energy company... and working at DTE is more than just a job. At DTE, we take great care of each other and our customers, and we use our energy to be a force for growth and prosperity in our communities. When you join us, you’ll be part of a team that welcomes, recognizes, and celebrates differences and values everyone’s health, safety, and wellbeing. Are you ready to make that kind of difference? Bring your energy to DTE. Together, we can achieve great things.

Testing Required: Not Applicable

Hybrid Role: Must be able to come on-site periodically and reside a commutable distance from the assigned work location.

Emergency Response: Yes – Must be available to perform a primary assignment in support of DTE’s emergency response to storms or other events that impact service to our customers.

Job Summary

Leads large business unit or enterprise-level analytics projects with broad responsibilities for translating business requirements into analytical constructs and providing analytical insights for effective decision making. Mentors less experienced team members to run analytical experiments in a methodical manner, evaluates alternative approaches and develops predictive models to forecast business performance metrics. Communicates effectively to technical and non-technical stakeholders with strong domain expertise and business acumen. Additionally, this role requires researching and recommending new technologies and best practices within the industry to develop the organization’s analytics strategies and roadmap.

Key Accountabilities
• Leads analytics projects and collaborates with cross-functional stakeholders to complete end-to-end analyses that includes business requirements, data gathering, analysis, scaleable solutions, and presentations
• Conducts advanced statistical analysis to determine trends and significant data relationships, and proactively recommend areas of improvement.
• Develops complex data sets and predictive models to support key decisions to improve safety, employee engagement, operation efficiency, product quality, and customer satisfaction
• Prepares and delivers insightful presentations and actionable recommendations. Educates leaders and other employees on complex analytical findings in basic terms with storytelling and data visualization
• Identifies and evaluates technologies and provides strategic inputs to advance the organization’s analytics capabilities
• Implements new statistical, mathematical, machine learning, or other methodologies for modeling or analyses
• Responsible for discovering insights from Big Data to help shape or meet specific business needs and goals.
• Utilizes business expertise to translate goals into data-based deliverables, such as predictive models, pattern detection analysis or optimization algorithms
• Champions self-service reporting capability and use of Business Intelligence and statistical tools; advances the analytical capabilities of the organization
• Develops data and analytical processes based on Continuous Improvement learnings and practices

Minimum Education & Experience Requirements

This is a dual-track base requirement job; education and experience requirements can be satisfied through one of the following three options:
• Bachelor’s degree with emphasis on coursework of a quantitative nature (e.g., Statistics, Computer Science, Engineering, Mathematics, Physics, Data Science, Industrial/Organizational Psychology and Econometrics, etc.) and 6 years of experience working in a data analytical or computer programming function; or
• Master’s degree with emphasis on coursework of a quantitative nature (e.g., Statistics, Computer Science, Engineering, Mathematics, Physics, Data Science, Industrial/Organizational Psychology and Econometrics, etc.) and 4 years of experience working in a data analytical or computer programming function
• PhD degree with emphasis on coursework of a quantitative nature (e.g., Statistics, Computer Science, Engineering, Mathematics, Physics, Data Science, Industrial/Organizational Psychology and Econometrics, etc.) and 2 years of experience working in a data analytical or computer programming function

Other Qualifications

Preferred:
• PhD degree in Data Science
• Experience in quantitative analytics (e.g., data mining, regression analysis, hypothesis testing, predictive modeling and model optimization)
• Intermediate- to advanced-level knowledge and skills in data modeling, data structure, and the application of complex SQL queries with data from multiple sources, including Big Data platforms (e.g., Hadoop, AWS, Azure, Databricks)
• Experience with SAP Business Intelligence tools and SAP CRM, ISU, and BW data
• Intermediate-level or higher Continuous Improvement knowledge, skills, and certifications
• Strong written and verbal communication skills
• Strong business acumen and utility/energy industry experience

Other Requirements:
• Intermediate- to advanced-level skills and experience with data mining and statistical analysis using analytical packages / tools (e.g., R, SAS, SPSS, Stata, MATLAB, Minitab, etc.)
• Intermediate- to advanced-level skills and experience articulating business questions, pulling data from relational databases (e.g., SAP BW, ORACLE, SQL SERVER) and using advanced excel and statistical tools (e.g., Minitab, Alteryx, Advanced Excel with VBA, R, SAS, SPSS, Stata, MATLAB, etc.) and determining the appropriate analytical approach to conduct in-depth analysis to support decision making
• Intermediate- to advanced-level programming skills in SQL, C/C++/C#, Java, R, Python, PHP, ASP, or SAS
• Intermediate- to advanced-level skills in applied research design and machine learning (e.g., multivariate statistical analysis, unsupervised and supervised learning, predictive modeling, etc.)
• Self-starter and quick learner; advances self and others' knowledge and skill sets in business processes, data science, new analytical frameworks, technologies, and applications
• Strong interpersonal, analytical and problem-solving skills, including ability to communicate technical information and complex data analytics to a non-technical audience

Additional Information

Incumbents may engage in all or some combination of the activities and accountabilities, and utilize a variety of the competencies cited in this description depending upon the organization and role to which they are assigned. This description is intended to describe the general nature and level of work performed by incumbents in this job. It is not intended as an all-inclusive list of accountabilities or responsibilities, nor is it intended to limit the rights of supervisors or management representatives to assign, direct and control the work of employees under their supervision.

PRIVACY NOTICE TO CALIFORNIA JOB APPLICANTS

At DTE Energy, we are committed to providing an inclusive workplace where everyone feels welcome and a sense of belonging. We seek individuals with a heart for service, a passion to help our communities prosper, and ideas to help shape the future of energy. We are proud to be an equal opportunity, employer that considers all qualified applicants without regard to race, color, sex, sexual orientation, gender identity, age, religion, disability, national origin, citizenship, height, weight, genetic information, marital status, pregnancy, protected veteran status or any other status protected by applicable federal and/or state laws.#LI-DNP",2025-07-22T00:00:00.000Z,2025-07-25,"['Testing Required: Not Applicable', 'This is a dual-track base requirement job; education and experience requirements can be satisfied through one of the following three options:', 'Bachelor’s degree with emphasis on coursework of a quantitative nature (e.g., Statistics, Computer Science, Engineering, Mathematics, Physics, Data Science, Industrial/Organizational Psychology and Econometrics, etc.) and 6 years of experience working in a data analytical or computer programming function; or', 'Master’s degree with emphasis on coursework of a quantitative nature (e.g., Statistics, Computer Science, Engineering, Mathematics, Physics, Data Science, Industrial/Organizational Psychology and Econometrics, etc.) and 4 years of experience working in a data analytical or computer programming function', 'PhD degree with emphasis on coursework of a quantitative nature (e.g., Statistics, Computer Science, Engineering, Mathematics, Physics, Data Science, Industrial/Organizational Psychology and Econometrics, etc.) and 2 years of experience working in a data analytical or computer programming function', 'Intermediate- to advanced-level skills and experience with data mining and statistical analysis using analytical packages / tools (e.g., R, SAS, SPSS, Stata, MATLAB, Minitab, etc.)', 'Intermediate- to advanced-level skills and experience articulating business questions, pulling data from relational databases (e.g., SAP BW, ORACLE, SQL SERVER) and using advanced excel and statistical tools (e.g., Minitab, Alteryx, Advanced Excel with VBA, R, SAS, SPSS, Stata, MATLAB, etc.) and determining the appropriate analytical approach to conduct in-depth analysis to support decision making', 'Intermediate- to advanced-level programming skills in SQL, C/C++/C#, Java, R, Python, PHP, ASP, or SAS', 'Intermediate- to advanced-level skills in applied research design and machine learning (e.g., multivariate statistical analysis, unsupervised and supervised learning, predictive modeling, etc.)', ""Self-starter and quick learner; advances self and others' knowledge and skill sets in business processes, data science, new analytical frameworks, technologies, and applications"", 'Strong interpersonal, analytical and problem-solving skills, including ability to communicate technical information and complex data analytics to a non-technical audience']","['Hybrid Role: Must be able to come on-site periodically and reside a commutable distance from the assigned work location', 'Emergency Response: Yes – Must be available to perform a primary assignment in support of DTE’s emergency response to storms or other events that impact service to our customers', 'Leads large business unit or enterprise-level analytics projects with broad responsibilities for translating business requirements into analytical constructs and providing analytical insights for effective decision making', 'Mentors less experienced team members to run analytical experiments in a methodical manner, evaluates alternative approaches and develops predictive models to forecast business performance metrics', 'Communicates effectively to technical and non-technical stakeholders with strong domain expertise and business acumen', 'Additionally, this role requires researching and recommending new technologies and best practices within the industry to develop the organization’s analytics strategies and roadmap', 'Leads analytics projects and collaborates with cross-functional stakeholders to complete end-to-end analyses that includes business requirements, data gathering, analysis, scaleable solutions, and presentations', 'Conducts advanced statistical analysis to determine trends and significant data relationships, and proactively recommend areas of improvement', 'Develops complex data sets and predictive models to support key decisions to improve safety, employee engagement, operation efficiency, product quality, and customer satisfaction', 'Prepares and delivers insightful presentations and actionable recommendations', 'Educates leaders and other employees on complex analytical findings in basic terms with storytelling and data visualization', 'Identifies and evaluates technologies and provides strategic inputs to advance the organization’s analytics capabilities', 'Implements new statistical, mathematical, machine learning, or other methodologies for modeling or analyses', 'Responsible for discovering insights from Big Data to help shape or meet specific business needs and goals', 'Utilizes business expertise to translate goals into data-based deliverables, such as predictive models, pattern detection analysis or optimization algorithms', 'Champions self-service reporting capability and use of Business Intelligence and statistical tools; advances the analytical capabilities of the organization', 'Develops data and analytical processes based on Continuous Improvement learnings and practices', 'Incumbents may engage in all or some combination of the activities and accountabilities, and utilize a variety of the competencies cited in this description depending upon the organization and role to which they are assigned']",True,[],,"['Predictive Modeling', 'Statistical Analysis', 'Data Mining', 'Machine Learning', 'SQL', 'Big Data Platforms', 'Business Intelligence Tools', 'Data Visualization', 'Continuous Improvement', 'Programming Languages', 'Regression Analysis', 'Hypothesis Testing', 'Multivariate Statistical Analysis', 'Data Modeling', 'Advanced Excel with VBA', 'Alteryx']","Predictive Modeling: Develops predictive models to forecast business performance metrics and support key decisions in areas like safety and operational efficiency.; Statistical Analysis: Conducts advanced statistical analysis to identify trends and significant data relationships for business improvement.; Data Mining: Utilizes data mining techniques to discover insights from large datasets to meet specific business needs.; Machine Learning: Implements machine learning methodologies including supervised and unsupervised learning for modeling and analysis.; SQL: Uses complex SQL queries to extract and manipulate data from multiple relational databases such as SAP BW, Oracle, and SQL Server.; Big Data Platforms: Works with Big Data platforms like Hadoop, AWS, Azure, and Databricks to handle and analyze large-scale data.; Business Intelligence Tools: Champions self-service reporting and uses BI tools including SAP Business Intelligence to advance organizational analytics.; Data Visualization: Prepares and delivers presentations with data visualization to communicate complex analytical findings effectively.; Continuous Improvement: Develops data and analytical processes based on Continuous Improvement methodologies to enhance analytics capabilities.; Programming Languages: Utilizes programming languages such as R, Python, SAS, SPSS, Stata, MATLAB, C/C++/C#, Java, PHP, and ASP for data analysis and modeling.; Regression Analysis: Applies regression analysis as part of quantitative analytics to understand relationships between variables.; Hypothesis Testing: Uses hypothesis testing to validate assumptions and support data-driven decision making.; Multivariate Statistical Analysis: Employs multivariate statistical techniques to analyze complex data sets and extract meaningful insights.; Data Modeling: Applies data modeling and data structuring skills to organize and prepare data for analysis.; Advanced Excel with VBA: Uses advanced Excel features and VBA scripting to manipulate data and automate analytical tasks.; Alteryx: Utilizes Alteryx for data preparation, blending, and advanced analytics workflows."
LJAy9IiIZGK-jIXJAAAAAA==,Principal Data Scientist,"Asurion is seeking a Principal Data Scientist to join our Data Science team. An individual in this role will be designing, developing, implementing, and fine-tuning Large Language Models to build one-of-a-kind autonomous sales agents in the context of tech support. The candidate will work on the cutting-edge of LLMs as we aim to leverage them for sales where the tasks are better defined and narrow, but margin of error is very low. Leveraging AI to be offer a highly targeted and personalized sales experience while setting state-of-the-art standards for compliance and hallucinations. They should be well versed on modern massive neural language model architectures, including BERT-like and GPT/autoregressive-like LLM's, neural language generation, AI agents, few-shot multitask learning etc. The candidate should also know the limitations of LLMs and how to design solutions and services keeping those in mind. Gather and analyze large volumes of unstructured, text data, evaluates scenarios to make predictions on future outcomes and supports decision making. An ideal candidate would have excellent communication (written and oral) and presentation skills, including creating and sharing complex ideas to peers, cross-functional partners and stakeholders. The candidate will also offer technical mentorship and guidance to junior data scientists.

Role and Responsibilities:
• Utilize Natural Language Processing to analyze speech and text data, build chatbot and expert systems
• Implement existing Large Language Models such as GPT, LLaMA, etc
• Refine Large Language Models via prompt engineering, Agentic frameworks, fine-tuning, reinforcement learning, or transfer learning
• Lead and mentor a team of scientists, driving high-impact technical initiatives with broad scope and visibility
• Discover and formulate business problems and create data science solutions
• Develop prototypes for new data product ideas
• Design and deploy complex, optimized and large-scale machine learning algorithms and generative models to improve Asurion’s wireless, connected home, and appliance customers’ experiences
• Analyze and interpret the results of product experiments
• Work closely with product managers to identify and answer important product questions that help improve outcomes
• Communicate findings to product managers and development groups
• Drive the collection of new data and the refinement of existing data
• Regularly invents new and novel approaches to problems; takes initiative and breaks down barriers to solve problems; recognized within team as the source of solutions

Qualifications:
• Master's or PhD preferably in Machine Learning role with at least 4+ years hands-on ML experience
• 2+ years of experience leading a team of scientists or engineers, with a strong track record of recruiting and/or mentoring junior team members
• Specialized practical experience in Generative AI
• Expert in Natural Language Processing tasks
• Applied experience in deploying NLP based solutions, including Gen AI, at scale in a cloud environment like AWS, GCP or Azure.
• Prior experience in applying machine learning for customer experience use cases
• Comfortable manipulating and analyzing complex, high-volume, high dimensionality data from multiple sources
• Comfortable in using advanced statistical data modeling techniques and tools
• Experience using Python and working with large scale systems
• Knowledge of data processing on Hadoop programming environments (e.g. Spark/Hive)
• Familiar with optimization techniques and underlying machine learning algorithms concepts
• Solid statistical knowledge; familiarity with hypothesis testing, experimental design and time series
• Familiarity with Linux/Unix/Shell environments
• Self-driven and able to ask and tackle the most important analytical questions with a view on driving product impact
• A strong passion for empirical research and for answering hard questions with data
• Result-driven and focused self-starters, great communicators that follow through on every initiative
• Love the responsibility of being individually empowered
• Ability to communicate complex quantitative analysis in a clear, precise, and actionable manner",,2025-07-25,"[""They should be well versed on modern massive neural language model architectures, including BERT-like and GPT/autoregressive-like LLM's, neural language generation, AI agents, few-shot multitask learning etc"", 'The candidate should also know the limitations of LLMs and how to design solutions and services keeping those in mind', ""Master's or PhD preferably in Machine Learning role with at least 4+ years hands-on ML experience"", '2+ years of experience leading a team of scientists or engineers, with a strong track record of recruiting and/or mentoring junior team members', 'Specialized practical experience in Generative AI', 'Expert in Natural Language Processing tasks', 'Applied experience in deploying NLP based solutions, including Gen AI, at scale in a cloud environment like AWS, GCP or Azure', 'Prior experience in applying machine learning for customer experience use cases', 'Comfortable manipulating and analyzing complex, high-volume, high dimensionality data from multiple sources', 'Comfortable in using advanced statistical data modeling techniques and tools', 'Experience using Python and working with large scale systems', 'Knowledge of data processing on Hadoop programming environments (e.g', 'Familiar with optimization techniques and underlying machine learning algorithms concepts', 'Solid statistical knowledge; familiarity with hypothesis testing, experimental design and time series', 'Familiarity with Linux/Unix/Shell environments', 'Self-driven and able to ask and tackle the most important analytical questions with a view on driving product impact', 'A strong passion for empirical research and for answering hard questions with data', 'Result-driven and focused self-starters, great communicators that follow through on every initiative', 'Love the responsibility of being individually empowered', 'Ability to communicate complex quantitative analysis in a clear, precise, and actionable manner']","['An individual in this role will be designing, developing, implementing, and fine-tuning Large Language Models to build one-of-a-kind autonomous sales agents in the context of tech support', 'The candidate will work on the cutting-edge of LLMs as we aim to leverage them for sales where the tasks are better defined and narrow, but margin of error is very low', 'Leveraging AI to be offer a highly targeted and personalized sales experience while setting state-of-the-art standards for compliance and hallucinations', 'Gather and analyze large volumes of unstructured, text data, evaluates scenarios to make predictions on future outcomes and supports decision making', 'An ideal candidate would have excellent communication (written and oral) and presentation skills, including creating and sharing complex ideas to peers, cross-functional partners and stakeholders', 'The candidate will also offer technical mentorship and guidance to junior data scientists', 'Utilize Natural Language Processing to analyze speech and text data, build chatbot and expert systems', 'Implement existing Large Language Models such as GPT, LLaMA, etc', 'Refine Large Language Models via prompt engineering, Agentic frameworks, fine-tuning, reinforcement learning, or transfer learning', 'Lead and mentor a team of scientists, driving high-impact technical initiatives with broad scope and visibility', 'Discover and formulate business problems and create data science solutions', 'Develop prototypes for new data product ideas', 'Design and deploy complex, optimized and large-scale machine learning algorithms and generative models to improve Asurion’s wireless, connected home, and appliance customers’ experiences', 'Analyze and interpret the results of product experiments', 'Work closely with product managers to identify and answer important product questions that help improve outcomes', 'Communicate findings to product managers and development groups', 'Drive the collection of new data and the refinement of existing data', 'Regularly invents new and novel approaches to problems; takes initiative and breaks down barriers to solve problems; recognized within team as the source of solutions']",True,"['Large Language Models', 'Generative AI', 'Prompt Engineering', 'Reinforcement Learning', 'Transfer Learning', 'Agentic Frameworks', 'Neural Language Generation', 'AI Agents', 'Few-Shot Multitask Learning', 'Cloud AI Deployment']","Large Language Models: Designing, developing, implementing, and fine-tuning LLMs like GPT and LLaMA for autonomous sales agents.; Generative AI: Specialized practical experience in generative AI to create personalized sales experiences and state-of-the-art compliance standards.; Prompt Engineering: Refining LLMs through prompt engineering to improve model responses and task performance.; Reinforcement Learning: Applied to fine-tune LLMs and improve autonomous agent behaviors.; Transfer Learning: Used to adapt pre-trained LLMs to specific sales and tech support tasks.; Agentic Frameworks: Frameworks for building autonomous AI agents leveraging LLMs in the sales context.; Neural Language Generation: Utilized for generating natural language outputs in AI-driven sales agents.; AI Agents: Developing autonomous agents powered by LLMs to handle tech support sales tasks.; Few-Shot Multitask Learning: Leveraged to enable LLMs to perform multiple tasks with limited training examples.; Cloud AI Deployment: Deploying NLP and generative AI solutions at scale on cloud platforms like AWS, GCP, or Azure.","['Natural Language Processing', 'Machine Learning', 'Statistical Modeling', 'Data Engineering with Hadoop Ecosystem', 'Python Programming', 'Feature Engineering', 'Experimental Design and A/B Testing', 'Data Analysis and Visualization']","Natural Language Processing: Used to analyze speech and text data and build chatbot and expert systems relevant to the job's focus on unstructured data.; Machine Learning: Applied to design, deploy, and optimize large-scale algorithms improving customer experiences and supporting predictive analytics.; Statistical Modeling: Involves advanced statistical techniques, hypothesis testing, experimental design, and time series analysis to support data-driven decision making.; Data Engineering with Hadoop Ecosystem: Knowledge of data processing using Hadoop environments like Spark and Hive to handle large-scale data pipelines.; Python Programming: Used for data manipulation, analysis, and building machine learning models within large-scale systems.; Feature Engineering: Implied through data manipulation and preparation for machine learning and predictive modeling tasks.; Experimental Design and A/B Testing: Used to analyze and interpret product experiments to improve outcomes.; Data Analysis and Visualization: Communicating complex quantitative analysis clearly to stakeholders and product managers."
JbEvU8LZ6KUYqj1uAAAAAA==,Snr Data Scientist (Manufacturing and Pricing ),"Role: Senior Data Scientist

Location: PA ? Candidate can work Remote in United States, with some needed travel

Note: The role needs strong Manufacturing / Product based industry experience. This will be a individual contributor position and will work with the top management directly in a ground up setup.

About the Role

We are seeking a highly skilled Senior Data Scientist with expertise in Pricing, FSN and point of Sales analysis for manufacturing parts for a Manufacturing Client. As an algorithm expert, you will be responsible for building and supporting predictive models that drive our pricing and FSN strategies. You will work independently and will be managing your scope of work to analyze, compile data and forecast results with predictive outcomes reporting directly to the CIO

This role requires a deep understanding of pricing experimentation, POS and manufacturing parts Supply chain process advanced modeling, and retail data analytics to uncover insights that directly impact the company?s bottom line. You will play a key role in designing, evaluating, and refining pricing strategies through data-driven approaches.

Key Responsibilities
• Develop and enhance predictive models for manufacturing parts pricing, FSN and POS.
• Analyze and interpret large, complex pricing-related datasets, applying feature engineering techniques.
• Identify opportunities to incorporate new data sources and insights for improved pricing accuracy.
• Leverage statistical and machine learning techniques to validate and refine pricing models.
• Using data analysis to identify areas for improvement in manufacturing processes, like optimizing parameters for better product quality and yield.
• Act as a strategic partner in defining pricing roadmaps and priorities in collaboration with cross-functional teams.
• Design and implement pricing evaluation frameworks to determine optimal pricing strategies.
• Monitoring quality metrics and implementing data-driven strategies to minimize defects and ensure product consistency.
• Translate complex analytical findings into actionable insights, presenting them to senior leaders and stakeholders.
• Lead end-to-end analytical projects, ensuring seamless execution from data processing to model deployment.
• Stay up to date with industry trends in pricing analytics, machine learning, and manufacturing sector developments.

Required Qualifications
• Bachelor?s or Master?s degree in a quantitative field (e.g., Data Science, Statistics, Mathematics, Economics, Computer Science) OR equivalent industry experience.
• 5+ years of experience in Manufacturing parts pricing analysis, FSN and POS data science, and statistical modeling, preferably in a manufacturing or supply chain environment. The role is seeking for a 10+ years of experience (Phd experience included)
• Proficiency in SQL, Python, R, or other data analysis and statistical programming languages.
• Strong understanding of pricing strategies, price elasticity modeling, and demand forecasting.
• Expertise in machine learning techniques (supervised/unsupervised learning, classification, regression, etc.).
• Experience with A/B testing, controlled experiments, and statistical analysis to assess pricing models' business value.
• Strong data engineering skills, including data cleaning, transformation, and feature engineering.
• Ability to communicate complex data insights to non-technical stakeholders and executives.
• Experience managing end-to-end machine learning pipelines and deploying models in production environments.
• Preferred Qualifications
• Prior experience in manufacturing, supply chain, or retail pricing analytics.
• Familiarity with big data technologies (e.g., Spark, Hadoop, Databricks).
• Experience with cloud platforms such as AWS, GCP, or Azure.
• Strong business acumen and the ability to translate data-driven insights into revenue-generating strategies.",,2025-07-25,"['Candidate can work Remote in United States, with some needed travel', 'Note: The role needs strong Manufacturing / Product based industry experience', 'Bachelor?s or Master?', 's degree in a quantitative field (e.g., Data Science, Statistics, Mathematics, Economics, Computer Science) OR equivalent industry experience', '5+ years of experience in Manufacturing parts pricing analysis, FSN and POS data science, and statistical modeling, preferably in a manufacturing or supply chain environment', 'The role is seeking for a 10+ years of experience (Phd experience included)', 'Proficiency in SQL, Python, R, or other data analysis and statistical programming languages', 'Strong understanding of pricing strategies, price elasticity modeling, and demand forecasting', 'Expertise in machine learning techniques (supervised/unsupervised learning, classification, regression, etc.)', ""Experience with A/B testing, controlled experiments, and statistical analysis to assess pricing models' business value"", 'Strong data engineering skills, including data cleaning, transformation, and feature engineering', 'Ability to communicate complex data insights to non-technical stakeholders and executives', 'Experience managing end-to-end machine learning pipelines and deploying models in production environments', 'Prior experience in manufacturing, supply chain, or retail pricing analytics', 'Familiarity with big data technologies (e.g., Spark, Hadoop, Databricks)', 'Experience with cloud platforms such as AWS, GCP, or Azure', 'Strong business acumen and the ability to translate data-driven insights into revenue-generating strategies']","['This will be a individual contributor position and will work with the top management directly in a ground up setup', 'We are seeking a highly skilled Senior Data Scientist with expertise in Pricing, FSN and point of Sales analysis for manufacturing parts for a Manufacturing Client', 'As an algorithm expert, you will be responsible for building and supporting predictive models that drive our pricing and FSN strategies', 'You will work independently and will be managing your scope of work to analyze, compile data and forecast results with predictive outcomes reporting directly to the CIO', 'This role requires a deep understanding of pricing experimentation, POS and manufacturing parts Supply chain process advanced modeling, and retail data analytics to uncover insights that directly impact the company?s bottom line', 'You will play a key role in designing, evaluating, and refining pricing strategies through data-driven approaches', 'Develop and enhance predictive models for manufacturing parts pricing, FSN and POS', 'Analyze and interpret large, complex pricing-related datasets, applying feature engineering techniques', 'Identify opportunities to incorporate new data sources and insights for improved pricing accuracy', 'Leverage statistical and machine learning techniques to validate and refine pricing models', 'Using data analysis to identify areas for improvement in manufacturing processes, like optimizing parameters for better product quality and yield', 'Act as a strategic partner in defining pricing roadmaps and priorities in collaboration with cross-functional teams', 'Design and implement pricing evaluation frameworks to determine optimal pricing strategies', 'Monitoring quality metrics and implementing data-driven strategies to minimize defects and ensure product consistency', 'Translate complex analytical findings into actionable insights, presenting them to senior leaders and stakeholders', 'Lead end-to-end analytical projects, ensuring seamless execution from data processing to model deployment', 'Stay up to date with industry trends in pricing analytics, machine learning, and manufacturing sector developments']",True,[],,"['Predictive Modeling', 'Pricing Strategies', 'Feature Engineering', 'Supervised and Unsupervised Learning', 'A/B Testing', 'Data Cleaning and Transformation', 'SQL', 'Python', 'R', 'Statistical Modeling', 'Machine Learning Pipelines', 'Big Data Technologies', 'Cloud Platforms', 'Demand Forecasting', 'Supply Chain Analytics', 'Data-Driven Decision Making']","Predictive Modeling: Building and supporting models to forecast manufacturing parts pricing, FSN, and POS outcomes.; Pricing Strategies: Designing, evaluating, and refining pricing approaches using data-driven methods to optimize revenue.; Feature Engineering: Applying techniques to transform and prepare pricing-related datasets for improved model accuracy.; Supervised and Unsupervised Learning: Using machine learning techniques such as classification and regression to validate and refine pricing models.; A/B Testing: Conducting controlled experiments to assess the business value of pricing models.; Data Cleaning and Transformation: Performing data engineering tasks to prepare complex datasets for analysis and modeling.; SQL: Utilizing SQL for querying and managing pricing and supply chain data.; Python: Using Python for data analysis, statistical programming, and model development.; R: Employing R for statistical modeling and data analysis in pricing and supply chain contexts.; Statistical Modeling: Applying statistical techniques to model price elasticity, demand forecasting, and pricing experimentation.; Machine Learning Pipelines: Managing end-to-end processes from data processing to deployment of machine learning models in production.; Big Data Technologies: Familiarity with Spark, Hadoop, and Databricks to handle large-scale manufacturing and pricing datasets.; Cloud Platforms: Experience with AWS, GCP, or Azure for deploying and managing data science workloads.; Demand Forecasting: Predicting future demand to inform pricing and supply chain decisions.; Supply Chain Analytics: Analyzing manufacturing parts supply chain data to optimize processes and pricing.; Data-Driven Decision Making: Translating complex analytical findings into actionable insights for senior leadership."
EOB9dCKQUnNyaM61AAAAAA==,Data Scientist 3 - 23502,"Requisition Number: 23502

Required Travel: 0 - 10%

Employment Type: Full Time/Salaried/Exempt

Anticipated Salary Range: $99,336.00 - $132,500.00

Security Clearance: Secret

Level of Experience: Mid

This opportunity resides with Warfare Systems (WS), a business group within HII’s Mission Technologies division. Warfare Systems comprises cyber and mission IT; electronic warfare; and C5ISR systems.

HII works within our nation’s intelligence and cyber operations communities to defend our interests in cyberspace and anticipate emerging threats. Our capabilities in cybersecurity, network architecture, reverse engineering, software and hardware development uniquely enable us to support sensitive missions for the U.S. military and federal agency partners.

Meet HII’s Mission Technologies Division

Our team of more than 7,000 professionals worldwide delivers all-domain expertise and advanced technologies in service of mission partners across the globe. Mission Technologies is leading the next evolution of national defense – the data evolution - by accelerating a breadth of national security solutions for government and commercial customers. Our capabilities range from C5ISR, AI and Big Data, cyber operations and synthetic training environments to fleet sustainment, environmental remediation and the largest family of unmanned underwater vehicles in every class. Find the role that’s right for you. Apply today. We look forward to meeting you.

To learn more about Mission Technologies, click here for a short video: https://vimeo.com/732533072

Job Description

HII-Mission Technologies is currently seeking a skilled Data Scientist/Engineer to design, develop, and implement a data base architecture, tools, and techniques for management and use of extremely large data sets for use by data analyst for our DoD customer's organization. This position will be performed at the DoD customer site at Wright-Patterson Air Force Base.

#LI-HB1

Essential Job Responsibilities
• Investigate, determine, and implement suitable open-source tools for storage, managing, and use of extremely large data sets.
• Investigate, determine, and implement tools and methodologies for extracting key data points for analysis by data analyst.
• Conducts data exploration, analysis, and feature extraction techniques to incorporate into DoD customer’s organization data pipelines and workflows.
• Be part of a team responsible for creating, maintaining, and augmenting an on-premises compute environment
• Translating requirements into capabilities for technical teams
• Present status reports to key internal stakeholders
• Evaluate new tools, technologies, and processes to improve on-premises environment
• Gain familiarity of customer mission to identify and/or develop data management and workflow solutions.
• Proposes solutions and strategies to unique challenges throughout the DoD customer’s organization.
• Linux system configuration and capacity planning for large scale data analytics on-premises and cloud.
• Additional duties as assigned or required.

Minimum Qualifications
• 5 years relevant experience with Bachelor in related field; 3 years relevant experience with Masters in related field.
• Experience with defining requirements for using and maintaining open-source data analytics, data workflow, and database tools.
• Develop, implement, and maintain data analytic protocols, standards, and documentation.
• Design data models based on requirements/needs for complex analysis of data analyst
• Define requirements for vendors to implement into their proposed solutions to meet DoD customer’s organization needs and use cases.
• Experience working with multiple types of datasets and database technologies
• Experience building data pipelines from end to end
• Experience with multiple industry standard cloud and on-premise database technologies
• Experience with data exploration, analysis, and visualization tools such as Python and Matlab
• Experience and familiarity with Linux operating environment
• Experience with open-source containerization technologies and tools and how to utilize those technologies as appropriately for database technologies and analytics
• Define internal process improvements to automate repetitive tasks to minimize downtime between analysis
• Clearance: Secret clearance to start. Must be able to obtain and maintain a TS/SCI security clearance with enhanced security checks.

Physical Requirements

May require working in an office, industrial, or laboratory environment. Capable of climbing ladders and tolerating confined spaces and extreme temperature variances.

The listed salary range for this role is intended as a good faith estimate based on the role's location, expectations, and responsibilities. When extending an offer, HII's Mission Technologies division takes a variety of factors into consideration which include, but are not limited to, the role's function and a candidate's education or training, work experience, and key skills.

Together we are working to ensure a future where everyone can be free and thrive.

All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, physical or mental disability, age, or veteran status or any other basis protected by federal, state, or local law.

Do You Need Assistance?

If you need a reasonable accommodation for any part of the employment process, please send an e-mail to buildyourcareer@hii-co.com and let us know the nature of your request and your contact information. Reasonable accommodations are considered on a case-by-case basis. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this email address. Additionally, you may also call 1-844-849-8463 for assistance. Press #3 for HII Mission Technologies.",2025-06-30T00:00:00.000Z,2025-07-25,"['5 years relevant experience with Bachelor in related field; 3 years relevant experience with Masters in related field', 'Experience with defining requirements for using and maintaining open-source data analytics, data workflow, and database tools', 'Develop, implement, and maintain data analytic protocols, standards, and documentation', 'Design data models based on requirements/needs for complex analysis of data analyst', 'Define requirements for vendors to implement into their proposed solutions to meet DoD customer’s organization needs and use cases', 'Experience working with multiple types of datasets and database technologies', 'Experience building data pipelines from end to end', 'Experience with multiple industry standard cloud and on-premise database technologies', 'Experience with data exploration, analysis, and visualization tools such as Python and Matlab', 'Experience and familiarity with Linux operating environment', 'Experience with open-source containerization technologies and tools and how to utilize those technologies as appropriately for database technologies and analytics', 'Define internal process improvements to automate repetitive tasks to minimize downtime between analysis', 'Clearance: Secret clearance to start', 'Must be able to obtain and maintain a TS/SCI security clearance with enhanced security checks', 'May require working in an office, industrial, or laboratory environment', 'Capable of climbing ladders and tolerating confined spaces and extreme temperature variances']","['This position will be performed at the DoD customer site at Wright-Patterson Air Force Base', 'Investigate, determine, and implement suitable open-source tools for storage, managing, and use of extremely large data sets', 'Investigate, determine, and implement tools and methodologies for extracting key data points for analysis by data analyst', 'Conducts data exploration, analysis, and feature extraction techniques to incorporate into DoD customer’s organization data pipelines and workflows', 'Be part of a team responsible for creating, maintaining, and augmenting an on-premises compute environment', 'Translating requirements into capabilities for technical teams', 'Present status reports to key internal stakeholders', 'Evaluate new tools, technologies, and processes to improve on-premises environment', 'Gain familiarity of customer mission to identify and/or develop data management and workflow solutions', 'Proposes solutions and strategies to unique challenges throughout the DoD customer’s organization', 'Linux system configuration and capacity planning for large scale data analytics on-premises and cloud', 'Additional duties as assigned or required']",True,[],,"['Data Pipelines', 'Feature Extraction', 'Data Exploration and Analysis', 'Open-Source Data Analytics Tools', 'Data Modeling', 'Python', 'MATLAB', 'SQL and Database Technologies', 'Linux Operating Environment', 'Containerization Technologies', 'Data Workflow Automation']","Data Pipelines: Building and maintaining end-to-end data pipelines to manage and process large datasets for analysis within the DoD customer’s organization.; Feature Extraction: Applying feature extraction techniques to prepare data for analysis and integration into workflows for the DoD customer.; Data Exploration and Analysis: Conducting exploratory data analysis to understand and extract insights from large datasets relevant to mission needs.; Open-Source Data Analytics Tools: Evaluating and implementing open-source tools for storage, management, and analysis of extremely large datasets.; Data Modeling: Designing data models based on requirements to support complex data analysis for the DoD customer.; Python: Using Python for data exploration, analysis, and visualization to support data-driven decision making.; MATLAB: Utilizing MATLAB for data analysis and visualization tasks within the data science workflows.; SQL and Database Technologies: Working with multiple types of datasets and database technologies, including cloud and on-premise databases, to support data storage and retrieval.; Linux Operating Environment: Configuring and managing Linux systems to support large-scale data analytics and compute environments.; Containerization Technologies: Using open-source containerization tools to deploy and manage database and analytics applications efficiently.; Data Workflow Automation: Defining process improvements to automate repetitive data analysis tasks and reduce downtime."
s5Fs7HUVGS5OvSfKAAAAAA==,"Senior Director, Advanced Analytics, Data Science & AI","About This Role

We are seeking a Sr Director of Advanced Analytics, Data Science & AI responsible for generating and delivering data-driven insights to support a brand, therapeutic area, or cross brand/enterprise and contribute to the development and enhancement of innovative capabilities. This role involves influencing business partners, leading the execution and interpretation of AI/ML models, framing problems, and crafting solutions, all while clearly and compellingly communicating data-driven insights.

This role is dynamic, fast-paced, highly collaborative, and covers a broad range of strategic topics that are critical to our business. To excel in this role, you must have a passion for data-driven problem solving, a strong background in data science and AI, and proven experience in leading and developing high-performing teams.

What You’ll Do:
• Provide an enterprise view of insights across Product / Brand and Therapeutic Areas (TA) on key topics like Resource Allocation, Measurement & attribution of market mix, channel optimization, digital analytics, predictive models, decision engine/next best action.
• Lead the development and implementation of data-driven solutions using advanced analytics and machine learning techniques, predictive algorithms, and AI-powered tools to extract actionable insights to drive US Commercial strategies and tactics.
• Manage and mentor a team of data scientists (internal and external) and AI experts to drive innovation and deliver high-quality results
• Influence end-to-end delivery of data science insights, from framing the business question, designing the solution, and delivering recommendations.
• Break down technical concepts into digestible insights and guide diverse stakeholders how to interpret.
• Collaborate Cross-Functionally:
• Collaborate within the insights & analytics team, coordinating efforts with the Insights & Analytics counterparts to develop and execute a comprehensive brand analytics plan.
• Deliver consolidated insights and actionable recommendations to US Commercial teams, ensuring alignment with strategic objectives and insights findings.
• Work closely with cross-functional teams to ensure seamless integration of brand analytics insights into decision-making processes and strategic initiatives.
• Define and track key performance indicators to measure the success and impact of data-driven solutions.
• Continuously evaluate and enhance existing brand /TA data science capabilities, identifying opportunities for optimization and innovation to drive greater business impact and ROI.
• Stay up to date with the latest advancements in data science and AI and apply them to improve processes and outcomes. Represent Biogen as a thought leader in data science and AI at conferences, events, and industry forums.
• Build university partnerships for driving innovation and leading-edge research technique
• Build strong relationships with key stakeholders across the enterprise, effectively communicating the value proposition of data science and fostering a culture of data-driven decision-making.
• Ensure compliance with data privacy and security regulations and maintain a high level of data integrity.
• Develop and manage budgets, resource allocation, and timelines for data science and AI projects.

Who You Are

You have a proven ability to prioritize and manage complex and innovative projects and establish vision and direction within a fast moving, challenging and energetic commercial environment. You are a highly collaborative and perceptive problem-solver with a demonstrated ability to synthesize strategic insights and drive innovation. You have exceptional and proven ability to influence, collaborate, and communicate with internal and external stakeholders at all levels.

Required Skills and Experience
• A minimum of 10 years of experience in advanced analytics in US commercial setting, previous experience in a biotech / pharmaceutical organization, or in leading global management consulting firm
• Minimum of bachelor's degree, preferably in engineering, economics, statistics, computer science, or related quantitative field
• A business leader that can contextualize the data science findings, recommendations and implications for the Business and be influential in decision making for topics like resource allocation, marketing mix optimizations and digital.
• Extensive expertise and experience with both traditional SQL and modern NoSQL data stores including SQL, and large-scale distributed systems such as Hadoop and or working in Snowflake/Databricks
• Strong experience with machine learning technology, such as: big data stack, Python, R, and visualization techniques
• Experience with pharmaceutical data sources such as IQVIA, SHS, Claims, and other syndicated resources; strong understanding of Patient/Claims data (APLD)
• Extensive experience using data science models to solve problems in a business environment setting
• Accountability for Results - focused on key strategic objectives, accountable for high standards of performance, and lead change
• Strategic Thinking & Problem Solving - Make decisions considering the long-term impact to customers, patients, employees, and the business.
• Patient & Customer Centricity - Maintain an ongoing focus on the needs of our customers and/or key stakeholders.
• Impactful Communication - Communicate with logic, clarity, and respect. Influence at all levels to achieve the best results for Biogen
• Respectful Collaboration - Seek and value others’ perspectives and strive for diverse partnerships to enhance work toward common goals.
• Empowered Development - Play an active role in professional development as a business imperative.

Job Level: Management

Additional Information

Base salary offered is determined through an analytical approach utilizing a combination of factors including, but not limited to, relevant skills & experience, job location, and internal equity.

Regular employees are eligible to receive both short term and long-term incentives, including cash bonus and equity incentive opportunities, designed to reward recent achievements and recognize your future potential based on individual, business unit and company performance.

In addition to compensation, Biogen offers a full and highly competitive range of benefits designed to support our employees’ and their families physical, financial, emotional, and social well-being; including, but not limited to:
• Medical, Dental, Vision, & Life insurances
• Fitness & Wellness programs including a fitness reimbursement
• Short- and Long-Term Disability insurance
• A minimum of 15 days of paid vacation and an additional end-of-year shutdown time off (Dec 26-Dec 31)
• Up to 12 company paid holidays + 3 paid days off for Personal Significance
• 80 hours of sick time per calendar year
• Paid Maternity and Parental Leave benefit
• 401(k) program participation with company matched contributions
• Employee stock purchase plan
• Tuition reimbursement of up to $10,000 per calendar year
• Employee Resource Groups participation

Why Biogen?

We are a global team with a commitment to excellence, and a pioneering spirit. As a mid-sized biotechnology company, we provide the stability and resources of a well-established business while fostering an environment where individual contributions make a significant impact. Our team encompasses some of the most talented and passionate achievers who have unparalleled opportunities for learning, growth, and expanding their skills. Above all, we work together to deliver life-changing medicines, with every role playing a vital part in our mission. Caring Deeply. Achieving Excellence. Changing Lives.

At Biogen, we are committed to building on our culture of inclusion and belonging that reflects the communities where we operate and the patients we serve. We know that diverse backgrounds, cultures, and perspectives make us a stronger and more innovative company, and we are focused on building teams where every employee feels empowered and inspired. Read on to learn more about our DE&I efforts.

All qualified applicants will receive consideration for employment without regard to sex, gender identity or expression, sexual orientation, marital status, race, color, national origin, ancestry, ethnicity, religion, age, veteran status, disability, genetic information or any other basis protected by federal, state or local law. Biogen is an E-Verify Employer in the United States.",2025-07-24T00:00:00.000Z,2025-07-25,"['To excel in this role, you must have a passion for data-driven problem solving, a strong background in data science and AI, and proven experience in leading and developing high-performing teams', 'You have a proven ability to prioritize and manage complex and innovative projects and establish vision and direction within a fast moving, challenging and energetic commercial environment', 'You are a highly collaborative and perceptive problem-solver with a demonstrated ability to synthesize strategic insights and drive innovation', 'You have exceptional and proven ability to influence, collaborate, and communicate with internal and external stakeholders at all levels', 'A minimum of 10 years of experience in advanced analytics in US commercial setting, previous experience in a biotech / pharmaceutical organization, or in leading global management consulting firm', ""Minimum of bachelor's degree, preferably in engineering, economics, statistics, computer science, or related quantitative field"", 'A business leader that can contextualize the data science findings, recommendations and implications for the Business and be influential in decision making for topics like resource allocation, marketing mix optimizations and digital', 'Extensive expertise and experience with both traditional SQL and modern NoSQL data stores including SQL, and large-scale distributed systems such as Hadoop and or working in Snowflake/Databricks', 'Strong experience with machine learning technology, such as: big data stack, Python, R, and visualization techniques', 'Experience with pharmaceutical data sources such as IQVIA, SHS, Claims, and other syndicated resources; strong understanding of Patient/Claims data (APLD)', 'Extensive experience using data science models to solve problems in a business environment setting', 'Accountability for Results - focused on key strategic objectives, accountable for high standards of performance, and lead change', 'Strategic Thinking & Problem Solving - Make decisions considering the long-term impact to customers, patients, employees, and the business', 'Patient & Customer Centricity - Maintain an ongoing focus on the needs of our customers and/or key stakeholders', 'Impactful Communication - Communicate with logic, clarity, and respect', 'Influence at all levels to achieve the best results for Biogen']","['We are seeking a Sr Director of Advanced Analytics, Data Science & AI responsible for generating and delivering data-driven insights to support a brand, therapeutic area, or cross brand/enterprise and contribute to the development and enhancement of innovative capabilities', 'This role involves influencing business partners, leading the execution and interpretation of AI/ML models, framing problems, and crafting solutions, all while clearly and compellingly communicating data-driven insights', 'This role is dynamic, fast-paced, highly collaborative, and covers a broad range of strategic topics that are critical to our business', 'Provide an enterprise view of insights across Product / Brand and Therapeutic Areas (TA) on key topics like Resource Allocation, Measurement & attribution of market mix, channel optimization, digital analytics, predictive models, decision engine/next best action', 'Lead the development and implementation of data-driven solutions using advanced analytics and machine learning techniques, predictive algorithms, and AI-powered tools to extract actionable insights to drive US Commercial strategies and tactics', 'Manage and mentor a team of data scientists (internal and external) and AI experts to drive innovation and deliver high-quality results', 'Influence end-to-end delivery of data science insights, from framing the business question, designing the solution, and delivering recommendations', 'Break down technical concepts into digestible insights and guide diverse stakeholders how to interpret', 'Collaborate Cross-Functionally:', 'Collaborate within the insights & analytics team, coordinating efforts with the Insights & Analytics counterparts to develop and execute a comprehensive brand analytics plan', 'Deliver consolidated insights and actionable recommendations to US Commercial teams, ensuring alignment with strategic objectives and insights findings', 'Work closely with cross-functional teams to ensure seamless integration of brand analytics insights into decision-making processes and strategic initiatives', 'Define and track key performance indicators to measure the success and impact of data-driven solutions', 'Continuously evaluate and enhance existing brand /TA data science capabilities, identifying opportunities for optimization and innovation to drive greater business impact and ROI', 'Stay up to date with the latest advancements in data science and AI and apply them to improve processes and outcomes', 'Represent Biogen as a thought leader in data science and AI at conferences, events, and industry forums', 'Build university partnerships for driving innovation and leading-edge research technique', 'Build strong relationships with key stakeholders across the enterprise, effectively communicating the value proposition of data science and fostering a culture of data-driven decision-making', 'Ensure compliance with data privacy and security regulations and maintain a high level of data integrity', 'Develop and manage budgets, resource allocation, and timelines for data science and AI projects', 'Respectful Collaboration - Seek and value others’ perspectives and strive for diverse partnerships to enhance work toward common goals', 'Empowered Development - Play an active role in professional development as a business imperative']",True,"['AI-Powered Tools', 'Artificial Intelligence']",AI-Powered Tools: Leveraged to extract actionable insights and enhance predictive modeling capabilities.; Artificial Intelligence: Applied alongside data science to develop innovative capabilities and solutions.,"['Advanced Analytics', 'Predictive Models', 'Machine Learning', 'SQL', 'NoSQL', 'Hadoop', 'Snowflake', 'Databricks', 'Python', 'R', 'Data Visualization', 'Pharmaceutical Data Sources', 'Market Mix Modeling', 'Channel Optimization', 'Decision Engine / Next Best Action', 'Key Performance Indicators (KPIs)', 'Data Privacy and Security']","Advanced Analytics: Used to generate and deliver data-driven insights supporting brand and therapeutic area strategies.; Predictive Models: Applied to forecast outcomes and support decision-making in US Commercial strategies.; Machine Learning: Employed to develop data-driven solutions and predictive algorithms for business problem solving.; SQL: Used for querying traditional relational databases to extract and manipulate data.; NoSQL: Utilized for handling modern, large-scale distributed data stores in analytics workflows.; Hadoop: Part of the big data stack used for distributed data processing and storage.; Snowflake: Cloud data platform used for scalable data warehousing and analytics.; Databricks: Platform for big data analytics and collaborative data science workflows.; Python: Programming language used for data science, machine learning, and analytics tasks.; R: Statistical programming language used for data analysis and visualization.; Data Visualization: Techniques applied to communicate data insights effectively to stakeholders.; Pharmaceutical Data Sources: Includes IQVIA, SHS, Claims, and syndicated resources used for patient and claims data analysis.; Market Mix Modeling: Used for measurement and attribution of marketing channel effectiveness.; Channel Optimization: Applied to improve marketing and sales channel performance using data insights.; Decision Engine / Next Best Action: Data-driven systems designed to recommend optimal business actions.; Key Performance Indicators (KPIs): Defined and tracked to measure success and impact of data-driven solutions.; Data Privacy and Security: Ensured compliance to maintain data integrity and protect sensitive information."
0X-dVx1GOIhD9Oj1AAAAAA==,Data Scientist - Technology Consulting - AI and Data - GPS - Manager - Multiple Positions - 1623873,"EY focuses on high-ethical standards and integrity among its employees and expects all candidates to demonstrate these qualities.

At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better. Join us and build an exceptional experience for yourself, and a better working world for all. The exceptional EY experience. It's yours to build.

Data Scientist, Technology Consulting, AI & Data, Government & Public Sector (Manager) (Multiple Positions) (1623873), EY Government Services LLC.

Provide a full range of consulting services to help State, Local and Education clients implement new ideas to help achieve their mission outcomes by delivering a unique perspective on how data science and analytics can transform and improve their entire organization. Apply data mining and statistical analysis techniques like hypothesis testing, segmentation, and modelling to analyze large amounts of data. Deliver the latest data science and big data technologies and practices to design, build and maintain scalable and robust solutions that unify, enrich and analyze data from multiple sources. Help clients make data-driven decisions by working with structured and unstructured data sets, building out predictive models and advise clients on data mining leading practices. Unify, enrich, and analyze client data to derive new insights and opportunities. Leverage in-house data platforms as needed and recommend and build new data platforms/solutions as required to exceed client’s requirements. Build and apply data analysis algorithms (data mining, statistics, machine learning, natural language processing, sentiment analysis, text mining, etc.) as appropriate. Communicate findings, recommendations, and opportunities to clients to improve data systems and solutions. Apply data driven approach (KPIs) in tying technology solutions to specific business outcomes. Share leading practices and insights about current industry or subject-matter topics with EY US leaders, proposal teams and clients. Manage and motivate teams with diverse skills and backgrounds.

Consistently deliver quality client services by monitoring progress. Demonstrate in-depth technical capabilities and professional knowledge. Maintain long-term client relationships and networks. Cultivate business development opportunities.

Full time employment, Monday – Friday, 40 hours per week, 8:30 am – 5:30 pm.

MINIMUM REQUIREMENTS:

Must have a Bachelor's degree in Mathematics, Information Systems, Statistics, Operations Research, Analytics, Computer Science, Engineering, Data Science, Machine Learning, or a related field, and 5 years of progressive, post-baccalaureate work experience. Alternatively, will accept a Master's degree in Mathematics, Information Systems, Statistics, Operations Research, Analytics, Computer Science, Engineering, Data Science, Machine Learning, or a related field and 4 years of work experience.

Must have 4 years of advisory and/or consulting experience.

Must have 4 years hands-on experience with one or a combination of the following: data science, big data, and/or data engineering.

Must have 3 years of experience connecting data sources and structures in one or a combination of any of the following: APIs, NoSQL, RDBMS, Hadoop, S3, SQL, Hive, Pig, and/or Blob Storage.

Must have 3 years of experience with advanced statistical modeling.

Must have 2 years of experience in at least one of the following: R, Python, Java, C#, or Scala.

Must have 2 years of experience in each of the following:- machine learning such as k-NN, naive bayes, decision trees, or SVM
- data mining and statistical tools
- pattern recognition and predictive modelling
- recommendation engines, scoring systems, A/B testing
- setting up data and experimental platforms.

Must have 2 years of hands-on experience with various big data technologies in at least one of the following ecosystems: Google, AWS, or Microsoft.

Must have 4 years of experience working with tools/libraries including with one or combination of any of the following: Python, Panda, and/or R.

Must have 2 years of experience of leading, coaching, mentoring and performance assessment of all levels of staff.

Requires domestic travel up to 30% to serve client needs.

Employer will accept any suitable combination of education, training, or experience.

Please apply on-line at ey.com/en_us/careers and click on ""Careers - Job Search”, then “Search Jobs"" (Job Number - 1623873).

What we offer

We offer a comprehensive compensation and beneﬁts package where you’ll be rewarded based on your performance and recognized for the value you bring to the business. The base salary for this job is $186,660.00 per year. In addition, our Total Rewards package includes medical and dental coverage, pension and 401(k) plans, and a wide range of paid time off options. Join us in our team-led and leader-enabled hybrid model. Our expectation is for most people in external, client serving roles to work together in person 40-60% of the time over the course of an engagement, project or year. Under our ﬂexible vacation policy, you’ll decide how much vacation time you need based on your own personal circumstances. You’ll also be granted time off for designated EY Paid Holidays, Winter/Summer breaks, Personal/Family Care, and other leaves of absence when needed to support your physical, ﬁnancial, and emotional well-being.

• Continuous learning: You’ll develop the mindset and skills to navigate whatever comes next.
• Success as defined by you: We’ll provide the tools and flexibility, so you can make a meaningful impact, your way.
• Transformative leadership: We’ll give you the insights, coaching and confidence to be the leader the world needs.
• Diverse and inclusive culture: You’ll be embraced for who you are and empowered to use your voice to help others find theirs.

EY accepts applications for this position on an on-going basis. If you can demonstrate that you meet the criteria above, please contact us as soon as possible.

The exceptional EY experience. It’s yours to build.
EY | Building a better working world

EY exists to build a better working world, helping to create long-term value for clients, people and society and build trust in the capital markets.

Enabled by data and technology, diverse EY teams in over 150 countries provide trust through assurance and help clients grow, transform and operate.

Working across assurance, consulting, law, strategy, tax and transactions, EY teams ask better questions to find new answers for the complex issues facing our world today.

For those living in California, please click here for additional information.

EY provides equal employment opportunities to applicants and employees without regard to race, color, religion, age, sex, sexual orientation, gender identity/expression, pregnancy, genetic information, national origin, protected veteran status, disability status, or any other legally protected basis, including arrest and conviction records, in accordance with applicable law. 

EY is committed to providing reasonable accommodation to qualified individuals with disabilities, including veterans with disabilities. If you have a disability and either need assistance applying online or need to request an accommodation during any part of the application process, please call 1-800-EY-HELP3, type Option 2 (HR-related inquiries) and then type Option 1 (HR Shared Services Center), which will route you to EY’s Talent Shared Services Team or email SSC Customer Support at ssc.customersupport@ey.com.

This particular position at Ernst & Young in the United States requires the qualified candidate to be a ""United States worker"" as defined by the U.S. Department of Labor regulations at 20 CFR 656.3. You can review this definition at https://www.gpo.gov/fdsys/pkg/CFR-2011-title20-vol3/pdf/CFR-2011-title20-vol3-sec656-3.pdf at the bottom of page 750. Please feel free to apply to other positions that do not require you to be a ""U.S. worker"".",2025-07-10T00:00:00.000Z,2025-07-25,"[""Must have a Bachelor's degree in Mathematics, Information Systems, Statistics, Operations Research, Analytics, Computer Science, Engineering, Data Science, Machine Learning, or a related field, and 5 years of progressive, post-baccalaureate work experience"", ""Alternatively, will accept a Master's degree in Mathematics, Information Systems, Statistics, Operations Research, Analytics, Computer Science, Engineering, Data Science, Machine Learning, or a related field and 4 years of work experience"", 'Must have 4 years of advisory and/or consulting experience', 'Must have 4 years hands-on experience with one or a combination of the following: data science, big data, and/or data engineering', 'Must have 3 years of experience connecting data sources and structures in one or a combination of any of the following: APIs, NoSQL, RDBMS, Hadoop, S3, SQL, Hive, Pig, and/or Blob Storage', 'Must have 3 years of experience with advanced statistical modeling', 'Must have 2 years of experience in at least one of the following: R, Python, Java, C#, or Scala', 'Must have 2 years of experience in each of the following:- machine learning such as k-NN, naive bayes, decision trees, or SVM', 'data mining and statistical tools', 'pattern recognition and predictive modelling', 'recommendation engines, scoring systems, A/B testing', 'setting up data and experimental platforms', 'Must have 2 years of hands-on experience with various big data technologies in at least one of the following ecosystems: Google, AWS, or Microsoft', 'Must have 4 years of experience working with tools/libraries including with one or combination of any of the following: Python, Panda, and/or R', 'Must have 2 years of experience of leading, coaching, mentoring and performance assessment of all levels of staff', 'Requires domestic travel up to 30% to serve client needs', 'Employer will accept any suitable combination of education, training, or experience', 'Success as defined by you: We’ll provide the tools and flexibility, so you can make a meaningful impact, your way', 'Transformative leadership: We’ll give you the insights, coaching and confidence to be the leader the world needs']","['Provide a full range of consulting services to help State, Local and Education clients implement new ideas to help achieve their mission outcomes by delivering a unique perspective on how data science and analytics can transform and improve their entire organization', 'Apply data mining and statistical analysis techniques like hypothesis testing, segmentation, and modelling to analyze large amounts of data', 'Deliver the latest data science and big data technologies and practices to design, build and maintain scalable and robust solutions that unify, enrich and analyze data from multiple sources', 'Help clients make data-driven decisions by working with structured and unstructured data sets, building out predictive models and advise clients on data mining leading practices', 'Unify, enrich, and analyze client data to derive new insights and opportunities', 'Leverage in-house data platforms as needed and recommend and build new data platforms/solutions as required to exceed client’s requirements', 'Build and apply data analysis algorithms (data mining, statistics, machine learning, natural language processing, sentiment analysis, text mining, etc.)', 'Communicate findings, recommendations, and opportunities to clients to improve data systems and solutions', 'Apply data driven approach (KPIs) in tying technology solutions to specific business outcomes', 'Share leading practices and insights about current industry or subject-matter topics with EY US leaders, proposal teams and clients', 'Manage and motivate teams with diverse skills and backgrounds', 'Consistently deliver quality client services by monitoring progress', 'Demonstrate in-depth technical capabilities and professional knowledge', 'Maintain long-term client relationships and networks', 'Cultivate business development opportunities', 'Full time employment, Monday – Friday, 40 hours per week, 8:30 am – 5:30 pm']",True,[],,"['Data Mining', 'Statistical Analysis', 'Predictive Modeling', 'Machine Learning', 'Natural Language Processing', 'A/B Testing', 'Big Data Technologies', 'Data Engineering', 'Advanced Statistical Modeling', 'Python', 'R', 'Pandas', 'Recommendation Engines', 'Pattern Recognition', 'Data Platforms', 'Segmentation', 'Hypothesis Testing']","Data Mining: Used to extract patterns and insights from large datasets to support client decision-making and improve organizational outcomes.; Statistical Analysis: Applied techniques such as hypothesis testing and segmentation to analyze data and build predictive models for clients.; Predictive Modeling: Building models to forecast outcomes and support data-driven decisions for clients in government and public sectors.; Machine Learning: Utilized algorithms like k-NN, naive Bayes, decision trees, and SVM to develop data-driven solutions and recommendation engines.; Natural Language Processing: Applied NLP techniques including sentiment analysis and text mining to analyze unstructured data for client insights.; A/B Testing: Used experimental platforms to evaluate and optimize client solutions through controlled testing.; Big Data Technologies: Experience with ecosystems such as Google, AWS, Microsoft, and tools like Hadoop, Hive, Pig, and Blob Storage to manage and analyze large-scale data.; Data Engineering: Connecting and integrating data sources using APIs, NoSQL, RDBMS, SQL, and cloud storage to build scalable data platforms.; Advanced Statistical Modeling: Developing complex statistical models to support data analysis and predictive insights for clients.; Python: Used for data analysis, machine learning, and building data science solutions with libraries such as Pandas.; R: Applied for statistical computing and data analysis in client projects.; Pandas: Utilized as a data manipulation and analysis library within Python to process structured data.; Recommendation Engines: Developed scoring systems and recommendation models to enhance client decision-making.; Pattern Recognition: Applied to identify trends and anomalies in data to support predictive modeling.; Data Platforms: Designed and maintained scalable data platforms to unify and enrich client data from multiple sources.; Segmentation: Used to categorize data into meaningful groups to improve analysis and targeting.; Hypothesis Testing: Employed to validate assumptions and support data-driven conclusions in client projects."
iqNcZ9-ZrCJwa25CAAAAAA==,Data Scientist for Financial Planning & Analysis (FP&A),"Description
The Leidos Corporate Financial Planning & Analysis (FP&A) team is looking for an experienced Data Scientist with an entrepreneur's mindset to support a new team working on projects to improve our Enterprise financial analytics and forecasting. The position will collaborate with the VP of FP&A in building a Data Analytics Team within Finance. You should be strongly experienced in Python coding and visualization building skills and have knowledge of commonly used ML libraries (SciKit-learn). Data Engineering and ML Ops experience is a plus!

We are looking for someone who is intellectually adaptive, likes to collaborate, inquisitive, and capable of conducting original science.

The FP&A Data & Analytics team will collaborate closely with Leidos' AI Accelerator team which includes junior and senior research/data scientists and data engineers with expertise in information retrieval, UI development, information science, machine learning and artificial intelligence, and statistics.

The Data Scientist will be expected to build statistical models, test hypotheses, interpret, summarize, visualize, and succinctly report on data findings. The Scientist will leverage automation and machine learning to manage data, predict scenarios and make recommendations. The data scientist will partner with business and operational leaders to provide an impact by leveraging data and analytical tools, strategic thinking, and hypothesis-based analysis on machine learning (ML)-based projects. The data scientist is responsible for modeling complex business problems through statistical, algorithmic, mining, and visualization techniques. Further, they will support senior leadership by creating business insights, reports, and analyses to aid in the decision-making process.

Responsibilities:
• Translates business needs into analytics/reporting requirements to support executive decisions and workflows with required information
• Performs large-scale experimentation and builds data-driven models to answer business questions
• Proactively mines data warehouses to identify trends and patterns and generates insights for business units and senior leadership
• Performs large-scale experimentation to identify hidden relationships between variables in large datasets
• Researches and implements cutting-edge techniques and tools in machine learning/deep learning/artificial intelligence to make data analysis more efficient
• Designs and conducts data analyses with the highest standard of rigor and scientific accuracy; this includes study design, methodology, algorithms, and statistical modeling
• Analyzes data provided to identify trends, inform decisions
• Supports developmental plans based on data findings related to program, personnel, training needs
• Supports development and maintenance of primary program database and run interval reporting
• Implements appropriate modeling and data science strategies required to address customer needs
• Communicates results and methods for solutions to internal and external stakeholders
• Designs, builds, trains, and evaluates machine learning models

Basic Qualifications:
• Bachelor's degree in Computer Science, Data Science, Data Engineering or related field with 2+ years of relevant experience
• Strong experience with Python as well as fluency in multiple programming languages and statistical analysis tools such as C++, JavaScript, R, SAS, Excel, SQL, MATLAB, SPSS
• Experience /familiarity with frequentist statistics and probability including predicative modeling
• Experience with data repositories and reporting tools
• Good understanding of machine learning algorithms, tools and platforms
• Experience with AI/ML tools, such as common Python packages (e.g., scikit-learn, NumPy, Pandas) and Jupyter notebooks
• Experience with time series modeling, causal inference, or probabilistic forecasting models.
• Experience with tabular data analysis using languages such as SQL, R, and/or Python
• Experience with statistical modeling and data analysis
• Understanding of transformers and foundation models
• Self-starter with high intellectual curiosity
• Great communication skills, able to explain model results to a non-technical audience
• Proficient in data exploration techniques and tools
• Ability to work in a cross functional team as this position will be under the Finance function but have opportunity to collaborate with the AI Accelerator team
• US citizenship is required and able to obtain security clearance as needed.

Preferred Qualifications:
• Experience with data visualization libraries such as Plotly, Streamlit, and matplotlib
• Willing to learn new skills and platforms to support data analytics
• Candidates will ideally have a specialization in ML or AI
• Experience with database technologies such as SQL, NoSQL, Oracle, Hadoop, or Teradata
• Proficient in data exploration techniques and tools such as Amazon Web Services (AWS)
• Experience with MLOps tools and frameworks, such as Kubeflow, MLflow, DVC, TensorBoard
• Ability to design, build, and deploy data solutions that capture, explore, transform, and utilize data to support AI, ML, and BI
• Experience with data repositories and ETL
• Knowledge of how to design and implement high-volume data ingestion and streaming pipelines using Open Source frameworks like Apache Spark, Flink, Nifi, and Kafka on AWS Cloud
• Ability to integrate data from different sources, including databases, data warehouses, APIs, and external system

Original Posting Date: 2024-12-17While subject to change based on business needs, Leidos reasonably anticipates that this job requisition will remain open for at least 3 days with an anticipated close date of no earlier than 3 days after the original posting date as listed above.

Pay Range: Pay Range $67,600.00 - $122,200.00
The Leidos pay range for this job level is a general guideline only and not a guarantee of compensation or salary. Additional factors considered in extending an offer include (but are not limited to) responsibilities of the job, education, experience, knowledge, skills, and abilities, as well as internal equity, alignment with market data, applicable bargaining agreement (if any), or other law.
About Leidos Leidos is a Fortune 500® innovation company rapidly addressing the world's most vexing challenges in national security and health. The company's global workforce of 47,000 collaborates to create smarter technology solutions for customers in heavily regulated industries. Headquartered in Reston, Virginia, Leidos reported annual revenues of approximately $15.4 billion for the fiscal year ended December 29, 2023. For more information, visit www.Leidos.com .
Pay and Benefits Pay and benefits are fundamental to any career decision. That's why we craft compensation packages that reflect the importance of the work we do for our customers. Employment benefits include competitive compensation, Health and Wellness programs, Income Protection, Paid Leave and Retirement. More details are available here .
Securing Your Data Beware of fake employment opportunities using Leidos' name. Leidos will never ask you to provide payment-related information during any part of the employment application process (i.e., ask you for money), nor will Leidos ever advance money as part of the hiring process (i.e., send you a check or money order before doing any work). Further, Leidos will only communicate with you through emails that are generated by the Leidos.com automated system - never from free commercial services (e.g., Gmail, Yahoo, Hotmail) or via WhatsApp, Telegram, etc. If you received an email purporting to be from Leidos that asks for payment-related information or any other person a l information (e.g., about you or your previous employer), and you are concerned about its legitimacy, please make us aware immediately by emailing us at [email protected] .
If you believe you are the victim of a scam, contact your local law enforcement and report the incident to the U.S. Federal Trade Commission .
Commitment to Diversity All qualified applicants will receive consideration for employment without regard to sex, race, ethnicity, age, national origin, citizenship, religion, physical or mental disability, medical condition, genetic information, pregnancy, family structure, marital status, ancestry, domestic partner status, sexual orientation, gender identity or expression, veteran or military status, or any other basis prohibited by law. Leidos will also consider for employment qualified applicants with criminal histories consistent with relevant laws.",,2025-07-25,"['You should be strongly experienced in Python coding and visualization building skills and have knowledge of commonly used ML libraries (SciKit-learn)', 'We are looking for someone who is intellectually adaptive, likes to collaborate, inquisitive, and capable of conducting original science', ""Bachelor's degree in Computer Science, Data Science, Data Engineering or related field with 2+ years of relevant experience"", 'Strong experience with Python as well as fluency in multiple programming languages and statistical analysis tools such as C++, JavaScript, R, SAS, Excel, SQL, MATLAB, SPSS', 'Experience /familiarity with frequentist statistics and probability including predicative modeling', 'Experience with data repositories and reporting tools', 'Good understanding of machine learning algorithms, tools and platforms', 'Experience with AI/ML tools, such as common Python packages (e.g., scikit-learn, NumPy, Pandas) and Jupyter notebooks', 'Experience with time series modeling, causal inference, or probabilistic forecasting models', 'Experience with tabular data analysis using languages such as SQL, R, and/or Python', 'Experience with statistical modeling and data analysis', 'Understanding of transformers and foundation models', 'Self-starter with high intellectual curiosity', 'Great communication skills, able to explain model results to a non-technical audience', 'Proficient in data exploration techniques and tools', 'Ability to work in a cross functional team as this position will be under the Finance function but have opportunity to collaborate with the AI Accelerator team', 'US citizenship is required and able to obtain security clearance as needed', 'Original Posting Date: 2024-12-17While subject to change based on business needs, Leidos reasonably anticipates that this job requisition will remain open for at least 3 days with an anticipated close date of no earlier than 3 days after the original posting date as listed above']","['The position will collaborate with the VP of FP&A in building a Data Analytics Team within Finance', 'The Data Scientist will be expected to build statistical models, test hypotheses, interpret, summarize, visualize, and succinctly report on data findings', 'The Scientist will leverage automation and machine learning to manage data, predict scenarios and make recommendations', 'The data scientist will partner with business and operational leaders to provide an impact by leveraging data and analytical tools, strategic thinking, and hypothesis-based analysis on machine learning (ML)-based projects', 'The data scientist is responsible for modeling complex business problems through statistical, algorithmic, mining, and visualization techniques', 'Further, they will support senior leadership by creating business insights, reports, and analyses to aid in the decision-making process', 'Translates business needs into analytics/reporting requirements to support executive decisions and workflows with required information', 'Performs large-scale experimentation and builds data-driven models to answer business questions', 'Proactively mines data warehouses to identify trends and patterns and generates insights for business units and senior leadership', 'Performs large-scale experimentation to identify hidden relationships between variables in large datasets', 'Researches and implements cutting-edge techniques and tools in machine learning/deep learning/artificial intelligence to make data analysis more efficient', 'Designs and conducts data analyses with the highest standard of rigor and scientific accuracy; this includes study design, methodology, algorithms, and statistical modeling', 'Analyzes data provided to identify trends, inform decisions', 'Supports developmental plans based on data findings related to program, personnel, training needs', 'Supports development and maintenance of primary program database and run interval reporting', 'Implements appropriate modeling and data science strategies required to address customer needs', 'Communicates results and methods for solutions to internal and external stakeholders', 'Designs, builds, trains, and evaluates machine learning models']",True,"['Transformers', 'Deep Learning', 'Artificial Intelligence']",Transformers: Understanding of transformer models and foundation models relevant to AI Accelerator collaboration.; Deep Learning: Research and implementation of deep learning techniques to enhance data analysis efficiency.; Artificial Intelligence: Application of AI methods alongside machine learning to improve financial analytics and forecasting.,"['Python', 'scikit-learn', 'Statistical Modeling', 'Frequentist Statistics', 'Time Series Modeling', 'Causal Inference', 'Probabilistic Forecasting', 'SQL', 'R', 'Pandas', 'NumPy', 'Jupyter Notebooks', 'Data Visualization Libraries', 'Data Warehouses', 'Data Exploration Techniques', 'Machine Learning Algorithms', 'MLOps', 'Data Engineering', 'ETL Pipelines', 'Apache Spark', 'Apache Flink', 'Apache NiFi', 'Apache Kafka', 'SQL Databases', 'NoSQL Databases', 'Amazon Web Services (AWS)']","Python: Primary programming language used for coding, data analysis, and building visualization in the role.; scikit-learn: Machine learning library used for building and evaluating ML models in financial analytics.; Statistical Modeling: Used to build models, test hypotheses, and analyze data to support financial decision-making.; Frequentist Statistics: Statistical approach applied for predictive modeling and hypothesis testing in financial data analysis.; Time Series Modeling: Applied for forecasting and analyzing temporal financial data trends.; Causal Inference: Used to identify cause-effect relationships within financial datasets to inform decisions.; Probabilistic Forecasting: Technique for predicting future financial scenarios with uncertainty quantification.; SQL: Language used for querying and managing tabular financial data from databases.; R: Statistical programming language used for data analysis and modeling.; Pandas: Python library used for data manipulation and analysis of tabular financial data.; NumPy: Python library for numerical computing supporting data processing tasks.; Jupyter Notebooks: Interactive environment used for developing and sharing data analyses and ML experiments.; Data Visualization Libraries: Tools like Plotly, Streamlit, and matplotlib used to create visual reports and dashboards.; Data Warehouses: Large-scale repositories mined to identify trends and patterns in financial data.; Data Exploration Techniques: Methods and tools used to investigate and understand financial datasets.; Machine Learning Algorithms: Algorithms applied to build predictive models and automate financial scenario analysis.; MLOps: Frameworks like Kubeflow, MLflow, and DVC used to manage ML lifecycle and deployment.; Data Engineering: Design and implementation of data pipelines and integration from multiple sources for analytics.; ETL Pipelines: Processes to extract, transform, and load financial data into usable formats for analysis.; Apache Spark: Open-source framework used for high-volume data processing and streaming in financial analytics.; Apache Flink: Framework for real-time data streaming and processing relevant to financial data ingestion.; Apache NiFi: Tool for automating data flow between systems, supporting data ingestion and integration.; Apache Kafka: Distributed streaming platform used for real-time data pipelines in financial data systems.; SQL Databases: Relational database technologies like Oracle and Teradata used for storing financial data.; NoSQL Databases: Non-relational databases used for flexible storage of diverse financial data types.; Amazon Web Services (AWS): Cloud platform supporting data storage, processing, and analytics infrastructure."
IAfRu9R8YRzc6ycbAAAAAA==,Data Science Analyst II-Geriatric and Palliative Medicine,"Description

The Data Science Analyst II collaborates with stakeholders from across the organization to develop sophisticated analytics to provide information, insights and BI (Business Intelligence) solutions that contribute to sound strategic planning, decision-making, goal setting, and effective performance measurement. The Data Science Analyst II demonstrates sound and a more advanced understanding of the healthcare domain, technical data manipulation and analytic development skills and impact the patient community of the Mount Sinai Health System.

Responsibilities
• Analyzes data requests using information technology, enrollment, claims, pharmacy, clinical, contract, medical management, financial, administrative and other corporate data from both modeled and disparate internal and external sources.
• Responsible for one or more stakeholder groups
• Takes a proactive role as liaison/analyst for internal stakeholders, understands their needs and translates them into reporting and analytic solutions.
• Effectively communicates with stakeholders and customers and ensures all requests are properly triaged, recorded and tracked.
• Adheres to corporate standards for performance metrics, data collection, data integrity, query design, and reporting format to ensure high quality, meaningful analytic output.
• Helps identify and understand data from internal and external sources for competitive, scenario and performance analyses, and financial modeling to gain member/provider insight into new and existing processes and business opportunities.
• Works closely with IT on the ongoing improvement of Mount Sinai’s integrated data warehouse, driven by strategic and business needs, and designed to ensure data and reporting consistency throughout the organization.
• Develops and maintains project work plans, including critical tasks, milestones, timelines, interdependencies and contingencies. Tracks and reports progress. Keeps stakeholders apprised of project status and implications for completion.
• Provides technical support to data analytics functions as they relate to varied business units, and technical expertise on the selection, development and implementation of various reporting and BI tools tied to business unit reporting requirements. Creates new BI reports and interactive dashboards as required.
• Prepares clear, well-organized project-specific documentation, including, at a minimum, analytic methods used, key decision points and caveats, with sufficient detail to support comprehension and replication.
• Ensures customers are adequately trained to use self-service BI tools and dashboards.
• Mentors level I Analysts, and teaches others within the organization on how to a) define meaningful process and performance measures, b) develop BI queries, and c) generate and use management reports effectively.
• Shares development and process knowledge with other analysts in order to assure redundancy and continuously builds a core of analytical strength within the organization.
• Demonstrates advanced level proficiency with the principles and methodologies of process improvement. Applies these in the execution of responsibilities in support of a process focused approach.

Qualifications
• BA or BS degree minimum, in a relevant field of study; Masters degree preferred.
• 5 years minimum in analytics development expertise, preferably in health care, or for a health provider, health plan or accountable care organization, including either:
• Working knowledge of a health care EMR such as Epic/Clarity, aCW, etc.; a payor claims system such as Facets, Amisys, etc.; or a hospital/provider system such as IDX, Soarian, etc.
• Knowledge of the New York State Medicaid and CMS Medicare regulations and related reporting requirements, such as STARS,QARR, MMCOR, MEDS, RAPS and HEDIS is a strong plus.
• Experience working in a health plan or consulting actuarial, financial reporting or medical economics departments highly valuable.
• Experience as a nurse informaticist highly valuable.
• Experience working in healthcare provider analytics related to revenue modeling, managed care contracting, population management, case management, clinical or financial decision report
• PhD, MD or DO program may be substituted for three years of experience.

, 851 - Geriatrics and Palliative Care - ISM, Icahn School of Medicine

Employer Description

Strength through Unity and Inclusion

The Mount Sinai Health System is committed to fostering an environment where everyone can contribute to excellence. We share a common dedication to delivering outstanding patient care. When you join us, you become part of Mount Sinai’s unparalleled legacy of achievement, education, and innovation as we work together to transform healthcare. We encourage all team members to actively participate in creating a culture that ensures fair access to opportunities, promotes inclusive practices, and supports the success of every individual.

At Mount Sinai, our leaders are committed to fostering a workplace where all employees feel valued, respected, and empowered to grow. We strive to create an environment where collaboration, fairness, and continuous learning drive positive change, improving the well-being of our staff, patients, and organization. Our leaders are expected to challenge outdated practices, promote a culture of respect, and work toward meaningful improvements that enhance patient care and workplace experiences. We are dedicated to building a supportive and welcoming environment where everyone has the opportunity to thrive and advance professionally. Explore this opportunity and be part of the next chapter in our history.

About the Mount Sinai Health System:

Mount Sinai Health System is one of the largest academic medical systems in the New York metro area, with more than 48,000 employees working across eight hospitals, more than 400 outpatient practices, more than 300 labs, a school of nursing, and a leading school of medicine and graduate education. Mount Sinai advances health for all people, everywhere, by taking on the most complex health care challenges of our time — discovering and applying new scientific learning and knowledge; developing safer, more effective treatments; educating the next generation of medical leaders and innovators; and supporting local communities by delivering high-quality care to all who need it. Through the integration of its hospitals, labs, and schools, Mount Sinai offers comprehensive health care solutions from birth through geriatrics, leveraging innovative approaches such as artificial intelligence and informatics while keeping patients’ medical and emotional needs at the center of all treatment. The Health System includes more than 9,000 primary and specialty care physicians; 13 joint-venture outpatient surgery centers throughout the five boroughs of New York City, Westchester, Long Island, and Florida; and more than 30 affiliated community health centers. We are consistently ranked by U.S. News & World Report's Best Hospitals, receiving high ""Honor Roll"" status, and are highly ranked: No. 1 in Geriatrics, top 5 in Cardiology/Heart Surgery, and top 20 in Diabetes/Endocrinology, Gastroenterology/GI Surgery, Neurology/Neurosurgery, Orthopedics, Pulmonology/Lung Surgery, Rehabilitation, and Urology. New York Eye and Ear Infirmary of Mount Sinai is ranked No. 12 in Ophthalmology. U.S. News & World Report’s “Best Children’s Hospitals” ranks Mount Sinai Kravis Children's Hospital among the country’s best in several pediatric specialties. The Icahn School of Medicine at Mount Sinai is ranked No. 11 nationwide in National Institutes of Health funding and in the 99th percentile in research dollars per investigator according to the Association of American Medical Colleges. Newsweek’s “The World’s Best Smart Hospitals” ranks The Mount Sinai Hospital as No. 1 in New York and in the top five globally, and Mount Sinai Morningside in the top 20 globally.

Equal Opportunity Employer

The Mount Sinai Health System is an equal opportunity employer, complying with all applicable federal civil rights laws. We do not discriminate, exclude, or treat individuals differently based on race, color, national origin, age, religion, disability, sex, sexual orientation, gender, veteran status, or any other characteristic protected by law. We are deeply committed to fostering an environment where all faculty, staff, students, trainees, patients, visitors, and the communities we serve feel respected and supported. Our goal is to create a healthcare and learning institution that actively works to remove barriers, address challenges, and promote fairness in all aspects of our organization.

Compensation

The Mount Sinai Health System (MSHS) provides salary ranges that comply with the New York City Law on Salary Transparency in Job Advertisements. The salary range for the role is $99999.98 - $121366.93 Annually. Actual salaries depend on a variety of factors, including experience, education, and operational need. The salary range or contractual rate listed does not include bonuses/incentive, differential pay or other forms of compensation or benefits.",2025-06-27T00:00:00.000Z,2025-07-25,"['5 years minimum in analytics development expertise, preferably in health care, or for a health provider, health plan or accountable care organization, including either:', 'Working knowledge of a health care EMR such as Epic/Clarity, aCW, etc.; a payor claims system such as Facets, Amisys, etc.; or a hospital/provider system such as IDX, Soarian, etc', 'Knowledge of the New York State Medicaid and CMS Medicare regulations and related reporting requirements, such as STARS,QARR, MMCOR, MEDS, RAPS and HEDIS is a strong plus', 'Experience working in a health plan or consulting actuarial, financial reporting or medical economics departments highly valuable', 'Experience as a nurse informaticist highly valuable', 'Experience working in healthcare provider analytics related to revenue modeling, managed care contracting, population management, case management, clinical or financial decision report', 'PhD, MD or DO program may be substituted for three years of experience']","['The Data Science Analyst II collaborates with stakeholders from across the organization to develop sophisticated analytics to provide information, insights and BI (Business Intelligence) solutions that contribute to sound strategic planning, decision-making, goal setting, and effective performance measurement', 'The Data Science Analyst II demonstrates sound and a more advanced understanding of the healthcare domain, technical data manipulation and analytic development skills and impact the patient community of the Mount Sinai Health System', 'Analyzes data requests using information technology, enrollment, claims, pharmacy, clinical, contract, medical management, financial, administrative and other corporate data from both modeled and disparate internal and external sources', 'Responsible for one or more stakeholder groups', 'Takes a proactive role as liaison/analyst for internal stakeholders, understands their needs and translates them into reporting and analytic solutions', 'Effectively communicates with stakeholders and customers and ensures all requests are properly triaged, recorded and tracked', 'Adheres to corporate standards for performance metrics, data collection, data integrity, query design, and reporting format to ensure high quality, meaningful analytic output', 'Helps identify and understand data from internal and external sources for competitive, scenario and performance analyses, and financial modeling to gain member/provider insight into new and existing processes and business opportunities', 'Works closely with IT on the ongoing improvement of Mount Sinai’s integrated data warehouse, driven by strategic and business needs, and designed to ensure data and reporting consistency throughout the organization', 'Develops and maintains project work plans, including critical tasks, milestones, timelines, interdependencies and contingencies', 'Tracks and reports progress', 'Keeps stakeholders apprised of project status and implications for completion', 'Provides technical support to data analytics functions as they relate to varied business units, and technical expertise on the selection, development and implementation of various reporting and BI tools tied to business unit reporting requirements', 'Creates new BI reports and interactive dashboards as required', 'Prepares clear, well-organized project-specific documentation, including, at a minimum, analytic methods used, key decision points and caveats, with sufficient detail to support comprehension and replication', 'Ensures customers are adequately trained to use self-service BI tools and dashboards', 'Mentors level I Analysts, and teaches others within the organization on how to a) define meaningful process and performance measures, b) develop BI queries, and c) generate and use management reports effectively', 'Shares development and process knowledge with other analysts in order to assure redundancy and continuously builds a core of analytical strength within the organization', 'Demonstrates advanced level proficiency with the principles and methodologies of process improvement', 'Applies these in the execution of responsibilities in support of a process focused approach']",True,[],,"['Business Intelligence', 'Data Warehousing', 'Healthcare Data Analytics', 'Financial Modeling', 'Performance Metrics', 'Self-Service BI Tools', 'Data Integrity and Query Design', 'Stakeholder Analytics Liaison', 'Healthcare EMR and Claims Systems', 'Regulatory Reporting Standards', 'Process Improvement Methodologies', 'Interactive Dashboards']","Business Intelligence: Used to develop reporting and analytic solutions that support strategic planning, decision-making, and performance measurement.; Data Warehousing: Involved in improving and maintaining an integrated data warehouse to ensure data and reporting consistency across the organization.; Healthcare Data Analytics: Analyzing healthcare-related data such as enrollment, claims, pharmacy, clinical, financial, and administrative data to generate insights.; Financial Modeling: Used to analyze financial data and support business opportunities and decision-making within healthcare provider analytics.; Performance Metrics: Developing and adhering to standards for performance measurement to ensure high-quality analytic output.; Self-Service BI Tools: Training customers to use interactive dashboards and BI tools for independent data exploration and reporting.; Data Integrity and Query Design: Ensuring data quality and designing queries that produce meaningful and accurate analytic results.; Stakeholder Analytics Liaison: Translating stakeholder needs into analytic and reporting solutions to support various business units.; Healthcare EMR and Claims Systems: Working knowledge of systems like Epic/Clarity, Facets, Amisys, IDX, and Soarian to access and analyze healthcare data.; Regulatory Reporting Standards: Knowledge of Medicaid, CMS Medicare regulations, and reporting requirements such as STARS, QARR, MMCOR, MEDS, RAPS, and HEDIS.; Process Improvement Methodologies: Applying advanced process improvement techniques to enhance analytic processes and organizational performance.; Interactive Dashboards: Creating dynamic visualizations to facilitate data-driven decision-making for stakeholders."
CwULlYgvqe3eUcVtAAAAAA==,Senior Data Scientist (Data Analytics) Jobs,"Overview

We are seeking a highly skilled Senior Data Scientist with specialized expertise in Artificial Intelligence (AI) and Machine Learning (ML) to support the analysis and interpretation of large-scale datasets. This role is vital for leveraging our law enforcement client's data holdings to develop innovative insights, predictive models, and business solutions. The ideal candidate will have experience working with unstructured data, statistical modeling, and advanced data analytics to drive decision-making and enhance operational effectiveness.

Contributions
• Develop and support AI/ML models for data analysis, focusing on the accuracy, authenticity, expectancy, timeliness, relevancy, and viability of intelligence data.
• Conduct advanced data integration and statistical analysis to identify patterns, trends, and intelligence gaps.
• Innovate by deriving investigative, statistical, and predictive value from our clients extensive data sources.
• Prepare, clean, and manage big data sets, design data models, and develop robust databases to support AI-driven business solutions.
• Tackle complex technical challenges using state-of-the-art techniques and industry knowledge.
• Deploy, validate, and manage various types of data models including supervised, unsupervised, and deep learning models.
• Perform advanced mathematical and statistical modeling to organize, optimize, and predict trends from both structured and unstructured data.
• Validate and improve machine learning models with rigorous statistical techniques to ensure high accuracy and precision.
• Design and implement algorithms such as neural networks, decision trees, and surrogate models to drive AI initiatives.
• Utilize modern tools and methodologies such as Data Lakes, serverless computing (Athena/Lambda), and ETL processes to manage data storage and computational needs.
• Employ data visualization tools like Power BI, Tableau, or Qlik to translate data insights into actionable intelligence.

Qualifications

Required Qualifications:
• 4+ years of hands-on experience in AI/ML model development, including supervised and unsupervised learning, with a strong focus on Natural Language Processing (NLP) for unstructured data.
• 5+ years of proficiency in at least one analytical/statistical programming language (e.g., Python, R, Scala, Closure).
• 2+ years of experience manipulating and processing unstructured data from various platforms.
• 2+ years of experience using data visualization tools such as Power BI, Tableau, Elastic X-Pack (including Graph), or Qlik.
• Bachelor's Degree in Data Science, Computer Science, Mathematics, or a related field; a combination of education and experience may be considered. An advanced degree is desirable.
• Must be local to El, Paso TX or willing to drive on site 5 days a week.
• Applicants selected will be subject to a Government background investigation and must meet eligibility and suitability requirements.
Preferred Skills:
• Experience in client engagement and relationship building.
• Experience in team leadership and staff / team management.
• Expertise in data architecture and big data management.
• Strong problem-solving abilities with a creative approach to model optimization and algorithm development.
• Ability to work collaboratively on cross-functional teams and communicate complex technical concepts to non-technical stakeholders.

In accordance with the contractual terms and conditions set by the customer, Steampunk is required to pre-screen candidates based on customer defined criteria to determine eligibility.

About steampunk

Steampunk relies on several factors to determine salary, including but not limited to geographic location, contractual requirements, education, knowledge, skills, competencies, and experience. The projected compensation range for this position is $140,000 to $190,000. The estimate displayed represents a typical annual salary range for this position. Annual salary is just one aspect of Steampunk's total compensation package for employees. Learn more about additional Steampunk benefits here.

Identity Statement

As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud.

Steampunk is a Change Agent in the Federal contracting industry, bringing new thinking to clients in the Homeland, Federal Civilian, Health and DoD sectors. Through our Human-Centered delivery methodology, we are fundamentally changing the expectations our Federal clients have for true shared accountability in solving their toughest mission challenges. As an employee owned company, we focus on investing in our employees to enable them to do the greatest work of their careers - and rewarding them for outstanding contributions to our growth. If you want to learn more about our story, visit http://www.steampunk.com .

We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law. Steampunk participates in the E-Verify program.",2025-07-25T01:00:00.000Z,2025-07-25,"['The ideal candidate will have experience working with unstructured data, statistical modeling, and advanced data analytics to drive decision-making and enhance operational effectiveness', 'Utilize modern tools and methodologies such as Data Lakes, serverless computing (Athena/Lambda), and ETL processes to manage data storage and computational needs', '4+ years of hands-on experience in AI/ML model development, including supervised and unsupervised learning, with a strong focus on Natural Language Processing (NLP) for unstructured data', '5+ years of proficiency in at least one analytical/statistical programming language (e.g., Python, R, Scala, Closure)', '2+ years of experience manipulating and processing unstructured data from various platforms', '2+ years of experience using data visualization tools such as Power BI, Tableau, Elastic X-Pack (including Graph), or Qlik', ""Bachelor's Degree in Data Science, Computer Science, Mathematics, or a related field; a combination of education and experience may be considered"", 'Must be local to El, Paso TX or willing to drive on site 5 days a week', 'Applicants selected will be subject to a Government background investigation and must meet eligibility and suitability requirements']","[""This role is vital for leveraging our law enforcement client's data holdings to develop innovative insights, predictive models, and business solutions"", 'Develop and support AI/ML models for data analysis, focusing on the accuracy, authenticity, expectancy, timeliness, relevancy, and viability of intelligence data', 'Conduct advanced data integration and statistical analysis to identify patterns, trends, and intelligence gaps', 'Innovate by deriving investigative, statistical, and predictive value from our clients extensive data sources', 'Prepare, clean, and manage big data sets, design data models, and develop robust databases to support AI-driven business solutions', 'Tackle complex technical challenges using state-of-the-art techniques and industry knowledge', 'Deploy, validate, and manage various types of data models including supervised, unsupervised, and deep learning models', 'Perform advanced mathematical and statistical modeling to organize, optimize, and predict trends from both structured and unstructured data', 'Validate and improve machine learning models with rigorous statistical techniques to ensure high accuracy and precision', 'Design and implement algorithms such as neural networks, decision trees, and surrogate models to drive AI initiatives', 'Employ data visualization tools like Power BI, Tableau, or Qlik to translate data insights into actionable intelligence']",True,"['Natural Language Processing', 'Deep Learning']",Natural Language Processing: Focused on analyzing unstructured text data to extract intelligence and support AI/ML model development.; Deep Learning: Applied through neural networks and deep learning models to enhance AI initiatives and predictive accuracy.,"['Supervised Learning', 'Unsupervised Learning', 'Statistical Modeling', 'Data Integration', 'Feature Engineering', 'Data Lakes', 'ETL Processes', 'Serverless Computing (Athena/Lambda)', 'Data Visualization Tools', 'Machine Learning', 'Neural Networks', 'Decision Trees', 'Surrogate Models', 'Programming Languages (Python, R, Scala, Closure)', 'Unstructured Data Processing']","Supervised Learning: Used to develop predictive models by training on labeled data to support intelligence data analysis.; Unsupervised Learning: Applied to identify patterns and intelligence gaps in large-scale, unlabeled datasets.; Statistical Modeling: Employed for advanced mathematical analysis to organize, optimize, and predict trends from structured and unstructured data.; Data Integration: Used to combine diverse data sources for comprehensive analysis and insight generation.; Feature Engineering: Implied in preparing and cleaning big data sets to design effective data models.; Data Lakes: Utilized as a modern data storage solution to manage large volumes of raw data for AI-driven business solutions.; ETL Processes: Implemented to extract, transform, and load data efficiently for analysis and model development.; Serverless Computing (Athena/Lambda): Used to manage data storage and computational needs in a scalable, cost-effective manner.; Data Visualization Tools: Power BI, Tableau, Elastic X-Pack, and Qlik are used to translate complex data insights into actionable intelligence.; Machine Learning: Applied broadly to develop and validate models that improve decision-making and operational effectiveness.; Neural Networks: Designed and implemented as part of algorithm development to support AI initiatives.; Decision Trees: Used as an algorithmic approach to support predictive modeling and data analysis.; Surrogate Models: Developed to approximate complex models for efficient analysis and prediction.; Programming Languages (Python, R, Scala, Closure): Used for analytical and statistical programming to manipulate data and develop models.; Unstructured Data Processing: Experience in handling and analyzing unstructured data from various platforms to extract meaningful insights."
npE7ACWV6keCaLZQAAAAAA==,Data Scientist,"We are seeking a Data Scientist for a long term contract in Tucson, AZ.

This position is ideal for a Data Scientist who is passionate about doing meaningful work—applying their skills in AI, machine learning, and image analysis to advance cancer diagnostics and digital pathology. You’ll be working with a mission-driven, highly respected healthcare company that's at the forefront of innovation in cancer technology and patient care.

Description: Data Scientist, Digital Pathology Development

Onsite – Tucson

Key Responsibilities:
• Work closely with the Tucson-based assay and algorithm development teams to ensure seamless data integration and maintain data integrity across complex digital pathology projects.
• Design, develop, and implement robust solutions to automate manual steps within the algorithm development and data management workflows, enhancing efficiency and reproducibility.
• Perform sophisticated image processing, data analysis, and predictive modeling using large-scale digital pathology datasets.
• Build, test, and deploy computational tools and algorithms, primarily using Python or similar languages, adhering to high standards of code quality, efficiency, and maintainability.
• Leverage your skills in digital pathology, machine learning (ML), artificial intelligence (AI), and GUI development to create impactful solutions and improve algorithm performance.
• Meticulously maintain the traceability and integrity of all data, including images and associated metadata, ensuring compliance with relevant standards and supporting contractual obligations.

Minimum Qualifications:
• Bachelor's degree in Computer Science, Data Science, Engineering, Statistics, or a related quantitative field with 7+ years of relevant experience.
• Proven experience developing, testing, and deploying solutions using Python or similar programming languages within a software development lifecycle.
• Solid understanding and practical experience in image analysis, machine learning/deep learning techniques, and AI concepts.
• Demonstrated ability to perform complex data modeling, processing, and analysis on large or intricate datasets.
• Experience developing graphical user interface (GUI) for technical applications or data visualization.
• Excellent analytical and problem-solving skills with meticulous attention to detail.
• Strong verbal and written communication skills, enabling effective collaboration within cross-functional teams.

Preferred Qualifications:
• Experience working within the life sciences, biotechnology, or pharmaceutical industry, particularly with digital pathology or medical imaging data.
• Familiarity with regulatory requirements and compliance standards applicable to medical devices or software as a medical device (SaMD) (e.g., FDA guidance, IVDR).
• Proficiency with cloud computing platforms (e.g., AWS, Azure, GCP) and associated services.
• Experience utilizing High-Performance Computing (HPC) environments for computationally intensive tasks.
• Knowledge of bioinformatics or molecular modeling techniques.",,2025-07-25,"[""Bachelor's degree in Computer Science, Data Science, Engineering, Statistics, or a related quantitative field with 7+ years of relevant experience"", 'Proven experience developing, testing, and deploying solutions using Python or similar programming languages within a software development lifecycle', 'Solid understanding and practical experience in image analysis, machine learning/deep learning techniques, and AI concepts', 'Demonstrated ability to perform complex data modeling, processing, and analysis on large or intricate datasets', 'Experience developing graphical user interface (GUI) for technical applications or data visualization', 'Excellent analytical and problem-solving skills with meticulous attention to detail', 'Strong verbal and written communication skills, enabling effective collaboration within cross-functional teams']","['Work closely with the Tucson-based assay and algorithm development teams to ensure seamless data integration and maintain data integrity across complex digital pathology projects', 'Design, develop, and implement robust solutions to automate manual steps within the algorithm development and data management workflows, enhancing efficiency and reproducibility', 'Perform sophisticated image processing, data analysis, and predictive modeling using large-scale digital pathology datasets', 'Build, test, and deploy computational tools and algorithms, primarily using Python or similar languages, adhering to high standards of code quality, efficiency, and maintainability', 'Leverage your skills in digital pathology, machine learning (ML), artificial intelligence (AI), and GUI development to create impactful solutions and improve algorithm performance', 'Meticulously maintain the traceability and integrity of all data, including images and associated metadata, ensuring compliance with relevant standards and supporting contractual obligations']",True,"['Deep Learning', 'Artificial Intelligence']",Deep Learning: Applied as part of advanced AI techniques for image analysis and algorithm improvement in digital pathology.; Artificial Intelligence: Leveraged to create impactful solutions and enhance algorithm performance in cancer diagnostics.,"['Image Processing', 'Predictive Modeling', 'Machine Learning', 'Data Integration', 'Data Integrity', 'Python Programming', 'Graphical User Interface (GUI) Development', 'Data Modeling', 'High-Performance Computing (HPC)']","Image Processing: Used to analyze and extract meaningful information from large-scale digital pathology images.; Predictive Modeling: Applied to develop models that predict outcomes based on digital pathology datasets.; Machine Learning: Employed to improve algorithm performance and automate data analysis workflows in digital pathology.; Data Integration: Ensures seamless combination and consistency of data across complex digital pathology projects.; Data Integrity: Maintained to ensure accuracy and reliability of images and associated metadata in compliance with standards.; Python Programming: Primary language used to build, test, and deploy computational tools and algorithms.; Graphical User Interface (GUI) Development: Developed for technical applications and data visualization to support algorithm development.; Data Modeling: Performed to represent and analyze complex digital pathology datasets effectively.; High-Performance Computing (HPC): Utilized for computationally intensive tasks related to image analysis and algorithm development."
HD_Y3R_tuV5zgVAeAAAAAA==,"Lead Data Scientist, Machine Learning Engineer 2025- US","Aimpoint Digital is a premier analytics consulting firm with a mission to drive business value for clients through expertise in data strategy, data analytics, decision sciences, and data engineering and infrastructure. This position is within our decision sciences practice which focuses on delivering solutions via machine learning and statistical modelling.

What you will do

As a part of Aimpoint Digital, you will focus on enabling clients to get the most out of their data. You will work with all levels of the client organization to build value driving solutions that extract insights and then train them on how to manage and maintain these solutions. Typical solutions will utilize machine learning, artificial intelligence, statistical analysis, automation, optimization, and/or data visualizations. As a Lead Data Scientist, you will be expected to work independently on client engagements, take part in the development of our practice, aid in business development, and contribute innovative ideas and initiatives to our company. As a Lead Data Scientist you will:
• Become a trusted advisor working with clients to design end-to-end analytical solutions
• Work independently to solve complex data science use-cases across various industries
• Design and develop feature engineering pipelines, build ML & AI infrastructure, deploy models, and orchestrate advanced analytical insights
• Write code in SQL, Python, and Spark following software engineering best practices
• Collaborate with stakeholders and customers to ensure successful project delivery

Who we are looking for

We are looking for collaborative individuals who want to drive value, work in a fast-paced environment, and solve real business problems. You are a coder who writes efficient and optimized code leveraging key Databricks features. You are a problem-solver who can deliver simple, elegant solutions as well as cutting-edge solutions that, regardless of complexity, your clients can understand, implement, and maintain. You genuinely think about the end-to-end machine learning pipeline as you generate robust solutions. You are both a teacher and a student as we enable our clients, upskill our teammates, and learn from one another. You want to drive impact for your clients and do so through thoughtfulness, prioritization, and seeing a solution through from brainstorming to deployment. In particular you have these traits:
• Degree in Computer Science, Engineering, Mathematics, or equivalent experience.
• Experience with building high quality Data Science models to solve a client's business problems
• Experience with managing stakeholders and collaborating with customers
• Strong written and verbal communication skills required
• Ability to manage an individual workstream independently
• 3+ years of experience developing and deploying ML models in any platform (Azure, AWS, GCP, Databricks etc.)
• Ability to apply data science methodologies and principles to real life projects
• Expertise in software engineering concepts and best practices
• Self-starter with excellent communication skills, able to work independently, and lead projects, initiatives, and/or people
• Willingness to travel.

Want to stand out?
• Consulting Experience
• Databricks Machine Learning Associate or Machine Learning Professional Certification.
• Familiarity with traditional machine learning tools such as Python, SKLearn, XGBoost, SparkML, etc.
• Experience with deep learning frameworks like TensorFlow or PyTorch.
• Knowledge of ML model deployment options (e.g., Azure Functions, FastAPI, Kubernetes) for real-time and batch processing.
• Experience with CI/CD pipelines (e.g., DevOps pipelines, GitHub Actions).
• Knowledge of infrastructure as code (e.g., Terraform, ARM Template, Databricks Asset Bundles).
• Understanding of advanced machine learning techniques, including graph-based processing, computer vision, natural language processing, and simulation modeling.
• Experience with generative AI and LLMs, such as LLamaIndex and LangChain
• Understanding of MLOps or LLMOps.
• Familiarity with Agile methodologies, preferably Scrum

We are actively seeking candidates for full-time, remote work within the US.",2025-07-14T00:00:00.000Z,2025-07-25,"['We are looking for collaborative individuals who want to drive value, work in a fast-paced environment, and solve real business problems', 'You are a coder who writes efficient and optimized code leveraging key Databricks features', 'You are a problem-solver who can deliver simple, elegant solutions as well as cutting-edge solutions that, regardless of complexity, your clients can understand, implement, and maintain', 'You genuinely think about the end-to-end machine learning pipeline as you generate robust solutions', 'Degree in Computer Science, Engineering, Mathematics, or equivalent experience', ""Experience with building high quality Data Science models to solve a client's business problems"", 'Experience with managing stakeholders and collaborating with customers', 'Strong written and verbal communication skills required', 'Ability to manage an individual workstream independently', '3+ years of experience developing and deploying ML models in any platform (Azure, AWS, GCP, Databricks etc.)', 'Ability to apply data science methodologies and principles to real life projects', 'Expertise in software engineering concepts and best practices', 'Self-starter with excellent communication skills, able to work independently, and lead projects, initiatives, and/or people', 'Willingness to travel', 'Consulting Experience', 'Databricks Machine Learning Associate or Machine Learning Professional Certification', 'Familiarity with traditional machine learning tools such as Python, SKLearn, XGBoost, SparkML, etc', 'Experience with deep learning frameworks like TensorFlow or PyTorch', 'Knowledge of ML model deployment options (e.g., Azure Functions, FastAPI, Kubernetes) for real-time and batch processing', 'Experience with CI/CD pipelines (e.g., DevOps pipelines, GitHub Actions)', 'Knowledge of infrastructure as code (e.g., Terraform, ARM Template, Databricks Asset Bundles)', 'Understanding of advanced machine learning techniques, including graph-based processing, computer vision, natural language processing, and simulation modeling', 'Experience with generative AI and LLMs, such as LLamaIndex and LangChain', 'Understanding of MLOps or LLMOps', 'Familiarity with Agile methodologies, preferably Scrum', 'We are actively seeking candidates for full-time, remote work within the US']","['As a part of Aimpoint Digital, you will focus on enabling clients to get the most out of their data', 'You will work with all levels of the client organization to build value driving solutions that extract insights and then train them on how to manage and maintain these solutions', 'Typical solutions will utilize machine learning, artificial intelligence, statistical analysis, automation, optimization, and/or data visualizations', 'As a Lead Data Scientist, you will be expected to work independently on client engagements, take part in the development of our practice, aid in business development, and contribute innovative ideas and initiatives to our company', 'Become a trusted advisor working with clients to design end-to-end analytical solutions', 'Work independently to solve complex data science use-cases across various industries', 'Design and develop feature engineering pipelines, build ML & AI infrastructure, deploy models, and orchestrate advanced analytical insights', 'Write code in SQL, Python, and Spark following software engineering best practices', 'Collaborate with stakeholders and customers to ensure successful project delivery', 'You are both a teacher and a student as we enable our clients, upskill our teammates, and learn from one another', 'You want to drive impact for your clients and do so through thoughtfulness, prioritization, and seeing a solution through from brainstorming to deployment']",True,"['Generative AI', 'Large Language Models', 'LLMOps']",Generative AI: Experience with generative AI models to create new content or data-driven insights.; Large Language Models: Use of LLMs such as LLamaIndex and LangChain for advanced natural language understanding and generation.; LLMOps: Operations and management practices specific to deploying and maintaining large language models.,"['Machine Learning', 'Statistical Analysis', 'Feature Engineering', 'SQL', 'Python', 'Spark', 'scikit-learn', 'XGBoost', 'SparkML', 'Deep Learning Frameworks', 'ML Model Deployment', 'CI/CD Pipelines', 'Infrastructure as Code', 'Graph-Based Processing', 'Computer Vision', 'Natural Language Processing', 'Simulation Modeling', 'MLOps', 'Databricks']","Machine Learning: Used to build predictive models and solve complex data science use-cases across various industries.; Statistical Analysis: Applied to analyze data and extract insights for client solutions.; Feature Engineering: Design and development of pipelines to transform raw data into features for ML models.; SQL: Used for querying and managing data within client projects.; Python: Primary coding language for developing data science models and pipelines.; Spark: Utilized for big data processing and building scalable data pipelines.; scikit-learn: Traditional machine learning library used for building models.; XGBoost: Gradient boosting framework used for high-quality predictive modeling.; SparkML: Machine learning library within Spark used for scalable model development.; Deep Learning Frameworks: TensorFlow and PyTorch used for advanced machine learning techniques.; ML Model Deployment: Deployment of models using platforms like Azure Functions, FastAPI, and Kubernetes for real-time and batch processing.; CI/CD Pipelines: Use of DevOps pipelines and GitHub Actions to automate model deployment and integration.; Infrastructure as Code: Tools like Terraform, ARM Template, and Databricks Asset Bundles used to manage infrastructure for data science projects.; Graph-Based Processing: Advanced machine learning technique applied to analyze graph-structured data.; Computer Vision: Applied machine learning technique for image and video data analysis.; Natural Language Processing: Traditional NLP techniques used for text data analysis and modeling.; Simulation Modeling: Use of simulation techniques to model complex systems and scenarios.; MLOps: Practices and tools to manage the lifecycle of machine learning models.; Databricks: Platform leveraged for data engineering, machine learning, and collaborative development."
Db5tG7QmN3FBIZ98AAAAAA==,"Data Scientist - Data and Machine Learning, WWPS ProServe","Description

Are you excited to help the healthcare and life sciences (HCLS) industry customers design, build, and implement AI algorithms, including advanced Generative AI solutions, to augment decision making while meeting the highest standards for reliability, transparency, and scalability? The Amazon Web Services (AWS) Professional Services team works directly with HCLS customers to achieve their goals through the adoption of Machine Learning (ML) and Generative AI methods. Our team collaborates across the entire AWS organization to bring access to product and service teams, to get the right solution delivered and drive feature innovation based on customer needs.

At AWS, we're hiring experienced data scientists with a background in both traditional and generative AI who can help our customers understand the opportunities their HCLS data presents, and build solutions that earn the customer trust needed for deployment to production systems.

In this role, you will work closely with customers to deeply understand their data challenges and requirements, and design tailored solutions that best fit their use cases. You should have broad experience building models using all kinds of HCLS data sources, and building data-intensive applications at scale. You should possess excellent business acumen and communication skills to collaborate effectively with stakeholders, develop key business questions, and translate requirements into actionable solutions. You will provide guidance and support to other engineers, sharing industry best practices and driving innovation in the field of data science and AI.

This position requires that the candidate selected be a US Citizen.

Key job responsibilities

As An Data Scientist, You Will
• Collaborate with AI/ML scientists and architects to research, design, develop, and evaluate AI algorithms to address real-world challenges
• Interact with customers directly to understand the business problem, help and aid them in implementation of AI solutions, deliver briefing and deep dive sessions to customers and guide customer on adoption patterns and paths to production.
• Create and deliver best practice recommendations, tutorials, blog posts, sample code, and presentations adapted to technical, business, and executive stakeholder
• Provide customer and market feedback to Product and Engineering teams to help define product direction

About The Team

Diverse Experiences: AWS values diverse experiences. Even if you do not meet all of the preferred qualifications and skills listed in the job below, we encourage candidates to apply. If your career is just starting, hasn’t followed a traditional path, or includes alternative experiences, don’t let it stop you from applying.

Why AWS? Amazon Web Services (AWS) is the world’s most comprehensive and broadly adopted cloud platform. We pioneered cloud computing and never stopped innovating — that’s why customers from the most successful startups to Global 500 companies trust our robust suite of products and services to power their businesses.

Inclusive Team Culture - Here at AWS, it’s in our nature to learn and be curious. Our employee-led affinity groups foster a culture of inclusion that empower us to be proud of our differences. Ongoing events and learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (diversity) conferences, inspire us to never stop embracing our uniqueness.

Mentorship & Career Growth - We’re continuously raising our performance bar as we strive to become Earth’s Best Employer. That’s why you’ll find endless knowledge-sharing, mentorship and other career-advancing resources here to help you develop into a better-rounded professional.

Work/Life Balance - We value work-life harmony. Achieving success at work should never come at the expense of sacrifices at home, which is why we strive for flexibility as part of our working culture. When we feel supported in the workplace and at home, there’s nothing we can’t achieve in the cloud.

Basic Qualifications
• Bachelor's degree in Computer Science, Engineering, related field, or equivalent experience
• 3+ years of experience building models for business applications
• Experience with algorithms, data structures, parsing, numerical optimization, data mining, parallel and distributed computing, high-performance computing, neural deep learning methods and/or machine learning
• Experience using Python and hands on experience building models with deep learning frameworks (i.e. Tensorflow, Keras, PyTorch, MXNet, JAX)
• Experience of working with healthcare and life sciences data (e.g. EHR, HL7/FHIR, insurance claims, genomics, medical imaging, etc)

Preferred Qualifications
• Masters or PhD Degree in computer science, engineering, mathematics, operations research, or in a highly quantitative field related to healthcare and life sciences
• Practical experience in solving complex problems using cloud computing
• Experience building applications leveraging GenAI

Amazon is an equal opportunity employer and does not discriminate on the basis of protected veteran status, disability, or other legally protected status.

Los Angeles County applicants: Job duties for this position include: work safely and cooperatively with other employees, supervisors, and staff; adhere to standards of excellence despite stressful conditions; communicate effectively and respectfully with employees, supervisors, and staff to ensure exceptional customer service; and follow all federal, state, and local laws and Company policies. Criminal history may have a direct, adverse, and negative relationship with some of the material job duties of this position. These include the duties and responsibilities listed above, as well as the abilities to adhere to company policies, exercise sound judgment, effectively manage stress and work safely and respectfully with others, exhibit trustworthiness and professionalism, and safeguard business operations and the Company’s reputation. Pursuant to the Los Angeles County Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $125,500/year in our lowest geographic market up to $212,800/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.

Company - Amazon Web Services, Inc.

Job ID: A2993489",2025-07-10T00:00:00.000Z,2025-07-25,"['You should have broad experience building models using all kinds of HCLS data sources, and building data-intensive applications at scale', 'You should possess excellent business acumen and communication skills to collaborate effectively with stakeholders, develop key business questions, and translate requirements into actionable solutions', 'This position requires that the candidate selected be a US Citizen', ""Bachelor's degree in Computer Science, Engineering, related field, or equivalent experience"", '3+ years of experience building models for business applications', 'Experience with algorithms, data structures, parsing, numerical optimization, data mining, parallel and distributed computing, high-performance computing, neural deep learning methods and/or machine learning', 'Experience using Python and hands on experience building models with deep learning frameworks (i.e', 'Tensorflow, Keras, PyTorch, MXNet, JAX)', 'Experience of working with healthcare and life sciences data (e.g', 'EHR, HL7/FHIR, insurance claims, genomics, medical imaging, etc)', 'These include the duties and responsibilities listed above, as well as the abilities to adhere to company policies, exercise sound judgment, effectively manage stress and work safely and respectfully with others, exhibit trustworthiness and professionalism, and safeguard business operations and the Company’s reputation']","['In this role, you will work closely with customers to deeply understand their data challenges and requirements, and design tailored solutions that best fit their use cases', 'You will provide guidance and support to other engineers, sharing industry best practices and driving innovation in the field of data science and AI', 'Collaborate with AI/ML scientists and architects to research, design, develop, and evaluate AI algorithms to address real-world challenges', 'Interact with customers directly to understand the business problem, help and aid them in implementation of AI solutions, deliver briefing and deep dive sessions to customers and guide customer on adoption patterns and paths to production', 'Create and deliver best practice recommendations, tutorials, blog posts, sample code, and presentations adapted to technical, business, and executive stakeholder', 'Provide customer and market feedback to Product and Engineering teams to help define product direction']",True,"['Generative AI', 'Artificial Intelligence Algorithms']","Generative AI: Designing and implementing advanced generative AI solutions to augment decision-making in healthcare.; Artificial Intelligence Algorithms: Collaborating to research, develop, and evaluate AI algorithms addressing real-world healthcare challenges.","['Healthcare and Life Sciences Data', 'Machine Learning', 'Neural Deep Learning Methods', 'Algorithms and Data Structures', 'Numerical Optimization', 'Data Mining', 'Parallel and Distributed Computing', 'Python', 'Deep Learning Frameworks']","Healthcare and Life Sciences Data: Experience working with diverse healthcare data sources such as EHR, HL7/FHIR, insurance claims, genomics, and medical imaging relevant to building domain-specific models.; Machine Learning: Building predictive models and algorithms for business applications using traditional machine learning methods.; Neural Deep Learning Methods: Applying neural network-based techniques to solve complex problems in healthcare and life sciences.; Algorithms and Data Structures: Utilizing fundamental computer science concepts to optimize data processing and model performance.; Numerical Optimization: Techniques used to improve model accuracy and efficiency in data science workflows.; Data Mining: Extracting meaningful patterns and insights from large healthcare datasets.; Parallel and Distributed Computing: Leveraging high-performance computing techniques to scale data-intensive applications.; Python: Primary programming language used for data analysis, model building, and prototyping.; Deep Learning Frameworks: Hands-on experience with frameworks like TensorFlow, Keras, PyTorch, MXNet, and JAX for building and training neural networks."
h902T2VUZpEt8OGEAAAAAA==,Data Scientist - Lead,"Description:
• Analyze and interpret datasets using statistical techniques and machine learning.
• Use data science tools like Azure Databricks, Power BI, and Python.
• Prepare and deliver analysis results that communicate data insights.
• Collaborate with cross-functional teams to understand data needs.
• Build predictive models and machine-learning algorithms.
• Coach and mentor team members on data science best practices.

Requirements:
• Bachelors degree with five (5) or more years of experience in the field or in a related area.
• Masters or doctorate degree
• Expertise in Power Platform s
• Familiarity with LLM (open source or closed)
• Experience in Front end web app development ( Flaskapp , Gradio etc )
• Familiarity with RAG architecture

Benefits:",2025-07-23T00:00:00.000Z,2025-07-25,"['Bachelors degree with five (5) or more years of experience in the field or in a related area', 'Masters or doctorate degree', 'Expertise in Power Platform s', 'Familiarity with LLM (open source or closed)', 'Experience in Front end web app development ( Flaskapp , Gradio etc )', 'Familiarity with RAG architecture']","['Analyze and interpret datasets using statistical techniques and machine learning', 'Use data science tools like Azure Databricks, Power BI, and Python', 'Prepare and deliver analysis results that communicate data insights', 'Collaborate with cross-functional teams to understand data needs', 'Build predictive models and machine-learning algorithms', 'Coach and mentor team members on data science best practices']",True,"['Large Language Models', 'Retrieval-Augmented Generation', 'Front-End AI Application Development']",Large Language Models: Familiarity with open source or closed LLMs indicates use of advanced AI models for natural language understanding or generation.; Retrieval-Augmented Generation: Knowledge of RAG architecture suggests integration of external knowledge sources with generative AI models.; Front-End AI Application Development: Experience with Flask and Gradio indicates building user interfaces for AI-powered applications.,"['Statistical Techniques', 'Machine Learning', 'Azure Databricks', 'Power BI', 'Python', 'Predictive Models']","Statistical Techniques: Used to analyze and interpret datasets to extract meaningful insights.; Machine Learning: Applied to build predictive models and algorithms for data-driven decision making.; Azure Databricks: A data science platform used for data processing and collaborative analytics.; Power BI: A business intelligence tool used to prepare and deliver data insights through dashboards and reports.; Python: Programming language used for data analysis, model building, and scripting data workflows.; Predictive Models: Built to forecast outcomes based on historical data."
dda2-nHv7bZhJWViAAAAAA==,Data Scientist 2 (Hawaii),"Prime Time Consulting provides clients with expert intelligence analysis services. Our clients include defense contractors, industrial and service corporations, and departments and agencies of the U.S. Federal Government.

Data Scientist 2

We are actively searching for Data Scientists, located in Hawaii, to support our team. We have varying levels of Data Scientist roles, depending on years of experience and education.

Job Description:
• Performs tasks associated with Big Data Platform management, utilizes skills in programming languages, develops prototype algorithms as well as algorithm refinements, and supports data visualization and analytics.

The Level 2 Data Scientist shall possess the following capabilities:

Employ some combination of the following skill areas:
• Foundations: (Mathematical, Computational, Statistical) 2. Data Processing: (Data management and curation, data description and visualization, workflow, and reproducibility)
• Modeling, Inference, and Prediction: (Data modeling and assessment, domain-specific considerations)
• Devise strategies for extracting meaning and value from large datasets. Make and communicate principled conclusions from data using elements of mathematics,
• Statistics, computer science, and application specific knowledge.
• Through analytic modeling, statistical analysis, programming, and/or another appropriate scientific method, develop and implement qualitative and quantitative methods for characterizing, exploring, and assessing large datasets in various states of organization, cleanliness, and structure that account for the unique features and limitations inherent in data holdings.
• Translate practical mission needs and analytic questions related to large datasets into technical requirements and, conversely, assist others with drawing appropriate conclusions from the analysis of such data. Effectively communicate complex technical information to non-technical audiences. Make informed recommendations regarding competing technical solutions by maintaining awareness of the constantly shifting, processing, storage and analytic capabilities and limitations.

Qualifications:
• Bachelor’s Degree with 3 years of relevant experience

OR
• Associates degree with 5 years of relevant experience
• Bachelor’s Degree must be in Mathematics, Applied Mathematics Statistics, Applied Statistics, Machine learning, Data Science, Operations Research, or Computer Science or a degree in a related field (Computer Information Systems, Engineering), a degree in the physical/hard sciences (e.g. physics, chemistry, biology, astronomy), or other science disciplines with a substantial computational component (i.e. behavioral, social, or life) may be considered if it included a concentration of coursework (5 or more courses) in advanced Mathematics (typically 300 level or higher, such as linear algebra, probability and statistics, machine learning) and/or computer science (e.g. algorithms, programming, , data structures, data mining, artificial intelligence). College-level requirements, or upper-level math courses designated as elementary or basic do not count. Note: A broader range of degrees will be considered if accompanied by a Certificate in Data Science from an accredited college/university.
• Relevant experience must be in designing/implementing machine learning, data science, advanced analytical algorithms, programming (skill in at least one high-level language (e.g., Python)), statistical analysis (e.g., variability, sampling error, inference, hypothesis testing, EDA, application of linear models), data management (e.g., data cleaning and transformation), data mining, data modeling and assessment, artificial intelligence, and/or software engineering. Experience in more than one area is strongly preferred.

Position requires active Security Clearance with appropriate Polygraph

Pay Range: $80,000-$130,000

The salary range provided in this job posting is intended to offer a general idea of the compensation for the role and is based on market research and internal benchmarks. The actual salary offered to the selected candidate will be determined based on factors such as experience, education, qualifications, and geographic location. This range is subject to change and does not constitute a guarantee of compensation. Additionally, the salary offered may be adjusted based on the candidate’s performance during the selection process and evolving business needs.

Company Perks
• 200 hours of PTO annually
• 6% 401k Contribution
• Competitive Health Care Options
• Short Term/Long Term/Life Insurance
• Annual Training Budget

We are an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, sex, age, national origin, disability, Veteran status, or any other category protected by federal, state, or local laws.",2025-06-29T00:00:00.000Z,2025-07-25,,,True,[],,"['Big Data Platform Management', 'Programming (Python)', 'Algorithm Development and Refinement', 'Data Visualization', 'Mathematical, Computational, and Statistical Foundations', 'Data Management and Curation', 'Data Modeling and Assessment', 'Statistical Analysis (Inference, Hypothesis Testing, EDA, Linear Models)', 'Machine Learning', 'Data Mining', 'Software Engineering']","Big Data Platform Management: Managing and utilizing large-scale data platforms to support data processing and analytics tasks.; Programming (Python): Using programming languages such as Python to develop algorithms and perform data analysis.; Algorithm Development and Refinement: Creating and improving prototype algorithms for data analysis and modeling.; Data Visualization: Presenting data insights visually to aid understanding and communication.; Mathematical, Computational, and Statistical Foundations: Applying core mathematical and statistical principles to analyze and interpret data.; Data Management and Curation: Organizing, cleaning, and maintaining data to ensure quality and usability.; Data Modeling and Assessment: Building and evaluating models to extract meaningful patterns and predictions from data.; Statistical Analysis (Inference, Hypothesis Testing, EDA, Linear Models): Using statistical methods to analyze data variability, test hypotheses, and explore data.; Machine Learning: Designing and implementing algorithms that enable computers to learn from and make predictions on data.; Data Mining: Extracting useful information and patterns from large datasets.; Software Engineering: Applying engineering principles to develop and maintain software systems supporting data science tasks."
BQFGF4-a8emlvysjAAAAAA==,"Data Scientist, Research, Youtube Ads, Advertiser Optimization","About the position

At Google, data drives all of our decision-making. As a Data Scientist focused on Research and Advertiser Optimization for YouTube Ads, you will play a crucial role in shaping Google's business and technical strategies by processing, analyzing, and interpreting vast data sets. Your analytical excellence and statistical methods will be essential in mining through data to identify opportunities for Google and its clients to operate more efficiently. This includes enhancing advertising efficacy, optimizing network infrastructure, and studying user behavior. In this role, you will not only analyze data but also collaborate with Engineers, Product Managers, Sales Associates, and Marketing teams to adjust Google's practices based on your findings. Identifying problems is just the beginning; you will also be responsible for devising solutions. You will evaluate and improve Google's products, working alongside a multi-disciplinary team of engineers and analysts on a wide range of challenges. This position requires a scientific approach and statistical methods to tackle product creation, development, and improvement while considering the behaviors of end users. The US base salary range for this full-time position is $127,000-$187,000, plus bonuses, equity, and benefits. The salary range reflects the minimum and maximum target salaries for the position across all US locations, with individual pay determined by work location and other factors such as job-related skills, experience, and relevant education or training. Your recruiter can provide more specific salary information during the hiring process. Google is committed to being an equal opportunity workplace and an affirmative action employer, ensuring equal employment opportunity regardless of various factors including race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements.

Responsibilities
• Manage bidding optimization to ensure exceptional advertiser experiences, while contributing to business growth.
,
• Align retrieval scores with auctions to maximize the total desired spend across all advertisers and ensure YouTube advertisers see immediate benefits from investments.
,
• Own the process of gathering, extracting, and compiling data across sources via relevant tools (e.g., SQL, R, Python).
,
• Independently format, re-structure, and/or validate data to ensure quality, and review the dataset to ensure it is ready for analysis.
,
• Use custom data infrastructure or existing data models as appropriate, using specialized knowledge.
,
• Design and evaluate models to mathematically express and solve defined problems with limited precedent.
,
• Collaborate with cross-functional stakeholders to identify and clarify business or product questions to answer.
,
• Provide feedback to translate and refine business questions into tractable analysis, evaluation metrics, or mathematical models.

Requirements
• Master's degree in Statistics, Data Science, Mathematics, Physics, Economics, Operations Research, Engineering, or a related quantitative field.
,
• 3 years of work experience using analytics to solve product or business problems, coding (e.g., Python, R, SQL), querying databases or statistical analysis, or a PhD degree.

Nice-to-haves
• 5 years of work experience using analytics to solve product or business problems, coding (e.g., Python, R, SQL), querying databases or statistical analysis, or a PhD degree.
,
• Experience and strong interest in understanding, measuring, and improving end user experience.
,
• Experience in constrained optimization theory.
,
• Knowledge of Ads systems, including auction, serving, and ads quality.

Benefits
• Health insurance
,
• Dental insurance
,
• Vision insurance
,
• 401(k) plan with company matching
,
• Paid time off
,
• Parental leave
,
• Employee stock purchase plan
,
• Tuition reimbursement
,
• Professional development opportunities
,
• Wellness programs",,2025-07-25,"[""Master's degree in Statistics, Data Science, Mathematics, Physics, Economics, Operations Research, Engineering, or a related quantitative field"", '3 years of work experience using analytics to solve product or business problems, coding (e.g., Python, R, SQL), querying databases or statistical analysis, or a PhD degree', '5 years of work experience using analytics to solve product or business problems, coding (e.g., Python, R, SQL), querying databases or statistical analysis, or a PhD degree', 'Experience and strong interest in understanding, measuring, and improving end user experience', 'Experience in constrained optimization theory', 'Knowledge of Ads systems, including auction, serving, and ads quality']","['Your analytical excellence and statistical methods will be essential in mining through data to identify opportunities for Google and its clients to operate more efficiently', 'This includes enhancing advertising efficacy, optimizing network infrastructure, and studying user behavior', ""In this role, you will not only analyze data but also collaborate with Engineers, Product Managers, Sales Associates, and Marketing teams to adjust Google's practices based on your findings"", 'Identifying problems is just the beginning; you will also be responsible for devising solutions', ""You will evaluate and improve Google's products, working alongside a multi-disciplinary team of engineers and analysts on a wide range of challenges"", 'This position requires a scientific approach and statistical methods to tackle product creation, development, and improvement while considering the behaviors of end users', 'Manage bidding optimization to ensure exceptional advertiser experiences, while contributing to business growth', 'Align retrieval scores with auctions to maximize the total desired spend across all advertisers and ensure YouTube advertisers see immediate benefits from investments', 'Own the process of gathering, extracting, and compiling data across sources via relevant tools (e.g., SQL, R, Python)', 'Independently format, re-structure, and/or validate data to ensure quality, and review the dataset to ensure it is ready for analysis', 'Use custom data infrastructure or existing data models as appropriate, using specialized knowledge', 'Design and evaluate models to mathematically express and solve defined problems with limited precedent', 'Collaborate with cross-functional stakeholders to identify and clarify business or product questions to answer', 'Provide feedback to translate and refine business questions into tractable analysis, evaluation metrics, or mathematical models']",True,[],,"['Statistical Methods', 'Bidding Optimization', 'SQL', 'Python', 'R', 'Data Validation and Quality Assurance', 'Custom Data Infrastructure', 'Mathematical Modeling', 'Constrained Optimization Theory', 'Data Analysis', 'Collaboration with Cross-Functional Teams']","Statistical Methods: Used to analyze and interpret vast data sets to identify opportunities and improve advertising efficacy and user behavior understanding.; Bidding Optimization: Applied to manage and optimize advertiser bidding strategies to enhance advertiser experiences and business growth.; SQL: Used for querying databases and extracting data from various sources for analysis.; Python: Utilized for data extraction, formatting, restructuring, validation, and building data models.; R: Employed for statistical analysis, data manipulation, and modeling.; Data Validation and Quality Assurance: Ensures datasets are accurate, well-structured, and ready for analysis.; Custom Data Infrastructure: Used to support data gathering, extraction, and modeling tailored to specific business needs.; Mathematical Modeling: Design and evaluation of models to solve defined business problems with limited precedent.; Constrained Optimization Theory: Applied to optimize advertising auctions and resource allocation under specific constraints.; Data Analysis: Mining through data to identify actionable insights for product and business improvements.; Collaboration with Cross-Functional Teams: Working with engineers, product managers, sales, and marketing to translate data insights into business actions."
wAr7PaXYId54vgswAAAAAA==,Senior Data Scientist,"Senior Data Scientist

Virta Health is pioneering a new standard of care for people to reclaim their lives. We are in the midst of a public health crisis: obesity rates are at an all-time high and over half of US adults have type 2 diabetes or prediabetes, and despite billions spent on new treatments, outcomes are largely worse. Virta reverses these diseases and delivers life-changing results by pairing individualized nutrition with ongoing care from a clinical support team. We have raised over $350 million from top-tier investors, and partner with the largest health plans, employers, and government organizations to help their employees and members restore their health and take back their lives.

Role Overview

The Advanced Analytics & AI (AAA) team is accountable for both pioneering new classes of data that power our business, and ensuring that data is powerful, clear, correct and easy to use throughout the company. The team collaborates closely with the engineering, product development, commercial, and clinical teams to transform data into actionable insights that propel Virta's mission forward.

As a Senior Data Scientist on the AAA team, you will play a crucial role in shaping our data-driven decision making processes and in driving impactful insights that advance our mission. This role offers a unique blend of hands-on coding and strategic leadership, working closely in partnership with the Product Development group that supports adoption of our member-facing products. You will get a chance to work closely with stakeholders to create impactful data-driven reports and analyses that strengthen Virta’s value proposition.

Responsibilities
• Serve as data lead for the Adoption Squad:
• Understand the product – strategy, goals, roadmap, users – deeply enough to identify high-impact, strategic opportunities and risks.
• Use data to steer conversations: bring data-driven hypotheses, challenge assumptions, frame trade-offs, prioritize strategically.
• Translate vague product hunches into sharp analytical questions, and design the right approach to answer them.
• Be the source of truth for KPIs and product metrics: help define and monitor them, and identify trends and drivers.
• Drive decision making with data: Prioritize analyses that meaningfully inform product decisions and change outcomes, reframe analysis requests that won’t do that into ones that will, and design and deliver the resulting analyses properly and rapidly.
• Lead experimentation thoughtfully: guide the team on when and when not to experiment, help enable self-serve experimentation, and focus on frequent, small experiments to speed learning.
• Identify where product strategy and ideas could be better, more easily, or more quickly implemented with the help of AI (ML or GenAI), and help enable this integration.
• Show up as a collaborative leader, not simply a service provider, and help focus work on what matters most.
• Work end-to-end to translate clinical, member, and claims data from our data warehouse into actionable recommendations: work with stakeholders to design reports and dashboards that answer real business questions, design the data flows to support these, and build the required data transformation pipelines.

Must-Haves
• Experience working at a digital health or similar startup, preferably during the growth phase, in order to function effectively in a fast-paced, rapidly changing environment.
• 7+ years of experience in a Healthcare Analytics or Data Science role, working with large datasets and conducting statistical and quantitative modeling, melding analytics with strong programming, data mining, clustering and segmentation.
• 5+ years of work experience working data science and visualization tools (SQL, R, and/or Python)
• Advanced understanding of data storage, ETL frameworks, data transformation, and validation
• Experience in building BI dashboards using tools such as Looker or Tableau
• Ability to explain technology, techniques and approaches to others

Nice-to-Haves
• Experience leading cross-functional efforts to build scalable systems and data pipelines, working with complex data structures
• Understanding of Generative AI concepts and basic usage of GenAI tools (ChatGPT, Claude, etc.)
• Experience building pipelines using dbt
• Demonstrated project management experience

90 Day Plan

Within your first 90 days at Virta, we expect you will do the following:
• Familiarize yourself with the Advanced Analytics & AI team roles and responsibilities. Get a pulse on team structure, key stakeholders, and areas for opportunity with an eye towards scalability and standardization.
• Integrate with the Adoption Squad to understand team dynamics, analyze key product features and data pipelines, and familiarize yourself with the Squad’s product roadmap
• Analyze current member journey to understand Virta’s technology ecosystem
• Meet cross-functional stakeholders to understand how their business needs align with Squad and Team goals
• Identify at least 1 area of opportunity to leverage GenAI to increase team efficiency or improve our processes
• Teach and inspire your team members through knowledge sharing, pair programming, and giving feedback during code reviews

Values-driven culture

Virta’s company values drive our culture, so you’ll do well if:
• You put people first and take care of yourself, your peers, and our patients equally
• You have a strong sense of ownership and take initiative while empowering others to do the same
• You prioritize positive impact over busy work
• You have no ego and understand that everyone has something to bring to the table regardless of experience
• You appreciate transparency and promote trust and empowerment through open access of information
• You are evidence-based and prioritize data and science over seniority or dogma
• You take risks and rapidly iterate

Is this role not quite what you're looking for? Join our Talent Community and follow us on Linkedin to stay connected!

Virta has a location based compensation structure. Starting pay will be based on a number of factors and commensurate with qualifications & experience. For this role, the compensation range is $167,249 - $216,000. Information about Virta’s benefits is on our Careers page at: https://www.virtahealth.com/careers.

As part of your duties at Virta, you may come in contact with sensitive patient information that is governed by HIPAA. Throughout your career at Virta, you will be expected to follow Virta's security and privacy procedures to ensure our patients' information remains strictly confidential. Security and privacy training will be provided.

As a remote-first company, our team is spread across various locations with office hubs in Denver and San Francisco.
Clinical roles: We currently do not hire in the following states: AK, HI, RI
Corporate roles: We currently do not hire in the following states: AK, AR, DE, HI, ME, MS, NM, OK, SD, VT, WI.

#LI-remote",2025-07-21T00:00:00.000Z,2025-07-25,"['Experience working at a digital health or similar startup, preferably during the growth phase, in order to function effectively in a fast-paced, rapidly changing environment', '7+ years of experience in a Healthcare Analytics or Data Science role, working with large datasets and conducting statistical and quantitative modeling, melding analytics with strong programming, data mining, clustering and segmentation', '5+ years of work experience working data science and visualization tools (SQL, R, and/or Python)', 'Advanced understanding of data storage, ETL frameworks, data transformation, and validation', 'Experience in building BI dashboards using tools such as Looker or Tableau', 'Ability to explain technology, techniques and approaches to others', 'Experience leading cross-functional efforts to build scalable systems and data pipelines, working with complex data structures', 'Understanding of Generative AI concepts and basic usage of GenAI tools (ChatGPT, Claude, etc.)', 'Experience building pipelines using dbt', 'Demonstrated project management experience', 'You have a strong sense of ownership and take initiative while empowering others to do the same', 'You prioritize positive impact over busy work', 'You have no ego and understand that everyone has something to bring to the table regardless of experience', 'You appreciate transparency and promote trust and empowerment through open access of information', 'You are evidence-based and prioritize data and science over seniority or dogma', 'You take risks and rapidly iterate']","['As a Senior Data Scientist on the AAA team, you will play a crucial role in shaping our data-driven decision making processes and in driving impactful insights that advance our mission', 'You will get a chance to work closely with stakeholders to create impactful data-driven reports and analyses that strengthen Virta’s value proposition', 'Serve as data lead for the Adoption Squad:', 'Understand the product – strategy, goals, roadmap, users – deeply enough to identify high-impact, strategic opportunities and risks', 'Use data to steer conversations: bring data-driven hypotheses, challenge assumptions, frame trade-offs, prioritize strategically', 'Translate vague product hunches into sharp analytical questions, and design the right approach to answer them', 'Be the source of truth for KPIs and product metrics: help define and monitor them, and identify trends and drivers', 'Drive decision making with data: Prioritize analyses that meaningfully inform product decisions and change outcomes, reframe analysis requests that won’t do that into ones that will, and design and deliver the resulting analyses properly and rapidly', 'Lead experimentation thoughtfully: guide the team on when and when not to experiment, help enable self-serve experimentation, and focus on frequent, small experiments to speed learning', 'Identify where product strategy and ideas could be better, more easily, or more quickly implemented with the help of AI (ML or GenAI), and help enable this integration', 'Show up as a collaborative leader, not simply a service provider, and help focus work on what matters most', 'Work end-to-end to translate clinical, member, and claims data from our data warehouse into actionable recommendations: work with stakeholders to design reports and dashboards that answer real business questions, design the data flows to support these, and build the required data transformation pipelines', 'Familiarize yourself with the Advanced Analytics & AI team roles and responsibilities', 'Get a pulse on team structure, key stakeholders, and areas for opportunity with an eye towards scalability and standardization', 'Integrate with the Adoption Squad to understand team dynamics, analyze key product features and data pipelines, and familiarize yourself with the Squad’s product roadmap', 'Analyze current member journey to understand Virta’s technology ecosystem', 'Meet cross-functional stakeholders to understand how their business needs align with Squad and Team goals', 'Identify at least 1 area of opportunity to leverage GenAI to increase team efficiency or improve our processes', 'Teach and inspire your team members through knowledge sharing, pair programming, and giving feedback during code reviews']",True,"['Generative AI', 'GenAI Tools']",Generative AI: Recognized as an opportunity to improve team efficiency and product strategy by integrating AI-driven solutions.; GenAI Tools: Basic usage of tools like ChatGPT and Claude to explore AI applications within the analytics team.,"['Statistical and Quantitative Modeling', 'Data Mining', 'Clustering and Segmentation', 'SQL', 'R', 'Python', 'ETL Frameworks', 'Data Transformation and Validation', 'BI Dashboards', 'Data Pipelines', 'dbt', 'Experimentation and A/B Testing']","Statistical and Quantitative Modeling: Used to analyze large healthcare datasets and derive insights for decision making and product strategy.; Data Mining: Applied to extract meaningful patterns and segmentations from complex clinical and member data.; Clustering and Segmentation: Techniques used to group similar data points for targeted analysis and personalized healthcare insights.; SQL: Utilized for querying and managing data within the company’s data warehouse to support reporting and analysis.; R: Used as a programming language for statistical analysis and data visualization in healthcare analytics.; Python: Employed for data science tasks including data transformation, analysis, and building data pipelines.; ETL Frameworks: Applied to extract, transform, and load clinical and claims data into usable formats for analysis.; Data Transformation and Validation: Processes to ensure data quality and readiness for accurate reporting and decision making.; BI Dashboards: Built using tools like Looker and Tableau to visualize KPIs and product metrics for stakeholders.; Data Pipelines: Designed and maintained to automate data flows from raw sources to actionable insights and dashboards.; dbt: Used to build and manage data transformation pipelines supporting scalable analytics.; Experimentation and A/B Testing: Guided and enabled to validate hypotheses and inform product decisions through frequent, small experiments."
fC1QkJ4uJ6xxBy5dAAAAAA==,Data Science & Analytics,"At Blocksi, We Are Always Looking for New Talent

As we strive to enhance student safety and foster a secure global digital school environment, we are actively seeking driven and dedicated team players to collaborate in shaping the future of
school safety with us.

Ready for a career dive into the booming EdTech industry?

Data Science & Analytics

Key player in transforming raw data into valuable business insights, aiding data-driven decision-making. Optimize AI solutions for scalability and manage big data tools and frameworks.

Don’t see an open position? We are always looking for enthusiastic individuals to join our team, so we encourage you to submit your application

Make sure to include your resume and cover letter.",,2025-07-25,['Optimize AI solutions for scalability and manage big data tools and frameworks'],"['Key player in transforming raw data into valuable business insights, aiding data-driven decision-making']",True,['AI Solution Optimization'],"AI Solution Optimization: Optimizing AI solutions for scalability, indicating involvement with AI models or systems to improve performance and deployment at scale.","['Big Data Tools and Frameworks', 'Data-Driven Decision Making']",Big Data Tools and Frameworks: Managing and utilizing big data technologies to handle and process large-scale datasets for analytics and insights.; Data-Driven Decision Making: Transforming raw data into actionable business insights to support strategic decisions.
cNQzFnQ5KGZiafZLAAAAAA==,"Data Scientist, Special Operations Command (Active Secret) Jobs","Rhombus Power is purposefully transforming defense and global security enterprises with Guardian, our Artificial Intelligence platform for strategic, operational, and tactical decision-making at the speed of relevance.

We provide relevant, actionable, and AI-powered insights at each step in the defense decision-making cycle. Equipped with Guardian's AI-powered tools-- from infrastructure to data to insights -- our clients are able to solve their most complex, interconnected challenges and achieve decision and operational superiority.

Come join our cross-disciplinary and world-class team that is delivering game-changing solutions to transform global security.

Learn more about Rhombus and watch a demonstration of Guardian, our AI Platform here -- https://youtube.com/watch?v=3PxY6su1Q-Q

See the following articles to learn more about what we do:

https://foreignpolicy.com/2023/06/19/ai-artificial-intelligence-national-security-foreign-policy-threats-prediction/

https://federalnewsnetwork.com/air-force/2023/12/new-decision-advantage-tool-will-change-how-air-force-makes-investment-decisions/

https://apnews.com/article/us-intelligence-services-ai-models-9471e8c5703306eb29f6c971b6923187

Job description:

As a Data Scientist at Rhombus you will work with our Product team. You will design, develop, and launch efficient and reliable data pipelines to move, analyze, and model data and to provide intuitive analytics from Rhombus’ large and complex datasets. A strong systematic mind is a priority, as well as the ability to communicate clearly in multiple technical contexts.

The ideal candidate should be passionate about finding insights in large datasets, while maintaining attention to database architecture, data reliability, efficiency, and quality. As we are continually releasing new features and products, the ability to construct elegant system-level data architecture is expected.

You will acquire, manipulate, and transform data to breathe life and meaning into arcane holdings, and use your creations to open new doors and opportunities to the customer. An innovative and inquisitive mind is required for success.

Responsibilities:

-Discover datasets that could help in solution development

-Data curation, data evaluation, and data analysis

-Design, create, and implement quantitative models

-Validation and quality assurance of data, models and results

-Deploy and implement solutions in collaboration with product team

-Interact with the product team on current and upcoming user requirements

-Responsiveness to customer feedback delivered by product team and responsiveness to customer timelines

-Systems-level approach to implementation to integrate solutions as part of a larger, interconnected project

Qualifications:

-Active Secret clearance

-A strong academic background in Statistics, Mathematics, Engineering, or similar degree is highly desired. -We prefer candidates to hold at minimum a Masters degree. We have multiple openings!

-Exceptional academic and industry experience with Python and especially with data handling libraries such as Pandas and PyArrow

-Strong background in database management solutions, familiarity with databases such as MySQL and Oracle

-Large-scale data processing and implementing batch processing pipelines in HPC or cloud architecture

-Experience with Cloud Computing environments (AWS, GCloud, Azure) is a plus

Location:

Palo Alto, CA; St. Louis, MO; Tampa, FL; San Antonio, TX; Colorado Springs, CO; Omaha, NE; Washington, D.C.

Benefits:

-Full medical, dental, vision coverage for employee and dependents

-401k matching program

-PTO and Holidays

-Bonus and other incentive programs

-Access to mental health program

-Access to Flexible Spending Accounts for Health Care, Dependent and Commuter

About Rhombus:

Rhombus Power Inc. (Rhombus) is a startup located in the heart of Silicon Valley at Stanford Research Park in Palo Alto.  We use cutting-edge cross-disciplinary approaches to solve pressing Big Data and Sensing problems in security, energy, and healthcare. Our advisory board includes two Nobel Laureates and a Draper Prize winner.

Rhombus compensates, motivates, and develops employees, who are trusted, empowered, and involved. Employees have clear roles and expectations – and their roles are flexible enough to move at the speed of innovation in order to meet and exceed client expectations. We have a unique culture of global purpose, rooted in the innovation and progress of Silicon Valley.

Rhombus knows that diversity is a condition for success. We are committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer.",2025-07-17T00:00:00.000Z,2025-07-25,"['A strong systematic mind is a priority, as well as the ability to communicate clearly in multiple technical contexts', 'The ideal candidate should be passionate about finding insights in large datasets, while maintaining attention to database architecture, data reliability, efficiency, and quality', 'An innovative and inquisitive mind is required for success', 'Active Secret clearance', 'We prefer candidates to hold at minimum a Masters degree', 'Exceptional academic and industry experience with Python and especially with data handling libraries such as Pandas and PyArrow', 'Strong background in database management solutions, familiarity with databases such as MySQL and Oracle', 'Large-scale data processing and implementing batch processing pipelines in HPC or cloud architecture']","['As a Data Scientist at Rhombus you will work with our Product team', 'You will design, develop, and launch efficient and reliable data pipelines to move, analyze, and model data and to provide intuitive analytics from Rhombus’ large and complex datasets', 'As we are continually releasing new features and products, the ability to construct elegant system-level data architecture is expected', 'You will acquire, manipulate, and transform data to breathe life and meaning into arcane holdings, and use your creations to open new doors and opportunities to the customer', 'Discover datasets that could help in solution development', 'Data curation, data evaluation, and data analysis', 'Design, create, and implement quantitative models', 'Validation and quality assurance of data, models and results', 'Deploy and implement solutions in collaboration with product team', 'Interact with the product team on current and upcoming user requirements', 'Responsiveness to customer feedback delivered by product team and responsiveness to customer timelines', 'Systems-level approach to implementation to integrate solutions as part of a larger, interconnected project']",True,[],,"['Data Pipelines', 'Data Curation', 'Quantitative Models', 'Data Validation and Quality Assurance', 'Python', 'Pandas', 'PyArrow', 'Database Management', 'Large-Scale Data Processing', 'Cloud Computing']","Data Pipelines: Designing, developing, and launching efficient pipelines to move, analyze, and model large and complex datasets.; Data Curation: Discovering, evaluating, and preparing datasets to support solution development and analysis.; Quantitative Models: Designing and implementing mathematical or statistical models to extract insights and support decision-making.; Data Validation and Quality Assurance: Ensuring the accuracy, reliability, and quality of data, models, and results before deployment.; Python: Using Python programming language, especially for data handling and analysis tasks.; Pandas: Utilizing the Pandas library for data manipulation and analysis within Python.; PyArrow: Employing PyArrow for efficient in-memory columnar data processing and interoperability.; Database Management: Managing and working with databases such as MySQL and Oracle to support data storage and retrieval.; Large-Scale Data Processing: Implementing batch processing pipelines for handling large datasets in HPC or cloud environments.; Cloud Computing: Using cloud platforms like AWS, Google Cloud, or Azure to support scalable data processing and storage."
fZCgCsjP2DX7ZTUXAAAAAA==,"Sr Data Scientist in Ridgefield, CT","Hi,

Hope you are doing great.

Please go through the job description given below and if you are interested do share an updated word copy of your resume and best time to reach you over the phone.

Position: Sr Data Scientist

Locations: Ridgefield, CT

Duration: Contract

Job Description:
• Sr Data Scientist with overall 10-15 years of IT experience out of which two or more years of hands-on experience designing and deploying GenAI solutions.
• 3+ years of experience in coding Python, R and Shiny
• Develop roadmap and strategy for NLP, LLM, Gen AI model development and lifecycle implementation
• Experience in Pharmaceuticals/Life sciences is preferred",,2025-07-25,"['Sr Data Scientist with overall 10-15 years of IT experience out of which two or more years of hands-on experience designing and deploying GenAI solutions', '3+ years of experience in coding Python, R and Shiny', 'Develop roadmap and strategy for NLP, LLM, Gen AI model development and lifecycle implementation']",,True,"['Generative AI', 'Natural Language Processing', 'Large Language Models']","Generative AI: Designing and deploying generative AI solutions as part of advanced AI model development.; Natural Language Processing: Developing NLP strategies and models, particularly in the context of language understanding and generation.; Large Language Models: Involved in the development and lifecycle management of LLMs for AI-driven applications.","['Python', 'R', 'Shiny']","Python: Used for coding and implementing data science solutions, including statistical analysis and data manipulation.; R: Used for statistical computing and data analysis tasks within the data science workflow.; Shiny: Utilized for building interactive web applications to visualize and communicate data insights."
TJmvQbs8fjvZtjc3AAAAAA==,Data Science Director,"Summary:

We’re looking for a seasoned analytics leader to drive data-informed decisions for Meta. You will play a critical role in helping Meta build the platforms of the future. You will partner with the product and business teams that build and grow our infrastructure for the future of Meta. You will be focused on results, be proactive, deliver rigorous analyses, and use data to drive change in products, strategies, and organizations.About the role:People leadership: You will inspire, lead and grow a world-class team.Product leadership: You will use data to shape development, quantify new opportunities, identify upcoming challenges, and ensure the products we build bring value to people, businesses, and Meta. You will help your partner teams prioritize what to build, set goals, and understand their product’s ecosystem.Analytics: You will guide teams using data and insights. You will focus on developing hypotheses and employ a broad toolkit of rigorous analytical approaches, different methodologies, frameworks, and technical approaches to test them.Communication and influence: You won’t simply present data, but tell data-driven stories. You will convince and influence your partners using clear insights and recommendations. You will build credibility through structure and clarity, and be a trusted strategic partner.

Required Skills:

Data Science Director Responsibilities:
• Inspire, lead and grow a distributed team of data scientists and data science leaders across North America
• Apply your expertise in quantitative analysis, data mining, and the presentation of data in developing data-informed strategies for growing and improving our product offerings.
• Contribute to long-term technical vision and strategy methods and metrics that will improve the quality and efficiency of our products at scale.
• Lead development and communication of product area insights and recommended action items with Meta Analytics leadership.

Minimum Qualifications:

Minimum Qualifications:
• 10+ years of work experience managing analytics teams, working collaboratively with Product and Infrastructure teams, and guiding data-influenced product and business planning, prioritization and strategy development.
• Demonstrated experience in hiring, retaining and scaling geographically dispersed, high-performing teams with a broad range of experiences, perspectives, approaches, and backgrounds
• Proven experience influencing strategy and driving change across org boundaries through clear and compelling communication of data-driven insights and analyses.
• Intellectual curiosity, drive, and decisiveness with ambiguous and complex enviornments.
• Experience working effectively with multiple stakeholders and cross-functionally.
• Effective communication skills.

Preferred Qualifications:

Preferred Qualifications:
• Experience with both product and business analytics work and demonstrated to deliver an integrated approach.

Public Compensation:

$253,000/year to $314,000/year + bonus + equity + benefits

Industry: Internet

Equal Opportunity:

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.",2025-07-02T00:00:00.000Z,2025-07-25,"['10+ years of work experience managing analytics teams, working collaboratively with Product and Infrastructure teams, and guiding data-influenced product and business planning, prioritization and strategy development', 'Demonstrated experience in hiring, retaining and scaling geographically dispersed, high-performing teams with a broad range of experiences, perspectives, approaches, and backgrounds', 'Proven experience influencing strategy and driving change across org boundaries through clear and compelling communication of data-driven insights and analyses', 'Intellectual curiosity, drive, and decisiveness with ambiguous and complex enviornments', 'Experience working effectively with multiple stakeholders and cross-functionally', 'Effective communication skills', 'Meta participates in the E-Verify program in certain locations, as required by law']","['You will play a critical role in helping Meta build the platforms of the future', 'You will partner with the product and business teams that build and grow our infrastructure for the future of Meta', 'You will be focused on results, be proactive, deliver rigorous analyses, and use data to drive change in products, strategies, and organizations', 'Product leadership: You will use data to shape development, quantify new opportunities, identify upcoming challenges, and ensure the products we build bring value to people, businesses, and Meta', 'You will help your partner teams prioritize what to build, set goals, and understand their product’s ecosystem.Analytics: You will guide teams using data and insights', 'You will focus on developing hypotheses and employ a broad toolkit of rigorous analytical approaches, different methodologies, frameworks, and technical approaches to test them', 'Communication and influence: You won’t simply present data, but tell data-driven stories', 'You will convince and influence your partners using clear insights and recommendations', 'You will build credibility through structure and clarity, and be a trusted strategic partner', 'Inspire, lead and grow a distributed team of data scientists and data science leaders across North America', 'Apply your expertise in quantitative analysis, data mining, and the presentation of data in developing data-informed strategies for growing and improving our product offerings', 'Contribute to long-term technical vision and strategy methods and metrics that will improve the quality and efficiency of our products at scale', 'Lead development and communication of product area insights and recommended action items with Meta Analytics leadership']",True,[],,"['Quantitative Analysis', 'Data Mining', 'Data-Driven Storytelling', 'Analytical Methodologies and Frameworks', 'Product and Business Analytics']","Quantitative Analysis: Used to develop data-informed strategies and guide product and business planning through rigorous numerical evaluation.; Data Mining: Applied to extract meaningful patterns and insights from large datasets to support product growth and improvement.; Data-Driven Storytelling: Employed to communicate insights effectively and influence stakeholders by presenting clear, structured data narratives.; Analytical Methodologies and Frameworks: Utilized to develop hypotheses and rigorously test them using a broad toolkit of analytical approaches.; Product and Business Analytics: Integrated approach to analyze product performance and business metrics to identify opportunities and challenges."
uodVhdEIF9g9sV9JAAAAAA==,Data Scientist,"Haystack News is the leading local & world news service on Connected TVs reaching millions of users! This is a unique opportunity to work at Haystack News, one of the fastest-growing TV startups in the world. We are already preloaded on 37% of all TVs shipped in the US!

Be part of a Silicon Valley startup and work directly with the founding team. Jumpstart your career by working with Stanford & Carnegie Mellon alumni and faculty who have already been part of other successful startups in Silicon Valley.

You should join us if you're hungry to learn how Silicon Valley startups thrive, you like to ship quickly and often, love to solve challenging problems, and like working in small teams.

See Haystack feature at Google IO: https://www.youtube.com/watch?v=-YawUi6qPck

Job functions

We are looking for an outstanding Data Scientist to join Haystack and help improve the experience of millions of users that rely on Haystack to get the news every day.

Within the team you’ll find many opportunities to work on various aspects of Data Science, Machine Learning, and Data Engineering. The job offers the opportunity of generating a major impact on the product while working with an awesome and talented team, using the latest technologies.

You will:
• Analyze large data sets to get insights using statistical analysis tools and techniques
• Build, evaluate and deploy machine learning models
• Maintain ongoing reliability, performance, and support of the data infrastructure, providing solutions based on application needs and anticipated growth.
• Work with tools to configure, monitor and orchestrate data infrastructure and pipelines.
• Run and monitor AB Tests
• Build and manage APIs

Qualifications and requirements
• Bachelor's degree in Computer Science, Statistics, Math or related field.
• 3+ years experience writing software in a professional setting
• Knowledge of AWS and Python
• Strong Math/Stats background with statistical analysis experience on big data sets
• Experience with SQL and NoSQL (e.g. MongoDb or DynamoDB)
• Big Plus: Experience with data warehouses (e.g. Snowflake, Big Query, Redshift)
• Exposure to ML/AI libraries such as sklearn, LightGBM and, XGBoost.
• Travel Visa to the US (desired)

Conditions
• Uber rides to come to the office!
• Travel to team's offsite events
• Learn about multiple technologies",,2025-07-25,"[""Bachelor's degree in Computer Science, Statistics, Math or related field"", '3+ years experience writing software in a professional setting', 'Knowledge of AWS and Python', 'Strong Math/Stats background with statistical analysis experience on big data sets', 'Experience with SQL and NoSQL (e.g. MongoDb or DynamoDB)', 'Big Plus: Experience with data warehouses (e.g. Snowflake, Big Query, Redshift)', 'Exposure to ML/AI libraries such as sklearn, LightGBM and, XGBoost']","['We are looking for an outstanding Data Scientist to join Haystack and help improve the experience of millions of users that rely on Haystack to get the news every day', 'Analyze large data sets to get insights using statistical analysis tools and techniques', 'Build, evaluate and deploy machine learning models', 'Maintain ongoing reliability, performance, and support of the data infrastructure, providing solutions based on application needs and anticipated growth', 'Work with tools to configure, monitor and orchestrate data infrastructure and pipelines', 'Run and monitor AB Tests', 'Build and manage APIs', ""Travel to team's offsite events""]",True,[],,"['Statistical Analysis', 'Machine Learning', 'A/B Testing', 'Data Infrastructure and Pipelines', 'SQL and NoSQL Databases', 'Data Warehouses', 'Python', 'ML Libraries', 'API Development', 'Cloud Computing (AWS)']","Statistical Analysis: Used to analyze large data sets to extract insights and inform decision-making.; Machine Learning: Building, evaluating, and deploying predictive models to improve user experience.; A/B Testing: Running and monitoring experiments to evaluate the impact of changes on user engagement.; Data Infrastructure and Pipelines: Configuring, monitoring, and orchestrating data workflows to ensure reliable data availability.; SQL and NoSQL Databases: Using relational and non-relational databases like MongoDB and DynamoDB for data storage and retrieval.; Data Warehouses: Experience with cloud-based warehouses such as Snowflake, BigQuery, and Redshift for large-scale data analytics.; Python: Programming language used for data analysis, machine learning model development, and scripting.; ML Libraries: Utilizing libraries like scikit-learn, LightGBM, and XGBoost for building machine learning models.; API Development: Building and managing APIs to enable data access and integration with other systems.; Cloud Computing (AWS): Using AWS services to support data infrastructure and machine learning workflows."
lNUvseFlY2wc0alQAAAAAA==,Imaging Data Scientist,"Overview

Frontier Technology Inc. (FTI) is seeking an experienced Data Scientist with a background in imaging science to support existing contracts in our Beverly, MA office. FTI’s Data, Cyber and Integrated Services (DCIS) group provides software development, data science, cyber security, and systems engineering support to FTI through a matrixed organization. The Image Science team based in Beverly, MA provides science and software development services to space-based electro-optical infrared (EOIR) sensor programs. Machine learning, AI-augmented decision support, and space wargaming are all directions of company growth, and experience or interest in these areas are desired. We have extensive experience in systems engineering, sensor requirements definition, sensor design, sensor calibration, data analysis, radiometric performance validation, physics-based and phenomenological simulation tools, and data management. Apply knowledge of statistics, machine learning, programming, data modeling, simulation, and advanced mathematics to recognize patterns, identify opportunities, pose business questions, and make valuable discoveries leading to prototype development and product improvement.

Responsibilities
• Develop algorithms associated with image processing, sensor calibration, data simulation and modeling, and software automation.
• Perform analysis of sensor data, simulated systems and algorithms.
• Work with other scientists on the team collaboratively to complete algorithm development or analysis tasks.
• Interface with software developers on the team to define software requirements and guide software implementation.
• Interface with customers to brief work and define tasking.
• Use a flexible, analytical approach to design, develop, and evaluate predictive models and advanced algorithms that lead to optimal value extraction from the data.

Education/Qualifications
• Must be a U.S. Citizen and currently have a TS clearance that will require an SCI upgrade. Current TS/SCI is preferred.
• Bachelor's or Master’s degree in Computer Science, Statistics, Mathematics, Data Science, Engineering, Astronomy, Physics, or a related technical field. Prefer PhD.
• Practical knowledge of telescopes, optical systems, and focal plane arrays, including observation planning or mission design.
• Strong technical background in astronomy or remote sensing.
• Experience with standard data analysis and reduction procedures.
• Strong foundation in mathematics. Experience with the application of statistical concepts and techniques to data preferred.
• Scientific programming competency in Python or Matlab.
• Excellent communication skills, with emphasis on the ability to communicate technical results to non-technical audiences (such as customers).
• Experience in statistical inference, machine learning for target detection and discrimination, or in AI-augmented decision support
• This position will require minimal travel and will be in our Beverly, MA office.

Optional Experience:
• Optical signatures modeling.
• Multi-scale modeling, first principles and phenomenological simulation of physical systems.
• Technical work on a sensor program.

#LI-GH1

#LI-Onsite",,2025-07-25,"['We have extensive experience in systems engineering, sensor requirements definition, sensor design, sensor calibration, data analysis, radiometric performance validation, physics-based and phenomenological simulation tools, and data management', 'Apply knowledge of statistics, machine learning, programming, data modeling, simulation, and advanced mathematics to recognize patterns, identify opportunities, pose business questions, and make valuable discoveries leading to prototype development and product improvement', 'Must be a U.S. Citizen and currently have a TS clearance that will require an SCI upgrade', 'Prefer PhD', 'Practical knowledge of telescopes, optical systems, and focal plane arrays, including observation planning or mission design', 'Strong technical background in astronomy or remote sensing', 'Experience with standard data analysis and reduction procedures', 'Strong foundation in mathematics', 'Optical signatures modeling', 'Multi-scale modeling, first principles and phenomenological simulation of physical systems', 'Technical work on a sensor program']","['Develop algorithms associated with image processing, sensor calibration, data simulation and modeling, and software automation', 'Perform analysis of sensor data, simulated systems and algorithms', 'Work with other scientists on the team collaboratively to complete algorithm development or analysis tasks', 'Interface with software developers on the team to define software requirements and guide software implementation', 'Interface with customers to brief work and define tasking', 'Use a flexible, analytical approach to design, develop, and evaluate predictive models and advanced algorithms that lead to optimal value extraction from the data']",True,['AI-Augmented Decision Support'],AI-Augmented Decision Support: Incorporating AI techniques to enhance decision-making processes based on sensor data analysis.,"['Image Processing', 'Sensor Calibration', 'Data Simulation and Modeling', 'Statistical Inference', 'Machine Learning', 'Predictive Modeling', 'Data Analysis and Reduction', 'Programming in Python and Matlab', 'Physics-Based and Phenomenological Simulation', 'Advanced Mathematics']","Image Processing: Developing algorithms to analyze and enhance sensor image data for improved interpretation and use.; Sensor Calibration: Creating and applying methods to adjust sensor data for accuracy and consistency in measurements.; Data Simulation and Modeling: Using simulation tools and models to replicate sensor behavior and physical systems for analysis and algorithm development.; Statistical Inference: Applying statistical techniques to draw conclusions from sensor and experimental data.; Machine Learning: Utilizing machine learning methods for target detection, discrimination, and predictive modeling based on sensor data.; Predictive Modeling: Designing and evaluating models that forecast outcomes or classify data patterns from sensor inputs.; Data Analysis and Reduction: Performing standard procedures to process and simplify raw sensor data for meaningful insights.; Programming in Python and Matlab: Using Python and Matlab for scientific programming, algorithm development, and data analysis.; Physics-Based and Phenomenological Simulation: Employing multi-scale and first principles simulations to model physical systems relevant to sensor data.; Advanced Mathematics: Applying mathematical concepts to support data modeling, algorithm development, and analysis."
YLxEIPUAI7fhR_mYAAAAAA==,Senior AI Data Scientist,"General Information

Locations: Kirkland, Washington, United States of America
• Location: Los Angeles - Chatsworth
• Country: United States of America
• Location: Austin
• Country: United States of America
• Location: Vancouver
• Country: Canada
• Location: Toronto
• Country: Canada
• Location: Edmonton
• Country: Canada
• Location: Orlando
• Country: United States of America
• Location: Redwood City
• Country: United States of America

Role ID

209183

Worker Type

Regular Employee

Studio/Department

EA Studios - CAP Central

Work Model

Hybrid

Description & Requirements

Electronic Arts creates next-level entertainment experiences that inspire players and fans around the world. Here, everyone is part of the story. Part of a community that connects across the globe. A place where creativity thrives, new perspectives are invited, and ideas matter. A team where everyone makes play happen.

Empowering players to create is an exciting future for the gaming industry. At Electronic Arts we have many examples of players creating content, whether it be a skateboard park in Skate or fantastical mansions in the Sims 4. The future definitely has our players being more empowered to create with their imagination being the only limit.

We are looking for a Data Scientist to help shape the future of content creation and gameplay with AI. If you have the right expertise and are interested we want to hear from you!

As a Senior AI Data Scientist you will:
• Build, fine-tune and implement AI and machine learning models to solve challenging problems
• Ensure AI and machine learning production pipelines are scalable, repeatable and cloud agnostic
• Apply current and emerging techniques in deep learning, natural language processing and other machine learning areas
• Collect, clean, manage, analyze and visualize large sets of data using multiple data platforms, tools and technique
• Work in partnership with game teams to integrate AI solutions into products and services.
• Optimize and fine-tune AI models for performance and scalability. Analyze and interpret data to extract meaningful insights and improve AI models.
• Document and present findings and solutions to stakeholders.

Desired qualifications and experience:
• A minimum of 3+ years of experience in data science
• PhD or MSc in statistics, mathematics, computer science, or related field
• Strong expertise in deep learning, fluent in Python and SQL
• Expertise in automating machine learning models and building end to end products
• Experience with devops tools and principles (Git, CI/CD, Docker)
• Effective within Cloud environments (GCP, AWS)
• Understanding of containerization and orchestration technologies (Docker, Kubernetes, etc.)
• C++ and game development experience is a plus.

COMPENSATION AND BENEFITS

The ranges listed below are what EA in good faith expects to pay applicants for this role in these locations at the time of this posting. If you reside in a different location, a recruiter will advise on the applicable range and benefits. Pay offered will be determined based on a number of relevant business and candidate factors (e.g. education, qualifications, certifications, experience, skills, geographic location, or business needs).

PAY RANGES
• British Columbia (depending on location e.g. Vancouver vs. Victoria) * $96,400 - $133,900 CAD
• California (depending on location e.g. Los Angeles vs. Sacramento) * $122,300 - $170,600 USD
• Washington (depending on location e.g. Seattle vs. Spokane) * $104,000 - $174,700 USD

In the US, we offer a package of benefits including paid time off (3 weeks per year to start), 80 hours per year of sick time, 16 paid company holidays per year, 10 weeks paid time off to bond with baby, medical/dental/vision insurance, life insurance, disability insurance, and 401(k) to regular full-time employees. Certain roles may also be eligible for bonus and equity.

In British Columbia, we offer a package of benefits including vacation (3 weeks per year to start), 10 days per year of sick time, paid top-up to EI/QPIP benefits up to 100% of base salary when you welcome a new child (12 weeks for maternity, and 4 weeks for parental/adoption leave), extended health/dental/vision coverage, life insurance, disability insurance, retirement plan to regular full-time employees. Certain roles may also be eligible for bonus and equity.

About Electronic Arts

We’re proud to have an extensive portfolio of games and experiences, locations around the world, and opportunities across EA. We value adaptability, resilience, creativity, and curiosity. From leadership that brings out your potential, to creating space for learning and experimenting, we empower you to do great work and pursue opportunities for growth.

We adopt a holistic approach to our benefits programs, emphasizing physical, emotional, financial, career, and community wellness to support a balanced life. Our packages are tailored to meet local needs and may include healthcare coverage, mental well-being support, retirement savings, paid time off, family leaves, complimentary games, and more. We nurture environments where our teams can always bring their best to what they do.

Electronic Arts is an equal opportunity employer. All employment decisions are made without regard to race, color, national origin, ancestry, sex, gender, gender identity or expression, sexual orientation, age, genetic information, religion, disability, medical condition, pregnancy, marital status, family status, veteran status, or any other characteristic protected by law. We will also consider employment qualified applicants with criminal records in accordance with applicable law. EA also makes workplace accommodations for qualified individuals with disabilities as required by applicable law.",,2025-07-25,['California (depending on location e.g'],"['Build, fine-tune and implement AI and machine learning models to solve challenging problems', 'Ensure AI and machine learning production pipelines are scalable, repeatable and cloud agnostic', 'Apply current and emerging techniques in deep learning, natural language processing and other machine learning areas', 'Collect, clean, manage, analyze and visualize large sets of data using multiple data platforms, tools and technique', 'Work in partnership with game teams to integrate AI solutions into products and services', 'Optimize and fine-tune AI models for performance and scalability', 'Analyze and interpret data to extract meaningful insights and improve AI models', 'Document and present findings and solutions to stakeholders']",True,"['Deep Learning', 'Natural Language Processing', 'AI Model Fine-Tuning', 'AI Production Pipelines']","Deep Learning: Applying deep learning techniques to develop advanced AI models for gameplay and content creation.; Natural Language Processing: Utilizing NLP methods to enhance AI capabilities related to language understanding within gaming contexts.; AI Model Fine-Tuning: Optimizing and fine-tuning AI models to improve performance and scalability in production.; AI Production Pipelines: Building scalable, repeatable, and cloud-agnostic pipelines specifically for deploying AI and machine learning models.","['Data Cleaning and Management', 'Data Analysis and Visualization', 'Machine Learning Models', 'SQL', 'Python', 'Cloud Computing (GCP, AWS)', 'DevOps Tools (Git, CI/CD, Docker)', 'Containerization and Orchestration (Docker, Kubernetes)']","Data Cleaning and Management: Collecting, cleaning, and managing large datasets to ensure quality data for analysis and model training.; Data Analysis and Visualization: Analyzing and visualizing data to extract meaningful insights that inform AI model improvements and business decisions.; Machine Learning Models: Building and implementing machine learning models to solve complex problems related to gameplay and content creation.; SQL: Using SQL for querying and managing data within various data platforms as part of data processing workflows.; Python: Utilizing Python programming language for data science tasks, model development, and automation.; Cloud Computing (GCP, AWS): Deploying and scaling data science and machine learning pipelines in cloud environments like Google Cloud Platform and Amazon Web Services.; DevOps Tools (Git, CI/CD, Docker): Applying DevOps principles and tools to automate machine learning model deployment and ensure scalable production pipelines.; Containerization and Orchestration (Docker, Kubernetes): Using containerization and orchestration technologies to manage scalable and repeatable AI/ML production environments."
-XlZLA8_bDy1vpVpAAAAAA==,Data Scientist II,"Overview

This position sits within our Product Development division, which develops, tests, and improves our software solutions in an innovative and collaborative environment.

ConstructConnect is looking for a full-time Data Scientist II.

The construction industry is ready for innovation. Metrics show an increase in buildings but a downturn in available labor. ConstructConnect is ready to fill this gap through a variety of artificial intelligence and machine learning approaches. Our opportunity to achieve this goal is vast and varied. We are leveraging natural language processing, object detection, image segmentation, and classifiers to name a few.

The ideal candidate for this role will have a deep interest in building models, developing training data, and researching the best algorithm to apply to a given situation. They will bring an energy for innovation and a desire to learn new techniques and tools. Come help us build the future of the pre-bid construction industry!

The Opportunity

As a Data Scientist II, you will play a crucial role in leveraging data-driven insights to guide strategic decision-making and drive business growth. You will engage in developing Machine Learning and AI solutions to complicated problems on the leading edge of construction planning technology. You will have the opportunity to design, develop and implement best-in-class solutions for our organization and our clients.

Responsibilities

What You’ll Be Doing
• Collaborate with cross-functional teams to define requirements, curate high-quality training datasets, and develop machine learning solutions for business challenges.
• Drive innovation by researching and experimenting with cutting-edge algorithms, architectures, and techniques.
• Optimize and fine-tune deep learning models to improve its performance, accuracy, and efficiency.
• Conduct thorough evaluations and assessments of models, providing recommendations for enhancements and optimizations.
• Contribute to the development of internal frameworks, and libraries to streamline ML workflows.
• Communicate research findings, insights, and recommendations effectively to both technical and non-technical stakeholders.
• Stay informed about industry trends, best practices, and emerging technologies in AI.
• Mentor and provide guidance to the team, sharing best practices.
• This job description in no way implies that the duties listed here are the only ones that team members can be required to perform

Qualifications

What Y ou Bring to the Team
• Creative problem-solver who is passionate about digging into complex problems and devising innovative approaches to reach results.
• Effective communication skills and experience distilling and presenting complex quantitative analysis into action-oriented recommendations.
• Proven experience as a Data Scientist, with a focus on computer vision, NLP, or predictive analytics.
• Solid understanding of deep learning architectures for computer vision and NLP.
• Knowledge of computer vision techniques, such as classification, object detection, and image segmentation.
• Familiarity with computer vision libraries and tools, such as OpenCV, scikit-image.
• Strong understanding of NLP methods and techniques, including text preprocessing, word embeddings, and language modeling.
• Proficiency in machine learning frameworks, such as TensorFlow, PyTorch , or scikit-learn.
• Strong programming skills in Python, with experience in data manipulation, analysis, and visualization using libraries such as Pandas, NumPy, and Matplotlib.
• Experience with cloud platforms, such as GCP, and deploying models to production environments is a plus.
• Bachelor's degree or equivalent experience in data science, Statistics, Computer Science, or a related field.

Physical Demands And Work Environment
• The physical activities of this position include frequent sitting, telephone communication, and working on a computer for extended periods. Visual acuity is required to perform activities close to the eyes.
• Team members are expected to maintain a dedicated and ergonomically appropriate remote workspace.
• Team members who live within commuting distance of one of our office locations (Greater Cincinnati/Northern Kentucky or Atlanta, Georgia) are expected to work in a hybrid capacity, with regular in-office presence as determined by the team or department.
• All team members must reside and perform their work within the United States. .

E-Verify Statement

ConstructConnect utilizes the E-Verify program with every potential new hire. This makes it possible for us to make certain that every employee who works for ConstructConnect is eligible to work in the United States. To learn more about E-Verify you can call 1-800-255-7688 or visit their website. E-Verify® is a registered trademark of the United States Department of Homeland Security.

Privacy Notice",2025-07-23T00:00:00.000Z,2025-07-25,"['Effective communication skills and experience distilling and presenting complex quantitative analysis into action-oriented recommendations', 'Proven experience as a Data Scientist, with a focus on computer vision, NLP, or predictive analytics', 'Solid understanding of deep learning architectures for computer vision and NLP', 'Knowledge of computer vision techniques, such as classification, object detection, and image segmentation', 'Familiarity with computer vision libraries and tools, such as OpenCV, scikit-image', 'Strong understanding of NLP methods and techniques, including text preprocessing, word embeddings, and language modeling', 'Proficiency in machine learning frameworks, such as TensorFlow, PyTorch , or scikit-learn', 'Strong programming skills in Python, with experience in data manipulation, analysis, and visualization using libraries such as Pandas, NumPy, and Matplotlib', ""Bachelor's degree or equivalent experience in data science, Statistics, Computer Science, or a related field"", 'Visual acuity is required to perform activities close to the eyes', 'Team members are expected to maintain a dedicated and ergonomically appropriate remote workspace', 'Team members who live within commuting distance of one of our office locations (Greater Cincinnati/Northern Kentucky or Atlanta, Georgia) are expected to work in a hybrid capacity, with regular in-office presence as determined by the team or department', 'All team members must reside and perform their work within the United States']","['The ideal candidate for this role will have a deep interest in building models, developing training data, and researching the best algorithm to apply to a given situation', 'They will bring an energy for innovation and a desire to learn new techniques and tools', 'As a Data Scientist II, you will play a crucial role in leveraging data-driven insights to guide strategic decision-making and drive business growth', 'You will engage in developing Machine Learning and AI solutions to complicated problems on the leading edge of construction planning technology', 'You will have the opportunity to design, develop and implement best-in-class solutions for our organization and our clients', 'Collaborate with cross-functional teams to define requirements, curate high-quality training datasets, and develop machine learning solutions for business challenges', 'Drive innovation by researching and experimenting with cutting-edge algorithms, architectures, and techniques', 'Optimize and fine-tune deep learning models to improve its performance, accuracy, and efficiency', 'Conduct thorough evaluations and assessments of models, providing recommendations for enhancements and optimizations', 'Contribute to the development of internal frameworks, and libraries to streamline ML workflows', 'Communicate research findings, insights, and recommendations effectively to both technical and non-technical stakeholders', 'Stay informed about industry trends, best practices, and emerging technologies in AI', 'Mentor and provide guidance to the team, sharing best practices', 'This job description in no way implies that the duties listed here are the only ones that team members can be required to perform', 'Creative problem-solver who is passionate about digging into complex problems and devising innovative approaches to reach results', 'The physical activities of this position include frequent sitting, telephone communication, and working on a computer for extended periods']",True,"['Generative AI', 'Deep Learning Architectures']",Generative AI: Leveraging artificial intelligence approaches including generative models to innovate in construction technology.; Deep Learning Architectures: Applying advanced neural network architectures specifically for computer vision and NLP tasks.,"['Machine Learning', 'Computer Vision', 'Natural Language Processing', 'Deep Learning', 'Training Data Development', 'Model Evaluation and Optimization', 'Python Programming', 'TensorFlow', 'PyTorch', 'Scikit-learn', 'OpenCV', 'Scikit-image', 'Data Visualization', 'Cloud Platforms']","Machine Learning: Developing and applying machine learning solutions to solve business challenges in construction planning.; Computer Vision: Using techniques like classification, object detection, and image segmentation to analyze visual data relevant to construction.; Natural Language Processing: Applying NLP methods such as text preprocessing, word embeddings, and language modeling to process and analyze textual data.; Deep Learning: Optimizing and fine-tuning deep learning architectures to improve model performance for computer vision and NLP tasks.; Training Data Development: Curating high-quality training datasets to support the development of machine learning and AI models.; Model Evaluation and Optimization: Conducting thorough assessments of models and recommending enhancements to improve accuracy and efficiency.; Python Programming: Using Python for data manipulation, analysis, and visualization with libraries such as Pandas, NumPy, and Matplotlib.; TensorFlow: Employing TensorFlow as a machine learning framework to build and train models.; PyTorch: Utilizing PyTorch for developing and fine-tuning deep learning models.; Scikit-learn: Applying scikit-learn for traditional machine learning tasks and model development.; OpenCV: Using OpenCV library for computer vision tasks such as image processing and object detection.; Scikit-image: Leveraging scikit-image for image processing and analysis in computer vision projects.; Data Visualization: Creating visual representations of data and model results using Matplotlib to communicate insights.; Cloud Platforms: Experience with cloud platforms like GCP for deploying machine learning models to production environments."
mQpi1jdqC_qPbVz-AAAAAA==,"General / data scientist / research analyst - direct at US Department of the Air Force Agency Wide Eglin Air Force Base, FL","General / data scientist / research analyst - direct job at US Department of the Air Force Agency Wide. Eglin Air Force Base, FL.

Duties

For additional information on direct hire opportunities with the Air Force please click here .

Duties:
• Supervise government civilians within the Advanced Capabilities Flight.
• Oversee supervisory administrative aspects such as time off, travel, talent management and retention.
• Act as hiring manager for new employees and oversee on-boarding.
• Organize, train, and equip team of test engineers, scientists, aircrew, logisticians, and support personnel to accomplish flight test mission sets.
• Provide technical subject matter expertise where applicable to solve issues that arise during flight test.
• Communicate program status to squadron and group leadership. Provide early indications of concerns before they manifest as issues.
• Provide technical continuity for military and civilian workforce.

Requirements
Conditions of Employment
• U.S. Citizenship Required
• Telework may be authorized.
• If authorized, PCS will be paid IAW JTR and AF Regulations. If receiving an authorized PCS, you may be subject to completing/signing a CONUS agreement. More information on PCS requirements, may be found at:
• Security clearance requirements are based upon actual position being filled.
• Locations are not negotiable. The actual duty locations available may be located on the Air Force Civilian Service website.
• Random drug testing may be required depending upon the position being filled.
• Supervisory requirements may be required depending upon the position being filled.
• Promotion potential may be authorized depending upon position being filled.
• For additional information on direct hire opportunities with the Air Force please go to
• Full/part-time employees occupying direct childcare positions are eligible for discounts IAW DAF AFSVC/CC Memo, 30 Sep 22; first child 100% / each additional child 25%. Other assigned CYP and FCC personnel are eligible for 25% discount.
• A professional degree at the bachelor’s level from a department that administers at least one engineering degree currently accredited by the Accreditation Board of Engineering and Technology (ABET) is highly desired
• Possess a bachelor’s degree in a related technical discipline such as mathematics, computer science, one of the physical sciences or engineering.
• Work may occasionally require travel away from the normal duty station on military or commercial aircraft.
• The work requires the employee to obtain and maintain the appropriate security clearance.
• This is an acquisition position and is covered by the Acquisition Professional Development Program (APDP).
• Applicant must be capable of achieving the APDP certification.

Qualifications

For additional information on direct hire opportunities with the Air Force please click here .

In order to qualify, you must meet the specialized experience requirements described in the Office of Personnel Management (OPM) Qualification Standards for General Schedule Positions, Administrative and Management positions located here

SPECIALIZED EXPERIENCE: Applicants must have at least one (1) year of specialized experience at the next lower broadband NH-03 or equivalent to the next lower grade GS-12 thru GS-13 in the Federal Service.

Knowledge, Skills and Abilities
• Knowledge of a wide range of advanced multidisciplinary professional engineering/data science/computer science/research analysis concepts, principles, practices, standards, methods, and techniques to apply experimental theories and new developments to problems not susceptible to treatment by accepted methods, and to plan and execute specialized programs of marked difficulty, responsibility, and significance.
• Knowledge of the mission, roles, functions, organizational structure, and operation of the DoD, Air Force, and

organizations that govern, interface with, and/or influence systems acquisition, development, and/or

sustainment; and knowledge of planning, programming, and budgeting cycles, financial systems, and restrictions on expenditure of funds.
• Knowledge of and skill in evaluating state-of-the-art and advancements in theory, application, technology, and policy affecting systems being developed, and in planning, organizing, and directing the functions and staff in critical aspects of development, production, and/or support of systems, subsystems, or equipment.
• Knowledge of safety, security, personnel management, and Equal Employment Opportunity (EEO) regulations, practices, and procedures.
• Skill in establishing and maintaining effective relationships, building consensus and coalitions, negotiating, and resolving conflicts with a variety of individuals and organizations as well as communicating effectively, both orally and in writing.
• Ability to plan, organize, and direct the functions of an organization, and mentor, motivate, and appraise the staff through subordinate supervisors as well as analyze, plan, and adjust work operations of one or more organizational segments to meet program requirements and objectives within available resources.

Education

All Professional Engineering Positions, 0800

Individual Occupational Requirements

A. Degree: Engineering. To be acceptable, the program must:
(1) lead to a bachelor's degree in a school of engineering with at least one program accredited by ABET; or
(2) include differential and integral calculus and courses (more advanced than first-year physics and chemistry) in five of the following seven areas of engineering science or physics: (a) statics, dynamics; (b) strength of materials (stress-strain relationships); (c) fluid mechanics, hydraulics; (d) thermodynamics; (e) electrical fields and circuits; (f) nature and properties of materials (relating particle and aggregate structure to properties); and (g) any other comparable area of fundamental engineering science or physics, such as optics, heat transfer, soil mechanics, or electronics. OR

B. Combination of education and experience - college-level education, training, and/or technical experience that furnished (1) a thorough knowledge of the physical and mathematical sciences underlying engineering, and (2) a good understanding, both theoretical and practical, of the engineering sciences and techniques and their applications to one of the branches of engineering. The adequacy of such background must be demonstrated by one of the following: 1. Professional registration or licensure - Current registration as an Engineer Intern (EI), Engineer in Training (EIT)1 , or licensure as a Professional Engineer (PE) by any State, the District of Columbia, Guam, or Puerto Rico. Absent other means of qualifying under this standard, those applicants who achieved such registration by means other than written test (e.g., State grandfather or eminence provisions) are eligible only for positions that are within or closely related to the specialty field of their registration. For example, an applicant who attains registration through a State Board's eminence provision as a manufacturing engineer typically would be rated eligible only for manufacturing engineering positions. 2. Written Test - Evidence of having successfully passed the Fundamentals of Engineering (FE)2 examination or any other written test required for professional registration by an engineering licensure board in the various States, the District of Columbia, Guam, and Puerto Rico. 3. Specified academic courses - Successful completion of at least 60 semester hours of courses in the physical, mathematical, and engineering sciences and that included the courses specified in the basic requirements under paragraph A. The courses must be fully acceptable toward meeting the requirements of an engineering program as described in paragraph A. 4. Related curriculum - Successful completion of a curriculum leading to a bachelor's degree in an appropriate scientific field, e.g., engineering technology, physics, chemistry, architecture, computer science, mathematics, hydrology, or geology, may be accepted in lieu of a bachelor's degree in engineering, provided the applicant has had at least 1 year of professional engineering experience acquired under professional engineering supervision and guidance. Ordinarily there should be either an established plan of intensive training to develop professional engineering competence, or several years of prior professional engineering-type experience, e.g., in interdisciplinary positions. (The above examples of related curricula are not all-inclusive.) Note: An applicant who meets the basic requirements as specified in A or B above, except as noted under B.1., may qualify for positions in any branch of engineering unless selective factors indicate otherwise.
Data Science Series 1560
Qualifications Standard for Data Science Series, 1560
Basic Requirements:
• Degree: Mathematics, statistics, computer science, data science or field directly related to the position. The degree must be in a major field of study (at least at the baccalaureate level) that is appropriate for the position.

or
• Combination of education and experience: Courses equivalent to a major field of study (30 semester hours) as shown in paragraph A above, plus additional education or appropriate experience.

Operations Research Series 1515
Individual Occupational Requirements
Basic Requirements:

Degree: in operations research; or at least 24 semester hours in a combination of operations research, mathematics, probability, statistics, mathematical logic, science, or subject-matter courses requiring substantial competence in college-level mathematics or statistics. At least 3 of the 24 semester hours must have been in calculus.

Additional information

Air Force Civilian Service Employment Benefits:

Paid Time Off:
• 11 Federal Holidays off per year
• Vacation time (Annual Leave) accumulates based on length of employment. Starts at 13 days (104 hours) per year and up to 26 days (208 hours) per year
• 13 sick days per year (104 hours)

Retirement:
• Pension: Federal Employees Retirement System (FERS)
• 401K: Thrift Savings Plan (TSP) available with up to 5% agency matching

Health & Wellness:
• Various Medical, Dental & Vision packages to choose from for entire family
• Flexible Spending Account
• Federal Long Term Care Insurance, and Life & Disability Insurance

Work/Life Balance:
• Family and Medical Leave Act
• Employee Assistance Program (EAP)
• Flexible Work Arrangements (dependent on position)

Career Development:
• Tuition Assistance & Professional Development opportunities
• Career enhancement and promotion opportunities

To learn more about our benefits, please check out the AFTC Benefits Trifold at .

Federal Resume Tips:

Office of Personnel Management (OPM) Classification & Qualifications for Federal Government Employees:

To receive additional information about current and future job openings with Air Force Civilian Service, please registerat and click ""Subscribe"" in the top right corner.

Please visit the Air Force Test Center job board to view other career opportunities:

Equal Opportunity Employer. U.S. citizenship required. Must be of legal working age.

Air Force Test Center is proud to be an Equal Employment Opportunity employer, and is dedicated to advancing diversity, equity, inclusion, and accessibility. We recognize diversity encompasses many parts of one's identity including but not limited to race, color, gender (including pregnancy, childbirth, or related medical conditions), gender identity and expression, age, sexual orientation, national origin, religion, genetic information, disability status, and veteran status. AFTC encourages ALL candidates to apply as our employees' points of view are key to our success.

Disabled veteran leave is available to a Federal employee hired on/after 5 Nov 2016, who is a veteran with a service-connected disability rating of 30% or more. For more information, click here.
• Benefits

A career with the U.S. government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Opens in a new windowLearn more about federal benefits.

Review our benefits

Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time or intermittent. Contact the hiring agency for more information on the specific benefits offered.

How You Will Be Evaluated

You will be evaluated for this job based on how well you meet the qualifications above.

For additional information on direct hire opportunities with the Air Force please click here .
• Benefits

A career with the U.S. government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Opens in a new windowLearn more about federal benefits.

Review our benefits

Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time or intermittent. Contact the hiring agency for more information on the specific benefits offered.
• Required Documents

As a new or existing federal employee, you and your family may have access to a range of benefits. Your benefits depend on the type of position you have - whether you're a permanent, part-time, temporary or an intermittent employee. You may be eligible for the following benefits, however, check with your agency to make sure you're eligible under their policies.

For additional information on direct hire opportunities with the Air Force please click here .

If you are relying on your education to meet qualification requirements:

Education must be accredited by an accrediting institution recognized by the U.S. Department of Education in order for it to be credited towards qualifications. Therefore, provide only the attendance and/or degrees from schools accredited by accrediting institutions recognized by the U.S. Department of Education.

Failure to provide all of the required information as stated in this vacancy announcement may result in an ineligible rating or may affect the overall rating.
• How to Apply

Ensure you click the READ MORE below to open the frame and then CLICK APPLY NOW to complete an application and upload resume (PDF or Word Doc) and/or additional documents (Transcripts, certifications, Vet Docs (DD214), SF-50).

To receive additional information about current and future job openings with AFCS via email notification, please register at and sign up to ""Get Career Updates.""

For additional information on direct hire opportunities with the Air Force please click here .

Equal Opportunity Employer. U.S. citizenship required. Must be of legal working age.

Agency contact information

Air Force Test Center Recruitment

Email

AFTC.Enterprise.Recruiting@us.af.mil

Address

Eglin AFB
310 W Van Matre Ave
Ste 102
Eglin AFB, FL 32542
US
Next steps

For additional information on direct hire opportunities with the Air Force please click here .
• Fair and Transparent

The Federal hiring process is set up to be fair and transparent. Please read the following guidance.
• Criminal history inquiries
• Equal Employment Opportunity (EEO) Policy
• Financial suitability
• New employee probationary period
• Privacy Act
• Reasonable accommodation policy
• Selective Service
• Signature and false statements
• Social security number request

Required Documents

For additional information on direct hire opportunities with the Air Force please click here .

If you are relying on your education to meet qualification requirements:

Education must be accredited by an accrediting institution recognized by the U.S. Department of Education in order for it to be credited towards qualifications. Therefore, provide only the attendance and/or degrees from schools accredited by accrediting institutions recognized by the U.S. Department of Education.

Failure to provide all of the required information as stated in this vacancy announcement may result in an ineligible rating or may affect the overall rating.

Help This job is open to
• The public

U.S. Citizens, Nationals or those who owe allegiance to the U.S.",2025-07-08T00:00:00.000Z,2025-07-25,"['U.S. Citizenship Required', 'Security clearance requirements are based upon actual position being filled', 'Possess a bachelor’s degree in a related technical discipline such as mathematics, computer science, one of the physical sciences or engineering', 'Applicant must be capable of achieving the APDP certification', 'SPECIALIZED EXPERIENCE: Applicants must have at least one (1) year of specialized experience at the next lower broadband NH-03 or equivalent to the next lower grade GS-12 thru GS-13 in the Federal Service', 'Knowledge of a wide range of advanced multidisciplinary professional engineering/data science/computer science/research analysis concepts, principles, practices, standards, methods, and techniques to apply experimental theories and new developments to problems not susceptible to treatment by accepted methods, and to plan and execute specialized programs of marked difficulty, responsibility, and significance', 'Knowledge of the mission, roles, functions, organizational structure, and operation of the DoD, Air Force, and', 'sustainment; and knowledge of planning, programming, and budgeting cycles, financial systems, and restrictions on expenditure of funds', 'Knowledge of and skill in evaluating state-of-the-art and advancements in theory, application, technology, and policy affecting systems being developed, and in planning, organizing, and directing the functions and staff in critical aspects of development, production, and/or support of systems, subsystems, or equipment', 'Knowledge of safety, security, personnel management, and Equal Employment Opportunity (EEO) regulations, practices, and procedures', 'Degree: Engineering', ""(1) lead to a bachelor's degree in a school of engineering with at least one program accredited by ABET; or"", '(2) include differential and integral calculus and courses (more advanced than first-year physics and chemistry) in five of the following seven areas of engineering science or physics: (a) statics, dynamics; (b) strength of materials (stress-strain relationships); (c) fluid mechanics, hydraulics; (d) thermodynamics; (e) electrical fields and circuits; (f) nature and properties of materials (relating particle and aggregate structure to properties); and (g) any other comparable area of fundamental engineering science or physics, such as optics, heat transfer, soil mechanics, or electronics', 'Combination of education and experience - college-level education, training, and/or technical experience that furnished (1) a thorough knowledge of the physical and mathematical sciences underlying engineering, and (2) a good understanding, both theoretical and practical, of the engineering sciences and techniques and their applications to one of the branches of engineering', 'The adequacy of such background must be demonstrated by one of the following: 1', 'Professional registration or licensure - Current registration as an Engineer Intern (EI), Engineer in Training (EIT)1 , or licensure as a Professional Engineer (PE) by any State, the District of Columbia, Guam, or Puerto Rico', 'Absent other means of qualifying under this standard, those applicants who achieved such registration by means other than written test (e.g., State grandfather or eminence provisions) are eligible only for positions that are within or closely related to the specialty field of their registration', ""For example, an applicant who attains registration through a State Board's eminence provision as a manufacturing engineer typically would be rated eligible only for manufacturing engineering positions"", 'Written Test - Evidence of having successfully passed the Fundamentals of Engineering (FE)2 examination or any other written test required for professional registration by an engineering licensure board in the various States, the District of Columbia, Guam, and Puerto Rico', 'Specified academic courses - Successful completion of at least 60 semester hours of courses in the physical, mathematical, and engineering sciences and that included the courses specified in the basic requirements under paragraph A', 'The courses must be fully acceptable toward meeting the requirements of an engineering program as described in paragraph A', ""Related curriculum - Successful completion of a curriculum leading to a bachelor's degree in an appropriate scientific field, e.g., engineering technology, physics, chemistry, architecture, computer science, mathematics, hydrology, or geology, may be accepted in lieu of a bachelor's degree in engineering, provided the applicant has had at least 1 year of professional engineering experience acquired under professional engineering supervision and guidance"", 'Ordinarily there should be either an established plan of intensive training to develop professional engineering competence, or several years of prior professional engineering-type experience, e.g., in interdisciplinary positions. (The above examples of related curricula are not all-inclusive.)', 'Note: An applicant who meets the basic requirements as specified in A or B above, except as noted under B.1., may qualify for positions in any branch of engineering unless selective factors indicate otherwise', 'Qualifications Standard for Data Science Series, 1560', 'Degree: Mathematics, statistics, computer science, data science or field directly related to the position', 'The degree must be in a major field of study (at least at the baccalaureate level) that is appropriate for the position', 'Combination of education and experience: Courses equivalent to a major field of study (30 semester hours) as shown in paragraph A above, plus additional education or appropriate experience', 'Degree: in operations research; or at least 24 semester hours in a combination of operations research, mathematics, probability, statistics, mathematical logic, science, or subject-matter courses requiring substantial competence in college-level mathematics or statistics', 'At least 3 of the 24 semester hours must have been in calculus', 'U.S. citizenship required', 'Must be of legal working age', 'Education must be accredited by an accrediting institution recognized by the U.S', 'Department of Education in order for it to be credited towards qualifications', 'U.S. citizenship required', 'Must be of legal working age', 'Education must be accredited by an accrediting institution recognized by the U.S', 'Department of Education in order for it to be credited towards qualifications']","['Supervise government civilians within the Advanced Capabilities Flight', 'Oversee supervisory administrative aspects such as time off, travel, talent management and retention', 'Act as hiring manager for new employees and oversee on-boarding', 'Organize, train, and equip team of test engineers, scientists, aircrew, logisticians, and support personnel to accomplish flight test mission sets', 'Provide technical subject matter expertise where applicable to solve issues that arise during flight test', 'Communicate program status to squadron and group leadership', 'Provide early indications of concerns before they manifest as issues', 'Provide technical continuity for military and civilian workforce', 'Random drug testing may be required depending upon the position being filled', 'Supervisory requirements may be required depending upon the position being filled', 'Work may occasionally require travel away from the normal duty station on military or commercial aircraft', 'The work requires the employee to obtain and maintain the appropriate security clearance', 'organizations that govern, interface with, and/or influence systems acquisition, development, and/or', 'Skill in establishing and maintaining effective relationships, building consensus and coalitions, negotiating, and resolving conflicts with a variety of individuals and organizations as well as communicating effectively, both orally and in writing', 'Ability to plan, organize, and direct the functions of an organization, and mentor, motivate, and appraise the staff through subordinate supervisors as well as analyze, plan, and adjust work operations of one or more organizational segments to meet program requirements and objectives within available resources']",False,[],,"['Data Science', 'Mathematics and Statistics', 'Operations Research', 'Engineering Sciences', 'Research Analysis']","Data Science: The role requires knowledge of data science concepts, principles, and methods to apply experimental theories and solve complex problems in the context of Air Force operations.; Mathematics and Statistics: A foundational requirement involving calculus, probability, statistics, and mathematical logic to support data analysis and research activities.; Operations Research: The job involves applying operations research techniques, including mathematical modeling and analysis, to optimize systems and decision-making processes.; Engineering Sciences: The position requires understanding engineering principles such as statics, dynamics, fluid mechanics, thermodynamics, and electrical circuits to support technical problem solving.; Research Analysis: The role includes conducting research analysis to evaluate advancements in theory, technology, and policy affecting Air Force systems."
FlHGei9nG1MoCK2bAAAAAA==,"Data Scientist, Radio & Music Informatics Science Oakland, CA, United States Job","Data Scientist, Radio & Music Informatics ScienceSiriusXM and Pandora have joined together to create the leading audio entertainment company in the U.S. Together, we are uniquely positioned to lead a new era of audio entertainment by delivering the most compelling subscription and ad-supported audio experiences to millions of listeners -- in the car, at home and on the go. Our talent, content, technology and innovation continue to be at the forefront, and we want you to be a part of it!Position Summary:In this role you'll be working on a team designing, building, and testing the next innovations that will delight millions of listeners. You will have access to billions of hours of music listening history across hundreds of millions of listeners who have provided a hundred billion thumbs on their stations and playlists. And truly unique to SiriusXM + Pandora, you'll be working with extremely rich and diverse interlinked music metadata, including annotations of our expert musicologists with the Music Genome Project's 450+ musical characteristics. With these resources at your fingertips, we want your help to make sure we always pick that perfect next song for our listeners.Duties and Responsibilities:Design, build, and A/B-test improvements and innovations to SiriusXM + Pandora’s algorithmic radio, playlist, and recommendations products.Improve upon SiriusXM + Pandora’s content understanding capabilities through audio and metadata analysis.Partner closely with product, analytics, and engineering.Supervisory Responsibilities:NoneMinimum Qualifications:Masters Degree in a quantitative field (CS, EE, Statistics, Physics, Math, etc.)Preferred Qualifications:PhD Degree in a quantitative field (CS, EE, Statistics, Physics, Math, etc.) or 2+ years industry experience working as a Data Scientist.Requirements and General Skills:Experience designing and building machine learning systems or recommender systems or music information retrieval systems.Solid understanding of A/B testing concepts.Demonstrated ability to work well in a small team.Excellent communication skills with both technical and non-technical audiences.Technical Skills:Proficiency with Python, Scala, or Java.Experience with SQL (or equivalent).Experience with distributed computing systems (e.g., Spark, etc.).Familiarity with common machine learning libraries (e.g., scikit-learn, Tensorflow, etc.).Our goal at SiriusXM + Pandora is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM + Pandora is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.
#J-18808-Ljbffr",2025-07-23T00:00:00.000Z,2025-07-25,"['Partner closely with product, analytics, and engineering', 'Requirements and General Skills:Experience designing and building machine learning systems or recommender systems or music information retrieval systems', 'Solid understanding of A/B testing concepts', 'Demonstrated ability to work well in a small team', 'Excellent communication skills with both technical and non-technical audiences', 'Technical Skills:Proficiency with Python, Scala, or Java', 'Experience with SQL (or equivalent)', 'Experience with distributed computing systems (e.g., Spark, etc.).Familiarity with common machine learning libraries (e.g., scikit-learn, Tensorflow, etc.).Our goal at SiriusXM + Pandora is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation']","['You will have access to billions of hours of music listening history across hundreds of millions of listeners who have provided a hundred billion thumbs on their stations and playlists', 'Duties and Responsibilities:Design, build, and A/B-test improvements and innovations to SiriusXM + Pandora’s algorithmic radio, playlist, and recommendations products', 'Improve upon SiriusXM + Pandora’s content understanding capabilities through audio and metadata analysis']",True,[],,"['A/B Testing', 'Recommender Systems', 'Machine Learning', 'Music Information Retrieval', 'Python', 'Scala', 'Java', 'SQL', 'Distributed Computing (Spark)', 'Scikit-learn', 'TensorFlow']","A/B Testing: Used to design and evaluate improvements to algorithmic radio, playlist, and recommendation products by comparing different versions.; Recommender Systems: Designing and building systems to suggest music content tailored to listeners based on their listening history and preferences.; Machine Learning: Developing predictive models and algorithms to enhance music recommendations and content understanding.; Music Information Retrieval: Analyzing audio and metadata to extract meaningful features for improving content understanding and recommendations.; Python: Programming language used for building machine learning models and data analysis pipelines.; Scala: Programming language used for distributed computing and data processing tasks.; Java: Programming language used in building scalable data systems and applications.; SQL: Used for querying and managing large-scale music listening and metadata databases.; Distributed Computing (Spark): Utilized to process and analyze large volumes of music listening data efficiently.; Scikit-learn: Machine learning library employed for building and testing predictive models.; TensorFlow: Machine learning framework used for developing and deploying models, including deep learning if applicable."
tWRA07qJ9cETDxqgAAAAAA==,Entry Level Data Scientist/ML Engineer - Remote,"The Job Market is Challenging due to almost 300,000 Tech Layoffs since October 2022 due to which thousands of laid off Techies are competing with existing Jobseekers. Entry level Job seekers struggle to get responses to their applications forget about getting client interviews. As the Saying goes ""when the Going gets tough the Tough get going” Candidates who want to make a tech career they need to differentiate themselves by ensuring they have exceptional skills and technologies to be noticed by clients.

Since 2010 Synergisticit has helped Jobseekers differentiate themselves by providing candidates the requisite skills and experience to outperform at interviews and clients. Here at SynergisticIT We just don't focus on getting you a Job we make careers.

All Positions are open for all visas and US citizens

We are matchmakers we provide clients with candidates who can perform from day 1 of starting work. In this challenging economy every client wants to save $$$'s and they want the best value for their money. Jobseekers need to self-evaluate if they have the requisite skills to meet client requirements and needs. Clients now post covid can also hire remote workers which increases even more competition for jobseekers.

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in IT Industry

We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

We also offer optionally Skill and technology enhancement programs for candidates who are either missing skills or are lacking Industry/Client experience with Projects and skills. Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. If they are qualified with enough skills and have hands on project work at clients then they should be good to be submitted to clients. Shortlisting and selection is totally based on clients discretion not ours.

please check the below links to see success outcomes of our candidates

https://www.synergisticit.com/candidate-outcomes/

We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please see us exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023

Oracle CloudWorld Event (OCW) Las Vegas 2023/ 2022 | SynergisticIT - YouTube

https://youtu.be/Rfn8Y0gnfL8?si=p2V4KFv5HukJXTrn https://youtu.be/-HkNN1ag6Zk?si=1NRfgsvL_HJMVb6Q https://www.youtube.com/watch?v=OAFOhcGy9Z8 https://www.youtube.com/watch?v=EmO7NrWHkLM https://www.youtube.com/watch?v=NVBU9RYZ6UI https://www.youtube.com/watch?v=Yy74yvjatVg

For preparing for interviews please visit https://www.synergisticit.com/interview-questions/

We are looking for the right matching candidates for our clients

Please apply via the job posting

REQUIRED SKILLS For Java /Full stack/Software Programmer
• Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
• Highly motivated, self-learner, and technically inquisitive
• Experience in programming language Java and understanding of the software development life cycle
• Project work on the skills
• Knowledge of Core Java , javascript , C++ or software programming
• Spring boot, Microservices, Docker, Jenkins and REST API's experience
• Excellent written and verbal communication skills

For data Science/Machine learning Positions
REQUIRED SKILLS
• Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
• Project work on the technologies needed
• Highly motivated, self-learner, and technically inquisitive
• Experience in programming language Java and understanding of the software development life cycle
• Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools
• Excellent written and verbal communication skills
Preferred skills: NLP, Text mining, Tableau, PowerBI, Tensorflow

If you get emails from our skill enhancement team please ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",,2025-07-25,"['Jobseekers need to self-evaluate if they have the requisite skills to meet client requirements and needs', 'Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in IT Industry', 'Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio', 'If they are qualified with enough skills and have hands on project work at clients then they should be good to be submitted to clients', 'REQUIRED SKILLS For Java /Full stack/Software Programmer', 'Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT', 'Highly motivated, self-learner, and technically inquisitive', 'Experience in programming language Java and understanding of the software development life cycle', 'Project work on the skills', 'Knowledge of Core Java , javascript , C++ or software programming', ""Spring boot, Microservices, Docker, Jenkins and REST API's experience"", 'Excellent written and verbal communication skills', 'For data Science/Machine learning Positions', 'Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT', 'Project work on the technologies needed', 'Highly motivated, self-learner, and technically inquisitive', 'Experience in programming language Java and understanding of the software development life cycle', 'Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools', 'Excellent written and verbal communication skills']",['https://youtu.be/Rfn8Y0gnfL8?si=p2V4KFv5HukJXTrn https://youtu.be/-HkNN1ag6Zk?si=1NRfgsvL_HJMVb6Q https://www.youtube.com/watch?v=OAFOhcGy9Z8 https://www.youtube.com/watch?v=EmO7NrWHkLM https://www.youtube.com/watch?v=NVBU9RYZ6UI https://www.youtube.com/watch?v=Yy74yvjatVg'],True,[],,"['Statistics', 'SAS', 'Python', 'Computer Vision', 'Data Visualization Tools', 'Tableau', 'PowerBI', 'TensorFlow', 'NLP', 'Text Mining', 'Java']","Statistics: Used as foundational knowledge for data science and machine learning tasks in the role.; SAS: A statistical software tool mentioned as a required skill for data analysis and statistical modeling.; Python: Programming language used for data science, machine learning, and data visualization tasks.; Computer Vision: A data science domain mentioned as a skill area relevant to the job, involving image data analysis.; Data Visualization Tools: Tools like Tableau and PowerBI are referenced for creating dashboards and visual analytics.; Tableau: A BI and data visualization tool preferred for creating interactive dashboards and reports.; PowerBI: A business intelligence tool preferred for data visualization and reporting.; TensorFlow: A deep learning framework mentioned as a preferred skill, used for building machine learning models.; NLP: Natural Language Processing is noted as a preferred skill, relevant for text mining and language data analysis.; Text Mining: A data analysis technique for extracting information from text data, listed as a preferred skill.; Java: Programming language required for software development and machine learning engineering tasks."
_5rM8LBIEtUYvKx8AAAAAA==,"Senior Data Scientist, Specialist Senior - SFL Scientific - Full-time","Senior Data Scientist, Specialist Senior - SFL Scientific

Our Deloitte Strategy & Transactions team helps guide clients through their most critical moments and transformational initiatives. From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability. Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journey-before, during, and after any major transformational projects or transactions.

SFL Scientific, a Deloitte Business, is a U.S. based, data science consulting firm specializing in building industry-specific, artificial intelligence (AI) technologies.

We are hiring a Senior Data Scientist to collaborate directly with clients to design and develop novel projects and solutions. Join a rapidly growing team of professionals working to build a world-class data science practice focused on solving complex and R&D problems.

Recruiting for this role ends on 7/31/2025.

Work You'll Do

As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services. You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions.

Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation. Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills.

+ Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production

+ Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives

+ Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization

+ Validate AI models and algorithm via code reviews, unit, and integration tests

+ Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives

+ Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives

The Team

Our Strategy offering architects bold strategies to achieve business and mission goals, enabling growth, competitive advantage, technology modernization, and continuous digital and AI transformation.

SFL Scientific, a Deloitte Business, is a data science professional services practice focused on strategy, technology, and solving business challenges with Artificial Intelligence (AI). The team has a proven track record serving large, market-leading organizations in the private and public sectors, successfully delivering high-quality, novel and complex projects, and offering deep domain and scientific capabilities. Made up of experienced AI strategists, data scientists, and AI engineers, they serve as trusted advisors to executives, helping them understand and evaluate new and essential areas for AI investment and identify unique opportunities to transform their businesses.

Qualifications:

+ Master's or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)

+ 3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)

+ 3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments

+ 3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow

+ 3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads

+ Live within commuting distance to one of Deloitte's consulting offices

+ Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve

+ Limited immigration sponsorship may be available

Preferred:

+ 2+ years of experience working in a client-facing, consulting environment

+ 2+ years of experience leading project/client engagement teams in the execution of complex AI data science solutions

+ 1+ year of experience with LLM/GenAI use cases and developing RAG solutions, tools, and services (i.e., LangChain, LangGraph, MCP, etc.)

+ 1+ year of experience with AWS Sagemaker or AWS ML Studio

Information for applicants with a need for accommodation: https://www2.deloitte.com/us/en/pages/careers/articles/join-deloitte-assistance-for-disabled-applicants.html

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $107,600 to $198,400.

You may also be eligible to participate in a discretionary annual incentive program, subject to the rules governing the program, whereby an award, if any, depends on various factors, including, without limitation, individual and organizational performance.

#MonitorDeloitte

#DeloitteJobs

#StrategyConsulting

#DeloitteStrategy

#Strategy26

#SFL26

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.

Senior Data Scientist, Specialist Senior - SFL Scientific

Our Deloitte Strategy & Transactions team helps guide clients through their most critical moments and transformational initiatives. From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability. Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journey-before, during, and after any major transformational projects or transactions.

SFL Scientific, a Deloitte Business, is a U.S. based, data science consulting firm specializing in building industry-specific, artificial intelligence (AI) technologies.

We are hiring a Senior Data Scientist to collaborate directly with clients to design and develop novel projects and solutions. Join a rapidly growing team of professionals working to build a world-class data science practice focused on solving complex and R&D problems.

Recruiting for this role ends on 7/31/2025.

Work You'll Do

As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services. You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions.

Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation. Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills.

+ Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production

+ Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives

+ Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization

+ Validate AI models and algorithm via code reviews, unit, and integration tests

+ Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives

+ Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives

The Team

Our Strategy offering architects bold strategies to achieve business and mission goals, enabling growth, competitive advantage, technology modernization, and continuous digital and AI transformation.

SFL Scientific, a Deloitte Business, is a data science professional services practice focused on strategy, technology, and solving business challenges with Artificial Intelligence (AI). The team has a proven track record serving large, market-leading organizations in the private and public sectors, successfully delivering high-quality, novel and complex projects, and offering deep domain and scientific capabilities. Made up of experienced AI strategists, data scientists, and AI engineers, they serve as trusted advisors to executives, helping them understand and evaluate new and essential areas for AI investment and identify unique opportunities to transform their businesses.

Qualifications:

+ Master's or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)

+ 3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)

+ 3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments

+ 3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow

+ 3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads

+ Live within commuting distance to one of Deloitte's consulting offices

+ Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve

+ Limited immigration sponsorship may be available

Preferred:

+ 2+ years of experience working in a client-facing, consulting environment

+ 2+ years of experience leading project/client engagement teams in the execution of complex AI data science solutions

+ 1+ year of experience with LLM/GenAI use cases and developing RAG solutions, tools, and services (i.e., LangChain, LangGraph, MCP, etc.)

+ 1+ year of experience with AWS Sagemaker or AWS ML Studio

Information for applicants with a need for accommodation: https://www2.deloitte.com/us/en/pages/careers/articles/join-deloitte-assistance-for-disabled-applicants.html

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $107,600 to $198,400.

You may also be eligible to participate in a discretionary annual incentive program, subject to the rules governing the program, whereby an award, if any, depends on various factors, including, without limitation, individual and organizational performance.

#MonitorDeloitte

#DeloitteJobs

#StrategyConsulting

#DeloitteStrategy

#Strategy26

#SFL26

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.",2025-07-24T00:00:00.000Z,2025-07-25,"[""Master's or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)"", '3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)', '3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments', '3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow', '3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads', ""Live within commuting distance to one of Deloitte's consulting offices"", 'Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve', 'Limited immigration sponsorship may be available', ""Master's or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)"", '3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)', '3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments', '3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow', '3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads', ""Live within commuting distance to one of Deloitte's consulting offices"", 'Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve', 'Limited immigration sponsorship may be available']","['From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability', 'Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journey-before, during, and after any major transformational projects or transactions', 'As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services', 'You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions', 'Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation', 'Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills', 'Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production', 'Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives', 'Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization', 'Validate AI models and algorithm via code reviews, unit, and integration tests', 'Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives', 'Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives', 'From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability', 'Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journey-before, during, and after any major transformational projects or transactions', 'As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services', 'You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions', 'Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation', 'Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills', 'Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production', 'Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives', 'Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization', 'Validate AI models and algorithm via code reviews, unit, and integration tests', 'Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives', 'Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives']",True,"['Generative AI', 'Large Language Models', 'Retrieval-Augmented Generation', 'Prompt Engineering', 'Transformers', 'Convolutional Neural Networks', 'Recurrent Neural Networks', 'Generative Adversarial Networks', 'PyTorch (Deep Learning)', 'Kubernetes (AI/ML Deployment)', 'Docker (AI/ML Deployment)', 'TensorRT (AI Optimization)', 'Kubeflow (AI Workflow Orchestration)', 'MLflow (AI Lifecycle Management)', 'AWS SageMaker', 'AWS ML Studio', 'Multi-Modal AI', 'Agentic AI Solutions', 'MCP (Model Control Plane)']","Generative AI: Involved in developing and deploying AI services including LLM/GenAI use cases.; Large Language Models: Experience with LLMs for building AI solutions and client advisory.; Retrieval-Augmented Generation: Developing RAG solutions and tools such as LangChain and LangGraph for AI applications.; Prompt Engineering: Used to optimize interactions with LLMs and generative AI models.; Transformers: Applied in deep learning models for NLP and other AI tasks.; Convolutional Neural Networks: Deep learning architecture used for computer vision tasks.; Recurrent Neural Networks: Deep learning architecture applied to sequential data like time series and NLP.; Generative Adversarial Networks: Used for generative modeling and advanced AI research projects.; PyTorch (Deep Learning): Framework specifically used for developing neural network-based AI models.; Kubernetes (AI/ML Deployment): Used to deploy and manage AI/ML models in production environments.; Docker (AI/ML Deployment): Containerization tool for deploying AI/ML models and services.; TensorRT (AI Optimization): Tool for optimizing AI model inference performance on hardware.; Kubeflow (AI Workflow Orchestration): Platform for orchestrating AI/ML workflows and pipelines.; MLflow (AI Lifecycle Management): Tool for managing AI model experimentation, tracking, and deployment.; AWS SageMaker: Cloud service used for building, training, and deploying AI/ML models.; AWS ML Studio: Cloud-based environment for developing and deploying AI/ML solutions.; Multi-Modal AI: Involves AI applications across NLP, computer vision, and other modalities.; Agentic AI Solutions: Developing autonomous AI agents and edge AI systems.; MCP (Model Control Plane): Used for managing AI model deployment and lifecycle in production.","['Exploratory Data Analysis', 'Machine Learning', 'Deep Learning', 'Natural Language Processing', 'Time-Series Analysis', 'Computer Vision', 'Python', 'PyTorch', 'Kubernetes', 'Docker', 'TensorRT', 'RAPIDs', 'Kubeflow', 'MLflow', 'Cloud Platforms', 'Valuation Modeling', 'Cost Optimization', 'Restructuring Analytics', 'Business Design and Transformation Analytics', 'Mergers and Acquisitions Analytics', 'Sustainability Analytics']","Exploratory Data Analysis: Used to understand client data sets and operational requirements to inform solution design.; Machine Learning: Applied to develop AI/ML solutions, including model building, tuning, and validation in production environments.; Deep Learning: Utilized techniques such as CNNs, RNNs, and GANs for real-world projects including model tuning and performance validation.; Natural Language Processing: Employed for data analysis tasks involving text data as part of AI/ML algorithm development.; Time-Series Analysis: Used for analyzing sequential data as part of AI/ML algorithm development.; Computer Vision: Applied in projects involving image data analysis and model development.; Python: Primary programming language used for AI/ML algorithm development and data analysis.; PyTorch: Framework used for developing AI/ML algorithms and deep learning models.; Kubernetes: Used to deploy and optimize machine learning models in production environments.; Docker: Containerization tool used for deploying and managing ML models.; TensorRT: Tool for optimizing machine learning model inference performance.; RAPIDs: Used for accelerating machine learning workflows on GPUs.; Kubeflow: Platform for deploying, orchestrating, and managing ML workflows.; MLflow: Tool for managing the ML lifecycle including experimentation, reproducibility, and deployment.; Cloud Platforms: AWS, Azure, and GCP used to deploy AI/ML workloads and support scalable solutions.; Valuation Modeling: Part of advisory services involving quantitative financial modeling.; Cost Optimization: Analytical approach to improve financial efficiency in client projects.; Restructuring Analytics: Data-driven analysis to support business transformation and restructuring efforts.; Business Design and Transformation Analytics: Use of data science to guide business design and transformation initiatives.; Mergers and Acquisitions Analytics: Data analysis supporting M&A activities and decision-making.; Sustainability Analytics: Data-driven approaches to support sustainability initiatives."
i0Qyb4YESwPo3TNeAAAAAA==,"Research Scientist, Gemini Data","Snapshot

The Gemini Data team

We are seeking a highly motivated and talented Research Scientist to join our team to work on Gemini data. Our goal is to organize the world's information and generate and curate high-quality tokens for Gemini core model training.
About Us

Artificial Intelligence could be one of humanity's most useful inventions. At Google DeepMind, we're a team of scientists, engineers, machine learning experts and more, working together to advance the state of the art in artificial intelligence. We use our technologies for widespread public benefit and scientific discovery, and collaborate with others on critical challenges, ensuring safety and ethics are the highest priority.
The Role

We are seeking a highly motivated and talented Research Scientist to join our team to work on Gemini data.

Key responsibilities
• Research and develop methods to create diversified high-quality synthetic data, scale the creation through collaborations, evaluate & improve its effectiveness through ablation in pretraining/post-training/distillation.
• Research and develop methods to identify quality issues horizontally in the pretraining data corpus, innovate on how to fix, and evaluate & improve its effectiveness through ablation into landing.
• Stay up-to-date with the latest advancements in LLM research.
About You

In order to set you up for success as a Research Scientist at Google DeepMind, we look for the following skills and experience:

In order to set you up for success as a Research Scientist at Google DeepMind, we look for the following skills and experience:
• PhD in Computer Science or related field.
• In-depth experience and familiarity of LLM training and/or agents.
• Strong publication record in top machine learning conferences (e.g., NeurIPS, CVPR, ICML, ICLR, ICCV, ECCV).
• Solid skills & experience in software engineering for ML

In addition, the following would be an advantage:
• Excellent communication and teamwork skills
• Passion for research and a desire to make a significant impact in the pretraining data area.
• Expertise in one or more of the following areas of LLMs: Synthetic Data, Data Quality, Scaling Data

The US base salary range for this full-time position is between $166,000 - $220,000 + bonus + equity + benefits. Your recruiter can share more about the specific salary range for your targeted location during the hiring process.

At Google DeepMind, we value diversity of experience, knowledge, backgrounds and perspectives and harness these qualities to create extraordinary impact. We are committed to equal employment opportunity regardless of sex, race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, gender identity, pregnancy, or related condition (including breastfeeding) or any other basis as protected by applicable law. If you have a disability or additional need that requires accommodation, please do not hesitate to let us know.",2025-07-08T00:00:00.000Z,2025-07-25,"['PhD in Computer Science or related field', 'In-depth experience and familiarity of LLM training and/or agents', 'Strong publication record in top machine learning conferences (e.g., NeurIPS, CVPR, ICML, ICLR, ICCV, ECCV)', 'Solid skills & experience in software engineering for ML', 'Excellent communication and teamwork skills', 'Passion for research and a desire to make a significant impact in the pretraining data area', 'Expertise in one or more of the following areas of LLMs: Synthetic Data, Data Quality, Scaling Data']","['We are seeking a highly motivated and talented Research Scientist to join our team to work on Gemini data', 'Research and develop methods to create diversified high-quality synthetic data, scale the creation through collaborations, evaluate & improve its effectiveness through ablation in pretraining/post-training/distillation', 'Research and develop methods to identify quality issues horizontally in the pretraining data corpus, innovate on how to fix, and evaluate & improve its effectiveness through ablation into landing', 'Stay up-to-date with the latest advancements in LLM research']",True,"['Large Language Models', 'Pretraining', 'Post-training', 'Distillation', 'LLM Agents']","Large Language Models: Central to the role, involving training and research on LLMs and their agents to advance AI capabilities.; Pretraining: Refers to the initial training phase of LLMs using large datasets, a key focus area for improving model performance.; Post-training: Techniques applied after initial training to refine and improve LLM performance.; Distillation: A method to compress and transfer knowledge from large LLMs to smaller models, enhancing efficiency.; LLM Agents: Refers to autonomous or semi-autonomous systems built on LLMs, relevant to the candidate's experience and research.","['Synthetic Data', 'Data Quality', 'Data Scaling', 'Ablation Studies']","Synthetic Data: Used to create diversified high-quality data for training models, improving data availability and quality in the pretraining process.; Data Quality: Focus on identifying and fixing quality issues in the pretraining data corpus to enhance model training effectiveness.; Data Scaling: Scaling the creation of synthetic data through collaborations to support large-scale model pretraining.; Ablation Studies: Evaluating and improving data and model effectiveness by systematically removing components during pretraining, post-training, and distillation."
nb_X9MFGMA5UnNR0AAAAAA==,Lead Data Scientist,"Company Overview

At Motorola Solutions, we believe that everything starts with our people. We're a global close-knit community, united by the relentless pursuit to help keep people safer everywhere. Our critical communications, video security and command center technologies support public safety agencies and enterprises alike, enabling the coordination that's critical for safer communities, safer schools, safer hospitals and safer businesses. Connect with a career that matters, and help us build a safer future.

Department OverviewThe Design & Tools (D&T) team is a strategic component of Centralized Managed Support Operations (CMSO), responsible for providing exceptional Service Design & innovative technology solutions to enable and empower MSI Centralized Managed Support Operations to meet and exceed customer's expectations. In this role, you will fit in the AI & Architecture team within D&T.
Job Description

We are looking for a Senior Data Scientist who will lead and drive the Artificial Intelligence & Analytics stream at D&T (Design and Tools). In this role, you will also serve as a subject matter expert in the AI and ML domain, and build analytical and statistical machine learning models that will drive business decisions. You will understand user requirements and translate them into AI solutions that turbocharge internal and external user experiences. Many of these AI solutions will be enabled within the core technologies used within CMSO, including Salesforce and ServiceNow. In other instances, you will also be responsible for building custom predictive and prescriptive ML models for preventative system health checks, system log analytics, automated root cause analysis etc.

Responsibilities include:
• Manage and direct processes of AI related projects
• Drive requirements for AI related projects, work with internal customers and with ServiceNow and Salesforce Product Managers for features planning, prioritization and implementation
• Understand and apply various statistical methods for data analysis, EDA, hypothesis testing, and drawing meaningful conclusions.
• Understand ML concepts and has applied one or more of Deep Learning methods, NLP, computer vision, sentiment analysis, topic modeling and graph theory in real world applications to solve business problems
• Guiding models to master the theory and application of supervised, unsupervised, and reinforcement learning algorithms for tasks like classification, regression, and clustering.
• Training ML models to effectively communicate complex data insights through clear and informative visualizations
• Instilling in models an understanding of the ethical implications of data science, including bias detection, fairness, and responsible data handling.
• Develop application-specific interfaces that leverage GenAI capabilities, LLMs and FMs to enhance the associate and customer experience.
• Design APIs for performance, real-time applications, scale, ease of use and governance automation.
• Serves as industry thought leader in data science and applies deep expertise to drive novel customer experiences
• Adaptive and the desire to learn new technologies.

Technical Experience
• Extensive knowledge in using Python libraries to perform univariate and bivariate analysis, building advanced machine learning models and data integrations with source systems and systems of record
• Experience with common data science tools such as Python, R, PyTorch, TensorFlow, Keras, NLTK, or spaCy
• Very good knowledge and experience with Databases like Postgres, Redshift, MSSQL
• Knowledge and experience in Cloud Environments (Azure, AWS, GCP)
• Experience to read data from multiple sources and cleanse, enhance and analyze the data.
• Ability to integrate data, sourcing data from several Sources including databases, files, API and Server logs.

Preferred Qualifications
• Minimum of 4+ years experience in data analytics, data mining, machine learning, and has employed predictive, prescriptive, conversational or generative AI to solve business problems
• Minimum of 4+ years experience in hands-on design, coding, development and deployment using data science tools such as Python, Tensorflow etc. to build AI solutions
• Minimum 2+ years experience leading teams to deliver solutions and results
• Deep knowledge of ML streams, e.g., natural language processing, computer vision, statistical learning theory and their application in real world situations
• Knowledge of ServiceNow and Salesforce products and features
• Experience working with one of the leading public clouds (AWS, Google, Azure)
• Excellent written and oral communication skills. Be able to work under pressure
• Ability to Multitask, Prioritize and Manage time effectively.
• Strong interpersonal skills and ability to work effectively across teams, functional groups

Target Base Salary Range for this role is $89,300 - $178,600

Consistent with Motorola Solutions values and applicable law, we provide the following information to promote pay transparency and equity. Pay within this range varies and depends on job-related knowledge, skills, and experience. The actual offer will be based on the individual candidate.

#LI-DB1

Basic Requirements
• Bachelor's degree in Data Science, Computer Science, or an IT related field
• Minimum of 4+ years experience in a Data Science related role
• Legal authorization to work in the U.S. indefinitely is required. Employer work permit sponsorship is not available for this position.

Travel RequirementsUnder 10%
Relocation ProvidedNone
Position TypeExperienced
Referral Payment PlanYes

Our U.S.Benefitsinclude:
• Incentive Bonus Plans
• Medical, Dental, Visionbenefits
• 401K
• 10 Paid Holidays
• GenerousPaidTime Off Packages
• Employee Stock Purchase Plan
• PaidParental & Family Leave
• and more!

EEO Statement

Motorola Solutions is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion or belief, sex, sexual orientation, gender identity, national origin, disability, veteran status or any other legally-protected characteristic.

We are proud of our people-first and community-focused culture, empowering every Motorolan to be their most authentic self and to do their best work to deliver on the promise of a safer world. If you'd like to join our team but feel that you don't quite meet all of the preferred skills, we'd still love to hear why you think you'd be a great addition to our team.

We're committed to providing an inclusive and accessible recruiting experience for candidates with disabilities, or other physical or mental health conditions. To request an accommodation, please complete thisReasonable Accommodations Formso we can assist you.",2025-07-08T00:00:00.000Z,2025-07-25,"['Adaptive and the desire to learn new technologies', 'Extensive knowledge in using Python libraries to perform univariate and bivariate analysis, building advanced machine learning models and data integrations with source systems and systems of record', 'Experience with common data science tools such as Python, R, PyTorch, TensorFlow, Keras, NLTK, or spaCy', 'Very good knowledge and experience with Databases like Postgres, Redshift, MSSQL', 'Knowledge and experience in Cloud Environments (Azure, AWS, GCP)', 'Experience to read data from multiple sources and cleanse, enhance and analyze the data', 'Ability to integrate data, sourcing data from several Sources including databases, files, API and Server logs', 'Minimum 2+ years experience leading teams to deliver solutions and results', 'Deep knowledge of ML streams, e.g., natural language processing, computer vision, statistical learning theory and their application in real world situations', 'Knowledge of ServiceNow and Salesforce products and features', 'Experience working with one of the leading public clouds (AWS, Google, Azure)', 'Excellent written and oral communication skills', 'Be able to work under pressure', 'Ability to Multitask, Prioritize and Manage time effectively', 'Strong interpersonal skills and ability to work effectively across teams, functional groups', ""Bachelor's degree in Data Science, Computer Science, or an IT related field"", 'Minimum of 4+ years experience in a Data Science related role', 'Legal authorization to work in the U.S. indefinitely is required', ""We're committed to providing an inclusive and accessible recruiting experience for candidates with disabilities, or other physical or mental health conditions""]","['In this role, you will fit in the AI & Architecture team within D&T', 'In this role, you will also serve as a subject matter expert in the AI and ML domain, and build analytical and statistical machine learning models that will drive business decisions', 'You will understand user requirements and translate them into AI solutions that turbocharge internal and external user experiences', 'Many of these AI solutions will be enabled within the core technologies used within CMSO, including Salesforce and ServiceNow', 'In other instances, you will also be responsible for building custom predictive and prescriptive ML models for preventative system health checks, system log analytics, automated root cause analysis etc', 'Manage and direct processes of AI related projects', 'Drive requirements for AI related projects, work with internal customers and with ServiceNow and Salesforce Product Managers for features planning, prioritization and implementation', 'Understand and apply various statistical methods for data analysis, EDA, hypothesis testing, and drawing meaningful conclusions', 'Understand ML concepts and has applied one or more of Deep Learning methods, NLP, computer vision, sentiment analysis, topic modeling and graph theory in real world applications to solve business problems', 'Guiding models to master the theory and application of supervised, unsupervised, and reinforcement learning algorithms for tasks like classification, regression, and clustering', 'Training ML models to effectively communicate complex data insights through clear and informative visualizations', 'Instilling in models an understanding of the ethical implications of data science, including bias detection, fairness, and responsible data handling', 'Develop application-specific interfaces that leverage GenAI capabilities, LLMs and FMs to enhance the associate and customer experience', 'Design APIs for performance, real-time applications, scale, ease of use and governance automation', 'Serves as industry thought leader in data science and applies deep expertise to drive novel customer experiences', 'to build AI solutions']",True,"['Generative AI', 'Large Language Models', 'Foundation Models', 'Deep Learning', 'Natural Language Processing (NLP)', 'Computer Vision', 'Ethical AI']","Generative AI: Developing AI solutions leveraging generative AI capabilities to enhance user and customer experiences.; Large Language Models: Building application-specific interfaces that utilize LLMs to improve associate and customer interactions.; Foundation Models: Employing foundation models as part of AI solutions to support advanced natural language and other AI tasks.; Deep Learning: Applying deep learning methods such as neural networks for NLP, computer vision, and other AI-driven business solutions.; Natural Language Processing (NLP): Using NLP techniques within AI projects to analyze and interpret human language for business applications.; Computer Vision: Applying computer vision methods to solve real-world business problems through AI.; Ethical AI: Incorporating bias detection, fairness, and responsible data handling principles in AI model development.","['Statistical Methods', 'Supervised Learning', 'Unsupervised Learning', 'Reinforcement Learning', 'Predictive Modeling', 'Prescriptive Modeling', 'Feature Engineering', 'Data Integration', 'Python', 'R', 'PyTorch', 'TensorFlow', 'Keras', 'NLTK', 'spaCy', 'PostgreSQL', 'Amazon Redshift', 'Microsoft SQL Server', 'Cloud Platforms', 'Exploratory Data Analysis (EDA)', 'Sentiment Analysis', 'Topic Modeling', 'Graph Theory', 'Data Visualization']","Statistical Methods: Used for data analysis, exploratory data analysis (EDA), hypothesis testing, and drawing meaningful conclusions to support business decisions.; Supervised Learning: Applied for tasks like classification and regression to build predictive models that drive business outcomes.; Unsupervised Learning: Used for clustering and discovering patterns in data without labeled outcomes to support analytics.; Reinforcement Learning: Guided models to apply reinforcement learning algorithms for specific business problem-solving tasks.; Predictive Modeling: Building custom predictive models for preventative system health checks and automated root cause analysis.; Prescriptive Modeling: Developing prescriptive models to recommend actions based on predictive insights for system health and operations.; Feature Engineering: Performing univariate and bivariate analysis using Python libraries to prepare data for advanced machine learning models.; Data Integration: Integrating and cleansing data from multiple sources including databases, files, APIs, and server logs for analysis.; Python: Primary programming language used for data analysis, building machine learning models, and data integration.; R: Used as a data science tool for statistical analysis and modeling.; PyTorch: Employed as a data science tool for building machine learning and deep learning models.; TensorFlow: Used for developing machine learning and deep learning models within data science projects.; Keras: A high-level neural networks API used for building and training deep learning models.; NLTK: Applied for natural language processing tasks within data science workflows.; spaCy: Used for advanced natural language processing and text analytics.; PostgreSQL: Database technology used for storing and querying structured data.; Amazon Redshift: Data warehousing solution used for large-scale data storage and analytics.; Microsoft SQL Server: Relational database management system used for data storage and querying.; Cloud Platforms: Experience with Azure, AWS, and Google Cloud Platform for deploying and managing data science solutions.; Exploratory Data Analysis (EDA): Conducting initial investigations on data to discover patterns, spot anomalies, and test hypotheses.; Sentiment Analysis: Analyzing text data to determine sentiment as part of data-driven business insights.; Topic Modeling: Unsupervised learning technique used to identify topics in large collections of text data.; Graph Theory: Applied to analyze relationships and structures within data for business problem solving.; Data Visualization: Training models to communicate complex data insights through clear and informative visualizations."
ON9FoPBRATzj3HmNAAAAAA==,Mid-Level Data Scientist / Quant - Risk & Trading,"About Sleeper

Sleeper is one of the fastest-growing sports platforms in the US. We build free‑to‑play fantasy titles and real‑money Daily Fantasy Sports (DFS) games across the NFL, NBA/WNBA, MLB, NHL, EU football, and more. Our Risk & Trading team safeguards game integrity and optimizes profitability through data‑driven pricing and exposure management.

What You'll Be Doing
• Feature engineering & model tuning - Own the pipelines that transform raw bet, player, and market data into features for our pricing and exposure models (BigQuery + SQLX, Python, Pandas).
• Predictive modeling - Train, validate, and deploy supervised and probabilistic models that forecast player performance, market volatility, and user value.
• Guardrail automation - Ship rule‑based limiters and anomaly‑detection jobs that run every few seconds, flagging and throttling outlier exposure before it becomes tail risk.
• Dashboards & alerting - Build Grafana dashboards and SQLX reports that surface live liability, promo uptake, and top‑line KPIs to trading and exec stakeholders.
• Light on‑call rotation - During peak sports windows, respond to automated alerts and, if necessary, execute a manual override (price suspension / limit change). < 2 hrs/wk on average.
• Cross‑functional collaboration - Pair with Backend & Data Engineers to productionize models, and with Product to iterate on game mechanics and promos.

Who You Are
• 3‑5 years in data science, machine learning, or quant research; comfortable owning end‑to‑end projects.
• Fluent in Python, SQL, and modern ML tooling (scikit‑learn, XGBoost, Airflow or similar).
• Familiar with sports data and the economics of fantasy / sportsbook markets; plus if you've built pricing or risk models.
• Systems thinker who anticipates failure modes and edge cases in real‑time environments.
• Willing to flex hours around major game slates; we're a remote‑first team and optimize schedules for coverage & work‑life balance.

Nice‑to‑Haves
• Experience with BigQuery, Looker, dbt, or similar analytics stacks.
• Exposure to real‑time streams (Kafka, Pub/Sub) and event‑driven architectures.
• Prior work building user‑level segmentation or LTV models.

Compensation

In the United States, the reasonable base salary range for this role is $90 000 - $175 000 USD, plus equity and benefits (medical, dental, vision, PTO, 401k). Final offers consider experience, skills, and market data.

Benefits
• Competitive salary and stock options
• Comprehensive health, dental, and vision insurance
• 401(k)
• Flexible working hours and remote-first culture
• Clear paths for career growth and leadership

What we offer

Sleeper believes in quality over quantity, and intentionally keeps our team small as a result. In past roles, we found it very hard to make a big impact when companies grow too large in size, which has a detrimental effect on the product and the impact any single individual can have. Our team includes designers, engineers, product experts, and finance & operation focused on one thing - connecting people over sports. We believe in fair and equitable pay. Certain locations in the United States require job postings to include a reasonable estimate of the base salary range and/or a general description of benefits and other compensation applicable to the role.

Competitive salary plus benefits including Medical, Dental, PTO, 401k. Please note that The salary range for this role takes into account a wide range of factors that are considered in making compensation decisions including, but not limited to, skill sets; experience and training; licensure and certifications; and other business and organizational needs. The policy of Sleeper is to provide equal employment opportunities to all applicants and employees without regard to race, color, creed, religion, sex, sexual orientation, gender identity, marital status, citizenship status, age, national origin, ancestry, disability, veteran status, or any other legally protected status and to affirmatively seek to advance the principles of equal employment opportunity. Sleeper is committed to being an Equal Opportunity Employer and offers opportunities to all job seekers, including job seekers with disabilities. If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access the Company's career webpage as a result of your disability. You may request reasonable accommodations by sending an email to jobs@sleeper.app.

Headquartered in Las Vegas, NV, Sleeper is backed by Silicon Valley's top investors, including Andreessen Horowitz, General Catalyst, and Expa.
To learn more, visit us online at: www.sleeper.com",2025-06-26T00:00:00.000Z,2025-07-25,"['3‑5 years in data science, machine learning, or quant research; comfortable owning end‑to‑end projects', 'Fluent in Python, SQL, and modern ML tooling (scikit‑learn, XGBoost, Airflow or similar)', ""Familiar with sports data and the economics of fantasy / sportsbook markets; plus if you've built pricing or risk models"", 'Experience with BigQuery, Looker, dbt, or similar analytics stacks', 'Exposure to real‑time streams (Kafka, Pub/Sub) and event‑driven architectures', 'Prior work building user‑level segmentation or LTV models']","['Our Risk & Trading team safeguards game integrity and optimizes profitability through data‑driven pricing and exposure management', 'Feature engineering & model tuning - Own the pipelines that transform raw bet, player, and market data into features for our pricing and exposure models (BigQuery + SQLX, Python, Pandas)', 'Predictive modeling - Train, validate, and deploy supervised and probabilistic models that forecast player performance, market volatility, and user value', 'Guardrail automation - Ship rule‑based limiters and anomaly‑detection jobs that run every few seconds, flagging and throttling outlier exposure before it becomes tail risk', 'Dashboards & alerting - Build Grafana dashboards and SQLX reports that surface live liability, promo uptake, and top‑line KPIs to trading and exec stakeholders', 'Light on‑call rotation - During peak sports windows, respond to automated alerts and, if necessary, execute a manual override (price suspension / limit change)', '< 2 hrs/wk on average', 'Systems thinker who anticipates failure modes and edge cases in real‑time environments', ""Willing to flex hours around major game slates; we're a remote‑first team and optimize schedules for coverage & work‑life balance""]",True,[],,"['Feature Engineering', 'Predictive Modeling', 'Anomaly Detection', 'SQL', 'Python', 'Pandas', 'scikit-learn', 'XGBoost', 'Airflow', 'BigQuery', 'Looker', 'dbt', 'Kafka', 'Pub/Sub', 'Grafana', 'User Segmentation', 'Lifetime Value Modeling']","Feature Engineering: Transforming raw bet, player, and market data into features for pricing and exposure models.; Predictive Modeling: Training, validating, and deploying supervised and probabilistic models to forecast player performance, market volatility, and user value.; Anomaly Detection: Implementing rule-based limiters and anomaly-detection jobs to flag and throttle outlier exposure in real-time.; SQL: Using SQLX and BigQuery for querying and managing data pipelines and reports.; Python: Utilizing Python for data processing, feature engineering, and model development.; Pandas: Employing Pandas library for data manipulation and analysis within data pipelines.; scikit-learn: Applying scikit-learn for building and tuning machine learning models.; XGBoost: Using XGBoost for gradient boosting models in predictive analytics.; Airflow: Managing and scheduling data workflows and pipelines.; BigQuery: Leveraging BigQuery for large-scale data warehousing and analytics.; Looker: Building dashboards and reports for data visualization and business intelligence.; dbt: Using dbt for data transformation and modeling within analytics stacks.; Kafka: Handling real-time data streams and event-driven architectures.; Pub/Sub: Managing real-time messaging and event-driven data pipelines.; Grafana: Creating dashboards and alerting systems to monitor live KPIs and liabilities.; User Segmentation: Building models to segment users for targeted analysis and marketing.; Lifetime Value Modeling: Developing models to estimate user lifetime value for business insights."
fqFG2JFX5aevR7w_AAAAAA==,Junior Data Scientist - Remote,"For more than 12 years Synergisticit has helped Jobseekers stand out from other Jobseekers by providing candidates the requisite skills, experience and technical competence to outperform at interviews and at clients. Here at SynergisticIT We just don't focus on getting you a tech Job we make careers.

In this market also our candidates get multiple job offers and $100k + salaries.

please check the below links to see success outcomes of our candidates .

https://www.synergisticit.com/candidate-outcomes/

https://reg.rf.oracle.com/flow/oracle/cwoh23/OCWExhibitorCatalog/page/OCWexhibitorcatalog

We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please see us exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023

All Positions are open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.

We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

https://www.youtube.com/watch?v=OFoqPTNORew

https://www.youtube.com/watch?v=-HkNN1ag6Zk

https://www.youtube.com/watch?v=OAFOhcGy9Z8

https://youtu.be/bJJl27D8bh0

We want Data Science/Machine learning/Data Analyst and Java Full stack candidates

For data Science/Machine learning Positions

REQUIRED SKILLS

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Project work on the technologies needed

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools

Excellent written and verbal communication skills

Preferred skills: NLP, Text mining, Tableau, PowerBI, Databricks, Tensorflow

REQUIRED SKILLS For Java /Full stack/Software Positions

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Project work on the skills

Knowledge of Core Java , javascript , C++ or software programming

Spring boot, Microservices, Docker, Jenkins and REST API's experience

Excellent written and verbal communication skills

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",,2025-07-25,"['Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry', 'We want Data Science/Machine learning/Data Analyst and Java Full stack candidates', 'For data Science/Machine learning Positions', 'Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT', 'Project work on the technologies needed', 'Highly motivated, self-learner, and technically inquisitive', 'Experience in programming language Java and understanding of the software development life cycle', 'Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools', 'Excellent written and verbal communication skills', 'REQUIRED SKILLS For Java /Full stack/Software Positions', 'Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT', 'Highly motivated, self-learner, and technically inquisitive', 'Experience in programming language Java and understanding of the software development life cycle', 'Project work on the skills', 'Knowledge of Core Java , javascript , C++ or software programming', ""Spring boot, Microservices, Docker, Jenkins and REST API's experience"", 'Excellent written and verbal communication skills']",,True,"['TensorFlow', 'Natural Language Processing']","TensorFlow: Mentioned as a preferred skill, indicating familiarity with deep learning frameworks used for building AI models.; Natural Language Processing: NLP is noted as a preferred skill, relating to AI techniques for processing and analyzing text data.","['Statistics', 'SAS', 'Python', 'Data Visualization Tools', 'Tableau', 'PowerBI', 'Databricks', 'Computer Vision']","Statistics: Used as foundational knowledge for data analysis and modeling tasks in data science roles.; SAS: A statistical software tool mentioned as part of the required skills for data science and analytics work.; Python: Programming language used for data manipulation, analysis, and building data science projects.; Data Visualization Tools: Tools like Tableau and PowerBI are referenced for creating dashboards and visual insights from data.; Tableau: A BI and data visualization tool preferred for creating interactive dashboards and reports.; PowerBI: A business intelligence tool preferred for data visualization and reporting.; Databricks: A unified analytics platform mentioned as a preferred skill, useful for data engineering and collaborative data science.; Computer Vision: Listed as a knowledge area, indicating experience with image data processing and analysis."
_Lvr-60CKa0fuda6AAAAAA==,"Principal Data Scientist - Generative AI, Machine Learning, Python, R - Remote","Job Description

Job Summary

Responsible for overseeing data science projects, managing and mentoring a team, and aligning data initiatives with business goals. Lead the development and implementation of data models, collaborate with cross-functional teams, and stay updated on industry trends. Ensure ethical data use and communicate complex technical concepts to non-technical stakeholders. Lead initiatives on model governance and model ops to align with regulatory and security requirements. This role requires technical expertise, strategic thinking, and leadership to drive data-driven decision-making within the organization and be the pioneer on generative AI healthcare solutions, aimed at revolutionizing healthcare operations as well as enhancing member experience.

Job Duties

• Research and Development: Stay current with the latest advancements in AI and machine learning and apply these insights to improve existing models and develop new methodologies.
• AI Model Deployment, Monitoring & Model Governance: Deploy AI models into production environments, monitor their performance, and adjust as necessary to maintain accuracy and effectiveness and meet all governance and regulatory requirements.
• Innovation Projects: Lead pilot projects to test and implement new AI technologies within the organization
• Data Analysis and Interpretation: Extract meaningful insights from complex datasets, identify patterns, and interpret data to inform strategic decision-making.
• Machine Learning Model Development: Design, develop, and train machine learning models using a variety of algorithms and techniques, including supervised and unsupervised learning, deep learning, and reinforcement learning.
• Agentic Workflows Implementation: Develop and implement agentic workflows that utilize AI agents for autonomous task execution, enhancing operational efficiency and decision-making capabilities.
• RAG Pattern Utilization: Employ retrieval-augmented generation patterns to improve the performance of language models, ensuring they can access and utilize external knowledge effectively to enhance their outputs.
• Model Fine-Tuning: Fine-tune pre-trained models to adapt them to specific tasks or datasets, ensuring optimal performance and relevance in various applications.
• Data Cleaning and Preprocessing: Prepare data for analysis by performing data cleaning, handling missing values, and removing outliers to ensure high-quality inputs for modeling.
• Collaboration: Work closely with cross-functional teams, including software engineers, product managers, and business analysts, to integrate AI solutions into existing systems and processes.
• Documentation and Reporting: Create comprehensive documentation of models, methodologies, and results; communicate findings clearly to non-technical stakeholders.
• Mentors, coaches, and provides guidance to newer data scientists.
• Partner closely with business and other technology teams to build ML models which helps in improving Star ratings, reduce care gap and other business objectives.
• Present complex analytical information to all level of audiences in a clear and concise manner Collaborate with analytics team, assigning and managing delivery of analytical projects as appropriate
• Perform other duties as business requirements change, looking out for data solutions and technology enabled solution opportunities and make referrals to the appropriate team members in building out payment integrity solutions.
• Use a broad range of tools and techniques to extract insights from current industry or sector trends

Job Qualifications

REQUIRED EDUCATION:

Master’s Degree in Computer Science, Data Science, Statistics, or a related field

REQUIRED EXPERIENCE/KNOWLEDGE, SKILLS & ABILITIES:

• 10+ years’ work experience as a data scientist preferably in healthcare environment but candidates with suitable experience in other industries will be considered
• Knowledge of big data technologies (e.g., Hadoop, Spark)
• Familiar with relational database concepts, and SDLC concepts
• Demonstrate critical thinking and the ability to bring order to unstructured problems
• Technical Proficiency: Strong programming skills in languages such as Python and R, and experience with machine learning frameworks like TensorFlow, Keras, or PyTorch.
• Statistical Analysis: Excellent understanding of statistical methods and machine learning algorithms, including k-NN, Naive Bayes, SVM, and neural networks.
• Experience with Agentic Workflows: Familiarity with designing and implementing agentic workflows that leverage AI agents for autonomous operations.
• RAG Techniques: Knowledge of retrieval-augmented generation techniques and their application in enhancing AI model outputs.
• Model Fine-Tuning Expertise: Proven experience in fine-tuning models for specific tasks, ensuring they meet the required performance metrics.
• Data Visualization: Proficiency in data visualization tools (e.g., Tableau, Power BI) to present complex data insights effectively.
• Database Management: Experience with SQL and NoSQL databases, data warehousing, and ETL processes.
• Problem-Solving Skills: Strong analytical and problem-solving abilities, with a focus on developing innovative solutions to complex challenges.

PREFERRED EDUCATION:

PHD or additional experience

PREFERRED EXPERIENCE:

• Experience with cloud platforms (e.g., Databricks, Snowflake, Azure AI Studio etc.) for working with AI workflows and deploying models.
• Familiarity with natural language processing (NLP) and computer vision techniques.

#PJCorp2

#LI-AC1

To all current Molina employees: If you are interested in applying for this position, please apply through the intranet job listing.

Molina Healthcare offers a competitive benefits and compensation package. Molina Healthcare is an Equal Opportunity Employer (EOE) M/F/D/V.",2025-07-11T00:00:00.000Z,2025-07-25,"['Master’s Degree in Computer Science, Data Science, Statistics, or a related field', '10+ years’ work experience as a data scientist preferably in healthcare environment but candidates with suitable experience in other industries will be considered', 'Knowledge of big data technologies (e.g., Hadoop, Spark)', 'Familiar with relational database concepts, and SDLC concepts', 'Demonstrate critical thinking and the ability to bring order to unstructured problems', 'Technical Proficiency: Strong programming skills in languages such as Python and R, and experience with machine learning frameworks like TensorFlow, Keras, or PyTorch', 'Statistical Analysis: Excellent understanding of statistical methods and machine learning algorithms, including k-NN, Naive Bayes, SVM, and neural networks', 'Experience with Agentic Workflows: Familiarity with designing and implementing agentic workflows that leverage AI agents for autonomous operations', 'RAG Techniques: Knowledge of retrieval-augmented generation techniques and their application in enhancing AI model outputs', 'Model Fine-Tuning Expertise: Proven experience in fine-tuning models for specific tasks, ensuring they meet the required performance metrics', 'Data Visualization: Proficiency in data visualization tools (e.g., Tableau, Power BI) to present complex data insights effectively', 'Database Management: Experience with SQL and NoSQL databases, data warehousing, and ETL processes', 'Problem-Solving Skills: Strong analytical and problem-solving abilities, with a focus on developing innovative solutions to complex challenges', 'PHD or additional experience']","['Responsible for overseeing data science projects, managing and mentoring a team, and aligning data initiatives with business goals', 'Lead the development and implementation of data models, collaborate with cross-functional teams, and stay updated on industry trends', 'Ensure ethical data use and communicate complex technical concepts to non-technical stakeholders', 'Lead initiatives on model governance and model ops to align with regulatory and security requirements', 'This role requires technical expertise, strategic thinking, and leadership to drive data-driven decision-making within the organization and be the pioneer on generative AI healthcare solutions, aimed at revolutionizing healthcare operations as well as enhancing member experience', 'Research and Development: Stay current with the latest advancements in AI and machine learning and apply these insights to improve existing models and develop new methodologies', 'AI Model Deployment, Monitoring & Model Governance: Deploy AI models into production environments, monitor their performance, and adjust as necessary to maintain accuracy and effectiveness and meet all governance and regulatory requirements', 'Innovation Projects: Lead pilot projects to test and implement new AI technologies within the organization', 'Data Analysis and Interpretation: Extract meaningful insights from complex datasets, identify patterns, and interpret data to inform strategic decision-making', 'Machine Learning Model Development: Design, develop, and train machine learning models using a variety of algorithms and techniques, including supervised and unsupervised learning, deep learning, and reinforcement learning', 'Agentic Workflows Implementation: Develop and implement agentic workflows that utilize AI agents for autonomous task execution, enhancing operational efficiency and decision-making capabilities', 'RAG Pattern Utilization: Employ retrieval-augmented generation patterns to improve the performance of language models, ensuring they can access and utilize external knowledge effectively to enhance their outputs', 'Model Fine-Tuning: Fine-tune pre-trained models to adapt them to specific tasks or datasets, ensuring optimal performance and relevance in various applications', 'Data Cleaning and Preprocessing: Prepare data for analysis by performing data cleaning, handling missing values, and removing outliers to ensure high-quality inputs for modeling', 'Collaboration: Work closely with cross-functional teams, including software engineers, product managers, and business analysts, to integrate AI solutions into existing systems and processes', 'Documentation and Reporting: Create comprehensive documentation of models, methodologies, and results; communicate findings clearly to non-technical stakeholders', 'Mentors, coaches, and provides guidance to newer data scientists', 'Partner closely with business and other technology teams to build ML models which helps in improving Star ratings, reduce care gap and other business objectives', 'Present complex analytical information to all level of audiences in a clear and concise manner Collaborate with analytics team, assigning and managing delivery of analytical projects as appropriate', 'Perform other duties as business requirements change, looking out for data solutions and technology enabled solution opportunities and make referrals to the appropriate team members in building out payment integrity solutions', 'Use a broad range of tools and techniques to extract insights from current industry or sector trends']",True,"['Generative AI', 'Agentic Workflows', 'Retrieval-Augmented Generation', 'Large Language Models', 'Prompt Engineering', 'AI Model Deployment and Monitoring', 'Natural Language Processing', 'Computer Vision', 'Cloud AI Platforms']","Generative AI: Leading initiatives to develop AI solutions that generate novel healthcare content and enhance member experience.; Agentic Workflows: Designing autonomous AI agent workflows to automate healthcare operational tasks and improve efficiency.; Retrieval-Augmented Generation: Applying RAG techniques to enhance language model outputs by integrating external healthcare knowledge.; Large Language Models: Utilizing LLMs for natural language processing tasks within healthcare AI solutions.; Prompt Engineering: Fine-tuning prompts to optimize the performance of generative AI models in healthcare applications.; AI Model Deployment and Monitoring: Managing the production lifecycle of AI models, ensuring their accuracy and compliance in healthcare environments.; Natural Language Processing: Applying NLP techniques to process and analyze healthcare text data as part of AI-driven solutions.; Computer Vision: Using computer vision methods to analyze healthcare images and support diagnostic processes.; Cloud AI Platforms: Leveraging cloud services like Databricks, Snowflake, and Azure AI Studio to deploy and manage AI workflows.","['Supervised Learning', 'Unsupervised Learning', 'Deep Learning', 'Reinforcement Learning', 'Machine Learning Model Development', 'Model Fine-Tuning', 'Data Cleaning and Preprocessing', 'Statistical Methods', 'Neural Networks', 'Big Data Technologies', 'SQL and NoSQL Databases', 'Data Warehousing and ETL', 'Data Visualization', 'Python and R Programming', 'Machine Learning Frameworks', 'Model Governance and Model Ops', 'Data Analysis and Interpretation', 'Feature Engineering']","Supervised Learning: Used to design and train machine learning models with labeled data to predict outcomes relevant to healthcare operations.; Unsupervised Learning: Applied to discover patterns and insights from unlabeled healthcare datasets to inform strategic decisions.; Deep Learning: Utilized for developing complex neural network models to improve predictive accuracy in healthcare applications.; Reinforcement Learning: Employed to develop models that learn optimal policies for autonomous decision-making in healthcare workflows.; Machine Learning Model Development: Involves designing, developing, and training various machine learning algorithms to support healthcare business objectives.; Model Fine-Tuning: Adjusting pre-trained models to specific healthcare tasks to enhance performance and relevance.; Data Cleaning and Preprocessing: Preparing healthcare data by handling missing values and outliers to ensure quality inputs for modeling.; Statistical Methods: Applying statistical analysis techniques such as k-NN, Naive Bayes, and SVM to extract insights from healthcare data.; Neural Networks: Used as part of deep learning approaches to model complex healthcare data relationships.; Big Data Technologies: Utilizing platforms like Hadoop and Spark to process and analyze large-scale healthcare datasets.; SQL and NoSQL Databases: Managing structured and unstructured healthcare data through relational and non-relational database systems.; Data Warehousing and ETL: Building and maintaining data pipelines to aggregate and transform healthcare data for analysis.; Data Visualization: Using tools like Tableau and Power BI to present complex healthcare data insights to stakeholders.; Python and R Programming: Primary languages for implementing data science workflows, statistical analysis, and machine learning in healthcare.; Machine Learning Frameworks: Employing TensorFlow, Keras, and PyTorch to develop and deploy machine learning models in healthcare contexts.; Model Governance and Model Ops: Ensuring deployed models comply with regulatory and security requirements within healthcare operations.; Data Analysis and Interpretation: Extracting meaningful insights from healthcare datasets to guide strategic decision-making.; Feature Engineering: Creating relevant features from healthcare data to improve model performance."
d96-yMLRAA3mGfySAAAAAA==,Entry Level Data Analyst/Scientist,"For more than 12 years Synergisticit has helped Jobseekers stand out from other Jobseekers by providing candidates the requisite skills, experience and technical competence to outperform at interviews and at clients. Here at SynergisticIT We just don't focus on getting you a tech Job we make careers.

In this market also our candidates get multiple job offers and $100k + salaries.

please check the below links to see success outcomes of our candidates .

https://www.synergisticit.com/candidate-outcomes/

https://reg.rf.oracle.com/flow/oracle/cwoh23/OCWExhibitorCatalog/page/OCWexhibitorcatalog

We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please see us exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023

All Positions are open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.

We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

https://www.youtube.com/watch?v=OFoqPTNORew

https://www.youtube.com/watch?v=-HkNN1ag6Zk

https://www.youtube.com/watch?v=OAFOhcGy9Z8

https://youtu.be/bJJl27D8bh0

We want Data Science/Machine learning/Data Analyst and Java Full stack candidates

For data Science/Machine learning Positions

REQUIRED SKILLS

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Project work on the technologies needed

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools

Excellent written and verbal communication skills

Preferred skills: NLP, Text mining, Tableau, PowerBI, Databricks, Tensorflow

REQUIRED SKILLS For Java /Full stack/Software Positions

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Project work on the skills

Knowledge of Core Java , javascript , C++ or software programming

Spring boot, Microservices, Docker, Jenkins and REST API's experience

Excellent written and verbal communication skills

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",,2025-07-25,"['Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry', 'We want Data Science/Machine learning/Data Analyst and Java Full stack candidates', 'For data Science/Machine learning Positions', 'Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT', 'Project work on the technologies needed', 'Highly motivated, self-learner, and technically inquisitive', 'Experience in programming language Java and understanding of the software development life cycle', 'Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools', 'Excellent written and verbal communication skills', 'REQUIRED SKILLS For Java /Full stack/Software Positions', 'Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT', 'Highly motivated, self-learner, and technically inquisitive', 'Experience in programming language Java and understanding of the software development life cycle', 'Project work on the skills', 'Knowledge of Core Java , javascript , C++ or software programming', ""Spring boot, Microservices, Docker, Jenkins and REST API's experience"", 'Excellent written and verbal communication skills']",,True,['TensorFlow'],"TensorFlow: A deep learning framework preferred for building neural network models, indicating AI-related skills.","['Statistics', 'SAS', 'Python', 'Data Visualization Tools', 'Tableau', 'PowerBI', 'Databricks', 'Computer Vision', 'NLP', 'Machine Learning']","Statistics: Used as foundational knowledge for data analysis and modeling tasks in data science roles.; SAS: A statistical software tool mentioned as part of the required skills for data analysis and statistical modeling.; Python: Programming language used for data manipulation, analysis, and building data science projects.; Data Visualization Tools: Tools like Tableau and PowerBI are referenced for creating dashboards and visual insights from data.; Tableau: A BI and data visualization tool preferred for creating interactive dashboards and reports.; PowerBI: A business intelligence tool preferred for data visualization and reporting.; Databricks: A unified analytics platform mentioned as a preferred skill for data engineering and collaborative data science.; Computer Vision: Listed as a knowledge area, relevant for image data analysis and related data science tasks.; NLP: Natural Language Processing is mentioned as a preferred skill for text mining and analysis.; Machine Learning: General machine learning knowledge is required for data science and machine learning engineer roles."
56LS-3FzhsqSA6rWAAAAAA==,"(USA) Principal, Data Scientist","Position Summary...

What you'll do...

This is an exciting opportunity to join our Sams Club Product Operations Data Science team, where you will unlock member and associate insights for our product managers.

About the Sams Club Product Operations Data Science Team

The team focusses on measuring the impact of our strategic product initiatives and better connecting insights across our Product Organization. We want to enhance the speed and quality of planning within our top-notch product management function and what better place to do that than in an organization that is Product Led, Data Driven and Member Obsessed.

What you'll do:
• Provide a macro view of product-driven value to our Executive Team; creating and measuring metrics that matter and being able to tell a compelling story
• Give easy access to voice-of-the-member ; voice-of-the-associate to our product managers; dishing it up in a way that is easy to draw insights from.
• Focus on input/leading indicators and being able to demonstrate impact to output/lagging indicators.
• Establish connectivity of our data ; insights; taking advantage of all touch points with our members, showing how our work complements each other to help drive operational fixes, backlog advancement and more strategic product solutions.
• Identify high impact and return on investment opportunities.
• Build and fostering collaborative relationships with key partners (business leaders, UX, Engineering) by driving priorities across business pillars and role modeling transparency.

What you'll bring:
• Strong Technical Skills: Causal Analysis, Experimentation, Statistics, SQL, Python, R
• Ability to connect the dots: Be a strategic advisor to technology partners and can understand the business problem, the product-based solution and connect it to an analytic methodology.
• Great Collaborator: Work with stakeholders such as product managers, engineering, sister analytics teams, User Experience, and business teams
• Demonstrates Good Judgement: This is a senior role and will influence senior leadership. Minimum 10 years of experience in a data science role
• Strong Retail Experience is a plus: Experience in data science in supply chain, merchandising, in-club analytics, operations, and e Commerce.

The above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.

Benefits ; Perks:

Beyond great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.
Equal Opportunity Employer:

Sams Club is an Equal Opportunity Employer- By Choice. We believe we are best equipped to help our associates, customers, and the communities we serve live better when we really know them. That means understanding, respecting, and valuing unique styles, experiences, identities, abilities, ideas and opinions- while being welcoming of all people.

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

‎

‎

‎
You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.

‎

For information about PTO, see https://one.walmart.com/notices.

‎

‎
Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

‎
Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

‎

For information about benefits and eligibility, see One.Walmart.

‎
The annual salary range for this position is $143,000.00-$286,000.00

‎
Additional compensation includes annual or quarterly performance bonuses.

‎
Additional compensation for certain positions may also include:

‎

‎
- Stock

‎

‎

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 5 years' experience in an analytics related field. Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 3 years' experience in an analytics related field. Option 3: 7 years' experience in an analytics or related field

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data science, machine learning, optimization models, PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Publications or active peer reviewer in related journals or conference, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.

Primary Location...

850 Cherry Avenue, San Bruno, CA 94066-3031, United States of America",2025-07-20T00:00:00.000Z,2025-07-25,"['Strong Technical Skills: Causal Analysis, Experimentation, Statistics, SQL, Python, R', 'Ability to connect the dots: Be a strategic advisor to technology partners and can understand the business problem, the product-based solution and connect it to an analytic methodology', 'Great Collaborator: Work with stakeholders such as product managers, engineering, sister analytics teams, User Experience, and business teams', 'Demonstrates Good Judgement: This is a senior role and will influence senior leadership', 'Minimum 10 years of experience in a data science role', 'That means understanding, respecting, and valuing unique styles, experiences, identities, abilities, ideas and opinions- while being welcoming of all people', ""Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 5 years' experience in an analytics related field"", ""Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 3 years' experience in an analytics related field"", ""Option 3: 7 years' experience in an analytics or related field"", 'Data science, machine learning, optimization models, PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Publications or active peer reviewer in related journals or conference, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly', 'The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture']","['We want to enhance the speed and quality of planning within our top-notch product management function and what better place to do that than in an organization that is Product Led, Data Driven and Member Obsessed', 'Provide a macro view of product-driven value to our Executive Team; creating and measuring metrics that matter and being able to tell a compelling story', 'Give easy access to voice-of-the-member ; voice-of-the-associate to our product managers; dishing it up in a way that is easy to draw insights from', 'Focus on input/leading indicators and being able to demonstrate impact to output/lagging indicators', 'Establish connectivity of our data ; insights; taking advantage of all touch points with our members, showing how our work complements each other to help drive operational fixes, backlog advancement and more strategic product solutions', 'Identify high impact and return on investment opportunities', 'Build and fostering collaborative relationships with key partners (business leaders, UX, Engineering) by driving priorities across business pillars and role modeling transparency']",True,[],,"['Causal Analysis', 'Experimentation', 'Statistics', 'SQL', 'Python', 'R', 'Data Science', 'Machine Learning', 'Optimization Models', 'Spark', 'Scala', 'Scikit-learn', 'TensorFlow', 'Torch']","Causal Analysis: Used to understand cause-effect relationships in product and member data to inform strategic decisions.; Experimentation: Applied to design and analyze tests (e.g., A/B testing) to measure impact of product initiatives.; Statistics: Fundamental for analyzing data, measuring metrics, and deriving insights to support product management.; SQL: Used for querying and managing data from relational databases to extract relevant insights.; Python: Programming language employed for data analysis, modeling, and building data pipelines.; R: Statistical programming language used for advanced analytics and data visualization.; Data Science: Core discipline encompassing data analysis, modeling, and deriving actionable insights for product operations.; Machine Learning: Utilized to build predictive and optimization models supporting product and operational decisions.; Optimization Models: Applied to improve operational efficiency and resource allocation within retail and product contexts.; Spark: Big data processing framework used for handling large-scale data analytics.; Scala: Programming language often used with Spark for scalable data processing.; Scikit-learn: Open-source machine learning library used for building and evaluating predictive models.; TensorFlow: Open-source framework mentioned as part of candidate assessments, used for machine learning tasks.; Torch: Open-source machine learning library referenced for candidate assessments, supporting model development."
27OjGwBBtqXGdv6PAAAAAA==,"Data Scientist, Infrastructure Finance (Technical Leadership)","Data Scientist, Infrastructure Finance (Technical Leadership)Join to apply for the Data Scientist, Infrastructure Finance (Technical Leadership) role at MetaData Scientist, Infrastructure Finance (Technical Leadership)1 day ago Be among the first 25 applicantsJoin to apply for the Data Scientist, Infrastructure Finance (Technical Leadership) role at MetaThis range is provided by Meta. Your actual pay will be based on your skills and experience — talk with your recruiter to learn more.Base pay range$206,000.00/yr - $281,000.00/yrMeta is seeking a Data Scientist to join a newly formed team in the Finance organization that partners very closely with Product, AI, Infrastructure, Finance and other Data Science teams across the company. These teams are building some of the most cutting edge and transformative AI products in the world that are being rolled out to Meta’s 3 Billion+ users. Building these products and features requires tens of billions of dollars of capital each year over a sustained period of time. Managing and optimizing the deployment of this vast capital and the allocation of these resources requires a team that has technical expertise in AI and Infrastructure along with a solid understanding of data science, finance and operations. We are building this team in recognition of the importance of AI and Infrastructure from a product perspective as well as the need to be efficient in our approach to deploying capital and generating returns for our shareholders. This position will use data and analysis to identify and solve product development's biggest challenges and will require one to understand the technical aspects of how AI and Infrastructure are built, operated and used to serve users. This role will help establish the ROI and company-wide prioritization of such investments and work on solving some of the most important technological problems of our times and also ensure that the company makes efficient investments. As an individual contributor, you will influence product strategy and investment decisions with data, be focused on impact, and collaborate with other teams. By joining Meta, you will become part of a world-class analytics community dedicated to skill development and career growth in analytics and beyond.Data Scientist, Infrastructure Finance (Technical Leadership) Responsibilities:Work with large and complex data sets to solve a wide array of challenging problems using different analytical and statistical approachesApply technical expertise with quantitative analysis, experimentation, data mining, and the presentation of data to build and maintain end-to-end models for long range planning and strategic decisionsBuild models to compute and explain Infrastructure OPEX and CAPEX costs at the company, product and resource levelsLeverage understanding of AI and Infrastructure to develop independent point-of-view on ROI of investments in Infrastructure and allocation of Infrastructure resources to various products and software platformsIdentify and measure success infrastructure investments through goal setting, forecasting, and monitoring of key metrics to understand trendsHelp define resource allocation policies that are reasonable and actionable from a technical, operational and financial perspectiveWork with product, engineering and data science teams to do technical, operational and business impact assessments of reallocation of resources based on changing business needs, competitive landscape and product roadmapsMaintain lineage of decisions around Infrastructure investments and assumptions under which those decisions were made to drive accountability for outcomes across the companyDefine, understand, and test opportunities and levers to improve our models, and drive roadmaps through your insights and recommendationsPartner with Product, Engineering, and cross-functional teams to inform, influence, support, and execute product strategy and investment decisionsMinimum Qualifications:Bachelor's degree in a directly related field, or equivalent practical experienceA minimum of 12 years of work experience in analytics (minimum of 8 years with a Ph.D.)Bachelor's degree in Mathematics, Statistics, a relevant technical field, or equivalent practical experienceExperience with data querying languages (e.g., SQL), scripting languages (e.g., Python), and/or statistical/mathematical software (e.g., R)Preferred Qualifications:Master's or Ph.D. degree in a quantitative fieldExperience working in a data science role at a hyperscaler, public cloud, and/or a customer of a public cloud companyExperience partnering cross-functionally with a wide range of teams, deal with ambiguity and present technical content in an easy to understand manner to technical and non-technical teamsCuriosity about the inter-relationship between business outcomes and technology investments and experience translating this to practical models for decision makingAbout Meta:Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.$206,000/year to $281,000/year + bonus + equity + benefitsIndividual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.Seniority levelSeniority levelNot ApplicableEmployment typeEmployment typeFull-timeJob functionJob functionEngineering and Information TechnologyIndustriesTechnology, Information and InternetReferrals increase your chances of interviewing at Meta by 2xGet notified about new Data Scientist jobs in Menlo Park, CA.AI Machine Learning Engineer II (Full Time) United StatesSan Jose, CA $195,800.00-$195,800.00 2 weeks agoSan Jose, CA $123,500.00-$212,850.00 3 weeks agoRedwood City, CA $80,000.00-$120,000.00 15 hours agoData Scientist, Generative AI & LLM AgentsSan Bruno, CA $119,000.00-$169,000.00 2 days agoMountain View, CA $132,000.00-$189,000.00 21 hours agoRedwood City, CA $123,000.00-$185,000.00 6 months agoSunnyvale, CA $114,000.00-$171,000.00 3 days agoSan Jose, CA $123,500.00-$212,850.00 17 hours agoSunnyvale, CA $46.63-$134,000.00 3 days agoMountain View, CA $136,301.00-$172,486.00 1 day agoSan Jose, CA $123,500.00-$212,850.00 2 weeks agoFremont, CA $145,000.00-$204,000.00 3 days agoApplied Scientist / Machine Learning Engineer, Software Engineer (Machine Learning)San Jose, CA $123,500.00-$212,850.00 2 weeks agoSan Jose, CA $123,500.00-$212,850.00 1 week agoWe’re unlocking community knowledge in a new way. Experts add insights directly into each article, started with the help of AI.
#J-18808-Ljbffr",,2025-07-25,,,True,['Artificial Intelligence'],"Artificial Intelligence: Relevant as the role requires understanding AI infrastructure and its ROI, supporting AI product strategy and investment decisions.","['SQL', 'Python', 'R', 'Quantitative Analysis', 'Data Mining', 'Statistical Modeling', 'Forecasting', 'Experimentation', 'Data Presentation']","SQL: Used for querying large and complex data sets to support analytics and modeling in infrastructure finance.; Python: Utilized as a scripting language for data analysis, statistical modeling, and building end-to-end models for strategic decisions.; R: Applied as statistical/mathematical software for quantitative analysis and experimentation in finance-related data science tasks.; Quantitative Analysis: Employed to analyze financial and operational data to build models for long-range planning and investment decisions.; Data Mining: Used to extract insights from large datasets to inform infrastructure investment and resource allocation strategies.; Statistical Modeling: Applied to develop models explaining infrastructure OPEX and CAPEX costs and to forecast key financial metrics.; Forecasting: Used to predict trends and measure success of infrastructure investments through goal setting and monitoring.; Experimentation: Implemented to test opportunities and levers for improving financial and operational models.; Data Presentation: Critical for communicating analytical results and model insights to technical and non-technical stakeholders."
cr3DQwZIyk28A0G7AAAAAA==,"Data Scientist Boston, Massachusetts, United States Boston, Massachusetts","Join Axon and be a Force for Good.

At Axon, we’re on a mission to Protect Life. We’re explorers, pursuing society’s most critical safety and justice issues with our ecosystem of devices and cloud software. Like our products, we work better together. We connect with candor and care, seeking out diverse perspectives from our customers, communities and each other.

Life at Axon is fast-paced, challenging and meaningful. Here, you’ll take ownership and drive real change. Constantly grow as you work hard for a mission that matters at a company where you matter.
Your Impact

Real-Time Operations (RTO) is a critical and fast-growing business line at Axon, focused on transforming public safety. Our vision is to become the world’s leading platform for real-time operations—connecting first responders, dispatchers, and supervisors through cutting-edge technology.

In today’s dynamic environments, public safety professionals need real-time situational awareness to act decisively and protect lives. Axon is leading this transformation with products like Axon Fusus, which aggregate livestreams from body-worn cameras, drones, CCTV, and IoT devices into a unified “single pane of glass.” This platform helps public safety teams focus on what matters most—prioritizing vital information while minimizing operational noise.

This is not a vision of the future—it’s happening now. Our team’s mission is to enhance decision-making and situational awareness for public safety professionals when it matters most. We’re building the infrastructure for the future of safe cities, with a relentless focus on saving lives and supporting those who serve.

What You’ll Do

Location: This role does require you to be based within commutable distance to one of our main R&D US Based Hubs (Scottsdale, AZ OR Boston, MA, OR Seattle, WA, OR Atlanta, GA); flexibility to be remote
Reports to:Sr Director of Product
Direct Reports: N/A
• Lead high-impact, cross-functional data initiatives from ideation through execution, collaborating with senior stakeholders across Sales, Operations, and Product to solve complex business challenges and improve customer outcomes.
• Define and operationalize key metrics in partnership with Product and Engineering to measure business performance and enhance the customer experience.
• Uncover insights using descriptive, inferential, and predictive statistical techniques; communicate findings clearly and drive action through data.
• Design and maintain scalable, transparent ETL/ELT pipelines in collaboration with Product Analytics and Data Engineering.
• Develop and own DBT models and curated BI layers that empower product managers and stakeholders to self-serve with confidence.
• Champion data governance, ensuring consistency, discoverability, and alignment with Axon’s enterprise data standards.
• Serve as a strategic thought partner to senior product leadership, surfacing insights and identifying opportunities for data-driven innovation and product development.
What You Bring
• 5+ years of experience in data science, analytics engineering, business intelligence, or related technical fields.
• Advanced proficiency in SQL and programming languages such as Python, R, or Spark for data manipulation and analysis.
• Expertise with modern data stacks including DBT, Airflow (or similar orchestration tools), Snowflake, and data observability tools like Great Expectations.
• Experience designing, building, and maintaining scalable ETL/ELT pipelines in cloud environments such as AWS or Azure.
• Strong data modeling skills with an emphasis on building analytics layers that serve product and business stakeholders.
• Proven ability to communicate complex analyses and insights to both technical and non-technical audiences.
• Demonstrated success visualizing and presenting data using BI tools like Sigma, Tableau, or Power BI.
• Strong attention to detail and comfort navigating ambiguity in complex datasets.
• Collaborative, optimistic, and self-directed mindset.
• A drive to continually learn and master new technologies and techniques.
Benefits that Benefit You
• Competitive salary and 401k with employer match
• Discretionary paid time off
• Paid parental leave for all
• Fitness Programs
• Emotional & Mental Wellness support
• And yes, we have snacks in our offices

Benefits listed herein may vary depending on the nature of your employment and the location where you work.

The Pay: Axon is a total compensation company, meaning compensation is made up of base pay, bonus, and stock awards. The starting base pay for this role is between USD 123,750 in the lowest geographic market and USD 198,000 in the highest geographic market. The actual base pay is dependent upon many factors, such as: level, function, training, transferable skills, work experience, business needs, geographic market, and often a combination of all these factors. Our benefits offer an array of options to help support you physically, financially and emotionally through the big milestones and in your everyday life. To see more details on our benefits offerings please visit www.axon.com/careers/benefits.

Don’t meet every single requirement? That's ok. At Axon, we Aim Far. We think big with a long-term view because we want to reinvent the world to be a safer, better place. We are also committed to building diverse teams that reflect the communities we serve.

Studies have shown that women and people of color are less likely to apply to jobs unless they check every box in the job description. If you’re excited about this role and our mission to Protect Life but your experience doesn’t align perfectly with every qualification listed here, we encourage you to apply anyways. You may be just the right candidate for this or other roles.

The above job description is not intended as, nor should it be construed as, exhaustive of all duties, responsibilities, skills, efforts, or working conditions associated with this job. The job description may change or be supplemented at any time in accordance with business needs and conditions.

Some roles may also require legal eligibility to work in a firearms environment.

Axon’s mission is to Protect Life and is committed to the well-being and safety of its employees as well as Axon’s impact on the environment. All Axon employees must be aware of and committed to the appropriate environmental, health, and safety regulations, policies, and procedures. Axon employees are empowered to report safety concerns as they arise and activities potentially impacting the environment.

We are an equal opportunity employer that promotes justice, advances equity, values diversity and fosters inclusion. We’re committed to hiring the best talent — regardless of race, creed, color, ancestry, religion, sex (including pregnancy), national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, genetic information, veteran status, or any other characteristic protected by applicable laws, regulations and ordinances — and empowering all of our employees so they can do their best work. If you have a disability or special need that requires assistance or accommodation during the application or the recruiting process, please emailrecruitingops@axon.com . Please note that this email address is for accommodation purposes only. Axon will not respond to inquiries for other purposes.
#J-18808-Ljbffr",2025-07-18T00:00:00.000Z,2025-07-25,"['5+ years of experience in data science, analytics engineering, business intelligence, or related technical fields', 'Advanced proficiency in SQL and programming languages such as Python, R, or Spark for data manipulation and analysis', 'Expertise with modern data stacks including DBT, Airflow (or similar orchestration tools), Snowflake, and data observability tools like Great Expectations', 'Experience designing, building, and maintaining scalable ETL/ELT pipelines in cloud environments such as AWS or Azure', 'Strong data modeling skills with an emphasis on building analytics layers that serve product and business stakeholders', 'Proven ability to communicate complex analyses and insights to both technical and non-technical audiences', 'Demonstrated success visualizing and presenting data using BI tools like Sigma, Tableau, or Power BI', 'Strong attention to detail and comfort navigating ambiguity in complex datasets', 'Collaborative, optimistic, and self-directed mindset', 'A drive to continually learn and master new technologies and techniques', 'Some roles may also require legal eligibility to work in a firearms environment']","['Location: This role does require you to be based within commutable distance to one of our main R&D US Based Hubs (Scottsdale, AZ OR Boston, MA, OR Seattle, WA, OR Atlanta, GA); flexibility to be remote', 'Lead high-impact, cross-functional data initiatives from ideation through execution, collaborating with senior stakeholders across Sales, Operations, and Product to solve complex business challenges and improve customer outcomes', 'Define and operationalize key metrics in partnership with Product and Engineering to measure business performance and enhance the customer experience', 'Uncover insights using descriptive, inferential, and predictive statistical techniques; communicate findings clearly and drive action through data', 'Design and maintain scalable, transparent ETL/ELT pipelines in collaboration with Product Analytics and Data Engineering', 'Develop and own DBT models and curated BI layers that empower product managers and stakeholders to self-serve with confidence', 'Champion data governance, ensuring consistency, discoverability, and alignment with Axon’s enterprise data standards', 'Serve as a strategic thought partner to senior product leadership, surfacing insights and identifying opportunities for data-driven innovation and product development']",True,[],,"['SQL', 'Python', 'R', 'Spark', 'DBT', 'Airflow', 'Snowflake', 'Great Expectations', 'ETL/ELT pipelines', 'AWS', 'Azure', 'Data modeling', 'Descriptive statistics', 'Inferential statistics', 'Predictive statistical techniques', 'Business Intelligence (BI) tools', 'Data governance']","SQL: Used for data manipulation and querying to support analysis and metric definition.; Python: Programming language employed for data manipulation, analysis, and building data pipelines.; R: Programming language used for statistical analysis and data science tasks.; Spark: Used for large-scale data processing and analysis within the data engineering workflows.; DBT: Tool for building and managing data transformation models and curated BI layers.; Airflow: Orchestration tool used to design and maintain scalable ETL/ELT pipelines.; Snowflake: Cloud data warehouse platform used for storing and querying large datasets.; Great Expectations: Data observability tool used to ensure data quality and governance.; ETL/ELT pipelines: Processes designed and maintained to extract, transform, and load data at scale in cloud environments.; AWS: Cloud platform used to host and run data infrastructure and pipelines.; Azure: Cloud platform used for scalable data storage and processing.; Data modeling: Building analytics layers to serve product and business stakeholders with reliable data structures.; Descriptive statistics: Used to summarize and describe data characteristics for insight generation.; Inferential statistics: Applied to draw conclusions and make predictions from data samples.; Predictive statistical techniques: Used to forecast outcomes and support decision-making based on data trends.; Business Intelligence (BI) tools: Tools like Sigma, Tableau, and Power BI used to visualize data and communicate insights to stakeholders.; Data governance: Ensuring data consistency, discoverability, and alignment with enterprise standards."
Xg80OBTFD7IoJL0sAAAAAA==,"Data Scientist, USAFSAM/OET, DR-1560-02","Job Overview

The United States Air Force School of Aerospace Medicine (USAFSAM) seeks to fill the mid-level, DR-02 position of Data Scientist within the Occupational & Environmental Health (OE) Department, Technical Operations Division, to serve as the primary Data Scientist.

This job announcement will be accepting candidate submissions until 7 Nov 24.

Position duties include, but are not limited to:
• Principal responsibilities is to develop/modify new methods, approaches, or scientific knowledge to solve challenges.
• Must apply knowledge of science/technology to analyze and resolve multifaceted issues/problems with minimal guidance and consult appropriately to develop objectives, priorities, and deadlines.
• The incumbent must plan and carry out work that is well aligned with organizational goals.
• Must present complex information, concepts, and ideas in a clear, concise, well-organized, and timely manner.
• Must demonstrate effective speaking skills for advanced briefings, tailoring presentations to facilitate understanding.
• Identifies and advocates for resources necessary to support and contribute to mission requirements.
• Demonstrates knowledge of corporate processes by effective application of resources.
• Incumbent will engage others in using resources more efficiently and suggest innovative ideas to optimize available resources.
• Implements the development and transition/transfer of technology solutions, within or beyond your own organization, based upon awareness of customer requirements.
• Evaluates and incorporates appropriate outside technology to support research and development.
• Work collaboratively with others in a dynamic environment, demonstrating respect for other people and alternative viewpoints.

Telework

Yes, this position is eligible for situational telework; as determined by agency policy
Remote Work (CONUS)

No, this position is not approved for remote work.
Required Qualifications
• US Citizenship
• Must be able to obtain and maintain a Secret security clearance.
• Males must be registered for Selective Service, see www.sss.gov
• As a minimum, possess a B.S. degree in mathematics, statistics, computer science, data science or field directly related to the position or a combination of education and experience with courses equivalent to a major field of study (30 semester hours) in mathematics, statistics, computer science, data science or field directly related to the position, plus additional education or appropriate experience.
• Must have at least one year of specialized experience at the DR-01/GS-11 or equivalent grade level. Specialized experience is experience providing the capacity and skills for working independently, leading collaborative events, working in teams and using these approaches to find and solve complex problems.

Desired Qualifications
• Possess an M.S. degree in data analytics, biostatistics, bioinformatics, business intelligence, epidemiology, statistics, computer science, or a related science or engineering field that emphasizes data processing, graphical data presentation, and programming.
• Demonstrate at least 3 years of experience analyzing and processing data sets using Python / Pandas, R, SQL, or related programming software.
• Demonstrate at least 3 years of experience developing advanced data visualizations with tools such as Tableau, Tableau Server, Tableau Desktop, Tableau Prep Builder, Pythong / Matplotlib, or Power BI.
• Demonstrate a minimum of 3 years experience using Microsoft Office software programs including Word, Outlook, PowerPoint, Access, Excel, Visio, or SharePoint.
• Demonstrate at least 5 years of experience applying data processing and visual analytics tools and techniques to medical (clinical) or Occupational and Environmental Health data sets.
• Demonstrate at least 5 years of experience supporting the Air Force or DoD in a medical/clinical, Public Health, or OEH-related field in a government civilian or military capacity.
• Demonstrate experience using SQL for ETL (extract, transform, and load) tools and business intelligence (BI) reporting, data mining, and analytics tools across cloud-based data warehouses, operational databases and data lakes, as well as API-brokered data.
• Demonstrate experience with Software as a Service (SaaS) / Cloud-based platforms such as AWS Redshift (Dbvisualizer) or Databricks (Redash)
• Able to work independently without extensive supervision.
• Able to manage projects to ensure all phases are completed expertly and in a timely manner.
• Have the ability to utilize their knowledge, skills, and abilities (KSA) for guiding, training, and assisting other team members.
• Able to exercise independent judgment.

(Requisition 68672)

Series

1560",,2025-07-25,"['US Citizenship', 'Must be able to obtain and maintain a Secret security clearance', 'Males must be registered for Selective Service, see www.sss.gov', 'As a minimum, possess a B.S. degree in mathematics, statistics, computer science, data science or field directly related to the position or a combination of education and experience with courses equivalent to a major field of study (30 semester hours) in mathematics, statistics, computer science, data science or field directly related to the position, plus additional education or appropriate experience', 'Must have at least one year of specialized experience at the DR-01/GS-11 or equivalent grade level', 'Specialized experience is experience providing the capacity and skills for working independently, leading collaborative events, working in teams and using these approaches to find and solve complex problems']","['Principal responsibilities is to develop/modify new methods, approaches, or scientific knowledge to solve challenges', 'Must apply knowledge of science/technology to analyze and resolve multifaceted issues/problems with minimal guidance and consult appropriately to develop objectives, priorities, and deadlines', 'The incumbent must plan and carry out work that is well aligned with organizational goals', 'Must present complex information, concepts, and ideas in a clear, concise, well-organized, and timely manner', 'Must demonstrate effective speaking skills for advanced briefings, tailoring presentations to facilitate understanding', 'Identifies and advocates for resources necessary to support and contribute to mission requirements', 'Demonstrates knowledge of corporate processes by effective application of resources', 'Incumbent will engage others in using resources more efficiently and suggest innovative ideas to optimize available resources', 'Implements the development and transition/transfer of technology solutions, within or beyond your own organization, based upon awareness of customer requirements', 'Evaluates and incorporates appropriate outside technology to support research and development', 'Work collaboratively with others in a dynamic environment, demonstrating respect for other people and alternative viewpoints']",True,[],,"['Python', 'Pandas', 'R', 'SQL', 'Tableau', 'Matplotlib', 'Power BI', 'AWS Redshift', 'Databricks', 'ETL', 'Business Intelligence', 'Data Visualization', 'Data Processing']","Python: Used for analyzing and processing data sets, including data manipulation with libraries like Pandas.; Pandas: A Python library utilized for data processing and manipulation of complex datasets.; R: Programming language applied for statistical analysis and data processing.; SQL: Used for ETL processes, querying cloud-based data warehouses, operational databases, and data lakes.; Tableau: Employed for developing advanced data visualizations and dashboards.; Matplotlib: Python library used for creating data visualizations.; Power BI: Business intelligence tool used for data visualization and reporting.; AWS Redshift: Cloud-based data warehouse platform used for storing and querying large datasets.; Databricks: Cloud-based platform used for data engineering, analytics, and collaborative data science.; ETL: Processes involving extract, transform, and load of data for analytics and reporting.; Business Intelligence: Techniques and tools used for data mining, reporting, and analytics to support decision-making.; Data Visualization: Techniques and tools applied to graphically represent data to facilitate understanding and insights.; Data Processing: Methods and tools used to clean, transform, and prepare data for analysis."
j9BM52GxZAd3Ib5jAAAAAA==,"Manager, Data Science (Non-Financial Risk)","KPMG Advisory practice is currently our fastest growing practice. We are seeing tremendous client demand, and looking forward we do not anticipate that slowing down. In this ever-changing market environment, our professionals must be adaptable and thrive in a collaborative, team-driven culture. At KPMG, our people are our number one priority. With a wealth of learning and career development opportunities, a world-class training facility and leading market tools, we make sure our people continue to grow both professionally and personally. If you're looking for a firm with a strong team connection where you can be your whole self, have an impact, advance your skills, deepen your experiences, and have the flexibility and access to constantly find new areas of inspiration and expand your capabilities, then consider a career in Advisory.

KPMG is currently seeking a Manager, NFR Data Science in Non-Financial Risk for our Consulting practice.

Responsibilities:
• Serve as the technical lead on projects to design and develop advanced AI/ML solutions to meet clients' unique requirements, including participation in internal and external discussions to gather business use case requirements, provide advanced analytics and data science expertise and solution options for business problems
• Engineer solutions using natural language processing and machine learning techniques to solve critical problems and improve processes for clients across capital markets and financial services businesses, including trade surveillance, electronic communications surveillance, payments fraud detection, third-party risk management and other operational risk categories
• Utilize machine learning, natural language, and statistical analysis methods, such as sentiment analysis, topic modeling, time-series analysis, regression, classification, statistical inference, and validation methods to review financial services client risks
• Perform explanatory data analyses, generate and test working hypotheses; prepare and analyze historical data and identify patterns to develop innovative solutions to financial services operational risk and regulatory compliance programs
• Lead technical teams, mentor junior data scientists, and grow data science expertise within the broader team, including offshore; collaborate with diverse, cross-functional teams to accurately identify and prioritize requirements, ensuring that AI/ML solutions meet the needs and expectations of various stakeholders
• Present to key stakeholders, such as approach, data requirements, interim findings, and final solution architecture and infrastructure

Qualifications:
• Minimum six years of recent professional experience working in advanced analytics and data science; minimum two years of recent experience managing teams and delivering complex and critical projects
• Bachelor's degree from an accredited college/university in a relevant STEM field such as data science, computer science, engineering, mathematics, physics and other related fields
• Extensive experience in AI/ML algorithm development and data analysis including at least one of the following: NLP, time-series analysis, predictive modeling; experience with scripting, data structures and algorithms and ability to work with large amounts of data
• Experience in a statistical programming language (for example, R or Python) and related data science / machine learning packages (for example, Pandas, Scikit-learn, Pytorch, Transformers)
• Excellent communication, written, presentation, and problem-solving skills
• Previous technical client service experience preferred
• Ability to travel as required (based on location and clients served)

KPMG complies with all local/state regulations regarding displaying salary ranges. If required, the ranges displayed below or via the URL below are specifically for those potential hires who will work in the location(s) listed. Any offered salary is determined based on relevant factors such as applicant's skills, job responsibilities, prior relevant experience, certain degrees and certifications and market considerations. In addition, the firm is proud to offer a comprehensive, competitive benefits package, with options designed to help you make the best decisions for yourself, your family, and your lifestyle. Available benefits are based on eligibility. Our Total Rewards package includes a variety of medical and dental plans, vision coverage, disability and life insurance, 401(k) plans, and a robust suite of personal well-being benefits to support your mental health. Depending on job classification, standard work hours, and years of service, KPMG provides Personal Time Off per fiscal year. Additionally, each year the firm publishes a calendar of holidays to be observed during the year and provides two firmwide breaks each year where employees will not be required to use Personal Time Off; one is at year end and the other is around the July 4th holiday. Additional details about our benefits can be found towards the bottom of our KPMG US Careers site at “Benefits & How We Work”.

Follow this link to obtain salary ranges by city outside of CA:

https://kpmg.com/us/en/how-we-work/pay-transparency.html/?id=M116_3_25

KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package. KPMG is an equal opportunity employer. KPMG complies with all applicable federal, state and local laws regarding recruitment and hiring. All qualified applicants are considered for employment without regard to race, color, religion, age, sex, sexual orientation, gender identity, national origin, citizenship status, disability, protected veteran status, or any other category protected by applicable federal, state or local laws. The attached link contains further information regarding the firm's compliance with federal, state and local recruitment and hiring laws. No phone calls or agencies please.

KPMG does not currently require partners or employees to be fully vaccinated or test negative for COVID-19 in order to go to KPMG offices, client sites or KPMG events, except when mandated by federal, state or local law. In some circumstances, clients also may require proof of vaccination or testing (e.g., to go to the client site).

KPMG recruits on a rolling basis. Candidates are considered as they apply, until the opportunity is filled. Candidates are encouraged to apply expeditiously to any role(s) for which they are qualified that is also of interest to them.

Los Angeles County applicants: Material job duties for this position are listed above. Criminal history may have a direct, adverse, and negative relationship with some of the material job duties of this position. These include the duties and responsibilities listed above, as well as the abilities to adhere to company policies, exercise sound judgment, effectively manage stress and work safely and respectfully with others, exhibit trustworthiness, and safeguard business operations and company reputation. Pursuant to the California Fair Chance Act, Los Angeles County Fair Chance Ordinance for Employers, Fair Chance Initiative for Hiring Ordinance, and San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.",2025-06-30T00:00:00.000Z,2025-07-25,"['Minimum six years of recent professional experience working in advanced analytics and data science; minimum two years of recent experience managing teams and delivering complex and critical projects', ""Bachelor's degree from an accredited college/university in a relevant STEM field such as data science, computer science, engineering, mathematics, physics and other related fields"", 'Extensive experience in AI/ML algorithm development and data analysis including at least one of the following: NLP, time-series analysis, predictive modeling; experience with scripting, data structures and algorithms and ability to work with large amounts of data', 'Experience in a statistical programming language (for example, R or Python) and related data science / machine learning packages (for example, Pandas, Scikit-learn, Pytorch, Transformers)', 'Excellent communication, written, presentation, and problem-solving skills', 'Ability to travel as required (based on location and clients served)', 'These include the duties and responsibilities listed above, as well as the abilities to adhere to company policies, exercise sound judgment, effectively manage stress and work safely and respectfully with others, exhibit trustworthiness, and safeguard business operations and company reputation']","[""Serve as the technical lead on projects to design and develop advanced AI/ML solutions to meet clients' unique requirements, including participation in internal and external discussions to gather business use case requirements, provide advanced analytics and data science expertise and solution options for business problems"", 'Engineer solutions using natural language processing and machine learning techniques to solve critical problems and improve processes for clients across capital markets and financial services businesses, including trade surveillance, electronic communications surveillance, payments fraud detection, third-party risk management and other operational risk categories', 'Utilize machine learning, natural language, and statistical analysis methods, such as sentiment analysis, topic modeling, time-series analysis, regression, classification, statistical inference, and validation methods to review financial services client risks', 'Perform explanatory data analyses, generate and test working hypotheses; prepare and analyze historical data and identify patterns to develop innovative solutions to financial services operational risk and regulatory compliance programs', 'Lead technical teams, mentor junior data scientists, and grow data science expertise within the broader team, including offshore; collaborate with diverse, cross-functional teams to accurately identify and prioritize requirements, ensuring that AI/ML solutions meet the needs and expectations of various stakeholders', 'Present to key stakeholders, such as approach, data requirements, interim findings, and final solution architecture and infrastructure', 'In some circumstances, clients also may require proof of vaccination or testing (e.g., to go to the client site)']",True,['Deep Learning Frameworks'],Deep Learning Frameworks: Use of PyTorch and Transformers for developing neural network models and advanced AI solutions.,"['Natural Language Processing', 'Machine Learning', 'Sentiment Analysis', 'Topic Modeling', 'Time-Series Analysis', 'Regression', 'Classification', 'Statistical Inference', 'Validation Methods', 'Explanatory Data Analysis', 'Predictive Modeling', 'Data Science Programming Languages', 'Data Science Libraries']","Natural Language Processing: Used to engineer solutions for trade surveillance, electronic communications surveillance, and payments fraud detection in financial services.; Machine Learning: Applied to develop advanced AI/ML solutions for operational risk and regulatory compliance in financial services.; Sentiment Analysis: Utilized as a statistical method to analyze client risks in financial services.; Topic Modeling: Employed to identify patterns and themes in textual data for risk management.; Time-Series Analysis: Used to analyze temporal data trends relevant to financial risk assessment.; Regression: Applied as a predictive modeling technique to assess financial service risks.; Classification: Used to categorize risk types and detect fraud in financial datasets.; Statistical Inference: Performed to validate hypotheses and support decision-making in risk analysis.; Validation Methods: Used to ensure the accuracy and reliability of predictive models.; Explanatory Data Analysis: Conducted to generate and test hypotheses and identify data patterns for innovative solutions.; Predictive Modeling: Developed to forecast risks and improve operational risk management.; Data Science Programming Languages: Experience with R and Python for scripting and data analysis in advanced analytics.; Data Science Libraries: Use of Pandas and Scikit-learn for data manipulation and machine learning model development."
N-Sh8FpaBR1RMO4lAAAAAA==,"Lead Data Science Engineer, Sportsbook","We’re defining what it means to build and deliver the most extraordinary sports and entertainment experiences. Our global team is trailblazing new markets, developing cutting-edge products, and shaping the future of responsible gaming.

Here, “impossible” isn’t part of our vocabulary. You’ll face some of the toughest but most rewarding challenges of your career. They’re worth it. Channeling your inner grit will accelerate your growth, help us win as a team, and create unforgettable moments for our customers.
The Crown Is Yours

We are looking for a Lead Data Science Engineer to join our Sportsbook Reinvestment team, where we focus on understanding and optimizing how players engage with our Online Sportsbook products over time. As a Lead Data Science Engineer, you will be responsible for building advanced models and algorithms, analyzing large-scale behavioral datasets, and driving measurable impact through experimentation and productionized solutions.

What you'll do as a Lead Data Science Engineer
• Lead end-to-end modeling projects to improve customer engagement and retention, from ideation to production deployment.
• Build, test, and optimize machine learning models to forecast user behavior, personalize promotions, and enhance Sportsbook product engagement.
• Partner with engineers, analysts, product managers, and marketers to translate insights into scalable solutions embedded within customer-facing systems.
• Mentor junior data scientists and share modeling and engineering best practices across the team.
• Clearly communicate findings and the impact of your models to stakeholders to influence product and marketing strategy.

What you'll bring
• Proven experience applying machine learning and statistical modeling to solve real-world business problems, ideally in marketing or customer lifecycle contexts.
• Experience leading and coaching other data scientists
• Strong proficiency in Python (or R) and experience working with large datasets using SQL and distributed computing platforms.
• Ability to structure and execute data science projects and deliver business value through production-ready models.
• Excellent communication and collaboration skills to work effectively across technical and non-technical teams.
• A Bachelor’s degree in a relevant field such as Computer Science, Statistics, Mathematics, or a related discipline.

Join Our Team

We’re a publicly traded (NASDAQ: DKNG) technology company headquartered in Boston. As a regulated gaming company, you may be required to obtain a gaming license issued by the appropriate state agency as a condition of employment. Don’t worry, we’ll guide you through the process if this is relevant to your role.
The US base salary range for this full-time position is 140,800.00 USD - 176,000.00 USD, plus bonus, equity, and benefits as applicable. Our ranges are determined by role, level, and location. The compensation information displayed on each job posting reflects the range for new hire pay rates for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific pay range and how that was determined during the hiring process. It is unlawful in Massachusetts to require or administer a lie detector test as a condition of employment or continued employment. An employer who violates this law shall be subject to criminal penalties and civil liability.",2025-07-17T00:00:00.000Z,2025-07-25,"['Proven experience applying machine learning and statistical modeling to solve real-world business problems, ideally in marketing or customer lifecycle contexts', 'Experience leading and coaching other data scientists', 'Strong proficiency in Python (or R) and experience working with large datasets using SQL and distributed computing platforms', 'Ability to structure and execute data science projects and deliver business value through production-ready models', 'Excellent communication and collaboration skills to work effectively across technical and non-technical teams', 'A Bachelor’s degree in a relevant field such as Computer Science, Statistics, Mathematics, or a related discipline']","['As a Lead Data Science Engineer, you will be responsible for building advanced models and algorithms, analyzing large-scale behavioral datasets, and driving measurable impact through experimentation and productionized solutions', ""What you'll do as a Lead Data Science Engineer"", 'Lead end-to-end modeling projects to improve customer engagement and retention, from ideation to production deployment', 'Build, test, and optimize machine learning models to forecast user behavior, personalize promotions, and enhance Sportsbook product engagement', 'Partner with engineers, analysts, product managers, and marketers to translate insights into scalable solutions embedded within customer-facing systems', 'Mentor junior data scientists and share modeling and engineering best practices across the team', 'Clearly communicate findings and the impact of your models to stakeholders to influence product and marketing strategy']",True,[],,"['Machine Learning', 'Statistical Modeling', 'Python', 'R', 'SQL', 'Distributed Computing Platforms', 'Data Science Project Lifecycle', 'Experimentation']","Machine Learning: Used to build, test, and optimize models forecasting user behavior and personalizing promotions to enhance product engagement.; Statistical Modeling: Applied to solve real-world business problems related to marketing and customer lifecycle.; Python: Primary programming language used for data science tasks and model development.; R: Alternative programming language for statistical analysis and modeling.; SQL: Used to query and manage large datasets essential for behavioral data analysis.; Distributed Computing Platforms: Employed to handle and process large-scale behavioral datasets efficiently.; Data Science Project Lifecycle: Involves structuring and executing end-to-end modeling projects from ideation to production deployment.; Experimentation: Used to validate models and measure their impact on customer engagement and retention."
4Pz9OfKNaMqqstSAAAAAAA==,Data Scientist,"Job Description:

Some things you can expect to do:
• Analyze structured and unstructured project data (e.g., scheduling information, safety reports, IoT sensor data) to identify trends, risks, and operational opportunities.
• Assist in the development, training, and validation of predictive models that support safety forecasting, scheduling optimization, and project risk analysis.
• Support data preparation, feature engineering, and the evaluation of model performance using tools such as pandas, scikit-learn, or XGBoost.
• Help translate machine learning outputs into actionable insights for construction and safety teams.
• Assist in the integration of predictive analytics into dashboards and field tools used by project managers and jobsite personnel.
• Collaborate with stakeholders to ensure analytics align with operational realities and business priorities.
• Work closely with the Lead Data Scientist to refine approaches, troubleshoot issues, and enhance modeling workflows.
• Participate in agile development practices and contribute to cross-functional analytics sprints.
• Communicate results and recommendations clearly to both technical and non-technical audiences, gaining exposure to real-time decision-making in the field.

To be successful in this role you must have:
• Bachelor's degree in Data Science, Statistics, Engineering, Computer Science, or a related field.
• 1-2 years of professional or academic experience applying data science methods to real-world problems.
• Proficiency in Python and SQL, with familiarity using tools such as pandas, scikit-learn, matplotlib, or XGBoost.
• Ability to work independently in a field-based environment and communicate effectively with multidisciplinary teams.
• Strong problem-solving skills, curiosity, and eagerness to learn new technologies and business processes.
• Exposure to construction or engineering project data (e.g., schedules, jobsite safety systems, field logs).
• Familiarity with cloud data platforms such as Azure, AWS, or GCP, and experience using MLflow or Databricks.
• Interest in predictive analytics and its application to safety, planning, and operational efficiency.
• Experience working with or integrating data into enterprise systems such as Procore, Power BI, or other project management tools.

Compensation:

The base pay range is $74,100-$111,100/Annually. The salary may vary within the anticipated range based on factors such as the ultimate location of the position and the selected candidate's knowledge, skills, and abilities. Position may be eligible for additional compensation that may include commission and/or an incentive program.

Eligibility:
• Positions require verification of employment eligibility to work in the U.S.

Ryan Companies is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.

Ryan Companies is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.

Non-Solicitation Notice to Recruitment Agencies:

Ryan Companies kindly requests that recruitment agencies and third-party recruiters do not submit unsolicited resumes or candidate information to any Ryan Companies employee or office. Ryan Companies will not be responsible for any fees or expenses associated with unsolicited submissions. If recruitment services are required, we will reach out directly to agencies on our approved vendor list. We appreciate your understanding and cooperation.

Ryan Companies US, Inc. is an equal opportunity and affirmative action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected Veteran status, age, or any other characteristic protected by law.

For information about your rights under Equal Employment Opportunity, https://www.dol.gov/agencies/ofccp/posters",,2025-07-25,"[""Bachelor's degree in Data Science, Statistics, Engineering, Computer Science, or a related field"", '1-2 years of professional or academic experience applying data science methods to real-world problems', 'Proficiency in Python and SQL, with familiarity using tools such as pandas, scikit-learn, matplotlib, or XGBoost', 'Ability to work independently in a field-based environment and communicate effectively with multidisciplinary teams', 'Strong problem-solving skills, curiosity, and eagerness to learn new technologies and business processes', 'Exposure to construction or engineering project data (e.g., schedules, jobsite safety systems, field logs)', 'Familiarity with cloud data platforms such as Azure, AWS, or GCP, and experience using MLflow or Databricks', 'Interest in predictive analytics and its application to safety, planning, and operational efficiency', 'Experience working with or integrating data into enterprise systems such as Procore, Power BI, or other project management tools', 'Positions require verification of employment eligibility to work in the U.S']","['Analyze structured and unstructured project data (e.g., scheduling information, safety reports, IoT sensor data) to identify trends, risks, and operational opportunities', 'Assist in the development, training, and validation of predictive models that support safety forecasting, scheduling optimization, and project risk analysis', 'Support data preparation, feature engineering, and the evaluation of model performance using tools such as pandas, scikit-learn, or XGBoost', 'Help translate machine learning outputs into actionable insights for construction and safety teams', 'Assist in the integration of predictive analytics into dashboards and field tools used by project managers and jobsite personnel', 'Collaborate with stakeholders to ensure analytics align with operational realities and business priorities', 'Work closely with the Lead Data Scientist to refine approaches, troubleshoot issues, and enhance modeling workflows', 'Participate in agile development practices and contribute to cross-functional analytics sprints', 'Communicate results and recommendations clearly to both technical and non-technical audiences, gaining exposure to real-time decision-making in the field']",True,[],,"['Predictive Modeling', 'Feature Engineering', 'Pandas', 'Scikit-learn', 'XGBoost', 'SQL', 'Matplotlib', 'Machine Learning', 'Data Integration', 'Cloud Data Platforms', 'MLflow', 'Databricks', 'Power BI', 'Data Analysis']","Predictive Modeling: Developing, training, and validating models to forecast safety, optimize scheduling, and analyze project risks.; Feature Engineering: Preparing and transforming project data to improve model performance.; Pandas: Used for data manipulation and analysis of structured and unstructured project data.; Scikit-learn: Applied for building and evaluating machine learning models in safety forecasting and scheduling optimization.; XGBoost: Utilized as a machine learning algorithm to enhance predictive model accuracy.; SQL: Used for querying and managing structured project data.; Matplotlib: Employed for visualizing data trends and model results to support decision-making.; Machine Learning: Applied to generate actionable insights from project data for construction and safety teams.; Data Integration: Incorporating predictive analytics into dashboards and field tools for project managers and jobsite personnel.; Cloud Data Platforms: Familiarity with Azure, AWS, or GCP for managing and processing project data.; MLflow: Used for managing the machine learning lifecycle including experiment tracking and model deployment.; Databricks: Platform used for collaborative data engineering and machine learning workflows.; Power BI: Business intelligence tool used to create dashboards integrating predictive analytics.; Data Analysis: Analyzing structured and unstructured data such as scheduling information, safety reports, and IoT sensor data to identify trends and risks."
FG8ZsaZcqiRRb7AZAAAAAA==,"Sr. Manager, Data Science & Analytics","Carrier Global Corporation, a global leader in intelligent climate and energy solutions, is committed to creating solutions that matter for people and our planet for generations to come. From the beginning, we've led in inventing new technologies and entirely new industries. Today, we continue to lead because we have a world-class, diverse workforce that puts the customer at the center of everything we do. For more information, visit corporate.carrier.com or follow Carrier on social media at @Carrier.

Role Purpose:

The successful candidate will have ownership of driving critical initiatives for analytics and data products, interfacing with our leadership team to align priorities, while providing guidance to the internal teams on analytics strategy and delivery. Additionally, the candidate will deliver end-to-end data and analytics solutions that will scale and empower our users to deliver on Carriers goals and mission.

Ideal Candidate will be within a commutable distance of Carrier's office in Palm Beach Gardens, FL or Carrier's office in Atlanta, GA.

Role Responsibilities:
• Define, develop, and maintain the product roadmap for analytics data products in alignment with business goals.
• Collaborate with stakeholders to gather requirements, define use cases, and prioritize features to maximize value.
• Act as a liaison between business and technical teams, translating business needs into technical solutions.
• Work closely with data engineers, data scientists, and BI developers to ensure accurate implementation of analytics solutions.
• Drive the integration of data analytics solutions into business processes, ensuring scalability and reliability.
• Monitor and evaluate product performance using KPIs, user feedback, and business impact metrics.
• Own the backlog for analytics and data-related products, ensuring that user stories are well-defined, prioritized, and executed efficiently.

Basic Qualifications:
• Bachelors Degree
• 7+ years of experience in analytics, data, statistics, Machine Learning, and/or AI delivery roles

Preferred Qualifications:
• Experience working with cloud-based data platforms such as AWS, Snowflake.
• Proficiency in data visualization tools (ex. Power BI) and SQL.
• Experience at large companies with complex data landscapes and scale.
• Experience delivering scalable analytics solutions, ideation through deployment.
• Experience leading teams and managing individual contributors.
• Data warehousing and data lake experience.
• Strong background in enterprise data and technology principles and best practices.

#LI-Onsite

RSRCAR

Carrier is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or veteran status, or any other applicable state or federal protected class. Carrier provides affirmative action in employment for qualified Individuals with a Disability and Protected Veterans in compliance with Section 503 of the Rehabilitation Act and the Vietnam Era Veterans' Readjustment Assistance Act.

Job Applicant's Privacy Notice:

Click on this link to read the Job Applicant's Privacy Notice",,2025-07-25,"['Bachelors Degree', '7+ years of experience in analytics, data, statistics, Machine Learning, and/or AI delivery roles', 'Power BI) and SQL', 'Experience at large companies with complex data landscapes and scale', 'Experience delivering scalable analytics solutions, ideation through deployment', 'Experience leading teams and managing individual contributors', 'Data warehousing and data lake experience', 'Strong background in enterprise data and technology principles and best practices']","['The successful candidate will have ownership of driving critical initiatives for analytics and data products, interfacing with our leadership team to align priorities, while providing guidance to the internal teams on analytics strategy and delivery', 'Additionally, the candidate will deliver end-to-end data and analytics solutions that will scale and empower our users to deliver on Carriers goals and mission', 'Define, develop, and maintain the product roadmap for analytics data products in alignment with business goals', 'Collaborate with stakeholders to gather requirements, define use cases, and prioritize features to maximize value', 'Act as a liaison between business and technical teams, translating business needs into technical solutions', 'Work closely with data engineers, data scientists, and BI developers to ensure accurate implementation of analytics solutions', 'Drive the integration of data analytics solutions into business processes, ensuring scalability and reliability', 'Monitor and evaluate product performance using KPIs, user feedback, and business impact metrics', 'Own the backlog for analytics and data-related products, ensuring that user stories are well-defined, prioritized, and executed efficiently']",True,[],,"['Analytics Data Products', 'Machine Learning', 'SQL', 'Power BI', 'Data Warehousing', 'Data Lakes', 'Cloud-based Data Platforms', 'KPIs and Business Impact Metrics']","Analytics Data Products: The role involves defining and maintaining analytics data products that align with business goals to deliver scalable data solutions.; Machine Learning: Experience in machine learning is required, indicating involvement in predictive modeling and data-driven decision-making.; SQL: Proficiency in SQL is necessary for querying and managing data within relational databases.; Power BI: Use of Power BI for data visualization and creating business intelligence dashboards to support analytics solutions.; Data Warehousing: Experience with data warehousing is important for managing large-scale structured data storage and retrieval.; Data Lakes: Experience with data lakes indicates handling large volumes of raw data in various formats for analytics purposes.; Cloud-based Data Platforms: Familiarity with cloud platforms like AWS and Snowflake for scalable data storage, processing, and analytics.; KPIs and Business Impact Metrics: Monitoring and evaluating product performance using key performance indicators and business impact metrics."
WrkVYutY_Bn1TmQrAAAAAA==,"Senior Analyst, Data Science (Audience Solutions Group)","Company description

Zenith is a full-service media agency with capabilities and expertise across all channels and disciplines. Zenith is part of Publicis Media, the #1 media buying network in the Americas and #2 globally. As “The ROI Agency,” Zenith’s expertise lies in driving real, tangible business outcomes, not just media metrics, that will have a measurable effect on our clients’ business. Every investment we make has an ROI mindset—not just for our clients, but for our agency at large. We’re focused on driving the maximum value for our people, our capabilities and our media investments for some of the world’s leading brands.

Overview

Working closely with both the Planning and Analytics teams, Data Sciences designs and implements statistical models and machine learning solutions that tie our clients’ marketing to real-world business goals. We use these models to understand past performance, predict future performance, and inform and optimize future decisions. Our work brings our clients closer to their marketing, helping them understand if they are talking to the right people in the right way.

We look for prior experience in media analytics, especially digital media and audiences segmentation/modeling. We hope you have a love for numbers and know how to bring data to life through a compelling story. We’re also hoping you have at least 1-2 years of experience.

Responsibilities

You will work very closely with planning, audience strategy and analytics teams to help them solve marketing problems. They also contribute crucial intellectual capital to the data science team by sharing knowledge and designing models and Data Science solutions based on their clients’ business needs and using data to tell great stories. A Senior Analyst will also help formulate a vision for their accounts and bring that vision to life. Day-to-day responsibilities include:
• Design, estimate, tune, score and maintain advanced statistical and mathematical models (e.g. classification, numeric forecasts, customer segmentation, customer propensity, attribution, etc.).
• Produce accurate statistical analysis and ensure high quality of the data analysis produced.
• Interpret, document and present/communicate analytical results to multiple business disciplines, providing conclusions and recommendations.
• Take analytical objectives and define data requirements. Extract, clean, and transform both customer level, and aggregated data for analysis, modelling, segmentation and reporting.

Qualifications
• 1+ years of work experience in quantitative analysis with proven results in leveraging customer/transaction to address business objectives
• Bachelor’s degree in a STEM or other related field, or equivalent work experience.
• Strong knowledge of Relational Databases and SQL programming.
• Highly proficient in at least one popular programming language used for Machine Learning, such as Python or R.
• Solid understanding of mathematical modeling, probability and statistics, and the design and simulation of stochastic systems.
• Familiarity with the mathematics behind important statistical learning algorithms such as ARIMA, Linear Regression, Logistic Regression, Centroid-based and Hierarchical Clustering, Principal Component Analysis (PCA), Decision Trees/Random Forest, Bayesian Inference, Markov Chain Monte-Carlo (MCMC).
• Familiarity with common advanced marketing analytics solutions such as Customer Segmentation, Marketing Mix Modeling (MMM), Multi-touch Attribution (MTA)
• Familiarity with the capabilities and mechanics of a broad range of marketing measurements and technologies such as Ad Servers, DSP, DMPs, CRMs, and Syndicated Research strongly preferred
• Strong communication skills. Ability to speak and write professionally. Ability and comfort with presenting work by phone or within small groups.

Additional information

Our Publicis Groupe motto “Viva La Différence” means we’re better together, and we believe that our differences make us stronger. It means we honor and celebrate all identities, across all facets of intersectionality, and it underpins all that we do as an organization. We are focused on fostering belonging and creating equitable & inclusive experiences for all talent.

Publicis Groupe provides robust and inclusive benefit programs and policies to support the evolving and diverse needs of our talent and enable every person to grow and thrive. Our benefits package includes medical coverage, dental, vision, disability, 401K, as well as parental and family care leave, family forming assistance, tuition reimbursement, and flexible time off.

If you require accommodation or assistance with the application or onboarding process specifically, please contact USMSTACompliance@publicis.com. All your information will be kept confidential according to EEO guidelines.

Compensation Range: $90,000 - $95,000. This is the pay range the Company believes it will pay for this position at the time of this posting. Consistent with applicable law, compensation will be determined based on the skills, qualifications, and experience of the applicant along with the requirements of the position, and the Company reserves the right to modify this pay range at any time. Temporary roles may be eligible to participate in our freelancer/temporary employee medical plan through a third-party benefits administration system once certain criteria have been met. Temporary roles may also qualify for participation in our 401(k) plan after eligibility criteria have been met. For regular roles, the Company will offer medical coverage, dental, vision, disability, 401k, and paid time off. The Company anticipates the application deadline for this job posting will be 7/15/2025.

Veterans Encouraged to Apply

#DNI",2025-07-03T00:00:00.000Z,2025-07-25,"['We look for prior experience in media analytics, especially digital media and audiences segmentation/modeling', 'We’re also hoping you have at least 1-2 years of experience', '1+ years of work experience in quantitative analysis with proven results in leveraging customer/transaction to address business objectives', 'Bachelor’s degree in a STEM or other related field, or equivalent work experience', 'Strong knowledge of Relational Databases and SQL programming', 'Highly proficient in at least one popular programming language used for Machine Learning, such as Python or R', 'Solid understanding of mathematical modeling, probability and statistics, and the design and simulation of stochastic systems', 'Familiarity with the mathematics behind important statistical learning algorithms such as ARIMA, Linear Regression, Logistic Regression, Centroid-based and Hierarchical Clustering, Principal Component Analysis (PCA), Decision Trees/Random Forest, Bayesian Inference, Markov Chain Monte-Carlo (MCMC)', 'Familiarity with common advanced marketing analytics solutions such as Customer Segmentation, Marketing Mix Modeling (MMM), Multi-touch Attribution (MTA)', 'Strong communication skills', 'Ability to speak and write professionally', 'Ability and comfort with presenting work by phone or within small groups']","['Working closely with both the Planning and Analytics teams, Data Sciences designs and implements statistical models and machine learning solutions that tie our clients’ marketing to real-world business goals', 'You will work very closely with planning, audience strategy and analytics teams to help them solve marketing problems', 'They also contribute crucial intellectual capital to the data science team by sharing knowledge and designing models and Data Science solutions based on their clients’ business needs and using data to tell great stories', 'A Senior Analyst will also help formulate a vision for their accounts and bring that vision to life', 'Design, estimate, tune, score and maintain advanced statistical and mathematical models (e.g. classification, numeric forecasts, customer segmentation, customer propensity, attribution, etc.)', 'Produce accurate statistical analysis and ensure high quality of the data analysis produced', 'Interpret, document and present/communicate analytical results to multiple business disciplines, providing conclusions and recommendations', 'Take analytical objectives and define data requirements', 'Extract, clean, and transform both customer level, and aggregated data for analysis, modelling, segmentation and reporting']",True,[],,"['Classification', 'Numeric Forecasting', 'Customer Segmentation', 'Customer Propensity Modeling', 'Attribution Modeling', 'SQL', 'Python', 'R', 'Mathematical Modeling', 'Probability and Statistics', 'Stochastic Systems Simulation', 'ARIMA', 'Linear Regression', 'Logistic Regression', 'Centroid-based Clustering', 'Hierarchical Clustering', 'Principal Component Analysis', 'Decision Trees', 'Random Forest', 'Bayesian Inference', 'Markov Chain Monte Carlo', 'Marketing Mix Modeling', 'Multi-touch Attribution', 'Data Extraction, Cleaning, and Transformation']","Classification: Used to design and maintain models that categorize data points, such as customer segmentation or propensity.; Numeric Forecasting: Applied to predict future performance metrics relevant to marketing and business outcomes.; Customer Segmentation: A key marketing analytics solution used to group customers based on behavior or attributes for targeted strategies.; Customer Propensity Modeling: Models designed to estimate the likelihood of customer actions, aiding marketing decision-making.; Attribution Modeling: Used to assign credit to marketing touchpoints, supporting multi-touch attribution analysis.; SQL: Essential for extracting and managing relational data required for analysis and modeling.; Python: A primary programming language used for implementing machine learning and data analysis solutions.; R: Another programming language used for statistical modeling and data analysis.; Mathematical Modeling: Fundamental for building statistical and stochastic models to understand and predict marketing outcomes.; Probability and Statistics: Core knowledge area supporting the design and interpretation of statistical learning algorithms.; Stochastic Systems Simulation: Used to model and simulate systems with inherent randomness, relevant for marketing and customer behavior analysis.; ARIMA: A time-series forecasting method applied to predict trends in marketing data.; Linear Regression: A statistical method used to model relationships between variables for predictive analytics.; Logistic Regression: Used for classification tasks such as predicting customer conversion or response.; Centroid-based Clustering: An unsupervised learning technique for grouping similar customers or data points.; Hierarchical Clustering: Another clustering method used for audience segmentation and pattern discovery.; Principal Component Analysis: A dimensionality reduction technique to simplify data while preserving variance for modeling.; Decision Trees: A model used for classification and regression tasks in marketing analytics.; Random Forest: An ensemble learning method improving prediction accuracy over single decision trees.; Bayesian Inference: A probabilistic approach used to update model predictions based on new data.; Markov Chain Monte Carlo: A simulation technique used for estimating complex probabilistic models.; Marketing Mix Modeling: An advanced analytics solution to measure the impact of marketing tactics on sales.; Multi-touch Attribution: A method to evaluate the contribution of multiple marketing channels to conversions.; Data Extraction, Cleaning, and Transformation: Processes essential for preparing customer and aggregated data for analysis and modeling."
qvzZMIg_4APWJ89BAAAAAA==,"Senior, Data Scientist","Position Summary...Design and develop scalable and efficient knowledge graph solutions to model complex relationships within our vast data sets.

Collaborate with cross-functional teams to identify and extract relevant data from various sources, ensuring data quality and integrity.

Utilize your expertise in knowledge graph construction, ontology development, and semantic reasoning to enhance data integration and analysis.

Develop algorithms and machine learning models to uncover patterns, insights, and predictive analytics within the knowledge graph.

Apply advanced statistical techniques and data visualization methods to effectively communicate complex concepts and findings to both technical and non-technical stakeholders.

Stay up-to-date with the latest advancements in knowledge graph technologies and contribute to the company's knowledge base by sharing best practices and emerging trends.

What you'll do...

Walmart employees more than 2.3 million employees worldwide, with 1.6 million associates in the U.S. Walmart hires 500,000 applicants a year to fill thousands of job profiles from engineers, designers, marketers to pilots and buyers and promotes more than 300,000 people to jobs of greater responsibility. People.AI team is responsible for developing and deploying AI/ML solutions supporting the Global People function.

About Team:
The Enterprise People Technology team supports the successful deployment and adoption of new People technology across the enterprise. As a Fortune #1 company, our work impacts millions of associates globally. We strive to continuously improve people technology and products to help managers and associates so they can focus on what matters most - supporting our customers and members. People Technology is one of the major segments of Walmart Global Techs Enterprise Business Services, which is invested in building a compact, robust organization that includes service operations and technology solutions for Finance, People, and the Associate Digital Experience.

What you'll do:
• Work in a highly collaborative environment with a multidisciplinary team.
• Work with data scientists to design, architect, and build AI/ML model and model systems.
• Work with machine learning engineers to deploy, operate, and optimize scalable solutions
• Work with product managers to design user journeys, feedback loop and analyze user telemetry.
• Create opportunities to develop yourself with an end-to-end AI/ML product experience.
• Work with a set of robust work standards to ensure we build trustworthy AI/ML solutions

What you'll bring:

Experience with statistical analysis and programming languages e.g. Python and mainstream machine learning frameworks, e.g. Tensor Flow or Py Torch.
• Expertise in building and deploying machine learning models for real-world applications.
• Experience with model evaluation, optimization, and tuning for performance improvements.
• Ability to lead end-to-end data science projects, from solution design, data collection and preprocessing to model development, validation, and deployment.
• Collaborate with domain experts to define problem statements and translate business objectives into actionable data science solutions.
• Added bonus if you have experience with Large Language Model or creation, maintenance, and utilization of knowledge graphs, working with graph databases such as Neo4j, or similar.

About Walmart Global Tech
Imagine working in an environment where one line of code can make life easier for hundreds of millions of people. Thats what we do at Walmart Global Tech. Were a team of software engineers, data scientists, cybersecurity experts and service professionals within the worlds leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.

Flexible, hybrid work:
We use a hybrid way of working that is primarily in office coupled with virtual when not onsite. Our campuses serve as a hub to enhance collaboration, bring us together for purpose and deliver on business needs. This approach helps us make quicker decisions, remove location barriers across our global team and be more flexible in our personal lives.

Benefits:
Benefits: Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.

Equal Opportunity Employer:
Walmart, Inc. is an Equal Opportunity Employer By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing unique styles, experiences, identities, ideas and opinions while being welcoming of all people.

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

‎

‎

‎
You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.

‎

For information about PTO, see https://one.walmart.com/notices.

‎

‎
Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

‎
Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

‎

For information about benefits and eligibility, see One.Walmart.

‎
The annual salary range for this position is $90,000.00-$180,000.00

‎
Additional compensation includes annual or quarterly performance bonuses.

‎
Additional compensation for certain positions may also include:

‎

‎
- Stock

‎

‎

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1- Bachelor’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years' experience in an analytics related field. Option 2- Master’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years' experience in an analytics related field. Option 3 - 5 years' experience in an analytics or related field.

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data science, machine learning, optimization models, Master’s degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.

Primary Location...

508 Sw 8Th St, Bentonville, AR 72712, United States of America",2025-07-21T00:00:00.000Z,2025-07-25,"['Experience with statistical analysis and programming languages e.g. Python and mainstream machine learning frameworks, e.g', 'Tensor Flow or Py Torch', 'Added bonus if you have experience with Large Language Model or creation, maintenance, and utilization of knowledge graphs, working with graph databases such as Neo4j, or similar', 'That means understanding, respecting and valuing unique styles, experiences, identities, ideas and opinions while being welcoming of all people', ""Option 1- Bachelor’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years' experience in an analytics related field"", ""Option 2- Master’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years' experience in an analytics related field"", ""Option 3 - 5 years' experience in an analytics or related field"", 'Data science, machine learning, optimization models, Master’s degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly', 'The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture']","['Collaborate with cross-functional teams to identify and extract relevant data from various sources, ensuring data quality and integrity', 'Utilize your expertise in knowledge graph construction, ontology development, and semantic reasoning to enhance data integration and analysis', 'Develop algorithms and machine learning models to uncover patterns, insights, and predictive analytics within the knowledge graph', 'Apply advanced statistical techniques and data visualization methods to effectively communicate complex concepts and findings to both technical and non-technical stakeholders', ""Stay up-to-date with the latest advancements in knowledge graph technologies and contribute to the company's knowledge base by sharing best practices and emerging trends"", 'Work in a highly collaborative environment with a multidisciplinary team', 'Work with data scientists to design, architect, and build AI/ML model and model systems', 'Work with machine learning engineers to deploy, operate, and optimize scalable solutions', 'Work with product managers to design user journeys, feedback loop and analyze user telemetry', 'Create opportunities to develop yourself with an end-to-end AI/ML product experience', 'Work with a set of robust work standards to ensure we build trustworthy AI/ML solutions', 'Expertise in building and deploying machine learning models for real-world applications', 'Experience with model evaluation, optimization, and tuning for performance improvements', 'Ability to lead end-to-end data science projects, from solution design, data collection and preprocessing to model development, validation, and deployment', 'Collaborate with domain experts to define problem statements and translate business objectives into actionable data science solutions']",True,"['Large Language Models', 'Deep Learning Frameworks']","Large Language Models: Experience with LLMs for advanced AI applications, including creation, maintenance, and utilization within the organization.; Deep Learning Frameworks: Using TensorFlow and PyTorch specifically for neural network-based AI model development and deployment.","['Knowledge Graph Construction', 'Ontology Development', 'Semantic Reasoning', 'Machine Learning Models', 'Statistical Analysis', 'Data Visualization', 'Python Programming', 'TensorFlow', 'PyTorch', 'Model Evaluation and Optimization', 'Data Collection and Preprocessing', 'Graph Databases', 'Data Quality and Integrity', 'Feature Engineering', 'Spark', 'Scala', 'R Programming', 'Optimization Models']","Knowledge Graph Construction: Building and maintaining knowledge graphs to model complex relationships within large datasets for enhanced data integration and analysis.; Ontology Development: Creating structured frameworks to define relationships and concepts within data to support semantic reasoning and knowledge graph accuracy.; Semantic Reasoning: Applying logic-based methods to infer new knowledge and insights from knowledge graphs and ontologies.; Machine Learning Models: Developing predictive and pattern recognition models to analyze data within knowledge graphs and other datasets.; Statistical Analysis: Using advanced statistical techniques to analyze data and communicate findings effectively to stakeholders.; Data Visualization: Employing visualization methods to present complex data insights clearly to both technical and non-technical audiences.; Python Programming: Utilizing Python as a primary programming language for data analysis, model development, and deployment.; TensorFlow: Using TensorFlow framework for building and deploying machine learning models.; PyTorch: Employing PyTorch framework for developing and optimizing machine learning models.; Model Evaluation and Optimization: Assessing and tuning machine learning models to improve performance and accuracy in real-world applications.; Data Collection and Preprocessing: Leading end-to-end data science projects including gathering and preparing data for model development.; Graph Databases: Working with graph database technologies such as Neo4j to store and query knowledge graphs.; Data Quality and Integrity: Ensuring the accuracy and reliability of data extracted from various sources for analysis.; Feature Engineering: Transforming raw data into meaningful features to improve machine learning model performance.; Spark: Using Apache Spark for large-scale data processing and analytics.; Scala: Programming in Scala for data engineering and analytics tasks.; R Programming: Applying R language for statistical analysis and data visualization.; Optimization Models: Developing mathematical models to optimize processes and decision-making based on data insights."
EcS_-mF0XtNHRfx0AAAAAA==,Insight Global,"A client in the Nashville area is looking for a strong Data Scientist that is strong in data ingesting, data cleansing, feature engineering, data filtering and aggregating, statistical estimation and hypothesis testing, machine learning and iterative development and continuous production integration and deployment. They will be supporting the clients Medicaid clients, but wrangling healthcare and other client data assets. They will be analyzing them iteratively to surface complex, impactfully actionable insights.",,2025-07-25,,"['A client in the Nashville area is looking for a strong Data Scientist that is strong in data ingesting, data cleansing, feature engineering, data filtering and aggregating, statistical estimation and hypothesis testing, machine learning and iterative development and continuous production integration and deployment', 'They will be supporting the clients Medicaid clients, but wrangling healthcare and other client data assets', 'They will be analyzing them iteratively to surface complex, impactfully actionable insights']",True,[],,"['Data Ingestion', 'Data Cleansing', 'Feature Engineering', 'Data Filtering and Aggregation', 'Statistical Estimation and Hypothesis Testing', 'Machine Learning', 'Iterative Development and Continuous Production Integration and Deployment']",Data Ingestion: Handling the process of collecting and importing healthcare and client data assets for analysis.; Data Cleansing: Cleaning healthcare and client data to ensure quality and accuracy before analysis.; Feature Engineering: Creating and transforming variables from raw healthcare data to improve model performance.; Data Filtering and Aggregation: Processing healthcare data by filtering and summarizing to prepare for analysis and modeling.; Statistical Estimation and Hypothesis Testing: Applying statistical methods to validate assumptions and derive insights from healthcare data.; Machine Learning: Developing predictive models using healthcare data to generate actionable insights.; Iterative Development and Continuous Production Integration and Deployment: Repeatedly refining models and integrating them into production systems to support Medicaid client needs.
B_2B0qIwNl6JcClEAAAAAA==,Professional Development Program (PDP) Internship - Data Science Summer 2026,"Professional Development Program (PDP) Internship - Data Science Summer 2026

The world needs solutions, and we need you! At BASF, we create chemistry through the power of connected minds. By balancing economic success with environmental protection and social responsibility, we are building a more sustainable future through chemistry. As the world’s leading chemical company, we help our customers in nearly every industry meet the current and future needs of society through science and innovation.

Join BASF for our 10 to 12-week Data Science Professional Development Program (PDP) Internship, where you'll immerse yourself in our dynamic Production, Manufacturing, Business, and Research and Development (R&D) teams. This internship offers a unique opportunity to gain hands-on experience while working on impactful projects that support our business objectives. You’ll collaborate closely with seasoned professionals, gaining insights into our data science processes and strategies.

Our internship is designed to accelerate your career growth by providing you with leadership opportunities and strategic insights critical for a successful future in data science.

We welcome applicants who are mobile-minded and open to relocation, as you may have the opportunity to be placed at any BASF site across the country. This will enhance your exposure to diverse business environments and deepen your understanding of our global operations.

Embrace this opportunity to kickstart your career at BASF, where innovation and collaboration drive our success!

Are you ready to create change?

In our Data Science program, no two days are alike. You'll engage in a dynamic environment where you'll tackle diverse challenges, collaborate with cross-functional teams, and adapt to rapidly changing situations. This role offers the opportunity to innovate and problem-solve in real-time, making every day an exciting and unique experience.

Some key areas of impact may include:
• During the PDP program, you will get the opportunity to work within various areas across the organization such as Production, Manufacturing, Business (Sales & Marketing), and Research and Development (R&D) teams.
• You will work closely with talented data scientists to gain experience with the technical and scientific aspects of plant engineering. You will work with mentors and have exposure to senior leadership through high impact initiatives.
• You will be “hands-on” and will have the opportunity to lead high value projects, to execute deliverables during all phases of an analytics project – starting from project definition to completion.
• Some of the deliverables will include the development of appropriate machine learning and optimization models, collaborating with members from other functions to gather and validate the necessary data, and presenting the project results and benefits to key stakeholders and internal clients.

Unlock Your Potential: More than Just a Job

Professional Development:

Exposure to data science applications and digital tools such as Python, R, RShinv, Dash, Flask, HTML, Git, SQL, Tableau and PowerBI, AWS, Databricks, Azure, Virtual environments and Docker containers, and many more. At the end of the internship, you will present your summer project to fellow interns, BASF employees, and senior leaders, showcasing your impact and contributions.

Mentorship

Each participant will be assigned a peer mentor for their internship. Peer mentors are full-time program participants and serve as a guide throughout the program. You will develop your expertise and the ability to network at senior levels throughout BASF and establish mentoring relationships that could span your whole career.

Networking

Interns have the opportunity to participate in Employee Resource Groups (ERGs) at their site. Successfully engaging across the business throughout your internship will expand your network, allow you to grow personally and professionally, and learn a variety of valuable skill sets. Interns will also participate in a week-long orientation during which they will have the opportunity to engage with alumni and executive leadership at our headquarters in New Jersey. Additionally, interns will collaborate with full-time P/LDP program participants to organize and participate in a community service volunteer day in celebration of National Intern Day.

Your Unique Blend: What We’re Looking For

The ideal candidate for our Professional Development Program internship at BASF is a student majoring in Data Science, Data Analytics, Applied Mathematics, Statistics, Chemical Engineering, Mechanical Engineering, or other related Engineering Majors, with a graduation date between December 2026 and July 2029.
• Candidates must have a minimum cumulative GPA of a 3.2.
• Candidates must have familiarity with tools such as Python and R programing
• Candidates must have basic knowledge of machine learning, artificial intelligence, big data, and new technologies.
• Candidates must be authorized to work in the U.S. without restrictions and be willing to relocate anywhere in the country during and after the program, as all assignments are in-person or hybrid.
• Candidates should demonstrate previous leadership experience and academic achievement, along with active participation in extracurricular activities and on-campus organizations.
• Previous internship/co-op experience is preferred.
• Candidates should have a strong interest in the manufacturing or chemical industry. Project management experience is also beneficial.

Interns will be assessed for a potential returning internship offer or full-time position in our 2-year rotational program. Mobility is crucial, with potential locations including Michigan, North Carolina, Texas, and Louisiana.

We are always working to form the best team—especially from within, with an emphasis on lifelong learning and career development!

Who We Are

BASF Corporation, headquartered in Florham Park, New Jersey, is the North American affiliate of BASF SE, Ludwigshafen, Germany. BASF has approximately 16,000 employees in North America and had sales of $19.7 billion in 2024.

At BASF, we create chemistry for a sustainable future. Our ambition: We want to be the preferred chemical company to enable our customers’ green transformation. We combine economic success with environmental protection and social responsibility. Around 112,000 employees in the BASF Group contribute to the success of our customers in nearly all sectors and almost every country in the world. Our portfolio comprises, as core businesses, the segments Chemicals, Materials, Industrial Solutions, and Nutrition & Care; our standalone businesses are bundled in the segments Surface Technologies and Agricultural Solutions.

At BASF, we are committed to creating an exceptional workplace that values diversity and prioritizes our employees' well-being and development. Our dedication has been recognized through various awards and accolades. In 2024-25, BASF received the Platinum Bell Seal for Workplace Mental Health from Mental Health America, as well as the Business Group on Health’s Best Employers: Excellence in Health & Well-being award. We were recognized by PLANSPONSOR for having a 2025 Best In Class 401(k) Plan and ranked among the Top 50 Employers by readers of Minority Engineer Magazine. Fair360 (formerly Diversity Inc) also placed us 22nd on their 2024 Top 50 Companies List. Additionally, we were named one of America's Best Large Employers and one of the World's Best Employers by Forbes and Statista. For the 11th consecutive year, we achieved a top score in the Human Rights Campaign Foundation’s Corporate Equality Index, earning the 2025 “Equality 100 Award"" as a leader in LGBTQ+ workplace inclusion.

To learn more about our programs, visit www.basf.com/universitycareers.

Privacy Statement

BASF takes security & data privacy very seriously. We will never request financial information of any kind via email, private text message or direct message on any social medial platform or job board. Furthermore, we will never send a candidate a check for equipment or request any type of payment during the job application process. If you have experienced any of the above, please contact myhr@basf.com to report fraud.

Pay Transparency

BASF is committed to pay transparency practices. The competitive Pay Range for this role is $1,907- $2,340 semi monthly. Actual pay will be determined based on education, certifications, experience, and other job-related factors permitted by law.

Equal Employment Opportunities

We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, age, citizenship, color, religion, sex, marital status, national origin, disability status, gender identity or expression, protected veteran status, or any other characteristic protected by law.

Applicants must be currently authorized to work in the United States on a full-time basis.",2025-07-22T00:00:00.000Z,2025-07-25,"['Exposure to data science applications and digital tools such as Python, R, RShinv, Dash, Flask, HTML, Git, SQL, Tableau and PowerBI, AWS, Databricks, Azure, Virtual environments and Docker containers, and many more', 'The ideal candidate for our Professional Development Program internship at BASF is a student majoring in Data Science, Data Analytics, Applied Mathematics, Statistics, Chemical Engineering, Mechanical Engineering, or other related Engineering Majors, with a graduation date between December 2026 and July 2029', 'Candidates must have a minimum cumulative GPA of a 3.2', 'Candidates must have familiarity with tools such as Python and R programing', 'Candidates must have basic knowledge of machine learning, artificial intelligence, big data, and new technologies', 'Candidates must be authorized to work in the U.S. without restrictions and be willing to relocate anywhere in the country during and after the program, as all assignments are in-person or hybrid', 'Candidates should demonstrate previous leadership experience and academic achievement, along with active participation in extracurricular activities and on-campus organizations', 'Candidates should have a strong interest in the manufacturing or chemical industry', 'Project management experience is also beneficial', 'Interns will be assessed for a potential returning internship offer or full-time position in our 2-year rotational program', 'Applicants must be currently authorized to work in the United States on a full-time basis']","['This role offers the opportunity to innovate and problem-solve in real-time, making every day an exciting and unique experience', 'During the PDP program, you will get the opportunity to work within various areas across the organization such as Production, Manufacturing, Business (Sales & Marketing), and Research and Development (R&D) teams', 'You will work closely with talented data scientists to gain experience with the technical and scientific aspects of plant engineering', 'You will work with mentors and have exposure to senior leadership through high impact initiatives', 'You will be “hands-on” and will have the opportunity to lead high value projects, to execute deliverables during all phases of an analytics project – starting from project definition to completion', 'Some of the deliverables will include the development of appropriate machine learning and optimization models, collaborating with members from other functions to gather and validate the necessary data, and presenting the project results and benefits to key stakeholders and internal clients', 'At the end of the internship, you will present your summer project to fellow interns, BASF employees, and senior leaders, showcasing your impact and contributions', 'Additionally, interns will collaborate with full-time P/LDP program participants to organize and participate in a community service volunteer day in celebration of National Intern Day']",True,[],,"['Python', 'R', 'SQL', 'Tableau', 'Power BI', 'Machine Learning', 'Optimization Models', 'Big Data', 'Git', 'Dash', 'Flask', 'HTML', 'AWS', 'Azure', 'Databricks', 'Docker', 'Data Science']","Python: Used as a primary programming language for data science applications and analytics projects during the internship.; R: Utilized for statistical analysis and data science tasks as part of the internship's technical toolkit.; SQL: Employed for data querying and management to gather and validate necessary data for analytics projects.; Tableau: Used to create business intelligence dashboards and visualizations to present project results to stakeholders.; Power BI: Another BI tool leveraged for data visualization and reporting during the internship.; Machine Learning: Applied to develop predictive and optimization models as part of high-value analytics projects.; Optimization Models: Developed to improve processes and decision-making within production, manufacturing, and business teams.; Big Data: Basic knowledge expected, indicating handling and analysis of large datasets relevant to business and manufacturing.; Git: Used for version control and collaboration on code and project deliverables.; Dash: Utilized for building interactive web-based data visualization applications.; Flask: Employed to develop lightweight web applications or APIs supporting data science projects.; HTML: Used in conjunction with Dash and Flask for building web interfaces for data visualization.; AWS: Cloud platform used for data storage, processing, or deployment of data science solutions.; Azure: Cloud service platform leveraged for data science and analytics workloads.; Databricks: Platform used for big data analytics and collaborative data science projects.; Docker: Used to create virtual environments and containerize applications for consistent deployment.; Data Science: Core focus of the internship involving data analysis, modeling, and problem-solving across business functions."
LSw3Xmtkv-uhV02OAAAAAA==,Data Scientist  II  - Graph Data Platform - Client Protection,"Job Description:

At Bank of America, we are guided by a common purpose to help make financial lives better through the power of every connection. We do this by driving Responsible Growth and delivering for our clients, teammates, communities and shareholders every day.

Being a Great Place to Work is core to how we drive Responsible Growth. This includes our commitment to being an inclusive workplace, attracting and developing exceptional talent, supporting our teammates physical, emotional, and financial wellness, recognizing and rewarding performance, and how we make an impact in the communities we serve.

Bank of America is committed to an in-office culture with specific requirements for office-based attendance and which allows for an appropriate level of flexibility for our teammates and businesses based on role-specific considerations.

At Bank of America, you can build a successful career with opportunities to learn, grow, and make an impact. Join us!

Job Summary

This job is responsible for reviewing and interpretating large datasets to uncover revenue generation opportunities and ensuring the development of effective risk management strategies. Key responsibilities include working with lines of business to comprehend problems, utilizing sophisticated analytics and deploying advanced techniques to devise solutions, and presenting recommendations based on findings. Job expectations include demonstrating leadership, resilience, accountability, a disciplined approach, and a commitment to fostering responsible growth for the enterprise.

This job is responsible for supporting advanced analytics technical development and the pathway to optimality, scalability, and sustainability in close partnership with Bank of America Technology. This work closely integrates with business efforts to improve portfolio risk, profitability, performance forecasting, and operational performance for customer products and related divisions such as credit cards. Key responsibilities include applying knowledge of multiple business and technical-related topics and independently driving strategic improvements, large-scale projects, and initiatives. Job expectations include working with counterparts within the Line of Business, across the technology organization, and risk teams.

Client Protection Shared Services Advanced Analytics is looking for a seasoned and energetic data science leader to join our team as a Lead Data Scientist and help us deliver data science products to the production environment especially for scalable graph analytics. In this role, you will be expected to work on large and complex data science projects. Collaborating with internal strategy, technology, product, and policy partners to deploy advanced analytical solutions with the goal of reducing fraud losses, lowering false positive impacts, improving client experience, and ensuring the Bank minimizes its total cost of fraud.

Responsibilities:
• Enables business analytics, including data analysis, trend identification, and pattern recognition, using advanced techniques to drive decision making and collection data driven insights
• Applies agile practices for project management, solution development, deployment, and maintenance
• Develops and reviews technical documentation, capturing the business requirements, and specifications related to the developed analytical solution and implementation in production
• Manages multiple priorities and ensures quality and timeliness of work deliverables such as quantitative models, data science products, data analysis reports, or data visualizations, while exhibiting the ability to work independently and in a team environment
• Delivers presentations in an engaging and effective manner through in-person and virtual conversations that communicates technical concepts and analysis results to a diverse set of internal stakeholders, and develops professional relationships to foster collaboration on work deliverables
• Supports the identification of potential issues and development of controls
• Maintains knowledge of the latest advances in the fields of data science and artificial intelligence to support business analytics
• Manages a roadmap of data science use cases for technical development and implementation to the production environment in close partnership with Bank of America Technology
• Manages relationships with multiple technology platform and development team leaders including alignment of roadmaps, managing projects, and managing risks
• Engages business and technology senior leaders on reporting of project/deliverable statuses, opportunity identification, and planning efforts
• Oversees development, delivery and quality assurance for data science use cases delivered to the production environment and other areas of the line of business
• Performs complex analysis of financial models, market data, financial data, and portfolio trends to understand product performance and improve portfolio risk, profitability, performance forecasting, and operational performance
• Coaches and mentors peers to improve proficiency in a variety of systems and serves as a subject matter expert on multiple business and technical-related topics
• Identifies business trends based on economic and portfolio conditions and communicates findings to senior management
• Supports execution of large scale projects, such as platform conversions or new project integrations by conducting advanced reporting and drawing analytics based insights
• Link Analysis/Graph analytics to find and mitigate densely connected fraud networks
• Developing and tuning graph algorithms to maximize detection of fraud
• Assist with the generation, prioritization, and investigation of fraud rings

Required Qualifications

Minimum of 4 years of experience in data and analytics

Must have familiarity with Graph databases (e.g. TigerGraph, Neo4J) and graph query languages

Must be proficient with SQL and one of SAS, Python, or Java

Critical problem-solving skills including selection of data and deployment of solutions

Proven ability to manage projects, exercise thought leadership and work with limited direction on complex problems to achieve project goals while also leading a broader team

Excellent communication and influencing skills

Thrives in fast-paced and highly dynamic environment

Intellectual curiosity and strong urge to figure out the whys of a problem and come up with creative solutions

Expertise handling data across its lifecycle in a variety of formats and storage technologies (e.g., structured, semi-structured, unstructured; graph; hadoop; kafka)

Expertise in data analytics and technical development lifecycles including having coached junior staff

Desired Qualifications

Advanced STEM (Science, Technology, Engineering, Math) degree (Masters or PhD)

7+ years of experience; work in financial services is very helpful, with preference to fraud, credit, cybersecurity, or other heavily quantitative areas

Deep understanding of graph databases, graph algorithms, and experience developing graph schemas

Understanding of advanced machine learning methodologies including neural networks, ensemble learning like XGB, and other techniques

Proficient with H2O or similar advanced analytical tools

Experience managing multi-year roadmaps, engaging technical and non-technical stakeholders, and leading large cross-functional formal projects

Experience influencing mid to senior (executive) level leaders

Experience managing risk and issue remediation

Understanding of computer science topics like automation, code versioning, computational complexity, parallel processing, requirements gathering, testing methodologies, and development lifecycle models like Agile

Skills:
• Agile Practices
• Application Development
• DevOps Practices
• Technical Documentation
• Written Communications
• Artificial Intelligence/Machine Learning
• Business Analytics
• Data Visualization
• Presentation Skills
• Risk Management
• Adaptability
• Collaboration
• Consulting
• Networking
• Policies, Procedures, and Guidelines Management

Shift:
1st shift (United States of America)

Hours Per Week:
40

Pay Transparency details

US - IL - Chicago - 110 N Wacker Dr - Bank Of America Tower Chicago (IL4110), US - NY - New York - 1114 Avenue Of The Americas - Grace (NY1544)

Pay and benefits information

Pay range

$165,000.00 - $246,200.00 annualized salary, offers to be determined based on experience, education and skill set.

Discretionary incentive eligible

This role is eligible to participate in the annual discretionary plan. Employees are eligible for an annual discretionary award based on their overall individual performance results and behaviors, the performance and contributions of their line of business and/or group; and the overall success of the Company.

Benefits

This role is currently benefits eligible. We provide industry-leading benefits, access to paid time off, resources and support to our employees so they can make a genuine impact and contribute to the sustainable growth of our business and the communities we serve.",2025-07-07T00:00:00.000Z,2025-07-25,"['Minimum of 4 years of experience in data and analytics', 'Must have familiarity with Graph databases (e.g. TigerGraph, Neo4J) and graph query languages', 'Must be proficient with SQL and one of SAS, Python, or Java', 'Critical problem-solving skills including selection of data and deployment of solutions', 'Proven ability to manage projects, exercise thought leadership and work with limited direction on complex problems to achieve project goals while also leading a broader team', 'Excellent communication and influencing skills', 'Thrives in fast-paced and highly dynamic environment', 'Intellectual curiosity and strong urge to figure out the whys of a problem and come up with creative solutions', 'Expertise handling data across its lifecycle in a variety of formats and storage technologies (e.g., structured, semi-structured, unstructured; graph; hadoop; kafka)', 'Expertise in data analytics and technical development lifecycles including having coached junior staff', 'Advanced STEM (Science, Technology, Engineering, Math) degree (Masters or PhD)', '7+ years of experience; work in financial services is very helpful, with preference to fraud, credit, cybersecurity, or other heavily quantitative areas', 'Deep understanding of graph databases, graph algorithms, and experience developing graph schemas', 'Understanding of advanced machine learning methodologies including neural networks, ensemble learning like XGB, and other techniques', 'Proficient with H2O or similar advanced analytical tools', 'Experience managing multi-year roadmaps, engaging technical and non-technical stakeholders, and leading large cross-functional formal projects', 'Experience influencing mid to senior (executive) level leaders', 'Experience managing risk and issue remediation', 'Understanding of computer science topics like automation, code versioning, computational complexity, parallel processing, requirements gathering, testing methodologies, and development lifecycle models like Agile', 'Agile Practices', 'Application Development', 'Technical Documentation', 'Written Communications', 'Artificial Intelligence/Machine Learning', 'Business Analytics', 'Data Visualization', 'Presentation Skills', 'Risk Management', 'Adaptability', 'Collaboration', 'Consulting', 'Networking', 'Policies, Procedures, and Guidelines Management']","['This job is responsible for reviewing and interpretating large datasets to uncover revenue generation opportunities and ensuring the development of effective risk management strategies', 'Key responsibilities include working with lines of business to comprehend problems, utilizing sophisticated analytics and deploying advanced techniques to devise solutions, and presenting recommendations based on findings', 'Job expectations include demonstrating leadership, resilience, accountability, a disciplined approach, and a commitment to fostering responsible growth for the enterprise', 'This job is responsible for supporting advanced analytics technical development and the pathway to optimality, scalability, and sustainability in close partnership with Bank of America Technology', 'This work closely integrates with business efforts to improve portfolio risk, profitability, performance forecasting, and operational performance for customer products and related divisions such as credit cards', 'Key responsibilities include applying knowledge of multiple business and technical-related topics and independently driving strategic improvements, large-scale projects, and initiatives', 'Job expectations include working with counterparts within the Line of Business, across the technology organization, and risk teams', 'Client Protection Shared Services Advanced Analytics is looking for a seasoned and energetic data science leader to join our team as a Lead Data Scientist and help us deliver data science products to the production environment especially for scalable graph analytics', 'In this role, you will be expected to work on large and complex data science projects', 'Collaborating with internal strategy, technology, product, and policy partners to deploy advanced analytical solutions with the goal of reducing fraud losses, lowering false positive impacts, improving client experience, and ensuring the Bank minimizes its total cost of fraud', 'Enables business analytics, including data analysis, trend identification, and pattern recognition, using advanced techniques to drive decision making and collection data driven insights', 'Applies agile practices for project management, solution development, deployment, and maintenance', 'Develops and reviews technical documentation, capturing the business requirements, and specifications related to the developed analytical solution and implementation in production', 'Manages multiple priorities and ensures quality and timeliness of work deliverables such as quantitative models, data science products, data analysis reports, or data visualizations, while exhibiting the ability to work independently and in a team environment', 'Delivers presentations in an engaging and effective manner through in-person and virtual conversations that communicates technical concepts and analysis results to a diverse set of internal stakeholders, and develops professional relationships to foster collaboration on work deliverables', 'Supports the identification of potential issues and development of controls', 'Maintains knowledge of the latest advances in the fields of data science and artificial intelligence to support business analytics', 'Manages a roadmap of data science use cases for technical development and implementation to the production environment in close partnership with Bank of America Technology', 'Manages relationships with multiple technology platform and development team leaders including alignment of roadmaps, managing projects, and managing risks', 'Engages business and technology senior leaders on reporting of project/deliverable statuses, opportunity identification, and planning efforts', 'Oversees development, delivery and quality assurance for data science use cases delivered to the production environment and other areas of the line of business', 'Performs complex analysis of financial models, market data, financial data, and portfolio trends to understand product performance and improve portfolio risk, profitability, performance forecasting, and operational performance', 'Coaches and mentors peers to improve proficiency in a variety of systems and serves as a subject matter expert on multiple business and technical-related topics', 'Identifies business trends based on economic and portfolio conditions and communicates findings to senior management', 'Supports execution of large scale projects, such as platform conversions or new project integrations by conducting advanced reporting and drawing analytics based insights', 'Link Analysis/Graph analytics to find and mitigate densely connected fraud networks', 'Developing and tuning graph algorithms to maximize detection of fraud', 'Assist with the generation, prioritization, and investigation of fraud rings', 'DevOps Practices']",True,[],,"['Graph Databases', 'Graph Algorithms', 'SQL', 'Python', 'SAS', 'Java', 'Hadoop', 'Kafka', 'Advanced Machine Learning', 'XGBoost', 'H2O', 'Data Visualization', 'Business Analytics', 'Quantitative Models', 'Link Analysis', 'Agile Practices', 'DevOps Practices']","Graph Databases: Used for storing and querying complex relationships in data, essential for scalable graph analytics and fraud network detection.; Graph Algorithms: Developed and tuned to maximize fraud detection by analyzing densely connected fraud networks.; SQL: Proficiency required for querying structured data to support data analysis and model development.; Python: Used as a programming language for data analysis, model development, and deployment.; SAS: One of the analytical tools used for statistical analysis and data modeling.; Java: Programming language used for application development and integration of data science solutions.; Hadoop: Technology for handling large-scale structured and unstructured data across its lifecycle.; Kafka: Used for managing real-time data streams and integration in data pipelines.; Advanced Machine Learning: Includes methodologies like neural networks and ensemble learning (e.g., XGBoost) applied to improve fraud detection and risk management.; XGBoost: An ensemble learning technique used for predictive modeling and improving fraud detection accuracy.; H2O: An advanced analytical tool used for building and deploying machine learning models.; Data Visualization: Used to create reports and dashboards that communicate analysis results to stakeholders.; Business Analytics: Applied to identify trends, patterns, and insights that drive decision making and risk mitigation.; Quantitative Models: Developed to forecast performance, manage portfolio risk, and improve profitability.; Link Analysis: A graph analytics technique used to detect and mitigate fraud rings by analyzing relationships.; Agile Practices: Applied for project management, solution development, deployment, and maintenance of data science products.; DevOps Practices: Used to support continuous integration and deployment of data science solutions."
1JXbwdk4P2mIYU2kAAAAAA==,CTIO-Data Scientist-Sr Associate,"At PwC, our people in data and analytics engineering focus on leveraging advanced technologies and techniques to design and develop robust data solutions for clients. They play a crucial role in transforming raw data into actionable insights, enabling informed decision-making and driving business growth. Those in data science and machine learning engineering at PwC will focus on leveraging advanced analytics and machine learning techniques to extract insights from large datasets and drive data-driven decision making. You will work on developing predictive models, conducting statistical analysis, and creating data visualisations to solve complex business problems.

Focused on relationships, you are building meaningful client connections, and learning how to manage and inspire others. Navigating increasingly complex situations, you are growing your personal brand, deepening technical expertise and awareness of your strengths. You are expected to anticipate the needs of your teams and clients, and to deliver quality. Embracing increased ambiguity, you are comfortable when the path forward isn’t clear, you ask questions, and you use these moments as opportunities to grow.

Examples of the skills, knowledge, and experiences you need to lead and deliver value at this level include but are not limited to:
• Respond effectively to the diverse perspectives, needs, and feelings of others.
• Use a broad range of tools, methodologies and techniques to generate new ideas and solve problems.
• Use critical thinking to break down complex concepts.
• Understand the broader objectives of your project or role and how your work fits into the overall strategy.
• Develop a deeper understanding of the business context and how it is changing.
• Use reflection to develop self awareness, enhance strengths and address development areas.
• Interpret data to inform insights and recommendations.
• Uphold and reinforce professional and technical standards (e.g. refer to specific PwC tax and audit guidance), the Firm's code of conduct, and independence requirements.

The Opportunity

As part of the Data Science and Machine Learning Engineering team you will design and develop AI/ML systems that transform client operations. As a Senior Associate, you will lead projects from conception to production, mentoring others while engaging clients to align technology with business objectives. This role allows you to stay at the forefront of AI advancements and contribute to innovative solutions that drive business success.

Responsibilities
• Conduct experiments to validate and refine models
• Stay abreast of advancements in AI and machine learning
• Work with diverse teams to foster innovation
• Translate technical models into scalable business solutions

What You Must Have
• Bachelor's Degree
• 3 years of experience

What Sets You Apart
• Demonstrating leadership in team environments
• Communicating technical concepts to diverse audiences
• Building and deploying machine learning systems
• Programming proficiency in Python
• Working with AI frameworks like Pytorch and Tensorflow
• Familiarity with MLOps and deployment tools
• Understanding generative AI model development
• Managing time effectively under deadlines
• Passion for continuous learning and knowledge acquisition

Learn more about how we work: https://pwc.to/how-we-work

PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.

As PwC is an equal opportunity employer, all qualified applicants will receive consideration for employment at PwC without regard to race; color; religion; national origin; sex (including pregnancy, sexual orientation, and gender identity); age; disability; genetic information (including family medical history); veteran, marital, or citizenship status; or, any other status protected by law.

For only those qualified applicants that are impacted by the Los Angeles County Fair Chance Ordinance for Employers, the Los Angeles' Fair Chance Initiative for Hiring Ordinance, the San Francisco Fair Chance Ordinance, San Diego County Fair Chance Ordinance, and the California Fair Chance Act, where applicable, arrest or conviction records will be considered for Employment in accordance with these laws. At PwC, we recognize that conviction records may have a direct, adverse, and negative relationship to responsibilities such as accessing sensitive company or customer information, handling proprietary assets, or collaborating closely with team members. We evaluate these factors thoughtfully to establish a secure and trusted workplace for all.

Applications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https://pwc.to/us-application-deadlines

The salary range for this position is: $55,000 - $187,000, plus individuals may be eligible for an annual discretionary bonus. For roles that are based in Maryland, this is the listed salary range for this position. Actual compensation within the range will be dependent upon the individual's skills, experience, qualifications and location, and applicable employment laws. PwC offers a wide range of benefits, including medical, dental, vision, 401k, holiday pay, vacation, personal and family sick leave, and more. To view our benefits at a glance, please visit the following link: https://pwc.to/benefits-at-a-glance",2025-07-23T00:00:00.000Z,2025-07-25,"[""Bachelor's Degree"", '3 years of experience', 'Demonstrating leadership in team environments', 'Communicating technical concepts to diverse audiences', 'Building and deploying machine learning systems', 'Programming proficiency in Python', 'Working with AI frameworks like Pytorch and Tensorflow', 'Familiarity with MLOps and deployment tools', 'Understanding generative AI model development', 'Managing time effectively under deadlines', 'Passion for continuous learning and knowledge acquisition']","['They play a crucial role in transforming raw data into actionable insights, enabling informed decision-making and driving business growth', 'Those in data science and machine learning engineering at PwC will focus on leveraging advanced analytics and machine learning techniques to extract insights from large datasets and drive data-driven decision making', 'You will work on developing predictive models, conducting statistical analysis, and creating data visualisations to solve complex business problems', 'Focused on relationships, you are building meaningful client connections, and learning how to manage and inspire others', 'Navigating increasingly complex situations, you are growing your personal brand, deepening technical expertise and awareness of your strengths', 'You are expected to anticipate the needs of your teams and clients, and to deliver quality', 'Respond effectively to the diverse perspectives, needs, and feelings of others', 'Use a broad range of tools, methodologies and techniques to generate new ideas and solve problems', 'Use critical thinking to break down complex concepts', 'Understand the broader objectives of your project or role and how your work fits into the overall strategy', 'Develop a deeper understanding of the business context and how it is changing', 'Use reflection to develop self awareness, enhance strengths and address development areas', 'Interpret data to inform insights and recommendations', ""Uphold and reinforce professional and technical standards (e.g. refer to specific PwC tax and audit guidance), the Firm's code of conduct, and independence requirements"", 'As part of the Data Science and Machine Learning Engineering team you will design and develop AI/ML systems that transform client operations', 'As a Senior Associate, you will lead projects from conception to production, mentoring others while engaging clients to align technology with business objectives', 'This role allows you to stay at the forefront of AI advancements and contribute to innovative solutions that drive business success', 'Conduct experiments to validate and refine models', 'Stay abreast of advancements in AI and machine learning', 'Work with diverse teams to foster innovation', 'Translate technical models into scalable business solutions']",True,"['PyTorch', 'TensorFlow', 'Generative AI Model Development']","PyTorch: Utilizing PyTorch framework for developing AI models, particularly deep learning neural networks.; TensorFlow: Employing TensorFlow framework to build and deploy AI and deep learning models.; Generative AI Model Development: Understanding and working on the development of generative AI models to create innovative AI solutions.","['Predictive Modeling', 'Statistical Analysis', 'Data Visualization', 'Machine Learning', 'Python Programming', 'MLOps']",Predictive Modeling: Developing models to forecast outcomes and support data-driven decision making for business problems.; Statistical Analysis: Conducting statistical methods to interpret data and extract actionable insights.; Data Visualization: Creating visual representations of data to communicate complex information effectively.; Machine Learning: Building and deploying machine learning systems to analyze large datasets and generate insights.; Python Programming: Using Python as the primary programming language for data science and machine learning tasks.; MLOps: Applying machine learning operations and deployment tools to manage and scale ML systems.
qt8_DrqpgWG4SnphAAAAAA==,"Manager, Data Scientist","About the position

Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making. As a Data Scientist at Capital One, you'll be part of a team that's leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives. Team Description- The Fraud Intelligence team builds the machine learning models that help protect our customers from fraudsters. We build, maintain, and manage models using a tech stack of Python, Spark, and Kubernetes.

Responsibilities
• Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love
,
• Leverage a broad stack of technologies - Python, Conda, AWS, H2O, Spark, and more - to reveal the insights hidden within huge volumes of numeric and textual data
,
• Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation
,
• Flex your interpersonal skills to translate the complexity of your work into tangible business goals

Requirements
• Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date: A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 6 years of experience performing data analytics
,
• A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 4 years of experience performing data analytics
,
• A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 1 year of experience performing data analytics
,
• At least 1 year of experience leveraging open source programming languages for large scale data analysis
,
• At least 1 year of experience working with machine learning
,
• At least 1 year of experience utilizing relational databases

Nice-to-haves
• PhD in 'STEM' field (Science, Technology, Engineering, or Mathematics) plus 3 years of experience in data science
,
• Master's Degree in 'STEM' field plus 5 years of experience in data science
,
• At least 1 year of experience working with AWS
,
• At least 4 years' experience in Python, Scala, or R for large scale data analysis
,
• At least 4 years' experience with machine learning
,
• At least 4 years' experience with SQL

Benefits
• Comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being
,
• Performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI)",,2025-07-25,"[""Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date: A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 6 years of experience performing data analytics"", ""A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 4 years of experience performing data analytics"", 'A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 1 year of experience performing data analytics', 'At least 1 year of experience leveraging open source programming languages for large scale data analysis', 'At least 1 year of experience working with machine learning', 'At least 1 year of experience utilizing relational databases', ""PhD in 'STEM' field (Science, Technology, Engineering, or Mathematics) plus 3 years of experience in data science"", ""Master's Degree in 'STEM' field plus 5 years of experience in data science"", 'At least 1 year of experience working with AWS', ""At least 4 years' experience in Python, Scala, or R for large scale data analysis"", ""At least 4 years' experience with machine learning"", ""At least 4 years' experience with SQL""]","['Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love', 'Leverage a broad stack of technologies - Python, Conda, AWS, H2O, Spark, and more - to reveal the insights hidden within huge volumes of numeric and textual data', 'Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation', 'Flex your interpersonal skills to translate the complexity of your work into tangible business goals']",True,[],,"['Statistical Modeling', 'Relational Databases', 'Machine Learning', 'Python', 'Spark', 'Conda', 'AWS', 'H2O', 'Scala', 'R', 'SQL']","Statistical Modeling: Used to personalize credit card offers by analyzing customer data to drive decision-making.; Relational Databases: Utilized for storing and querying structured customer data to support analytics and model building.; Machine Learning: Applied to build fraud detection models that protect customers by identifying fraudulent activities.; Python: Primary programming language used for data analysis, model development, and building machine learning pipelines.; Spark: Used for large-scale data processing and analytics on huge volumes of numeric and textual data.; Conda: Environment and package management tool used to manage dependencies for data science workflows.; AWS: Cloud platform leveraged for scalable data storage, processing, and machine learning model deployment.; H2O: Machine learning platform used to build and deploy scalable predictive models.; Scala: Programming language used for large scale data analysis, often in conjunction with Spark.; R: Statistical programming language used for data analysis and modeling.; SQL: Used to query and manipulate data stored in relational databases."
X6v2WbpOkslKZsjCAAAAAA==,Data Scientist,"The advanced analytics team is seeking a Data Scientist who has strong data analytics and data science background. The individual will spend time building and maintaining advanced analytical tools and leverage analytical and critical reasoning to solve complex, multidimensional problems using quantitative information and applying statistical and machine learning techniques. Develop predictive models for customer attrition and digital marketing to support retention programs, vertical segmentation and marketing strategies. Identify, collect, and explore the right data used for predictive modeling and algorithm development. Design and develop state-of-the-art data-driven analyses using statistical & advanced analytics methodologies to solve business problems.

Heartland Payment Systems is an Equal Opportunity Employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. We do not discriminate based upon race, religion, color, national origin, sex, sexual orientation, gender identity, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.",,2025-07-25,,"['The individual will spend time building and maintaining advanced analytical tools and leverage analytical and critical reasoning to solve complex, multidimensional problems using quantitative information and applying statistical and machine learning techniques', 'Develop predictive models for customer attrition and digital marketing to support retention programs, vertical segmentation and marketing strategies', 'Identify, collect, and explore the right data used for predictive modeling and algorithm development', 'Design and develop state-of-the-art data-driven analyses using statistical & advanced analytics methodologies to solve business problems']",True,[],,"['Predictive Modeling', 'Statistical Analysis', 'Machine Learning', 'Data Exploration', 'Advanced Analytics']","Predictive Modeling: Used to develop models predicting customer attrition and support marketing strategies.; Statistical Analysis: Applied to design and develop data-driven analyses for solving business problems.; Machine Learning: Employed to build advanced analytical tools and solve complex, multidimensional problems.; Data Exploration: Involves identifying, collecting, and exploring data for predictive modeling and algorithm development.; Advanced Analytics: Used to apply sophisticated methodologies for business problem solving and marketing segmentation."
_QeDs0JMADGJt1J9AAAAAA==,"Senior Machine Learning Scientist, BRAID (Foundational ML)","The Position

A healthier future. It’s what drives us to innovate. To continuously advance science and ensure everyone has access to the healthcare they need today and for generations to come. Creating a world where we all have more time with the people we love. That’s what makes us Roche.

Advances in AI, data, and computational sciences are transforming drug discovery and development. Roche’s Research and Early Development organisations at Genentech (gRED) and Pharma (pRED) have demonstrated how these technologies accelerate R&D, leveraging data and novel computational models to drive impact. Seamless data sharing and access to models across gRED and pRED are essential to maximising these opportunities. The new Computational Sciences Center of Excellence (CoE) is a strategic, unified group whose goal is to harness the transformative power of data and Artificial Intelligence (AI) to assist our scientists in both pRED and gRED to deliver more innovative and transformative medicines for patients worldwide.

The Opportunity

Genentech is seeking a highly motivated Senior AI Scientist to join the Deep Learning Theory and Algorithms (DELTA) lab within the BRAID (Biology Research | AI Development) department in Genentech Research and Early Development (gRED). Our lab is dedicated to advancing AI research to support drug discovery and target discovery efforts, with a focus on large-scale foundation models in research biology. We are committed to driving innovation through cutting-edge AI methods with real-world impact in the drug discovery field. The successful candidate will contribute to a research program focused on AI foundation models, including LLMs and agents, with the ultimate aim of accelerating the drug discovery process. They will work at the intersection of AI research and engineering challenges to build the next generation of biomedical large-scale foundation models. They will contribute to developing cutting-edge AI methods, including multimodal generative modeling, large language models, and reinforcement learning techniques. Furthermore, they will contribute to system design, scaling, and optimization across the full model-development lifecycle. The successful candidate will work in an exciting and multidisciplinary environment alongside AI scientists, ML engineers, and computational biologists.

In this role, you will:
• Drive research on novel foundation models, with a specific focus on multimodal generative models, LLMs, AI Agents, and reinforcement learning.
• Lead the design and implementation of novel, cutting-edge ML methods with applications to drug discovery and target discovery.
• Work at the intersection of deep learning and engineering challenges, focusing on system design, architectural choices, and scalability, in collaboration with the MLOps team.
• Regularly publish in top-tier ML venues (e.g., NeurIPS, ICLR, ICML, AISTATS, etc.) and scientific journals, presenting results at internal and external scientific venues, conferences, and workshops.
• Collaborate closely with interdisciplinary and cross-functional teams across gRED.

Who you are
• Educational Background: Ph.D. in Computer Science, Machine Learning, Statistics, Mathematics, Physics, or a related field.
• Excellent knowledge of the theory and practice of deep learning, as demonstrated in past projects and publication record at top-tier ML venues such as NeurIPS, ICML, ICLR, AISTATS, ACL, EMNLP, etc.
• Proven experience in developing and delivering innovative ML solutions, in particular in the following areas: large-scale representation learning, multi-modal generative modeling, reinforcement learning, large language modeling, AI agents.
• Excellent Python and PyTorch programming skills, with extensive knowledge of the best practices of software engineering, data engineering, and MLOps (e.g., familiar with code version control, high-performance compute infrastructures, and machine learning experiment monitoring workflows).
• Passionate about writing excellent software, system design, scaling, and optimization across the full model-development lifecycle.
• Excellent communication, collaboration, and problem-solving skills.

Relocation benefits are available for this job posting

The expected salary range for this position, based on the primary location of California, is $167,400 - 310,800. Actual pay will be determined based on experience, qualifications, geographic location, and other job-related factors permitted by law. A discretionary annual bonus may be available based on individual and Company performance. This position also qualifies for the benefits detailed at the link provided below.

Benefits

#ComputationCoE

#tech4lifeComputationalScience

#tech4lifeAI

Genentech is an equal opportunity employer. It is our policy and practice to employ, promote, and otherwise treat any and all employees and applicants on the basis of merit, qualifications, and competence. The company's policy prohibits unlawful discrimination, including but not limited to, discrimination on the basis of Protected Veteran status, individuals with disabilities status, and consistent with all federal, state, or local laws.

If you have a disability and need an accommodation in relation to the online application process, please contact us by completing this form Accommodations for Applicants.",2025-07-15T00:00:00.000Z,2025-07-25,"['Educational Background: Ph.D. in Computer Science, Machine Learning, Statistics, Mathematics, Physics, or a related field', 'Excellent knowledge of the theory and practice of deep learning, as demonstrated in past projects and publication record at top-tier ML venues such as NeurIPS, ICML, ICLR, AISTATS, ACL, EMNLP, etc', 'Proven experience in developing and delivering innovative ML solutions, in particular in the following areas: large-scale representation learning, multi-modal generative modeling, reinforcement learning, large language modeling, AI agents', 'Excellent Python and PyTorch programming skills, with extensive knowledge of the best practices of software engineering, data engineering, and MLOps (e.g., familiar with code version control, high-performance compute infrastructures, and machine learning experiment monitoring workflows)', 'Passionate about writing excellent software, system design, scaling, and optimization across the full model-development lifecycle', 'Excellent communication, collaboration, and problem-solving skills']","['The successful candidate will contribute to a research program focused on AI foundation models, including LLMs and agents, with the ultimate aim of accelerating the drug discovery process', 'They will work at the intersection of AI research and engineering challenges to build the next generation of biomedical large-scale foundation models', 'They will contribute to developing cutting-edge AI methods, including multimodal generative modeling, large language models, and reinforcement learning techniques', 'Furthermore, they will contribute to system design, scaling, and optimization across the full model-development lifecycle', 'The successful candidate will work in an exciting and multidisciplinary environment alongside AI scientists, ML engineers, and computational biologists', 'Drive research on novel foundation models, with a specific focus on multimodal generative models, LLMs, AI Agents, and reinforcement learning', 'Lead the design and implementation of novel, cutting-edge ML methods with applications to drug discovery and target discovery', 'Work at the intersection of deep learning and engineering challenges, focusing on system design, architectural choices, and scalability, in collaboration with the MLOps team', 'Regularly publish in top-tier ML venues (e.g., NeurIPS, ICLR, ICML, AISTATS, etc.) and scientific journals, presenting results at internal and external scientific venues, conferences, and workshops', 'Collaborate closely with interdisciplinary and cross-functional teams across gRED']",True,"['Deep Learning', 'Large Language Models', 'Multimodal Generative Modeling', 'AI Agents', 'PyTorch', 'Reinforcement Learning']","Deep Learning: Core methodology for developing foundation models and advanced AI techniques in drug discovery.; Large Language Models: Central to the research focus, these models are developed and optimized to accelerate drug discovery processes.; Multimodal Generative Modeling: Used to create AI models that integrate multiple data types for enhanced biological insights.; AI Agents: Developed as part of foundation models to support autonomous decision-making in biomedical research.; PyTorch: Deep learning framework employed for building and scaling neural network models in the AI research.; Reinforcement Learning: Applied as an AI technique to improve model performance and decision-making in drug discovery.","['Machine Learning', 'Reinforcement Learning', 'Large-scale Representation Learning', 'Data Engineering', 'MLOps', 'Python']","Machine Learning: The role involves developing and delivering innovative machine learning solutions applied to drug and target discovery.; Reinforcement Learning: Used as a technique for advancing AI methods in drug discovery and target discovery within the research program.; Large-scale Representation Learning: Applied to build biomedical foundation models that capture complex biological data representations.; Data Engineering: Essential for managing data workflows and infrastructure supporting model development and experimentation.; MLOps: Practiced to ensure scalable, maintainable machine learning experiment monitoring and deployment workflows.; Python: Primary programming language used for implementing machine learning and data engineering solutions."
v3gSeLJdguHyvKpoAAAAAA==,Data Scientist IV,"Job Title: Senior Data Scientist – Advertising & Insights

Location: Remote (PST preferred; must have overlap with Eastern and Pacific Time Zones)

Employment Type: W2 Contract Only

Pay Rate: $61/hour

Duration: 5 Months (Strong likelihood of extension)

Work Hours: 40 hours/week

Introduction

TPG is hiring a Senior Data Scientist to join a high-impact Ads Data Science team within a fast-scaling digital media and advertising technology environment. This team is focused on optimizing the ad experience and maximizing platform performance through robust data infrastructure, experimentation, and machine learning innovation.

This role is ideal for a data scientist with a passion for solving complex ad tech challenges—ranging from auction optimization and targeting to performance measurement and anomaly detection. You’ll work with product, engineering, and business stakeholders to drive strategic improvements in ad delivery and advertiser experience.

Key Responsibilities
• Design and apply data science solutions to improve ad platform performance and advertiser outcomes
• Analyze large-scale datasets to uncover insights, trends, and strategic opportunities
• Build self-service data assets and dashboards for product and engineering teams
• Lead deep dives into topline metrics to support decision-making and guide product roadmaps
• Collaborate across functions to define product requirements and translate them into DS models
• Develop ML-based systems for anomaly detection, forecasting, and pattern recognition
• Drive continuous improvement through causal inference, A/B testing, and experimentation
• Communicate data insights and model recommendations to technical and non-technical stakeholders

Required Qualifications
• MS or PhD in Computer Science, Statistics, Mathematics, or related quantitative field
• 5+ years of experience in data science, ML, or applied analytics roles
• Strong understanding of statistical modeling, causal inference, and experimental design
• Proficiency in Python or R, with experience using libraries like scikit-learn, TensorFlow, or PyTorch
• Deep knowledge of SQL and working with relational databases

Preferred Skills
• Experience with large-scale data processing (e.g., Spark, Hadoop, Hive); BigQuery experience is a plus
• Background in digital advertising, ad tech, or real-time bidding environments
• Experience designing and analyzing online experiments (A/B testing)
• Ability to build and deploy production-level ML models

Why You’ll Want This Role
• Join a cutting-edge team focused on transforming digital ad performance with data
• Collaborate cross-functionally in a fast-paced, mission-driven environment
• Opportunity to make a tangible impact on ad strategy and product development
• Fully remote with flexible scheduling aligned to core U.S. time zones

Are you ready to drive innovation through data and help scale next-generation ad solutions?

Apply now and bring your data science expertise to a team transforming digital advertising performance.

#LI-CW1 #TECH #Remote",2025-07-17T00:00:00.000Z,2025-07-25,"['MS or PhD in Computer Science, Statistics, Mathematics, or related quantitative field', '5+ years of experience in data science, ML, or applied analytics roles', 'Strong understanding of statistical modeling, causal inference, and experimental design', 'Proficiency in Python or R, with experience using libraries like scikit-learn, TensorFlow, or PyTorch', 'Deep knowledge of SQL and working with relational databases', 'Join a cutting-edge team focused on transforming digital ad performance with data', 'Collaborate cross-functionally in a fast-paced, mission-driven environment', 'Opportunity to make a tangible impact on ad strategy and product development', 'Fully remote with flexible scheduling aligned to core U.S. time zones']","['Location: Remote (PST preferred; must have overlap with Eastern and Pacific Time Zones)', 'Work Hours: 40 hours/week', 'This role is ideal for a data scientist with a passion for solving complex ad tech challenges—ranging from auction optimization and targeting to performance measurement and anomaly detection', 'You’ll work with product, engineering, and business stakeholders to drive strategic improvements in ad delivery and advertiser experience', 'Design and apply data science solutions to improve ad platform performance and advertiser outcomes', 'Analyze large-scale datasets to uncover insights, trends, and strategic opportunities', 'Build self-service data assets and dashboards for product and engineering teams', 'Lead deep dives into topline metrics to support decision-making and guide product roadmaps', 'Collaborate across functions to define product requirements and translate them into DS models', 'Develop ML-based systems for anomaly detection, forecasting, and pattern recognition', 'Drive continuous improvement through causal inference, A/B testing, and experimentation', 'Communicate data insights and model recommendations to technical and non-technical stakeholders']",True,[],,"['Statistical Modeling', 'Causal Inference', 'Experimental Design', 'A/B Testing', 'Machine Learning', 'Anomaly Detection', 'Forecasting', 'Pattern Recognition', 'Python', 'R', 'scikit-learn', 'TensorFlow', 'PyTorch', 'SQL', 'Relational Databases', 'Large-Scale Data Processing', 'BigQuery', 'Dashboards']","Statistical Modeling: Used to analyze and interpret data patterns to improve ad platform performance and advertiser outcomes.; Causal Inference: Applied to understand cause-effect relationships in ad experiments and drive continuous improvement.; Experimental Design: Employed to structure A/B testing and experimentation for measuring ad performance and validating models.; A/B Testing: Used to evaluate the effectiveness of different ad strategies and optimize platform features.; Machine Learning: Developed ML-based systems for anomaly detection, forecasting, and pattern recognition in ad tech.; Anomaly Detection: Implemented to identify unusual patterns or issues in ad delivery and platform metrics.; Forecasting: Used to predict future trends and performance metrics in advertising data.; Pattern Recognition: Applied to detect meaningful trends and behaviors within large-scale advertising datasets.; Python: Primary programming language used for data analysis, modeling, and building ML systems.; R: Used for statistical analysis and data science tasks within the advertising domain.; scikit-learn: A Python library utilized for building and deploying machine learning models in ad tech.; TensorFlow: Used as a machine learning framework to develop models for ad performance optimization.; PyTorch: Employed as a deep learning framework for building ML models related to advertising data.; SQL: Used extensively for querying and managing relational databases containing advertising data.; Relational Databases: Data storage systems used to manage structured advertising and performance data.; Large-Scale Data Processing: Techniques and tools like Spark, Hadoop, and Hive used to handle and analyze big advertising datasets.; BigQuery: Cloud-based data warehouse used for querying and analyzing large advertising datasets.; Dashboards: Built self-service dashboards to visualize ad performance metrics for product and engineering teams."
xFjqQDYVd1oYxSEjAAAAAA==,Data Scientist,"Tombras, a 400+ person, full-service, national advertising agency with a digital mindset, is seeking a Data Scientist.

Where you'll be working: Knoxville or Atlanta. Relocation assistance may be provided.

The analytics practice at Tombras delivers on the agency's promise of data + creativity for business results. This role will be foundational to our advanced analytics team, which will partner with our analytics, media, and data-ops teams to realize the vision of offering best in class marketing science for our clients. You'll build proprietary tooling, work on brands with household recognition, and grow the team as the agency scales.

What you will be doing:
• Lead client engagements for advanced analytics including Media Mix Modeling, Message Mix Modeling, Multi-Touch Attribution, Forecasting, and support testing, experimentation, and optimization. Your remit will be end-to-end, from selling in new work thru delivery of the results.
• Develop the framework and approach for marketing science and develop bespoke offerings.
• Employ best in class tooling to develop proprietary Martech in partnership with the Technology and Media practices.
• Identify new and innovative data sets that can be used to improve existing modeling work, or deliver net new models.
• Clearly articulate statistical results to clients, ultimately leading to continued client engagement and implementation.

What you bring:
• M.S. or Ph.D. degree in a relevant field such as Data Science, Statistics, Mathematics, Computer Science, Business Analytics, or Operations Research
• (Optional) Experience in marketing science or advertising analytics
• Mastery of advanced analytical techniques including but not limited to Multivariate/Bayesian Regression, Randomized Control Trials, Media Mix/Multi-Touch Attribution, Time-Series, Forecasting, Predictive Modeling, Discrete Choice Models
• Strong competency with python, R, SQL, and other commonly used statistical tools
• Client services mindset
• Ability to influence clients and partner agencies to act on insights
• Ability to distill complicated information into succinct graphical presentations for senior stakeholders.

Why Join Tombras Analytics?

Tombras Analytics sits at the cornerstone of Connecting Data + Creativity for Business Results and delivers Diagnostic, Descriptive, Predictive and Prescriptive Analytics across both internal teams and a diverse global, national and regional client base. We are a passionate team of 20+ professionals dedicated to pushing the boundaries of analytics to help our clients discover opportunities, capitalize on trends, create efficiencies and improve marketing and business results for maximum growth.

Why you'll want to work at Tombras:

You'll be joining one of the top independent agencies in North America. Connecting Data & Creativity for Business Results® is working for our clients and creating a flywheel affect fueling both client and agency growth. You'll be a part of a highly creative agency that has been recognized by AdAge, Adweek, Communication Arts, Fast Company, Forbes and Fortune. Tombras was recently named 2025 AdAge Agency of the year and 2024 AdAge Independent Agency of the Year.

Tombras Benefits:

Family - It comes first, on every list. Tombras has been family-run since day 1, we strive to facilitate a family-oriented environment rooted in supporting one another.

Dog-friendly offices

Unlimited PTO

Generous parental leave for primary and non-primary caregivers.

Medical (PPO or High Deductible option) for employee + dependents

401(k) Participation

Employer-paid Dental & Vision

A company culture of promotions from within and an atmosphere allowing for varied and rapid career development.

New, Modern building in Downtown Knoxville

Want more reasons to work at Tombras? Check out the latest Tombras News and Our Values.

Tombras is proud to be an equal opportunity employer dedicated to pursuing and hiring a diverse workforce.

Tombras is an E-Verify employer and participates in the E-Verify program.

This job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee. Duties, responsibilities and activities may change or new ones may be assigned at any time with or without notice. Job may require traveling overnight, driving long distances as required and sitting for extended periods of time with occasional walking and standing and occasionally lifting or carrying articles weighing less than 10 pounds.",,2025-07-25,"['M.S. or Ph.D. degree in a relevant field such as Data Science, Statistics, Mathematics, Computer Science, Business Analytics, or Operations Research', '(Optional) Experience in marketing science or advertising analytics', 'Mastery of advanced analytical techniques including but not limited to Multivariate/Bayesian Regression, Randomized Control Trials, Media Mix/Multi-Touch Attribution, Time-Series, Forecasting, Predictive Modeling, Discrete Choice Models', 'Strong competency with python, R, SQL, and other commonly used statistical tools', 'Client services mindset', 'Ability to influence clients and partner agencies to act on insights', 'Ability to distill complicated information into succinct graphical presentations for senior stakeholders', 'Job may require traveling overnight, driving long distances as required and sitting for extended periods of time with occasional walking and standing and occasionally lifting or carrying articles weighing less than 10 pounds']","[""The analytics practice at Tombras delivers on the agency's promise of data + creativity for business results"", 'This role will be foundational to our advanced analytics team, which will partner with our analytics, media, and data-ops teams to realize the vision of offering best in class marketing science for our clients', ""You'll build proprietary tooling, work on brands with household recognition, and grow the team as the agency scales"", 'Lead client engagements for advanced analytics including Media Mix Modeling, Message Mix Modeling, Multi-Touch Attribution, Forecasting, and support testing, experimentation, and optimization', 'Your remit will be end-to-end, from selling in new work thru delivery of the results', 'Develop the framework and approach for marketing science and develop bespoke offerings', 'Employ best in class tooling to develop proprietary Martech in partnership with the Technology and Media practices', 'Identify new and innovative data sets that can be used to improve existing modeling work, or deliver net new models', 'Clearly articulate statistical results to clients, ultimately leading to continued client engagement and implementation']",True,[],,"['Media Mix Modeling', 'Message Mix Modeling', 'Multi-Touch Attribution', 'Forecasting', 'Randomized Control Trials', 'Multivariate Regression', 'Bayesian Regression', 'Predictive Modeling', 'Discrete Choice Models', 'Time-Series Analysis', 'Python', 'R', 'SQL']",Media Mix Modeling: Used to analyze the effectiveness of various marketing channels to optimize advertising spend.; Message Mix Modeling: Applied to evaluate the impact of different messaging strategies on marketing outcomes.; Multi-Touch Attribution: Employed to assign credit to multiple marketing touchpoints influencing customer conversion.; Forecasting: Used to predict future marketing performance and trends based on historical data.; Randomized Control Trials: Implemented to test and validate marketing strategies through controlled experimentation.; Multivariate Regression: Applied to model relationships between multiple independent variables and marketing outcomes.; Bayesian Regression: Used for probabilistic modeling and inference in marketing analytics.; Predictive Modeling: Developed to forecast customer behavior and marketing campaign results.; Discrete Choice Models: Utilized to model consumer decision-making processes in marketing contexts.; Time-Series Analysis: Applied to analyze sequential marketing data over time for trend and seasonality detection.; Python: Used as a primary programming language for data analysis and building statistical models.; R: Employed for statistical computing and advanced analytics in marketing science.; SQL: Used to query and manage marketing and customer data stored in relational databases.
uXHo1IJOM4IwE46KAAAAAA==,Data Scientist - SME - Clearance Required - Remote Work,"Description:
• ICF seeks an experienced Data Scientist with Subject Matter Expert (SME) - Level experience
• Lead and support the research and development of new cyber analytic capabilities
• Help the US protect and defend its networks and critical information systems
• Act as a Data Scientist SME to support a large federal cyber security analytic program
• Utilize skills to help experiment and prototype future cyber capabilities for large-scale implementation
• Create useful and actionable insight for the customer through the development of machine learning, deep learning models, and related algorithms
• Strong mathematically; can automate scoring using machine learning techniques, build recommendation systems, and select the correct data points for analysis from large data sets
• Contribute to an important project from its beginning, work with the latest and emerging technologies
• Primarily telework-based with occasional meetings at client locations or ICF facilities within the National Capital Region

Requirements:
• Active US government issued security clearance required
• US Citizenship required as part of client contract requirements
• Bachelor’s degree with 12+ year of experience or Master’s degree with 10+ years of experience in Computer Science, Statistics, Applied Mathematics, Computational Linguistics, Artificial Intelligence or related field
• 15 or more years of practical working experience in one or more of the following areas: Natural Language Processing, Machine Learning Models, Question Answering, Text Mining, Information Retrieval, Distributional Semantics, Data Science, Knowledge Engineering
• Demonstrated, advanced level experience using a variety of mathematical, statistical, data mining, and data analysis methods/tools
• 15+ years' experience in Cyber Threats, Computer Science, Statistics, Applied Mathematics, Computational Linguistics, Artificial Intelligence or related field
• Interpersonal skills and the ability to communicate effectively with various clients in order to explain and elaborate on technical details
• Experience in productization of machine learning algorithms and the ability to deliver data science components that are part of successful deliverables
• Working knowledge of general machine learning algorithms and NLP, Graph Theory, and Network Analysis
• Fluency in one or more programming languages (e.g., Python, JavaScript, R, etc.)
• Experience with statistical data analysis, experimental design, and hypotheses validation
• Experience with database querying like SQL
• Readiness to collaborate with engineering teams, product teams, and customers to develop prototypes and software products
• Practical experience with the Databricks Intelligence Platform
• CompTIA Security+ or higher certification level preferred

Benefits:
• Reasonable Accommodations are available
• We are an equal opportunity employer
• Our employees are empowered to share their expertise and collaborate with others",2025-07-16T00:00:00.000Z,2025-07-25,"['ICF seeks an experienced Data Scientist with Subject Matter Expert (SME) - Level experience', 'Active US government issued security clearance required', 'US Citizenship required as part of client contract requirements', 'Bachelor’s degree with 12+ year of experience or Master’s degree with 10+ years of experience in Computer Science, Statistics, Applied Mathematics, Computational Linguistics, Artificial Intelligence or related field', '15 or more years of practical working experience in one or more of the following areas: Natural Language Processing, Machine Learning Models, Question Answering, Text Mining, Information Retrieval, Distributional Semantics, Data Science, Knowledge Engineering', 'Demonstrated, advanced level experience using a variety of mathematical, statistical, data mining, and data analysis methods/tools', ""15+ years' experience in Cyber Threats, Computer Science, Statistics, Applied Mathematics, Computational Linguistics, Artificial Intelligence or related field"", 'Interpersonal skills and the ability to communicate effectively with various clients in order to explain and elaborate on technical details', 'Experience in productization of machine learning algorithms and the ability to deliver data science components that are part of successful deliverables', 'Working knowledge of general machine learning algorithms and NLP, Graph Theory, and Network Analysis', 'Fluency in one or more programming languages (e.g., Python, JavaScript, R, etc.)', 'Experience with statistical data analysis, experimental design, and hypotheses validation', 'Experience with database querying like SQL', 'Readiness to collaborate with engineering teams, product teams, and customers to develop prototypes and software products', 'Practical experience with the Databricks Intelligence Platform']","['Lead and support the research and development of new cyber analytic capabilities', 'Help the US protect and defend its networks and critical information systems', 'Act as a Data Scientist SME to support a large federal cyber security analytic program', 'Utilize skills to help experiment and prototype future cyber capabilities for large-scale implementation', 'Create useful and actionable insight for the customer through the development of machine learning, deep learning models, and related algorithms', 'Strong mathematically; can automate scoring using machine learning techniques, build recommendation systems, and select the correct data points for analysis from large data sets', 'Contribute to an important project from its beginning, work with the latest and emerging technologies', 'Primarily telework-based with occasional meetings at client locations or ICF facilities within the National Capital Region']",True,[],,"['Machine Learning', 'Deep Learning', 'Natural Language Processing', 'Statistical Data Analysis', 'Data Mining', 'Graph Theory', 'Network Analysis', 'SQL', 'Python', 'R', 'Databricks Intelligence Platform']","Machine Learning: Used to develop models for automating scoring, building recommendation systems, and analyzing large datasets in cyber analytic capabilities.; Deep Learning: Applied to create advanced models and algorithms for cyber security analytics and prototyping future cyber capabilities.; Natural Language Processing: Utilized for text mining, question answering, information retrieval, and distributional semantics in cyber security contexts.; Statistical Data Analysis: Employed for experimental design, hypothesis validation, and deriving actionable insights from data.; Data Mining: Used to extract meaningful patterns and knowledge from large cyber security datasets.; Graph Theory: Applied to analyze network structures and relationships relevant to cyber threat detection.; Network Analysis: Used to study and interpret cyber network data for threat identification and defense.; SQL: Used for querying databases to retrieve and manipulate data necessary for analysis and model development.; Python: A programming language used for implementing machine learning models, data analysis, and prototyping.; R: A programming language used for statistical analysis and data science tasks.; Databricks Intelligence Platform: A platform leveraged for data engineering, collaborative analytics, and deploying machine learning models."
PB6jkB5FPMUGC660AAAAAA==,Data Scientist – Cybersecurity (BHJOB22048_730) Job at ITmPowered in Denver,"Data Scientist (AI/ML) – Medical Device Cybersecurity – ITmPowered ConsultingThe Sr. Data Scientist will apply Data Science to enterprise Medical Device Cybersecurity, Network security, Attacks & Events. Leverage big data in support of an enterprise scale Medical Device Cybersecurity program spanning Risk Management, Cyber Digital Transformation, Threat Management, Network Security, End Point Security, IT Controls, Security Operations and Identity and Data Management. Will have direct impact providing strategic insight into Medical Device cybersecurity protection and improving networking security.How you’ll make an impact:Analyze large amounts of data and develop statistical models to find patterns and solve problems that will help drive strategic business decisions.Analyze data from numerous sources (Splunk, Qualis, CMDB/Asset Inventory, CyberArk, Armis, ForeScout, Automated Patch Management systems, Threat and Vulnerability, Network Traffic, Governance and Standards data, Risk Assessment data, Security baselines, etc.)Look at cybersecurity and machine learning opportunities identifying opportunities and goals (detect threats, predict attacks, prediction, prevention, detection, response, monitoring)Design and implementation of machine learning solutions using regression, model, clustering (KNN, K-means, Bayesian, Mean-shift), statistical profiling, inference, classification, and predictive analysis.Leverage AI and Machine Learning in both supervised (classification, regression) and unsupervised scenarios (clustering, association, dimension reduction).Looking at data across Network Security, network traffic analysis, Network security scanning (Wired, Wireless, cloud), Endpoint (anti-malware), Application Security (micro firewalls, WAF, Data firewalls), User Behavior Analytics, Device behavior analytics, access management. Security of data in transit, at rest, historically.Network Protection, Network Traffic Analytics, IP Traffic, Ports, intrusion detection. Identify different classes of network attacks – scanning and spoofing. Network anomaly detection, Encrypted traffic classification, Clustering for forensic analysis. Medical Device endpoint protection.Qualifications for success:Bachelor’s Degree in Data Science, Computer Science, Information Systems, Mathematics, Statistics, Engineering or similar (Masters Preferred)Experience with a range of machine learning techniques: linear regression, classifications, random forest, clustering, supervised and unsupervised learning, graph algorithms, etc.Experience in Machine, and Deep Learning frameworks, model validation and deployment tools, data pipeline technologies, and visualization and data storytelling tools (R, Tableau, Jupyter, etc.).Advanced knowledge of statistical concepts such as regressions, time series, mixed model, Bayesian methods, clustering, classification, and graph models to analyze data and provide insights.Expertise in common data science toolkits and programming languages, including R, Python (including SciPy, NumPy, and/or PySpark) and/or Scala, Java, SQL, and shell scripting.Hands-on experience with Spark and Hadoop.Experience working with high volume data lakes, and large databases.Demonstrated experience applying data science methods to real-world data problems.Preferred Expertise:Understanding of cyber security, computer network security, security protocols, encryption, security scanning, threat and vulnerability management, Technology Risk Assessment, cybersecurity assessment, IT Controls.Logistics:Local Denver resources only. No relocation provided.Will be remote primarily but must be able to come into DTC office periodically after COVID Abates.COVID-19 – Must be fully vaccinated OR provide medical or religious exemption.W2 only – No sub vendors. Sponsorship NOT available. Must have direct contact information on resume to apply.You will need to be a US Citizen, and with the ability to obtain US Government TOP SECRET clearance, as well as successfully pass a 12 panel drug screen and 10 year background check, in order to meet eligibility requirements for access to classified information.
#J-18808-Ljbffr",2025-07-20T00:00:00.000Z,2025-07-25,"['Security of data in transit, at rest, historically', 'Experience in Machine, and Deep Learning frameworks, model validation and deployment tools, data pipeline technologies, and visualization and data storytelling tools (R, Tableau, Jupyter, etc.).Advanced knowledge of statistical concepts such as regressions, time series, mixed model, Bayesian methods, clustering, classification, and graph models to analyze data and provide insights', 'Expertise in common data science toolkits and programming languages, including R, Python (including SciPy, NumPy, and/or PySpark) and/or Scala, Java, SQL, and shell scripting.Hands-on experience with Spark and Hadoop', 'Experience working with high volume data lakes, and large databases', 'Demonstrated experience applying data science methods to real-world data problems', 'You will need to be a US Citizen, and with the ability to obtain US Government TOP SECRET clearance, as well as successfully pass a 12 panel drug screen and 10 year background check, in order to meet eligibility requirements for access to classified information']","['Leverage big data in support of an enterprise scale Medical Device Cybersecurity program spanning Risk Management, Cyber Digital Transformation, Threat Management, Network Security, End Point Security, IT Controls, Security Operations and Identity and Data Management', 'Will have direct impact providing strategic insight into Medical Device cybersecurity protection and improving networking security', 'How you’ll make an impact:Analyze large amounts of data and develop statistical models to find patterns and solve problems that will help drive strategic business decisions', 'Analyze data from numerous sources (Splunk, Qualis, CMDB/Asset Inventory, CyberArk, Armis, ForeScout, Automated Patch Management systems, Threat and Vulnerability, Network Traffic, Governance and Standards data, Risk Assessment data, Security baselines, etc.)Look at cybersecurity and machine learning opportunities identifying opportunities and goals (detect threats, predict attacks, prediction, prevention, detection, response, monitoring)Design and implementation of machine learning solutions using regression, model, clustering (KNN, K-means, Bayesian, Mean-shift), statistical profiling, inference, classification, and predictive analysis', 'Leverage AI and Machine Learning in both supervised (classification, regression) and unsupervised scenarios (clustering, association, dimension reduction)', 'Looking at data across Network Security, network traffic analysis, Network security scanning (Wired, Wireless, cloud), Endpoint (anti-malware), Application Security (micro firewalls, WAF, Data firewalls), User Behavior Analytics, Device behavior analytics, access management', 'Network Protection, Network Traffic Analytics, IP Traffic, Ports, intrusion detection', 'Identify different classes of network attacks – scanning and spoofing', 'Network anomaly detection, Encrypted traffic classification, Clustering for forensic analysis', 'Medical Device endpoint protection']",True,['Deep Learning'],Deep Learning: Used alongside machine learning frameworks to develop advanced models for cybersecurity threat detection and prevention.,"['Regression Models', 'Classification', 'Clustering', 'Bayesian Methods', 'Time Series Analysis', 'Graph Models', 'Feature Engineering', 'Data Pipelines', 'SQL', 'Python (SciPy, NumPy, PySpark)', 'R', 'Scala', 'Java', 'Shell Scripting', 'Spark', 'Hadoop', 'Machine Learning', 'Statistical Profiling', 'Predictive Analysis', 'Data Visualization and Storytelling', 'Network Traffic Analytics', 'User and Device Behavior Analytics']","Regression Models: Used to develop statistical models for predicting cybersecurity threats and attacks based on large datasets.; Classification: Applied to categorize network traffic and detect different classes of network attacks such as scanning and spoofing.; Clustering: Used for unsupervised learning tasks like network anomaly detection and forensic analysis of cybersecurity events.; Bayesian Methods: Employed for statistical profiling and inference in analyzing cybersecurity data patterns.; Time Series Analysis: Utilized to analyze temporal cybersecurity data for threat prediction and monitoring.; Graph Models: Used to analyze relationships and interactions within network security data and cyber threat patterns.; Feature Engineering: Performed on cybersecurity data from multiple sources to improve machine learning model performance.; Data Pipelines: Implemented to process and manage large volumes of cybersecurity data from diverse sources like Splunk and network traffic logs.; SQL: Used to query and manage large cybersecurity databases and data lakes.; Python (SciPy, NumPy, PySpark): Programming languages and libraries used for data analysis, machine learning model development, and big data processing in cybersecurity.; R: Utilized for statistical analysis, visualization, and data storytelling in cybersecurity projects.; Scala: Used for big data processing and machine learning tasks within cybersecurity data environments.; Java: Applied in developing data processing and machine learning solutions for cybersecurity.; Shell Scripting: Used to automate data processing and management tasks in cybersecurity workflows.; Spark: Employed for distributed big data processing and machine learning on large cybersecurity datasets.; Hadoop: Used to manage and process high volume cybersecurity data lakes.; Machine Learning: Applied to detect, predict, and prevent cybersecurity threats through supervised and unsupervised learning techniques.; Statistical Profiling: Used to identify patterns and anomalies in cybersecurity data for threat detection.; Predictive Analysis: Implemented to forecast potential cybersecurity attacks and vulnerabilities.; Data Visualization and Storytelling: Utilized tools like Tableau and Jupyter to communicate cybersecurity insights effectively.; Network Traffic Analytics: Analyzing IP traffic, ports, and encrypted traffic to identify anomalies and potential cyber threats.; User and Device Behavior Analytics: Analyzing behavior patterns to detect suspicious activities and potential security breaches."
EtmlA8aarewd1UubAAAAAA==,"Senior Data Scientist – Data and Machine Learning, WWPS ProServe","Senior Data Scientist - Data and Machine Learning, WWPS ProServe Job ID: 2953184 | Amazon Web Services, Inc. Are you excited to help the US Intelligence Community design, build, and implement AI algorithms, including advanced Generative AI solutions, to augment decision making while meeting the highest standards for reliability, transparency, and scalability? The Amazon Web Services (AWS) US Federal Professional Services team works directly with US Intelligence Community agencies and other public sector entities to achieve their mission goals through the adoption of Machine Learning (ML) and Generative AI methods. We build models for text, image, video, audio, and multi-modal use cases, leveraging both traditional ML approaches and state-of-the-art generative models including Large Language Models (LLMs), text-to-image generation, and other advanced AI capabilities to fit the mission. At AWS, we're hiring experienced data scientists with a background in both traditional and generative AI who can help our customers understand the opportunities their data presents, and build solutions that earn the customer trust needed for deployment to production systems. In this role, you will work closely with customers to deeply understand their data challenges and requirements, and design tailored solutions that best fit their use cases. You should have broad experience building models using all kinds of data sources, and building data-intensive applications at scale. You should possess excellent business acumen and communication skills to collaborate effectively with stakeholders, develop key business questions, and translate requirements into actionable solutions. You will provide guidance and support to other engineers, sharing industry best practices and driving innovation in the field of data science and AI. This position requires that the candidate selected must currently possess and maintain an active TS/SCI Security Clearance with Polygraph. The position further requires the candidate to opt into a commensurate clearance for each government agency for which they perform AWS work. Key job responsibilities As a Data Scientist, you will: Collaborate with AI/ML scientists and architects to research, design, develop, and evaluate AI algorithms to address real-world challenges. Interact with customers directly to understand the business problem, help and aid them in implementation of AI solutions, deliver briefing and deep dive sessions to customers and guide customer on adoption patterns and paths to production. Create and deliver best practice recommendations, tutorials, blog posts, sample code, and presentations adapted to technical, business, and executive stakeholders. Provide customer and market feedback to Product and Engineering teams to help define product direction. This position may require up to 25% local travel. BASIC QUALIFICATIONS Bachelor's degree in Computer Science, Engineering, related field, or equivalent experience. 5+ years of experience building models for business applications. Experience with algorithms, data structures, parsing, numerical optimization, data mining, parallel and distributed computing, high-performance computing, neural deep learning methods and/or machine learning. Experience using Python and hands-on experience building models with deep learning frameworks (i.e. Tensorflow, Keras, PyTorch, MXNet). Current, active US Government Security Clearance of TS/SCI with Polygraph. PREFERRED QUALIFICATIONS Masters or PhD Degree in computer science, engineering, mathematics, operations research, or in a highly quantitative field. Practical experience in solving complex problems in an applied environment. Hands-on experience building models with deep learning frameworks like PyTorch, Tensorflow, or JAX. Experience building applications leveraging GenAI. Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit this link for more information. Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $143,300/year in our lowest geographic market up to $247,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit this link . Posted: April 1, 2025 (Updated 14 days ago) Share this job Important FAQs for current Government employees Before proceeding, please review the following FAQs here . #J-18808-Ljbffr",2025-07-16T00:00:00.000Z,2025-07-25,"['You should have broad experience building models using all kinds of data sources, and building data-intensive applications at scale', 'You should possess excellent business acumen and communication skills to collaborate effectively with stakeholders, develop key business questions, and translate requirements into actionable solutions', 'This position requires that the candidate selected must currently possess and maintain an active TS/SCI Security Clearance with Polygraph', ""BASIC QUALIFICATIONS Bachelor's degree in Computer Science, Engineering, related field, or equivalent experience"", '5+ years of experience building models for business applications', 'Experience with algorithms, data structures, parsing, numerical optimization, data mining, parallel and distributed computing, high-performance computing, neural deep learning methods and/or machine learning', 'Experience using Python and hands-on experience building models with deep learning frameworks (i.e', 'Tensorflow, Keras, PyTorch, MXNet)', 'Current, active US Government Security Clearance of TS/SCI with Polygraph', 'Practical experience in solving complex problems in an applied environment', 'Hands-on experience building models with deep learning frameworks like PyTorch, Tensorflow, or JAX', 'Experience building applications leveraging GenAI']","['In this role, you will work closely with customers to deeply understand their data challenges and requirements, and design tailored solutions that best fit their use cases', 'You will provide guidance and support to other engineers, sharing industry best practices and driving innovation in the field of data science and AI', 'Key job responsibilities As a Data Scientist, you will: Collaborate with AI/ML scientists and architects to research, design, develop, and evaluate AI algorithms to address real-world challenges', 'Interact with customers directly to understand the business problem, help and aid them in implementation of AI solutions, deliver briefing and deep dive sessions to customers and guide customer on adoption patterns and paths to production', 'Create and deliver best practice recommendations, tutorials, blog posts, sample code, and presentations adapted to technical, business, and executive stakeholders', 'Provide customer and market feedback to Product and Engineering teams to help define product direction', 'This position may require up to 25% local travel']",True,"['Generative AI', 'Large Language Models', 'Deep Learning Frameworks']","Generative AI: Applied to develop advanced AI solutions including text, image, video, and audio generation for mission-specific use cases.; Large Language Models: Used to build state-of-the-art AI models for text and multi-modal applications in intelligence community projects.; Deep Learning Frameworks: Frameworks like TensorFlow, PyTorch, Keras, MXNet, and JAX are used for building and deploying neural deep learning models.","['Machine Learning', 'Data Mining', 'Numerical Optimization', 'Algorithms and Data Structures', 'Parallel and Distributed Computing', 'High-Performance Computing', 'Python']",Machine Learning: Used to build predictive models and data-intensive applications for business and intelligence community use cases.; Data Mining: Applied to extract useful patterns and insights from diverse data sources to support decision making.; Numerical Optimization: Utilized to improve model performance and solve complex computational problems in model building.; Algorithms and Data Structures: Fundamental for designing efficient data processing and model implementation solutions.; Parallel and Distributed Computing: Employed to handle large-scale data processing and high-performance computing tasks.; High-Performance Computing: Used to accelerate computation-intensive data science and machine learning workflows.; Python: Primary programming language for building models and data science applications.
8LeYF2XmL_c0lKQeAAAAAA==,Data Analyst/Scientist/Engineer - Entry/Junior Level,"Since 2010 Synergisticit has helped Jobseekers differentiate themselves by providing candidates the requisite skills and experience to outperform at interviews and clients. Here at SynergisticIT We just don't focus on getting you a tech Job we make careers.
In this market also we have been able to help our candidates get multiple job offers and $100k + salaries.
please check the below links to see the success outcomes of our candidates our participation at different Tech industry events and how we are different from other organizations in helping Jobseekers secure Tech careers
https://www.synergisticit.com/candidate-outcomes/
https://reg.rf.oracle.com/flow/oracle/cwoh23/OCWExhibitorCatalog/page/OCWexhibitorcatalog
We regularly interact with the Top Tech companies to give our candidates a competitive advantage see us exhibiting at Oracle Cloud World/Oracle Java One (Las Vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023
All Positions are open for all visas and US citizens
We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like Apple, Google, Paypal, Western Union, Client, visa, Walmart lab s etc to name a few.
We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, Java full-stack developers, Python/Java developers, Data analysts/ Data Scientists, and Machine Learning engineers for full-time positions with clients.
Who Should Apply Recent Computer Science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry?
We assist in filing for STEM extension and also for H1b and Green card filing to Candidates
https://www.youtube.com/watch?v=OFoqPTNORew
https://www.youtube.com/watch?v=-HkNN1ag6Zk
https://www.youtube.com/watch?v=OAFOhcGy9Z8
https://youtu.be/bJJl27D8bh0
We are looking for the right matching candidates for our clients
REQUIRED SKILLS For Java /Full stack/Software Programmer
• Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
• Highly motivated, self-learner, and technically inquisitive
• Experience in programming language Java and understanding of the software development life cycle
• Project work on the skills
• Knowledge of Core Java , javascript, C++, or software programming
• Spring boot, Microservices, Docker, Jenkins, and REST API experience
• Excellent written and verbal communication skills
For data Science/Machine learning Positions
REQUIRED SKILLS
• Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
• Project work on the technologies needed
• Highly motivated, self-learner, and technically inquisitive
• Experience in programming language Java and understanding of the software development life cycle
• Knowledge of Statistics, SAS, Python, Computer Vision, and data visualization tools
• Excellent written and verbal communication skills

Preferred skills: NLP, Text mining, Tableau, PowerBI, SAS, Tensorflow
If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team and only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third-party or agency candidates or c2c candidates",,2025-07-25,"['REQUIRED SKILLS For Java /Full stack/Software Programmer', 'Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT', 'Highly motivated, self-learner, and technically inquisitive', 'Experience in programming language Java and understanding of the software development life cycle', 'Project work on the skills', 'Knowledge of Core Java , javascript, C++, or software programming', 'Spring boot, Microservices, Docker, Jenkins, and REST API experience', 'Excellent written and verbal communication skills', 'For data Science/Machine learning Positions', 'Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT', 'Project work on the technologies needed', 'Highly motivated, self-learner, and technically inquisitive', 'Experience in programming language Java and understanding of the software development life cycle', 'Knowledge of Statistics, SAS, Python, Computer Vision, and data visualization tools', 'Excellent written and verbal communication skills']",,True,['TensorFlow'],TensorFlow: Preferred skill indicating experience with deep learning frameworks used for building AI models.,"['Statistics', 'SAS', 'Python', 'Data Visualization Tools', 'Computer Vision', 'Machine Learning', 'NLP']","Statistics: Used as a foundational skill for data analysis and modeling in data science roles.; SAS: A statistical software tool mentioned as a required skill for data science and machine learning positions.; Python: Programming language used for data analysis, machine learning, and data visualization tasks.; Data Visualization Tools: Tools like Tableau and PowerBI are preferred for creating dashboards and visualizing data insights.; Computer Vision: Listed as a knowledge area relevant to data science and machine learning roles, indicating work with image data.; Machine Learning: A core skill for the data science and machine learning positions, involving building predictive models.; NLP: Natural Language Processing is mentioned as a preferred skill, relevant for text mining and analysis."
bbUxVNWuJFKrOXU-AAAAAA==,"Sr. Data Science Manager, Marketing","We are Farmers!

We are… more than just your favorite commercials.  At Farmers, we strive to deliver peace of mind to our customers by providing protection and comprehensive advice and delivering in the moments of truth. That means having people who can help us meet changing customer and business needs. Farmers high-performance culture is focused on results and the people who achieve them. We hold ourselves and others accountable for sustainably growing the business and each other. We seek solutions, own our actions, and grow through discomfort. We see setbacks as opportunities while continuously asking ourselves how we impact our customers.

Farmers is an award winning, equal opportunity employer, committed to the strength of a diverse workforce. We are dedicated to supporting the well-being of our people through our extensive suite of benefits, as well as the well-being of the communities we serve through employee volunteer programs and nonprofit partnerships. Helping others in their time of need isn’t just our business – it’s our culture!  To learn more about our high-performance culture and open opportunities, check out www.Farmers.com/careers/corporate and be sure to follow us on Instagram, LinkedIn, and TikTok.

Workplace: Hybrid ( #LI-Hybrid ), Remote ( #LI-Remote )

Farmers believes in a culture of collaboration, creativity, and innovation, which thrives when we have the ability to work flexibly in a virtual setting as well as the opportunity to be together in person. Our hybrid work environment combines the best of both worlds with at least three (3) days in office and up to two (2) days virtual for employees who live within fifty (50) miles of a Farmers corporate office. Applicants beyond fifty (50) miles may still be considered.
Job Summary
• Utilizes specialized knowledge and experience to apply advanced analytics and modeling to improve business results.
• Leverages unique customer information and behavioral data to influence strategic business decisions while using complex, innovative analytics, multi-variate models, machine learning and data mining technologies.
• Assists in and leads complex, cross-functional projects operationalizing business decisions.
• Works independently receiving guidance in only the most complex situations.
• The role mentors, coaches, and trains less experienced team members and supervises direct reports who are individual contributors.

What You'll Do
• Takes ownership and executes on more complex and often vague business challenges involving data science. Succeeds in specialized projects by scoping, defining measures of success, utilizing a data science vision for project success, and exceeding on prescribed and some vague timelines. Executes and leads broad projects independently with a sense of urgency. Utilizes specialized knowledge of consumer analytics including retention models, agency economics, and leads optimization in their daily work.
• Utilizes broad knowledge of advanced programing, complex ETL and specialized modeling methods to execute projects and leads the team through examples of effective technical skills. Demonstrates clean reusable code and effective documentation, encourages others to do the same. Acts as the main contributor to multiple phases of a data science project (ideation, experiment design, EDA, feature engineering, model building, deployment, etc. ). Utilizes a strong sense of ownership and contributes to multiple tasks and deadlines simultaneously.
• Partners closely with IT, business, and data management/engineering teams to understand, utilize, and improve our data infrastructure. Advises on complex matters and serves as an objective and transparent partner to drive fact-based decision making and a measures of success culture. Provides strategic direction, project clarity and methodological consultation. Delivers results both individually and by mentoring and empowering other team members.
• Mentors and provides guidance to team members. Provides high level coaching and knowledge around technical and non-technical skills. Reviews AI/ML modeling, statistical analysis, and data analysis completed by other team members, providing coaching and feedback as needed.
• Develops presentations and presents to all groups and levels of leadership, including executives. Regularly communicates complex technical material understandable to non-technical associates.
• Manages specialized model deployments via MLOps techniques. Partners closely with analytics and IT teams to deploy models/rules in various platforms and leads testing of new solutions. Takes active role in steering MLOps environment improvements.

What You'll Bring
• Minimum seven years of work experience required in data analysis, statistical or mathematical modeling, or related.
• Marketing experience preferred; Marketing Mix Modeling experience strongly preferred (not required).

Education You'll Need
• High School Diploma or equivalent required.
• Masters degree required in data science, statistics, mathematics, business analytics or related.

Additional Qualifications
• Strong verbal communication and listening skills. Advanced storytelling skills with ability to communicate complex data insights clearly to technical and non-technical audiences.
• Demonstrated written communication skills.
• Proficient in Microsoft Office Suite.
• Develops and delivers effective presentations.
• Effectively coaches and delivers constructive feedback.
• Demonstrated problem solving skills.
• Excellent collaboration and team building skills.
• Ability to influence internal and/or external constituents.
• Seeks to acquire knowledge in area of specialty.
• Possesses flexibility to work in a fast paced, dynamic environment. Able to meet deadlines and priorities that shift with business needs. Able to simultaneously handle multiple priorities. Possesses solid project management skills.
• Demonstrated analytical skills. Possesses advanced technical aptitude.
• Advanced proficiency working on large-scale structured and unstructured multidimensional data using advanced knowledge of open-source cloud-enabled analytical programming languages. Advanced ability to consult on data extraction, data manipulation and data design for statistical, modeling and monitoring needs. Advanced knowledge of data analysis, manipulation tools (SQL, Python, SAS, R, and/or Snowflake) and cloud computing services (AWS). Advanced knowledge of data visualization tools (example, Tableau, Power BI).
• Advanced proficiency in using explanatory, diagnostic, and inferential techniques such as experimental design, hypothesis testing, clustering analysis, time series and other statistical modeling algorithms with the ability to decide the appropriate methodology for the purpose. Advanced proficiency in predictive and prescriptive modeling using advanced machine learning and deep learning techniques. Advanced in ML/AI model deployment best practices. Able to adapt quickly to new technologies. Advanced knowledge of coding standards and version control (Git). Other. Broad knowledge of data ethics and data privacy.

Benefits
• Farmers offers a competitive salary commensurate with experience, qualifications and location.
o CA Only: $134,320 - $214,390
o CO Only: $126,240 - $184,690
o HI/IL/MN/VT Only: $126,240 - $197,780
o MA Only: $126,240 - $197,780
• o MD Only: $126,240 - $197,780
o NY/DC/NJ Only: $126,240 - $214,390
o Albany County: $134,320 - $184,690
o WA Only: $126,240 - $224,750
• Bonus Opportunity (based on Company and Individual Performance)
• 401(k)
• Medical
• Dental
• Vision
• Health Savings and Flexible Spending Accounts
• Life Insurance
• Paid Time Off
• Paid Parental Leave
• Tuition Assistance
• For more information, review “What we offer” on https://www.farmers.com/careers/corporate/#offer

Job Location(s): R_US - United States, US - CA - WdlndHills-6301, US - CA - WdlndHills-6303, US - CA - Woodland Hills

Anticipated application deadline: At Farmers, the recruitment process is designed to ensure that we find the best talent to join our team. As part of this process, we typically close open positions within 8 to 21 days after posting. If you are interested in any of our open positions, we encourage you to submit your application promptly.

Farmers will consider for employment all qualified applicants, including those with criminal histories, in accordance with the Los Angeles Fair Chance Initiative for Hiring Ordinance or other applicable law. Pursuant to 18 U.S.C. Section 1033, Farmers is prohibited from employing any individual who has been convicted of any criminal felony involving dishonesty or a breach of trust without prior written consent from the state Department of Insurance.

Farmers is an Equal Opportunity Employer and does not discriminate in any employer/employee relations based on race, color, religion, gender, sexual orientation, gender expression, genetic information, national origin, age, disability, marital status, military and veteran's status, or any other basis protected by applicable discrimination laws.

Want to learn more about our culture & opportunities? Check out www.Farmers.com/careers/corporate and be sure to follow us on Instagram, LinkedIn, and TikTok.

Spokane, WA only: Residents who prefer not to provide their address click here to submit your resume via email: careers@farmers.com",2025-07-14T00:00:00.000Z,2025-07-25,"['Minimum seven years of work experience required in data analysis, statistical or mathematical modeling, or related', 'High School Diploma or equivalent required', 'Masters degree required in data science, statistics, mathematics, business analytics or related', 'Strong verbal communication and listening skills', 'Advanced storytelling skills with ability to communicate complex data insights clearly to technical and non-technical audiences', 'Demonstrated written communication skills', 'Proficient in Microsoft Office Suite', 'Develops and delivers effective presentations', 'Demonstrated problem solving skills', 'Excellent collaboration and team building skills', 'Ability to influence internal and/or external constituents', 'Seeks to acquire knowledge in area of specialty', 'Possesses flexibility to work in a fast paced, dynamic environment', 'Able to meet deadlines and priorities that shift with business needs', 'Able to simultaneously handle multiple priorities', 'Possesses solid project management skills', 'Demonstrated analytical skills', 'Possesses advanced technical aptitude', 'Advanced proficiency working on large-scale structured and unstructured multidimensional data using advanced knowledge of open-source cloud-enabled analytical programming languages', 'Advanced ability to consult on data extraction, data manipulation and data design for statistical, modeling and monitoring needs', 'Advanced knowledge of data analysis, manipulation tools (SQL, Python, SAS, R, and/or Snowflake) and cloud computing services (AWS)', 'Advanced knowledge of data visualization tools (example, Tableau, Power BI)', 'Advanced proficiency in using explanatory, diagnostic, and inferential techniques such as experimental design, hypothesis testing, clustering analysis, time series and other statistical modeling algorithms with the ability to decide the appropriate methodology for the purpose', 'Advanced proficiency in predictive and prescriptive modeling using advanced machine learning and deep learning techniques', 'Advanced in ML/AI model deployment best practices', 'Able to adapt quickly to new technologies', 'Advanced knowledge of coding standards and version control (Git)', 'Broad knowledge of data ethics and data privacy']","['That means having people who can help us meet changing customer and business needs', 'Utilizes specialized knowledge and experience to apply advanced analytics and modeling to improve business results', 'Leverages unique customer information and behavioral data to influence strategic business decisions while using complex, innovative analytics, multi-variate models, machine learning and data mining technologies', 'Assists in and leads complex, cross-functional projects operationalizing business decisions', 'Works independently receiving guidance in only the most complex situations', 'The role mentors, coaches, and trains less experienced team members and supervises direct reports who are individual contributors', 'Takes ownership and executes on more complex and often vague business challenges involving data science', 'Succeeds in specialized projects by scoping, defining measures of success, utilizing a data science vision for project success, and exceeding on prescribed and some vague timelines', 'Executes and leads broad projects independently with a sense of urgency', 'Utilizes specialized knowledge of consumer analytics including retention models, agency economics, and leads optimization in their daily work', 'Utilizes broad knowledge of advanced programing, complex ETL and specialized modeling methods to execute projects and leads the team through examples of effective technical skills', 'Demonstrates clean reusable code and effective documentation, encourages others to do the same', 'Acts as the main contributor to multiple phases of a data science project (ideation, experiment design, EDA, feature engineering, model building, deployment, etc', 'Utilizes a strong sense of ownership and contributes to multiple tasks and deadlines simultaneously', 'Partners closely with IT, business, and data management/engineering teams to understand, utilize, and improve our data infrastructure', 'Advises on complex matters and serves as an objective and transparent partner to drive fact-based decision making and a measures of success culture', 'Provides strategic direction, project clarity and methodological consultation', 'Delivers results both individually and by mentoring and empowering other team members', 'Mentors and provides guidance to team members', 'Provides high level coaching and knowledge around technical and non-technical skills', 'Reviews AI/ML modeling, statistical analysis, and data analysis completed by other team members, providing coaching and feedback as needed', 'Develops presentations and presents to all groups and levels of leadership, including executives', 'Regularly communicates complex technical material understandable to non-technical associates', 'Manages specialized model deployments via MLOps techniques', 'Partners closely with analytics and IT teams to deploy models/rules in various platforms and leads testing of new solutions', 'Takes active role in steering MLOps environment improvements', 'Effectively coaches and delivers constructive feedback']",True,[],,"['Advanced Analytics', 'Multivariate Models', 'Machine Learning', 'Data Mining', 'Consumer Analytics', 'ETL (Extract, Transform, Load)', 'Experiment Design', 'Exploratory Data Analysis (EDA)', 'Feature Engineering', 'Model Building', 'Model Deployment', 'SQL', 'Python', 'SAS', 'R', 'Snowflake', 'AWS (Amazon Web Services)', 'Tableau', 'Power BI', 'Experimental Design', 'Hypothesis Testing', 'Clustering Analysis', 'Time Series Modeling', 'Predictive Modeling', 'Prescriptive Modeling', 'Deep Learning Techniques', 'MLOps', 'Git', 'Data Ethics and Privacy']","Advanced Analytics: Used to apply sophisticated analytical techniques to improve business results and support strategic decision-making.; Multivariate Models: Employed to analyze multiple variables simultaneously for complex business insights, such as customer behavior and marketing effectiveness.; Machine Learning: Applied to build predictive and prescriptive models that enhance marketing strategies and operational decisions.; Data Mining: Used to extract patterns and insights from large datasets to inform business strategies.; Consumer Analytics: Focuses on analyzing customer data including retention models and leads optimization to drive marketing performance.; ETL (Extract, Transform, Load): Involved in complex data processing workflows to prepare data for analysis and modeling.; Experiment Design: Used to structure experiments for testing hypotheses and measuring the impact of marketing initiatives.; Exploratory Data Analysis (EDA): Conducted to understand data characteristics and inform feature engineering and modeling.; Feature Engineering: Performed to create meaningful input variables that improve model performance.; Model Building: Involves developing statistical and machine learning models to predict and optimize business outcomes.; Model Deployment: Managing the operationalization of models into production environments using MLOps techniques.; SQL: Used for data extraction and manipulation from relational databases to support analysis and modeling.; Python: Utilized as a primary programming language for data analysis, modeling, and automation.; SAS: Applied for advanced statistical analysis and modeling in marketing analytics.; R: Used for statistical computing and graphics to support data science projects.; Snowflake: Cloud data platform leveraged for scalable data storage and processing.; AWS (Amazon Web Services): Cloud computing services used to support data infrastructure and analytics workloads.; Tableau: Data visualization tool used to create dashboards and reports for communicating insights.; Power BI: Business intelligence tool employed to develop interactive visualizations and support decision-making.; Experimental Design: Applied to structure and analyze controlled experiments for hypothesis testing.; Hypothesis Testing: Used to validate assumptions and measure the statistical significance of findings.; Clustering Analysis: Performed to segment customers or data points into meaningful groups for targeted marketing.; Time Series Modeling: Used to analyze and forecast data points collected over time, relevant for marketing trends.; Predictive Modeling: Developed to forecast future outcomes such as customer behavior and campaign effectiveness.; Prescriptive Modeling: Used to recommend optimal actions based on predictive insights.; Deep Learning Techniques: Applied advanced neural network methods to enhance predictive modeling capabilities.; MLOps: Practices used to manage and deploy machine learning models efficiently in production.; Git: Version control system used to manage codebase and ensure collaboration and reproducibility.; Data Ethics and Privacy: Considerations integrated into data handling and modeling to ensure compliance and responsible use."
W7z9qXFh2jQjilApAAAAAA==,"Data Scientist, Marketing & Commercial Analytics","At Zelis, we Get Stuff Done. So, let’s get to it! A Little About Us Zelis is modernizing the healthcare financial experience across payers, providers, and healthcare consumers. We serve more than 750 payers, including the top five national health plans, regional health plans, TPAs and millions of healthcare providers and consumers across our platform of solutions. Zelis sees across the system to identify, optimize, and solve problems holistically with technology built by healthcare experts – driving real, measurable results for clients. A Little About You You bring a unique blend of personality and professional expertise to your work, inspiring others with your passion and dedication. Your career is a testament to your diverse experiences, community involvement, and the valuable lessons you've learned along the way. You are more than just your resume; you are a reflection of your achievements, the knowledge you've gained, and the personal interests that shape who you are. Position Overview Zelis is seeking a Data Scientist to join our growing Analytics team supporting marketing and commercial strategy across all business units. This is a strategic, net-new role designed to expand our enterprise-wide use of data science to drive insights, accelerate growth, and optimize decision-making. You will work cross-functionally with marketing, sales, product, and client teams to unlock the value of data through advanced analytics, modeling, and impactful visual storytelling. This role is ideal for someone who is hands-on, deeply analytical, and excited by the challenge of building scalable analytics solutions that inform go-to-market strategies and campaign performance. Position Overview What You’ll Do Key Responsibilities: End-to-End Data Science Execution: Own the full analytics lifecycle—from ingesting and cleaning raw data to developing predictive models, running statistical analyses, and translating findings into actionable insights for business leaders. Cross-Functional Impact: Partner with stakeholders across marketing, sales, and product teams to uncover opportunities through segmentation, attribution, funnel optimization, and campaign performance analysis. Predictive Modeling & Segmentation: Develop customer and account-level models to predict behavior, inform targeting strategies, and personalize engagement across digital and direct channels. Advanced Visualization & Dashboarding: Build interactive dashboards (Power BI preferred) that surface insights clearly and intuitively to both technical and non-technical users. Integrate AI-based tools to accelerate insight delivery. Data Quality & Governance: Proactively identify data gaps and inconsistencies across systems (e.g., CRM, campaign tools, external sources). Work with internal partners to resolve data quality issues and improve governance standards. Innovation & Tooling: Continuously evaluate and recommend new data sources, technologies, and techniques—including generative AI applications—to improve analytical workflows and business outcomes. What You’ll Bring to Zelis Qualifications 3+ years of hands-on experience in a data science or advanced analytics role, ideally supporting marketing, sales, or commercial operations Proficiency in Python and SQL required; experience with R is a plus Strong experience using data visualization platforms such as Power BI or Tableau to develop executive-level dashboards Experience working with CRM and marketing systems such as Hubspot, Salesforce, LinkedIn Campaign Manager, or similar Demonstrated ability to drive projects independently and explain complex concepts to business stakeholders Strong understanding of data modeling, A/B testing, and predictive analytics Exceptional attention to data integrity, structure, and usability across multiple sources Experience in healthcare is preferred but not required Preferred Education Master’s degree in a quantitative field such as Statistics, Computer Science, Marketing Analytics, or Business Analytics (or equivalent real-world experience) Please note at this time we are unable to proceed with candidates who require visa sponsorship now or in the future. Location and Workplace Flexibility We have offices in Atlanta GA, Boston MA, Morristown NJ, Plano TX, St. Louis MO, St. Petersburg FL, and Hyderabad, India. We foster a hybrid and remote friendly culture, and all our employee's work locations are based on the needs of the position and determined by the Leadership team. In-office work and activities, if applicable, vary based on the work and team objectives in accordance with Company policies. Equal Employment Opportunity Zelis is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. We welcome applicants from all backgrounds and encourage you to apply even if you don’t meet 100% of the qualifications for the role. We believe in the value of diverse perspectives and experiences and are committed to building an inclusive workplace for all. Accessibility Support We are dedicated to ensuring our application process is accessible to all candidates. If you are a qualified individual with a disability or a disabled veteran and require a reasonable accommodation with any part of the application and/or interview process, please email TalentAcquisition@zelis.com. Disclaimer We are an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law. The above statements are intended to describe the general nature and level of work being performed by people assigned to this classification. They are not to be construed as an exhaustive list of all responsibilities, duties, and skills required of personnel so classified. All personnel may be required to perform duties outside of their normal responsibilities, duties, and skills from time to time. Zelis is modernizing the healthcare financial experience across payers, providers, and healthcare consumers. We serve more than 750 payers, including the top five national health plans, regional health plans, TPAs and millions of healthcare providers and consumers across our platform of solutions. Zelis sees across the system to identify, optimize, and solve problems holistically with technology built by healthcare experts – driving real, measurable results for clients.",2025-06-26T00:00:00.000Z,2025-07-25,,,True,['Generative AI'],Generative AI: Evaluating and integrating generative AI applications to enhance analytical workflows and accelerate insight delivery.,"['Predictive Modeling', 'Statistical Analysis', 'Segmentation', 'Attribution Analysis', 'A/B Testing', 'Data Cleaning and Ingestion', 'Data Quality and Governance', 'Python', 'SQL', 'R', 'Power BI', 'Tableau', 'CRM and Marketing Systems', 'Advanced Analytics']","Predictive Modeling: Developing models to predict customer and account behavior to inform targeting and personalization strategies.; Statistical Analysis: Running statistical analyses to extract actionable insights from marketing and commercial data.; Segmentation: Uncovering customer segments to optimize marketing and sales strategies.; Attribution Analysis: Analyzing marketing funnel and campaign performance to attribute outcomes to specific actions.; A/B Testing: Using controlled experiments to evaluate marketing strategies and campaign effectiveness.; Data Cleaning and Ingestion: Handling raw data preparation to ensure quality and usability for analytics.; Data Quality and Governance: Identifying and resolving data inconsistencies and improving governance standards across systems.; Python: Using Python programming for data manipulation, analysis, and modeling.; SQL: Querying and managing data stored in relational databases.; R: Optional use of R for statistical computing and data analysis.; Power BI: Building interactive dashboards to visualize insights for technical and non-technical stakeholders.; Tableau: Alternative data visualization platform for executive-level dashboard development.; CRM and Marketing Systems: Working with data from platforms like Hubspot, Salesforce, and LinkedIn Campaign Manager to support analytics.; Advanced Analytics: Applying sophisticated analytical techniques to drive marketing and commercial decision-making."
y9FYKoONTLbfhN-DAAAAAA==,Lead Data Scientist - Full-time,"Do you have a strong background in machine learning and deep learning? Are you interested in utilizing your data science skills and working with a small team in a fast-paced environment to achieve strategic mission goals? If so, Deloitte has an exciting opportunity for you!

The Team:

The GPS GSi group at Deloitte is dedicated to driving innovation and efficiency through advanced data science and business intelligence solutions. Our team collaborates closely with Enabling Area professionals to develop and implement cutting-edge machine learning, deep learning, and generative AI initiatives. We thrive in a dynamic environment where teamwork and independent problem-solving are key to achieving our strategic mission goals. Join us to be part of a small, agile team that is at the forefront of transforming decision-making processes and delivering impactful solutions.

Recruiting for this role ends on July 31st, 2025.

What You'll Do:

As a member of our GPS GSi group, you will play a crucial role in the development and maintenance of our data science and business intelligence solutions. This role will specialize in assisting with machine learning, deep learning, and generative AI initiatives that will be utilized by Enabling Area professionals to enhance and expedite decision-making. You will provide expertise within and across business teams, demonstrate the ability to work independently, and apply problem-solving skills to resolve complex issues.

+ Lead and participate in developing data science products, transforming client needs into quantifiable solutions.

+ Independently carry out tasks, using critical thinking and problem-solving skills to devise effective solutions.

+ Design, train, and deploy machine learning and deep learning models on platforms like AWS, Databricks, and Dataiku.

+ Develop and advise on Large Language Model (LLM) solutions for enterprise-wide documentation, including RAG, CPT, and SFT.

+ Utilize MLOps pipelines, including containerization (Docker) and CI/CD, for training and deploying models.

+ Write clean, well-commented code for easy collaboration and maintain structured project documentation using GitHub and/or Jira.

Qualifications

Required skills:

+ Bachelor's Degree in Statistics, Mathematics, Computer Science, Engineering, or another analytical field.

+ 6+ years of experience in data science, with deep knowledge of Python, machine learning, deep learning, and related packages (e.g., sklearn, TensorFlow, PyTorch). Proven ability to lead data science projects from inception to deployment.

+ Strong knowledge of Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG).

+ Familiarity with AWS, Databricks, and/or Dataiku platforms.

+ Working knowledge of MLOps, including containerization (e.g., Docker).

+ Strong organizational skills, with clear project documentation and the ability to write clean code.

+ Familiarity with agile project methodology and project development lifecycle.

+ Experience with GitHub for version control.

+ Ability to manage multiple detailed tasks and responsibilities simultaneously, meeting deadlines and objectives accurately.

+ Must be legally authorized to work in the United States without employer sponsorship, now or in the future.

+ Ability to travel 10%-25%, on average, based on the work you do and the clients and industries/sectors you serve

Preferred Skills:

+ Master's Degree in Statistics, Mathematics, Computer Science, Engineering, or another analytical field, or equivalent direct work experience.

+ Significant experience with MLOps and associated serving frameworks (e.g., Flask, FastAPI) and orchestration pipelines (e.g., SageMaker Pipelines, Step Functions, Metaflow).

+ Significant experience working with open-source LLMs, including serving via TGI/vLLM and performing Continued Pre-training (CPT) and/or Supervised Fine-tuning (SFT).

+ Experience using various AWS Services (e.g., Textract, Transcribe, Lambda, etc.).

+ Proficiency in basic front-end web development (e.g., Streamlit).

+ Knowledge of Object-Oriented Programming (OOP) concepts.

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $97,600 to $179,900

You may also be eligible to participate in a discretionary annual incentive program, subject to the rules governing the program, whereby an award, if any, depends on various factors, including, without limitation, individual and organizational performance.

Information for applicants with a need for accommodation: https://www2.deloitte.com/us/en/pages/careers/articles/join-deloitte-assistance-for-disabled-applicants.html

EA_ExpHire, EA_GPS_ExpHire, #LI-JK2

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.

Do you have a strong background in machine learning and deep learning? Are you interested in utilizing your data science skills and working with a small team in a fast-paced environment to achieve strategic mission goals? If so, Deloitte has an exciting opportunity for you!

The Team:

The GPS GSi group at Deloitte is dedicated to driving innovation and efficiency through advanced data science and business intelligence solutions. Our team collaborates closely with Enabling Area professionals to develop and implement cutting-edge machine learning, deep learning, and generative AI initiatives. We thrive in a dynamic environment where teamwork and independent problem-solving are key to achieving our strategic mission goals. Join us to be part of a small, agile team that is at the forefront of transforming decision-making processes and delivering impactful solutions.

Recruiting for this role ends on July 31st, 2025.

What You'll Do:

As a member of our GPS GSi group, you will play a crucial role in the development and maintenance of our data science and business intelligence solutions. This role will specialize in assisting with machine learning, deep learning, and generative AI initiatives that will be utilized by Enabling Area professionals to enhance and expedite decision-making. You will provide expertise within and across business teams, demonstrate the ability to work independently, and apply problem-solving skills to resolve complex issues.

+ Lead and participate in developing data science products, transforming client needs into quantifiable solutions.

+ Independently carry out tasks, using critical thinking and problem-solving skills to devise effective solutions.

+ Design, train, and deploy machine learning and deep learning models on platforms like AWS, Databricks, and Dataiku.

+ Develop and advise on Large Language Model (LLM) solutions for enterprise-wide documentation, including RAG, CPT, and SFT.

+ Utilize MLOps pipelines, including containerization (Docker) and CI/CD, for training and deploying models.

+ Write clean, well-commented code for easy collaboration and maintain structured project documentation using GitHub and/or Jira.

Qualifications

Required skills:

+ Bachelor's Degree in Statistics, Mathematics, Computer Science, Engineering, or another analytical field.

+ 6+ years of experience in data science, with deep knowledge of Python, machine learning, deep learning, and related packages (e.g., sklearn, TensorFlow, PyTorch). Proven ability to lead data science projects from inception to deployment.

+ Strong knowledge of Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG).

+ Familiarity with AWS, Databricks, and/or Dataiku platforms.

+ Working knowledge of MLOps, including containerization (e.g., Docker).

+ Strong organizational skills, with clear project documentation and the ability to write clean code.

+ Familiarity with agile project methodology and project development lifecycle.

+ Experience with GitHub for version control.

+ Ability to manage multiple detailed tasks and responsibilities simultaneously, meeting deadlines and objectives accurately.

+ Must be legally authorized to work in the United States without employer sponsorship, now or in the future.

+ Ability to travel 10%-25%, on average, based on the work you do and the clients and industries/sectors you serve

Preferred Skills:

+ Master's Degree in Statistics, Mathematics, Computer Science, Engineering, or another analytical field, or equivalent direct work experience.

+ Significant experience with MLOps and associated serving frameworks (e.g., Flask, FastAPI) and orchestration pipelines (e.g., SageMaker Pipelines, Step Functions, Metaflow).

+ Significant experience working with open-source LLMs, including serving via TGI/vLLM and performing Continued Pre-training (CPT) and/or Supervised Fine-tuning (SFT).

+ Experience using various AWS Services (e.g., Textract, Transcribe, Lambda, etc.).

+ Proficiency in basic front-end web development (e.g., Streamlit).

+ Knowledge of Object-Oriented Programming (OOP) concepts.

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $97,600 to $179,900

You may also be eligible to participate in a discretionary annual incentive program, subject to the rules governing the program, whereby an award, if any, depends on various factors, including, without limitation, individual and organizational performance.

Information for applicants with a need for accommodation: https://www2.deloitte.com/us/en/pages/careers/articles/join-deloitte-assistance-for-disabled-applicants.html

EA_ExpHire, EA_GPS_ExpHire, #LI-JK2

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.",2025-07-25T08:00:00.000Z,2025-07-25,"[""Bachelor's Degree in Statistics, Mathematics, Computer Science, Engineering, or another analytical field"", '6+ years of experience in data science, with deep knowledge of Python, machine learning, deep learning, and related packages (e.g., sklearn, TensorFlow, PyTorch)', 'Proven ability to lead data science projects from inception to deployment', 'Strong knowledge of Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG)', 'Familiarity with AWS, Databricks, and/or Dataiku platforms', 'Working knowledge of MLOps, including containerization (e.g., Docker)', 'Strong organizational skills, with clear project documentation and the ability to write clean code', 'Familiarity with agile project methodology and project development lifecycle', 'Experience with GitHub for version control', 'Ability to manage multiple detailed tasks and responsibilities simultaneously, meeting deadlines and objectives accurately', 'Must be legally authorized to work in the United States without employer sponsorship, now or in the future', 'Ability to travel 10%-25%, on average, based on the work you do and the clients and industries/sectors you serve', 'All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law', 'Do you have a strong background in machine learning and deep learning?', ""Bachelor's Degree in Statistics, Mathematics, Computer Science, Engineering, or another analytical field"", '6+ years of experience in data science, with deep knowledge of Python, machine learning, deep learning, and related packages (e.g., sklearn, TensorFlow, PyTorch)', 'Proven ability to lead data science projects from inception to deployment', 'Strong knowledge of Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG)', 'Familiarity with AWS, Databricks, and/or Dataiku platforms', 'Working knowledge of MLOps, including containerization (e.g., Docker)', 'Strong organizational skills, with clear project documentation and the ability to write clean code', 'Familiarity with agile project methodology and project development lifecycle', 'Experience with GitHub for version control', 'Ability to manage multiple detailed tasks and responsibilities simultaneously, meeting deadlines and objectives accurately', 'Must be legally authorized to work in the United States without employer sponsorship, now or in the future', 'Ability to travel 10%-25%, on average, based on the work you do and the clients and industries/sectors you serve']","['As a member of our GPS GSi group, you will play a crucial role in the development and maintenance of our data science and business intelligence solutions', 'This role will specialize in assisting with machine learning, deep learning, and generative AI initiatives that will be utilized by Enabling Area professionals to enhance and expedite decision-making', 'You will provide expertise within and across business teams, demonstrate the ability to work independently, and apply problem-solving skills to resolve complex issues', 'Lead and participate in developing data science products, transforming client needs into quantifiable solutions', 'Independently carry out tasks, using critical thinking and problem-solving skills to devise effective solutions', 'Design, train, and deploy machine learning and deep learning models on platforms like AWS, Databricks, and Dataiku', 'Develop and advise on Large Language Model (LLM) solutions for enterprise-wide documentation, including RAG, CPT, and SFT', 'Utilize MLOps pipelines, including containerization (Docker) and CI/CD, for training and deploying models', 'Write clean, well-commented code for easy collaboration and maintain structured project documentation using GitHub and/or Jira', 'As a member of our GPS GSi group, you will play a crucial role in the development and maintenance of our data science and business intelligence solutions', 'This role will specialize in assisting with machine learning, deep learning, and generative AI initiatives that will be utilized by Enabling Area professionals to enhance and expedite decision-making', 'You will provide expertise within and across business teams, demonstrate the ability to work independently, and apply problem-solving skills to resolve complex issues', 'Lead and participate in developing data science products, transforming client needs into quantifiable solutions', 'Independently carry out tasks, using critical thinking and problem-solving skills to devise effective solutions', 'Design, train, and deploy machine learning and deep learning models on platforms like AWS, Databricks, and Dataiku', 'Develop and advise on Large Language Model (LLM) solutions for enterprise-wide documentation, including RAG, CPT, and SFT', 'Utilize MLOps pipelines, including containerization (Docker) and CI/CD, for training and deploying models', 'Write clean, well-commented code for easy collaboration and maintain structured project documentation using GitHub and/or Jira']",True,"['Large Language Models', 'Retrieval-Augmented Generation', 'Continued Pre-Training', 'Supervised Fine-Tuning', 'Generative AI', 'PyTorch', 'TensorFlow', 'TGI/vLLM']","Large Language Models: Develop and advise on enterprise-wide documentation solutions using LLMs to enhance decision-making.; Retrieval-Augmented Generation: Technique used with LLMs to improve information retrieval and generation for enterprise documentation.; Continued Pre-Training: Process of further training LLMs on domain-specific data to improve performance for enterprise applications.; Supervised Fine-Tuning: Technique to fine-tune LLMs with labeled data to optimize them for specific enterprise use cases.; Generative AI: Initiatives involving creation of AI-generated content and solutions using advanced models like LLMs.; PyTorch: Deep learning framework used specifically for developing and fine-tuning neural network models including LLMs.; TensorFlow: Deep learning framework applied to build and deploy neural network models, including those for generative AI.; TGI/vLLM: Open-source serving frameworks used to deploy and serve large language models efficiently.","['Machine Learning', 'Deep Learning', 'Python', 'Scikit-learn', 'MLOps', 'Containerization', 'CI/CD', 'AWS', 'Databricks', 'Dataiku', 'GitHub', 'Business Intelligence', 'Agile Project Methodology', 'Flask', 'FastAPI', 'SageMaker Pipelines', 'Step Functions', 'Metaflow', 'Object-Oriented Programming', 'Streamlit']","Machine Learning: Used for developing predictive models and data science products to transform client needs into quantifiable solutions.; Deep Learning: Applied to design, train, and deploy complex neural network models on platforms like AWS, Databricks, and Dataiku.; Python: Primary programming language used for implementing machine learning and deep learning models, including libraries like sklearn.; Scikit-learn: A Python package used for traditional machine learning model development and data science tasks.; MLOps: Practices and pipelines including containerization and CI/CD used for training and deploying machine learning and deep learning models.; Containerization: Use of Docker to package and deploy machine learning and deep learning models efficiently within MLOps pipelines.; CI/CD: Continuous Integration and Continuous Deployment pipelines used to automate model training and deployment processes.; AWS: Cloud platform used for deploying machine learning and deep learning models and leveraging services like SageMaker Pipelines.; Databricks: Platform used for collaborative data science, model training, and deployment.; Dataiku: Data science platform used for building and deploying machine learning and deep learning models.; GitHub: Version control system used for managing code and project documentation collaboratively.; Business Intelligence: Solutions developed and maintained to support data-driven decision-making processes.; Agile Project Methodology: Project management approach used to organize and deliver data science and machine learning projects efficiently.; Flask: Serving framework used to deploy machine learning models as APIs.; FastAPI: Modern serving framework used for deploying machine learning models with high performance.; SageMaker Pipelines: AWS orchestration service used to automate machine learning workflows and model deployment.; Step Functions: AWS orchestration service used to coordinate components of machine learning pipelines.; Metaflow: Workflow orchestration tool used to manage machine learning pipelines and data science workflows.; Object-Oriented Programming: Programming paradigm knowledge applied to write clean, maintainable code for data science projects.; Streamlit: Front-end web development tool used to create interactive data science applications and dashboards."
VPzUecK83U6OIqSGAAAAAA==,Adjunct Professor of Data Science,"Job Number: 202300030

Description

ABOUT RAMAPO COLLEGE:

Ramapo College of New Jersey (RCNJ) develops ethical leaders who serve as change agents across all sectors. The College's unique interdisciplinary academic structure, its liberal arts core, its size (approximately 5,500 students), and its setting in the foothills of the Ramapo Mountains on the New Jersey/New York border provide an optimal environment for individualized, student-centered learning and leadership development. RCNJ's designation as ""New Jersey's Public Liberal Arts College"" by the State legislature is the foundation from which the College's commitment to an accessible and transformative undergraduate and graduate education is realized.

Established in 1969, CondeNast Traveler named Ramapo one of the 50 Most Beautiful College Campuses in America. The barrier-free campus occupies 300 acres and is home to 52 bachelor's degree programs spanning the arts, business, data science, humanities, education, nursing, social work, social sciences, and the sciences. Ramapo College boasts an average student/faculty ratio of 16:1 and an average class size of 21; affording students the opportunity to develop close ties to the College's exceptional faculty. In addition, the College offers graduate programs leading to master's degrees in Accounting, Applied Mathematics, Business Administration, Contemporary Instructional Design, Computer Science, Creative Music Technology, Data Science, Educational Leadership, Nursing, Social Work, and Special Education, as well as a Doctor of Nursing Practice. Every degree program is designed and delivered through the collaborative and interdisciplinary efforts of student-centered faculty scholars and staff who are committed to serving the public good through the delivery of an academically rigorous, inclusive, and a transformative collegiate experience. Ramapo is ranked #1 among New Jersey public institutions by College Choice and is recognized as the State's top college on the list of Best Disability Schools by Great Value Colleges. Further commendations include designation as a ""Military Friendly College"" in Victory Media's Guide to Military Friendly Schools, and as a leading college by U.S. News & World Report, Kiplinger's, Princeton Review, and Money Magazine, among others.

Examples of Duties

JOB SUMMARY:

Ramapo College of New Jersey is searching for an Adjunct Professor of Data Science to teach one or two sections on an as needed basis. Courses may include Graduate Level Statistics and Probability.

Applications are being accepted by logging on to www.ramapojobs.com. Attach resume, cover letter, letter discussing teaching philosophy. All applications must be completed online. Hard copies of resumes and/or applications will not be accepted. To request accommodations, call (201) 684-7506.
Compensation:
Fall 2025/Spring 2026 Semesters- $2,100 per credit

Qualifications

REQUIREMENTS:

Masters's degree with relevant teaching experience required.

Supplemental Information

EEO Statement:

Ramapo College is an Affirmative Action/Equal Employment Opportunity Employer. Ramapo is committed to academic excellence through interdisciplinary and experiential learning and international and intercultural understanding. Ramapo is also committed to fostering a community that inspires a culture of inclusivity. Examples can be found in its mission statement, strategic plans, degree and course offerings and other programs. Ramapo's environment is welcoming, dedicated to social justice, and respectful of freedom of expression.",,2025-07-25,"['Every degree program is designed and delivered through the collaborative and interdisciplinary efforts of student-centered faculty scholars and staff who are committed to serving the public good through the delivery of an academically rigorous, inclusive, and a transformative collegiate experience', 'Courses may include Graduate Level Statistics and Probability', 'Hard copies of resumes and/or applications will not be accepted', ""Masters's degree with relevant teaching experience required""]",['Ramapo College of New Jersey is searching for an Adjunct Professor of Data Science to teach one or two sections on an as needed basis'],False,[],,"['Statistics', 'Probability']","Statistics: Graduate level statistics is mentioned as a course to be taught, indicating a focus on statistical methods relevant to data science education.; Probability: Probability is included as a graduate-level course topic, highlighting foundational concepts important for data science and statistical modeling."
AewwRofIWcwySa44AAAAAA==,Data Scientist/Curator,"Data Curator 4 month contract assignment Cambridge, MA (onsite) Required/Most Important Skills:Mass spectrometry based proteomics data R/Python Metadata capture, versioning control and curation POSITION SUMMARY:We are looking for a data scientist/curator who will help annotate proteomics data at the MLCS. The contractor will apply proteomics related knowledge with bioinformatics skills to help curate and register high dimensional proteomics data into internal data registry. The deliverable will facilitate data processing, analysis, machine learning with high reproducibility and scalability, as well as data management and visualization.EDUCATION AND EXPERIENCE:B.S or advanced degree in Bioinformatics, Biology, Molecular Cell Biology, Biochemistry, Analytical Chemistry or related fields.TECHNICAL SKILLS REQUIREMENTS:Familiarity with mass spectrometry based proteomics data type is strongly preferred. Wet-lab experience in Biology, Biochemistry, Molecular Biology, Analytical Chemistry or related field is strongly preferred. Knowledge of relational or graph database is preferred. Experience in scripting languages like R/Python is desirable. Familiarity with workflow languages (Nextflow, CWL, etc) is desirable. Familiarity with shell scripting, cluster or cloud computing infrastructure (AWS, GCP) is desirable.System One, and its subsidiaries including Joulé, ALTA IT Services, and Mountain Ltd., are leaders in delivering outsourced services and workforce solutions across North America. We help clients get work done more efficiently and economically, without compromising quality. System One not only serves as a valued partner for our clients, but we offer eligible employees health and welfare benefits coverage options including medical, dental, vision, spending accounts, life insurance, voluntary plans, as well as participation in a 401(k) plan.System One is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, age, national origin, disability, family care or medical leave status, genetic information, veteran status, marital status, or any other characteristic protected by applicable federal, state, or local law.Ref: #568-Clinical",2025-07-22T00:00:00.000Z,2025-07-25,"['EDUCATION AND EXPERIENCE:B.S or advanced degree in Bioinformatics, Biology, Molecular Cell Biology, Biochemistry, Analytical Chemistry or related fields']","['Data Curator 4 month contract assignment Cambridge, MA (onsite) Required/Most Important Skills:Mass spectrometry based proteomics data R/Python Metadata capture, versioning control and curation POSITION SUMMARY:We are looking for a data scientist/curator who will help annotate proteomics data at the MLCS', 'The contractor will apply proteomics related knowledge with bioinformatics skills to help curate and register high dimensional proteomics data into internal data registry', 'The deliverable will facilitate data processing, analysis, machine learning with high reproducibility and scalability, as well as data management and visualization']",True,[],,"['Mass Spectrometry Proteomics Data', 'R', 'Python', 'Metadata Capture and Versioning Control', 'Relational and Graph Databases', 'Workflow Languages', 'Cluster and Cloud Computing Infrastructure', 'Machine Learning', 'Data Management and Visualization']","Mass Spectrometry Proteomics Data: Used for annotating and curating high-dimensional proteomics data relevant to biological and biochemical analysis.; R: Scripting language employed for data processing, analysis, and visualization of proteomics datasets.; Python: Scripting language used for data curation, processing, and machine learning tasks on proteomics data.; Metadata Capture and Versioning Control: Techniques applied to ensure accurate annotation and reproducibility of proteomics data.; Relational and Graph Databases: Preferred database technologies for storing and managing curated proteomics data.; Workflow Languages: Nextflow and CWL used to automate and manage data processing pipelines for proteomics data.; Cluster and Cloud Computing Infrastructure: AWS and GCP platforms utilized to support scalable data processing and machine learning workflows.; Machine Learning: Applied to analyze proteomics data with emphasis on reproducibility and scalability.; Data Management and Visualization: Practices to organize, curate, and visually represent proteomics data for better insight and usability."
FtbFbUPhXlyFkXaXAAAAAA==,Data Scientist,"State Farm is looking for an experienced and talented Data Scientist to join our team. We are searching for an individual who is passionate about working with and analyzing data to uncover trends and develop insights for our business. Our ideal candidate is a self-starter with a keen eye for detail and excellent problem-solving skills.Required Qualifications:• A Bachelor's degree in Computer Science, Statistics, Mathematics, or related field; advanced degree preferred• Proven experience in data analysis and data mining• Proficiency in SQL, Python, and other programming languages• Knowledge of machine learning, predictive analytics, and natural language processing• Ability to work independently and in a team setting• Ability to communicate technical concepts to non-technical audiences• Understanding of data visualization tools and techniques• Ability to work with large, complex datasets• Attention to detail and accuracy• Experience with data warehousing and big data technologies

State Farm is an Equal Opportunity Employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. We do not discriminate based upon race, religion, color, national origin, sex, sexual orientation, gender identity, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.",,2025-07-25,['Our ideal candidate is a self-starter with a keen eye for detail and excellent problem-solving skills'],,True,[],,"['SQL', 'Python', 'Machine Learning', 'Predictive Analytics', 'Natural Language Processing', 'Data Visualization', 'Data Warehousing', 'Big Data Technologies']","SQL: Used for querying and managing large datasets as part of data analysis tasks.; Python: Programming language employed for data analysis, data mining, and implementing machine learning models.; Machine Learning: Applied to develop predictive analytics models and uncover trends from data.; Predictive Analytics: Used to forecast business outcomes based on historical data patterns.; Natural Language Processing: Utilized to analyze and extract insights from text data.; Data Visualization: Techniques and tools used to communicate data insights effectively to stakeholders.; Data Warehousing: Managing and storing large volumes of data to support analysis and reporting.; Big Data Technologies: Technologies used to handle and process large, complex datasets."
iYDM8RABtSBWYFzLAAAAAA==,Data Scientist - Top Secret with CI or FS Poly,"Overview

Paradyme, a CATHEXIS Company is a rapidly growing government technology leader that puts service first, for its customers, its team and the communities it supports. We harness DevSecOps and Agile development processes to deliver exceptional results for digital transformations. With headquarters office in Tysons Corner, VA, Our award-winning culture sets it apart through its team's deep commitment to service and collaboration with its customers, each other and the community. Learn more at www.paradyme.us .
Responsibilities

Paradyme, a CATHEXIS Company is hiring a Top Secret clearance with CI or FS Polygraph Data Scientist to support mission critical programs.

The Data Scientist will work directly with data scientists, software engineers, and subject matter experts in the definition of new analytics capabilities able to provide our federal customers with the information they need to make proper decisions and enable their digital transformation. Duties include:
• Research, design, implement, and deploy Machine Learning algorithms for enterprise applications.
• Assist and enable federal customers to build their own applications.
• Contribute to the design and implementation of new features.

Qualifications:
• Top Secret clearance with CI or FS Poly or above.
• Bachelor's degree in Computer Science, Electrical Engineering, Statistics, or equivalent fields required.
• MS or PhD in Computer Science, Electrical Engineering, Statistics, or equivalent fields preferred.
• Minimum 2 years relevant work experience preferred.
• Excellent programming skills in Python.
• Applied Machine Learning experience (regression and classification, supervised, and unsupervised learning).
• Strong mathematical background (linear algebra, calculus, probability, and statistics).
• Experience with scalable ML (MapReduce, streaming).
• Ability to drive a project and work both independently and in a team.
• Smart, motivated, can-do attitude, and seeks to make a difference.
• Excellent verbal and written communication.

Nice to Have:
• Real passion for developing team-oriented solutions to complex engineering problems.
• Thrive in an autonomous, empowering and exciting environment.
• Great verbal and written communication skills to collaborate multi-functionally and improve scalability.
• Interest in committing to a fun, friendly, expansive, and intellectually stimulating environment.
• Hands-on experience deploying and operating applications using IaaS and PaaS on major cloud providers, such as Amazon AWS, Microsoft Azure, or Google Cloud Services.
• Experience with deep learning, natural language processing, computer vision, or reinforcement learning.
• Conveys highly technical concepts and information in written form to technical and non-technical audiences.
• The ability to work on multiple concurrent projects is essential. Strong self -motivation and the ability to work with minimal supervision.
• Must be a team-oriented individual, energetic, result & delivery oriented, with a keen interest on quality and the ability to meet deadlines.
• Ability to work in an agile environment

Physical Requirements: These are the essential physical requirements needed to successfully perform the job.
• Sedentary work.
• Requires sitting up to 8 hours per day.
• May require lifting up to 5 pounds unassisted.
• Fine repetitive motor skills with hands, wrists, and fingers in coordination with eyes.
• Hearing, speaking, and vision: Adequate to perform job duties and communicate in person, via video, and telephone. Includes reading information from printed sources and computer screens.
• Other: Work may be performed in an office environment, which may involve frequent contact with staff and the public. Work may be stressful at times.

EEO Statement

Paradyme, a CATHEXIS Company is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law. If you are an individual with a disability and would like to request a reasonable accommodation as part of the employment selection process, please contact HR@paradyme.us
Employment Type: OTHER",,2025-07-25,"['Top Secret clearance with CI or FS Poly or above', ""Bachelor's degree in Computer Science, Electrical Engineering, Statistics, or equivalent fields required"", 'Excellent programming skills in Python', 'Applied Machine Learning experience (regression and classification, supervised, and unsupervised learning)', 'Strong mathematical background (linear algebra, calculus, probability, and statistics)', 'Experience with scalable ML (MapReduce, streaming)', 'Ability to drive a project and work both independently and in a team', 'Smart, motivated, can-do attitude, and seeks to make a difference', 'Excellent verbal and written communication', 'Real passion for developing team-oriented solutions to complex engineering problems', 'Thrive in an autonomous, empowering and exciting environment', 'Great verbal and written communication skills to collaborate multi-functionally and improve scalability', 'Interest in committing to a fun, friendly, expansive, and intellectually stimulating environment', 'Hands-on experience deploying and operating applications using IaaS and PaaS on major cloud providers, such as Amazon AWS, Microsoft Azure, or Google Cloud Services', 'Experience with deep learning, natural language processing, computer vision, or reinforcement learning', 'Conveys highly technical concepts and information in written form to technical and non-technical audiences', 'The ability to work on multiple concurrent projects is essential', 'Strong self -motivation and the ability to work with minimal supervision', 'Must be a team-oriented individual, energetic, result & delivery oriented, with a keen interest on quality and the ability to meet deadlines', 'Ability to work in an agile environment', 'Physical Requirements: These are the essential physical requirements needed to successfully perform the job', 'Requires sitting up to 8 hours per day', 'May require lifting up to 5 pounds unassisted', 'Fine repetitive motor skills with hands, wrists, and fingers in coordination with eyes', 'Hearing, speaking, and vision: Adequate to perform job duties and communicate in person, via video, and telephone']","['The Data Scientist will work directly with data scientists, software engineers, and subject matter experts in the definition of new analytics capabilities able to provide our federal customers with the information they need to make proper decisions and enable their digital transformation', 'Research, design, implement, and deploy Machine Learning algorithms for enterprise applications', 'Assist and enable federal customers to build their own applications', 'Contribute to the design and implementation of new features', 'Sedentary work', 'Includes reading information from printed sources and computer screens', 'Other: Work may be performed in an office environment, which may involve frequent contact with staff and the public']",True,"['Deep Learning', 'Natural Language Processing', 'Computer Vision', 'Reinforcement Learning']",Deep Learning: Experience with neural network-based models for advanced analytics including computer vision and natural language processing.; Natural Language Processing: Applied AI techniques for processing and analyzing human language data as part of advanced machine learning projects.; Computer Vision: Use of AI methods to interpret and analyze visual data for mission-critical applications.; Reinforcement Learning: Applied AI approach for training models based on feedback from interactions with the environment to improve decision-making.,"['Machine Learning', 'Supervised Learning', 'Unsupervised Learning', 'Regression Models', 'Classification Models', 'Scalable Machine Learning', 'Python Programming', 'Mathematical Foundations', 'Cloud Computing Platforms']","Machine Learning: Used for designing, implementing, and deploying algorithms such as regression and classification to support enterprise applications and analytics capabilities.; Supervised Learning: Applied in building predictive models where labeled data is used to train algorithms for classification and regression tasks.; Unsupervised Learning: Used for discovering patterns and insights from unlabeled data to enhance analytics capabilities.; Regression Models: Employed as part of machine learning techniques to predict continuous outcomes for federal customer applications.; Classification Models: Used to categorize data points into classes to support decision-making in mission-critical programs.; Scalable Machine Learning: Experience with distributed computing frameworks like MapReduce and streaming to handle large-scale data processing.; Python Programming: Primary programming language used for developing machine learning models and data science solutions.; Mathematical Foundations: Strong background in linear algebra, calculus, probability, and statistics to support algorithm development and data analysis.; Cloud Computing Platforms: Hands-on experience deploying and operating applications on IaaS and PaaS services from AWS, Azure, or Google Cloud to support scalable data solutions."
9rv1R7t03lIBqnisAAAAAA==,"Senior Director, Data Science - Debit Routing","Job Description Position Summary: The Senior Director of Data Science – Dynamic Routing will lead the strategy and execution of intelligent transaction routing and pricing optimization. This position will lead a team of ~15 data scientists tasked with developing and operationalizing advanced machine learning and algorithmic solutions that optimize interchange fees, enhance transaction approval rates, and drive margin expansion for the business and its merchants. As the public-facing ""face"" of our transaction routing solutions, the Senior Director will play a crucial role in client engagements, articulating complex data science concepts in an accessible manner to explain trends and actions taken in routing. This leader will collaborate closely with business leaders to tailor strategies on a customer-by-customer basis, ensuring alignment with broader business goals. This leader will work in partnership with Product and Engineering teams to craft the future state vision for transaction routing solutions, ensuring the development of innovative products that meet evolving market demands. This role requires a deep understanding of data science methodologies and the ability to translate technical insights into strategic business actions, fostering strong relationships with clients and internal stakeholders to drive success. Key Responsibilities: Strategic Leadership: Own the data science roadmap for dynamic routing and interchange optimization across U.S. domestic, cross-border payment flows, and extension of dynamic routing globally. Build and deploy ML/AI models that inform routing decisions based on issuer behavior, cost structures, geo/location, network rules and eligibility, and approval likelihood. Develop scalable, low-latency algorithms integrated into real-time payment decisioning engines. Design and validate experiments to quantify the financial impact of routing and interchange strategies (e.g., A/B tests, multi-armed bandits). Model complex cost structures (interchange, scheme fees, FX margins) to recommend optimal routing paths for each transaction. Team & Capability Development: Build, lead, and mentor a multidisciplinary team of ~15 data scientists and data analysts. Mentor junior team members on best practices in modeling, experimentation, and payments domain knowledge. Foster a culture of innovation, experimentation, and continuous learning. Cross-Functional Collaboration: Collaborate with Product and Global Network Partnership teams to align optimization strategies with commercial agreements and market coverage. Work closely with Finance, Product, and Worldpay’s Lines of Business to report on savings, approval uplift, and margin impact. Communicate complex analytical concepts to non-technical stakeholders effectively. Key Areas of Focus: Ensure models meet requirements for scalability, latency, explainability, and regulatory compliance. Work with data governance and legal teams to ensure compliance with data privacy regulations (e.g., PCI-DSS, GDPR). Optimize transaction paths across processors, networks (Visa, Mastercard, Regional Networks), and endpoints to maximize approval rates and minimize costs. Use data-driven insights to steer transactions toward more favorable interchange categories or fee structures. Model historical issuer behavior (approval decline patterns, time-of-day trends, geo-specific sensitivity). Monitor and optimize for performance, latency, and reliability across network routes. Performance Measurement: Define and track KPIs to measure the business and client impact of dynamic routing Provide regular updates to executive leadership on progress, risks, and opportunities. Qualifications: Deep experience in payments, fintech, or financial transaction optimization required. Deep understanding of global regulatory frameworks that impact transaction routing (e.g. U.S. Durbin Amendment) Excellent understanding of global interchange systems, scheme fee structures, and cross-border routing economics. Strong applied knowledge of ML/AI, optimization, and decision science techniques. Proficiency in Python, SQL, and Spark Advanced degree (PhD or Master’s) in Computer Science, Statistics, Mathematics, Engineering, or related field. 10 years of experience in data science or analytics, with at least 5 years in a leadership role. Preferred Qualifications: Experience in a merchant acquiring, PSP, or card network environment. Familiarity with tokenization, real-time payments (RTP), and authorization lifecycle. Understanding of card present vs. card-not-present dynamics, tokenization, and authorization lifecycle. Experience working within SAFe Agile product development environments. Worldpay is committed to providing its employees with an exciting career opportunity and competitive compensation. The pay range for this full-time position is $177,100.00 - $297,500.00 and reflects the minimum and maximum target for new hire salaries for this position based on the posted role, level, and location. Within the range, actual individual starting pay is determined by additional factors, including job-related skills, experience, and relevant education or training. Any changes in work location will also impact actual individual starting pay. Please consult with your recruiter about the specific salary range for your preferred location during the hiring process. The job duties outlined above may be directly, and negatively impacted by a criminal history, which could lead to the withdrawal of a conditional offer. However, all qualified candidates with arrests or convictions will still be considered. Privacy Statement Worldpay is committed to protecting the privacy and security of all personal information that we process in order to provide services to our clients. For specific information on how Worldpay protects personal information online, please see the Online Privacy Notice. EEOC Statement Worldpay is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, marital status, genetic information, national origin, disability, veteran status, and other protected characteristics. The EEO is the Law poster is available here. If you are made a conditional offer of employment and will be working in the United States, you will be required to undergo a drug test. In developing this job description care was taken to include all competencies and requirements needed to successfully perform the position. Reasonable accommodations will be provided for individuals with qualified disabilities both during the hiring process, as well as to allow the individual to perform the essential functions of the job, if hired. Sourcing Model Recruitment at Worldpay works primarily on a direct sourcing model; a relatively small portion of our hiring is through recruitment agencies. Worldpay does not accept resumes from recruitment agencies which are not on the preferred supplier list and is not responsible for any related fees for resumes submitted to job postings, our employees, or any other part of our company.",2025-06-29T00:00:00.000Z,2025-07-25,"['Qualifications: Deep experience in payments, fintech, or financial transaction optimization required', 'Deep understanding of global regulatory frameworks that impact transaction routing (e.g', 'U.S. Durbin Amendment) Excellent understanding of global interchange systems, scheme fee structures, and cross-border routing economics', 'Strong applied knowledge of ML/AI, optimization, and decision science techniques', 'Proficiency in Python, SQL, and Spark Advanced degree (PhD or Master’s) in Computer Science, Statistics, Mathematics, Engineering, or related field', '10 years of experience in data science or analytics, with at least 5 years in a leadership role', 'Familiarity with tokenization, real-time payments (RTP), and authorization lifecycle', 'Understanding of card present vs. card-not-present dynamics, tokenization, and authorization lifecycle', 'Experience working within SAFe Agile product development environments']","['Job Description Position Summary: The Senior Director of Data Science – Dynamic Routing will lead the strategy and execution of intelligent transaction routing and pricing optimization', 'This position will lead a team of ~15 data scientists tasked with developing and operationalizing advanced machine learning and algorithmic solutions that optimize interchange fees, enhance transaction approval rates, and drive margin expansion for the business and its merchants', 'As the public-facing ""face"" of our transaction routing solutions, the Senior Director will play a crucial role in client engagements, articulating complex data science concepts in an accessible manner to explain trends and actions taken in routing', 'This leader will collaborate closely with business leaders to tailor strategies on a customer-by-customer basis, ensuring alignment with broader business goals', 'This leader will work in partnership with Product and Engineering teams to craft the future state vision for transaction routing solutions, ensuring the development of innovative products that meet evolving market demands', 'This role requires a deep understanding of data science methodologies and the ability to translate technical insights into strategic business actions, fostering strong relationships with clients and internal stakeholders to drive success', 'Key Responsibilities: Strategic Leadership: Own the data science roadmap for dynamic routing and interchange optimization across U.S. domestic, cross-border payment flows, and extension of dynamic routing globally', 'Build and deploy ML/AI models that inform routing decisions based on issuer behavior, cost structures, geo/location, network rules and eligibility, and approval likelihood', 'Develop scalable, low-latency algorithms integrated into real-time payment decisioning engines', 'Design and validate experiments to quantify the financial impact of routing and interchange strategies (e.g., A/B tests, multi-armed bandits)', 'Model complex cost structures (interchange, scheme fees, FX margins) to recommend optimal routing paths for each transaction', 'Team & Capability Development: Build, lead, and mentor a multidisciplinary team of ~15 data scientists and data analysts', 'Mentor junior team members on best practices in modeling, experimentation, and payments domain knowledge', 'Foster a culture of innovation, experimentation, and continuous learning', 'Cross-Functional Collaboration: Collaborate with Product and Global Network Partnership teams to align optimization strategies with commercial agreements and market coverage', 'Work closely with Finance, Product, and Worldpay’s Lines of Business to report on savings, approval uplift, and margin impact', 'Communicate complex analytical concepts to non-technical stakeholders effectively', 'Key Areas of Focus: Ensure models meet requirements for scalability, latency, explainability, and regulatory compliance', 'Work with data governance and legal teams to ensure compliance with data privacy regulations (e.g., PCI-DSS, GDPR)', 'Optimize transaction paths across processors, networks (Visa, Mastercard, Regional Networks), and endpoints to maximize approval rates and minimize costs', 'Use data-driven insights to steer transactions toward more favorable interchange categories or fee structures', 'Model historical issuer behavior (approval decline patterns, time-of-day trends, geo-specific sensitivity)', 'Monitor and optimize for performance, latency, and reliability across network routes', 'Performance Measurement: Define and track KPIs to measure the business and client impact of dynamic routing Provide regular updates to executive leadership on progress, risks, and opportunities']",True,[],,"['Machine Learning', 'Optimization Algorithms', 'A/B Testing', 'Multi-Armed Bandits', 'Python', 'SQL', 'Apache Spark', 'Data Science Methodologies', 'Feature Engineering', 'Real-Time Data Pipelines', 'Statistical Modeling', 'KPI Tracking', 'Data Privacy Compliance']","Machine Learning: Used to develop models that optimize transaction routing decisions based on issuer behavior, cost structures, and network rules.; Optimization Algorithms: Applied to optimize interchange fees, transaction approval rates, and margin expansion in payment routing.; A/B Testing: Designed and validated experiments to quantify the financial impact of routing and interchange strategies.; Multi-Armed Bandits: Used as an experimental design technique to optimize routing strategies dynamically.; Python: Programming language used for building and deploying data science and machine learning models.; SQL: Used for querying and managing data related to transaction routing and payment flows.; Apache Spark: Utilized for large-scale data processing and analytics in payment transaction data.; Data Science Methodologies: Applied to translate technical insights into strategic business actions for transaction routing.; Feature Engineering: Inferred as part of modeling issuer behavior and transaction characteristics to improve routing decisions.; Real-Time Data Pipelines: Developed scalable, low-latency algorithms integrated into real-time payment decisioning engines.; Statistical Modeling: Used to model complex cost structures and historical issuer behavior patterns.; KPI Tracking: Defined and tracked key performance indicators to measure business and client impact of routing.; Data Privacy Compliance: Ensured models and data usage comply with regulations like PCI-DSS and GDPR."
6fGpmHTcSlpADv6KAAAAAA==,"Senior Manager, Data Scientist - Parsippany, NJ (Hybrid)","Apply now »

Senior Manager, Data Scientist - Parsippany, NJ (Hybrid)

Date: Jul 15, 2025

Location:
Parsippany, United States, New Jersey, 07054

Company: Teva Pharmaceuticals

Job Id: 62440

Who we are

Together, we’re on a mission to make good health more affordable and accessible, to help millions around the world enjoy healthier lives. It’s a mission that bonds our people across nearly 60 countries and a rich, diverse variety of nationalities and backgrounds. Working here means working with the world’s leading manufacturer of generic medicines, and the proud producer of many of the products on the World Health Organization’s Essential Medicines List. Today, at least 200 million people around the world take one of our medicines every single day. An amazing number, but we’re always looking for new ways to continue making a difference, and new people to make a difference with.

The opportunity

Directly supporting the Teva’s Data Science & Analytics and Patient Services teams, the Sr Manager, Data Scientist will be responsible for creating actionable insights from data to enhance best patient experiences; for identifying and analyzing data to measure patient journeys; for building machine learning / AI models to customize patient services.

This candidate will collaborate closely with Teva’s Patient Services team in Innovative Medicines to support our world-class vision. The candidate will engage with Patient Service team to explore innovative partners, identify data needs and requirements, and evaluate partner data. The candidate will leverage data science and advanced analytics, visualization and automation to provide data-driven insights, communicate meaningful findings, and drive business results.

Location: This is a hybrid role (3 days/week in office) based in our Parsippany, NJ office.

How you’ll spend your day

All areas of responsibility listed below are essential to the satisfactory performance of this position by any incumbents with reasonable accommodation if necessary. Any non-essential functions are assumed to be included in other related duties or assignments.

The ideal candidate will closely work with the unit Leader and business partner to drive solutions that enable data-driven decision making.
• Drive business value through data science and advanced analytics
• Conduct exploratory data analysis to understand the strengths and limitations of complex data sets and identify the appropriate analytical approach
• Design and manage complex analytical projects, breaking down complex business problems into multiple independent and sequential phases of analysis
• Derive insights from data and present results to internal clients and senior management
• Engineer and prepare data from disparate systems
• Integrate and prepare large, varied datasets, design appropriate data science models and algorithms, and professionally communicate results
• Implement ML models in production and track performance
• Summarize key metrics for dashboard

Your experience and qualifications

Any equivalent combination of education, training and/or experience that fulfills the requirements of the position will be considered.

Education/Certification/Experience:
• Master’s Degree with at least 2 years of experience within a highly technical/quantitative discipline (Statistics, Computer Science, Data Science, Mathematics); PhD preferred.
• Minimum 4 years of hands-on experience in generating advanced insights and predictive capability from statistical models, including (but not limited to) multivariate linear regression, cluster algorithms, decision trees, logistic regression, Principal Component Analysis (PCA), time series, survival analysis, machine learning (supervised and unsupervised), Bayesian Methods, Neural Networks, LLM etc.
• Minimum 4 years of experience in performing data analysis and modeling using Python (NumPy, pandas, Scikit-learn, TensorFlow etc).

Skills/Knowledge/Abilities:
• Strong SQL skills for data manipulation, aggregation, and optimization. Proficiency in bringing structure to ambiguous problems and deriving insights from multiple data and information sources.
• Ability to communicate complex ideas, insights, and analytical proficiency into meaningful conclusions to internal and external stakeholders.
• Strong data curiosity, analytical skills and problem-solving abilities.
• Excellent written and verbal communication skills ability to work effectively with both technical and non-technical stakeholders.
• Understanding of the brand and generic pharmaceutical landscape and the commercial data and analytic needs.
• Strong inter-personal skills and team player.
• Ability to quickly adapt to changing priorities and generate innovative solutions in a fast-paced environment.

PHYSICAL REQUIREMENTS:

Occasional:

Sitting for extended periods of time at work station or mobile equipment.

Visual Acuity:

Perform activities such as computer work, preparing and analyzing data, and extensive reading.

Compensation Data

The annual starting salary for this position is between $138,880 - $160,000 annually. Factors which may affect starting salary within this range and level of role may include geography/market, skills, education, experience and other qualifications of the successful candidate.

Enjoy a more rewarding choice

We offer a competitive benefits package, including:
• Comprehensive Health Insurance: Medical, Dental, Vision, and Prescription coverage starting on the first day of employment, providing the employee enrolls.
• Retirement Savings: 401(k) with employer match, up to 6% and an annual 3.75% Defined Contribution to the 401k plan.
• Time Off: Paid Time Off including vacation, sick/safe time, caretaker time, 13 paid Holidays and 3 paid floating holidays.
• Life and Disability Protection: Company paid Life and Disability insurance.
• Additional benefits include, but not limited to, Employee Assistance Program, Employee Stock Purchase Plan, Tuition Assistance, Flexible Spending Accounts, Health Savings Account, Life Style Spending Account, Volunteer Time Off, Paid Parental Leave, if eligible , Family Building Benefits, Virtual Physical Therapy, Accident, Critical Illness and Hospital Indemnity Insurances, Identity Theft Protection, Legal Plan, Voluntary Life Insurance and Long Term Disability and more.

Already Working @TEVA?

If you are a current Teva employee, please apply using the internal career site available on ""Employee Central"". By doing so, your application will be treated with priority. You will also be able to see opportunities that are open exclusively to Teva employees. Use the following link to search and apply: Internal Career Site

The internal career site is available from your home network as well. If you have trouble accessing your EC account, please contact your local HR/IT partner.

Teva’s Equal Employment Opportunity Commitment

Teva Pharmaceuticals is committed to equal opportunity in employment. It is Teva's policy that equal employment opportunity be provided without regard to age, race, creed, color, religion, sex, disability, pregnancy, medical condition, genetic information, marital status, sexual orientation, gender identity or expression, ancestry, national or ethnic origin, citizenship status, military status or status as a disabled or protected veteran, or any legally recognized status entitled to protection under applicable federal, state, or local laws.

Please advise us of any accommodations needed to support you throughout the recruitment and selection process. All accommodation information provided will be treated as confidential and used only for the purpose of providing an accessible candidate experience. Request a reasonable accommodation by sending an email to disabilityassistance@tevapharm.com with the nature of your request and your contact information. Only inquiries concerning a request for a reasonable accommodation will be responded to from this email address.

Important notice to Employment Agencies - Please Read Carefully

Teva Pharmaceuticals USA does not accept unsolicited assistance from agencies for employment opportunities. All CVs / resumes submitted by search firms to any employee at our company without a valid written search agreement in place for this position will be deemed the sole property of our company. No fee will be paid in the event a candidate is hired by our company as a result of an agency referral where no pre-existing agreement is in place. Where agency agreements are in place, introductions are position specific. Please, no phone calls or emails.

Apply now »",2025-07-15T00:00:00.000Z,2025-07-25,"['Any equivalent combination of education, training and/or experience that fulfills the requirements of the position will be considered', 'Minimum 4 years of hands-on experience in generating advanced insights and predictive capability from statistical models, including (but not limited to) multivariate linear regression, cluster algorithms, decision trees, logistic regression, Principal Component Analysis (PCA), time series, survival analysis, machine learning (supervised and unsupervised), Bayesian Methods, Neural Networks, LLM etc', 'Minimum 4 years of experience in performing data analysis and modeling using Python (NumPy, pandas, Scikit-learn, TensorFlow etc)', 'Strong SQL skills for data manipulation, aggregation, and optimization', 'Proficiency in bringing structure to ambiguous problems and deriving insights from multiple data and information sources', 'Ability to communicate complex ideas, insights, and analytical proficiency into meaningful conclusions to internal and external stakeholders', 'Strong data curiosity, analytical skills and problem-solving abilities', 'Excellent written and verbal communication skills ability to work effectively with both technical and non-technical stakeholders', 'Understanding of the brand and generic pharmaceutical landscape and the commercial data and analytic needs', 'Strong inter-personal skills and team player', 'Ability to quickly adapt to changing priorities and generate innovative solutions in a fast-paced environment']","['Directly supporting the Teva’s Data Science & Analytics and Patient Services teams, the Sr Manager, Data Scientist will be responsible for creating actionable insights from data to enhance best patient experiences; for identifying and analyzing data to measure patient journeys; for building machine learning / AI models to customize patient services', 'This candidate will collaborate closely with Teva’s Patient Services team in Innovative Medicines to support our world-class vision', 'The candidate will engage with Patient Service team to explore innovative partners, identify data needs and requirements, and evaluate partner data', 'The candidate will leverage data science and advanced analytics, visualization and automation to provide data-driven insights, communicate meaningful findings, and drive business results', 'All areas of responsibility listed below are essential to the satisfactory performance of this position by any incumbents with reasonable accommodation if necessary', 'Any non-essential functions are assumed to be included in other related duties or assignments', 'The ideal candidate will closely work with the unit Leader and business partner to drive solutions that enable data-driven decision making', 'Drive business value through data science and advanced analytics', 'Conduct exploratory data analysis to understand the strengths and limitations of complex data sets and identify the appropriate analytical approach', 'Design and manage complex analytical projects, breaking down complex business problems into multiple independent and sequential phases of analysis', 'Derive insights from data and present results to internal clients and senior management', 'Engineer and prepare data from disparate systems', 'Integrate and prepare large, varied datasets, design appropriate data science models and algorithms, and professionally communicate results', 'Implement ML models in production and track performance', 'Summarize key metrics for dashboard', 'Sitting for extended periods of time at work station or mobile equipment', 'Perform activities such as computer work, preparing and analyzing data, and extensive reading']",True,['Large Language Models'],Large Language Models: Referenced as part of advanced AI techniques to customize patient services and enhance data-driven insights.,"['Multivariate Linear Regression', 'Cluster Algorithms', 'Decision Trees', 'Logistic Regression', 'Principal Component Analysis', 'Time Series Analysis', 'Survival Analysis', 'Supervised and Unsupervised Machine Learning', 'Bayesian Methods', 'Neural Networks', 'Python (NumPy, pandas, Scikit-learn, TensorFlow)', 'SQL', 'Data Visualization and Dashboards', 'Data Engineering and Integration', 'Exploratory Data Analysis', 'Predictive Modeling', 'Model Deployment and Performance Tracking']","Multivariate Linear Regression: Used to generate predictive insights by modeling relationships between multiple variables in patient and business data.; Cluster Algorithms: Applied to segment patient data and identify distinct groups for targeted analysis and service customization.; Decision Trees: Employed for classification and decision-making processes within patient journey analysis and predictive modeling.; Logistic Regression: Used for binary classification tasks such as patient outcome predictions and service effectiveness.; Principal Component Analysis: Utilized to reduce dimensionality of complex datasets, improving model performance and interpretability.; Time Series Analysis: Applied to analyze patient data trends over time and forecast future outcomes or behaviors.; Survival Analysis: Used to model time-to-event data relevant to patient outcomes and treatment effectiveness.; Supervised and Unsupervised Machine Learning: Implemented to build predictive models and uncover patterns in patient and operational data.; Bayesian Methods: Applied for probabilistic modeling and inference to enhance predictive accuracy in patient data analysis.; Neural Networks: Used as part of advanced modeling techniques to capture complex relationships in healthcare data.; Python (NumPy, pandas, Scikit-learn, TensorFlow): Primary programming environment and libraries for data manipulation, analysis, modeling, and machine learning implementation.; SQL: Essential for data extraction, manipulation, and aggregation from diverse data sources to support analysis.; Data Visualization and Dashboards: Used to communicate key metrics and insights effectively to stakeholders and senior management.; Data Engineering and Integration: Involves preparing and combining large, varied datasets from disparate systems for analysis and modeling.; Exploratory Data Analysis: Conducted to understand data quality, characteristics, and to select appropriate analytical approaches.; Predictive Modeling: Building models to forecast patient behaviors and outcomes to enhance patient services.; Model Deployment and Performance Tracking: Implementing machine learning models in production environments and monitoring their effectiveness over time."
jlx4B7G84QjAVJjjAAAAAA==,Machine Learning Specialist (flex – hybrid),"Skip to content
• Returning Applicants
• Employee Resources
• Employee Onboarding

MENU

Machine Learning Specialist (flex – hybrid)

Work Location Los Angeles,CA Job #25844 Work Hours Monday-Friday, 8:00 AM – 5:00 PM PST Employment Type 2 – Staff- Career

Duration Indefinite Salary Range $83800-179400 Annually Posted Date July 22, 2025 Bargaining Unit 99

Apply Now

Apply as Internal/Current Employee

Back to Search Results

Refer A Friend

Provide the tools necessary to deliver cutting-edge health care and groundbreaking research. As part of our Information Technology team, you’ll ensure that our medical professionals have access to the latest breakthroughs in technology, and you’ll play a key role in protecting our global patient community.
• JOB DUTIES
• JOB QUALIFICATIONS

Description UCLA Health is seeking an innovative Machine Learning Specialist to help shape the future of healthcare through artificial intelligence. This role drives the development and validation of AI/ML models that empower data-driven decision-making across clinical, financial, and operational domains.

What You’ll Do
• Design, test, and validate AI/ML models using structured and unstructured healthcare data
• Contribute to MLOps process improvements and the adoption of robust governance policies
• Develop standards, documentation, and training materials to support enterprise-wide AI/ML efforts
• Collaborate with cross-functional teams to solve complex organizational challenges
• Translate domain knowledge into scalable technical solutions that support UCLA Health’s mission

What You Bring
• Expertise in machine learning, software engineering, and data science
• Understanding of healthcare workflows across clinical, financial, and operational domains
• Ability to communicate complex technical concepts clearly to diverse audiences
• Passion for advancing healthcare through innovation and collaboration

This flexible hybrid role allows for a blend of remote and on-site work, requiring presence on-site at least 10%, within 48 hours of being asked to come in, and as needed based on operational requirements. Please note, travel to the “home office” location is not reimbursed. Each employee will complete a FlexWork Agreement with their manager to outline expectations and ensure mutual understanding. These arrangements are periodically reviewed and may be adjusted or terminated as necessary.

Salary offers are based on a variety of factors including qualifications, experience, and internal equity. The full salary range for this position is $83,800 – $179,400 annually. The University anticipates offering a salary between the minimum and midpoint of this range.

JERRY

Your career path at UCLA Health will enable you to follow a myriad of avenues and turns. It opens up a wide variety of opportunities.

ORLANDO

There’s a togetherness and higher level of commitment to teamwork at UCLA Health. We are several groups and teams that work together with a common goal which is to improve our patients experience.

DAVID

UCLA Health walks the walk and talks the talk! It's an incredible feeling to work for an organization that always puts the patient first. I am honored to work in full alignment with the UCLA Health Mission and Vision.

GET INSPIRED by our latest happenings

Awards & recognition
• ©2025 UC Regents
• UCLA Health
• Disability Accommodation Resources
• Privacy Practices
• Recruitment Fraud Alert
• Sitemap
• Terms of Use
• EE Employer

Go to Top",2025-07-22T00:00:00.000Z,2025-07-25,"['Expertise in machine learning, software engineering, and data science', 'Understanding of healthcare workflows across clinical, financial, and operational domains', 'Ability to communicate complex technical concepts clearly to diverse audiences', 'Passion for advancing healthcare through innovation and collaboration']","['Provide the tools necessary to deliver cutting-edge health care and groundbreaking research', 'As part of our Information Technology team, you’ll ensure that our medical professionals have access to the latest breakthroughs in technology, and you’ll play a key role in protecting our global patient community', 'This role drives the development and validation of AI/ML models that empower data-driven decision-making across clinical, financial, and operational domains', 'Design, test, and validate AI/ML models using structured and unstructured healthcare data', 'Contribute to MLOps process improvements and the adoption of robust governance policies', 'Develop standards, documentation, and training materials to support enterprise-wide AI/ML efforts', 'Collaborate with cross-functional teams to solve complex organizational challenges', 'Translate domain knowledge into scalable technical solutions that support UCLA Health’s mission', 'This flexible hybrid role allows for a blend of remote and on-site work, requiring presence on-site at least 10%, within 48 hours of being asked to come in, and as needed based on operational requirements', 'Each employee will complete a FlexWork Agreement with their manager to outline expectations and ensure mutual understanding', 'These arrangements are periodically reviewed and may be adjusted or terminated as necessary']",True,['Artificial Intelligence'],"Artificial Intelligence: Central to the role, focusing on designing, testing, and validating AI models that enhance healthcare outcomes and operational efficiency.","['Machine Learning', 'Data Science', 'MLOps']","Machine Learning: Used to develop and validate predictive models that support decision-making in clinical, financial, and operational healthcare domains.; Data Science: Applied to analyze structured and unstructured healthcare data to derive insights and support AI/ML model development.; MLOps: Involved in improving processes and governance policies to ensure robust deployment and management of AI/ML models enterprise-wide."
GLzGWz9HNOjBml78AAAAAA==,"Data Scientist, Product - Full-time","**Summary:**

Meta Platforms, Inc. (Meta), formerly known as Facebook Inc., builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps and services like Messenger, Instagram, and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. To apply, click “Apply to Job” online on this web page.
• *Required Skills:**

Data Scientist, Product Responsibilities:

1. Collect, organize, interpret, and summarize statistical data in order to contribute to the design and development of Meta products.

2. Apply your expertise in quantitative analysis, data mining, and the presentation of data to see beyond the numbers and understand how our users interact with both our consumer and business products.

3. Partner with Product and Engineering teams to solve problems and identify trends and opportunities.

4. Inform, influence, support, and execute our product decisions and product launches.

5. May be assigned projects in various areas including, but not limited to, product operations, exploratory analysis, product influence, and data infrastructure.

6. Work on problems of diverse scope where analysis of data requires evaluation of identifiable factors.

7. Demonstrate good judgment in selecting methods and techniques for obtaining solutions.

8. Telecommute from anywhere in the US permitted.
• *Minimum Qualifications:**

Minimum Qualifications:

9. Requires a PhD degree(or foreign equivalent degree) in Computer Science, Engineering, Information Systems, Analytics, Mathematics, Physics, Applied Sciences, or a related field. Requires completion of a university-level course, research project, internship, or thesis in the following:

10. 1. Machine learning techniques

11. 2. Working with large data sets and network-based data (TCP or HTTP)

12. 3. ETL (Extract, Transform, Load) processes

13. 4. Relational database (SQL or PL*SQL)

14. 5. Developing in scripting language: PHP, Python, or Perl

15. 6. Statistical analysis using R, MATLAB, Mathematica, ROOT, SPSS, SAS, or Stata

16. 7. Large scale data processing infrastructures using distributed systems (Hadoop, Hive, MapReduce, LCG, or MPI)

17. 8. Quantitative analysis techniques: clustering, regression, patterns recognition, or descriptive and inferential statistics

18. 9. Communicating and presenting results of data analyses.
• *Public Compensation:**

$216,571/year to $235,400/year + bonus + equity + benefits
• *Industry:** Internet
• *Equal Opportunity:**

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.
• *Summary:**

Meta Platforms, Inc. (Meta), formerly known as Facebook Inc., builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps and services like Messenger, Instagram, and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. To apply, click “Apply to Job” online on this web page.
• *Required Skills:**

Data Scientist, Product Responsibilities:

1. Collect, organize, interpret, and summarize statistical data in order to contribute to the design and development of Meta products.

2. Apply your expertise in quantitative analysis, data mining, and the presentation of data to see beyond the numbers and understand how our users interact with both our consumer and business products.

3. Partner with Product and Engineering teams to solve problems and identify trends and opportunities.

4. Inform, influence, support, and execute our product decisions and product launches.

5. May be assigned projects in various areas including, but not limited to, product operations, exploratory analysis, product influence, and data infrastructure.

6. Work on problems of diverse scope where analysis of data requires evaluation of identifiable factors.

7. Demonstrate good judgment in selecting methods and techniques for obtaining solutions.

8. Telecommute from anywhere in the US permitted.
• *Minimum Qualifications:**

Minimum Qualifications:

9. Requires a PhD degree(or foreign equivalent degree) in Computer Science, Engineering, Information Systems, Analytics, Mathematics, Physics, Applied Sciences, or a related field. Requires completion of a university-level course, research project, internship, or thesis in the following:

10. 1. Machine learning techniques

11. 2. Working with large data sets and network-based data (TCP or HTTP)

12. 3. ETL (Extract, Transform, Load) processes

13. 4. Relational database (SQL or PL*SQL)

14. 5. Developing in scripting language: PHP, Python, or Perl

15. 6. Statistical analysis using R, MATLAB, Mathematica, ROOT, SPSS, SAS, or Stata

16. 7. Large scale data processing infrastructures using distributed systems (Hadoop, Hive, MapReduce, LCG, or MPI)

17. 8. Quantitative analysis techniques: clustering, regression, patterns recognition, or descriptive and inferential statistics

18. 9. Communicating and presenting results of data analyses.
• *Public Compensation:**

$216,571/year to $235,400/year + bonus + equity + benefits
• *Industry:** Internet
• *Equal Opportunity:**

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.",2025-07-25T14:00:00.000Z,2025-07-25,"['Requires a PhD degree(or foreign equivalent degree) in Computer Science, Engineering, Information Systems, Analytics, Mathematics, Physics, Applied Sciences, or a related field', 'Requires completion of a university-level course, research project, internship, or thesis in the following:', 'Relational database (SQL or PL*SQL)', 'Developing in scripting language: PHP, Python, or Perl', 'Statistical analysis using R, MATLAB, Mathematica, ROOT, SPSS, SAS, or Stata', 'Large scale data processing infrastructures using distributed systems (Hadoop, Hive, MapReduce, LCG, or MPI)', 'Meta participates in the E-Verify program in certain locations, as required by law', 'Demonstrate good judgment in selecting methods and techniques for obtaining solutions', 'Telecommute from anywhere in the US permitted', 'Requires a PhD degree(or foreign equivalent degree) in Computer Science, Engineering, Information Systems, Analytics, Mathematics, Physics, Applied Sciences, or a related field', 'Requires completion of a university-level course, research project, internship, or thesis in the following:', 'Machine learning techniques', 'ETL (Extract, Transform, Load) processes', 'Relational database (SQL or PL*SQL)', 'Developing in scripting language: PHP, Python, or Perl', 'Statistical analysis using R, MATLAB, Mathematica, ROOT, SPSS, SAS, or Stata', 'Large scale data processing infrastructures using distributed systems (Hadoop, Hive, MapReduce, LCG, or MPI)', 'Meta participates in the E-Verify program in certain locations, as required by law']","['Collect, organize, interpret, and summarize statistical data in order to contribute to the design and development of Meta products', 'Apply your expertise in quantitative analysis, data mining, and the presentation of data to see beyond the numbers and understand how our users interact with both our consumer and business products', 'Partner with Product and Engineering teams to solve problems and identify trends and opportunities', 'Inform, influence, support, and execute our product decisions and product launches', 'May be assigned projects in various areas including, but not limited to, product operations, exploratory analysis, product influence, and data infrastructure', 'Work on problems of diverse scope where analysis of data requires evaluation of identifiable factors', 'Demonstrate good judgment in selecting methods and techniques for obtaining solutions', 'Telecommute from anywhere in the US permitted', 'Machine learning techniques', 'Working with large data sets and network-based data (TCP or HTTP)', 'ETL (Extract, Transform, Load) processes', 'Quantitative analysis techniques: clustering, regression, patterns recognition, or descriptive and inferential statistics', 'Communicating and presenting results of data analyses', '*Public Compensation:*', 'Collect, organize, interpret, and summarize statistical data in order to contribute to the design and development of Meta products', 'Apply your expertise in quantitative analysis, data mining, and the presentation of data to see beyond the numbers and understand how our users interact with both our consumer and business products', 'Partner with Product and Engineering teams to solve problems and identify trends and opportunities', 'Inform, influence, support, and execute our product decisions and product launches', 'May be assigned projects in various areas including, but not limited to, product operations, exploratory analysis, product influence, and data infrastructure', 'Work on problems of diverse scope where analysis of data requires evaluation of identifiable factors', 'Working with large data sets and network-based data (TCP or HTTP)', 'Quantitative analysis techniques: clustering, regression, patterns recognition, or descriptive and inferential statistics', 'Communicating and presenting results of data analyses']",True,[],,"['Machine Learning Techniques', 'Large Data Sets', 'ETL Processes', 'Relational Databases (SQL, PL/SQL)', 'Scripting Languages (Python, PHP, Perl)', 'Statistical Analysis Tools (R, MATLAB, Mathematica, ROOT, SPSS, SAS, Stata)', 'Distributed Data Processing (Hadoop, Hive, MapReduce, LCG, MPI)', 'Quantitative Analysis Techniques', 'Data Mining', 'Data Presentation']","Machine Learning Techniques: Used to develop predictive models and analyze user interactions for product improvements.; Large Data Sets: Handling and analyzing extensive network-based data (TCP or HTTP) to extract insights relevant to Meta's products.; ETL Processes: Extracting, transforming, and loading data to prepare it for analysis and product development.; Relational Databases (SQL, PL/SQL): Managing and querying structured data to support data analysis and product decision-making.; Scripting Languages (Python, PHP, Perl): Developing scripts for data manipulation, analysis, and automation within product data workflows.; Statistical Analysis Tools (R, MATLAB, Mathematica, ROOT, SPSS, SAS, Stata): Applying statistical methods to interpret data and support product design and evaluation.; Distributed Data Processing (Hadoop, Hive, MapReduce, LCG, MPI): Utilizing large-scale distributed systems to process and analyze big data efficiently.; Quantitative Analysis Techniques: Employing clustering, regression, pattern recognition, and inferential statistics to identify trends and user behavior.; Data Mining: Extracting meaningful patterns from large datasets to inform product decisions.; Data Presentation: Communicating analytical results effectively to influence product strategy and launches."
3tuYGjYGj111rYs3AAAAAA==,Solution Data Scientist (Fraud & AML),"About Us

DataVisor is the world’s leading AI-powered Fraud and Risk Platform that delivers the best overall detection coverage in the industry. With an open SaaS platform that supports easy consolidation and enrichment of any data, DataVisor's fraud and anti-money laundering (AML) solutions scale infinitely and enable organizations to act on fast-evolving fraud and money laundering activities in real time. Its patented unsupervised machine learning technology, advanced device intelligence, powerful decision engine, and investigation tools work together to provide significant performance lift from day one. DataVisor's platform is architected to support multiple use cases across different business units flexibly, dramatically lowering total cost of ownership, compared to legacy point solutions. DataVisor is recognized as an industry leader and has been adopted by many Fortune 500 companies across the globe.

Our award-winning software platform is powered by a team of world-class experts in big data, machine learning, security, and scalable infrastructure. Our culture is open, positive, collaborative, and results-driven. Come join us!

Position Overview

The Solution Data Scientist (Fraud & AML) will be part of our Professional Service team, reporting to our Chief Solution Architect and VP Professional Services. You will lead various types of technical projects e.g. fraud attack pattern study, risk strategy development, data pipeline and platform configuration, and machine learning model evaluation. Such projects may span both pre-sales and post-sales engagements with DataVisor clients.

You will drive the internal engagement with Customer Success, ML Model, Product and Engineering teams to deliver fraud and AML solutions and custom platform configuration that bring business impacts to our clients and generate revenue for DataVisor. You are a big believer and proficient user of GenAI tools e.g. ChatGPT to perform data analysis tasks 10x more efficiently than before.

Key Responsibilities
• Business Problem Discovery: Discover and understand the client’s business logic and business problems, e.g. risk decision flows, business pain points, fraud patterns, data availability and quality, and expected business outcome.
• Data Integration and Quality Check: Lead technical discussions with clients’ risk business teams (Fraud and AML) and data team to ensure high quality and comprehensive data is provided. Own the data transfers and data quality validation.
• Risk Pattern Analyses and Strategies: Leverage your strong domain expertise and business sense to conduct data analyses, pattern analyses, suggest and create detection strategies, and perform strategy testing and iterations.
• Solution Design and Configurations: Design and configure various DataVisor solution components e.g. Rules Engine, Decision Flows, Case Management, Knowledge Graph, BI Dashboards to provide tailored results and strong business values to clients.
• ML Model Performance Analysis: Work with ML Modeling team to develop, tune, and evaluate fraud detection models (unsupervised and supervised), and conduct performance metrics analysis to guide the threshold selection and decision adoption.
• Project Management and Documentation: Manage the solution service projects with project management tools e.g. Monday.com, and own the creation and reporting of key internal and external-facing project documents as deliverables.
• Presentation and Demonstration: Present the project results and demonstrate the configured solutions to key business stakeholders.
• Experience:
• 4+ years of experience in Fraud and/or AML strategies or models
• 2+ years of experience in client-facing data analytic projects
• Technical Skills:
• Domain knowledge in Fraud and AML use cases in financial services industry
• Proficient in SQL queries with complex joining and layered logics
• Familiarity with data streaming/processing e.g. REST API, Kafka, SFTP, Hadoop
• Familiarity with Python, R, and Java is a plus
• Proficient in LLM tools e.g. ChatGPT to research new business problems
• Soft Skills:
• Excellent communication, presentation, and interpersonal skills
• Strong problem-solving mindset and results-driven mindset
• Strong mindset of documentation and automation with AI tools/agents
• Ability to work collaboratively in a face-paced, team environment and manage multiple projects simultaneously
• Education:
• Bachelor’s degree in a technical or analytical discipline e.g. Data Science, Statistics, Computer Science

Why Join Us?
• Opportunity to work on impactful projects that protect businesses from risk loss
• Collaborate with a diverse and talented team of experts in AI and machine learning
• Enjoy a flexible, supportive work environment with opportunities for professional growth
• Competitive compensation and benefits package
• Stock options, Medical insurance, 401K, PTO
#J-18808-Ljbffr",2025-07-10T00:00:00.000Z,2025-07-25,"['You are a big believer and proficient user of GenAI tools e.g. ChatGPT to perform data analysis tasks 10x more efficiently than before', '4+ years of experience in Fraud and/or AML strategies or models', '2+ years of experience in client-facing data analytic projects', 'Domain knowledge in Fraud and AML use cases in financial services industry', 'Proficient in SQL queries with complex joining and layered logics', 'Familiarity with data streaming/processing e.g. REST API, Kafka, SFTP, Hadoop', 'Proficient in LLM tools e.g. ChatGPT to research new business problems', 'Excellent communication, presentation, and interpersonal skills', 'Strong problem-solving mindset and results-driven mindset', 'Strong mindset of documentation and automation with AI tools/agents', 'Ability to work collaboratively in a face-paced, team environment and manage multiple projects simultaneously', 'Bachelor’s degree in a technical or analytical discipline e.g', 'Data Science, Statistics, Computer Science']","['The Solution Data Scientist (Fraud & AML) will be part of our Professional Service team, reporting to our Chief Solution Architect and VP Professional Services', 'You will lead various types of technical projects e.g. fraud attack pattern study, risk strategy development, data pipeline and platform configuration, and machine learning model evaluation', 'Such projects may span both pre-sales and post-sales engagements with DataVisor clients', 'You will drive the internal engagement with Customer Success, ML Model, Product and Engineering teams to deliver fraud and AML solutions and custom platform configuration that bring business impacts to our clients and generate revenue for DataVisor', 'Business Problem Discovery: Discover and understand the client’s business logic and business problems, e.g. risk decision flows, business pain points, fraud patterns, data availability and quality, and expected business outcome', 'Data Integration and Quality Check: Lead technical discussions with clients’ risk business teams (Fraud and AML) and data team to ensure high quality and comprehensive data is provided', 'Own the data transfers and data quality validation', 'Risk Pattern Analyses and Strategies: Leverage your strong domain expertise and business sense to conduct data analyses, pattern analyses, suggest and create detection strategies, and perform strategy testing and iterations', 'Solution Design and Configurations: Design and configure various DataVisor solution components e.g. Rules Engine, Decision Flows, Case Management, Knowledge Graph, BI Dashboards to provide tailored results and strong business values to clients', 'ML Model Performance Analysis: Work with ML Modeling team to develop, tune, and evaluate fraud detection models (unsupervised and supervised), and conduct performance metrics analysis to guide the threshold selection and decision adoption', 'Project Management and Documentation: Manage the solution service projects with project management tools e.g. Monday.com, and own the creation and reporting of key internal and external-facing project documents as deliverables', 'Presentation and Demonstration: Present the project results and demonstrate the configured solutions to key business stakeholders']",True,"['Large Language Models', 'Generative AI Tools', 'AI Automation Agents']",Large Language Models: Using LLM tools like ChatGPT to research new business problems and enhance data analysis efficiency.; Generative AI Tools: Applying generative AI tools such as ChatGPT to automate and accelerate data analysis and documentation tasks.; AI Automation Agents: Employing AI-powered agents to automate documentation and other workflow processes within fraud and AML projects.,"['Fraud Detection Models', 'Data Pipelines', 'SQL', 'Data Streaming and Processing', 'Business Intelligence Dashboards', 'Pattern Analysis', 'Machine Learning Model Evaluation', 'Rules Engine and Decision Flows', 'Knowledge Graph']","Fraud Detection Models: Developing, tuning, and evaluating supervised and unsupervised machine learning models specifically for fraud and AML detection.; Data Pipelines: Leading data integration, data transfers, and quality validation to ensure comprehensive and high-quality data for fraud and AML analysis.; SQL: Using complex SQL queries with joins and layered logic to analyze and manipulate data relevant to fraud and AML use cases.; Data Streaming and Processing: Familiarity with technologies like REST API, Kafka, SFTP, and Hadoop to handle real-time and batch data processing for fraud detection.; Business Intelligence Dashboards: Designing and configuring BI dashboards to visualize fraud and AML detection results and support decision-making.; Pattern Analysis: Conducting data and risk pattern analyses to identify fraud attack patterns and develop detection strategies.; Machine Learning Model Evaluation: Analyzing performance metrics of fraud detection models to guide threshold selection and decision adoption.; Rules Engine and Decision Flows: Configuring rules engines and decision flows as part of the fraud detection solution to automate risk decisions.; Knowledge Graph: Utilizing knowledge graphs to represent relationships and entities in fraud and AML investigations."
zQbX8Kunk1O0HLj_AAAAAA==,"Senior, Data Scientist - Military veterans preferred","Position Summary...

What you'll do...

Data Source Identification: Requires knowledge of Functional business domain and scenarios; Categories of data and where it is held; Business data requirements; Database technologies and distributed datastores (e.g. SQL, NoSQL); Data Quality; Existing business systems and processes, including the key drivers and measures of success. To support the understanding of the priority order of requirements and service level agreements. Help identify the most suitable source for data that is fit for purpose. Perform initial data quality checks on extracted data.
Data Strategy: Requires knowledge of understanding of business value and relevance of data and data enabled insights / decisions; Appropriate application and understanding of data ecosystem including Data Management, Data Quality Standards and Data Governance, Accessibility, Storage and Scalability, etc.; Understanding of the methods and applications that unlock the monetary value of data assets. To understand, articulate, and apply principles of the defined strategy to routine business problems that involve a single function.
Model Deployment and Scaling: Requires knowledge of impact of variables and features on model performance; understanding of servers, model formats to store models. To support efforts to ensure that analytical models and techniques used can be deployed into production. Support evaluation of the analytical model. Support the scalability and sustainability of analytical models.
Code Development and Testing: Requires knowledge of coding languages like SQL, Java, C++, Python and others; Testing methods such as static, dynamic, software composition analysis, manual penetration testing and others; Business, domain understanding. To write code to develop the required solution and application features by using the recommended programming language and leveraging business, technical, and data requirements. Test the code using the recommended testing approach.
Model Assessment and Validation: Requires knowledge of model fit testing, tuning, and validation techniques (e.g., Chi square, ROC curve, root mean square error etc.); Impact of variables and features on model performance To Identify the model evaluation metrics. Apply best practice techniques for model testing and tuning to assess accuracy, fit, validity, and robustness for multi-stage models and model ensembles.
Data Visualization: Requires knowledge of Visualization guidelines and best practices for complex data types; Multiple data visualization tools (for example, Python, R libraries, GGplot, Matplotlib, Ploty, Tableau, PowerBI etc.); Advanced visualization techniques/ tools; Multiple story plots and structures (OABCDE); Communication & influencing technique; Emotional intelligence. To generate appropriate graphical representations of data and model outcomes. Understand customer requirements to design appropriate data representation for multiple data sets. Work with User Experience designers and User Interface engineers as required to build front end applications. Present to and influence the team and business audience using the appropriate data visualization frameworks and conveys clear messages through business and stakeholder understanding. Customize communication style based on stakeholder under guidance, and leverages rational arguments. Guide and mentor junior associates on story types, structures, and techniques based on context.
Understanding Business Context: Requires knowledge of Industry and environmental factors; Common business vernacular; Business practices across two or more domains such as product, finance, marketing, sales, technology, business systems, and human resources and in-depth knowledge of related practices; Directly relevant business metrics and business areas. To Provide recommendations to business stakeholders to solve complex business issues. Develop business cases for projects with a projected return on investment or cost savings. Translate business requirements into projects, activities, and tasks and aligns to overall business strategy and develops domain specific artifact. Serve as an interpreter and conduit to connect business needs with tangible solutions and results. Identify and recommend relevant business insights pertaining to their area of work.
Tech. Problem Formulation: Requires knowledge of Analytics/big data analytics / automation techniques and methods; Business understanding; Precedence and use cases; Business requirements and insights. To translate/ co-own business problems within one's discipline to data related or mathematical solutions. Identify appropriate methods/tools to be leveraged to provide a solution for the problem. Share use cases and gives examples to demonstrate how the method would solve the business problem.
Analytical Modeling: Requires knowledge of feature relevance and selection; Exploratory data analysis methods and techniques; Advanced statistical methods and best-practice advanced modelling techniques (e.g., graphical models, Bayesian inference, basic level of NLP, Vision, neural networks, SVM, Random Forest etc.); Multivariate calculus; Statistical models behind standard ML models; Advanced excel techniques and Programming languages like R/Python; Basic classical optimization techniques (e.g., Newton-Rapson methods, Gradient descent); Numerical methods of optimization (e.g. Linear Programming, Integer Programming, Quadratic Programming, etc.) To select the analytical modeling technique most suitable for the structured, complex data and develops custom analytical models. Conduct exploratory data analysis activities (for example, basic statistical analysis, hypothesis testing, statistical inferences) on available data. Define and finalize features based on model responses and introduces new or revised features to enhance the analysis and outcomes. Identify the dimensions of the experiment, finalize the design, test hypotheses, and conduct the experiment. Perform trend and cluster analysis on data to answer practical business problems and provide recommendations and key insights to the business. Mentor and guide junior associates on basic modeling and analytics techniques to solve complex problems.
Demonstrates up-to-date expertise and applies this to the development, execution, and improvement of action plans by providing expert advice and guidance to others in the application of information and best practices; supporting and aligning efforts to meet customer and business needs; and building commitment for perspectives and rationales.
Provides and supports the implementation of business solutions by building relationships and partnerships with key stakeholders; identifying business needs; determining and carrying out necessary processes and practices; monitoring progress and results; recognizing and capitalizing on improvement opportunities; and adapting to competing demands, organizational changes, and new responsibilities.
Models compliance with company policies and procedures and supports company mission, values, and standards of ethics and integrity by incorporating these into the development and implementation of business plans; using the Open Door Policy; and demonstrating and assisting others with how to apply these in executing business processes and practices.

Leadership Expectations

Respect for the Individual: Demonstrates and encourages respect for all; builds a high-performing, diverse team; seeks, and embraces differences in people, cultures, ideas and experiences; creates a workplace and equitable experiences where associates feel seen, supported and connected through culture of belonging so associates thrive and perform; drives a positive associate and customer/member experience for all; identifies, attracts, and retains the best, diverse team members.

Respect for the Individual: Creates a discipline and focus around developing talent, through feedback, coaching, mentoring, and developmental opportunities; promotes an environment allowing everyone to bring their best selves to work; empowers associates and partners to act in the best interest of the customer/member and company; and regularly recognizes others’ contributions and accomplishments.

Respect for the Individual: Builds strong and trusting relationships with team members and business partners; works collaboratively and cross-functionally to achieve objectives; and communicates and listens attentively, with energy and positivity to motivate, influence, and inspire commitment and action.

Acts with Integrity: Maintains and promotes the highest standards of integrity, ethics and compliance; models the Walmart values and leads by example to foster our culture; supports Walmart’s goal of becoming a regenerative company by making a positive impact for associates, customers, members, and the world around us.

Acts with Integrity: Follows the law, our code of conduct and company policies, and sets expectations for others to do the same; promotes an environment where associates feel comfortable sharing concerns and reinforces our culture of non-retaliation; listens to concerns raised by associates. takes action and encourages others to do the same; holds self and others accountable for achieving results in a way that is consistent with our values.

Acts with Integrity: Acts as an altruistic servant leader and is consistently humble, self-aware, honest, and transparent.

Service to the Customer/Member: Delivers expected business results while putting the customer/member first and consistently applying an omni-merchant mindset and acts with an Every Day Low Cost mindset to drive value and Every Day Low Prices for customers/members.

Service to the Customer/Member: Adopts a holistic perspective that considers data, analytics, customer/member insights, and different parts of the business when making plans and shaping the team’s strategy.

Strive for Excellence: Consistently raises the bar and seeks to improve; demonstrates curiosity and a growth mindset; seeks feedback, asks thoughtful questions, fosters an environment that supports learning, innovation, and learning from mistakes, and intelligent risk-taking; and exhibits resilience in the face of setbacks.

Strive for Excellence: Seeks and implements continuous improvements and encourages the team to leverage new digital tools and ways of working.

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

?

?

?
You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.

?

For information about PTO, see .

?

?
Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

?
Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

?

For information about benefits and eligibility, see .

?
The annual salary range for this position is $90,000.00-$180,000.00

?
Additional compensation includes annual or quarterly performance bonuses.

?
Additional compensation for certain positions may also include:

?

?
- Stock

?

?

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1- Bachelor’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years' experience in an analytics related field. Option 2- Master’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years' experience in an analytics related field. Option 3 - 5 years' experience in an analytics or related field.

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data science, machine learning, optimization models, Master’s degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.

Primary Location...

805 Se Moberly Ln, Bentonville, AR 72712, United States of America",2025-07-11T00:00:00.000Z,2025-07-25,"['Data Strategy: Requires knowledge of understanding of business value and relevance of data and data enabled insights / decisions; Appropriate application and understanding of data ecosystem including Data Management, Data Quality Standards and Data Governance, Accessibility, Storage and Scalability, etc.; Understanding of the methods and applications that unlock the monetary value of data assets', 'Code Development and Testing: Requires knowledge of coding languages like SQL, Java, C++, Python and others; Testing methods such as static, dynamic, software composition analysis, manual penetration testing and others; Business, domain understanding', 'Model Assessment and Validation: Requires knowledge of model fit testing, tuning, and validation techniques (e.g., Chi square, ROC curve, root mean square error etc.); Impact of variables and features on model performance To Identify the model evaluation metrics', 'Problem Formulation: Requires knowledge of Analytics/big data analytics / automation techniques and methods; Business understanding; Precedence and use cases; Business requirements and insights', 'Analytical Modeling: Requires knowledge of feature relevance and selection; Exploratory data analysis methods and techniques; Advanced statistical methods and best-practice advanced modelling techniques (e.g., graphical models, Bayesian inference, basic level of NLP, Vision, neural networks, SVM, Random Forest etc.); Multivariate calculus; Statistical models behind standard ML models; Advanced excel techniques and Programming languages like R/Python; Basic classical optimization techniques (e.g., Newton-Rapson methods, Gradient descent); Numerical methods of optimization (e.g. Linear Programming, Integer Programming, Quadratic Programming, etc.) To select the analytical modeling technique most suitable for the structured, complex data and develops custom analytical models', 'Respect for the Individual: Demonstrates and encourages respect for all; builds a high-performing, diverse team; seeks, and embraces differences in people, cultures, ideas and experiences; creates a workplace and equitable experiences where associates feel seen, supported and connected through culture of belonging so associates thrive and perform; drives a positive associate and customer/member experience for all; identifies, attracts, and retains the best, diverse team members', ""Option 1- Bachelor’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years' experience in an analytics related field"", ""Option 2- Master’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years' experience in an analytics related field"", ""Option 3 - 5 years' experience in an analytics or related field"", 'Data science, machine learning, optimization models, Master’s degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly', 'The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture']","['Data Source Identification: Requires knowledge of Functional business domain and scenarios; Categories of data and where it is held; Business data requirements; Database technologies and distributed datastores (e.g. SQL, NoSQL); Data Quality; Existing business systems and processes, including the key drivers and measures of success', 'To support the understanding of the priority order of requirements and service level agreements', 'Help identify the most suitable source for data that is fit for purpose', 'Perform initial data quality checks on extracted data', 'To understand, articulate, and apply principles of the defined strategy to routine business problems that involve a single function', 'Model Deployment and Scaling: Requires knowledge of impact of variables and features on model performance; understanding of servers, model formats to store models', 'To support efforts to ensure that analytical models and techniques used can be deployed into production', 'Support evaluation of the analytical model', 'Support the scalability and sustainability of analytical models', 'To write code to develop the required solution and application features by using the recommended programming language and leveraging business, technical, and data requirements', 'Test the code using the recommended testing approach', 'Apply best practice techniques for model testing and tuning to assess accuracy, fit, validity, and robustness for multi-stage models and model ensembles', 'Data Visualization: Requires knowledge of Visualization guidelines and best practices for complex data types; Multiple data visualization tools (for example, Python, R libraries, GGplot, Matplotlib, Ploty, Tableau, PowerBI etc.); Advanced visualization techniques/ tools; Multiple story plots and structures (OABCDE); Communication & influencing technique; Emotional intelligence', 'To generate appropriate graphical representations of data and model outcomes', 'Understand customer requirements to design appropriate data representation for multiple data sets', 'Work with User Experience designers and User Interface engineers as required to build front end applications', 'Present to and influence the team and business audience using the appropriate data visualization frameworks and conveys clear messages through business and stakeholder understanding', 'Customize communication style based on stakeholder under guidance, and leverages rational arguments', 'Guide and mentor junior associates on story types, structures, and techniques based on context', 'Understanding Business Context: Requires knowledge of Industry and environmental factors; Common business vernacular; Business practices across two or more domains such as product, finance, marketing, sales, technology, business systems, and human resources and in-depth knowledge of related practices; Directly relevant business metrics and business areas', 'To Provide recommendations to business stakeholders to solve complex business issues', 'Develop business cases for projects with a projected return on investment or cost savings', 'Translate business requirements into projects, activities, and tasks and aligns to overall business strategy and develops domain specific artifact', 'Serve as an interpreter and conduit to connect business needs with tangible solutions and results', 'Identify and recommend relevant business insights pertaining to their area of work', ""To translate/ co-own business problems within one's discipline to data related or mathematical solutions"", 'Identify appropriate methods/tools to be leveraged to provide a solution for the problem', 'Share use cases and gives examples to demonstrate how the method would solve the business problem', 'Conduct exploratory data analysis activities (for example, basic statistical analysis, hypothesis testing, statistical inferences) on available data', 'Define and finalize features based on model responses and introduces new or revised features to enhance the analysis and outcomes', 'Identify the dimensions of the experiment, finalize the design, test hypotheses, and conduct the experiment', 'Perform trend and cluster analysis on data to answer practical business problems and provide recommendations and key insights to the business', 'Mentor and guide junior associates on basic modeling and analytics techniques to solve complex problems', 'Demonstrates up-to-date expertise and applies this to the development, execution, and improvement of action plans by providing expert advice and guidance to others in the application of information and best practices; supporting and aligning efforts to meet customer and business needs; and building commitment for perspectives and rationales', 'Provides and supports the implementation of business solutions by building relationships and partnerships with key stakeholders; identifying business needs; determining and carrying out necessary processes and practices; monitoring progress and results; recognizing and capitalizing on improvement opportunities; and adapting to competing demands, organizational changes, and new responsibilities', 'Models compliance with company policies and procedures and supports company mission, values, and standards of ethics and integrity by incorporating these into the development and implementation of business plans; using the Open Door Policy; and demonstrating and assisting others with how to apply these in executing business processes and practices', 'Respect for the Individual: Builds strong and trusting relationships with team members and business partners; works collaboratively and cross-functionally to achieve objectives; and communicates and listens attentively, with energy and positivity to motivate, influence, and inspire commitment and action', 'Acts with Integrity: Maintains and promotes the highest standards of integrity, ethics and compliance; models the Walmart values and leads by example to foster our culture; supports Walmart’s goal of becoming a regenerative company by making a positive impact for associates, customers, members, and the world around us', 'takes action and encourages others to do the same; holds self and others accountable for achieving results in a way that is consistent with our values', 'Acts with Integrity: Acts as an altruistic servant leader and is consistently humble, self-aware, honest, and transparent', 'Service to the Customer/Member: Delivers expected business results while putting the customer/member first and consistently applying an omni-merchant mindset and acts with an Every Day Low Cost mindset to drive value and Every Day Low Prices for customers/members', 'Service to the Customer/Member: Adopts a holistic perspective that considers data, analytics, customer/member insights, and different parts of the business when making plans and shaping the team’s strategy', 'Strive for Excellence: Consistently raises the bar and seeks to improve; demonstrates curiosity and a growth mindset; seeks feedback, asks thoughtful questions, fosters an environment that supports learning, innovation, and learning from mistakes, and intelligent risk-taking; and exhibits resilience in the face of setbacks']",True,"['Deep Learning Frameworks', 'Basic Natural Language Processing', 'Neural Networks']",Deep Learning Frameworks: Using TensorFlow and PyTorch specifically for neural network modeling as part of advanced analytical modeling.; Basic Natural Language Processing: Applying foundational NLP techniques as part of analytical modeling to handle text data.; Neural Networks: Incorporating neural network models within analytical modeling to solve complex data problems.,"['Data Source Identification', 'Data Strategy', 'Model Deployment and Scaling', 'Code Development and Testing', 'Model Assessment and Validation', 'Data Visualization', 'Business Context Understanding', 'Problem Formulation', 'Analytical Modeling', 'Exploratory Data Analysis', 'Programming Languages', 'Open Source Frameworks', 'Optimization Techniques']","Data Source Identification: Involves identifying and assessing various data sources including SQL and NoSQL databases to ensure data quality and suitability for business needs.; Data Strategy: Applying principles of data management, governance, quality standards, and scalability to unlock business value from data assets.; Model Deployment and Scaling: Supporting the deployment and scalability of analytical models by understanding model performance variables and server/model storage formats.; Code Development and Testing: Developing solutions using programming languages like SQL, Python, Java, and C++ and applying testing methods to ensure code quality.; Model Assessment and Validation: Using statistical evaluation metrics such as Chi square, ROC curve, and RMSE to test, tune, and validate model accuracy and robustness.; Data Visualization: Creating graphical representations of complex data and model outcomes using tools like Python libraries, R, GGplot, Matplotlib, Plotly, Tableau, and PowerBI.; Business Context Understanding: Translating business requirements across multiple domains into data-driven solutions and providing actionable insights.; Problem Formulation: Translating business problems into data or mathematical solutions using analytics and big data techniques.; Analytical Modeling: Applying advanced statistical and machine learning techniques such as graphical models, Bayesian inference, SVM, Random Forest, neural networks, and optimization methods to develop custom models.; Exploratory Data Analysis: Conducting statistical analysis, hypothesis testing, and feature engineering to prepare data for modeling and derive insights.; Programming Languages: Utilizing languages such as Python, R, SQL, Java, C++, Scala, and Spark for data analysis, modeling, and solution development.; Open Source Frameworks: Using frameworks like scikit-learn, TensorFlow, and PyTorch for building and deploying machine learning models.; Optimization Techniques: Employing classical and numerical optimization methods including Newton-Raphson, Gradient Descent, Linear Programming, Integer Programming, and Quadratic Programming to improve model performance."
gnaaq_1XFeoRQdOoAAAAAA==,Data Science Internship,"This is a role well suited to an ambitious professional, looking for the next step in their career. As a Data Science Intern, you will be responsible for:

Working with real data to solve real business problems

Using data science and visualization tools

Collaborating with other Data Scientists and Analysts to research new methodologies and deliver new solutions

Siemens is an Equal Opportunity Employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. We do not discriminate based upon race, religion, color, national origin, sex, sexual orientation, gender identity, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.",,2025-07-25,,"['Working with real data to solve real business problems', 'Using data science and visualization tools', 'Collaborating with other Data Scientists and Analysts to research new methodologies and deliver new solutions']",True,[],,"['Data Science', 'Data Visualization']",Data Science: The role involves applying data science techniques to analyze real data and solve business problems.; Data Visualization: Using visualization tools to represent data insights effectively as part of the data science workflow.
vfZjZiS8ZdRbtRuKAAAAAA==,Intern - Data Science,"About the position

RGA is a purpose-driven organization working to solve today's challenges through innovation and collaboration. A Fortune 500 Company and listed among its World's Most Admired Companies, we're the only global reinsurance company to focus primarily on life- and health-related solutions. Join our multinational team of intelligent, motivated, and collaborative people, and help us make financial protection accessible to all. The intern will develop and implement predictive modeling solutions and commercial applications for both RGA internal and external clients. The successful candidate will work on designing and developing data analytic tools to meet the needs of different business applications. Communicate and collaborate with colleagues to ensure highly efficient and innovative performance. The intern will work full time from June-August.

Responsibilities
• Assist in development of predictive modeling for applications.
,
• Create and develop data processing tools for different data sources: tables, texts and images.
,
• Perform tests and develop diagnostic methodology to ensure the accuracy and reliability of data process pipeline.
,
• Validate and clean data from multiple sources. Ensure data quality and integrity for effective modeling.
,
• Participate in research related activities.
,
• Maintain regular and predictable attendance.

Requirements

undefined

Nice-to-haves

undefined

Benefits
• Gain valuable knowledge from and experience with diverse, caring colleagues around the world.
,
• Enjoy a respectful, welcoming environment that fosters individuality and encourages pioneering thought.
,
• Join the bright and creative minds of RGA, and experience vast, endless career potential.",,2025-07-25,,"['The intern will develop and implement predictive modeling solutions and commercial applications for both RGA internal and external clients', 'The successful candidate will work on designing and developing data analytic tools to meet the needs of different business applications', 'Communicate and collaborate with colleagues to ensure highly efficient and innovative performance', 'The intern will work full time from June-August', 'Assist in development of predictive modeling for applications', 'Create and develop data processing tools for different data sources: tables, texts and images', 'Perform tests and develop diagnostic methodology to ensure the accuracy and reliability of data process pipeline', 'Validate and clean data from multiple sources', 'Ensure data quality and integrity for effective modeling', 'Participate in research related activities', 'Maintain regular and predictable attendance']",True,[],,"['Predictive Modeling', 'Data Processing', 'Data Validation and Cleaning', 'Data Pipeline Testing and Diagnostics']","Predictive Modeling: Developing and implementing models to predict outcomes for internal and external business applications.; Data Processing: Creating tools to process various data types including tables, texts, and images for analysis.; Data Validation and Cleaning: Ensuring data quality and integrity by validating and cleaning data from multiple sources.; Data Pipeline Testing and Diagnostics: Performing tests and developing methodologies to ensure accuracy and reliability of data processing pipelines."
8Upetwi2ajJ92iZ0AAAAAA==,"Senior Data Scientist, Costing","Xometry (NASDAQ: XMTR) powers the industries of today and tomorrow by connecting the people with big ideas to the manufacturers who can bring them to life. Xometry's digital marketplace gives manufacturers the critical resources they need to grow their business while also making it easy for buyers at Fortune 1000 companies to tap into global manufacturing capacity.

Xometry is adding a Sr. Data Scientist to our sourcing team. The ideal candidate will have a passion for using machine learning tools and techniques to construct, optimize, and evaluate predictive models that predict the likelihood of different business outcomes. Additionally, this person will use their knowledge of probability and statistics to make defensible statistical inferences from data.

Responsibilities:
• Use data science and machine learning principles to develop effective predictive models
• Write software to prepare, clean, and sample data for use in developing predictive models
• Use cloud resources (e.g., Amazon Web Services) to prepare and process data
• Query and extract data from databases (Snowflake)
• Use data analysis and visualization tools (examples include SQL, Python, Jupyter Notebooks, and Looker) to inform the business strategy
• Relentlessly iterate solutions within a fast-paced environment where ambiguity is the norm
• Solve challenging, uncharted problems
• Work in an environment that thrives on teamwork and continuous learning opportunities

Requirements:
• Bachelor's degree required; degree in applied math, computer science, natural sciences or engineering preferred
• M.S. or Ph.D. in a related field highly desired
• 5+ years of experience with machine learning, statistical modeling, and optimization techniques
• Fluent in Python (pandas, numpy, SciPy, and scikit-learn preferred)
• Proficient in linear algebra and statistics
• Familiar with scientific software principals, e.g. versioning systems, reproducibility
• Experience in the manufacturing industry is desired
• Must be a US Citizen or Green Card holder (ITAR)

#LI-Hybrid

Xometry is an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran, or disability status.

For US based roles: Xometry participates in E-Verify and after a job offer is accepted, will provide the federal government with your Form I-9 information to confirm that you are authorized to work in the U.S.",2025-06-26T00:00:00.000Z,2025-07-25,"['5+ years of experience with machine learning, statistical modeling, and optimization techniques', 'Proficient in linear algebra and statistics', 'Familiar with scientific software principals, e.g. versioning systems, reproducibility', 'Must be a US Citizen or Green Card holder (ITAR)']","['The ideal candidate will have a passion for using machine learning tools and techniques to construct, optimize, and evaluate predictive models that predict the likelihood of different business outcomes', 'Additionally, this person will use their knowledge of probability and statistics to make defensible statistical inferences from data', 'Use data science and machine learning principles to develop effective predictive models', 'Write software to prepare, clean, and sample data for use in developing predictive models', 'Use cloud resources (e.g., Amazon Web Services) to prepare and process data', 'Query and extract data from databases (Snowflake)', 'Use data analysis and visualization tools (examples include SQL, Python, Jupyter Notebooks, and Looker) to inform the business strategy', 'Relentlessly iterate solutions within a fast-paced environment where ambiguity is the norm', 'Solve challenging, uncharted problems', 'Work in an environment that thrives on teamwork and continuous learning opportunities']",True,[],,"['Predictive Modeling', 'Machine Learning', 'Statistical Modeling', 'Data Preparation and Cleaning', 'Cloud Data Processing', 'SQL', 'Python', 'Data Visualization and BI Tools', 'Scientific Software Practices', 'Linear Algebra and Statistics']","Predictive Modeling: Developing models to predict business outcomes using machine learning and statistical techniques.; Machine Learning: Applying machine learning tools and principles to construct, optimize, and evaluate predictive models.; Statistical Modeling: Using probability and statistics to make defensible inferences from data and support predictive modeling.; Data Preparation and Cleaning: Writing software to prepare, clean, and sample data for model development.; Cloud Data Processing: Utilizing cloud resources such as Amazon Web Services to prepare and process data.; SQL: Querying and extracting data from databases like Snowflake to support analysis and modeling.; Python: Using Python and libraries such as pandas, numpy, SciPy, and scikit-learn for data analysis and machine learning.; Data Visualization and BI Tools: Employing tools like Jupyter Notebooks and Looker to visualize data and inform business strategy.; Scientific Software Practices: Applying principles like version control and reproducibility in software development for data science.; Linear Algebra and Statistics: Leveraging mathematical foundations essential for building and understanding predictive models."
Kja4P_O8wJbP0NWVAAAAAA==,Associate Data Analyst,"Responsiblities Importing data from PDH OBIA and OBIEE finalizing and reconciling reports for various geographies in Excel PPT and Smartsheets. Supporting teams across various geographies in managing schedules reports dashboards and workflows. Create graphs to compare durations between plan trending and actuals deliveries. Support in creating dashboards on early on time and delayed deliveries broken up as per geographies. Troubleshoot Smartsheet access issues. Grant and remove Smartsheet Access as per requirements. Manage data including clean up and back up.

Key Skills Statistical programming. Machine learning. Probability and statistics. Data management. Statistical visualization. Econometrics.",,2025-07-25,"['Key Skills Statistical programming', 'Machine learning', 'Probability and statistics']","['Responsiblities Importing data from PDH OBIA and OBIEE finalizing and reconciling reports for various geographies in Excel PPT and Smartsheets', 'Supporting teams across various geographies in managing schedules reports dashboards and workflows', 'Create graphs to compare durations between plan trending and actuals deliveries', 'Support in creating dashboards on early on time and delayed deliveries broken up as per geographies', 'Troubleshoot Smartsheet access issues', 'Grant and remove Smartsheet Access as per requirements', 'Manage data including clean up and back up']",True,[],,"['Statistical programming', 'Machine learning', 'Probability and statistics', 'Data management', 'Statistical visualization', 'Econometrics', 'Excel', 'Smartsheet', 'OBIA and OBIEE']","Statistical programming: Used for analyzing and processing data to support reporting and visualization tasks.; Machine learning: Applied to develop predictive models or analyze data patterns as part of data analysis.; Probability and statistics: Fundamental for performing statistical analysis and interpreting data trends.; Data management: Involves cleaning, backing up, and organizing data to ensure accuracy and availability.; Statistical visualization: Creating graphs and dashboards to compare plan versus actual delivery durations and other metrics.; Econometrics: Used for applying statistical methods to economic data for analysis and forecasting.; Excel: Utilized for data import, report finalization, and creating visualizations.; Smartsheet: Used for managing schedules, reports, dashboards, and workflows across teams.; OBIA and OBIEE: Data sources from which data is imported for analysis and reporting."
qB4HAz9l6SsBV-KYAAAAAA==,"Staff, Data Scientist – Conversational AI - Full-time / Part-time","**Position Summary...**
• *What you'll do...**

Cortex Team is Walmarts core A.I. conversational platform, powering the vision of delivering the worlds best personal assistants to Walmarts customers, accessible via natural voice commands, text messages, rich UI interactions, and a mix of all of the above via multi-modal experiences.

We believe _conversations_ are a natural and powerful user interface for interacting with technology and enable a richer customer experiences both online and in-store. We are building and designing the next generation of Natural Language Understanding (NLU) services that other teams can easily integrate and leverage, and build rich experiences: from pure voice and text shopping assistants (Siri,Sparky (https://tech.walmart.com/content/walmart-global-tech/en\_us/blog/post/walmart-is-building-a-genai-powered-shopping-assistant.html) ), to customer care channels, to mobile apps with rich, intertwined, multi-modal interaction modes (Me@Walmart (https://apps.apple.com/us/app/me-walmart/id1459898418) ).

Interested in diving in?

We need passionate and seasoned NLP data-scientists to help us improve and evolve our capabilities, taking into account the full conversational context, multi-modal interactions, and an ever increasing list of use cases.

Come at the right time, and you will have an enormous opportunity to make a massive impact on the design, architecture, and implementation of an innovative, mission critical product, driven by data-science, used every day, by people you know, and which customers love.

As part of the emerging tech group, you will also have the additional opportunity of building demos, proof of concepts, creating white papers, writing blogs, etc.

Minimum Qualifications

+ Experience with Python; solid knowledge SQL.

+ Hands on experience with classical ML models, test/train/evaluation metrics, key parameters/techniques that affect model performance

+ Understanding of relevant statistical measures such as confidence intervals, significance of error measurements, development and evaluation data sets.

+ Familiarity and ideally experience with NLU/NLP, more recent deep ML models (e.g., Transformers, BERT, Llama, Gpts, Gemini) and safe fine-tuning of these.

+ A business analytical mind; ability to communicate with consumers of the model and present results in intuitive ways.

+ Experience analyzing data to identify patterns and conducting error/deviation analysis; passion for fixing issues in the data and finding the optimal representation.

+ Ability to take a project from scoping requirements through actual launch.

+ A continuous drive to explore, improve, enhance, automate, and optimize models and products.

+ Excellent oral and written communication skills.

+ Bachelors degree or certification in Machine Learning, Computer Science, Engineering, Mathematics, Statistics or any other related field.

Preferred Qualifications

+ Exposure to real-world, production grade agentic systems.

+ Familiarity with LLMs serving optimizations and multi-LoRa

+ Ability to develop experimental and analytic plans for data modeling processes, use of strong baselines, ability to accurately determine cause and effect relations

+ Strong attention to detail and exceptional level of organization

+ Proven ability to achieve results in a fast paced, highly collaborative, dynamic work environment

+ Hands-on expertise in many disparate technologies and the full model lifecycle, typically ranging from data pipelines, data extraction, model training, model serving, labeling tools, ML-ops, ad-hoc tooling and all points in between.

+ PhD in a relevant field (Machine Learning, Computer Science, Engineering, Mathematics, Physics, Statistics or a related field)
• *About Walmart Global Tech**

Imagine working in an environment where one line of code can make life easier for hundreds of millions of people. Thats what we do at Walmart Global Tech. Were a team of software engineers, data scientists, cybersecurity experts and service professionals within the worlds leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.
• *Flexible, hybrid work:**

We use a hybrid way of working that is primarily in office coupled with virtual when not onsite. Our campuses serve as a hub to enhance collaboration, bring us together for purpose and deliver on business needs. This approach helps us make quicker decisions, remove location barriers across our global team and be more flexible in our personal lives.
• *Benefits:**

Benefits: Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.
• *Equal Opportunity Employer:**

Walmart, Inc. is an Equal Opportunity Employer By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting, and valuing unique styles, experiences, identities, ideas and opinions while being welcoming of all people.

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

‎

‎

‎

You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.

‎

For information about PTO, see https://one.walmart.com/notices .

‎

‎

Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

‎

Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

‎

For information about benefits and eligibility, see One.Walmart (https://bit.ly/3iOOb1J) .

‎

The annual salary range for this position is $143,000.00-$286,000.00

‎

Additional compensation includes annual or quarterly performance bonuses.

‎

Additional compensation for certain positions may also include:

‎

‎

- Stock

‎

‎
• *Minimum Qualifications...**

_Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications._

Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 4 years' experience in an analytics related field. Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 2 years' experience in an analytics related field. Option 3: 6 years' experience in an analytics or related field
• *Preferred Qualifications...**

_Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications._

Data science, machine learning, optimization models, PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.
• *Primary Location...**

680 West California Avenue, Sunnyvale, CA 94086-4834, United States of America

Walmart, Inc. is an Equal Opportunity Employer- By Choice. We believe we are best equipped to help our associates, customers, and the communities we serve live better when we really know them. That means understanding, respecting, and valuing diversity- unique styles, experiences, identities, abilities, ideas and opinions- while being inclusive of all people.
• *Position Summary...**
• *What you'll do...**

Cortex Team is Walmarts core A.I. conversational platform, powering the vision of delivering the worlds best personal assistants to Walmarts customers, accessible via natural voice commands, text messages, rich UI interactions, and a mix of all of the above via multi-modal experiences.

We believe _conversations_ are a natural and powerful user interface for interacting with technology and enable a richer customer experiences both online and in-store. We are building and designing the next generation of Natural Language Understanding (NLU) services that other teams can easily integrate and leverage, and build rich experiences: from pure voice and text shopping assistants (Siri,Sparky (https://tech.walmart.com/content/walmart-global-tech/en\_us/blog/post/walmart-is-building-a-genai-powered-shopping-assistant.html) ), to customer care channels, to mobile apps with rich, intertwined, multi-modal interaction modes (Me@Walmart (https://apps.apple.com/us/app/me-walmart/id1459898418) ).

Interested in diving in?

We need passionate and seasoned NLP data-scientists to help us improve and evolve our capabilities, taking into account the full conversational context, multi-modal interactions, and an ever increasing list of use cases.

Come at the right time, and you will have an enormous opportunity to make a massive impact on the design, architecture, and implementation of an innovative, mission critical product, driven by data-science, used every day, by people you know, and which customers love.

As part of the emerging tech group, you will also have the additional opportunity of building demos, proof of concepts, creating white papers, writing blogs, etc.

Minimum Qualifications

+ Experience with Python; solid knowledge SQL.

+ Hands on experience with classical ML models, test/train/evaluation metrics, key parameters/techniques that affect model performance

+ Understanding of relevant statistical measures such as confidence intervals, significance of error measurements, development and evaluation data sets.

+ Familiarity and ideally experience with NLU/NLP, more recent deep ML models (e.g., Transformers, BERT, Llama, Gpts, Gemini) and safe fine-tuning of these.

+ A business analytical mind; ability to communicate with consumers of the model and present results in intuitive ways.

+ Experience analyzing data to identify patterns and conducting error/deviation analysis; passion for fixing issues in the data and finding the optimal representation.

+ Ability to take a project from scoping requirements through actual launch.

+ A continuous drive to explore, improve, enhance, automate, and optimize models and products.

+ Excellent oral and written communication skills.

+ Bachelors degree or certification in Machine Learning, Computer Science, Engineering, Mathematics, Statistics or any other related field.

Preferred Qualifications

+ Exposure to real-world, production grade agentic systems.

+ Familiarity with LLMs serving optimizations and multi-LoRa

+ Ability to develop experimental and analytic plans for data modeling processes, use of strong baselines, ability to accurately determine cause and effect relations

+ Strong attention to detail and exceptional level of organization

+ Proven ability to achieve results in a fast paced, highly collaborative, dynamic work environment

+ Hands-on expertise in many disparate technologies and the full model lifecycle, typically ranging from data pipelines, data extraction, model training, model serving, labeling tools, ML-ops, ad-hoc tooling and all points in between.

+ PhD in a relevant field (Machine Learning, Computer Science, Engineering, Mathematics, Physics, Statistics or a related field)
• *About Walmart Global Tech**

Imagine working in an environment where one line of code can make life easier for hundreds of millions of people. Thats what we do at Walmart Global Tech. Were a team of software engineers, data scientists, cybersecurity experts and service professionals within the worlds leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.
• *Flexible, hybrid work:**

We use a hybrid way of working that is primarily in office coupled with virtual when not onsite. Our campuses serve as a hub to enhance collaboration, bring us together for purpose and deliver on business needs. This approach helps us make quicker decisions, remove location barriers across our global team and be more flexible in our personal lives.
• *Benefits:**

Benefits: Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.
• *Equal Opportunity Employer:**

Walmart, Inc. is an Equal Opportunity Employer By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting, and valuing unique styles, experiences, identities, ideas and opinions while being welcoming of all people.

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

‎

‎

‎

You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.

‎

For information about PTO, see https://one.walmart.com/notices .

‎

‎

Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

‎

Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

‎

For information about benefits and eligibility, see One.Walmart (https://bit.ly/3iOOb1J) .

‎

The annual salary range for this position is $143,000.00-$286,000.00

‎

Additional compensation includes annual or quarterly performance bonuses.

‎

Additional compensation for certain positions may also include:

‎

‎

- Stock

‎

‎
• *Minimum Qualifications...**

_Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications._

Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 4 years' experience in an analytics related field. Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 2 years' experience in an analytics related field. Option 3: 6 years' experience in an analytics or related field
• *Preferred Qualifications...**

_Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications._

Data science, machine learning, optimization models, PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.
• *Primary Location...**

680 West California Avenue, Sunnyvale, CA 94086-4834, United States of America

Walmart, Inc. is an Equal Opportunity Employer- By Choice. We believe we are best equipped to help our associates, customers, and the communities we serve live better when we really know them. That means understanding, respecting, and valuing diversity- unique styles, experiences, identities, abilities, ideas and opinions- while being inclusive of all people.",2025-07-24T00:00:00.000Z,2025-07-25,"['Experience with Python; solid knowledge SQL', 'Hands on experience with classical ML models, test/train/evaluation metrics, key parameters/techniques that affect model performance', 'Understanding of relevant statistical measures such as confidence intervals, significance of error measurements, development and evaluation data sets', 'Familiarity and ideally experience with NLU/NLP, more recent deep ML models (e.g., Transformers, BERT, Llama, Gpts, Gemini) and safe fine-tuning of these', 'A business analytical mind; ability to communicate with consumers of the model and present results in intuitive ways', 'Experience analyzing data to identify patterns and conducting error/deviation analysis; passion for fixing issues in the data and finding the optimal representation', 'Ability to take a project from scoping requirements through actual launch', 'A continuous drive to explore, improve, enhance, automate, and optimize models and products', 'Excellent oral and written communication skills', 'Bachelors degree or certification in Machine Learning, Computer Science, Engineering, Mathematics, Statistics or any other related field', ""Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 4 years' experience in an analytics related field"", ""Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 2 years' experience in an analytics related field"", ""Option 3: 6 years' experience in an analytics or related field"", 'Data science, machine learning, optimization models, PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly', 'The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture', 'We need passionate and seasoned NLP data-scientists to help us improve and evolve our capabilities, taking into account the full conversational context, multi-modal interactions, and an ever increasing list of use cases', 'Experience with Python; solid knowledge SQL', 'Hands on experience with classical ML models, test/train/evaluation metrics, key parameters/techniques that affect model performance', 'Understanding of relevant statistical measures such as confidence intervals, significance of error measurements, development and evaluation data sets', 'Familiarity and ideally experience with NLU/NLP, more recent deep ML models (e.g., Transformers, BERT, Llama, Gpts, Gemini) and safe fine-tuning of these', 'A business analytical mind; ability to communicate with consumers of the model and present results in intuitive ways', 'Experience analyzing data to identify patterns and conducting error/deviation analysis; passion for fixing issues in the data and finding the optimal representation', 'Ability to take a project from scoping requirements through actual launch', 'A continuous drive to explore, improve, enhance, automate, and optimize models and products', 'Excellent oral and written communication skills', 'Bachelors degree or certification in Machine Learning, Computer Science, Engineering, Mathematics, Statistics or any other related field', 'That means understanding, respecting, and valuing unique styles, experiences, identities, ideas and opinions while being welcoming of all people', ""Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 4 years' experience in an analytics related field"", ""Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 2 years' experience in an analytics related field"", ""Option 3: 6 years' experience in an analytics or related field"", 'Data science, machine learning, optimization models, PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly', 'The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture']","['As part of the emerging tech group, you will also have the additional opportunity of building demos, proof of concepts, creating white papers, writing blogs, etc', 'Come at the right time, and you will have an enormous opportunity to make a massive impact on the design, architecture, and implementation of an innovative, mission critical product, driven by data-science, used every day, by people you know, and which customers love', 'As part of the emerging tech group, you will also have the additional opportunity of building demos, proof of concepts, creating white papers, writing blogs, etc']",True,"['Natural Language Understanding', 'Transformers', 'BERT', 'Large Language Models', 'Fine-tuning of Large Language Models', 'Multi-LoRa', 'Agentic Systems']","Natural Language Understanding: Developing and improving NLU services to enable conversational AI capabilities in voice and text assistants.; Transformers: Deep learning architectures used for advanced NLP tasks, including language understanding and generation.; BERT: A transformer-based model applied for natural language understanding tasks within conversational AI.; Large Language Models: Models such as GPT, LLaMA, and Gemini used for generating and understanding human-like text in AI applications.; Fine-tuning of Large Language Models: Adapting pre-trained LLMs safely to specific tasks or domains to improve performance in conversational AI.; Multi-LoRa: Techniques for optimizing serving of large language models to improve efficiency and scalability.; Agentic Systems: Production-grade autonomous AI systems that interact with users or environments, relevant to conversational AI.","['Python', 'SQL', 'Classical Machine Learning Models', 'Statistical Measures', 'Data Analysis and Error Analysis', 'Data Pipelines', 'Model Training and Serving', 'ML Ops', 'Scikit-learn', 'TensorFlow', 'PyTorch', 'Spark', 'Scala', 'R', 'Optimization Models', 'Experimental and Analytic Planning']","Python: Used as a primary programming language for data analysis, model development, and scripting in the data science workflow.; SQL: Essential for querying and managing structured data from databases to support data analysis and feature engineering.; Classical Machine Learning Models: Applied for predictive modeling and data-driven decision making, including training, testing, and evaluation of models.; Statistical Measures: Used to evaluate model performance and data quality, including confidence intervals and significance testing.; Data Analysis and Error Analysis: Involves identifying patterns, diagnosing data issues, and optimizing data representations to improve model accuracy.; Data Pipelines: Managing the end-to-end flow of data from extraction through transformation to model training and deployment.; Model Training and Serving: Processes involved in building machine learning models and deploying them into production environments.; ML Ops: Practices and tools for operationalizing machine learning models, including monitoring, maintenance, and automation.; Scikit-learn: An open-source Python library used for implementing classical machine learning algorithms and model evaluation.; TensorFlow: Used as a framework for building and training machine learning models, including deep learning architectures.; PyTorch: A deep learning framework employed for model development, experimentation, and deployment.; Spark: A big data processing framework used for scalable data analytics and machine learning workflows.; Scala: Programming language often used with Spark for data processing and analytics.; R: Statistical programming language used for data analysis, modeling, and visualization.; Optimization Models: Mathematical models used to improve decision-making and resource allocation within data science projects.; Experimental and Analytic Planning: Designing experiments and analytic strategies to validate models and determine cause-effect relationships."
otZsAj2XLUruWbW4AAAAAA==,"Intern, Data Science-Remote","Overview

Since our founding in 1924, we've cut cardiovascular disease deaths in half, but there is still so much more to do. To overcome today’s biggest health challenges and accelerate this progress, we need passionate individuals like you. Join our movement, be part of the progress, and help ensure a healthier future for all. You matter, and so does the impact you can make with us.

This internship supports the Data Science team and offers hands-on experience in data science and statistical analysis within clinical or biomedical research settings. Interns will contribute to the development of machine learning models, conduct experimental design and evaluation, and assist in summarizing results and drafting manuscripts. You will have the opportunity to work closely with staff across departments and contribute to impactful, high-quality research.

The American Heart Association’s Internship Program provides college students an opportunity for hands-on experience in various facets for individuals interested in gaining work experience with a non-profit, voluntary health organization.

The Association offers many resources to help you maintain work-life harmonization through your changing needs and life situations. To help you be successful, you will have access to Heart U, our award-winning corporate university, as well as training and support locally and through our National Center.

\#TheAHALife is more than a company culture; it is our way of life. It embodies our commitment to work-life harmonization and is guided by our core values where our employees can thrive both personally and professionally. Discover why you will Be Seen. Be Heard. Be Valued at the American Heart Association by following us on LinkedIn, Instagram, Facebook, X, and at heart.jobs.

Internship Overview:
• Time Commitment: 25 hours per week
• Internship Duration: 9/8/25-12/5/25
• Location:Remote
• Salary: $23.00 per hour

Internship Outcomes:

Individuals participating in the internship program are provided with an opportunity to:
• Gain important and practical job skills to be successful in a non-profit environment.
• Opportunity to explore a career-path with a reputable voluntary health/service organization.
• Complete an internship that enriches your academic and professional resume as well as enriching your personal life by making a difference in the lives of others.

Responsibilities

Tasks could include things like the following:
• Retrieve, process, and clean large-scale biomedical data, build high-quality datasets.
• Design and develop machine learning models for clinical or biomedical research, with a focus on Large Language Models (LLMs), medical imaging, or multimodal AI.
• Conduct experimental design and evaluation, including statistical analysis, performance assessment, error analysis, and robustness testing.
• Collaborate with cross-functional teams, including clinicians, data scientists, and engineers, to refine research questions and interpret results.
• Contribute to scientific writing, including drafting manuscripts for peer-reviewed journals and preparing materials for presentations or conferences.
• Develop interactive data visualization tools to communicate insights clearly.

Qualifications
• Currently pursuing an MS or PhD degree in Computer Science, Biomedical Informatics, Engineering, Statistics, or a related quantitative field.
• Demonstrated experience with large-scale machine learning or foundation models, including training, fine-tuning, and evaluating LLMs (e.g., GPT, BERT) or vision models (e.g., CNNs, Vision Transformers.
• Strong programming skills in Python (or R), with experience in machine learning frameworks.
• In-depth knowledge of study design, data analysis, and statistical methodologies, with prior experience working with clinical or biomedical data (e.g., EHRs, images.
• Prior authorship or co-authorship of peer-reviewed publications is strongly preferred.
• Experience with interactive visualization tools (e.g., Plotly, Dash, D3.js, or React) is a plus.
• Excellent communication skills, with the ability to present results to both technical and non-technical audiences.
• Ability to deal professionally in a corporate or non-profit environment and assume responsibility for guiding projects and programs from inception through completion.
• Ability to work in a fast-paced, dynamic environment managing multiple priorities involving multiple entities.
• Intermediate to excellent proficiency in MS Word, Excel, Outlook and PowerPoint.
• Minimum availability of 20 hrs/wk, M-F between the hours of 8:00am-5:00pm.
• Required Equipment: Reliable WiFi Connection.
• Must be legally authorized to work in the United States for any employer without sponsorship, now or in the future. For any roles working remotely, the work must also be performed inside the United States, not in a foreign country.

Compensation & Benefits

The job application window is expected to close: August 1, 2025.

The American Heart Association invests in its people. Visit Rewards & Benefits to see more details.
• Compensation and Performance – Attracting talented, committed interns means offering competitive compensation, ongoing professional development and training, and an environment in which to work and grow. And we do.
• Professional Development – You can join one of our many Employee Resource Groups (ERG) or be a mentor/mentee in our professional mentoring program. HeartU is the Association’s national online university, with more than 100,000 resources designed to meet your needs and busy schedule.
• Healthcare Benefits – You will have the opportunity to participate in our Teladoc General Medical and Behavioral Health programs. We also provide access to our Employee Assistance Program (EAP) at no cost as a confidential program designed to assist employees and family members with personal issues that affect their relationships at home or at work.

Apply Today:

So, are you ready to intern for the largest voluntary health organization dedicated to fighting heart disease, stroke, and other cardiovascular diseases?

The American Heart Association’s 2028 Goal: Building on over 100 years of trusted leadership in cardiovascular and brain health, by 2028 the AHA will drive breakthroughs and implement proven solutions in science, policy, and care for healthier people and communities. The greatest discoveries in health must reach everyone where they are.

At American Heart Association | American Stroke Association, our mission is to be a relentless force for a world of longer, healthier lives, regardless of race, ethnicity, gender, gender identity, religion, age, language, sexual orientation, national origin and physical or cognitive abilities.

This position not a match with your skills? Click here to see other opportunities.

In accordance with local and state laws where applicable, qualified applicants with arrest or conviction records will be considered for employment.

EOE/Protected Veterans/Persons with Disabilities

\#AHAWAYUP, #LI-DNP

Join our Talent Community!

Join our Talent Community to receive updates on new opportunities and future events.

Default: Location : LocationUS-TX-Dallas

Posted Date57 minutes ago(7/9/2025 9:51 AM)

Requisition ID2025-16131

Job CategoryAdministrative Support

Position TypePart Time

Overview

Since our founding in 1924, we've cut cardiovascular disease deaths in half, but there is still so much more to do. To overcome today’s biggest health challenges and accelerate this progress, we need passionate individuals like you. Join our movement, be part of the progress, and help ensure a healthier future for all. You matter, and so does the impact you can make with us.

This internship supports the Data Science team and offers hands-on experience in data science and statistical analysis within clinical or biomedical research settings. Interns will contribute to the development of machine learning models, conduct experimental design and evaluation, and assist in summarizing results and drafting manuscripts. You will have the opportunity to work closely with staff across departments and contribute to impactful, high-quality research.

The American Heart Association’s Internship Program provides college students an opportunity for hands-on experience in various facets for individuals interested in gaining work experience with a non-profit, voluntary health organization.

The Association offers many resources to help you maintain work-life harmonization through your changing needs and life situations. To help you be successful, you will have access to Heart U, our award-winning corporate university, as well as training and support locally and through our National Center.

\#TheAHALife is more than a company culture; it is our way of life. It embodies our commitment to work-life harmonization and is guided by our core values where our employees can thrive both personally and professionally. Discover why you will Be Seen. Be Heard. Be Valued at the American Heart Association by following us on LinkedIn, Instagram, Facebook, X, and at heart.jobs.

Internship Overview:
• Time Commitment: 25 hours per week
• Internship Duration: 9/8/25-12/5/25
• Location:Remote
• Salary: $23.00 per hour

Internship Outcomes:

Individuals participating in the internship program are provided with an opportunity to:
• Gain important and practical job skills to be successful in a non-profit environment.
• Opportunity to explore a career-path with a reputable voluntary health/service organization.
• Complete an internship that enriches your academic and professional resume as well as enriching your personal life by making a difference in the lives of others.

Responsibilities

Tasks could include things like the following:
• Retrieve, process, and clean large-scale biomedical data, build high-quality datasets.
• Design and develop machine learning models for clinical or biomedical research, with a focus on Large Language Models (LLMs), medical imaging, or multimodal AI.
• Conduct experimental design and evaluation, including statistical analysis, performance assessment, error analysis, and robustness testing.
• Collaborate with cross-functional teams, including clinicians, data scientists, and engineers, to refine research questions and interpret results.
• Contribute to scientific writing, including drafting manuscripts for peer-reviewed journals and preparing materials for presentations or conferences.
• Develop interactive data visualization tools to communicate insights clearly.

Qualifications
• Currently pursuing an MS or PhD degree in Computer Science, Biomedical Informatics, Engineering, Statistics, or a related quantitative field.
• Demonstrated experience with large-scale machine learning or foundation models, including training, fine-tuning, and evaluating LLMs (e.g., GPT, BERT) or vision models (e.g., CNNs, Vision Transformers.
• Strong programming skills in Python (or R), with experience in machine learning frameworks.
• In-depth knowledge of study design, data analysis, and statistical methodologies, with prior experience working with clinical or biomedical data (e.g., EHRs, images.
• Prior authorship or co-authorship of peer-reviewed publications is strongly preferred.
• Experience with interactive visualization tools (e.g., Plotly, Dash, D3.js, or React) is a plus.
• Excellent communication skills, with the ability to present results to both technical and non-technical audiences.
• Ability to deal professionally in a corporate or non-profit environment and assume responsibility for guiding projects and programs from inception through completion.
• Ability to work in a fast-paced, dynamic environment managing multiple priorities involving multiple entities.
• Intermediate to excellent proficiency in MS Word, Excel, Outlook and PowerPoint.
• Minimum availability of 20 hrs/wk, M-F between the hours of 8:00am-5:00pm.
• Required Equipment: Reliable WiFi Connection.
• Must be legally authorized to work in the United States for any employer without sponsorship, now or in the future. For any roles working remotely, the work must also be performed inside the United States, not in a foreign country.

Compensation & Benefits

The job application window is expected to close: August 1, 2025.

The American Heart Association invests in its people. Visit Rewards & Benefits to see more details.
• Compensation and Performance – Attracting talented, committed interns means offering competitive compensation, ongoing professional development and training, and an environment in which to work and grow. And we do.
• Professional Development – You can join one of our many Employee Resource Groups (ERG) or be a mentor/mentee in our professional mentoring program. HeartU is the Association’s national online university, with more than 100,000 resources designed to meet your needs and busy schedule.
• Healthcare Benefits – You will have the opportunity to participate in our Teladoc General Medical and Behavioral Health programs. We also provide access to our Employee Assistance Program (EAP) at no cost as a confidential program designed to assist employees and family members with personal issues that affect their relationships at home or at work.

Apply Today:

So, are you ready to intern for the largest voluntary health organization dedicated to fighting heart disease, stroke, and other cardiovascular diseases?

The American Heart Association’s 2028 Goal: Building on over 100 years of trusted leadership in cardiovascular and brain health, by 2028 the AHA will drive breakthroughs and implement proven solutions in science, policy, and care for healthier people and communities. The greatest discoveries in health must reach everyone where they are.

At American Heart Association | American Stroke Association, our mission is to be a relentless force for a world of longer, healthier lives, regardless of race, ethnicity, gender, gender identity, religion, age, language, sexual orientation, national origin and physical or cognitive abilities.

This position not a match with your skills? Click here to see other opportunities.

In accordance with local and state laws where applicable, qualified applicants with arrest or conviction records will be considered for employment.

EOE/Protected Veterans/Persons with Disabilities

\#AHAWAYUP, #LI-DNP

Join our Talent Community!

Join our Talent Community to receive updates on new opportunities and future events.

Default: Location : LocationUS-TX-Dallas

Posted Date57 minutes ago(7/9/2025 9:51 AM)

Requisition ID2025-16131

Job CategoryAdministrative Support

Position TypePart Time",2025-07-09T00:00:00.000Z,2025-07-25,"['Currently pursuing an MS or PhD degree in Computer Science, Biomedical Informatics, Engineering, Statistics, or a related quantitative field', 'Demonstrated experience with large-scale machine learning or foundation models, including training, fine-tuning, and evaluating LLMs (e.g., GPT, BERT) or vision models (e.g., CNNs, Vision Transformers', 'Strong programming skills in Python (or R), with experience in machine learning frameworks', 'In-depth knowledge of study design, data analysis, and statistical methodologies, with prior experience working with clinical or biomedical data (e.g., EHRs, images', 'Excellent communication skills, with the ability to present results to both technical and non-technical audiences', 'Ability to deal professionally in a corporate or non-profit environment and assume responsibility for guiding projects and programs from inception through completion', 'Ability to work in a fast-paced, dynamic environment managing multiple priorities involving multiple entities', 'Intermediate to excellent proficiency in MS Word, Excel, Outlook and PowerPoint', 'Minimum availability of 20 hrs/wk, M-F between the hours of 8:00am-5:00pm', 'Required Equipment: Reliable WiFi Connection', 'Must be legally authorized to work in the United States for any employer without sponsorship, now or in the future', 'For any roles working remotely, the work must also be performed inside the United States, not in a foreign country', 'Gain important and practical job skills to be successful in a non-profit environment', 'Opportunity to explore a career-path with a reputable voluntary health/service organization', 'Currently pursuing an MS or PhD degree in Computer Science, Biomedical Informatics, Engineering, Statistics, or a related quantitative field', 'Demonstrated experience with large-scale machine learning or foundation models, including training, fine-tuning, and evaluating LLMs (e.g., GPT, BERT) or vision models (e.g., CNNs, Vision Transformers', 'Strong programming skills in Python (or R), with experience in machine learning frameworks', 'In-depth knowledge of study design, data analysis, and statistical methodologies, with prior experience working with clinical or biomedical data (e.g., EHRs, images', 'Excellent communication skills, with the ability to present results to both technical and non-technical audiences', 'Ability to deal professionally in a corporate or non-profit environment and assume responsibility for guiding projects and programs from inception through completion', 'Ability to work in a fast-paced, dynamic environment managing multiple priorities involving multiple entities', 'Intermediate to excellent proficiency in MS Word, Excel, Outlook and PowerPoint', 'Minimum availability of 20 hrs/wk, M-F between the hours of 8:00am-5:00pm', 'Required Equipment: Reliable WiFi Connection', 'Must be legally authorized to work in the United States for any employer without sponsorship, now or in the future', 'For any roles working remotely, the work must also be performed inside the United States, not in a foreign country']","['This internship supports the Data Science team and offers hands-on experience in data science and statistical analysis within clinical or biomedical research settings', 'Interns will contribute to the development of machine learning models, conduct experimental design and evaluation, and assist in summarizing results and drafting manuscripts', 'You will have the opportunity to work closely with staff across departments and contribute to impactful, high-quality research', 'Retrieve, process, and clean large-scale biomedical data, build high-quality datasets', 'Design and develop machine learning models for clinical or biomedical research, with a focus on Large Language Models (LLMs), medical imaging, or multimodal AI', 'Conduct experimental design and evaluation, including statistical analysis, performance assessment, error analysis, and robustness testing', 'Collaborate with cross-functional teams, including clinicians, data scientists, and engineers, to refine research questions and interpret results', 'Contribute to scientific writing, including drafting manuscripts for peer-reviewed journals and preparing materials for presentations or conferences', 'Develop interactive data visualization tools to communicate insights clearly', 'This internship supports the Data Science team and offers hands-on experience in data science and statistical analysis within clinical or biomedical research settings', 'Interns will contribute to the development of machine learning models, conduct experimental design and evaluation, and assist in summarizing results and drafting manuscripts', 'You will have the opportunity to work closely with staff across departments and contribute to impactful, high-quality research', 'Retrieve, process, and clean large-scale biomedical data, build high-quality datasets', 'Design and develop machine learning models for clinical or biomedical research, with a focus on Large Language Models (LLMs), medical imaging, or multimodal AI', 'Conduct experimental design and evaluation, including statistical analysis, performance assessment, error analysis, and robustness testing', 'Collaborate with cross-functional teams, including clinicians, data scientists, and engineers, to refine research questions and interpret results', 'Contribute to scientific writing, including drafting manuscripts for peer-reviewed journals and preparing materials for presentations or conferences', 'Develop interactive data visualization tools to communicate insights clearly']",True,"['Large Language Models', 'Vision Transformers', 'Convolutional Neural Networks', 'Multimodal AI']","Large Language Models: Designing, training, fine-tuning, and evaluating foundation models like GPT and BERT for biomedical research applications.; Vision Transformers: Applying advanced neural network architectures for medical imaging analysis within the research projects.; Convolutional Neural Networks: Using CNNs as part of vision models to analyze medical images in clinical research.; Multimodal AI: Integrating multiple data modalities such as text and images using AI models to enhance biomedical research insights.","['Data Cleaning and Processing', 'Statistical Analysis', 'Machine Learning Models', 'Study Design', 'Data Visualization Tools', 'Programming with Python and R', 'Clinical and Biomedical Data']","Data Cleaning and Processing: Involves retrieving, processing, and cleaning large-scale biomedical data to build high-quality datasets for research.; Statistical Analysis: Used for experimental design, performance assessment, error analysis, and robustness testing within clinical and biomedical research.; Machine Learning Models: Development and evaluation of predictive models applied to clinical or biomedical data to support research outcomes.; Study Design: Application of in-depth knowledge of study design methodologies to ensure valid and reliable biomedical research.; Data Visualization Tools: Creation of interactive visualizations (e.g., using Plotly, Dash, D3.js, React) to communicate data insights effectively.; Programming with Python and R: Utilizing programming languages Python or R for data analysis, model development, and statistical computations.; Clinical and Biomedical Data: Working with electronic health records (EHRs), medical images, and other biomedical datasets for analysis and modeling."
Ehv1fZjmJt__2icEAAAAAA==,"Associate Director, Data Scientist & Data Operations (Washington) at Eisai US Washington DC","Associate Director, Data Scientist & Data Operations (Washington) job at Eisai US. Washington DC. Associate Director, Data Scientist & Data Operations

Join to apply for the Associate Director, Data Scientist & Data Operations role at Eisai US .

At Eisai, our mission is to satisfy unmet medical needs and enhance healthcare benefits for patients, families, and caregivers. We are a growing pharmaceutical company focused on neurology and oncology, emphasizing research and development. Our history includes developing innovative medicines, notably the world's most widely-used treatment for Alzheimer’s disease. As we expand, we seek motivated individuals eager to make a difference in a fast-paced environment.

Role Overview: The Data Operations Group at Eisai is seeking an Associate Director - Data Scientist/Programmer to develop AI-powered dashboards. The Data Scientist will collaborate with Data Operations and Biostatisticians to support projects at various development stages, providing actionable insights for critical business initiatives.

This position can be office-based (hybrid) in Nutley, NJ, or remote.
Responsibilities
• Data Extraction & Analysis: Manipulate complex datasets to generate reports, charts, and graphs, analyzing for outliers, root causes, and correlations. Propose solutions to optimize outcomes.
• AI-Driven Data Preparation: Utilize AI and machine learning for automated data prep, especially for dynamic visualizations in Power BI.
• Natural Language Processing & LLM: Apply LLM and NLP techniques to generate insights and infographics.
• Data Preparation for Analysis: Clean datasets, handle missing values, and remove outliers for accurate modeling.
• Insight Generation for Drug Discovery: Identify patterns to support drug discovery processes.
• Data Integration: Combine diverse data sources for comprehensive analysis.
• Model Training & Data Quality: Ensure high-quality data for predictive models.
• Communication of Findings: Present insights clearly to stakeholders.
• Team Collaboration: Work with data scientists, biostatisticians, and data standards teams.
• Data Visualization: Convey complex data through visualizations, reports, and dashboards.
Qualifications
• Master’s degree in Computer Science or related field with research experience.
• Expertise in data modeling techniques.
• Proficiency in Python or R, with strong data analysis skills.
• Experience with visualization tools like Tableau or matplotlib.
• Strong problem-solving and project management skills.
• Excellent communication skills for technical and non-technical audiences.

Salary & Benefits: The base salary range is $171,100 - $224,600, with eligibility for annual and long-term incentives. Benefits details are available on our website. Eisai is an equal opportunity employer committed to diversity and inclusion.
#J-18808-Ljbffr",2025-07-20T00:00:00.000Z,2025-07-25,"['Master’s degree in Computer Science or related field with research experience', 'Expertise in data modeling techniques', 'Proficiency in Python or R, with strong data analysis skills', 'Experience with visualization tools like Tableau or matplotlib', 'Strong problem-solving and project management skills', 'Excellent communication skills for technical and non-technical audiences']","['Role Overview: The Data Operations Group at Eisai is seeking an Associate Director - Data Scientist/Programmer to develop AI-powered dashboards', 'The Data Scientist will collaborate with Data Operations and Biostatisticians to support projects at various development stages, providing actionable insights for critical business initiatives', 'Data Extraction & Analysis: Manipulate complex datasets to generate reports, charts, and graphs, analyzing for outliers, root causes, and correlations', 'Propose solutions to optimize outcomes', 'AI-Driven Data Preparation: Utilize AI and machine learning for automated data prep, especially for dynamic visualizations in Power BI', 'Natural Language Processing & LLM: Apply LLM and NLP techniques to generate insights and infographics', 'Data Preparation for Analysis: Clean datasets, handle missing values, and remove outliers for accurate modeling', 'Insight Generation for Drug Discovery: Identify patterns to support drug discovery processes', 'Data Integration: Combine diverse data sources for comprehensive analysis', 'Model Training & Data Quality: Ensure high-quality data for predictive models', 'Communication of Findings: Present insights clearly to stakeholders', 'Team Collaboration: Work with data scientists, biostatisticians, and data standards teams', 'Data Visualization: Convey complex data through visualizations, reports, and dashboards']",True,"['Large Language Models', 'Natural Language Processing', 'AI-Driven Data Preparation']","Large Language Models: Applying LLM techniques to generate insights and infographics, enhancing data interpretation and communication.; Natural Language Processing: Utilizing NLP methods in conjunction with LLMs to extract and generate meaningful insights from textual data.; AI-Driven Data Preparation: Leveraging AI and machine learning for automated data preparation, particularly to support dynamic visualizations in Power BI.","['Data Extraction and Analysis', 'Data Preparation', 'Data Integration', 'Predictive Modeling', 'Data Visualization', 'Python and R', 'Data Modeling Techniques']","Data Extraction and Analysis: Manipulating complex datasets to generate reports, charts, and graphs, and analyzing data for outliers, root causes, and correlations to optimize outcomes.; Data Preparation: Cleaning datasets, handling missing values, and removing outliers to ensure accurate modeling and high-quality data for predictive models.; Data Integration: Combining diverse data sources to enable comprehensive analysis supporting drug discovery and other business initiatives.; Predictive Modeling: Training models using high-quality data to generate actionable insights for critical business and drug discovery projects.; Data Visualization: Creating dynamic visualizations, reports, and dashboards using tools like Power BI, Tableau, and matplotlib to communicate complex data clearly.; Python and R: Using programming languages Python and R for data analysis, modeling, and visualization tasks.; Data Modeling Techniques: Applying expertise in data modeling to structure and analyze data effectively for insights and decision-making."
bP4L-99QPwarZkutAAAAAA==,"Director, Data Science - Model Risk","Director, Data Science - Model Risk

Data is at the center of everything we do. As a startup, we disrupted the credit card industry by individually personalizing every credit card offer using statistical modeling and the relational database, cutting edge technology in 1988! Fast-forward a few years, and this little innovation and our passion for data has skyrocketed us to a Fortune 200 company and a leader in the world of data-driven decision-making.

As a Data Science Leader at Capital One, you'll be part of a team that's leading the next wave of disruption at a whole new scale, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives.

In Capital One's Model Risk Office, we defend the company against model failures and find new ways of making better decisions with models. We use our statistics, software engineering, and business expertise to drive the best outcomes in both Risk Management and the Enterprise. We understand that we can't prepare for tomorrow by focusing on today, so we invest in the future: investing in new skills, building better tools, and maintaining a network of trusted partners. We learn from past mistakes, and develop increasingly powerful techniques to avoid their repetition.

In this role, you will:
• Partner with a cross-functional team of data scientists, data analysts, and business analysts to drive great decisions through modeling
• Distill the details of complex interconnected modeling systems to influence senior business leaders on model strategy, business use, and risks
• Assess, challenge, and at times defend state-of-the-art decision-making systems to internal and regulatory partners
• Shape our practice of building machine learning models, from design through training, evaluation, validation, and implementation
• Oversee development of benchmark and challenger models to stress test critical modeling decisions

The Ideal Candidate is:
• A leader. You challenge conventional thinking and work with stakeholders to identify and improve the status quo.
• Creative. You thrive on bringing definition to big, undefined problems. You love asking questions and pushing hard to find answers. You're not afraid to share a new idea.
• Technical. You're comfortable with open-source languages and are passionate about developing further. You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms.
• Statistically-minded. You've built models, validated them, and backtested them. You know how to interpret a confusion matrix or a ROC curve. You have experience with clustering, classification, sentiment analysis, time series, and deep learning.

Basic Qualifications:
• Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:
• A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 9 years of experience performing data analytics
• A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 7 years of experience performing data analytics
• A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 4 years of experience performing data analytics
• At least 4 years of experience leveraging open source programming languages for large scale data analysis
• At least 4 years of experience working with machine learning
• At least 4 years of experience utilizing relational databases

Preferred Qualifications:
• PhD in ""STEM"" field (Science, Technology, Engineering, or Mathematics) plus 5 years of experience in data analytics
• At least 5 years of experience in Python, Scala, or R for large scale data analysis
• At least 5 years of experience with machine learning
• At least 1 year of experience working with AWS

Capital One will consider sponsoring a new qualified applicant for employment authorization for this position.

The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.

Chicago, IL: $239,900 - $273,800 for Dir, Data Science

McLean, VA: $263,900 - $301,200 for Dir, Data Science

New York, NY: $287,800 - $328,500 for Dir, Data Science

Richmond, VA: $239,900 - $273,800 for Dir, Data Science

Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate's offer letter.

This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.

Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at theCapital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.

This role is expected to accept applications for a minimum of 5 business days.

No agencies please. Capital One is an equal opportunity employer (EOE, including disability/vet) committed to non-discrimination in compliance with applicable federal, state, and local laws. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City's Fair Chance Act; Philadelphia's Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",,2025-07-25,"['A leader', 'You thrive on bringing definition to big, undefined problems', 'You love asking questions and pushing hard to find answers', ""You're comfortable with open-source languages and are passionate about developing further"", 'You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms', 'Statistically-minded', 'You know how to interpret a confusion matrix or a ROC curve', 'You have experience with clustering, classification, sentiment analysis, time series, and deep learning', 'Currently has, or is in the process of obtaining one of the following with an expectation that the required degree will be obtained on or before the scheduled start date:', ""A Bachelor's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 9 years of experience performing data analytics"", ""A Master's Degree in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) or an MBA with a quantitative concentration plus 7 years of experience performing data analytics"", 'A PhD in a quantitative field (Statistics, Economics, Operations Research, Analytics, Mathematics, Computer Science, or a related quantitative field) plus 4 years of experience performing data analytics', 'At least 4 years of experience leveraging open source programming languages for large scale data analysis', 'At least 4 years of experience working with machine learning', 'At least 4 years of experience utilizing relational databases']","['Partner with a cross-functional team of data scientists, data analysts, and business analysts to drive great decisions through modeling', 'Distill the details of complex interconnected modeling systems to influence senior business leaders on model strategy, business use, and risks', 'Assess, challenge, and at times defend state-of-the-art decision-making systems to internal and regulatory partners', 'Shape our practice of building machine learning models, from design through training, evaluation, validation, and implementation', 'Oversee development of benchmark and challenger models to stress test critical modeling decisions', 'You challenge conventional thinking and work with stakeholders to identify and improve the status quo', 'Creative', ""You've built models, validated them, and backtested them""]",True,[],,"['Statistical Modeling', 'Relational Databases', 'Machine Learning', 'Model Validation and Backtesting', 'Classification', 'Clustering', 'Sentiment Analysis', 'Time Series Analysis', 'Deep Learning', 'Open-Source Programming Languages', 'Cloud Computing Platforms', 'Confusion Matrix and ROC Curve']","Statistical Modeling: Used to personalize credit card offers and drive data-driven decision-making in model risk management.; Relational Databases: Utilized for managing and querying large-scale customer data to support analytics and modeling.; Machine Learning: Applied to build, train, evaluate, validate, and implement predictive models for decision-making and risk assessment.; Model Validation and Backtesting: Processes to ensure model accuracy and reliability, critical for defending models to internal and regulatory partners.; Classification: Used as a modeling technique to categorize data, relevant for risk and decision-making models.; Clustering: Applied for unsupervised learning tasks to identify patterns or segments within data.; Sentiment Analysis: Employed to analyze textual data for insights, supporting model development and business decisions.; Time Series Analysis: Used to analyze temporal data trends, important for forecasting and risk modeling.; Deep Learning: Implemented as part of advanced modeling techniques to improve predictive performance.; Open-Source Programming Languages: Languages like Python, Scala, or R are used for large-scale data analysis and model development.; Cloud Computing Platforms: Utilized to scale data science solutions and manage computational resources efficiently.; Confusion Matrix and ROC Curve: Metrics used to interpret and evaluate classification model performance."
OyvMi6BztJoRyLuVAAAAAA==,Data Scientist - Civil Engineering,"Overview

ABOUT THE POSITION

Are you a dedicated Data Scientist looking to make a significant impact through cutting-edge technology and data-driven approaches? Join VHB's innovative Technology Enablement Team in a corporate Data Science position, where you'll work with a diverse team of experts, including engineers, scientists, planners, designers, and technologists. At VHB, we collaborate with a broad range of clients-from government agencies to private businesses in the transportation, real estate, institutional, and federal industries-working collectively to enhance communities, stimulate economic growth, and promote environmental sustainability.

In this role, your skills in data analysis and modeling will be crucial in uncovering valuable insights and providing VHB with a competitive advantage. Start a fulfilling career with VHB, where your expertise will aid in enhancing mobility, community livability, and sustainable development. Apply now and help shape the future with VHB!

Key Responsibilities
• Lead big data-related projects across multiple areas including planning, transportation safety, planning, traffic operations, and transit/rail. Develop and maintain dashboards and websites that support large databases, facilitate complex search queries, and enhance various business functions.
• Produce innovative solutions driven by exploratory data analysis from complex and high dimensional datasets that are both qualitative and quantitative across the AEC industry.
• Mines and analyzes highly complex structured/unstructured data sets using highly advanced statistical methods for use in data-driven decision making.
• Strategizes, identifies, and implements new uses for existing data sources and unique opportunities to locate and collect new data; designs, modifies, and builds new data processes, and builds large, complex data sets ensuring data integrity and statistical accuracy.
• Extracts and identifies relevant information from databases and systems.
• Recognizes patterns, identifies opportunities, poses business questions, and makes valuable discoveries leading to prototype development and product improvement.
• Employs sophisticated analytical methods, machine learning, and statistical methods to prepare data for use in predictive and prescriptive modeling. Designs, develops, tests, validates, and analyzes models and advanced algorithms that lead to optimal value extraction from the data.
• Interprets results, predicts future data trends and other data foresights, and proposes strategic business solutions.
• Writes and distributes findings. Using strong business acumen, communicates data insights, foresights, and strategic solutions to both business and IT leaders through effective data visualizations and reports to influence how the organization approaches and meets business challenges. Recommends strategic cost-effective changes to existing business practices.
• Develops and applies customized algorithms or models to key business metrics with the goal of improving operations or answering business questions. Implements automated processes for efficiently producing scale models.
• May leads a project team of less experienced data staff and GIS analysts. Directs and monitors the work of less experience staff. Provides direction and support to ensure departmental effectiveness and efficiency. Orients and trains team members. Provides input into evaluating performance. May act as a supervisor in the absence of an actual supervisor.
• Trains the data management team on new or updated procedures.
• Writes and implements quality procedures.

Skills and Attributes
• Ability to implement common data management and reporting technologies, including the basics of columnar databases, unstructured data, and data visualization in Esri products (ArcGIS Online), Power BI or other tools.
• Active listening skills with the ability to breakdown complex problems or processes to solve problems internally and externally for clients.
• Skilled in strategic thinking, problem solving and connecting disparate dots.
• Familiar with Low-Code/No-Code experience, MicrosoftPowerApps, Databricks, ElasticSearch, MongoDB, Tableau, Azure, GTFS data.
• Familiarity with database management systems, such as SQL Server or Oracle
• Exposure with project management and task management and leading portions of a project and/or budget.
• Attention to detail and ability to meet tight deadlines.
• Stays updated on new and innovative development technologies and workflow improvements.

Minimum Qualifications
• Minimum of 5+ years of experience with advanced analytics in a professional setting.
• Master's degree in Statistics, Mathematics, or equivalent discipline; or equivalent experience.
• Demonstrated experience working in Planning, Architecture, Engineering, or Construction is required with emphasis in providing services for transportation agencies and/or state and federal governments.
• Advanced knowledge of machine learning, data mining, statistical predictive modeling programming, simulation, and advanced mathematics.
• Understanding of parallelization, scalability, and complexity analysis.
• Extensive experience using many of the following technologies: Python (Pandas, NumPy, SciPy), R (tidyverse), SQL, Tableau, Power BI, advanced Microsoft Excel, machine learning, statistical analysis.
• Team oriented with ability to perform multiple tasks independently in a timely manner and collaborate effectively and positively with coworkers.
• Excellent ability to communicate effectively (both written and verbal) with all levels of Employees including non-technical staff.
• Ability to absorb new concepts quickly and a willingness to learn new skills and datasets within the AEC industry.
• Applicants must be legally authorized to work for VHB in the U.S. without employer sponsorship.

The base salary range for this position is $110,025 - 138,050 for the Washington, DC and New York location. This offer is determined based on a number of job-related factors including internal comparators, skills, education, training, credentials, experience, scope and complexity of role responsibilities and geographic location. In addition, VHB offers a holistic benefits package which can be found here.

We are VHB! We're an inspired and innovative team of engineers, scientists, planners, and designers who partner with clients in the transportation, real estate, institutional, and energy industries, as well as federal, state, and local governments. Our work helps improve mobility, enhance communities, and contribute to economic vitality. We do this while balancing development and infrastructure needs with stewardship of our environment.

Our people make us great! VHB provides a differentiating employee experience, which includes:
• Diverse and inclusive culture of collaboration and innovation
• Opportunity to work on complex, transformational projects
• Community and social responsibility as sustainable stewards
• Focus on learning, development, and career growth
• Best-in-class benefits, including flexible, hybrid workplace

We are consistently rated one of the top AEC firms to work for across our 30+ offices on the East Coast. We're growing, and we hope you'll join us!

VHB is a proud Equal Opportunity Employer. Since our founding, we have intentionally fostered a culture of inclusion and belonging, supported by deep-rooted core values, one of which is diversity. Qualified applicants will receive consideration for employment without regard to race, color, religion, gender, sex, sexual orientation, gender identity/expression, national origin, disability, protected veteran status, or other characteristics protected by law.

#LI-LO1

#LI-Hybrid
Employment Type: FULL_TIME",,2025-07-25,"['Ability to implement common data management and reporting technologies, including the basics of columnar databases, unstructured data, and data visualization in Esri products (ArcGIS Online), Power BI or other tools', 'Active listening skills with the ability to breakdown complex problems or processes to solve problems internally and externally for clients', 'Skilled in strategic thinking, problem solving and connecting disparate dots', 'Familiar with Low-Code/No-Code experience, MicrosoftPowerApps, Databricks, ElasticSearch, MongoDB, Tableau, Azure, GTFS data', 'Familiarity with database management systems, such as SQL Server or Oracle', 'Exposure with project management and task management and leading portions of a project and/or budget', 'Attention to detail and ability to meet tight deadlines', 'Stays updated on new and innovative development technologies and workflow improvements', 'Minimum of 5+ years of experience with advanced analytics in a professional setting', ""Master's degree in Statistics, Mathematics, or equivalent discipline; or equivalent experience"", 'Demonstrated experience working in Planning, Architecture, Engineering, or Construction is required with emphasis in providing services for transportation agencies and/or state and federal governments', 'Advanced knowledge of machine learning, data mining, statistical predictive modeling programming, simulation, and advanced mathematics', 'Understanding of parallelization, scalability, and complexity analysis', 'Extensive experience using many of the following technologies: Python (Pandas, NumPy, SciPy), R (tidyverse), SQL, Tableau, Power BI, advanced Microsoft Excel, machine learning, statistical analysis', 'Team oriented with ability to perform multiple tasks independently in a timely manner and collaborate effectively and positively with coworkers', 'Excellent ability to communicate effectively (both written and verbal) with all levels of Employees including non-technical staff', 'Ability to absorb new concepts quickly and a willingness to learn new skills and datasets within the AEC industry', 'Applicants must be legally authorized to work for VHB in the U.S. without employer sponsorship', 'Opportunity to work on complex, transformational projects']","['In this role, your skills in data analysis and modeling will be crucial in uncovering valuable insights and providing VHB with a competitive advantage', 'Lead big data-related projects across multiple areas including planning, transportation safety, planning, traffic operations, and transit/rail', 'Develop and maintain dashboards and websites that support large databases, facilitate complex search queries, and enhance various business functions', 'Produce innovative solutions driven by exploratory data analysis from complex and high dimensional datasets that are both qualitative and quantitative across the AEC industry', 'Mines and analyzes highly complex structured/unstructured data sets using highly advanced statistical methods for use in data-driven decision making', 'Strategizes, identifies, and implements new uses for existing data sources and unique opportunities to locate and collect new data; designs, modifies, and builds new data processes, and builds large, complex data sets ensuring data integrity and statistical accuracy', 'Extracts and identifies relevant information from databases and systems', 'Recognizes patterns, identifies opportunities, poses business questions, and makes valuable discoveries leading to prototype development and product improvement', 'Employs sophisticated analytical methods, machine learning, and statistical methods to prepare data for use in predictive and prescriptive modeling', 'Designs, develops, tests, validates, and analyzes models and advanced algorithms that lead to optimal value extraction from the data', 'Interprets results, predicts future data trends and other data foresights, and proposes strategic business solutions', 'Writes and distributes findings', 'Using strong business acumen, communicates data insights, foresights, and strategic solutions to both business and IT leaders through effective data visualizations and reports to influence how the organization approaches and meets business challenges', 'Recommends strategic cost-effective changes to existing business practices', 'Develops and applies customized algorithms or models to key business metrics with the goal of improving operations or answering business questions', 'Implements automated processes for efficiently producing scale models', 'May leads a project team of less experienced data staff and GIS analysts', 'Directs and monitors the work of less experience staff', 'Provides direction and support to ensure departmental effectiveness and efficiency', 'Orients and trains team members', 'Provides input into evaluating performance', 'May act as a supervisor in the absence of an actual supervisor', 'Trains the data management team on new or updated procedures', 'Writes and implements quality procedures', 'Community and social responsibility as sustainable stewards']",True,[],,"['Exploratory Data Analysis', 'Statistical Methods', 'Machine Learning', 'Predictive Modeling', 'Data Visualization', 'Data Pipelines', 'SQL', 'Python (Pandas, NumPy, SciPy)', 'R (tidyverse)', 'Tableau', 'Power BI', 'Advanced Microsoft Excel', 'Columnar Databases', 'Unstructured Data Handling', 'Esri Products (ArcGIS Online)', 'Low-Code/No-Code Platforms', 'Databricks', 'ElasticSearch', 'MongoDB', 'Azure', 'GTFS Data', 'Database Management Systems (SQL Server, Oracle)', 'Advanced Analytics', 'Simulation', 'Parallelization and Scalability']","Exploratory Data Analysis: Used to produce innovative solutions by analyzing complex and high-dimensional qualitative and quantitative datasets in the AEC industry.; Statistical Methods: Applied to mine and analyze highly complex structured and unstructured data sets for data-driven decision making.; Machine Learning: Employed to prepare data for predictive and prescriptive modeling, including designing, testing, validating, and analyzing models and advanced algorithms.; Predictive Modeling: Used to interpret results, predict future data trends, and propose strategic business solutions.; Data Visualization: Implemented through dashboards, reports, and tools like Power BI, Tableau, and Esri products to communicate insights and influence business decisions.; Data Pipelines: Designed and modified to build large, complex datasets ensuring data integrity and statistical accuracy.; SQL: Used for database management and extracting relevant information from databases and systems.; Python (Pandas, NumPy, SciPy): Utilized for data analysis, statistical computing, and machine learning tasks.; R (tidyverse): Applied for statistical analysis and data manipulation.; Tableau: Used as a BI tool for creating interactive dashboards and visualizations.; Power BI: Employed for data visualization and reporting to support business functions.; Advanced Microsoft Excel: Used for data analysis, reporting, and managing datasets.; Columnar Databases: Implemented as part of data management technologies to optimize storage and query performance.; Unstructured Data Handling: Managed to analyze and extract insights from non-tabular data sources.; Esri Products (ArcGIS Online): Used for geospatial data visualization and analysis relevant to transportation and planning.; Low-Code/No-Code Platforms: Familiarity with tools like Microsoft PowerApps to streamline application development and data workflows.; Databricks: Used for big data processing and collaborative data science workflows.; ElasticSearch: Applied for complex search queries and indexing large datasets.; MongoDB: Used as a NoSQL database for managing unstructured data.; Azure: Cloud platform utilized for data storage, processing, and analytics.; GTFS Data: Used for transit data analysis and transportation planning.; Database Management Systems (SQL Server, Oracle): Used to manage and query relational databases supporting business functions.; Advanced Analytics: Applied across multiple domains including transportation safety and traffic operations to uncover insights and improve decision making.; Simulation: Used to model and analyze complex systems and scenarios within the civil engineering context.; Parallelization and Scalability: Considered in algorithm and model design to handle large datasets efficiently."
R2QB7JrLkZh-8nJ3AAAAAA==,"Intern, Data Science-Remote","Overview

Since our founding in 1924, we've cut cardiovascular disease deaths in half, but there is still so much more to do. To overcome today’s biggest health challenges and accelerate this progress, we need passionate individuals like you. Join our movement, be part of the progress, and help ensure a healthier future for all. You matter, and so does the impact you can make with us.

This internship supports the Data Science team and offers hands-on experience in data science and statistical analysis within clinical or biomedical research settings. Interns will contribute to the development of machine learning models, conduct experimental design and evaluation, and assist in summarizing results and drafting manuscripts. You will have the opportunity to work closely with staff across departments and contribute to impactful, high-quality research.

The American Heart Association’s Internship Program provides college students an opportunity for hands-on experience in various facets for individuals interested in gaining work experience with a non-profit, voluntary health organization.

The Association offers many resources to help you maintain work-life harmonization through your changing needs and life situations. To help you be successful, you will have access to Heart U, our award-winning corporate university, as well as training and support locally and through our National Center.

\#TheAHALife is more than a company culture; it is our way of life. It embodies our commitment to work-life harmonization and is guided by our core values where our employees can thrive both personally and professionally. Discover why you will Be Seen. Be Heard. Be Valued at the American Heart Association by following us on LinkedIn, Instagram, Facebook, X, and at heart.jobs.

Internship Overview:
• Time Commitment: 25 hours per week
• Internship Duration: 9/8/25-12/5/25
• Location:Remote
• Salary: $23.00 per hour

Internship Outcomes:

Individuals participating in the internship program are provided with an opportunity to:
• Gain important and practical job skills to be successful in a non-profit environment.
• Opportunity to explore a career-path with a reputable voluntary health/service organization.
• Complete an internship that enriches your academic and professional resume as well as enriching your personal life by making a difference in the lives of others.

Responsibilities

Tasks could include things like the following:
• Retrieve, process, and clean large-scale biomedical data, build high-quality datasets.
• Design and develop machine learning models for clinical or biomedical research, with a focus on Large Language Models (LLMs), medical imaging, or multimodal AI.
• Conduct experimental design and evaluation, including statistical analysis, performance assessment, error analysis, and robustness testing.
• Collaborate with cross-functional teams, including clinicians, data scientists, and engineers, to refine research questions and interpret results.
• Contribute to scientific writing, including drafting manuscripts for peer-reviewed journals and preparing materials for presentations or conferences.
• Develop interactive data visualization tools to communicate insights clearly.

Qualifications
• Currently pursuing an MS or PhD degree in Computer Science, Biomedical Informatics, Engineering, Statistics, or a related quantitative field.
• Demonstrated experience with large-scale machine learning or foundation models, including training, fine-tuning, and evaluating LLMs (e.g., GPT, BERT) or vision models (e.g., CNNs, Vision Transformers.
• Strong programming skills in Python (or R), with experience in machine learning frameworks.
• In-depth knowledge of study design, data analysis, and statistical methodologies, with prior experience working with clinical or biomedical data (e.g., EHRs, images.
• Prior authorship or co-authorship of peer-reviewed publications is strongly preferred.
• Experience with interactive visualization tools (e.g., Plotly, Dash, D3.js, or React) is a plus.
• Excellent communication skills, with the ability to present results to both technical and non-technical audiences.
• Ability to deal professionally in a corporate or non-profit environment and assume responsibility for guiding projects and programs from inception through completion.
• Ability to work in a fast-paced, dynamic environment managing multiple priorities involving multiple entities.
• Intermediate to excellent proficiency in MS Word, Excel, Outlook and PowerPoint.
• Minimum availability of 20 hrs/wk, M-F between the hours of 8:00am-5:00pm.
• Required Equipment: Reliable WiFi Connection.
• Must be legally authorized to work in the United States for any employer without sponsorship, now or in the future. For any roles working remotely, the work must also be performed inside the United States, not in a foreign country.

Compensation & Benefits

The job application window is expected to close: August 1, 2025.

The American Heart Association invests in its people. Visit Rewards & Benefits to see more details.
• Compensation and Performance – Attracting talented, committed interns means offering competitive compensation, ongoing professional development and training, and an environment in which to work and grow. And we do.
• Professional Development – You can join one of our many Employee Resource Groups (ERG) or be a mentor/mentee in our professional mentoring program. HeartU is the Association’s national online university, with more than 100,000 resources designed to meet your needs and busy schedule.
• Healthcare Benefits – You will have the opportunity to participate in our Teladoc General Medical and Behavioral Health programs. We also provide access to our Employee Assistance Program (EAP) at no cost as a confidential program designed to assist employees and family members with personal issues that affect their relationships at home or at work.

Apply Today:

So, are you ready to intern for the largest voluntary health organization dedicated to fighting heart disease, stroke, and other cardiovascular diseases?

The American Heart Association’s 2028 Goal: Building on over 100 years of trusted leadership in cardiovascular and brain health, by 2028 the AHA will drive breakthroughs and implement proven solutions in science, policy, and care for healthier people and communities. The greatest discoveries in health must reach everyone where they are.

At American Heart Association | American Stroke Association, our mission is to be a relentless force for a world of longer, healthier lives, regardless of race, ethnicity, gender, gender identity, religion, age, language, sexual orientation, national origin and physical or cognitive abilities.

This position not a match with your skills? Click here to see other opportunities.

In accordance with local and state laws where applicable, qualified applicants with arrest or conviction records will be considered for employment.

EOE/Protected Veterans/Persons with Disabilities

\#AHAWAYUP, #LI-DNP

Join our Talent Community!

Join our Talent Community to receive updates on new opportunities and future events.

Default: Location : LocationUS-TX-Dallas

Posted Date57 minutes ago(7/9/2025 9:51 AM)

Requisition ID2025-16131

Job CategoryAdministrative Support

Position TypePart Time

Overview

Since our founding in 1924, we've cut cardiovascular disease deaths in half, but there is still so much more to do. To overcome today’s biggest health challenges and accelerate this progress, we need passionate individuals like you. Join our movement, be part of the progress, and help ensure a healthier future for all. You matter, and so does the impact you can make with us.

This internship supports the Data Science team and offers hands-on experience in data science and statistical analysis within clinical or biomedical research settings. Interns will contribute to the development of machine learning models, conduct experimental design and evaluation, and assist in summarizing results and drafting manuscripts. You will have the opportunity to work closely with staff across departments and contribute to impactful, high-quality research.

The American Heart Association’s Internship Program provides college students an opportunity for hands-on experience in various facets for individuals interested in gaining work experience with a non-profit, voluntary health organization.

The Association offers many resources to help you maintain work-life harmonization through your changing needs and life situations. To help you be successful, you will have access to Heart U, our award-winning corporate university, as well as training and support locally and through our National Center.

\#TheAHALife is more than a company culture; it is our way of life. It embodies our commitment to work-life harmonization and is guided by our core values where our employees can thrive both personally and professionally. Discover why you will Be Seen. Be Heard. Be Valued at the American Heart Association by following us on LinkedIn, Instagram, Facebook, X, and at heart.jobs.

Internship Overview:
• Time Commitment: 25 hours per week
• Internship Duration: 9/8/25-12/5/25
• Location:Remote
• Salary: $23.00 per hour

Internship Outcomes:

Individuals participating in the internship program are provided with an opportunity to:
• Gain important and practical job skills to be successful in a non-profit environment.
• Opportunity to explore a career-path with a reputable voluntary health/service organization.
• Complete an internship that enriches your academic and professional resume as well as enriching your personal life by making a difference in the lives of others.

Responsibilities

Tasks could include things like the following:
• Retrieve, process, and clean large-scale biomedical data, build high-quality datasets.
• Design and develop machine learning models for clinical or biomedical research, with a focus on Large Language Models (LLMs), medical imaging, or multimodal AI.
• Conduct experimental design and evaluation, including statistical analysis, performance assessment, error analysis, and robustness testing.
• Collaborate with cross-functional teams, including clinicians, data scientists, and engineers, to refine research questions and interpret results.
• Contribute to scientific writing, including drafting manuscripts for peer-reviewed journals and preparing materials for presentations or conferences.
• Develop interactive data visualization tools to communicate insights clearly.

Qualifications
• Currently pursuing an MS or PhD degree in Computer Science, Biomedical Informatics, Engineering, Statistics, or a related quantitative field.
• Demonstrated experience with large-scale machine learning or foundation models, including training, fine-tuning, and evaluating LLMs (e.g., GPT, BERT) or vision models (e.g., CNNs, Vision Transformers.
• Strong programming skills in Python (or R), with experience in machine learning frameworks.
• In-depth knowledge of study design, data analysis, and statistical methodologies, with prior experience working with clinical or biomedical data (e.g., EHRs, images.
• Prior authorship or co-authorship of peer-reviewed publications is strongly preferred.
• Experience with interactive visualization tools (e.g., Plotly, Dash, D3.js, or React) is a plus.
• Excellent communication skills, with the ability to present results to both technical and non-technical audiences.
• Ability to deal professionally in a corporate or non-profit environment and assume responsibility for guiding projects and programs from inception through completion.
• Ability to work in a fast-paced, dynamic environment managing multiple priorities involving multiple entities.
• Intermediate to excellent proficiency in MS Word, Excel, Outlook and PowerPoint.
• Minimum availability of 20 hrs/wk, M-F between the hours of 8:00am-5:00pm.
• Required Equipment: Reliable WiFi Connection.
• Must be legally authorized to work in the United States for any employer without sponsorship, now or in the future. For any roles working remotely, the work must also be performed inside the United States, not in a foreign country.

Compensation & Benefits

The job application window is expected to close: August 1, 2025.

The American Heart Association invests in its people. Visit Rewards & Benefits to see more details.
• Compensation and Performance – Attracting talented, committed interns means offering competitive compensation, ongoing professional development and training, and an environment in which to work and grow. And we do.
• Professional Development – You can join one of our many Employee Resource Groups (ERG) or be a mentor/mentee in our professional mentoring program. HeartU is the Association’s national online university, with more than 100,000 resources designed to meet your needs and busy schedule.
• Healthcare Benefits – You will have the opportunity to participate in our Teladoc General Medical and Behavioral Health programs. We also provide access to our Employee Assistance Program (EAP) at no cost as a confidential program designed to assist employees and family members with personal issues that affect their relationships at home or at work.

Apply Today:

So, are you ready to intern for the largest voluntary health organization dedicated to fighting heart disease, stroke, and other cardiovascular diseases?

The American Heart Association’s 2028 Goal: Building on over 100 years of trusted leadership in cardiovascular and brain health, by 2028 the AHA will drive breakthroughs and implement proven solutions in science, policy, and care for healthier people and communities. The greatest discoveries in health must reach everyone where they are.

At American Heart Association | American Stroke Association, our mission is to be a relentless force for a world of longer, healthier lives, regardless of race, ethnicity, gender, gender identity, religion, age, language, sexual orientation, national origin and physical or cognitive abilities.

This position not a match with your skills? Click here to see other opportunities.

In accordance with local and state laws where applicable, qualified applicants with arrest or conviction records will be considered for employment.

EOE/Protected Veterans/Persons with Disabilities

\#AHAWAYUP, #LI-DNP

Join our Talent Community!

Join our Talent Community to receive updates on new opportunities and future events.

Default: Location : LocationUS-TX-Dallas

Posted Date57 minutes ago(7/9/2025 9:51 AM)

Requisition ID2025-16131

Job CategoryAdministrative Support

Position TypePart Time",2025-07-09T00:00:00.000Z,2025-07-25,"['Currently pursuing an MS or PhD degree in Computer Science, Biomedical Informatics, Engineering, Statistics, or a related quantitative field', 'Demonstrated experience with large-scale machine learning or foundation models, including training, fine-tuning, and evaluating LLMs (e.g., GPT, BERT) or vision models (e.g., CNNs, Vision Transformers', 'Strong programming skills in Python (or R), with experience in machine learning frameworks', 'In-depth knowledge of study design, data analysis, and statistical methodologies, with prior experience working with clinical or biomedical data (e.g., EHRs, images', 'Excellent communication skills, with the ability to present results to both technical and non-technical audiences', 'Ability to deal professionally in a corporate or non-profit environment and assume responsibility for guiding projects and programs from inception through completion', 'Ability to work in a fast-paced, dynamic environment managing multiple priorities involving multiple entities', 'Intermediate to excellent proficiency in MS Word, Excel, Outlook and PowerPoint', 'Minimum availability of 20 hrs/wk, M-F between the hours of 8:00am-5:00pm', 'Required Equipment: Reliable WiFi Connection', 'Must be legally authorized to work in the United States for any employer without sponsorship, now or in the future', 'For any roles working remotely, the work must also be performed inside the United States, not in a foreign country', 'Gain important and practical job skills to be successful in a non-profit environment', 'Opportunity to explore a career-path with a reputable voluntary health/service organization', 'Currently pursuing an MS or PhD degree in Computer Science, Biomedical Informatics, Engineering, Statistics, or a related quantitative field', 'Demonstrated experience with large-scale machine learning or foundation models, including training, fine-tuning, and evaluating LLMs (e.g., GPT, BERT) or vision models (e.g., CNNs, Vision Transformers', 'Strong programming skills in Python (or R), with experience in machine learning frameworks', 'In-depth knowledge of study design, data analysis, and statistical methodologies, with prior experience working with clinical or biomedical data (e.g., EHRs, images', 'Excellent communication skills, with the ability to present results to both technical and non-technical audiences', 'Ability to deal professionally in a corporate or non-profit environment and assume responsibility for guiding projects and programs from inception through completion', 'Ability to work in a fast-paced, dynamic environment managing multiple priorities involving multiple entities', 'Intermediate to excellent proficiency in MS Word, Excel, Outlook and PowerPoint', 'Minimum availability of 20 hrs/wk, M-F between the hours of 8:00am-5:00pm', 'Required Equipment: Reliable WiFi Connection', 'Must be legally authorized to work in the United States for any employer without sponsorship, now or in the future', 'For any roles working remotely, the work must also be performed inside the United States, not in a foreign country']","['This internship supports the Data Science team and offers hands-on experience in data science and statistical analysis within clinical or biomedical research settings', 'Interns will contribute to the development of machine learning models, conduct experimental design and evaluation, and assist in summarizing results and drafting manuscripts', 'You will have the opportunity to work closely with staff across departments and contribute to impactful, high-quality research', 'Retrieve, process, and clean large-scale biomedical data, build high-quality datasets', 'Design and develop machine learning models for clinical or biomedical research, with a focus on Large Language Models (LLMs), medical imaging, or multimodal AI', 'Conduct experimental design and evaluation, including statistical analysis, performance assessment, error analysis, and robustness testing', 'Collaborate with cross-functional teams, including clinicians, data scientists, and engineers, to refine research questions and interpret results', 'Contribute to scientific writing, including drafting manuscripts for peer-reviewed journals and preparing materials for presentations or conferences', 'Develop interactive data visualization tools to communicate insights clearly', 'This internship supports the Data Science team and offers hands-on experience in data science and statistical analysis within clinical or biomedical research settings', 'Interns will contribute to the development of machine learning models, conduct experimental design and evaluation, and assist in summarizing results and drafting manuscripts', 'You will have the opportunity to work closely with staff across departments and contribute to impactful, high-quality research', 'Retrieve, process, and clean large-scale biomedical data, build high-quality datasets', 'Design and develop machine learning models for clinical or biomedical research, with a focus on Large Language Models (LLMs), medical imaging, or multimodal AI', 'Conduct experimental design and evaluation, including statistical analysis, performance assessment, error analysis, and robustness testing', 'Collaborate with cross-functional teams, including clinicians, data scientists, and engineers, to refine research questions and interpret results', 'Contribute to scientific writing, including drafting manuscripts for peer-reviewed journals and preparing materials for presentations or conferences', 'Develop interactive data visualization tools to communicate insights clearly']",True,"['Large Language Models', 'Vision Transformers', 'Convolutional Neural Networks', 'Multimodal AI']","Large Language Models: Designing, training, fine-tuning, and evaluating foundation models like GPT and BERT for biomedical research applications.; Vision Transformers: Applying advanced neural network architectures for medical imaging analysis within multimodal AI research.; Convolutional Neural Networks: Using CNNs for processing and analyzing medical images as part of machine learning model development.; Multimodal AI: Integrating multiple data types such as text and images using AI models to enhance clinical research insights.","['Data Cleaning and Processing', 'Statistical Analysis', 'Machine Learning Models', 'Study Design', 'Data Visualization Tools', 'Programming with Python and R', 'Clinical and Biomedical Data']","Data Cleaning and Processing: Involves retrieving, processing, and cleaning large-scale biomedical data to build high-quality datasets for research.; Statistical Analysis: Used for experimental design, performance assessment, error analysis, and robustness testing within clinical and biomedical research.; Machine Learning Models: Development and evaluation of predictive models applied to clinical or biomedical data to support research outcomes.; Study Design: Application of in-depth knowledge of experimental and clinical study design to ensure valid and reliable research results.; Data Visualization Tools: Creation of interactive visualizations (e.g., using Plotly, Dash, D3.js, React) to communicate data insights effectively.; Programming with Python and R: Utilizing programming languages Python or R for data analysis, model development, and statistical computations.; Clinical and Biomedical Data: Working with electronic health records (EHRs), medical images, and other biomedical datasets relevant to health research."
Y7KH4dh7O3uUnfIeAAAAAA==,Entry Level Python Programmer/Data scientist/Analyst,"Since 2010 and almost 14 years SynergisticIT has helped Jobseekers get employed in the tech Job market by providing candidates the requisite skills, experience and technical competence to outperform at interviews and at clients.
Post Covid the tech Layoffs have been massive-In 2022 there were 165,269 tech layoffs, In 2023 there were 264,220 tech layoffs and so far in 2024 there have been 126,382 tech layoffs. (Source Layoffs.fyi ) -Total layoffs as per this 555,871 tech layoffs.
Client, Dell and Cisco have announced 15,000/12,500 and 4000 tech layoffs respectively in August.
The Job market is Hyper Competitive. For 1 position 500-2000 candidates or more are applying and laid off job seekers are also competing for entry level Job positions.
Acquiring the right technology skillsets which are being demanded by clients and getting yourself in front of clients is the way to get to get Interviews and eventually a Job Offer. Survival of the Fittest is the only way to get a tech Job in this job market.
In this Layoffs fueled market also SynergisticIT's candidates are able to achieve multiple job offers and $100k + salaries once they acquire the required skills.
please check the below links to see success outcomes, salaries of our candidates .
https://www.synergisticit.com/candidate-outcomes/
https://www.synergisticit.com/roi-of-computer-science-degree-colleges-vs-synergisticit/
We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please visit the below videos exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023
https://synergisticit.wistia.com/medias/tmwjwchxz5
https://synergisticit.wistia.com/medias/n8487768di
https://synergisticit.wistia.com/medias/o5gmv7i9eu
https://synergisticit.wistia.com/medias/k6t6a1n4kb
https://synergisticit.wistia.com/medias/pgrvq4fgni
https://synergisticit.wistia.com/medias/ce4syhm853
All Positions are open for all visas and US citizens
We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.
Currently, we are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Data Engineers, Machine Learning engineers for full time positions with clients.
Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.
We want Data Science/Machine learning/Data Analyst and Java Full stack candidates
REQUIRED SKILLS For Java /Full stack/Devops Positions
Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
Knowledge of Core Java , javascript , C++ or software programming
Spring boot, Microservices, Docker, Jenkins, Github, Kubernates and REST API's experience
For data Science/Data Analyst/AI/Machine learning Positions
REQUIRED SKILLS
Associate or Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT, Statistics, Mathematics or having good logical aptitude
Knowledge of Statistics, Gen AI, LLM, Sagemaker, Python, Computer Vision, data visualization tools
Preferred skills: NLP, Text mining, Tableau, PowerBI, Databricks, Tensorflow
If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.
No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",,2025-07-25,"['Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry', 'We want Data Science/Machine learning/Data Analyst and Java Full stack candidates', 'REQUIRED SKILLS For Java /Full stack/Devops Positions', 'Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT', 'Knowledge of Core Java , javascript , C++ or software programming', ""Spring boot, Microservices, Docker, Jenkins, Github, Kubernates and REST API's experience"", 'For data Science/Data Analyst/AI/Machine learning Positions', 'Associate or Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT, Statistics, Mathematics or having good logical aptitude', 'Knowledge of Statistics, Gen AI, LLM, Sagemaker, Python, Computer Vision, data visualization tools']",,True,"['Generative AI', 'Large Language Models', 'Amazon SageMaker', 'Computer Vision']","Generative AI: Mentioned as a required skill, indicating use of AI models that generate content or data.; Large Language Models: Refers to LLMs used for advanced AI tasks such as natural language understanding and generation.; Amazon SageMaker: Cloud service for building, training, and deploying machine learning and AI models, including LLMs.; Computer Vision: AI domain involving image and video analysis, relevant for roles requiring visual data processing.","['Statistics', 'Python', 'Data Visualization Tools', 'NLP', 'Databricks', 'TensorFlow']","Statistics: Fundamental knowledge required for data analysis and modeling tasks in data science and analytics roles.; Python: Programming language used for data manipulation, analysis, and building data science workflows.; Data Visualization Tools: Tools like Tableau and PowerBI used to create dashboards and visual insights from data.; NLP: Natural Language Processing techniques applied for text mining and analysis in data science.; Databricks: Platform used for big data processing and collaborative data science workflows.; TensorFlow: Framework used for building machine learning models, including deep learning, in data science roles."
nvd4TKHvearttw2aAAAAAA==,Director Data Science,"Job Description:

Job Title

ESC D&AA Data Science Director

Collaborate with Innovative 3Mers Around the World

Choosing where to start and grow your career has a major impact on your professional and personal life, so it's equally important you know that the company that you choose to work at, and its leaders, will support and guide you. With a wide variety of people, global locations, technologies and products, 3M is a place where you can collaborate with other curious, creative 3Mers.

This position provides an opportunity to transition from other private, public, government or military experience to a 3M career.

The Impact You'll Make in this Role

As the Data Science Director for 3M's Enterprise Supply Chain (ESC) Digitization & Advanced Analytics (D&AA) team, you will have the opportunity to tap into your curiosity and collaborate with some of the most innovative people around the world. Here, you will make an impact by leading a team of data scientists to deliver global ML modeling and Gen AI solutions for 3M ESC, including projects within and among Planning, Procurement, Manufacturing and Global Logistics. The person in this role will also serve as a member of the D&AA leadership team, with the opportunity to shape 3M ESC's strategy of an agile and responsive supply chain through better, faster, and more accurate decision based on Data and AI.

Primary responsibilities include:
• Leading and mentoring a team of data scientists to develop and deploy advanced analytical solutions that enable autonomous supply chain
• Providing technical and contextual guidance to members of the data science team on their projects, establishing forums for peer-to-peer collaboration, identifying resources and removing roadblocks as they occur
• Participating in prioritization discussions, executive reviews, and program updates with functional leaders and peers on the D&AA leadership team
• Coordinating with colleagues and other teams in D&AA to manage project execution
• Articulating and executing toward a clear vision for the new technical capabilities the team needs to advance to support Supply Chain's long-term digital strategy
• Maintaining a strong network of internal and external partnerships, including with IT, Corporate Laboratories and others

Your Skills and Expertise

To set you up for success in this role from day one, 3M requires (at a minimum) the following qualifications:
• Bachelor's degree or higher (completed and verified prior to start)
• Five (5) years of experiencein manufacturing or supply chain analytics roleswith increasing responsibility in a private, public, government or military environment
• Five (5) years of program leadership
• Three (3) years of experience managing direct reports

Additional qualifications that could help you succeed even further in this role include:
• Direct experience deploying ML, Gen AI, Decision Intelligence, Graph Data Science, Optimization/Simulation, and other advanced analytics solutions at enterprise scale
• Master's Degree or higher(completed and verified prior to start) in Data Science, Statistics or other data analytics field from an accredited institution
• Demonstrated ability to coordinate and influence across organizational boundaries to deliver project deliverables and timelines
• Demonstrated ability to translate business challenges into well-defined data science technical project requirements
• Ability to work collaboratively with peers and teams to identify, consider, and then choose among candidate approaches to key projects
• Expertise in ML Ops at enterprise scale
• Experience coding in one or more of Python, R, SQL, etc.
• Experience balancing near term priorities with longer-term strategic imperatives
• Experience working with global and/or remote teams
• Demonstrated change management skills.

Work location:
• Onsite: Maplewood, MN (minimum 4 days a week onsite)

Travel:May include up to 10% (Domestic / International)

Relocation Assistance: May be Authorized

Must be legally authorized to work in country of employment without sponsorship for employment visa status (e.g., H1B status).

Supporting Your Well-being

3M offers many programs to help you live your best life - both physically and financially. To ensure competitive pay and benefits, 3M regularly benchmarks with other companies that are comparable in size and scope.

Chat with Max

For assistance with searching through our current job openings or for more information about all things 3M, visit Max, our virtual recruiting assistant on 3M.com/careers.

Applicable to US Applicants Only:The expected compensation range for this position is $228,040 - $278,715, which includes base pay plus variable incentive pay, if eligible. This range represents a good faith estimate for this position. The specific compensation offered to a candidate may vary based on factors including, but not limited to, the candidate's relevant knowledge, training, skills, work location, and/or experience. In addition, this position may be eligible for a range of benefits (e.g., Medical, Dental & Vision, Health Savings Accounts, Health Care & Dependent Care Flexible Spending Accounts, Disability Benefits, Life Insurance, Voluntary Benefits, Paid Absences and Retirement Benefits, etc.). Additional information is available at: https://www.3m.com/3M/en_US/careers-us/working-at-3m/benefits/.

Good Faith Posting Date Range 07/15/2025 To 08/14/2025 Or until filled

All US-based 3M full time employees will need to sign an employee agreement as a condition of employment with 3M. This agreement lays out key terms on using 3M Confidential Information and Trade Secrets. It also has provisions discussing conflicts of interest and how inventions are assigned. Employees that are Job Grade 7 or equivalent and above may also have obligations to not compete against 3M or solicit its employees or customers, both during their employment, and for a period after they leave 3M.

Learn more about 3M's creative solutions to the world's problems at www.3M.com or on Instagram, Facebook, and LinkedIn @3M.

Responsibilities of this position include that corporate policies, procedures and security standards are complied with while performing assigned duties.

Safety is a core value at 3M. All employees are expected to contribute to a strong EHS culture by following safety policies, identifying hazards, and engaging in continuous improvement.

Pay & Benefits Overview: https://www.3m.com/3M/en_US/careers-us/working-at-3m/benefits/

3M does not discriminate in hiring or employment on the basis of race, color, sex, national origin, religion, age, disability, veteran status, or any other characteristic protected by applicable law.

Please note: your application may not be considered if you do not provide your education and work history, either by: 1) uploading a resume, or 2) entering the information into the application fields directly.

3M Global Terms of Use and Privacy Statement

Carefully read these Terms of Use before using this website. Your access to and use of this website and application for a job at 3M are conditioned on your acceptance and compliance with these terms.

Please access the linked document by clicking here, select the country where you are applying for employment, and review. Before submitting your application, you will be asked to confirm your agreement with the terms.",2025-07-15T00:00:00.000Z,2025-07-25,"['To set you up for success in this role from day one, 3M requires (at a minimum) the following qualifications:', ""Bachelor's degree or higher (completed and verified prior to start)"", 'Five (5) years of experiencein manufacturing or supply chain analytics roleswith increasing responsibility in a private, public, government or military environment', 'Five (5) years of program leadership', 'Three (3) years of experience managing direct reports', 'Direct experience deploying ML, Gen AI, Decision Intelligence, Graph Data Science, Optimization/Simulation, and other advanced analytics solutions at enterprise scale', ""Master's Degree or higher(completed and verified prior to start) in Data Science, Statistics or other data analytics field from an accredited institution"", 'Demonstrated ability to coordinate and influence across organizational boundaries to deliver project deliverables and timelines', 'Demonstrated ability to translate business challenges into well-defined data science technical project requirements', 'Ability to work collaboratively with peers and teams to identify, consider, and then choose among candidate approaches to key projects', 'Expertise in ML Ops at enterprise scale', 'Experience coding in one or more of Python, R, SQL, etc', 'Experience balancing near term priorities with longer-term strategic imperatives', 'Experience working with global and/or remote teams', 'Demonstrated change management skills', 'Must be legally authorized to work in country of employment without sponsorship for employment visa status (e.g., H1B status)', 'Good Faith Posting Date Range 07/15/2025 To 08/14/2025 Or until filled', 'All US-based 3M full time employees will need to sign an employee agreement as a condition of employment with 3M', 'This agreement lays out key terms on using 3M Confidential Information and Trade Secrets', 'Employees that are Job Grade 7 or equivalent and above may also have obligations to not compete against 3M or solicit its employees or customers, both during their employment, and for a period after they leave 3M']","[""As the Data Science Director for 3M's Enterprise Supply Chain (ESC) Digitization & Advanced Analytics (D&AA) team, you will have the opportunity to tap into your curiosity and collaborate with some of the most innovative people around the world"", 'Here, you will make an impact by leading a team of data scientists to deliver global ML modeling and Gen AI solutions for 3M ESC, including projects within and among Planning, Procurement, Manufacturing and Global Logistics', ""The person in this role will also serve as a member of the D&AA leadership team, with the opportunity to shape 3M ESC's strategy of an agile and responsive supply chain through better, faster, and more accurate decision based on Data and AI"", 'Leading and mentoring a team of data scientists to develop and deploy advanced analytical solutions that enable autonomous supply chain', 'Providing technical and contextual guidance to members of the data science team on their projects, establishing forums for peer-to-peer collaboration, identifying resources and removing roadblocks as they occur', 'Participating in prioritization discussions, executive reviews, and program updates with functional leaders and peers on the D&AA leadership team', 'Coordinating with colleagues and other teams in D&AA to manage project execution', ""Articulating and executing toward a clear vision for the new technical capabilities the team needs to advance to support Supply Chain's long-term digital strategy"", 'Maintaining a strong network of internal and external partnerships, including with IT, Corporate Laboratories and others', 'Onsite: Maplewood, MN (minimum 4 days a week onsite)']",True,['Generative AI'],Generative AI: Delivering generative AI solutions as part of global projects to enhance supply chain processes.,"['Machine Learning', 'Graph Data Science', 'Optimization and Simulation', 'ML Ops', 'Python', 'R', 'SQL', 'Advanced Analytics', 'Decision Intelligence']",Machine Learning: Leading a team to develop and deploy machine learning models for supply chain analytics and decision-making.; Graph Data Science: Applying graph-based analytical methods to model and optimize supply chain relationships and networks.; Optimization and Simulation: Using optimization and simulation techniques to improve supply chain planning and operations.; ML Ops: Managing machine learning operations at enterprise scale to ensure reliable deployment and maintenance of ML models.; Python: Utilizing Python programming for data science and analytics tasks within the supply chain context.; R: Employing R programming for statistical analysis and data modeling in supply chain analytics.; SQL: Using SQL for data querying and management to support analytics and modeling efforts.; Advanced Analytics: Developing and deploying advanced analytical solutions to enable autonomous supply chain capabilities.; Decision Intelligence: Implementing data-driven decision-making frameworks to enhance supply chain responsiveness and agility.
g8X_IFaPzLpUL6I6AAAAAA==,"Manager, Data Science","The Company:

Hearts & Science has been inspired by confident marketers seeking business advantage in a world of personalized digital marketing, where CRM and addressable channels converge, and decisions must be made in real time to aggregate effective reach and deliver the right message at the right time.

Designed to inform brand strategies with real-time insights, Hearts & Science is a data-driven marketing agency with expert media planning and buying capabilities, among other services that include shopper marketing, marketing innovation and content activation.

The Data Science team is pivotal in the delivery of modern agency services. We are tightly integrated with marketing science teams to deliver on and exceed our clients' business goals.
Responsibilities

External facing responsibilities:
• Build advanced ML models to cluster and segment audiences, scale and deploy custom audiences across various platforms/ publishers
• Run descriptive and diagnostic analyses to help measure campaign performance within clean rooms and/or other analytics platforms (e.g., Google ADH, Facebook advanced analytics, Amazon Marketing Cloud, etc.)
• Adhere to set deadlines and ensure high quality work product

Internal facing responsibilities:
• Leverage technical (coding) skills to help bring about process efficiencies
• Contribute to building decks and reports that help translate analytical results to internal and client teams
• Contribute to building DS Practice knowledge repository via decks, documents and other artifacts

Required Skills
• Hands-on programming language skills (SQL, Python, R, etc)
• Intermediate exposure to machine learning techniques, causal models, etc. to support the analysis of information
• Advanced presentation and communication skills
• Some experience working with non-technical teams
• Knowledge of digital clean rooms, and their related concepts and strategy
• Certifications in any of the following: Meta (Blueprint), SQL, Python, R (online)
• Demonstrated domain knowledge of business/industry

Education and Experience
• A university degree in mathematics, computer science, statistics or related field, and 3-5 years of experience in informatics work in academia, advertising, management consulting, marketing or digital consulting
• Knowledge of agency-side execution process is desirable, but not required

#LI-CC2

This is the pay range the Company believes it will pay for this position at the time of this posting. Consistent with applicable law, compensation will be determined based on relevant experience, other job-related qualifications/skills, and geographic location (to account for comparative cost of living). The Company reserves the right to modify this pay range at any time. For this role, benefits include: health insurance, vision insurance, dental insurance, 401(k), Healthcare Flexible Spending Account, Dependent Care Flexible Spending Account, vacation days, sick days, personal days, paid parental leave, paid medical leave, and STD/LTD insurance benefits.

Compensation Range

$125,000-$130,000 USD

This role is hybrid, requiring three (3) days per week in the office. The remaining two (2) days may be worked remotely. Specific in-office days will be discussed during the interview process, with flexibility to align with team needs. Please note that the number or required in-office days may be adjusted over time, potentially increasing the number of required in-office days based on business needs.

Review Our Recruitment Privacy Notice",2025-07-20T00:00:00.000Z,2025-07-25,"['Hands-on programming language skills (SQL, Python, R, etc)', 'Intermediate exposure to machine learning techniques, causal models, etc', 'Some experience working with non-technical teams', 'Knowledge of digital clean rooms, and their related concepts and strategy', 'Certifications in any of the following: Meta (Blueprint), SQL, Python, R (online)', 'Demonstrated domain knowledge of business/industry', 'A university degree in mathematics, computer science, statistics or related field, and 3-5 years of experience in informatics work in academia, advertising, management consulting, marketing or digital consulting', 'The remaining two (2) days may be worked remotely', 'Specific in-office days will be discussed during the interview process, with flexibility to align with team needs']","['Build advanced ML models to cluster and segment audiences, scale and deploy custom audiences across various platforms/ publishers', 'Run descriptive and diagnostic analyses to help measure campaign performance within clean rooms and/or other analytics platforms (e.g., Google ADH, Facebook advanced analytics, Amazon Marketing Cloud, etc.)', 'Adhere to set deadlines and ensure high quality work product', 'Leverage technical (coding) skills to help bring about process efficiencies', 'Contribute to building decks and reports that help translate analytical results to internal and client teams', 'Contribute to building DS Practice knowledge repository via decks, documents and other artifacts', 'to support the analysis of information', 'Advanced presentation and communication skills']",True,[],,"['Machine Learning', 'Causal Models', 'SQL', 'Python', 'R', 'Descriptive and Diagnostic Analytics', 'Digital Clean Rooms', 'Data Reporting and Visualization']",Machine Learning: Used to build advanced models for clustering and segmenting audiences to support marketing campaign targeting.; Causal Models: Applied to analyze and understand cause-effect relationships in marketing data to improve campaign measurement.; SQL: Utilized for querying and managing data within digital clean rooms and analytics platforms.; Python: Used for programming and implementing data science workflows and machine learning models.; R: Employed for statistical analysis and data visualization in marketing analytics.; Descriptive and Diagnostic Analytics: Performed to measure campaign performance and generate insights from marketing data.; Digital Clean Rooms: Platforms used to securely analyze and aggregate marketing data from multiple sources while preserving privacy.; Data Reporting and Visualization: Creating decks and reports to translate analytical results for internal and client stakeholders.
bEuejHaG2OpO7IW5AAAAAA==,Manager & Sr Data Scientist,"Who Are We?

Taking care of our customers, our communities and each other. That's the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.

Job Category

Data Science

Compensation Overview

The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards.

Salary Range$142,500.00 - $235,100.00

Target Openings

1

What Is the Opportunity?

Travelers Data Scientists are taking the organization to the next level of intelligence by using advanced statistical techniques and machine learning algorithms. As a Manager & Sr. Data Scientist, you will build sophisticated models that solve important business problems and enhance our customer experience. This may include the use of artificial intelligence techniques to analyze imagery, text, and other unstructured data. You will employ storytelling using data to communicate insights and findings to stakeholders. This role may manage others.

As a member of Loss Analytics Research team, you will lead efforts to monitor and refresh the models for one line of business, engage in finding insights, and communicate results with reserving actuaries. You will collaborate with reserving actuaries to gain insights from the output of claim level predictive models. There are opportunities to leverage Machine Learning and Artificial Intelligence techniques to improve modeling accuracy and insights, as well as opportunities to support training and skill development initiatives, including supervising of modeling academy participants.What Will You Do?
• Manage portions of business or technical projects focused on the design or development of analytical solutions.
• Share expertise with the community through discussions, presentations, or peer reviews
• Set and manage expectations with business partners for small projects, and with limited guidance, identify potential conflicts and build consensus.
• Communicate analysis, insights, and results to team, peers, and business partners, and with guidance, tailor communication to the audience.
• Be a mentor or resource for less experienced analytic talent, onboard new employees and interns, and support recruiting and talent assessment efforts.
• Support various training and skill development initiatives.
• Perform other duties as assigned.
What Will Our Ideal Candidate Have?
• Masters in STEM related field or equivalent
• 5 years of related experience
• Advanced working knowledge of modeling/research/ analytics or actuarial required
• Strong grasp of value creation and business model concepts
• Advanced knowledge of multiple statistical software programs
• Ability to develop advanced models and interpret model results
• Application of advanced statistics underlying data models
• Ability to develop emerging statistical procedures to work
• Advanced knowledge in 2-3 of the following: Regression, Classification, Machine Vision, Natural Language Processing, Deep Learning and Statistical modeling.

What is a Must Have?
• Master's degree in Statistics, Mathematics, Decision Sciences, Actuarial Science or related analytical STEM field plus three years of experience, or PhD in Statistics, Mathematics, Decision Sciences, Actuarial Science or related analytical STEM field plus zero years of experience, or any suitable and equivalent combination of education and work experience.
• Heavy concentration in mathematics, including statistics and programming, business intelligence/analytics, as well as data science tools and research using large data sets. Additional verification of specific coursework will be required.

What Is in It for You?
• Health Insurance:Employees and their eligible family members - including spouses, domestic partners, and children - are eligible for coverage from the first day of employment.
• Retirement:Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers.
• Paid Time Off:Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays.
• Wellness Program:The Travelers wellness program is comprised of tools, discounts and resources that empower you to achieve your wellness goals and caregiving needs. In addition, our mental health program provides access to free professional counseling services, health coaching and other resources to support your daily life needs.
• Volunteer Encouragement:We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice.

Employment Practices

Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences.

In accordance with local law, candidates seeking employment in Colorado are not required to disclose dates of attendance at or graduation from educational institutions.

If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you.

Travelers reserves the right to fill this position at a level above or below the level included in this posting.

To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/.",,2025-07-25,"['Masters in STEM related field or equivalent', '5 years of related experience', 'Advanced working knowledge of modeling/research/ analytics or actuarial required', 'Strong grasp of value creation and business model concepts', 'Advanced knowledge of multiple statistical software programs', 'Ability to develop advanced models and interpret model results', 'Application of advanced statistics underlying data models', 'Ability to develop emerging statistical procedures to work', 'Advanced knowledge in 2-3 of the following: Regression, Classification, Machine Vision, Natural Language Processing, Deep Learning and Statistical modeling', ""Master's degree in Statistics, Mathematics, Decision Sciences, Actuarial Science or related analytical STEM field plus three years of experience, or PhD in Statistics, Mathematics, Decision Sciences, Actuarial Science or related analytical STEM field plus zero years of experience, or any suitable and equivalent combination of education and work experience"", 'Heavy concentration in mathematics, including statistics and programming, business intelligence/analytics, as well as data science tools and research using large data sets', 'Additional verification of specific coursework will be required']","['Data Scientist, you will build sophisticated models that solve important business problems and enhance our customer experience', 'This may include the use of artificial intelligence techniques to analyze imagery, text, and other unstructured data', 'You will employ storytelling using data to communicate insights and findings to stakeholders', 'This role may manage others', 'As a member of Loss Analytics Research team, you will lead efforts to monitor and refresh the models for one line of business, engage in finding insights, and communicate results with reserving actuaries', 'You will collaborate with reserving actuaries to gain insights from the output of claim level predictive models', 'There are opportunities to leverage Machine Learning and Artificial Intelligence techniques to improve modeling accuracy and insights, as well as opportunities to support training and skill development initiatives, including supervising of modeling academy participants', 'Manage portions of business or technical projects focused on the design or development of analytical solutions', 'Share expertise with the community through discussions, presentations, or peer reviews', 'Set and manage expectations with business partners for small projects, and with limited guidance, identify potential conflicts and build consensus', 'Communicate analysis, insights, and results to team, peers, and business partners, and with guidance, tailor communication to the audience', 'Be a mentor or resource for less experienced analytic talent, onboard new employees and interns, and support recruiting and talent assessment efforts', 'Support various training and skill development initiatives', 'Perform other duties as assigned']",True,['Artificial Intelligence'],"Artificial Intelligence: Applied to analyze imagery, text, and unstructured data to enhance modeling accuracy and business insights.","['Regression', 'Classification', 'Machine Learning', 'Statistical Modeling', 'Natural Language Processing', 'Deep Learning', 'Machine Vision', 'Business Intelligence', 'Advanced Statistical Software']","Regression: Used as one of the advanced statistical modeling techniques to build predictive models for business problems.; Classification: Applied as a statistical method to categorize data points and improve model accuracy in claim-level predictions.; Machine Learning: Leveraged to develop sophisticated models that enhance customer experience and improve modeling accuracy.; Statistical Modeling: Employed to create and interpret advanced models underlying business data for insights and decision-making.; Natural Language Processing: Used to analyze text data as part of modeling efforts involving unstructured data sources.; Deep Learning: Applied as an advanced statistical technique to improve model performance, particularly in analyzing imagery and complex data.; Machine Vision: Utilized to analyze imagery data for business insights and model development.; Business Intelligence: Incorporated to support analytics and data storytelling for communicating insights to stakeholders.; Advanced Statistical Software: Used to develop, monitor, and refresh predictive models and perform complex data analysis."
94GX-3cOtn2mqtkfAAAAAA==,Junior Data Analyst/Scientist/Engineer,"For more than 12 years Synergisticit has helped Jobseekers stand out from other Jobseekers by providing candidates the requisite skills, experience and technical competence to outperform at interviews and at clients. Here at SynergisticIT We just don't focus on getting you a tech Job we make careers.

In this market also our candidates get multiple job offers and $100k + salaries.

please check the below links to see success outcomes of our candidates .

https://www.synergisticit.com/candidate-outcomes/

https://reg.rf.oracle.com/flow/oracle/cwoh23/OCWExhibitorCatalog/page/OCWexhibitorcatalog

We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please see us exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023

All Positions are open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.

We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

https://www.youtube.com/watch?v=OFoqPTNORew

https://www.youtube.com/watch?v=-HkNN1ag6Zk

https://www.youtube.com/watch?v=OAFOhcGy9Z8

https://youtu.be/bJJl27D8bh0

We want Data Science/Machine learning/Data Analyst and Java Full stack candidates

For data Science/Machine learning Positions

REQUIRED SKILLS

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Project work on the technologies needed

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools

Excellent written and verbal communication skills

Preferred skills: NLP, Text mining, Tableau, PowerBI, Databricks, Tensorflow

REQUIRED SKILLS For Java /Full stack/Software Positions

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Project work on the skills

Knowledge of Core Java , javascript , C++ or software programming

Spring boot, Microservices, Docker, Jenkins and REST API's experience

Excellent written and verbal communication skills

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",,2025-07-25,"['Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry', 'We want Data Science/Machine learning/Data Analyst and Java Full stack candidates', 'For data Science/Machine learning Positions', 'Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT', 'Project work on the technologies needed', 'Highly motivated, self-learner, and technically inquisitive', 'Experience in programming language Java and understanding of the software development life cycle', 'Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools', 'Excellent written and verbal communication skills', 'REQUIRED SKILLS For Java /Full stack/Software Positions', 'Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT', 'Highly motivated, self-learner, and technically inquisitive', 'Experience in programming language Java and understanding of the software development life cycle', 'Project work on the skills', 'Knowledge of Core Java , javascript , C++ or software programming', ""Spring boot, Microservices, Docker, Jenkins and REST API's experience"", 'Excellent written and verbal communication skills']",,True,[],,"['Statistics', 'SAS', 'Python', 'Data Visualization Tools', 'Tableau', 'PowerBI', 'Databricks', 'Java', 'Core Java', 'JavaScript', 'C++', 'Software Development Life Cycle', 'Spring Boot', 'Microservices', 'Docker', 'Jenkins', 'REST APIs', 'Computer Vision', 'Machine Learning', 'NLP', 'TensorFlow']","Statistics: Used as foundational knowledge for data analysis and modeling tasks in data science roles.; SAS: A statistical software tool mentioned as part of the required skills for data analysis and statistical modeling.; Python: Programming language used for data manipulation, analysis, and building data science projects.; Data Visualization Tools: Tools like Tableau and PowerBI are referenced for creating dashboards and visual insights from data.; Tableau: A BI tool used for creating interactive data visualizations and dashboards.; PowerBI: A business intelligence tool used for data visualization and reporting.; Databricks: A unified analytics platform mentioned as a preferred skill for data engineering and data science workflows.; Java: Programming language required for software development and data science project work.; Core Java: Fundamental Java programming skills needed for software development roles.; JavaScript: Programming language knowledge required for full stack development.; C++: Programming language knowledge relevant for software programming roles.; Software Development Life Cycle: Understanding of the software development process is required for programming and engineering roles.; Spring Boot: Java framework used for building microservices and backend applications.; Microservices: Architectural style for building modular and scalable backend services.; Docker: Containerization tool used to package and deploy applications consistently.; Jenkins: Automation server used for continuous integration and continuous deployment pipelines.; REST APIs: Web service interfaces used for communication between software components.; Computer Vision: A field of data science involving image processing and analysis, mentioned as a knowledge area.; Machine Learning: General machine learning knowledge is required for data science and machine learning engineer roles.; NLP: Natural Language Processing is listed as a preferred skill for text mining and language data analysis.; TensorFlow: A machine learning framework mentioned as a preferred skill, typically used for building ML models."
3L7SmRsLsP-eMQApAAAAAA==,"Senior, Data Scientist","Position Summary...

What you'll do...

At Sam’s Club, we are member obsessed. We work to add value to Sam’s Club membership, and we partner with suppliers to bring unique and exciting products to our members. The Sam’s Club Member Access Platform (MAP), the retail media network arm, is the nexus of the Supplier -Marketer- Merchant partnership. MAP is responsible for delivering impactful omnichannel advertising experiences to our members that are married with closed-loop measurement.

The Measurement, Insights and Data Strategy (MINDS) team is a data and analytics function supporting the MAP organization. They provide campaign performance measurement and audience insights for marketing effectiveness and optimization and lead innovation and monetization initiatives through media experimentation and data strategy. The team fuels MAP’s winning formula – easy to buy, easy to sell, easy to operate -- to drive accelerated growth for both supplier brands and Sam’s Club. Realizing the unique strength in 100% traceable member journey data, omni-channel fulfillment capabilities, and personalization capabilities with growing member reach.

We are seeking a Senior Data Scientist to join its Media Science and Experimentation team and help drive the company’s data innovation strategy. In this role, you will focus on implementing clean room technologies for closed-loop measurement, developing generative AI solutions for social listening, and advancing audience monetization through sophisticated experiments and machine learning–based targeting and measurement. You’ll collaborate with internal teams across Sales, Marketing, Operations, Product, Engineering, and Site Analytics to design and execute advanced analytics and measurement solutions. Additionally, you will work with external ad-tech and measurement partners—including Meta, Pinterest, Tradedesk, LiveRamp, Circana, and Epsilon—to explore new monetization opportunities using emerging technologies such as clean rooms, in-store beacons, and data marketplaces. This position reports to the Director of Media Science and Experimentation.

What you’ll do:
• Lead clean-room data science initiatives with Meta and Pinterest, managing end-to-end workflows such as audience joins, closed loop attribution measurement, campaign incrementality testing, and cross-channel measurements.
• Collaborate closely with cross-functional teams—including Product, Engineering, and Legal—to define scalable schema, governance protocols, and privacy-safe data-sharing pipelines that support both campaign measurement and audience activation.
• Design and implement advanced GenAI solutions for social listening, building LLM-powered systems that process and extract sentiment, intent, and brand affinity signals from comment data across influencer and social campaigns.
• Deliver actionable insights to campaign managers and advertisers by transforming unstructured social content into structured, high-signal intelligence.
• Integrate third-party data sources—including Freeosk sampling, Experian, Epsilon, and Circana panel data—to enhance targeting accuracy and segmentation depth, enabling more advanced use cases in personalization, lifecycle marketing, and high-value audience activation across media channels.
• Develop scalable audience automation and sharing frameworks by integrating clean-room capabilities with internal audience builders and external media platforms. Enable dynamic audience modeling, streamlined data activation, and seamless measurement workflows across partner ecosystems to drive campaign efficiency and personalization.
• Support go-to-market strategies by partnering with commercial and product teams on sales enablement, including the creation of training materials, case study collateral, and data-backed narratives to demonstrate value to advertisers and internal stakeholders.
• Develop new and innovative measurement solutions in Data Clean Rooms using advanced ML algorithms such as KD Tree Nearest Neighbor Synthetic control matching, propensity scores, t-test and bootstrapping tests for statistical significance calculations on partner media impressions data, demographics, and Sam’s buyer segments.
• Participate, and support analytics consultation projects by providing expert advice in experimental design, learning agenda, success metrics, and requirements for testing of new product feature roll-out, new ad partnership, new data adoption, campaign and audience test & learn.
• Manage end-to-end project execution, from planning and data collection to model prototyping and deployment, while effectively communicating with stakeholders and cross-functional partners.
• Conduct statistical power analyses using baseline metrics from historical data, expected impact from past learnings or expert opinion, and population size for qualifying audience to determine minimum sample size required to conduct a feasible test to get statistically significant results.
• Analyze experiment results using advanced statistical techniques such as normality tests, t-test for normally distributed data, non-parametric tests for non-normal data, and difference in difference regression for biased tests.

What you’ll bring:
• Proven experience as a Senior Data Scientist with a focus on marketing analytics, preferably in a retail or membership-based environment
• Statistical analysis experience, including experimental design, regression modeling, and machine learning using tools such as GCP, Adobe analytics, Python, R, Spark SQL and MLlib for custom analysis, in conjunction with SQL for data query and extraction techniques.
• Strong knowledge of statistical analysis, experimental design, regression modeling, machine learning, and data visualization techniques
• Well versed in ad-tech and mar-tech industry with extensive experience in econometric modeling, digital multi-touch attribution, experimental A/B testing, predictive modeling and able to advise when and how to best leverage those approaches.
• Excellent communication skills with the ability to translate complex findings into actionable insights for non-technical stakeholders.
• A comfort level working with ambiguity and the ability to thrive in an environment with rapid change.
• A curious and collaborative mindset that finds enjoyment working on complex problems.
• Familiarity with retail and membership concepts is a plus.
• AI/ML Engineering experience in building scalable media measurement and targeting solutions is a BIG PLUS.

Perks and Benefits

Beyond competitive pay, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more. 

At Sam's Club, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet!

‎
- Health benefits include medical, vision and dental coverage

‎
- Financial benefits include 401(k), stock purchase and company-paid life insurance

‎
- Paid time off benefits include PTO, parental leave, family care leave, bereavement, jury duty, and voting. You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.

‎

For information about PTO, see https://one.walmart.com/notices.

‎
- Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

‎
Live Better U is a company paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

‎
Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

‎

For information about benefits and eligibility, see One.Walmart.

‎
San Bruno, California US-08848:The annual salary range for this position is $117,000.00-$234,000.00

‎
Bentonville, Arkansas US-09930:The annual salary range for this position is $90,000.00-$180,000.00

‎

‎

‎

‎

‎

‎

‎

‎

‎

‎
Additional compensation includes annual or quarterly performance bonuses.

‎

‎

‎

‎

‎

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1- Bachelor’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years' experience in an analytics related field. Option 2- Master’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years' experience in an analytics related field. Option 3 - 5 years' experience in an analytics or related field.

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data science, machine learning, optimization models, Master’s degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.

Primary Location...

850 Cherry Avenue, San Bruno, CA 94066-3031, United States of America",2025-07-23T00:00:00.000Z,2025-07-25,"['Proven experience as a Senior Data Scientist with a focus on marketing analytics, preferably in a retail or membership-based environment', 'Statistical analysis experience, including experimental design, regression modeling, and machine learning using tools such as GCP, Adobe analytics, Python, R, Spark SQL and MLlib for custom analysis, in conjunction with SQL for data query and extraction techniques', 'Strong knowledge of statistical analysis, experimental design, regression modeling, machine learning, and data visualization techniques', 'Well versed in ad-tech and mar-tech industry with extensive experience in econometric modeling, digital multi-touch attribution, experimental A/B testing, predictive modeling and able to advise when and how to best leverage those approaches', 'Excellent communication skills with the ability to translate complex findings into actionable insights for non-technical stakeholders', 'A comfort level working with ambiguity and the ability to thrive in an environment with rapid change', 'A curious and collaborative mindset that finds enjoyment working on complex problems', 'AI/ML Engineering experience in building scalable media measurement and targeting solutions is a BIG PLUS', ""Option 1- Bachelor’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years' experience in an analytics related field"", ""Option 2- Master’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years' experience in an analytics related field"", ""Option 3 - 5 years' experience in an analytics or related field"", 'Data science, machine learning, optimization models, Master’s degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly', 'The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture']","['The Measurement, Insights and Data Strategy (MINDS) team is a data and analytics function supporting the MAP organization', 'In this role, you will focus on implementing clean room technologies for closed-loop measurement, developing generative AI solutions for social listening, and advancing audience monetization through sophisticated experiments and machine learning–based targeting and measurement', 'You’ll collaborate with internal teams across Sales, Marketing, Operations, Product, Engineering, and Site Analytics to design and execute advanced analytics and measurement solutions', 'Additionally, you will work with external ad-tech and measurement partners—including Meta, Pinterest, Tradedesk, LiveRamp, Circana, and Epsilon—to explore new monetization opportunities using emerging technologies such as clean rooms, in-store beacons, and data marketplaces', 'This position reports to the Director of Media Science and Experimentation', 'Lead clean-room data science initiatives with Meta and Pinterest, managing end-to-end workflows such as audience joins, closed loop attribution measurement, campaign incrementality testing, and cross-channel measurements', 'Collaborate closely with cross-functional teams—including Product, Engineering, and Legal—to define scalable schema, governance protocols, and privacy-safe data-sharing pipelines that support both campaign measurement and audience activation', 'Design and implement advanced GenAI solutions for social listening, building LLM-powered systems that process and extract sentiment, intent, and brand affinity signals from comment data across influencer and social campaigns', 'Deliver actionable insights to campaign managers and advertisers by transforming unstructured social content into structured, high-signal intelligence', 'Integrate third-party data sources—including Freeosk sampling, Experian, Epsilon, and Circana panel data—to enhance targeting accuracy and segmentation depth, enabling more advanced use cases in personalization, lifecycle marketing, and high-value audience activation across media channels', 'Develop scalable audience automation and sharing frameworks by integrating clean-room capabilities with internal audience builders and external media platforms', 'Enable dynamic audience modeling, streamlined data activation, and seamless measurement workflows across partner ecosystems to drive campaign efficiency and personalization', 'Support go-to-market strategies by partnering with commercial and product teams on sales enablement, including the creation of training materials, case study collateral, and data-backed narratives to demonstrate value to advertisers and internal stakeholders', 'Develop new and innovative measurement solutions in Data Clean Rooms using advanced ML algorithms such as KD Tree Nearest Neighbor Synthetic control matching, propensity scores, t-test and bootstrapping tests for statistical significance calculations on partner media impressions data, demographics, and Sam’s buyer segments', 'Participate, and support analytics consultation projects by providing expert advice in experimental design, learning agenda, success metrics, and requirements for testing of new product feature roll-out, new ad partnership, new data adoption, campaign and audience test & learn', 'Manage end-to-end project execution, from planning and data collection to model prototyping and deployment, while effectively communicating with stakeholders and cross-functional partners', 'Conduct statistical power analyses using baseline metrics from historical data, expected impact from past learnings or expert opinion, and population size for qualifying audience to determine minimum sample size required to conduct a feasible test to get statistically significant results', 'Analyze experiment results using advanced statistical techniques such as normality tests, t-test for normally distributed data, non-parametric tests for non-normal data, and difference in difference regression for biased tests']",True,"['Generative AI', 'Large Language Models']","Generative AI: Developing AI solutions to generate insights from social listening data, enhancing brand sentiment and intent analysis.; Large Language Models: Using LLM-powered systems to process unstructured social media comments for extracting sentiment and brand affinity.","['Clean Room Technologies', 'Closed-Loop Attribution Measurement', 'Campaign Incrementality Testing', 'Cross-Channel Measurement', 'Experimental Design', 'Regression Modeling', 'Machine Learning', 'KD Tree Nearest Neighbor', 'Propensity Score Matching', 'T-Test and Bootstrapping', 'Difference-in-Differences Regression', 'Statistical Power Analysis', 'SQL', 'Python', 'R', 'Spark SQL', 'MLlib', 'Adobe Analytics', 'Econometric Modeling', 'Digital Multi-Touch Attribution', 'Predictive Modeling', 'Data Visualization', 'Data Pipelines', 'Audience Segmentation', 'Third-Party Data Integration', 'Media Experimentation', 'Data Clean Rooms']","Clean Room Technologies: Used for privacy-safe data sharing and closed-loop measurement to enable accurate campaign attribution and audience joins.; Closed-Loop Attribution Measurement: Technique to measure the effectiveness of marketing campaigns by linking ad exposure to consumer actions across channels.; Campaign Incrementality Testing: Experimental method to determine the true incremental impact of marketing campaigns on desired outcomes.; Cross-Channel Measurement: Measuring campaign performance across multiple marketing channels to understand overall effectiveness.; Experimental Design: Designing controlled experiments such as A/B tests to evaluate marketing strategies and product features.; Regression Modeling: Statistical technique used to model relationships between variables for marketing analytics and predictive insights.; Machine Learning: Applied to targeting, measurement, and predictive modeling to optimize marketing campaigns and audience segmentation.; KD Tree Nearest Neighbor: Algorithm used for synthetic control matching in advanced measurement solutions within data clean rooms.; Propensity Score Matching: Statistical method to reduce bias in observational studies by matching treated and control groups based on covariates.; T-Test and Bootstrapping: Statistical tests used to assess significance and confidence intervals in campaign and audience experiments.; Difference-in-Differences Regression: Analytical technique to estimate causal effects in biased or non-randomized experiments.; Statistical Power Analysis: Used to determine minimum sample sizes required for statistically significant experimental results.; SQL: Used for querying and extracting data from databases to support analytics and modeling tasks.; Python: Programming language employed for data analysis, machine learning, and building custom analytics solutions.; R: Statistical programming language used for advanced analytics, modeling, and visualization.; Spark SQL: Big data processing tool used for querying large datasets and integrating with machine learning pipelines.; MLlib: Spark's machine learning library used for scalable machine learning model development and deployment.; Adobe Analytics: Tool used for digital marketing analytics and deriving insights from web and campaign data.; Econometric Modeling: Applied to marketing analytics for understanding economic relationships and multi-touch attribution.; Digital Multi-Touch Attribution: Methodology to assign credit to multiple marketing touchpoints influencing customer conversion.; Predictive Modeling: Building models to forecast customer behavior and campaign outcomes for marketing optimization.; Data Visualization: Techniques used to communicate complex data insights effectively to stakeholders.; Data Pipelines: Infrastructure to ingest, process, and transform data for analytics and modeling purposes.; Audience Segmentation: Dividing customers into groups based on data to enable targeted marketing and personalization.; Third-Party Data Integration: Incorporating external data sources like Experian and Circana to enhance targeting and analytics.; Media Experimentation: Running controlled tests to optimize media spend and campaign effectiveness.; Data Clean Rooms: Secure environments for combining and analyzing data from multiple parties while preserving privacy."
4JMZcXuU2wbJEZJJAAAAAA==,Entry Level Developer/Coder/Programmer/Data Scientist/Analyst/Engineer,"The Job Market is Challenging due to almost 300,000 Tech Layoffs since October 2022 due to which thousands of laid off Techies are competing with existing Jobseekers. Entry level Job seekers struggle to get responses to their applications forget about getting client interviews. As the Saying goes ""when the Going gets tough the Tough get going"" Candidates who want to make a tech career they need to differentiate themselves by ensuring they have exceptional skills and technologies to be noticed by clients.

Since 2010 Synergisticit has helped Jobseekers differentiate themselves by providing candidates the requisite skills and experience to outperform at interviews and clients. Here at SynergisticIT We just don't focus on getting you a Job we make careers.

All Positions are open for all visas and US citizens

We are matchmakers we provide clients with candidates who can perform from day 1 of starting work. In this challenging economy every client wants to save $$$'s and they want the best value for their money. Jobseekers need to self-evaluate if they have the requisite skills to meet client requirements and needs. Clients now post covid can also hire remote workers which increases even more competition for jobseekers.

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, PayPal, western union, Client, visa, Walmart lab s etc. to name a few.

We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in IT Industry

We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

We also offer optionally Skill and technology enhancement programs for candidates who are either missing skills or are lacking Industry/Client experience with Projects and skills. Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. If they are qualified with enough skills and have hands on project work at clients then they should be good to be submitted to clients. Shortlisting and selection is totally based on clients discretion not ours.

please check the below links to see success outcomes of our candidates

https://www.synergisticit.com/candidate-outcomes/

We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please see us exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023

https://youtu.be/Rfn8Y0gnfL8?si=p2V4KFv5HukJXTrn

https://youtu.be/-HkNN1ag6Zk?si=1NRfgsvL_HJMVb6Q

https://www.youtube.com/watch?v=OAFOhcGy9Z8

https://www.youtube.com/watch?v=EmO7NrWHkLM

https://www.youtube.com/watch?v=NVBU9RYZ6UI

https://www.youtube.com/watch?v=Yy74yvjatVg

For preparing for interviews please visit https://www.synergisticit.com/interview-questions/

We are looking for the right matching candidates for our clients

Please apply via the job posting

REQUIRED SKILLS For Java /Full stack/Software Programmer
• Bachelor's degree or Master's degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
• Highly motivated, self-learner, and technically inquisitive
• Experience in programming language Java and understanding of the software development life cycle
• Project work on the skills
• Knowledge of Core Java, JavaScript, C++ or software programming
• Spring boot, Microservices, Docker, Jenkins and REST API's experience
• Excellent written and verbal communication skills

For data Science/Machine learning Positions

REQUIRED SKILLS
• Bachelor's degree or Master's degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
• Project work on the technologies needed
• Highly motivated, self-learner, and technically inquisitive
• Experience in programming language Java and understanding of the software development life cycle
• Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools
• Excellent written and verbal communication skills

Preferred skills: NLP, Text mining, Tableau, PowerBI, TensorFlow

If you get emails from our skill enhancement team please ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",,2025-07-25,"['Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in IT Industry', 'Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio', 'If they are qualified with enough skills and have hands on project work at clients then they should be good to be submitted to clients', 'REQUIRED SKILLS For Java /Full stack/Software Programmer', ""Bachelor's degree or Master's degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT"", 'Highly motivated, self-learner, and technically inquisitive', 'Experience in programming language Java and understanding of the software development life cycle', 'Project work on the skills', 'Knowledge of Core Java, JavaScript, C++ or software programming', ""Spring boot, Microservices, Docker, Jenkins and REST API's experience"", 'Excellent written and verbal communication skills', 'For data Science/Machine learning Positions', ""Bachelor's degree or Master's degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT"", 'Project work on the technologies needed', 'Highly motivated, self-learner, and technically inquisitive', 'Experience in programming language Java and understanding of the software development life cycle', 'Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools', 'Excellent written and verbal communication skills']",,True,['TensorFlow'],TensorFlow: Deep learning framework preferred for AI-related tasks such as neural network development.,"['Statistics', 'SAS', 'Python', 'Data Visualization Tools', 'Tableau', 'PowerBI', 'Machine Learning', 'Computer Vision', 'NLP', 'Java', 'Core Java', 'JavaScript', 'C++', 'Spring Boot', 'Microservices', 'Docker', 'Jenkins', 'REST APIs', 'Project Work']","Statistics: Used as a foundational skill for data science roles to analyze and interpret data.; SAS: A statistical software tool mentioned as a required skill for data science positions.; Python: Programming language used for data analysis, machine learning, and data science projects.; Data Visualization Tools: Tools like Tableau and PowerBI used to create visual representations of data for insights.; Tableau: A BI and data visualization tool preferred for creating dashboards and reports.; PowerBI: A business intelligence tool preferred for data visualization and reporting.; Machine Learning: General machine learning knowledge required for data science and machine learning engineer roles.; Computer Vision: A data science domain mentioned as a skill area, involving image data analysis.; NLP: Natural Language Processing mentioned as a preferred skill for text mining and analysis.; Java: Programming language required for software development and data science project work.; Core Java: Fundamental Java programming knowledge required for software development roles.; JavaScript: Programming language mentioned for software programming and full stack development.; C++: Programming language listed as part of software programming knowledge.; Spring Boot: Java framework used for building microservices and backend applications.; Microservices: Architectural style for building distributed applications, relevant for software roles.; Docker: Containerization tool used to package and deploy applications consistently.; Jenkins: Automation server used for continuous integration and deployment in software projects.; REST APIs: Web service interfaces used for communication between software components.; Project Work: Hands-on experience with relevant technologies emphasized for all roles."
Q5yyelc-6pcT_Az8AAAAAA==,"Senior Data Scientist - Competitive Intelligence at Coinbase Memphis, TN","Senior Data Scientist - Competitive Intelligence job at Coinbase. Memphis, TN. Ready to be pushed beyond what you think you’re capable of?
At Coinbase, our mission is to increase economic freedom in the world. It’s a massive, ambitious opportunity that demands the best of us, every day, as we build the emerging onchain platform — and with it, the future global financial system.
To achieve our mission, we’re seeking a very specific candidate. We want someone who is passionate about our mission and who believes in the power of crypto and blockchain technology to update the financial system. We want someone who is eager to leave their mark on the world, who relishes the pressure and privilege of working with high caliber colleagues, and who actively seeks feedback to keep leveling up. We want someone who will run towards, not away from, solving the company’s hardest problems.
Our work culture is intense and isn’t for everyone. But if you want to build the future alongside others who excel in their disciplines and expect the same from you, there’s no better place to be.
While many roles at Coinbase are remote-first, we are not remote-only. In-person participation is required throughout the year. Team and company-wide offsites are held multiple times annually to foster collaboration, connection, and alignment. Attendance is expected and fully supported.Role Overview:
Data Science is a pivotal element of our operational strategy at Coinbase, influencing product, engineering, and decision-making processes. This role is integral to our senior leadership, investor relations, and peer teams– you will tackle complex, ambiguous questions that influence insights generation and decision making at the highest levels.
What You'll Be Doing:

Develop and maintain a comprehensive competitive intelligence framework to monitor industry trends and competitors' performance, products and activities
Engage with senior leadership to provide analytics and insights on business performance, competitive landscape and metric trends.
Gather, process, and analyze data from multiple sources (internal and external) to identify market trends and opportunities
Conduct exploratory data analysis (EDA) to uncover insights that explain business drivers and drive strategic decisions.
Prepare and present clear, concise readouts and dashboards for a senior-level audience, ensuring exceptional executive presence.
Develop and maintain data models and data pipelines to support data collection, analyses and reporting.

What We Look for in You:

A BA/BS or higher in a quantitative field such as Financial Engineering, Math, Statistics, Physics, or Computer Science. Preferably with ≥5+ years of relevant experience or a PhD in a quantitative field with with ≥3+ years of relevant experience
Demonstrated experience in driving impactful data science projects that tackle ambiguous problem spaces.
Ability to thrive in a fast-paced environment by effectively multitasking, prioritizing tasks, and managing competing demands
Ability to influence stakeholders by synthesizing data learnings into compelling stories.
Proven track record of effectively managing and communicating with senior leadership, including presenting complex information in a clear and concise manner
Self-starter with the determination and persistence to run through brick walls to achieve results
Professional experience using SQL and Python.
Understanding of the dynamics of working within a public company and managing sensitive stakeholder relationships.
Demonstration of our core cultural values: clear communication, positive energy, continuous learning, and efficient execution.

Disclaimer: Applying for a specific role does not guarantee consideration for that exact position. Leveling and team matching are assessed throughout the interview process.
ID: G2462Pay Transparency Notice: Depending on your work location, the target annual salary for this position can range as detailed below. Full time offers from Coinbase also include target bonus + benefits (including medical, dental, vision and 401(k)).Pay Range:$180,370—$212,200 USDPlease be advised that each candidate may submit a maximum of four applications within any 30-day period. We encourage you to carefully evaluate how your skills and interests align with Coinbase's roles before applying.
Commitment to Equal Opportunity
Coinbase is committed to diversity in its workforce and is proud to be an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, creed, gender, national origin, age, disability, veteran status, sex, gender expression or identity, sexual orientation or any other basis protected by applicable law. Coinbase will also consider for employment qualified applicants with criminal histories in a manner consistent with applicable federal, state and local law. For US applicants, you may view the Know Your Rights notice here. Additionally, Coinbase participates in the E-Verify program in certain locations, as required by law.
Coinbase is also committed to providing reasonable accommodations to individuals with disabilities. If you need a reasonable accommodation because of a disability for any part of the employment process, please contact us at accommodations[at]coinbase.com to let us know the nature of your request and your contact information. For quick access to screen reading technology compatible with this site click here to download a free compatible screen reader (free step by step tutorial can be found here).
Global Data Privacy Notice for Job Candidates and Applicants
Depending on your location, the General Data Protection Regulation (GDPR) and California Consumer Privacy Act (CCPA) may regulate the way we manage the data of job applicants. Our full notice outlining how data will be processed as part of the application procedure for applicable locations is available here. By submitting your application, you are agreeing to our use and processing of your data as required. For US applicants only, by submitting your application you are agreeing to arbitration of disputes as outlined here.",2025-06-30T00:00:00.000Z,2025-07-25,"['We want someone who is eager to leave their mark on the world, who relishes the pressure and privilege of working with high caliber colleagues, and who actively seeks feedback to keep leveling up', 'We want someone who will run towards, not away from, solving the company’s hardest problems', 'A BA/BS or higher in a quantitative field such as Financial Engineering, Math, Statistics, Physics, or Computer Science', 'Preferably with ≥5+ years of relevant experience or a PhD in a quantitative field with with ≥3+ years of relevant experience', 'Demonstrated experience in driving impactful data science projects that tackle ambiguous problem spaces', 'Ability to thrive in a fast-paced environment by effectively multitasking, prioritizing tasks, and managing competing demands', 'Ability to influence stakeholders by synthesizing data learnings into compelling stories', 'Proven track record of effectively managing and communicating with senior leadership, including presenting complex information in a clear and concise manner', 'Self-starter with the determination and persistence to run through brick walls to achieve results', 'Professional experience using SQL and Python', 'Understanding of the dynamics of working within a public company and managing sensitive stakeholder relationships']","['In-person participation is required throughout the year', 'Team and company-wide offsites are held multiple times annually to foster collaboration, connection, and alignment', 'Attendance is expected and fully supported', 'Data Science is a pivotal element of our operational strategy at Coinbase, influencing product, engineering, and decision-making processes', 'This role is integral to our senior leadership, investor relations, and peer teams– you will tackle complex, ambiguous questions that influence insights generation and decision making at the highest levels', ""Develop and maintain a comprehensive competitive intelligence framework to monitor industry trends and competitors' performance, products and activities"", 'Engage with senior leadership to provide analytics and insights on business performance, competitive landscape and metric trends', 'Gather, process, and analyze data from multiple sources (internal and external) to identify market trends and opportunities', 'Conduct exploratory data analysis (EDA) to uncover insights that explain business drivers and drive strategic decisions', 'Prepare and present clear, concise readouts and dashboards for a senior-level audience, ensuring exceptional executive presence', 'Develop and maintain data models and data pipelines to support data collection, analyses and reporting', 'Demonstration of our core cultural values: clear communication, positive energy, continuous learning, and efficient execution', 'Leveling and team matching are assessed throughout the interview process']",True,[],,"['Competitive Intelligence Framework', 'Exploratory Data Analysis', 'Data Models', 'Data Pipelines', 'SQL', 'Python', 'Dashboards and Reporting']","Competitive Intelligence Framework: Used to monitor industry trends and competitors' performance, products, and activities to inform strategic decisions.; Exploratory Data Analysis: Applied to uncover insights that explain business drivers and support strategic decision-making.; Data Models: Developed and maintained to support data collection, analysis, and reporting for business insights.; Data Pipelines: Built and maintained to facilitate efficient data collection and processing from multiple sources.; SQL: Used professionally for querying and managing data from databases to support analysis.; Python: Utilized for data processing, analysis, and building data science solutions.; Dashboards and Reporting: Prepared and presented to senior leadership to communicate business performance and metric trends."
XW0IRUn7bngH8eOnAAAAAA==,"Member of Technical Staff, Experimentation Data Scientist","At Microsoft, we are committed to advancing the frontiers of artificial intelligence in ways that are bold, responsible, and inclusive. Our vision is to build intelligent systems-spanning agents, applications, services, and infrastructure-that empower every person and organization on the planet to achieve more. We believe AI should be accessible to all: consumers, businesses, and developers alike.

The Microsoft AI (MAI) team is looking for an Experimentation Data Scientist to help shape the next generation of personal AI experiences through Copilot. This role involves managing and analyzing experiments to provide actionable insights that drive product improvements and user experience enhancements. Key Responsibilities: Experimentation Management: Collaborate with feature teams to design, implement, and debug experiments.

Conduct ad hoc analysis to understand metrics and user behavior changes. Statistical Analysis: Perform power analysis and experimental inference to ensure the validity and reliability of experiments. Data Analysis: Utilize SQL and Python to pull and analyze data quickly, providing insights into user behavior and experiment outcomes.

Collaboration: Work closely with partners to ensure robust telemetry and instrumentation and with feature teams to design and implement experiments. Qualifications Bachelor's Degree in Statistics, Econometrics, Computer Science, Electrical or Computer Engineering, or related field AND 6+ years related experience (e.g., statistics, predictive analytics, research) OR Master's Degree in Statistics, Econometrics, Computer Science, Electrical or Computer Engineering, or related field AND 4+ years related experience (e.g., statistics, predictive analytics, research) OR Doctorate in Statistics, Econometrics, Computer Science, Electrical or Computer Engineering, or related field AND 3+ years related experience (e.g., statistics, predictive analytics, research) OR equivalent experience. Strong background in statistics, economics, or a related field

Proficiency in SQL and Python. Experience with online A/B testing. Ability to conduct power analysis and experimental inference.

Strong problem-solving skills and attention to detail. Excellent communication and collaboration skills. Preferred Qualifications: Experience in a similar role within a data science or analytics team.

Familiarity with telemetry and instrumentation frameworks. Data Science IC5 - The typical base pay range for this role across the U.S. is USD $139,900 - $274,800 per year

There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $188,000 - $304,200 per year. Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here: https://careers.microsoft.com/us/en/us-corporate-pay Microsoft will accept applications for the role until Month Day, Year

Microsoft's mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.

#MAI Copilot",2025-07-10T00:00:00.000Z,2025-07-25,"[""Qualifications Bachelor's Degree in Statistics, Econometrics, Computer Science, Electrical or Computer Engineering, or related field AND 6+ years related experience (e.g., statistics, predictive analytics, research) OR Master's Degree in Statistics, Econometrics, Computer Science, Electrical or Computer Engineering, or related field AND 4+ years related experience (e.g., statistics, predictive analytics, research) OR Doctorate in Statistics, Econometrics, Computer Science, Electrical or Computer Engineering, or related field AND 3+ years related experience (e.g., statistics, predictive analytics, research) OR equivalent experience"", 'Strong background in statistics, economics, or a related field', 'Proficiency in SQL and Python', 'Experience with online A/B testing', 'Ability to conduct power analysis and experimental inference', 'Strong problem-solving skills and attention to detail', 'Excellent communication and collaboration skills', 'Familiarity with telemetry and instrumentation frameworks']","['This role involves managing and analyzing experiments to provide actionable insights that drive product improvements and user experience enhancements', 'Key Responsibilities: Experimentation Management: Collaborate with feature teams to design, implement, and debug experiments', 'Conduct ad hoc analysis to understand metrics and user behavior changes', 'Statistical Analysis: Perform power analysis and experimental inference to ensure the validity and reliability of experiments', 'Data Analysis: Utilize SQL and Python to pull and analyze data quickly, providing insights into user behavior and experiment outcomes', 'Collaboration: Work closely with partners to ensure robust telemetry and instrumentation and with feature teams to design and implement experiments']",True,[],,"['Experimentation Management', 'A/B Testing', 'Power Analysis', 'Experimental Inference', 'SQL', 'Python', 'Telemetry and Instrumentation', 'Statistical Analysis']","Experimentation Management: Managing and analyzing experiments to derive actionable insights for product and user experience improvements.; A/B Testing: Conducting online controlled experiments to compare different versions of features and measure their impact on user behavior.; Power Analysis: Performing statistical power analysis to ensure experiments have sufficient sample size for valid inference.; Experimental Inference: Applying statistical methods to draw valid conclusions from experimental data.; SQL: Using SQL to query and extract data efficiently for analysis of user behavior and experiment outcomes.; Python: Utilizing Python programming for data manipulation, analysis, and statistical computations.; Telemetry and Instrumentation: Ensuring robust data collection frameworks to capture user interactions and experiment metrics.; Statistical Analysis: Applying statistical techniques to analyze data and validate experimental results."
lmVpVHR6235f71D8AAAAAA==,Data Scientist- Minneapolis MNinnea,"Position- Data Scientist
Location- Minneapolis MN
Duration- Contract
Rate- DOE

Lead Researcher / Data Scientist
Proficiency across the entire Client pipeline is essential, coupled with a confident aptitude for evaluating outcomes and understand the business impact. As a pivotal member of a small team, you will take ownership of projects, adeptly managing and engaging stakeholders while adhering to industry best practices.

Additionally, a hunger for deeper Client/AI knowledge and a willingness to delve into the engineering and deployment facets of Client are crucial. The ability to thrive in an agile environment, fostering close collaboration with product, engineering, and UX teams, is paramount. We are particularly interested in candidates capable of swiftly validating business value and guiding projects to successful production. Prior experience in LLM is desirable. Join us in shaping the future of legal technology innovation!

As an Applied Scientist in Labs, you will be part of a global interdisciplinary team of experts. We hire specialists across a variety of AI research areas, as well as engineers, to drive the company's digital transformation. TR Labs is known for delivering innovative AI products that serve Client customers in new and exciting ways.

About The Role

As a Senior/Lead Data Scientist/Researcher, NLP you will:
• Experiment and Develop: You will drive the end-to-end model development lifecycle, championing best practices to ensure reproducible research and well-managed software delivery
• Collaborate : Working on a collaborative cross-functional team, you will share information, value diverse ideas, and partner effectively with colleagues across the globe. You will elevate and mentor teammates
• Deliver : with a sense of urgency and the desire to work in a fast-paced, dynamic environment, you will translate complex business problems into projects with clearly defined scope. Our problems are complex; our solutions are right-sized. You will be accountable for timely, well-managed deliverables
• Innovate : You will be empowered to try new approaches and learn new technologies. You will foster innovative ideas to solve real-world challenges
• Inspire : You will be a proactive communicator who is excited to share your work. You will be articulate and compelling in describing ideas to both technical and non-technical audiences. You will help lead the way in the adoption of AI across the enterprise.
Basic Qualifications
• Master or a a comparable level of experience
• At least 5 years practical, relevant experience building Client/AI systems, from ideation to production
• Solid software engineering skills for prototyping
• Professional experience as a technical leader, translating complex business problems into projects with clearly defined scope, coordinating and guiding the work of others",,2025-07-25,"['Proficiency across the entire Client pipeline is essential, coupled with a confident aptitude for evaluating outcomes and understand the business impact', 'Additionally, a hunger for deeper Client/AI knowledge and a willingness to delve into the engineering and deployment facets of Client are crucial', 'The ability to thrive in an agile environment, fostering close collaboration with product, engineering, and UX teams, is paramount', 'We are particularly interested in candidates capable of swiftly validating business value and guiding projects to successful production', 'You will be articulate and compelling in describing ideas to both technical and non-technical audiences', 'Master or a a comparable level of experience', 'At least 5 years practical, relevant experience building Client/AI systems, from ideation to production', 'Solid software engineering skills for prototyping', 'Professional experience as a technical leader, translating complex business problems into projects with clearly defined scope, coordinating and guiding the work of others']","['As a pivotal member of a small team, you will take ownership of projects, adeptly managing and engaging stakeholders while adhering to industry best practices', 'Experiment and Develop: You will drive the end-to-end model development lifecycle, championing best practices to ensure reproducible research and well-managed software delivery', 'Collaborate : Working on a collaborative cross-functional team, you will share information, value diverse ideas, and partner effectively with colleagues across the globe', 'You will elevate and mentor teammates', 'Deliver : with a sense of urgency and the desire to work in a fast-paced, dynamic environment, you will translate complex business problems into projects with clearly defined scope', 'You will be accountable for timely, well-managed deliverables', 'Innovate : You will be empowered to try new approaches and learn new technologies', 'You will foster innovative ideas to solve real-world challenges', 'Inspire : You will be a proactive communicator who is excited to share your work', 'You will help lead the way in the adoption of AI across the enterprise']",True,"['Large Language Models', 'Natural Language Processing', 'AI System Engineering and Deployment']","Large Language Models: Experience with LLMs is desirable, indicating work with advanced AI models for natural language processing.; Natural Language Processing: Developing and experimenting with NLP models as part of AI research and product innovation.; AI System Engineering and Deployment: Involvement in engineering and deploying AI systems from ideation to production.","['Model Development Lifecycle', 'Reproducible Research', 'Software Prototyping', 'Stakeholder Management']",Model Development Lifecycle: Driving the end-to-end process of building and deploying predictive models to solve business problems.; Reproducible Research: Ensuring that data experiments and analyses can be consistently replicated to validate findings.; Software Prototyping: Using software engineering skills to quickly develop and test data science models and solutions.; Stakeholder Management: Engaging and managing stakeholders to align data projects with business objectives.
2X2i3m-VlA5XoRFuAAAAAA==,"Staff, Data Scientist","Position Summary...

What you'll do...

We are looking for a computer vision scientist to solve some real retail problems/challenges. Utilize Computer Vision algorithms, Generative AI methods, deep learning architectures, VLMs and state-of-the-art techniques to build and deploy advanced retail solutions.

About Team:
At Walmart, we prioritize innovation and data security. Our team is dedicated to maintaining a secure operating environment and preserving the trust of our customers, associates, and stakeholders. We combine a range of services and expertise to prevent fraud, detect threats, and manage digital risk and access. Our focus is on mitigating attack risks, securing cloud transformation, and fostering a culture of security and reliability within our team

What you'll do:
• Design, train, and deploy deep learning models for object detection, image-based personalization, including product discovery, visual recommendations, and generative image content.
• Build and scale foundation model pipelines that leverage multimodal signals — including text, images, and customer embeddings — to power highly personalized visual experiences.
• Lead innovation efforts on image generative modeling, including diffusion models, CNNs, or text-to-image synthesis aligned with retail context.
• Implement efficient image understanding models for visual similarity, visual search, or classification across Walmart's vast product catalog.
• Design model workflow that integrates with MLOps to optimize model performance and latency, especially for customer-facing features with visual components.
• Contribute to cutting-edge research and internal knowledge by publishing work or presenting findings on vision-language models, multimodal personalization, and generative AI for e-commerce.

What you'll bring:
• MS or (preferably) PhD in Computer Science, Machine Learning, Computer Vision, Applied Mathematics, or a related technical field, with 2–4 years of industry or research experience.
• Demonstrated expertise in deep learning for computer vision, including CNNs, vision transformers (ViTs), and diffusion-based generative models.
• Experience building and deploying image generation, manipulation, or understanding systems in production — such as visual search, personalized image recommendations.
• Proficiency in Python and strong familiarity with deep learning frameworks such as PyTorch, TensorFlow, and image modeling libraries like OpenCV, torchvision, or Hugging Face.
• Familiarity with multimodal models (e.g., CLIP, BLIP, Flamingo) that combine vision and language for richer customer understanding and content personalization.
• Experience working with large-scale datasets, data pipelines, and distributed training.

About Walmart Global Tech
Imagine working in an environment where one line of code can make life easier for hundreds of millions of people. That’s what we do at Walmart Global Tech. We’re a team of software engineers, data scientists, cybersecurity expert's and service professionals within the world’s leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.

Walmart’s culture is a competitive advantage, and it’s fostered by being together. Working together in person allows us to collaborate, align quickly and innovate with greater speed. We use our campuses to create purposeful connection rooted in deepening understanding and investing in the development of our associates.
Our hubs: Walmart is a global company with offices across the United States and around the world. Our global headquarters is in Bentonville, Arkansas, with primary hubs in the San Francisco Bay area and New York/New Jersey.

Benefits:
Benefits: Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.

Equal Opportunity Employer:
Walmart, Inc. is an Equal Opportunity Employer – By Choice. We believe we are best equipped to help our associates, customers, and the communities we serve live better when we really know them. That means understanding, respecting, and valuing unique styles, experiences, identities, ideas, and opinions – while being inclusive of all people.

The above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

‎

‎

‎
You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.

‎

For information about PTO, see https://one.walmart.com/notices.

‎

‎
Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

‎
Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

‎

For information about benefits and eligibility, see One.Walmart.

‎
The annual salary range for this position is $110,000.00-$220,000.00

‎
Additional compensation includes annual or quarterly performance bonuses.

‎
Additional compensation for certain positions may also include:

‎

‎
- Stock

‎

‎

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 4 years' experience in an analytics related field. Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 2 years' experience in an analytics related field. Option 3: 6 years' experience in an analytics or related field

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data science, machine learning, optimization models, PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.

Primary Location...

805 Se Moberly Ln, Bentonville, AR 72712, United States of America",2025-07-22T00:00:00.000Z,2025-07-25,"['MS or (preferably) PhD in Computer Science, Machine Learning, Computer Vision, Applied Mathematics, or a related technical field, with 2–4 years of industry or research experience', 'Demonstrated expertise in deep learning for computer vision, including CNNs, vision transformers (ViTs), and diffusion-based generative models', 'Experience building and deploying image generation, manipulation, or understanding systems in production — such as visual search, personalized image recommendations', 'Proficiency in Python and strong familiarity with deep learning frameworks such as PyTorch, TensorFlow, and image modeling libraries like OpenCV, torchvision, or Hugging Face', 'Familiarity with multimodal models (e.g., CLIP, BLIP, Flamingo) that combine vision and language for richer customer understanding and content personalization', 'Experience working with large-scale datasets, data pipelines, and distributed training', ""Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 4 years' experience in an analytics related field"", ""Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 2 years' experience in an analytics related field"", ""Option 3: 6 years' experience in an analytics or related field"", 'Data science, machine learning, optimization models, PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly', 'The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture']","['We are looking for a computer vision scientist to solve some real retail problems/challenges', 'Utilize Computer Vision algorithms, Generative AI methods, deep learning architectures, VLMs and state-of-the-art techniques to build and deploy advanced retail solutions', 'Design, train, and deploy deep learning models for object detection, image-based personalization, including product discovery, visual recommendations, and generative image content', 'Build and scale foundation model pipelines that leverage multimodal signals — including text, images, and customer embeddings — to power highly personalized visual experiences', 'Lead innovation efforts on image generative modeling, including diffusion models, CNNs, or text-to-image synthesis aligned with retail context', ""Implement efficient image understanding models for visual similarity, visual search, or classification across Walmart's vast product catalog"", 'Design model workflow that integrates with MLOps to optimize model performance and latency, especially for customer-facing features with visual components', 'Contribute to cutting-edge research and internal knowledge by publishing work or presenting findings on vision-language models, multimodal personalization, and generative AI for e-commerce', 'That means understanding, respecting, and valuing unique styles, experiences, identities, ideas, and opinions – while being inclusive of all people']",True,"['Generative AI', 'Diffusion Models', 'Vision-Language Models', 'Foundation Models', 'Hugging Face', 'Prompt Engineering']",Generative AI: Used for image generation and manipulation to create personalized visual content in retail.; Diffusion Models: Applied as state-of-the-art generative models for text-to-image synthesis and image generation.; Vision-Language Models: Multimodal AI models combining vision and language to power personalized visual experiences.; Foundation Models: Large-scale pretrained models leveraged to build scalable multimodal pipelines for retail applications.; Hugging Face: Platform and library used for deploying and fine-tuning state-of-the-art AI models including vision-language models.; Prompt Engineering: Implied in the use of generative AI and foundation models to tailor outputs for retail personalization.,"['Computer Vision', 'Deep Learning', 'Convolutional Neural Networks', 'Vision Transformers', 'Data Pipelines', 'Python', 'PyTorch', 'TensorFlow', 'OpenCV', 'Torchvision', 'Scikit-learn', 'Spark', 'Scala', 'R', 'Machine Learning', 'Optimization Models', 'Multimodal Models']","Computer Vision: Used to solve retail problems through image-based personalization, object detection, and visual search.; Deep Learning: Applied to build and deploy models for image understanding, personalization, and generative content.; Convolutional Neural Networks: Used as a core architecture for image generative modeling and visual recognition tasks.; Vision Transformers: Employed for advanced image understanding and classification across large product catalogs.; Data Pipelines: Built and scaled to handle large-scale datasets and distributed training for model development.; Python: Primary programming language for developing and deploying machine learning and data science models.; PyTorch: Deep learning framework used for training and deploying neural network models.; TensorFlow: Deep learning framework utilized for building and scaling image-based models.; OpenCV: Library used for image processing and computer vision tasks in production systems.; Torchvision: Library providing datasets, model architectures, and image transformations for computer vision.; Scikit-learn: Open source framework mentioned for general machine learning and data science tasks.; Spark: Used for large-scale data processing and analytics in distributed environments.; Scala: Programming language referenced for data engineering and analytics tasks.; R: Statistical programming language used for analytics and data science.; Machine Learning: General approach for building predictive and optimization models in retail analytics.; Optimization Models: Applied to improve retail operations and decision-making processes.; Multimodal Models: Models combining text, images, and embeddings to enhance customer understanding and personalization."
TlSdO-H7sbBty-NgAAAAAA==,"(USA) Senior Data Scientist, Tech","Position Summary...

What you'll do...

X4 Time Series Data Scientist – Forecasting & Generative AI

What you’ll do:

· Develop scalable time series forecasting systems leveraging global models like Temporal Fusion Transformers, N-BEATS, and PATCHTST, enabling robust forecasting across thousands of retails and e-commerce time series.

· Foundational Knowledge on advanced regression.

· Apply generative AI to synthesize time series data, enhance model training pipelines, and build intelligent NLP-based assistants for analytics enablement.

· Design and train large-scale neural networks for time series, anomaly detection, and causal inference, with deployment via automated batch pipelines using tools like Airflow or Astronomer.

· Build and maintain production-ready forecasting and LLM applications on cloud platforms (GCP or Azure), integrated with internal systems to deliver insights at scale.

· Perform Big Data processing and feature engineering using distributed compute platforms like Spark or Ray.

· Collaborate with cross-functional teams (product, engineering, business) to define objectives, formulate hypotheses, and deploy models that directly influence decision-making.

What you’ll bring:

· Strong foundation in time series forecasting, deep learning, and optimization theory, with a focus on sequence modeling and attention-based architectures.

· Experience in training and deploying transformer-based neural networks (e.g., TFT, LSTM, GPT variants) for real-world business applications.

· Proficient in Python, SQL, and hands-on with PyTorch, TensorFlow/Keras, Scikit-learn, and stats models.

· Demonstrated ability to work on GPU-based model training pipelines, and exposure to managing experimentation at scale.

Great to have:

· Hands-on experience with distributed training, multi-GPU setups, or TPU-based workflows.

· Exposure to LLM fine-tuning, retrieval-augmented generation (RAG), NLP applications.

· Familiarity with ML model monitoring, drift detection, and model retraining strategies in live systems.

· Knowledge of econometrics or domain experience in retail, demand forecasting, or e-commerce analytics.

Behavioral Qualifications:

· Self-starter with a problem-solving mindset, comfort with ambiguity, and ability to adapt quickly in a fast-paced environment.

· Strong communication skills to translate complex technical findings into actionable insights for non-technical stakeholders.

· A collaborative approach with a bias for action, ownership mindset, and a passion for learning and innovation.

About Walmart Global Tech:

Imagine working in an environment where one line of code can make life easier for hundreds of millions of people. Thats what we do at Walmart Global Tech. Were a team of software engineers, data scientists, cybersecurity experts and service professionals within the world's leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.

Flexible, hybrid work:

We use a hybrid way of working that is primarily in office coupled with virtual when not onsite. Our campuses serve as a hub to enhance collaboration, bring us together for purpose and deliver on business needs. This approach helps us make quicker decisions, remove location barriers across our global team and be more flexible in our personal lives.

Benefits:

Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.

Equal Opportunity Statement:

Walmart, Inc. is an Equal Opportunity Employer By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting, and valuing unique styles, experiences, identities, ideas and opinions while being welcoming of all people.

The above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

‎

‎

‎
You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.

‎

For information about PTO, see https://one.walmart.com/notices.

‎

‎
Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

‎
Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

‎

For information about benefits and eligibility, see One.Walmart.

‎
The annual salary range for this position is $73,000.00-$127,000.00

‎
Additional compensation includes annual or quarterly performance bonuses.

‎
Additional compensation for certain positions may also include:

‎
- Regional Pay Zone (RPZ) (based on location)

‎
- Stock

‎

‎

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1- Bachelor’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3
years' experience in an analytics related field. Option 2- Master’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science,
Information Technology, or related field and 1 years' experience in an analytics related field. Option 3 - 5 years' experience in an analytics or
related field.

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data science, machine learning, optimization models, Master’s degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch)

Primary Location...

805 Se Moberly Ln, Bentonville, AR 72712, United States of America",2025-07-21T00:00:00.000Z,2025-07-25,"['Experience in training and deploying transformer-based neural networks (e.g., TFT, LSTM, GPT variants) for real-world business applications', 'Proficient in Python, SQL, and hands-on with PyTorch, TensorFlow/Keras, Scikit-learn, and stats models', 'Demonstrated ability to work on GPU-based model training pipelines, and exposure to managing experimentation at scale', 'Hands-on experience with distributed training, multi-GPU setups, or TPU-based workflows', 'Exposure to LLM fine-tuning, retrieval-augmented generation (RAG), NLP applications', 'Familiarity with ML model monitoring, drift detection, and model retraining strategies in live systems', 'Knowledge of econometrics or domain experience in retail, demand forecasting, or e-commerce analytics', 'Self-starter with a problem-solving mindset, comfort with ambiguity, and ability to adapt quickly in a fast-paced environment', 'Strong communication skills to translate complex technical findings into actionable insights for non-technical stakeholders', 'A collaborative approach with a bias for action, ownership mindset, and a passion for learning and innovation', 'That means understanding, respecting, and valuing unique styles, experiences, identities, ideas and opinions while being welcoming of all people', 'Option 1- Bachelor’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3', ""years' experience in an analytics related field"", 'Option 2- Master’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science,', ""Information Technology, or related field and 1 years' experience in an analytics related field"", ""Option 3 - 5 years' experience in an analytics or"", 'Data science, machine learning, optimization models, Master’s degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch)']","['Develop scalable time series forecasting systems leveraging global models like Temporal Fusion Transformers, N-BEATS, and PATCHTST, enabling robust forecasting across thousands of retails and e-commerce time series', 'Foundational Knowledge on advanced regression', 'Apply generative AI to synthesize time series data, enhance model training pipelines, and build intelligent NLP-based assistants for analytics enablement', 'Design and train large-scale neural networks for time series, anomaly detection, and causal inference, with deployment via automated batch pipelines using tools like Airflow or Astronomer', 'Build and maintain production-ready forecasting and LLM applications on cloud platforms (GCP or Azure), integrated with internal systems to deliver insights at scale', 'Perform Big Data processing and feature engineering using distributed compute platforms like Spark or Ray', 'Collaborate with cross-functional teams (product, engineering, business) to define objectives, formulate hypotheses, and deploy models that directly influence decision-making', 'Strong foundation in time series forecasting, deep learning, and optimization theory, with a focus on sequence modeling and attention-based architectures']",True,"['Generative AI', 'Large Language Models', 'Transformer Neural Networks', 'Retrieval-Augmented Generation', 'Prompt Engineering', 'Deep Learning Frameworks', 'Model Monitoring and Drift Detection']",Generative AI: Applying generative AI techniques to synthesize time series data and enhance model training pipelines.; Large Language Models: Building and maintaining production-ready LLM applications integrated with internal systems for analytics enablement.; Transformer Neural Networks: Training and deploying transformer-based neural networks such as Temporal Fusion Transformers and GPT variants for sequence modeling.; Retrieval-Augmented Generation: Utilizing RAG techniques to improve NLP-based assistants and enhance information retrieval in AI applications.; Prompt Engineering: Applying prompt engineering methods to optimize interactions with LLMs and NLP assistants.; Deep Learning Frameworks: Using PyTorch and TensorFlow/Keras specifically for training and deploying neural networks in AI applications.; Model Monitoring and Drift Detection: Implementing monitoring and drift detection strategies to maintain AI model performance in live systems.,"['Time Series Forecasting', 'Advanced Regression', 'Feature Engineering', 'Big Data Processing', 'Neural Networks for Time Series and Anomaly Detection', 'Machine Learning Frameworks', 'Python and SQL', 'Model Deployment Pipelines', 'Optimization Theory', 'Econometrics', 'Distributed Training']","Time Series Forecasting: Developing scalable forecasting systems using models like Temporal Fusion Transformers, N-BEATS, and PATCHTST to predict retail and e-commerce trends.; Advanced Regression: Applying foundational knowledge of regression techniques to support predictive modeling tasks.; Feature Engineering: Performing feature extraction and transformation on big data using distributed platforms like Spark and Ray to improve model performance.; Big Data Processing: Handling large-scale data processing tasks using distributed compute frameworks such as Spark and Ray.; Neural Networks for Time Series and Anomaly Detection: Designing and training large-scale neural networks for time series analysis, anomaly detection, and causal inference.; Machine Learning Frameworks: Utilizing frameworks like Scikit-learn and statsmodels for traditional machine learning and statistical modeling.; Python and SQL: Using Python and SQL for data manipulation, querying, and model development.; Model Deployment Pipelines: Deploying models via automated batch pipelines using orchestration tools like Airflow or Astronomer.; Optimization Theory: Applying optimization techniques to improve model training and forecasting accuracy.; Econometrics: Leveraging econometric methods and domain knowledge in retail and demand forecasting.; Distributed Training: Implementing distributed training strategies including multi-GPU and TPU workflows to scale model training."
bwefpvyZgb9Xr6OzAAAAAA==,"Principal, Data Scientist - People.AI","Position Summary...

What you'll do...

About Walmart

Walmart employs more than 2.3 million associates worldwide, with 1.6 million associates in the U.S. Each year, Walmart hires 500,000 applicants to fill thousands of job profiles from engineers, designers, and marketers to pilots and buyers. We promote over 300,000 people annually to positions of greater responsibility.

About People Technology Team

The Enterprise People Technology team supports the successful deployment and adoption of new People technology across the enterprise. As a Fortune #1 company, our work impacts millions of associates globally. We strive to continuously improve people technology and products to help managers and associates focus on what matters most - supporting our customers and members. People Technology is a significant segment of Walmart Global Tech’s Enterprise Business Services, invested in building a compact, robust organization that includes service operations and technology solutions for Finance, People, and the Associate Digital Experience.

About People.AI Team

The People.AI team is responsible for developing and deploying AI/ML solutions supporting the Walmart associates globally. In this role, you will build an LLM-powered intelligent experience within a chatbot or business application to enhance associate experience and productivity. You will design and build an intelligent conversational interface that improves communication, automates tasks, accesses data and insights, and provides personalized Q&A support to associates, ultimately creating a more efficient and engaging work environment.

What You'll Do
• Develop LLM-powered intelligent experiences that interpret and generate insights from both tabular and unstructured data.
• Build and optimize personalized Q&A systems using large language models, enabling context-aware responses tailored to user needs.
• Design and enhance conversational talent recommendation systems, combining autonomous agent architectures with personalized recommendation algorithms.
• Advance traditional recommendation systems by evolving them from simple ranked lists to multi-topic, interactive experiences that better reflect user intent.
• Construct multi-agent intelligent workflows that translate natural language inputs into complex, goal-directed task sequences.
• Collaborate within a highly cross-functional team, including data scientists, machine learning engineers, product managers, and UX designers.
• Partner with fellow data scientists to design, prototype, and iterate on AI/ML models and system architectures.
• Work closely with machine learning engineers to deploy, monitor, and optimize scalable AI/ML solutions in production environments.
• Collaborate with product managers to design intuitive user experiences, define feedback loops, and analyze user telemetry to guide product improvements.
• Engage in end-to-end AI/ML product development, from ideation to deployment, while continually expanding your technical and product skillset.
• Follow and help define robust development standards to ensure the creation of trustworthy, safe, and responsible AI systems.
• Contribute to internal and external AI/ML research through experimentation, whitepapers, and collaboration with the broader AI community.

What You'll Bring
• Proven experience deploying high-risk NLP applications in real-world, production environments—such as those involving regulatory compliance, privacy, safety, or fairness.
• Demonstrated ability to advance and implement Trustworthy AI and Responsible ML practices, working cross-functionally with engineering, legal, policy, and product stakeholders across a large enterprise.
• Track record of mentoring and coaching junior data scientists, especially in navigating ambiguous or novel problem spaces.
• Strong applied machine learning experience, with solid foundational knowledge in statistics, optimization, and deep learning—preferably gained at leading technology companies (e.g., Google, Meta, Microsoft) or AI-first startups.
• Excellent communication skills with the ability to synthesize complex technical work into accessible insights for executive briefings, research publications, and external presentations.
• Advanced proficiency in Python and common ML/DS libraries such as NumPy, pandas, scikit-learn, as well as deep learning frameworks like TensorFlow, PyTorch.
• Experience designing and deploying scalable deep learning systems, including neural network architecture optimization, model distillation, quantization, or on-device inference.
• Strong understanding of machine learning infrastructure, including experience with Kubeflow, MLflow, Airflow is a plus.
• 8+ years of industry experience, with a demonstrated ability to take ownership of complex projects and deliver impactful AI/ML solutions from concept to production.

Bonus Skills:
• Hands-on experience with Text-to-SQL or Text-to-Cypher based application, or the design of modern recommender systems.
• Experience developing or fine-tuning large language models (LLMs), including prompt engineering, retrieval-augmented generation (RAG), or open-weight model customization.
• Publication history in top-tier ML/NLP conferences such as NeurIPS, ICML, ACL, EMNLP, or ICLR

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

‎

‎

‎
You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.

‎

For information about PTO, see https://one.walmart.com/notices.

‎

‎
Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

‎
Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

‎

For information about benefits and eligibility, see One.Walmart.

‎
The annual salary range for this position is $110,000.00-$220,000.00

‎
Additional compensation includes annual or quarterly performance bonuses.

‎
Additional compensation for certain positions may also include:

‎

‎
- Stock

‎

‎

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 5 years' experience in an analytics related field. Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 3 years' experience in an analytics related field. Option 3: 7 years' experience in an analytics or related field

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data science, machine learning, optimization models, PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Publications or active peer reviewer in related journals or conference, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.

Primary Location...

2501 Se J St, Ste A, Bentonville, AR 72716-3724, United States of America",2025-07-20T00:00:00.000Z,2025-07-25,"['Proven experience deploying high-risk NLP applications in real-world, production environments—such as those involving regulatory compliance, privacy, safety, or fairness', 'Demonstrated ability to advance and implement Trustworthy AI and Responsible ML practices, working cross-functionally with engineering, legal, policy, and product stakeholders across a large enterprise', 'Track record of mentoring and coaching junior data scientists, especially in navigating ambiguous or novel problem spaces', 'Strong applied machine learning experience, with solid foundational knowledge in statistics, optimization, and deep learning—preferably gained at leading technology companies (e.g., Google, Meta, Microsoft) or AI-first startups', 'Excellent communication skills with the ability to synthesize complex technical work into accessible insights for executive briefings, research publications, and external presentations', 'Advanced proficiency in Python and common ML/DS libraries such as NumPy, pandas, scikit-learn, as well as deep learning frameworks like TensorFlow, PyTorch', 'Experience designing and deploying scalable deep learning systems, including neural network architecture optimization, model distillation, quantization, or on-device inference', '8+ years of industry experience, with a demonstrated ability to take ownership of complex projects and deliver impactful AI/ML solutions from concept to production', 'Hands-on experience with Text-to-SQL or Text-to-Cypher based application, or the design of modern recommender systems', 'Experience developing or fine-tuning large language models (LLMs), including prompt engineering, retrieval-augmented generation (RAG), or open-weight model customization', 'Publication history in top-tier ML/NLP conferences such as NeurIPS, ICML, ACL, EMNLP, or ICLR', ""Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 5 years' experience in an analytics related field"", ""Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 3 years' experience in an analytics related field"", ""Option 3: 7 years' experience in an analytics or related field"", 'Data science, machine learning, optimization models, PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Publications or active peer reviewer in related journals or conference, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly', 'The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture']","['In this role, you will build an LLM-powered intelligent experience within a chatbot or business application to enhance associate experience and productivity', 'You will design and build an intelligent conversational interface that improves communication, automates tasks, accesses data and insights, and provides personalized Q&A support to associates, ultimately creating a more efficient and engaging work environment', 'Develop LLM-powered intelligent experiences that interpret and generate insights from both tabular and unstructured data', 'Build and optimize personalized Q&A systems using large language models, enabling context-aware responses tailored to user needs', 'Design and enhance conversational talent recommendation systems, combining autonomous agent architectures with personalized recommendation algorithms', 'Advance traditional recommendation systems by evolving them from simple ranked lists to multi-topic, interactive experiences that better reflect user intent', 'Construct multi-agent intelligent workflows that translate natural language inputs into complex, goal-directed task sequences', 'Collaborate within a highly cross-functional team, including data scientists, machine learning engineers, product managers, and UX designers', 'Partner with fellow data scientists to design, prototype, and iterate on AI/ML models and system architectures', 'Work closely with machine learning engineers to deploy, monitor, and optimize scalable AI/ML solutions in production environments', 'Collaborate with product managers to design intuitive user experiences, define feedback loops, and analyze user telemetry to guide product improvements', 'Engage in end-to-end AI/ML product development, from ideation to deployment, while continually expanding your technical and product skillset', 'Follow and help define robust development standards to ensure the creation of trustworthy, safe, and responsible AI systems', 'Contribute to internal and external AI/ML research through experimentation, whitepapers, and collaboration with the broader AI community']",True,"['Large language models', 'Conversational AI', 'Autonomous agent architectures', 'Multi-agent systems', 'Prompt engineering', 'Retrieval-Augmented Generation', 'Open-weight model customization', 'TensorFlow', 'PyTorch', 'Trustworthy AI and Responsible ML', 'NLP applications']","Large language models: Core AI technology powering intelligent conversational interfaces and personalized Q&A systems.; Conversational AI: Design and development of chatbots and interfaces that understand and generate natural language.; Autonomous agent architectures: Used to build multi-agent intelligent workflows that translate natural language into complex tasks.; Multi-agent systems: Frameworks enabling multiple AI agents to collaborate on goal-directed workflows.; Prompt engineering: Technique for designing effective inputs to large language models to optimize output quality.; Retrieval-Augmented Generation: Method combining retrieval of relevant information with generative AI to improve response accuracy.; Open-weight model customization: Fine-tuning or adapting pre-trained large language models to specific business needs.; TensorFlow: Deep learning framework used for building and deploying neural network models in AI applications.; PyTorch: Deep learning framework favored for research and production of neural network-based AI models.; Trustworthy AI and Responsible ML: Practices ensuring AI systems are safe, fair, and compliant with regulatory and ethical standards.; NLP applications: Natural language processing solutions deployed in production environments with compliance considerations.","['Tabular and unstructured data', 'Personalized recommendation algorithms', 'Traditional recommendation systems', 'Optimization models', 'Statistics', 'Python', 'NumPy', 'Pandas', 'Scikit-learn', 'Spark', 'Scala', 'R', 'Machine learning', 'Deep learning', 'Neural network architecture optimization', 'Model distillation', 'Quantization', 'On-device inference', 'ML infrastructure', 'Kubeflow', 'MLflow', 'Airflow', 'Text-to-SQL and Text-to-Cypher applications', 'Recommender systems']","Tabular and unstructured data: Used as input data types for developing LLM-powered intelligent experiences and insights.; Personalized recommendation algorithms: Applied to enhance conversational talent recommendation systems by tailoring suggestions to user preferences.; Traditional recommendation systems: Evolved from simple ranked lists to multi-topic, interactive experiences reflecting user intent.; Optimization models: Utilized for improving machine learning and recommendation system performance.; Statistics: Foundational knowledge supporting applied machine learning and data science tasks.; Python: Primary programming language used for data science and machine learning development.; NumPy: Library for numerical computing and array operations in Python.; Pandas: Library for data manipulation and analysis, especially tabular data.; Scikit-learn: Open-source machine learning library used for traditional ML model development.; Spark: Big data processing framework used for scalable analytics.; Scala: Programming language often used with Apache Spark for data processing.; R: Statistical programming language used for analytics and data science.; Machine learning: Applied to build predictive models and AI/ML solutions from concept to production.; Deep learning: Used for designing and deploying scalable neural network systems.; Neural network architecture optimization: Techniques applied to improve deep learning model efficiency and performance.; Model distillation: Method to compress large models into smaller, efficient versions for deployment.; Quantization: Technique to reduce model size and improve inference speed, especially on-device.; On-device inference: Deploying models to run directly on user devices for low-latency predictions.; ML infrastructure: Systems and tools supporting deployment, monitoring, and optimization of ML models.; Kubeflow: Platform for deploying and managing machine learning workflows at scale.; MLflow: Tool for managing the ML lifecycle including experimentation, reproducibility, and deployment.; Airflow: Workflow orchestration tool used to schedule and monitor data pipelines and ML workflows.; Text-to-SQL and Text-to-Cypher applications: Natural language interfaces that translate user queries into database queries for analytics.; Recommender systems: Systems designed to provide personalized content or talent recommendations."
M_ZRUaefrohfGkDxAAAAAA==,"(USA) Senior Manager, Data Science","Position Summary...

What you'll do...

Senior Manager, Data Science – Last Mile Delivery

Elevator Pitch

Lead the strategy and execution for Walmart’s core Last Mile Delivery platform algorithm. Own algorithmic decisions that directly impact customer experience, driver performance, and Walmart’s cost structure. Apply LLMs, Gen AI, and advanced ML techniques to solve high-impact logistics challenges. Act as a thought leader in a high-visibility, independent role with direct senior leadership engagement.

Key Responsibilities

- Own and lead end-to-end strategy, design, and optimization of Last Mile Delivery platform algorithms.

-Serve as the primary thought leader for algorithmic decisions affecting Last Mile logistics.

- Drive alignment with cross-functional teams including engineering, product, and business leadership. - Integrate cutting-edge technologies such as LLMs, Gen AI, and advanced ML techniques to improve routing efficiency.

- Lead large-scale data analysis to identify opportunities for operational and business improvement.

- Present complex technical insights to senior leadership in a clear, business-relevant way.

- Ensure delivery of scalable, robust, and measurable solutions that impact key business outcomes.

- Mentor and guide junior data scientists and team members.

Why Join Us

- Direct ownership of a mission-critical algorithm with national-scale impact.

- Shape the future of Walmart’s Last Mile Delivery through innovation and leadership.

- High visibility role with recognition for driving strategic business results.

Ideal Candidate Profile

- 6–8+ years of experience in data science, machine learning, and logistics or routing optimization.

- Proven leadership experience managing projects or teams in a technical environment.

- Expertise in advanced ML techniques, optimization, and cloud platforms (e.g., GCP).

- Strong business acumen combined with exceptional communication and stakeholder management skills.

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

‎

‎

‎
You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.

‎

For information about PTO, see https://one.walmart.com/notices.

‎

‎
Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

‎
Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

‎

For information about benefits and eligibility, see One.Walmart.

‎
The annual salary range for this position is $110,000.00-$220,000.00

‎
Additional compensation includes annual or quarterly performance bonuses.

‎
Additional compensation for certain positions may also include:

‎

‎
- Stock

‎

‎

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 5 years' experience in an analytics related field. Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 3 years' experience in an analytics related field. Option 3: 7 years' experience in an analytics or related field.

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data science, machine learning, optimization models, PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Supervisory experience, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.

Primary Location...

702 Sw 8Th St, Bentonville, AR 72716, United States of America",2025-07-24T00:00:00.000Z,2025-07-25,"['6–8+ years of experience in data science, machine learning, and logistics or routing optimization', 'Proven leadership experience managing projects or teams in a technical environment', 'Expertise in advanced ML techniques, optimization, and cloud platforms (e.g., GCP)', 'Strong business acumen combined with exceptional communication and stakeholder management skills', ""Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 5 years' experience in an analytics related field"", ""Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 3 years' experience in an analytics related field"", ""Option 3: 7 years' experience in an analytics or related field"", 'Data science, machine learning, optimization models, PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Supervisory experience, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly', 'The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture']","['Lead the strategy and execution for Walmart’s core Last Mile Delivery platform algorithm', 'Own algorithmic decisions that directly impact customer experience, driver performance, and Walmart’s cost structure', 'Apply LLMs, Gen AI, and advanced ML techniques to solve high-impact logistics challenges', 'Act as a thought leader in a high-visibility, independent role with direct senior leadership engagement', 'Own and lead end-to-end strategy, design, and optimization of Last Mile Delivery platform algorithms', 'Serve as the primary thought leader for algorithmic decisions affecting Last Mile logistics', 'Drive alignment with cross-functional teams including engineering, product, and business leadership. - Integrate cutting-edge technologies such as LLMs, Gen AI, and advanced ML techniques to improve routing efficiency', 'Lead large-scale data analysis to identify opportunities for operational and business improvement', 'Present complex technical insights to senior leadership in a clear, business-relevant way', 'Ensure delivery of scalable, robust, and measurable solutions that impact key business outcomes', 'Mentor and guide junior data scientists and team members']",True,"['Large Language Models', 'Generative AI', 'TensorFlow', 'PyTorch']",Large Language Models: Applied to solve high-impact logistics challenges and improve routing efficiency within the Last Mile Delivery platform.; Generative AI: Integrated as a cutting-edge technology to enhance algorithmic decision-making and operational performance.; TensorFlow: Used as an open source deep learning framework for developing AI models related to the delivery platform.; PyTorch: Another deep learning framework employed for building neural network models in AI applications.,"['Advanced Machine Learning Techniques', 'Optimization Models', 'Large-Scale Data Analysis', 'Python', 'Spark', 'Scala', 'R', 'Scikit-learn', 'Cloud Platforms (GCP)']","Advanced Machine Learning Techniques: Used to develop and optimize algorithms for Walmart's Last Mile Delivery platform to improve routing efficiency and operational outcomes.; Optimization Models: Applied to enhance logistics and routing decisions impacting customer experience and cost structure.; Large-Scale Data Analysis: Conducted to identify opportunities for operational and business improvements within the delivery platform.; Python: One of the programming languages used for data science and machine learning tasks, as indicated by assessment requirements.; Spark: A big data processing framework used for handling large datasets relevant to logistics and delivery optimization.; Scala: Programming language often used with Spark for scalable data processing in analytics workflows.; R: Statistical programming language used for analytics and data science tasks.; Scikit-learn: Open source machine learning framework used for building and deploying ML models in the delivery platform.; Cloud Platforms (GCP): Cloud infrastructure used to deploy and scale machine learning and data science solutions."
WvC-xZO3_loct8pSAAAAAA==,"Senior Data Scientist, AWS Professional Services","Description

Are you looking to work at the forefront of Machine Learning (ML) and Artificial Intelligence (AI)? Would you be excited to apply AI algorithms to solve real world problems with significant impact? The Amazon Web Services Professional Services (ProServe) team is seeking a skilled Senior Data Scientist to help customers implement AI/ML solutions and realize transformational business opportunities.

This is a team of scientists, engineers, and architects working step-by-step with customers to build bespoke solutions that harness the power of AI. The team helps customers imagine and scope the use cases that will create the greatest value for their businesses, select and train and fine-tune the right models, define paths to navigate technical or business challenges, develop scalable solutions and applications, and launch them in production. The team provides guidance and implements best practices for applying AI responsibly and cost efficiently.

You will work directly with customers and innovate in a fast-paced organization that contributes to game-changing projects and technologies. You will design and run experiments, research new algorithms, and find new ways of optimizing risk, profitability, and customer experience.

We’re looking for Senior Data Scientists capable of using AI/ML and other techniques to design, evangelize, and implement state-of-the-art solutions for never-before-solved problems.

Key job responsibilities

As an experienced Senior Data Scientist, you will be responsible for:
• Lead end-to-end AI/ML and GenAI projects, from understanding business needs to data preparation, model development, solution deployment, and post-production monitoring
• Collaborate with AI/ML scientists, engineers, and architects to research, design, develop, and evaluate AI algorithms and build ML systems and operations (MLOps) using AWS services to address real-world challenges
• Interact with customers directly to understand the business challenges, deliver briefing and deep dive sessions to customers and guide them on adoption patterns and paths to production
• Create and deliver best practice recommendations, tutorials, blog posts, publications, sample code, and presentations tailored to technical, business, and executive stakeholders
• Provide customer and market feedback to product and engineering teams to help define product direction

This is a customer-facing role with potential travel to customer sites as needed.

About The Team

ABOUT AWS:

Diverse Experiences

Amazon values diverse experiences. Even if you do not meet all of the preferred qualifications and skills listed in the job description, we encourage candidates to apply. If your career is just starting, hasn’t followed a traditional path, or includes alternative experiences, don’t let it stop you from applying.

Why AWS

Amazon Web Services (AWS) is the world’s most comprehensive and broadly adopted cloud platform. We pioneered cloud computing and never stopped innovating — that’s why customers from the most successful startups to Global 500 companies trust our robust suite of products and services to power their businesses.

Work/Life Balance

We value work-life harmony. Achieving success at work should never come at the expense of sacrifices at home, which is why we strive for flexibility as part of our working culture. When we feel supported in the workplace and at home, there’s nothing we can’t achieve in the cloud.

Inclusive Team Culture

Here at AWS, it’s in our nature to learn and be curious. Our employee-led affinity groups foster a culture of inclusion that empower us to be proud of our differences. Ongoing events and learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences, inspire us to never stop embracing our uniqueness.

Mentorship and Career Growth

We’re continuously raising our performance bar as we strive to become Earth’s Best Employer. That’s why you’ll find endless knowledge-sharing, mentorship and other career-advancing resources here to help you develop into a better-rounded professional.

Basic Qualifications
• Master's degree in computer science, machine learning, robotics, operations research, statistics, mathematics or equivalent quantitative field with 5+ years of experience; or bachelor's degree with 8+ years of experience
• 5+ years of building machine learning models for business application experience
• 3+ years of hands-on experience with training, fine-tuning, evaluating, and deploying transformer models in production
• Experience with cloud services related to machine learning (e.g., Amazon SageMaker) and generative AI applications
• Experience with technical customer-facing engagements, and strong communication skills, with attention to detail and ability to convey rigorous technical concepts and considerations to non-experts

Preferred Qualifications
• PhD in computer science, machine learning, robotics, operations research, statistics, mathematics or equivalent quantitative field
• AWS experience preferred, with proficiency in a range of AWS services (e.g., SageMaker, Bedrock, EC2, ECS, EKS, OpenSearch, VPC) and professional certifications (e.g., Solutions Architect Professional)
• 2+ years of experience with design, deployment, and evaluation of AI agents and orchestration approaches; experience with open source frameworks like LangChain, LangGraph, LlamaIndex, and/ or similar tools
• 5+ years of deep learning, computer vision, human robotic interaction, algorithms implementation experience using PyTorch or TensorFlow
• Experience in launching AI applications in production on AWS
• Experience building ML pipelines with MLOps best practices, including: data preprocessing, distributed & GPU training, model deployment, monitoring, and retraining; experience with container and CI/CD pipelines

Amazon is an equal opportunity employer and does not discriminate on the basis of protected veteran status, disability, or other legally protected status.

Los Angeles County applicants: Job duties for this position include: work safely and cooperatively with other employees, supervisors, and staff; adhere to standards of excellence despite stressful conditions; communicate effectively and respectfully with employees, supervisors, and staff to ensure exceptional customer service; and follow all federal, state, and local laws and Company policies. Criminal history may have a direct, adverse, and negative relationship with some of the material job duties of this position. These include the duties and responsibilities listed above, as well as the abilities to adhere to company policies, exercise sound judgment, effectively manage stress and work safely and respectfully with others, exhibit trustworthiness and professionalism, and safeguard business operations and the Company’s reputation. Pursuant to the Los Angeles County Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $143,300/year in our lowest geographic market up to $247,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.

Company - Amazon Web Services, Inc.

Job ID: A2999972",2025-07-18T00:00:00.000Z,2025-07-25,"[""Master's degree in computer science, machine learning, robotics, operations research, statistics, mathematics or equivalent quantitative field with 5+ years of experience; or bachelor's degree with 8+ years of experience"", '5+ years of building machine learning models for business application experience', '3+ years of hands-on experience with training, fine-tuning, evaluating, and deploying transformer models in production', 'Experience with cloud services related to machine learning (e.g., Amazon SageMaker) and generative AI applications', 'Experience with technical customer-facing engagements, and strong communication skills, with attention to detail and ability to convey rigorous technical concepts and considerations to non-experts', 'These include the duties and responsibilities listed above, as well as the abilities to adhere to company policies, exercise sound judgment, effectively manage stress and work safely and respectfully with others, exhibit trustworthiness and professionalism, and safeguard business operations and the Company’s reputation']","['The team helps customers imagine and scope the use cases that will create the greatest value for their businesses, select and train and fine-tune the right models, define paths to navigate technical or business challenges, develop scalable solutions and applications, and launch them in production', 'You will work directly with customers and innovate in a fast-paced organization that contributes to game-changing projects and technologies', 'You will design and run experiments, research new algorithms, and find new ways of optimizing risk, profitability, and customer experience', 'We’re looking for Senior Data Scientists capable of using AI/ML and other techniques to design, evangelize, and implement state-of-the-art solutions for never-before-solved problems', 'Lead end-to-end AI/ML and GenAI projects, from understanding business needs to data preparation, model development, solution deployment, and post-production monitoring', 'Collaborate with AI/ML scientists, engineers, and architects to research, design, develop, and evaluate AI algorithms and build ML systems and operations (MLOps) using AWS services to address real-world challenges', 'Interact with customers directly to understand the business challenges, deliver briefing and deep dive sessions to customers and guide them on adoption patterns and paths to production', 'Create and deliver best practice recommendations, tutorials, blog posts, publications, sample code, and presentations tailored to technical, business, and executive stakeholders', 'Provide customer and market feedback to product and engineering teams to help define product direction', 'This is a customer-facing role with potential travel to customer sites as needed']",True,"['Generative AI', 'Large Language Models', 'AI Agents', 'Prompt Engineering', 'LangChain', 'LangGraph', 'LlamaIndex', 'AWS Bedrock', 'PyTorch', 'TensorFlow']","Generative AI: Led projects involving generative AI applications to create innovative AI-driven solutions.; Large Language Models: Trained, fine-tuned, and deployed transformer-based LLMs to address complex natural language tasks.; AI Agents: Designed and deployed AI agents and orchestration approaches for autonomous decision-making systems.; Prompt Engineering: Applied to optimize interactions with LLMs and generative AI models for improved performance.; LangChain: Utilized as an open-source framework to build AI agent orchestration and application workflows.; LangGraph: Used as a tool to support AI agent orchestration and complex AI workflows.; LlamaIndex: Employed to facilitate indexing and retrieval in AI applications involving large language models.; AWS Bedrock: Used as a managed service to build and scale generative AI applications on AWS.; PyTorch: Applied as a deep learning framework for developing neural network models in AI projects.; TensorFlow: Used as a deep learning framework for building and deploying AI models, especially neural networks.","['Machine Learning', 'Transformer Models', 'MLOps', 'AWS SageMaker', 'Deep Learning', 'Data Preparation', 'Model Evaluation', 'Model Deployment', 'AI Algorithms', 'Cloud Computing', 'CI/CD Pipelines', 'Containerization']","Machine Learning: Used to build predictive models and solve business problems through data-driven techniques.; Transformer Models: Trained, fine-tuned, evaluated, and deployed in production to handle complex sequence data tasks.; MLOps: Applied to build and manage machine learning pipelines including data preprocessing, training, deployment, monitoring, and retraining.; AWS SageMaker: Cloud service used for building, training, and deploying machine learning models at scale.; Deep Learning: Utilized for computer vision, robotics, and algorithm implementation using frameworks like PyTorch and TensorFlow.; Data Preparation: Involved in cleaning and transforming data to enable effective model training and deployment.; Model Evaluation: Conducted to assess the performance and accuracy of machine learning and AI models.; Model Deployment: Process of launching machine learning models into production environments for real-world use.; AI Algorithms: Researched, designed, and developed to optimize business outcomes such as risk and profitability.; Cloud Computing: Leveraged AWS cloud services to support scalable AI/ML solutions and infrastructure.; CI/CD Pipelines: Used to automate continuous integration and deployment of machine learning models and applications.; Containerization: Employed to package and deploy machine learning models and applications consistently across environments."
CBAdXkHc6Pv_MTV_AAAAAA==,"Data Scientist, Senior (Clearance Required) - Remote work local to DC Metro or FL","ICF International seeks an experienced Senior Data Scientist to support the research and development of new cyber analytic capabilities that will help the US protect and defend its networks and critical information systems. The successful cleared candidate will act as a Senior Data Scientist to support a large federal cyber security analytic program. Your work will contribute to the knowledge of how cyber-attacks work, how vulnerabilities are exploited, and the way hostile cyber actors operate. Utilize your skills to help experiment and prototype future cyber capabilities for implementation at large scale.

As the Senior Data Scientist, your exceptional skillset will create useful and actionable insight for the customer through the development of machine learning, deep learning models, and related algorithms. The ideal candidate is strong mathematically; can automate scoring using machine learning techniques, build recommendation systems, and select the correct data points for analysis from large data sets. You are focused on results, a self-starter, and have demonstrated success for using analytics to drive the understanding, growth, and success of the analysis. This is an opportunity to contribute to an important project from the beginning, work with the latest and emerging technologies, and all while building a great career at ICF!

This role is primarily telework-based with occasional meetings at client locations (Arlington, VA or Pensacola, FL) or ICF facilities within the National Capital Region (Washington, DC Metro Area).

What You Will Be Doing:
• Perform knowledge elicitation from customer subject matter experts and convert that to derived algorithms
• Analyze large data sets to identify actionable insights with mathematical statistical rigor
• Rigorously critique and correct intermediate results to improve the algorithmic outcomes
• Design and deploy deep learning algorithms and predictive models
• Develop custom data models and algorithms to apply to data sets
• Assess the effectiveness and accuracy of new data sources and data gathering techniques
• Develop processes and tools to monitor and analyze model performance and data accuracy
• Interpret and communicate results to non-technical customers

What You Must Have:
• Bachelor's degree with 12+ or Master's degree with 10+ years of experience in Computer Science, Statistics, Applied Mathematics, Computational Linguistics, Artificial Intelligence or related field
• 10 or more years of practical working experience in one or more of the following areas: Natural Language Processing, Machine Learning Models, Question Answering, Text Mining, Information Retrieval, Distributional Semantics, Data Science, Knowledge Engineering
• Strong experience using a variety of mathematical, statistical, data mining, and data analysis methods/tools
• Active high-level security clearance required as part of client contract requirement
• US Citizenship required as part of client contract requirements

Preferred Skills/Experience:
• Experience in Computer Science, Statistics, Applied Mathematics, Computational Linguistics, Artificial Intelligence or related field
• Interpersonal skills and the ability to communicate effectively with various clients in order to explain and elaborate on technical details
• Experience in productization of machine learning algorithms and the ability to deliver data science components that are part of successful deliverables
• Working knowledge of general machine learning algorithms and NLP, Graph Theory, and Network Analysis
• Fluency in one or more programming languages (e.g., Python, JavaScript, R, etc.)
• Experience with statistical data analysis, experimental design, and hypotheses validation
• Experience with database querying like SQL
• Readiness to collaborate with engineering teams, product teams, and customers to develop prototypes and software products
• Scaled Agile Framework (SAFe) experience
• CompTIA Security+ or higher certification level preferred

Working at ICF
ICF is a global advisory and technology services provider, but we're not your typical consultants. We combine unmatched expertise with cutting-edge technology to help clients solve their most complex challenges, navigate change, and shape the future.

We can only solve the world's toughest challenges by building a workplace that allows everyone to thrive. We are an equal opportunity employer. Together, our employees are empowered to share their expertise and collaborate with others to achieve personal and professional goals. For more information, please read our EEO policy.

Reasonable Accommodations are available, including, but not limited to, for disabled veterans, individuals with disabilities, and individuals with sincerely held religious beliefs, in all phases of the application and employment process. To request an accommodation, please email Candidateaccommodation@icf.com and we will be happy to assist. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

Read more about workplace discrimination rights or our benefit offerings which are included in the Transparency in (Benefits) Coverage Act.

Candidate AI Usage Policy

At ICF, we are committed to ensuring a fair interview process for all candidates based on their own skills and knowledge. As part of this commitment, the use of artificial intelligence (AI) tools to generate or assist with responses during interviews (whether in-person or virtual) is not permitted. This policy is in place to maintain the integrity and authenticity of the interview process.

However, we understand that some candidates may require accommodation that involves the use of AI. If such an accommodation is needed, candidates are instructed to contact us in advance at candidateaccommodation@icf.com. We are dedicated to providing the necessary support to ensure that all candidates have an equal opportunity to succeed.

Pay Range - There are multiple factors that are considered in determining final pay for a position, including, but not limited to, relevant work experience, skills, certifications and competencies that align to the specified role, geographic location, education and certifications as well as contract provisions regarding labor categories that are specific to the position.

The pay range for this position based on full-time employment is:
$118,730.00 - $201,840.00

Virginia Remote Office (VA99)",,2025-07-25,"[""Bachelor's degree with 12+ or Master's degree with 10+ years of experience in Computer Science, Statistics, Applied Mathematics, Computational Linguistics, Artificial Intelligence or related field"", '10 or more years of practical working experience in one or more of the following areas: Natural Language Processing, Machine Learning Models, Question Answering, Text Mining, Information Retrieval, Distributional Semantics, Data Science, Knowledge Engineering', 'Strong experience using a variety of mathematical, statistical, data mining, and data analysis methods/tools', 'Active high-level security clearance required as part of client contract requirement', 'US Citizenship required as part of client contract requirements']","['The successful cleared candidate will act as a Senior Data Scientist to support a large federal cyber security analytic program', 'Your work will contribute to the knowledge of how cyber-attacks work, how vulnerabilities are exploited, and the way hostile cyber actors operate', 'Utilize your skills to help experiment and prototype future cyber capabilities for implementation at large scale', 'As the Senior Data Scientist, your exceptional skillset will create useful and actionable insight for the customer through the development of machine learning, deep learning models, and related algorithms', 'The ideal candidate is strong mathematically; can automate scoring using machine learning techniques, build recommendation systems, and select the correct data points for analysis from large data sets', 'You are focused on results, a self-starter, and have demonstrated success for using analytics to drive the understanding, growth, and success of the analysis', 'This role is primarily telework-based with occasional meetings at client locations (Arlington, VA or Pensacola, FL) or ICF facilities within the National Capital Region (Washington, DC Metro Area)', 'Perform knowledge elicitation from customer subject matter experts and convert that to derived algorithms', 'Analyze large data sets to identify actionable insights with mathematical statistical rigor', 'Rigorously critique and correct intermediate results to improve the algorithmic outcomes', 'Design and deploy deep learning algorithms and predictive models', 'Develop custom data models and algorithms to apply to data sets', 'Assess the effectiveness and accuracy of new data sources and data gathering techniques', 'Develop processes and tools to monitor and analyze model performance and data accuracy', 'Interpret and communicate results to non-technical customers']",True,[],,"['Machine Learning', 'Deep Learning', 'Natural Language Processing', 'Statistical Data Analysis', 'Predictive Modeling', 'Data Mining', 'Feature Engineering', 'SQL', 'Experimental Design', 'Graph Theory and Network Analysis', 'Programming Languages']","Machine Learning: Used to automate scoring, build recommendation systems, and analyze large datasets for actionable insights in cybersecurity analytics.; Deep Learning: Applied to design and deploy advanced algorithms and predictive models for cyber analytic capabilities.; Natural Language Processing: Utilized for text mining, question answering, and information retrieval to understand cyber threats and hostile actor behaviors.; Statistical Data Analysis: Employed to rigorously analyze data with mathematical and statistical rigor to improve algorithmic outcomes.; Predictive Modeling: Developed custom models to forecast cyber-attack patterns and vulnerabilities.; Data Mining: Used to extract meaningful patterns and insights from large cybersecurity datasets.; Feature Engineering: Selecting and preparing relevant data points from large datasets for analysis and model building.; SQL: Used for querying databases to gather and assess data sources relevant to cybersecurity analytics.; Experimental Design: Applied to validate hypotheses and assess the effectiveness of new data sources and algorithms.; Graph Theory and Network Analysis: Used to analyze relationships and structures within cyber networks and threat actor behaviors.; Programming Languages: Fluency in Python, JavaScript, and R supports development and prototyping of data science components."
-NpPrxS4_eufwQxnAAAAAA==,"Data Scientist, Senior","Job Number: R0221171

Data Scientist, Senior

The Opportunity:

As a data scientist, you’re excited at the prospect of unlocking the secrets held by a data set, and you’re fascinated by the possibilities presented by IoT, machine learning, and artificial intelligence. In an increasingly connected world, massive amounts of structured and unstructured data open new opportunities. As a data scientist at Booz Allen, you can help turn these complex data sets into useful information to solve global challenges. Across private and public sectors—from fraud detection to cancer research to national intelligence—we need you to help find the answers in the data.

On our team, you’ll use your leadership skills and data science expertise to create real-world impact. You’ll work closely with clients to understand their questions and needs, and then dig into their data-rich environments to find the pieces of their information puzzle. You’ll guide teammates and lead the development of algorithms and systems. You’ll use the right combination of tools and frameworks to turn sets of disparate data points into objective answers to advise your clients as they make informed decisions. Ultimately, you’ll provide a deep understanding of the data, what it all means, and how it can be used.

Work with us as we use data science for good.

Join us. The world can’t wait.

You Have:  
• 5+ years of experience in applied data science or ML roles, including using Python and NLP and LLM implementation
• 5+ years of experience with data exploration, data cleaning, data analysis, data visualization, or data mining
• Experience with production-level systems, data lake environments, and streaming data, including Kafka
• Experience implementing end-to-end ML workflows from data prep to deployment and evaluation
• Ability to quickly learn infrastructure or systems concepts, including how pipelines interface with data lakes
• Ability to design, implement, and iterate on ML models for document classification, extraction, summarization, and search
• Ability to take ownership of data science workflows that interact with a production system streaming millions of documents per week
• TS/SCI clearance
• Bachelor's degree

Nice If You Have:  
• Experience in collaborating with MLOps and infrastructure engineers to ensure robust model deployment, monitoring, and retraining pipelines
• Experience supporting platform components such as documents indexing or search, GPU workloads, and distributed storage, including Cloudera
• Experience in the development of algorithms leveraging R, Python, SQL, or NoSQL
• Experience with Distributed data or computing tools, including MapReduce, Hadoop, Hive, EMR, Spark, Gurobi, or MySQL 
• Experience with visualization packages, including Plotly, Seaborn, or ggplot2

Clearance: 

Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance is required. 

Compensation

At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.

Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $99,000.00 to $225,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees. This posting will close within 90 days from the Posting Date.

Identity Statement

As part of the application process, you are expected to be on camera during interviews and assessments. We reserve the right to take your picture to verify your identity and prevent fraud.

Work Model

Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.
• If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility.
• If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role.

Commitment to Non-Discrimination

All qualified applicants will receive consideration for employment without regard to disability, status as a protected veteran or any other status protected by applicable federal, state, local, or international law.",2025-07-08T00:00:00.000Z,2025-07-25,"['5+ years of experience in applied data science or ML roles, including using Python and NLP and LLM implementation', '5+ years of experience with data exploration, data cleaning, data analysis, data visualization, or data mining', 'Experience with production-level systems, data lake environments, and streaming data, including Kafka', 'Experience implementing end-to-end ML workflows from data prep to deployment and evaluation', 'Ability to quickly learn infrastructure or systems concepts, including how pipelines interface with data lakes', 'Ability to design, implement, and iterate on ML models for document classification, extraction, summarization, and search', 'Ability to take ownership of data science workflows that interact with a production system streaming millions of documents per week', 'TS/SCI clearance', ""Bachelor's degree"", 'Experience in collaborating with MLOps and infrastructure engineers to ensure robust model deployment, monitoring, and retraining pipelines', 'Experience supporting platform components such as documents indexing or search, GPU workloads, and distributed storage, including Cloudera', 'Experience in the development of algorithms leveraging R, Python, SQL, or NoSQL', 'Experience with Distributed data or computing tools, including MapReduce, Hadoop, Hive, EMR, Spark, Gurobi, or MySQL\u202f', 'Experience with visualization packages, including Plotly, Seaborn, or ggplot2']","['On our team, you’ll use your leadership skills and data science expertise to create real-world impact', 'You’ll work closely with clients to understand their questions and needs, and then dig into their data-rich environments to find the pieces of their information puzzle', 'You’ll guide teammates and lead the development of algorithms and systems', 'You’ll use the right combination of tools and frameworks to turn sets of disparate data points into objective answers to advise your clients as they make informed decisions', 'Ultimately, you’ll provide a deep understanding of the data, what it all means, and how it can be used', 'If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility', 'If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role']",True,['Large Language Models'],"Large Language Models: Implemented and applied LLMs for NLP tasks such as document classification, extraction, summarization, and search.","['Python', 'Natural Language Processing', 'Machine Learning', 'Data Exploration', 'Data Cleaning', 'Data Analysis', 'Data Visualization', 'Data Mining', 'Data Lakes', 'Streaming Data', 'Kafka', 'MLOps', 'R', 'SQL', 'NoSQL', 'Distributed Computing', 'Gurobi', 'MySQL', 'Data Visualization Packages', 'Cloudera']","Python: Used as a primary programming language for data exploration, cleaning, analysis, and implementing machine learning workflows.; Natural Language Processing: Applied for document classification, extraction, summarization, and search tasks within data science workflows.; Machine Learning: Involved in designing, implementing, and iterating on models for various data-driven tasks and end-to-end ML workflows.; Data Exploration: Performed to understand and analyze data sets before modeling or visualization.; Data Cleaning: Essential step to prepare raw data for analysis and modeling.; Data Analysis: Used to extract insights and inform decision-making from complex data sets.; Data Visualization: Utilized visualization packages like Plotly, Seaborn, and ggplot2 to communicate data insights effectively.; Data Mining: Applied to discover patterns and relationships in large data sets.; Data Lakes: Used as storage environments for large volumes of structured and unstructured data, interfaced by data pipelines.; Streaming Data: Handled real-time data streams, including millions of documents per week, often using Kafka.; Kafka: Employed as a streaming platform to manage real-time data ingestion and processing.; MLOps: Collaborated with engineers to ensure robust deployment, monitoring, and retraining of machine learning models.; R: Used for algorithm development and statistical analysis.; SQL: Applied for querying and managing relational databases.; NoSQL: Used for handling non-relational data storage and retrieval.; Distributed Computing: Utilized tools like MapReduce, Hadoop, Hive, EMR, and Spark to process large-scale data efficiently.; Gurobi: Applied as an optimization solver in algorithm development.; MySQL: Used as a relational database management system for data storage and querying.; Data Visualization Packages: Tools such as Plotly, Seaborn, and ggplot2 used to create visual representations of data insights.; Cloudera: Supported distributed storage and data platform components for managing large data sets."
GZLlvlCrp8E8rvQKAAAAAA==,Senior Data Scientist,"Position Summary:

As a Senior Data Scientist, you will drive the development and implementation of Machine Learning and Artificial intelligent techniques for Penske next-generation Supply Chain & Logistics products. With a robust background in data science and industry experience with machine learning, coding, and distributed computing systems such as PySpark, your role will be instrumental in establishing and advancing Penske's predictive analytics capabilities, particularly at the enterprise level.

In addition to your hands-on contributions, you will serve as a mentor to less experienced data scientists, guiding them towards professional growth and instilling a culture of best practices within the team. As a Senior Data Scientist, you will simultaneously navigate multiple projects, each of significant scale and complexity, with potential organization-wide impact. You will be expected to provide detailed analysis, formulate project approaches, and define their scope. Success in this role involves extensive cross-functional collaboration with customers, vendors, and suppliers.

Major Responsibilities:

Strategic Opportunities and Process Improvement:

• Collaborate closely with diverse stakeholders to identify and define complex business problems

• Conduct comprehensive ROI analysis to establish the feasibility of potential projects

• Contribute to building business cases for significant, enterprise-wide analytics initiatives

Data Evaluation and Analysis:

• Identify appropriate data sources to answer intricate business questions

• Extract, blend, cleanse, and organize data, leveraging automated ETL processes

• Visualize data to facilitate understanding and decision-making

• Identify and address outliers, missing or incomplete records in the data

Model Building and Implementation:

• Identify appropriate techniques and algorithms for model construction

• Develop, test, and fine-tune machine learning models

• Construct applications and embed models for enterprise-level use

Communication and Leadership:

• Actively engage in best practices discussions with team members regarding modeling activities

• Provide regular updates on project activities and results with the team

• Participate in and lead discussions about Penske's data-driven vision and strategy

• Act as a mentor for junior data scientists, fostering their growth and development

Exploring New Technologies and Industry Trends:

• Stay abreast of business trends in the logistics industry

• Evaluate new technologies and assess their potential application to our business

Qualifications for External Candidates

Qualifications:

• 6+ years of experience along with a master’s degree in Engineering, Operations Research, Statistics, Applied Math, Computer Science, or related quantitative field required

• 4+ years of experience along with a PhD in Engineering, Operations Research, Statistics, Applied Math, Computer Science, or related quantitative field preferred.

• Minimum of 4 years of experience designing and building machine learning applications using both structured and unstructured datasets.

• Demonstrated proficiency in Python, or other high-level scripting languages, with practical experience in programming.

• Extensive experience in distributed computing frameworks, such as PySpark, is required

• Proven expertise in the application of advanced Machine Learning and Deep Learning techniques in a business environment is a must.

• Solid experience with SQL.

• Ability to manage multiple complex projects simultaneously

• Experience translating complex data insights into strategic recommendations for non-technical stakeholders.

• Strong oral and written communication skills

• Strong ability to collaborate with different functional teams and stakeholders with both tech and non-tech backgrounds.

• Demonstrated ability to mentor and guide junior team members.

• Familiarity with model deployment, MLOps practices as well as exposure to containerization technologies (like Docker) and orchestration systems (like Kubernetes), will be considered a significant asset, although not strictly required.

Physical Requirements: • The physical and mental demands described here are representative of those that must be met by an associate to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. • The associate will be required to: read; communicate verbally and/or in written form; remember and analyze certain information; and remember and understand certain instructions or guidelines. • While performing the duties of this job, the associate may be required to stand, walk, and sit. The associate is frequently required to use hands to touch, handle, and feel, and to reach with hands and arms. The associate must be able to occasionally lift and/or move up to 25lbs/12kg. • Specific vision abilities required by this job include close vision, distance vision, peripheral vision, depth perception and the ability to adjust focus.

Penske is an Equal Opportunity Employer.

About Penske Logistics Penske Logistics is a wholly owned subsidiary of Penske Truck Leasing. With operations in North America, South America, Europe and Asia, Penske Logistics provides supply chain management and logistics services to leading companies around the world. Penske Logistics delivers value through its design, planning and execution in transportation, warehousing and freight management. Visit www.PenskeLogistics.com to learn more.

About Penske Truck Leasing/Transportation Solutions

Penske Truck Leasing/Transportation Solutions is a premier global transportation provider that delivers essential and innovative transportation, logistics and technology services to help companies and people move forward. With headquarters in Reading, PA, Penske and its associates are driven by a dedication to excellence and a commitment to customer success. Visit Go Penske to learn more.

Job Category: Information Technology

Job Family: Common

Address: 100 Gundy Drive

Primary Location: US-PA-Reading

Employer: Penske Truck Leasing Co., L.P.

Req ID: 2406093",2025-07-23T00:00:00.000Z,2025-07-25,"['6+ years of experience along with a master’s degree in Engineering, Operations Research, Statistics, Applied Math, Computer Science, or related quantitative field required', 'Minimum of 4 years of experience designing and building machine learning applications using both structured and unstructured datasets', 'Demonstrated proficiency in Python, or other high-level scripting languages, with practical experience in programming', 'Extensive experience in distributed computing frameworks, such as PySpark, is required', 'Proven expertise in the application of advanced Machine Learning and Deep Learning techniques in a business environment is a must', 'Solid experience with SQL', 'Ability to manage multiple complex projects simultaneously', 'Experience translating complex data insights into strategic recommendations for non-technical stakeholders', 'Strong oral and written communication skills', 'Strong ability to collaborate with different functional teams and stakeholders with both tech and non-tech backgrounds', 'Demonstrated ability to mentor and guide junior team members', 'Familiarity with model deployment, MLOps practices as well as exposure to containerization technologies (like Docker) and orchestration systems (like Kubernetes), will be considered a significant asset, although not strictly required', 'The physical and mental demands described here are representative of those that must be met by an associate to successfully perform the essential functions of this job', 'The associate will be required to: read; communicate verbally and/or in written form; remember and analyze certain information; and remember and understand certain instructions or guidelines', 'While performing the duties of this job, the associate may be required to stand, walk, and sit', 'The associate is frequently required to use hands to touch, handle, and feel, and to reach with hands and arms', 'The associate must be able to occasionally lift and/or move up to 25lbs/12kg', 'Specific vision abilities required by this job include close vision, distance vision, peripheral vision, depth perception and the ability to adjust focus']","['As a Senior Data Scientist, you will drive the development and implementation of Machine Learning and Artificial intelligent techniques for Penske next-generation Supply Chain & Logistics products', ""With a robust background in data science and industry experience with machine learning, coding, and distributed computing systems such as PySpark, your role will be instrumental in establishing and advancing Penske's predictive analytics capabilities, particularly at the enterprise level"", 'In addition to your hands-on contributions, you will serve as a mentor to less experienced data scientists, guiding them towards professional growth and instilling a culture of best practices within the team', 'As a Senior Data Scientist, you will simultaneously navigate multiple projects, each of significant scale and complexity, with potential organization-wide impact', 'You will be expected to provide detailed analysis, formulate project approaches, and define their scope', 'Success in this role involves extensive cross-functional collaboration with customers, vendors, and suppliers', 'Collaborate closely with diverse stakeholders to identify and define complex business problems', 'Conduct comprehensive ROI analysis to establish the feasibility of potential projects', 'Contribute to building business cases for significant, enterprise-wide analytics initiatives', 'Identify appropriate data sources to answer intricate business questions', 'Extract, blend, cleanse, and organize data, leveraging automated ETL processes', 'Visualize data to facilitate understanding and decision-making', 'Identify and address outliers, missing or incomplete records in the data', 'Model Building and Implementation:', 'Identify appropriate techniques and algorithms for model construction', 'Develop, test, and fine-tune machine learning models', 'Construct applications and embed models for enterprise-level use', 'Actively engage in best practices discussions with team members regarding modeling activities', 'Provide regular updates on project activities and results with the team', ""Participate in and lead discussions about Penske's data-driven vision and strategy"", 'Act as a mentor for junior data scientists, fostering their growth and development', 'Stay abreast of business trends in the logistics industry', 'Evaluate new technologies and assess their potential application to our business', 'Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions']",True,[],,"['Machine Learning', 'Deep Learning', 'PySpark', 'Python', 'SQL', 'ETL Processes', 'Data Visualization', 'Model Deployment', 'MLOps', 'Containerization', 'Orchestration Systems', 'Data Cleansing', 'ROI Analysis']","Machine Learning: Used for developing predictive analytics models and applications to solve complex business problems in supply chain and logistics.; Deep Learning: Applied as an advanced technique within machine learning to enhance model performance in business environments.; PySpark: Utilized as a distributed computing framework to process large-scale data efficiently for analytics and model building.; Python: Primary programming language used for coding, data manipulation, and building machine learning models.; SQL: Used for querying and managing structured data from databases to support data extraction and analysis.; ETL Processes: Automated extraction, transformation, and loading of data to prepare datasets for analysis and modeling.; Data Visualization: Employed to facilitate understanding and decision-making by representing data insights graphically.; Model Deployment: Embedding and operationalizing machine learning models for enterprise-level use within applications.; MLOps: Practices related to managing the lifecycle of machine learning models including deployment and monitoring.; Containerization: Use of technologies like Docker to package and deploy machine learning models and applications consistently.; Orchestration Systems: Use of systems like Kubernetes to manage containerized applications and ensure scalability and reliability.; Data Cleansing: Processes to identify and address outliers, missing, or incomplete records to improve data quality for modeling.; ROI Analysis: Conducted to evaluate the feasibility and potential business impact of analytics projects."
mJTOv-IE2zQAxuBZAAAAAA==,Senior Data Scientist,"About the Team
Fanatics is one of the world’s most transformative companies, which over the past decade has implemented a revolutionary vertical commerce model, cutting-edge tech platform and agile supply chain to morph from a North American e-commerce vendor into a new breed of mobile-first consumer brand: part tech company, part on-demand manufacturer and part logistics expert. Fanatics’ commerce division is the world’s largest manufacturer and provider of licensed sports merchandise, and the same innovation and differentiation the company applied to the antiquated licensed apparel industry is now being optimized across the entire sports ecosystem, including physical and digital trading cards and collectibles and online sports betting and iGaming. With more choices at the fingertips of consumers than ever before, Fanatics is building the leading global digital sports platform to create interactive, lasting fan experiences which also helps partners establish better direct-to-consumer relationships in today’s highly competitive world.

Fanatics Collectibles has the combined vision and distinct strengths of both Fanatics and Topps that will improve the collector experience while maintaining vital parts of the hobby. Fanatics’ data-driven, direct-to-consumer expertise, which includes a database of more than 80 million sports fans globally, will enhance and expand Topps’ existing digital capabilities and grow the market opportunity for all participants. In addition, Topps’ world-class quality, product development, and manufacturing capabilities, along with their commitment to collectors and hobby shops, will ensure products are more readily accessible, positively impacting current and future collectors and partners.

The Role
We are looking for senior-level Data Scientists to join our Data Engineering, Science, and Analytics team. Do you thrive at applying data science to solve business problems? As a data scientist, you will have ample opportunities to apply your data science skillset to unlock vast business opportunities by extracting key insights using a wide range of data sources, advanced statistical models, and machine learning algorithms and translating results into meaningful, goal-oriented business actions. Each day, you will be presented with a variety of new challenges and interesting projects that tap your interests and strengths.

Responsibilities:

Collaborate with cross-functional partners in operations, finance, marketing, and engineering to understand business need and scope data science projects.
Wrangle, process, cleanse, verify, and enrich data from different sources used for analysis.
Help build data-informed business strategy and roadmaps.
Translate business needs into data product requirements, evaluate technologies, and identify opportunities to innovate and improve our data science capabilities.
Use creative problem-solving skills to analyze data and build statistical / machine learning models to help solve business problems from different perspectives.
Work closely with data engineers to create services that can ingest and supply data to and from both internal and external sources and ensure data quality and timeliness.
Lead the development of data visualization and dashboards to help the organization monitor performance, generate insights, and continuously improve user experience.
Establish playbooks to drive process and consistent outcomes.
Participating in the full life cycle of model development, which spans from business problem discovery, data discovery to model deployment and monitoring.

Qualifications:

Master’s or Doctoral degree in Computer Science (with a focus on Data Mining, Machine Learning), Statistics, Econometrics, Physics, or other rigorous quantitative disciplines that require processing and modeling data at a complex and large scale.
4+ years of professional experience as a data scientist.
Proficient in Python, SQL, Spark, the associated Python and Spark packages commonly used by data scientists, and Deep Learning libraries, such as PyTorch.
Proficient in wrangle and analyze data with complex relationships and time scale.
Strong understanding of and practical experience in a wide range of machine learning algorithms and statistical modeling.
Experience in using data visualization and dashboard tools.
Experience and knowledge with computer vision domain, library such as OpenCV, PIL, and modern CV architectures (CNNs, Vision Transformers, Image Gen AI etc.)
Experience in software development, system design and deployment is preferred.
Working experience in cloud-native technology.
Experience working with large structured and unstructured datasets stored in relational and NOSQL databases.
Out-of-the-box thinker and problem solver who can turn ambiguous business problems into clear data-driven solutions that deliver meaningful business impacts.
Excellent organizational skills, verbal and written communication skills, and presentation skills.

Some things you may want to know about us:

We’re a small team (growing fast!) and everyone wears lots of hats.
We’re have offices in Los Angeles and New York, and many of us are remote.
We work hard, but not all the time. We have families that we like to spend time with.

The salary range for this position is $200,000- $240,000 which represents base pay only and does not include short-term or long-term incentive compensation. When determining base pay, as part of a final compensation package, we consider several factors such as location, experience, qualifications, and training.

Ensure your Fanatics job offer is legitimate and don’t fall victim to fraud. Fanatics never seeks payment from job applicants. Feel free to ask your recruiter for a phone call or other type of communication for interview, and ensure your communication is coming from a Fanatics email address (including @collectfanatics.com). For added security, where possible, apply through our company website at www.fanaticsinc.com/careers

Fanatics is building a leading global digital sports platform. We ignite the passions of global sports fans and maximize the presence and reach for our hundreds of sports partners globally by offering products and services across Fanatics Commerce, Fanatics Collectibles, and Fanatics Betting & Gaming, allowing sports fans to Buy, Collect, and Bet. Through the Fanatics platform, sports fans can buy licensed fan gear, jerseys, lifestyle and streetwear products, headwear, and hardgoods; collect physical and digital trading cards, sports memorabilia, and other digital assets; and bet as the company builds its Sportsbook and iGaming platform. Fanatics has an established database of over 100 million global sports fans; a global partner network with approximately 900 sports properties, including major national and international professional sports leagues, players associations, teams, colleges, college conferences and retail partners, 2,500 athletes and celebrities, and 200 exclusive athletes; and over 2,000 retail locations, including its Lids retail stores. Our more than 22,000 employees are committed to relentlessly enhancing the fan experience and delighting sports fans globally.",2025-07-18T00:00:00.000Z,2025-07-25,"['Do you thrive at applying data science to solve business problems?', 'As a data scientist, you will have ample opportunities to apply your data science skillset to unlock vast business opportunities by extracting key insights using a wide range of data sources, advanced statistical models, and machine learning algorithms and translating results into meaningful, goal-oriented business actions', 'Master’s or Doctoral degree in Computer Science (with a focus on Data Mining, Machine Learning), Statistics, Econometrics, Physics, or other rigorous quantitative disciplines that require processing and modeling data at a complex and large scale', '4+ years of professional experience as a data scientist', 'Proficient in Python, SQL, Spark, the associated Python and Spark packages commonly used by data scientists, and Deep Learning libraries, such as PyTorch', 'Proficient in wrangle and analyze data with complex relationships and time scale', 'Strong understanding of and practical experience in a wide range of machine learning algorithms and statistical modeling', 'Experience in using data visualization and dashboard tools', 'Experience and knowledge with computer vision domain, library such as OpenCV, PIL, and modern CV architectures (CNNs, Vision Transformers, Image Gen AI etc.)', 'Working experience in cloud-native technology', 'Experience working with large structured and unstructured datasets stored in relational and NOSQL databases', 'Out-of-the-box thinker and problem solver who can turn ambiguous business problems into clear data-driven solutions that deliver meaningful business impacts', 'Excellent organizational skills, verbal and written communication skills, and presentation skills']","['Collaborate with cross-functional partners in operations, finance, marketing, and engineering to understand business need and scope data science projects', 'Wrangle, process, cleanse, verify, and enrich data from different sources used for analysis', 'Help build data-informed business strategy and roadmaps', 'Translate business needs into data product requirements, evaluate technologies, and identify opportunities to innovate and improve our data science capabilities', 'Use creative problem-solving skills to analyze data and build statistical / machine learning models to help solve business problems from different perspectives', 'Work closely with data engineers to create services that can ingest and supply data to and from both internal and external sources and ensure data quality and timeliness', 'Lead the development of data visualization and dashboards to help the organization monitor performance, generate insights, and continuously improve user experience', 'Establish playbooks to drive process and consistent outcomes', 'Participating in the full life cycle of model development, which spans from business problem discovery, data discovery to model deployment and monitoring']",True,"['Deep Learning', 'Vision Transformers', 'Generative AI']",Deep Learning: Employing deep learning libraries such as PyTorch to build neural network models for complex data tasks.; Vision Transformers: Using modern transformer-based architectures for advanced computer vision applications.; Generative AI: Applying generative AI techniques within the computer vision domain to create or enhance images.,"['Data Wrangling', 'Statistical Modeling', 'Machine Learning Algorithms', 'Python', 'SQL', 'Apache Spark', 'Data Visualization and Dashboards', 'Time-Series Analysis', 'Computer Vision', 'Convolutional Neural Networks', 'Cloud-Native Technologies', 'Relational and NoSQL Databases', 'Model Development Lifecycle']","Data Wrangling: Processing, cleansing, verifying, and enriching data from multiple sources to prepare it for analysis and modeling.; Statistical Modeling: Applying advanced statistical models to extract insights and solve business problems using data.; Machine Learning Algorithms: Using a wide range of machine learning techniques to build predictive models that address various business challenges.; Python: Primary programming language used for data analysis, modeling, and working with data science libraries.; SQL: Querying and managing structured data stored in relational databases to support data analysis and modeling.; Apache Spark: Big data processing framework used to handle large-scale data processing and analytics.; Data Visualization and Dashboards: Creating visual representations and dashboards to monitor performance and generate actionable insights.; Time-Series Analysis: Analyzing data with complex relationships and temporal components to understand trends and patterns.; Computer Vision: Applying image processing and analysis techniques using libraries like OpenCV and PIL to extract insights from visual data.; Convolutional Neural Networks: Using CNN architectures for image-related tasks within the computer vision domain.; Cloud-Native Technologies: Utilizing cloud-based infrastructure and tools to deploy and scale data science solutions.; Relational and NoSQL Databases: Managing and analyzing large structured and unstructured datasets stored in various database systems.; Model Development Lifecycle: Participating in all stages from problem discovery, data exploration, model building, deployment, to monitoring."
AN7jrONXj9RSGt1JAAAAAA==,"(USA) Senior, Data Scientist","Position Summary...

Join Walmart|VIZIO and take your career to the next level!

We are looking for a highly talented and motivated Data Scientist to help deliver strategic initiatives across the organization. We look for people who can effectively partner with Product Management, Engineering, and business leaders to deliver easy, effective, and insightful analytics. We are a growing team, focusing on challenging problems that make a difference to our business. We concentrate on high-impact, high-value development, and analysis. We are looking for someone who is versatile, methodical, excited by modern technology and enjoys focusing on tackling software challenges.

What you'll do...

About the Data Science Team:

Our Data Science team operates at the heart of VIZIO/Walmart's mission to deliver the best shopping experience to our customers. We leverage advanced analytics, machine learning, and big data to drive business insights and strategic decisions. As a Senior Data Scientist, you will play a crucial role in enhancing our data capabilities and contributing to VIZIO/Walmart’s growth and innovation.

What You’ll Do:
• Solve novel and complex business problems with high-quality, maintainable code.
• Collaborate cross-functionally with Product Managers and Engineering teams to gather requirements and develop solutions.
• Analyze high volumes of data to understand business problems and propose technical solutions.
• Develop and iterate on machine learning models, from quick prototypes to production deployment.
• Evaluate the efficacy and value of product features using data-driven insights.
• Organize and document complex technical projects.

What You’ll Bring:
• Expertise in big data analytics and automation techniques.
• Strong understanding of business contexts and the ability to translate business problems into data solutions.
• Proficiency with database technologies and distributed datastores (e.g., SQL, NoSQL).
• Experience in developing and deploying machine learning models.
• Experience writing production code in Python, fluent in PySpark
• Expertise with at least one ML framework (pytorch, tensorflow, jax)
• Experience with CI/CD frameworks

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.
‎

‎

‎
You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.
‎

For information about PTO, see https://one.walmart.com/notices.

‎

‎
Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.
‎
Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.
‎

For information about benefits and eligibility, see One.Walmart.

‎
New York, New York US-11582:The annual salary range for this position is $108,000.00-$216,000.00
‎
San Francisco, California US-11574:The annual salary range for this position is $117,000.00-$234,000.00
‎

‎

‎

‎

‎

‎

‎

‎

‎

‎
Additional compensation includes annual or quarterly performance bonuses.
‎
Additional compensation for certain positions may also include:
‎

‎
- Stock
‎

‎

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1- Bachelor’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years' experience in an analytics related field. Option 2- Master’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years' experience in an analytics related field. Option 3 - 5 years' experience in an analytics or related field.

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data science, machine learning, optimization models, Master’s degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.

Primary Location...

350 5Th Ave, New York, NY 10118-4801, United States of America",,2025-07-25,"['We look for people who can effectively partner with Product Management, Engineering, and business leaders to deliver easy, effective, and insightful analytics', 'We are looking for someone who is versatile, methodical, excited by modern technology and enjoys focusing on tackling software challenges', 'Expertise in big data analytics and automation techniques', 'Strong understanding of business contexts and the ability to translate business problems into data solutions', 'Proficiency with database technologies and distributed datastores (e.g., SQL, NoSQL)', 'Experience in developing and deploying machine learning models', 'Experience writing production code in Python, fluent in PySpark', 'Expertise with at least one ML framework (pytorch, tensorflow, jax)', 'Experience with CI/CD frameworks', ""Option 1- Bachelor’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years' experience in an analytics related field"", ""Option 2- Master’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years' experience in an analytics related field"", ""Option 3 - 5 years' experience in an analytics or related field"", 'Data science, machine learning, optimization models, Master’s degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly', 'The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture']","['Solve novel and complex business problems with high-quality, maintainable code', 'Collaborate cross-functionally with Product Managers and Engineering teams to gather requirements and develop solutions', 'Analyze high volumes of data to understand business problems and propose technical solutions', 'Develop and iterate on machine learning models, from quick prototypes to production deployment', 'Evaluate the efficacy and value of product features using data-driven insights', 'Organize and document complex technical projects']",True,[],,"['Big Data Analytics', 'Machine Learning', 'SQL', 'NoSQL', 'Python', 'PySpark', 'Scikit-learn', 'TensorFlow', 'PyTorch', 'JAX', 'CI/CD Frameworks', 'Optimization Models', 'Spark', 'Scala', 'R']","Big Data Analytics: Used to analyze large volumes of data to derive business insights and support strategic decisions.; Machine Learning: Developing and deploying predictive models to solve complex business problems and improve product features.; SQL: Utilized for querying and managing relational databases as part of data processing and analysis.; NoSQL: Used for handling distributed datastores to support scalable data storage and retrieval.; Python: Primary programming language for writing production code and implementing data science solutions.; PySpark: Used for big data processing and analytics within distributed computing environments.; Scikit-learn: An open-source machine learning framework used for building and iterating on ML models.; TensorFlow: Machine learning framework employed for model development and deployment.; PyTorch: ML framework used for developing machine learning models, including prototyping and production.; JAX: ML framework used for high-performance machine learning model development.; CI/CD Frameworks: Applied to automate the deployment and integration of machine learning models and data solutions.; Optimization Models: Used to improve decision-making processes and enhance business outcomes through mathematical modeling.; Spark: Big data processing engine used for distributed data analytics and machine learning workflows.; Scala: Programming language used in big data environments, often with Spark for data processing.; R: Statistical programming language used for data analysis and modeling."
iDjdplG40ufZFVE9AAAAAA==,Senior Data Scientist,"Senior Data Scientist

Virta Health is pioneering a new standard of care for people to reclaim their lives. We are in the midst of a public health crisis: obesity rates are at an all-time high and over half of US adults have type 2 diabetes or prediabetes, and despite billions spent on new treatments, outcomes are largely worse. Virta reverses these diseases and delivers life-changing results by pairing individualized nutrition with ongoing care from a clinical support team. We have raised over $350 million from top-tier investors, and partner with the largest health plans, employers, and government organizations to help their employees and members restore their health and take back their lives.

Role Overview

The Advanced Analytics & AI (AAA) team is accountable for both pioneering new classes of data that power our business, and ensuring that data is powerful, clear, correct and easy to use throughout the company. The team collaborates closely with the engineering, product development, commercial, and clinical teams to transform data into actionable insights that propel Virta's mission forward.

As a Senior Data Scientist on the AAA team, you will play a crucial role in shaping our data-driven decision making processes and in driving impactful insights that advance our mission. This role offers a unique blend of hands-on coding and strategic leadership, working closely in partnership with the Product Development group that supports adoption of our member-facing products. You will get a chance to work closely with stakeholders to create impactful data-driven reports and analyses that strengthen Virta’s value proposition.

Responsibilities
• Serve as data lead for the Adoption Squad:
• Understand the product – strategy, goals, roadmap, users – deeply enough to identify high-impact, strategic opportunities and risks.
• Use data to steer conversations: bring data-driven hypotheses, challenge assumptions, frame trade-offs, prioritize strategically.
• Translate vague product hunches into sharp analytical questions, and design the right approach to answer them.
• Be the source of truth for KPIs and product metrics: help define and monitor them, and identify trends and drivers.
• Drive decision making with data: Prioritize analyses that meaningfully inform product decisions and change outcomes, reframe analysis requests that won’t do that into ones that will, and design and deliver the resulting analyses properly and rapidly.
• Lead experimentation thoughtfully: guide the team on when and when not to experiment, help enable self-serve experimentation, and focus on frequent, small experiments to speed learning.
• Identify where product strategy and ideas could be better, more easily, or more quickly implemented with the help of AI (ML or GenAI), and help enable this integration.
• Show up as a collaborative leader, not simply a service provider, and help focus work on what matters most.
• Work end-to-end to translate clinical, member, and claims data from our data warehouse into actionable recommendations: work with stakeholders to design reports and dashboards that answer real business questions, design the data flows to support these, and build the required data transformation pipelines.

Must-Haves
• Experience working at a digital health or similar startup, preferably during the growth phase, in order to function effectively in a fast-paced, rapidly changing environment.
• 7+ years of experience in a Healthcare Analytics or Data Science role, working with large datasets and conducting statistical and quantitative modeling, melding analytics with strong programming, data mining, clustering and segmentation.
• 5+ years of work experience working data science and visualization tools (SQL, R, and/or Python)
• Advanced understanding of data storage, ETL frameworks, data transformation, and validation
• Experience in building BI dashboards using tools such as Looker or Tableau
• Ability to explain technology, techniques and approaches to others

Nice-to-Haves
• Experience leading cross-functional efforts to build scalable systems and data pipelines, working with complex data structures
• Understanding of Generative AI concepts and basic usage of GenAI tools (ChatGPT, Claude, etc.)
• Experience building pipelines using dbt
• Demonstrated project management experience

90 Day Plan

Within your first 90 days at Virta, we expect you will do the following:
• Familiarize yourself with the Advanced Analytics & AI team roles and responsibilities. Get a pulse on team structure, key stakeholders, and areas for opportunity with an eye towards scalability and standardization.
• Integrate with the Adoption Squad to understand team dynamics, analyze key product features and data pipelines, and familiarize yourself with the Squad’s product roadmap
• Analyze current member journey to understand Virta’s technology ecosystem
• Meet cross-functional stakeholders to understand how their business needs align with Squad and Team goals
• Identify at least 1 area of opportunity to leverage GenAI to increase team efficiency or improve our processes
• Teach and inspire your team members through knowledge sharing, pair programming, and giving feedback during code reviews

Values-driven culture

Virta’s company values drive our culture, so you’ll do well if:
• You put people first and take care of yourself, your peers, and our patients equally
• You have a strong sense of ownership and take initiative while empowering others to do the same
• You prioritize positive impact over busy work
• You have no ego and understand that everyone has something to bring to the table regardless of experience
• You appreciate transparency and promote trust and empowerment through open access of information
• You are evidence-based and prioritize data and science over seniority or dogma
• You take risks and rapidly iterate

Is this role not quite what you're looking for? Join our Talent Community and follow us on Linkedin to stay connected!

Virta has a location based compensation structure. Starting pay will be based on a number of factors and commensurate with qualifications & experience. For this role, the compensation range is $167,249 - $216,000. Information about Virta’s benefits is on our Careers page at: https://www.virtahealth.com/careers.

As part of your duties at Virta, you may come in contact with sensitive patient information that is governed by HIPAA. Throughout your career at Virta, you will be expected to follow Virta's security and privacy procedures to ensure our patients' information remains strictly confidential. Security and privacy training will be provided.

As a remote-first company, our team is spread across various locations with office hubs in Denver and San Francisco.
Clinical roles: We currently do not hire in the following states: AK, HI, RI
Corporate roles: We currently do not hire in the following states: AK, AR, DE, HI, ME, MS, NM, OK, SD, VT, WI.

#LI-remote",2025-07-21T00:00:00.000Z,2025-07-25,"['Experience working at a digital health or similar startup, preferably during the growth phase, in order to function effectively in a fast-paced, rapidly changing environment', '7+ years of experience in a Healthcare Analytics or Data Science role, working with large datasets and conducting statistical and quantitative modeling, melding analytics with strong programming, data mining, clustering and segmentation', '5+ years of work experience working data science and visualization tools (SQL, R, and/or Python)', 'Advanced understanding of data storage, ETL frameworks, data transformation, and validation', 'Experience in building BI dashboards using tools such as Looker or Tableau', 'Ability to explain technology, techniques and approaches to others', 'Experience leading cross-functional efforts to build scalable systems and data pipelines, working with complex data structures', 'Understanding of Generative AI concepts and basic usage of GenAI tools (ChatGPT, Claude, etc.)', 'Experience building pipelines using dbt', 'Demonstrated project management experience', 'You have a strong sense of ownership and take initiative while empowering others to do the same', 'You prioritize positive impact over busy work', 'You have no ego and understand that everyone has something to bring to the table regardless of experience', 'You appreciate transparency and promote trust and empowerment through open access of information', 'You are evidence-based and prioritize data and science over seniority or dogma', 'You take risks and rapidly iterate']","['As a Senior Data Scientist on the AAA team, you will play a crucial role in shaping our data-driven decision making processes and in driving impactful insights that advance our mission', 'You will get a chance to work closely with stakeholders to create impactful data-driven reports and analyses that strengthen Virta’s value proposition', 'Serve as data lead for the Adoption Squad:', 'Understand the product – strategy, goals, roadmap, users – deeply enough to identify high-impact, strategic opportunities and risks', 'Use data to steer conversations: bring data-driven hypotheses, challenge assumptions, frame trade-offs, prioritize strategically', 'Translate vague product hunches into sharp analytical questions, and design the right approach to answer them', 'Be the source of truth for KPIs and product metrics: help define and monitor them, and identify trends and drivers', 'Drive decision making with data: Prioritize analyses that meaningfully inform product decisions and change outcomes, reframe analysis requests that won’t do that into ones that will, and design and deliver the resulting analyses properly and rapidly', 'Lead experimentation thoughtfully: guide the team on when and when not to experiment, help enable self-serve experimentation, and focus on frequent, small experiments to speed learning', 'Identify where product strategy and ideas could be better, more easily, or more quickly implemented with the help of AI (ML or GenAI), and help enable this integration', 'Show up as a collaborative leader, not simply a service provider, and help focus work on what matters most', 'Work end-to-end to translate clinical, member, and claims data from our data warehouse into actionable recommendations: work with stakeholders to design reports and dashboards that answer real business questions, design the data flows to support these, and build the required data transformation pipelines', 'Familiarize yourself with the Advanced Analytics & AI team roles and responsibilities', 'Get a pulse on team structure, key stakeholders, and areas for opportunity with an eye towards scalability and standardization', 'Integrate with the Adoption Squad to understand team dynamics, analyze key product features and data pipelines, and familiarize yourself with the Squad’s product roadmap', 'Analyze current member journey to understand Virta’s technology ecosystem', 'Meet cross-functional stakeholders to understand how their business needs align with Squad and Team goals', 'Identify at least 1 area of opportunity to leverage GenAI to increase team efficiency or improve our processes', 'Teach and inspire your team members through knowledge sharing, pair programming, and giving feedback during code reviews']",True,"['Generative AI', 'GenAI Tools']",Generative AI: Identified as an opportunity to improve team efficiency and product strategy through AI-driven solutions.; GenAI Tools: Basic usage of tools like ChatGPT and Claude to support AI integration and innovation within the team.,"['Statistical and Quantitative Modeling', 'Data Mining', 'Clustering and Segmentation', 'SQL', 'R', 'Python', 'ETL Frameworks', 'Data Transformation and Validation', 'BI Dashboards', 'Data Pipelines', 'dbt', 'Experimentation and A/B Testing']","Statistical and Quantitative Modeling: Used to analyze large healthcare datasets and derive insights for decision making and product strategy.; Data Mining: Applied to extract meaningful patterns and segmentations from complex clinical and member data.; Clustering and Segmentation: Techniques used to group similar data points for targeted analysis and personalized healthcare insights.; SQL: Utilized for querying and managing data within Virta’s data warehouse to support reporting and analysis.; R: Used as a programming tool for statistical analysis and data visualization in healthcare analytics.; Python: Employed for data science tasks including data transformation, analysis, and building data pipelines.; ETL Frameworks: Applied to extract, transform, and load clinical and claims data into usable formats for analysis.; Data Transformation and Validation: Processes to ensure data quality and readiness for accurate reporting and decision making.; BI Dashboards: Built using tools like Looker and Tableau to visualize KPIs and product metrics for stakeholders.; Data Pipelines: Designed and maintained to automate data flows from raw sources to actionable insights and dashboards.; dbt: Used to build and manage scalable data transformation pipelines within the analytics infrastructure.; Experimentation and A/B Testing: Guided frequent, small experiments to validate hypotheses and inform product decisions."
KRaSg822gWoBsIzeAAAAAA==,"(USA) Senior, Data Scientist","Position Summary...

Join Walmart|VIZIO and take your career to the next level!

We are looking for a highly talented and motivated Data Scientist to help deliver strategic initiatives across the organization. We look for people who can effectively partner with Product Management, Engineering, and business leaders to deliver easy, effective, and insightful analytics. We are a growing team, focusing on challenging problems that make a difference to our business. We concentrate on high-impact, high-value development, and analysis. We are looking for someone who is versatile, methodical, excited by modern technology and enjoys focusing on tackling software challenges.

What you'll do...

About the Data Science Team:

Our Data Science team operates at the heart of VIZIO/Walmart's mission to deliver the best shopping experience to our customers. We leverage advanced analytics, machine learning, and big data to drive business insights and strategic decisions. As a Senior Data Scientist, you will play a crucial role in enhancing our data capabilities and contributing to VIZIO/Walmart’s growth and innovation.

What You’ll Do:
• Solve novel and complex business problems with high-quality, maintainable code.
• Collaborate cross-functionally with Product Managers and Engineering teams to gather requirements and develop solutions.
• Analyze high volumes of data to understand business problems and propose technical solutions.
• Develop and iterate on machine learning models, from quick prototypes to production deployment.
• Evaluate the efficacy and value of product features using data-driven insights.
• Organize and document complex technical projects.

What You’ll Bring:
• Expertise in big data analytics and automation techniques.
• Strong understanding of business contexts and the ability to translate business problems into data solutions.
• Proficiency with database technologies and distributed datastores (e.g., SQL, NoSQL).
• Experience in developing and deploying machine learning models.
• Experience writing production code in Python, fluent in PySpark
• Expertise with at least one ML framework (pytorch, tensorflow, jax)
• Experience with CI/CD frameworks

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.
‎

‎

‎
You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.
‎

For information about PTO, see https://one.walmart.com/notices.

‎

‎
Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.
‎
Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.
‎

For information about benefits and eligibility, see One.Walmart.

‎
New York, New York US-11582:The annual salary range for this position is $108,000.00-$216,000.00
‎
San Francisco, California US-11574:The annual salary range for this position is $117,000.00-$234,000.00
‎

‎

‎

‎

‎

‎

‎

‎

‎

‎
Additional compensation includes annual or quarterly performance bonuses.
‎
Additional compensation for certain positions may also include:
‎

‎
- Stock
‎

‎

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1- Bachelor’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years' experience in an analytics related field. Option 2- Master’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years' experience in an analytics related field. Option 3 - 5 years' experience in an analytics or related field.

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data science, machine learning, optimization models, Master’s degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.

Primary Location...

350 5Th Ave, New York, NY 10118-4801, United States of America",,2025-07-25,"['We look for people who can effectively partner with Product Management, Engineering, and business leaders to deliver easy, effective, and insightful analytics', 'We are looking for someone who is versatile, methodical, excited by modern technology and enjoys focusing on tackling software challenges', 'Expertise in big data analytics and automation techniques', 'Strong understanding of business contexts and the ability to translate business problems into data solutions', 'Proficiency with database technologies and distributed datastores (e.g., SQL, NoSQL)', 'Experience in developing and deploying machine learning models', 'Experience writing production code in Python, fluent in PySpark', 'Expertise with at least one ML framework (pytorch, tensorflow, jax)', 'Experience with CI/CD frameworks', ""Option 1- Bachelor’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years' experience in an analytics related field"", ""Option 2- Master’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years' experience in an analytics related field"", ""Option 3 - 5 years' experience in an analytics or related field"", 'Data science, machine learning, optimization models, Master’s degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly', 'The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture']","['Solve novel and complex business problems with high-quality, maintainable code', 'Collaborate cross-functionally with Product Managers and Engineering teams to gather requirements and develop solutions', 'Analyze high volumes of data to understand business problems and propose technical solutions', 'Develop and iterate on machine learning models, from quick prototypes to production deployment', 'Evaluate the efficacy and value of product features using data-driven insights', 'Organize and document complex technical projects']",True,[],,"['Big Data Analytics', 'Machine Learning', 'SQL', 'NoSQL', 'Python', 'PySpark', 'Scikit-learn', 'TensorFlow', 'PyTorch', 'JAX', 'CI/CD Frameworks', 'Optimization Models', 'Spark', 'Scala', 'R']",Big Data Analytics: Used to analyze large volumes of data to derive business insights and support strategic decisions.; Machine Learning: Developing and deploying predictive models to solve complex business problems and improve product features.; SQL: Utilized for querying and managing structured data within relational databases.; NoSQL: Used for handling distributed datastores and non-relational data storage solutions.; Python: Primary programming language for writing production code and building data science solutions.; PySpark: Used for big data processing and analytics within distributed computing environments.; Scikit-learn: Open source machine learning framework employed for building and prototyping ML models.; TensorFlow: Machine learning framework used for developing and deploying ML models.; PyTorch: ML framework leveraged for model development and experimentation.; JAX: ML framework used for high-performance machine learning model development.; CI/CD Frameworks: Applied to automate the deployment and integration of machine learning models and data solutions.; Optimization Models: Used to improve decision-making processes and business outcomes through mathematical modeling.; Spark: Big data processing engine used for distributed data analytics and machine learning workflows.; Scala: Programming language often used with Spark for big data processing tasks.; R: Statistical programming language used for analytics and data science tasks.
2gTZt9EtBBLTOfd6AAAAAA==,Senior Data Scientist,"Intuit Credit Karma is a mission-driven company, focused on championing financial progress for our more than 140 million members globally. While we're best known for pioneering free credit scores, our members turn to us for everything related to their financial goals, including identity monitoring, applying for credit cards, shopping for insurance and loans (car, home and personal) and savings accounts and checking accounts* – all for free. Credit Karma has grown significantly through the years: we now have more than 1,700 employees across our offices in Oakland, Charlotte, Culver City, San Diego, London, Bangalore, and New York City.
• Banking services provided by MVB Bank, Inc., Member FDIC

Senior Data Scientist

Credit Karma is looking for a results-oriented and strategically innovative Senior Data Scientist who is passionate about applying machine learning to solve financial challenges for millions of members. In this role, you will drive data-informed decisions and deliver AI-powered recommendations that help our members achieve their financial goals. Data Science plays a ubiquitous role in Credit Karma's product, serving as the foundation for core machine learning capabilities that drive monetization, personalization, and a value-centric experience for our members. As such, this role is highly cross-functional and requires tight partnerships with a wide range of functions - including engineering, product, marketing, finance and analytics.

We are seeking a Senior Data Scientist to drive innovation in the development and application of data science techniques that power the most relevant financial products including and actionable recommendations at Credit Karma. This role is ideal for someone who combines strong statistical and machine learning skills with business acumen and cross-functional collaboration.

What you'll do:
• Partner with colleagues throughout the organization to identify high-impact opportunities to leverage our extensive data to better serve our users
• Responsible for accelerating revenue and engagement advancement through disruptive and continuous improvements in various data science models (targeting, marketing campaigns, etc.), feature engineering including user profiles and behavior, personalization, etc.
• Participate research efforts with other team members to explore the frontiers of GenAI, Deep Learning, Recommender systems, and other areas, as they apply to Personal Finance
• Collaborate closely with partner teams to define metrics that quantify various aspects of our business, including but not limited to revenue, engagement, user experience, etc. Provide solid statistical bases in designing experiments.
• Represent Data Science in cross functional meetings and reviews. Be able to translate difficult technical subject matter to business partners
• Represent Credit Karma in external forums such as conferences and meetups, and act as an evangelist for CK team in such forums

What's great about the role:
• You will work with large scale Machine Learning Models to optimize for Personal Finance Products
• You will be part of a highly impactful team, who are working on large scale projects that directly impact the business and members
• You will experience both personal and professional growth as you encourage growth throughout the team

Minimum Basic Requirement:
• MS in Computer Science, Mathematics, Statistics, Physics or a related quantitative discipline
• 5+ years of industrial experience in Data Science, Machine Learning and related areas, ideally in hyper-growth consumer Internet scenarios
• Deep statistical understanding of data at scale
• Authoritative knowledge of Python/R and SQL
• Experience with advanced modeling techniques, such as deep neutral network, collaborative filtering, matrix factorization, time series analysis, mixed-effect models, etc

Preferred Qualifications:
• Experience with driving monetization, member engagement, longer term member value through AI
• Experience working on large scale AI systems with applications across machine learning and generative AI, AI infrastructure, data foundation, and self-serve analytics through DS methods
• Ability to balance fast paced environments at a large scale company
• Ads business and product experience

Credit Karma's mission of championing financial progress for all starts from within. That's why we implemented role-based compensation, which ensures people who are in the same role receive the same pay with variations for geographic location only. It's all part of a more comprehensive DEI strategy that helps level the playing field. The base salary range for this role is $296,068, plus equity and benefits.

Benefits at Credit Karma includes:
• Medical and Dental Coverage
• Retirement Plan
• Commuter Benefits
• Wellness perks
• Paid Time Off (Vacation, Sick, Baby Bonding, Cultural Observance, & More)
• Education Perks
• Paid Gift Week in December

Equal Employment Opportunity:

Credit Karma is proud to be an Equal Employment Opportunity Employer. We welcome all candidates without regard to race, color, religion, age, marital status, sex (including pregnancy, childbirth, or related medical condition), sexual orientation, gender identity or gender expression, national origin, veteran or military status, disability (physical or mental), genetic information or other protected characteristic. We prohibit discrimination of any kind and operate in compliance with applicable fair chance laws.

Credit Karma is also committed to a diverse and inclusive work environment because it is the right thing to do. We believe that such an environment advances long-term professional growth, creates a robust business, and supports our mission of championing financial progress for everyone. We offer generous benefits and perks with a single eye to nourishing an inclusive environment that recognizes the contributions of all and fosters diversity by supporting our internal Employee Resource Groups. We've worked hard to build an intensely collaborative and creative environment, a diverse and inclusive employee culture, and the opportunity for professional growth. As part of the Credit Karma team, your voice will be heard, your contributions will matter, and your unique background and experiences will be celebrated.

Privacy Policies:

Credit Karma is strongly committed to protecting personal data. Please take a look below to review our privacy policies:
• GDPR Privacy Policy
• U.S. Job Applicant Privacy Notice",,2025-07-25,"['Credit Karma is looking for a results-oriented and strategically innovative Senior Data Scientist who is passionate about applying machine learning to solve financial challenges for millions of members', 'We are seeking a Senior Data Scientist to drive innovation in the development and application of data science techniques that power the most relevant financial products including and actionable recommendations at Credit Karma', 'This role is ideal for someone who combines strong statistical and machine learning skills with business acumen and cross-functional collaboration', 'MS in Computer Science, Mathematics, Statistics, Physics or a related quantitative discipline', '5+ years of industrial experience in Data Science, Machine Learning and related areas, ideally in hyper-growth consumer Internet scenarios', 'Deep statistical understanding of data at scale', 'Authoritative knowledge of Python/R and SQL', 'Experience with advanced modeling techniques, such as deep neutral network, collaborative filtering, matrix factorization, time series analysis, mixed-effect models, etc']","[""Data Science plays a ubiquitous role in Credit Karma's product, serving as the foundation for core machine learning capabilities that drive monetization, personalization, and a value-centric experience for our members"", 'Partner with colleagues throughout the organization to identify high-impact opportunities to leverage our extensive data to better serve our users', 'Responsible for accelerating revenue and engagement advancement through disruptive and continuous improvements in various data science models (targeting, marketing campaigns, etc.), feature engineering including user profiles and behavior, personalization, etc', 'Participate research efforts with other team members to explore the frontiers of GenAI, Deep Learning, Recommender systems, and other areas, as they apply to Personal Finance', 'Collaborate closely with partner teams to define metrics that quantify various aspects of our business, including but not limited to revenue, engagement, user experience, etc', 'Provide solid statistical bases in designing experiments', 'Represent Data Science in cross functional meetings and reviews', 'Be able to translate difficult technical subject matter to business partners', 'Represent Credit Karma in external forums such as conferences and meetups, and act as an evangelist for CK team in such forums']",True,"['Generative AI', 'Deep Learning']",Generative AI: Explored as part of research efforts to innovate financial product recommendations and personalization.; Deep Learning: Applied to develop advanced AI models that enhance personalization and predictive capabilities.,"['Machine Learning', 'Feature Engineering', 'Python', 'R', 'SQL', 'Deep Neural Networks', 'Collaborative Filtering', 'Matrix Factorization', 'Time Series Analysis', 'Mixed-Effect Models', 'Statistical Experiment Design', 'Recommender Systems']","Machine Learning: Core capability used to develop models that drive monetization, personalization, and user engagement in financial products.; Feature Engineering: Creating user profiles and behavioral features to improve targeting and personalization models.; Python: Primary programming language used for data science and machine learning model development.; R: Statistical programming language used for data analysis and modeling.; SQL: Used for querying and managing large-scale data to support data science workflows.; Deep Neural Networks: Advanced modeling technique applied to improve predictive accuracy in financial product recommendations.; Collaborative Filtering: Modeling approach used for recommender systems to personalize financial product suggestions.; Matrix Factorization: Technique used in recommendation algorithms to identify latent factors in user-item interactions.; Time Series Analysis: Applied to analyze temporal financial data for forecasting and trend detection.; Mixed-Effect Models: Statistical models used to account for both fixed and random effects in financial data.; Statistical Experiment Design: Used to define metrics and design experiments that quantify business impact such as revenue and engagement.; Recommender Systems: Systems developed to provide personalized financial product recommendations to users."
JVN5an6JjGzZrIZoAAAAAA==,"Senior Data Scientist, Specialist Senior - SFL Scientific","Senior Data Scientist, Specialist Senior - SFL Scientific

Our Deloitte Strategy & Transactions team helps guide clients through their most critical moments and transformational initiatives. From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability. Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journey-before, during, and after any major transformational projects or transactions.

SFL Scientific, a Deloitte Business, is a U.S. based, data science consulting firm specializing in building industry-specific, artificial intelligence (AI) technologies.

We are hiring a Senior Data Scientist to collaborate directly with clients to design and develop novel projects and solutions. Join a rapidly growing team of professionals working to build a world-class data science practice focused on solving complex and R&D problems.

Recruiting for this role ends on 7/31/2025.

Work You'll Do

As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services. You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions.

Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation. Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills.
• Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production
• Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives
• Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization
• Validate AI models and algorithm via code reviews, unit, and integration tests
• Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives
• Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives

The Team

Our Strategy offering architects bold strategies to achieve business and mission goals, enabling growth, competitive advantage, technology modernization, and continuous digital and AI transformation.

SFL Scientific, a Deloitte Business, is a data science professional services practice focused on strategy, technology, and solving business challenges with Artificial Intelligence (AI). The team has a proven track record serving large, market-leading organizations in the private and public sectors, successfully delivering high-quality, novel and complex projects, and offering deep domain and scientific capabilities. Made up of experienced AI strategists, data scientists, and AI engineers, they serve as trusted advisors to executives, helping them understand and evaluate new and essential areas for AI investment and identify unique opportunities to transform their businesses.

Qualifications:
• Master's or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)
• 3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)
• 3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments
• 3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow
• 3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads
• Live within commuting distance to one of Deloitte's consulting offices
• Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve
• Limited immigration sponsorship may be available

Preferred:
• 2+ years of experience working in a client-facing, consulting environment
• 2+ years of experience leading project/client engagement teams in the execution of complex AI data science solutions
• 1+ year of experience with LLM/GenAI use cases and developing RAG solutions, tools, and services (i.e., LangChain, LangGraph, MCP, etc.)
• 1+ year of experience with AWS Sagemaker or AWS ML Studio

Information for applicants with a need for accommodation: https://www2.deloitte.com/us/en/pages/careers/articles/join-deloitte-assistance-for-disabled-applicants.html

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $107,600 to $198,400.

You may also be eligible to participate in a discretionary annual incentive program, subject to the rules governing the program, whereby an award, if any, depends on various factors, including, without limitation, individual and organizational performance.

#MonitorDeloitte

#DeloitteJobs

#StrategyConsulting

#DeloitteStrategy

#Strategy26

#SFL26

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.",2025-06-26T00:00:00.000Z,2025-07-25,"[""Master's or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)"", '3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)', '3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments', '3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow', '3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads', ""Live within commuting distance to one of Deloitte's consulting offices"", 'Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve', 'Limited immigration sponsorship may be available', 'Information for applicants with a need for accommodation: https://www2.deloitte.com/us/en/pages/careers/articles/join-deloitte-assistance-for-disabled-applicants.html']","['From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability', 'Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journey-before, during, and after any major transformational projects or transactions', 'As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services', 'You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions', 'Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation', 'Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills', 'Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production', 'Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives', 'Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization', 'Validate AI models and algorithm via code reviews, unit, and integration tests', 'Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives', 'Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives']",True,"['Generative AI', 'Large Language Models', 'Retrieval-Augmented Generation', 'Prompt Engineering', 'Multi-Modal Cognitive Platform', 'Convolutional Neural Networks', 'Recurrent Neural Networks', 'Generative Adversarial Networks', 'AWS SageMaker', 'AWS ML Studio']","Generative AI: Involved in developing next-generation AI services and solutions including novel projects like drug discovery and autonomous systems.; Large Language Models: Applied in client projects involving LLM/GenAI use cases and development of related solutions.; Retrieval-Augmented Generation: Used to build advanced AI tools and services such as LangChain and LangGraph for enhanced information retrieval.; Prompt Engineering: Employed to optimize interactions with LLMs and generative AI models for client solutions.; Multi-Modal Cognitive Platform: Referenced as MCP, used in developing AI services integrating multiple data modalities.; Convolutional Neural Networks: Deep learning architecture applied in computer vision tasks within AI projects.; Recurrent Neural Networks: Used for sequence modeling tasks such as time-series and NLP within AI solutions.; Generative Adversarial Networks: Applied for generating synthetic data or enhancing model training in AI projects.; AWS SageMaker: Cloud service used to build, train, and deploy machine learning models including AI workloads.; AWS ML Studio: Platform for developing and deploying AI/ML models in cloud environments.","['Exploratory Data Analysis', 'Time-Series Analysis', 'Natural Language Processing', 'Computer Vision', 'Machine Learning', 'Deep Learning', 'Model Tuning and Performance Validation', 'Model Deployment and Optimization', 'Kubernetes', 'Docker', 'TensorRT', 'RAPIDs', 'Kubeflow', 'MLflow', 'Cloud Platforms', 'Python', 'PyTorch']","Exploratory Data Analysis: Used to understand client data sets and operational requirements to design long-term data science solutions.; Time-Series Analysis: Applied as part of data analysis techniques relevant to client projects involving temporal data.; Natural Language Processing: Used for analyzing and extracting insights from text data as part of AI/ML algorithm development.; Computer Vision: Applied in projects involving image data, such as cancer detection and autonomous systems.; Machine Learning: Core to developing predictive models and AI/ML solutions for clients across various domains.; Deep Learning: Used for advanced modeling techniques including CNNs, RNNs, and GANs in real-world projects.; Model Tuning and Performance Validation: Ensures deployed models meet performance standards and business objectives.; Model Deployment and Optimization: Involves deploying ML models into production environments and optimizing their performance.; Kubernetes: Used as a container orchestration tool to deploy and manage ML models in production.; Docker: Utilized for containerizing ML applications to ensure consistent deployment environments.; TensorRT: Applied for optimizing deep learning model inference performance in production.; RAPIDs: Used to accelerate data science and ML workflows leveraging GPU computing.; Kubeflow: Employed to build and manage scalable ML workflows and pipelines.; MLflow: Used for managing the ML lifecycle including experiment tracking and model registry.; Cloud Platforms: AWS, Azure, and GCP are leveraged to deploy and scale AI/ML workloads in cloud environments.; Python: Primary programming language used for AI/ML algorithm development and data analysis.; PyTorch: Framework used for developing deep learning models and AI solutions."
Ql269g0qeg8rzPDQAAAAAA==,Senior Data Scientist [$203K/yr] TS/SCI FS-Poly Jobs,"Candidates must already possess an active Top Secret/SCI w. Full Scope Polygraph to be considered for this position.

Apply in 60 seconds at https://apply.systolic.com

Summary:

• SYSTOLIC is seeking a Senior Data Scientist

• Building and maintaining custom data analytics to automate and scale analysis

Qualifications & Compensation:

• Associate's degree with 12 years of relevant experience

• Bachelor’s Degree with 10 years of relevant experience

• Master's degree with 8 years of relevant experience

• Doctorate with 6 years of relevant experience

• Degree must be in Mathematics, Applied Mathematics Statistics, Applied Statistics, Machine learning, Data Science, Operations Research, or Computer Science or a degree in a related field. A broader range of degrees will be considered if accompanied by a Certificate in Data Science from an accredited college/university.

• Relevant experience must be in designing/implementing machine learning, data science, advanced analytical algorithms, programming, statistical analysis (e.g. variability, sampling error, inference, hypothesis testing, EDA, application of linear models), data management, data mining, data modeling and assessment, artificial intelligence, and/or software engineering.

• Candidates who meet these requirements will receive an annual compensation of approximately [$203K/yr]

About SYSTOLIC:

SYSTOLIC is dedicated to giving our employees the best possible company experience so that they can focus on providing outstanding support to their customer’s mission. Our company is founded on integrity, enthusiasm, and a relentless commitment to supporting the Intelligence Community. You can learn more about us and submit an application at https://systolic.com.

To learn about our compensation ranges, visit our Pay Transparency page at: https://systolic.com/pay-transparency",2025-07-18T00:00:00.000Z,2025-07-25,"['Candidates must already possess an active Top Secret/SCI w', 'Full Scope Polygraph to be considered for this position', ""Associate's degree with 12 years of relevant experience"", 'Bachelor’s Degree with 10 years of relevant experience', ""Master's degree with 8 years of relevant experience"", 'Doctorate with 6 years of relevant experience', 'Degree must be in Mathematics, Applied Mathematics Statistics, Applied Statistics, Machine learning, Data Science, Operations Research, or Computer Science or a degree in a related field', 'A broader range of degrees will be considered if accompanied by a Certificate in Data Science from an accredited college/university', 'Relevant experience must be in designing/implementing machine learning, data science, advanced analytical algorithms, programming, statistical analysis (e.g. variability, sampling error, inference, hypothesis testing, EDA, application of linear models), data management, data mining, data modeling and assessment, artificial intelligence, and/or software engineering']","['SYSTOLIC is seeking a Senior Data Scientist', 'Building and maintaining custom data analytics to automate and scale analysis']",True,['Artificial Intelligence'],"Artificial Intelligence: Experience with AI techniques is required, indicating involvement with intelligent systems beyond traditional data science.","['Machine Learning', 'Statistical Analysis', 'Data Mining', 'Data Modeling', 'Data Management', 'Advanced Analytical Algorithms', 'Programming']","Machine Learning: Designing and implementing machine learning models to support advanced analytical algorithms and data science tasks.; Statistical Analysis: Applying statistical methods such as variability, sampling error, inference, hypothesis testing, exploratory data analysis, and linear models to analyze data.; Data Mining: Extracting useful patterns and insights from large datasets to support decision-making and analysis.; Data Modeling: Creating data models and assessments to represent and analyze data structures relevant to the business context.; Data Management: Handling and organizing data to ensure quality and accessibility for analytics and modeling.; Advanced Analytical Algorithms: Developing and applying complex algorithms to automate and scale data analysis processes.; Programming: Using programming skills to implement data science solutions and automate analytics workflows."
9URUKTsZ6I8sQh_wAAAAAA==,"(USA) Senior, Data Scientist","Position Summary...

Join Walmart|VIZIO and take your career to the next level!

We are looking for a highly talented and motivated Data Scientist to help deliver strategic initiatives across the organization. We look for people who can effectively partner with Product Management, Engineering, and business leaders to deliver easy, effective, and insightful analytics. We are a growing team, focusing on challenging problems that make a difference to our business. We concentrate on high-impact, high-value development, and analysis. We are looking for someone who is versatile, methodical, excited by modern technology and enjoys focusing on tackling software challenges.

What you'll do...

About the Data Science Team:

Our Data Science team operates at the heart of VIZIO/Walmart's mission to deliver the best shopping experience to our customers. We leverage advanced analytics, machine learning, and big data to drive business insights and strategic decisions. As a Senior Data Scientist, you will play a crucial role in enhancing our data capabilities and contributing to VIZIO/Walmart’s growth and innovation.

What You’ll Do:
• Solve novel and complex business problems with high-quality, maintainable code.
• Collaborate cross-functionally with Product Managers and Engineering teams to gather requirements and develop solutions.
• Analyze high volumes of data to understand business problems and propose technical solutions.
• Develop and iterate on machine learning models, from quick prototypes to production deployment.
• Evaluate the efficacy and value of product features using data-driven insights.
• Organize and document complex technical projects.

What You’ll Bring:
• Expertise in big data analytics and automation techniques.
• Strong understanding of business contexts and the ability to translate business problems into data solutions.
• Proficiency with database technologies and distributed datastores (e.g., SQL, NoSQL).
• Experience in developing and deploying machine learning models.
• Experience writing production code in Python, fluent in PySpark
• Expertise with at least one ML framework (pytorch, tensorflow, jax)
• Experience with CI/CD frameworks

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.
‎

‎

‎
You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.
‎

For information about PTO, see https://one.walmart.com/notices.

‎

‎
Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.
‎
Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.
‎

For information about benefits and eligibility, see One.Walmart.

‎
New York, New York US-11582:The annual salary range for this position is $108,000.00-$216,000.00
‎
San Francisco, California US-11574:The annual salary range for this position is $117,000.00-$234,000.00
‎

‎

‎

‎

‎

‎

‎

‎

‎

‎
Additional compensation includes annual or quarterly performance bonuses.
‎
Additional compensation for certain positions may also include:
‎

‎
- Stock
‎

‎

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1- Bachelor’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years' experience in an analytics related field. Option 2- Master’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years' experience in an analytics related field. Option 3 - 5 years' experience in an analytics or related field.

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data science, machine learning, optimization models, Master’s degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.

Primary Location...

350 5Th Ave, New York, NY 10118-4801, United States of America",,2025-07-25,"['We look for people who can effectively partner with Product Management, Engineering, and business leaders to deliver easy, effective, and insightful analytics', 'We are looking for someone who is versatile, methodical, excited by modern technology and enjoys focusing on tackling software challenges', 'Expertise in big data analytics and automation techniques', 'Strong understanding of business contexts and the ability to translate business problems into data solutions', 'Proficiency with database technologies and distributed datastores (e.g., SQL, NoSQL)', 'Experience in developing and deploying machine learning models', 'Experience writing production code in Python, fluent in PySpark', 'Expertise with at least one ML framework (pytorch, tensorflow, jax)', 'Experience with CI/CD frameworks', ""Option 1- Bachelor’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years' experience in an analytics related field"", ""Option 2- Master’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years' experience in an analytics related field"", ""Option 3 - 5 years' experience in an analytics or related field"", 'Data science, machine learning, optimization models, Master’s degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly', 'The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture']","['Solve novel and complex business problems with high-quality, maintainable code', 'Collaborate cross-functionally with Product Managers and Engineering teams to gather requirements and develop solutions', 'Analyze high volumes of data to understand business problems and propose technical solutions', 'Develop and iterate on machine learning models, from quick prototypes to production deployment', 'Evaluate the efficacy and value of product features using data-driven insights', 'Organize and document complex technical projects']",True,[],,"['Big Data Analytics', 'Machine Learning', 'SQL', 'NoSQL', 'Python', 'PySpark', 'Scikit-learn', 'TensorFlow', 'PyTorch', 'JAX', 'CI/CD Frameworks', 'Optimization Models', 'Spark', 'Scala', 'R']","Big Data Analytics: Used to analyze large volumes of data to derive business insights and support strategic decisions.; Machine Learning: Developing and deploying predictive models to solve complex business problems and improve product features.; SQL: Utilized for querying and managing relational databases as part of data processing and analysis.; NoSQL: Used for handling distributed datastores to support scalable data storage and retrieval.; Python: Primary programming language for writing production code and implementing data science solutions.; PySpark: Used for big data processing and analytics within distributed computing environments.; Scikit-learn: An open-source machine learning framework employed for building and iterating on ML models.; TensorFlow: Machine learning framework used for developing and deploying ML models.; PyTorch: ML framework leveraged for building machine learning models, including deep learning architectures.; JAX: ML framework used for high-performance machine learning model development.; CI/CD Frameworks: Applied to automate the deployment and integration of machine learning models into production.; Optimization Models: Used to improve decision-making processes and enhance business outcomes through mathematical modeling.; Spark: Big data processing engine used for distributed data analytics and machine learning workflows.; Scala: Programming language used in big data environments, often with Spark for data processing.; R: Statistical programming language used for data analysis and modeling."
0abUPN9AxuM80uqSAAAAAA==,"Senior Data Scientist, Amazon Advertising","DESCRIPTION

Amazon Advertising is one of Amazon's fastest growing and most profitable businesses, responsible for defining and delivering a collection of advertising products that drive discovery and sales. Our products and solutions are strategically important to enable our Retail and Marketplace businesses to drive long-term growth. We deliver billions of ad impressions and millions of clicks and break fresh ground in product and technical innovations every day!

As a Senior Data Scientist on this team you will:
• Lead Data Science solutions from beginning to end.
• Deliver with independence on challenging large-scale problems with complexity and ambiguity.
• Write code (Python, R, Scala, SQL, etc.) to obtain, manipulate, and analyze data.
• Build Machine Learning and statistical models to solve specific business problems.
• Retrieve, synthesize, and present critical data in a format that is immediately useful to answering specific questions or improving system performance.
• Analyze historical data to identify trends and support optimal decision making.
• Apply statistical and machine learning knowledge to specific business problems and data.
• Formalize assumptions about how our systems should work, create statistical definitions of outliers, and develop methods to systematically identify outliers. Work out why such examples are outliers and define if any actions needed.
• Given anecdotes about anomalies or generate automatic scripts to define anomalies, deep dive to explain why they happen, and identify fixes.
• Build decision-making models and propose effective solutions for the business problems you define.
• Conduct written and verbal presentations to share insights to audiences of varying levels of technical sophistication.

Why you will love this opportunity: Amazon has invested heavily in building a world-class advertising business. This team defines and delivers a collection of advertising products that drive discovery and sales. Our solutions generate billions in revenue and drive long-term growth for Amazon’s Retail and Marketplace businesses. We deliver billions of ad impressions, millions of clicks daily, and break fresh ground to create world-class products. We are a highly motivated, collaborative, and fun-loving team with an entrepreneurial spirit - with a broad mandate to experiment and innovate.

Impact and Career Growth: You will invent new experiences and influence customer-facing shopping experiences to help suppliers grow their retail business and the auction dynamics that leverage native advertising; this is your opportunity to work within the fastest-growing businesses across all of Amazon! Define a long-term science vision for our advertising business, driven from our customers' needs, translating that direction into specific plans for research and applied scientists, as well as engineering and product teams. This role combines science leadership, organizational ability, technical strength, product focus, and business understanding.

Team video ~ https://youtu.be/zD_6Lzw8raE

BASIC QUALIFICATIONS
• 5+ years of data querying languages (e.g. SQL), scripting languages (e.g. Python) or statistical/mathematical software (e.g. R, SAS, Matlab, etc.) experience
• 4+ years of data scientist experience
• Bachelor's degree
• Experience with statistical models e.g. multinomial logistic regression

PREFERRED QUALIFICATIONS
• 2+ years of data visualization using AWS QuickSight, Tableau, R Shiny, etc. experience
• Experience managing data pipelines
• Experience as a leader and mentor on a data science team

Amazon is an equal opportunity employer and does not discriminate on the basis of protected veteran status, disability, or other legally protected status.

Los Angeles County applicants: Job duties for this position include: work safely and cooperatively with other employees, supervisors, and staff; adhere to standards of excellence despite stressful conditions; communicate effectively and respectfully with employees, supervisors, and staff to ensure exceptional customer service; and follow all federal, state, and local laws and Company policies. Criminal history may have a direct, adverse, and negative relationship with some of the material job duties of this position. These include the duties and responsibilities listed above, as well as the abilities to adhere to company policies, exercise sound judgment, effectively manage stress and work safely and respectfully with others, exhibit trustworthiness and professionalism, and safeguard business operations and the Company’s reputation. Pursuant to the Los Angeles County Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $143,300/year in our lowest geographic market up to $247,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.

Job details

USA, TX, Austin

USA, WA, Seattle

USA, VA, Arlington

USA, NY, New York

USA, CA, West Hollywood

USA, CA, Los Angeles

USA, CA, Palo Alto

Machine Learning Science",2025-07-16T00:00:00.000Z,2025-07-25,"['5+ years of data querying languages (e.g. SQL), scripting languages (e.g. Python) or statistical/mathematical software (e.g. R, SAS, Matlab, etc.) experience', '4+ years of data scientist experience', ""Bachelor's degree"", 'Experience with statistical models e.g. multinomial logistic regression', 'These include the duties and responsibilities listed above, as well as the abilities to adhere to company policies, exercise sound judgment, effectively manage stress and work safely and respectfully with others, exhibit trustworthiness and professionalism, and safeguard business operations and the Company’s reputation']","['Lead Data Science solutions from beginning to end', 'Deliver with independence on challenging large-scale problems with complexity and ambiguity', 'Write code (Python, R, Scala, SQL, etc.)', 'to obtain, manipulate, and analyze data', 'Build Machine Learning and statistical models to solve specific business problems', 'Retrieve, synthesize, and present critical data in a format that is immediately useful to answering specific questions or improving system performance', 'Analyze historical data to identify trends and support optimal decision making', 'Apply statistical and machine learning knowledge to specific business problems and data', 'Formalize assumptions about how our systems should work, create statistical definitions of outliers, and develop methods to systematically identify outliers', 'Work out why such examples are outliers and define if any actions needed', 'Given anecdotes about anomalies or generate automatic scripts to define anomalies, deep dive to explain why they happen, and identify fixes', 'Build decision-making models and propose effective solutions for the business problems you define', 'Conduct written and verbal presentations to share insights to audiences of varying levels of technical sophistication', ""Define a long-term science vision for our advertising business, driven from our customers' needs, translating that direction into specific plans for research and applied scientists, as well as engineering and product teams"", 'This role combines science leadership, organizational ability, technical strength, product focus, and business understanding']",True,[],,"['SQL', 'Python', 'R', 'Scala', 'Statistical Models', 'Multinomial Logistic Regression', 'Machine Learning', 'Data Pipelines', 'Data Visualization', 'Anomaly Detection']","SQL: Used for querying and manipulating large-scale advertising data to extract insights and support decision making.; Python: Employed for scripting, data manipulation, and building machine learning models to solve business problems.; R: Utilized for statistical analysis and building models to analyze advertising data and identify trends.; Scala: Used as a programming language for data processing and analysis within the data science workflow.; Statistical Models: Applied to formalize assumptions, detect outliers, and analyze historical data to improve advertising system performance.; Multinomial Logistic Regression: A specific statistical model used to address classification problems within advertising data.; Machine Learning: Built and applied to develop predictive and decision-making models that solve specific business challenges in advertising.; Data Pipelines: Managed to ensure efficient data flow and processing for large-scale advertising datasets.; Data Visualization: Used tools like AWS QuickSight, Tableau, and R Shiny to present data insights and support decision making.; Anomaly Detection: Developed methods and scripts to identify and explain anomalies in advertising data to improve system reliability."
GswHAqACfpS8GXwSAAAAAA==,Senior Data Scientist - Full-time,"At Johnson & Johnson, we believe health is everything. Our strength in healthcare innovation empowers us to build a world where complex diseases are prevented, treated, and cured, where treatments are smarter and less invasive, and solutions are personal. Through our expertise in Innovative Medicine and MedTech, we are uniquely positioned to innovate across the full spectrum of healthcare solutions today to deliver the breakthroughs of tomorrow, and profoundly impact health for humanity. Learn more at https://www.jnj.com
• *Job Function:**

Data Analytics & Computational Sciences
• *Job Sub** **Function:**

Data Science
• *Job Category:**

Scientific/Technology
• *All Job Posting Locations:**

Titusville, New Jersey, United States of America
• *Job Description:**

We are searching for the best talent for Senior Data Scientist to be in Titusville, NJ.

Our expertise in Innovative Medicine is informed and inspired by patients, whose insights fuel our science-based advancements. Visionaries like you work on teams that save lives by developing the medicines of tomorrow.

Join us in developing treatments, finding cures, and pioneering the path from lab to life while championing patients every step of the way.

Learn more at https://www.jnj.com/innovative-medicine
• *The Commercial Data Sciences Team** is looking for an extraordinary scientist who is passionate about crafting, developing, and fielding data science solutions that drive impact for patients and for Johnson & Johnson. There are many ways to explore and analyze data, and this powers the enthusiasm and passion of data scientists at J&J as many business units are eager to use the data to build business value.
• *You will be responsible for:**

This role needs someone who stays on the cutting edge of artificial intelligence, data science, and advanced analytics research through novel project execution and development of algorithms that influence decisions at various levels in the organization, with main focus on omnichannel sales and marketing optimization, but also including distribution demands, patient/payer analytics, commercial strategy, and related commercially focused model development.

The role requires both a broad knowledge of existing AI-type algorithms and the ingenuity to invent and customize when necessary. You will lead and deliver projects and develop solutions that in turn deliver insights. You will also work closely with cross departmental teams across business and technology to understand how best to solve complex problems. You will be a member of a highly collaborative and supportive team, which is part of a broader dynamic and accomplished organization that supports multiple therapeutic areas and commercial functions.

Come join us in our mission to transform the future of health!
• *Qualifications / Requirements:**

+ Ph.D. with 2+ years of experience, or M.S. with 5+ years, B.S. with 7+ years of relevant pharma experience, with degree in Computer Sciences, Statistics, Machine Learning & Artificial Intelligence, Physics, Molecular Biology, Bioinformatics, Computational Informatics, Medical Informatics, Computational Biology or a related field.

+ Solid understanding of machine learning platforms/environments.

+ Experience with practical applications of AI-type algorithms, including machine learning techniques such as regression, decision trees, probability networks, association rules, clustering, neural networks, and/or Bayesian models.

+ Familiarity with large datasets, handling of healthcare relevant datasets and understanding of data analysis workflows.

+ Proficiency with one or more programming language such as Python or R.

+ Proficiency with SQL.

+ Experience delivering on data science projects using Machine learning and AI technologies, data mining and/or text mining.

+ Familiarity with working in a cloud-based technology stack.

+ Sophisticated communication skills and ability to translate complex methods and results to diverse audiences.

+ Strong ability to establish relationships with business partners and understand their needs.

+ Proven track record to deliver end-to-end machine learning projects from understanding business requirements, development, deployment, and management of post-launch operations

+ Experience with vendor management – ensuring timelines and expectations
• *Preferred Qualifications:**

+ Experience in the Commercial Pharmaceutical business.

+ Experience with Medical / Scientific Affairs functions, Evidence generation, Unmet Need identification

+ Experience in digital media and direct-to-consumer marketing

+ Familiarity of commercially available healthcare data sets.

+ Experience with PySpark.

+ Familiarity with usage of Generative AI for productivity improvement.

+ Familiarity with open-source and gated/paid model landscape
• *Other:**

+ This position will require up to 15% domestic travel.

Johnson & Johnson is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, national origin, disability, protected veteran status or other characteristics protected by federal, state or local law. We actively seek qualified candidates who are protected veterans and individuals with disabilities as defined under VEVRAA and Section 503 of the Rehabilitation Act.

Johnson and Johnson is committed to providing an interview process that is inclusive of our applicants’ needs. If you are an individual with a disability and would like to request an accommodation, please email the Employee Health Support Center (ra-employeehealthsup@its.jnj.com) or contact AskGS to be directed to your accommodation resource.

\#Li-Hybrid

\#JNJDataScience

\#JNJIMCommercial-DS

At Johnson & Johnson, we believe health is everything. Our strength in healthcare innovation empowers us to build a world where complex diseases are prevented, treated, and cured, where treatments are smarter and less invasive, and solutions are personal. Through our expertise in Innovative Medicine and MedTech, we are uniquely positioned to innovate across the full spectrum of healthcare solutions today to deliver the breakthroughs of tomorrow, and profoundly impact health for humanity. Learn more at https://www.jnj.com
• *Job Function:**

Data Analytics & Computational Sciences
• *Job Sub** **Function:**

Data Science
• *Job Category:**

Scientific/Technology
• *All Job Posting Locations:**

Titusville, New Jersey, United States of America
• *Job Description:**

We are searching for the best talent for Senior Data Scientist to be in Titusville, NJ.

Our expertise in Innovative Medicine is informed and inspired by patients, whose insights fuel our science-based advancements. Visionaries like you work on teams that save lives by developing the medicines of tomorrow.

Join us in developing treatments, finding cures, and pioneering the path from lab to life while championing patients every step of the way.

Learn more at https://www.jnj.com/innovative-medicine
• *The Commercial Data Sciences Team** is looking for an extraordinary scientist who is passionate about crafting, developing, and fielding data science solutions that drive impact for patients and for Johnson & Johnson. There are many ways to explore and analyze data, and this powers the enthusiasm and passion of data scientists at J&J as many business units are eager to use the data to build business value.
• *You will be responsible for:**

This role needs someone who stays on the cutting edge of artificial intelligence, data science, and advanced analytics research through novel project execution and development of algorithms that influence decisions at various levels in the organization, with main focus on omnichannel sales and marketing optimization, but also including distribution demands, patient/payer analytics, commercial strategy, and related commercially focused model development.

The role requires both a broad knowledge of existing AI-type algorithms and the ingenuity to invent and customize when necessary. You will lead and deliver projects and develop solutions that in turn deliver insights. You will also work closely with cross departmental teams across business and technology to understand how best to solve complex problems. You will be a member of a highly collaborative and supportive team, which is part of a broader dynamic and accomplished organization that supports multiple therapeutic areas and commercial functions.

Come join us in our mission to transform the future of health!
• *Qualifications / Requirements:**

+ Ph.D. with 2+ years of experience, or M.S. with 5+ years, B.S. with 7+ years of relevant pharma experience, with degree in Computer Sciences, Statistics, Machine Learning & Artificial Intelligence, Physics, Molecular Biology, Bioinformatics, Computational Informatics, Medical Informatics, Computational Biology or a related field.

+ Solid understanding of machine learning platforms/environments.

+ Experience with practical applications of AI-type algorithms, including machine learning techniques such as regression, decision trees, probability networks, association rules, clustering, neural networks, and/or Bayesian models.

+ Familiarity with large datasets, handling of healthcare relevant datasets and understanding of data analysis workflows.

+ Proficiency with one or more programming language such as Python or R.

+ Proficiency with SQL.

+ Experience delivering on data science projects using Machine learning and AI technologies, data mining and/or text mining.

+ Familiarity with working in a cloud-based technology stack.

+ Sophisticated communication skills and ability to translate complex methods and results to diverse audiences.

+ Strong ability to establish relationships with business partners and understand their needs.

+ Proven track record to deliver end-to-end machine learning projects from understanding business requirements, development, deployment, and management of post-launch operations

+ Experience with vendor management – ensuring timelines and expectations
• *Preferred Qualifications:**

+ Experience in the Commercial Pharmaceutical business.

+ Experience with Medical / Scientific Affairs functions, Evidence generation, Unmet Need identification

+ Experience in digital media and direct-to-consumer marketing

+ Familiarity of commercially available healthcare data sets.

+ Experience with PySpark.

+ Familiarity with usage of Generative AI for productivity improvement.

+ Familiarity with open-source and gated/paid model landscape
• *Other:**

+ This position will require up to 15% domestic travel.

Johnson & Johnson is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, national origin, disability, protected veteran status or other characteristics protected by federal, state or local law. We actively seek qualified candidates who are protected veterans and individuals with disabilities as defined under VEVRAA and Section 503 of the Rehabilitation Act.

Johnson and Johnson is committed to providing an interview process that is inclusive of our applicants’ needs. If you are an individual with a disability and would like to request an accommodation, please email the Employee Health Support Center (ra-employeehealthsup@its.jnj.com) or contact AskGS to be directed to your accommodation resource.

\#Li-Hybrid

\#JNJDataScience

\#JNJIMCommercial-DS",2025-07-25T14:00:00.000Z,2025-07-25,"['This role needs someone who stays on the cutting edge of artificial intelligence, data science, and advanced analytics research through novel project execution and development of algorithms that influence decisions at various levels in the organization, with main focus on omnichannel sales and marketing optimization, but also including distribution demands, patient/payer analytics, commercial strategy, and related commercially focused model development', 'The role requires both a broad knowledge of existing AI-type algorithms and the ingenuity to invent and customize when necessary', 'Ph.D. with 2+ years of experience, or M.S. with 5+ years, B.S. with 7+ years of relevant pharma experience, with degree in Computer Sciences, Statistics, Machine Learning & Artificial Intelligence, Physics, Molecular Biology, Bioinformatics, Computational Informatics, Medical Informatics, Computational Biology or a related field', 'Solid understanding of machine learning platforms/environments', 'Experience with practical applications of AI-type algorithms, including machine learning techniques such as regression, decision trees, probability networks, association rules, clustering, neural networks, and/or Bayesian models', 'Familiarity with large datasets, handling of healthcare relevant datasets and understanding of data analysis workflows', 'Proficiency with one or more programming language such as Python or R', 'Proficiency with SQL', 'Experience delivering on data science projects using Machine learning and AI technologies, data mining and/or text mining', 'Familiarity with working in a cloud-based technology stack', 'Sophisticated communication skills and ability to translate complex methods and results to diverse audiences', 'Strong ability to establish relationships with business partners and understand their needs', 'Proven track record to deliver end-to-end machine learning projects from understanding business requirements, development, deployment, and management of post-launch operations', 'Experience with vendor management – ensuring timelines and expectations', 'Experience in the Commercial Pharmaceutical business', 'Experience with Medical / Scientific Affairs functions, Evidence generation, Unmet Need identification', 'Experience in digital media and direct-to-consumer marketing', 'Familiarity of commercially available healthcare data sets', 'Experience with PySpark', 'Familiarity with usage of Generative AI for productivity improvement', 'Familiarity with open-source and gated/paid model landscape', 'This position will require up to 15% domestic travel', 'This role needs someone who stays on the cutting edge of artificial intelligence, data science, and advanced analytics research through novel project execution and development of algorithms that influence decisions at various levels in the organization, with main focus on omnichannel sales and marketing optimization, but also including distribution demands, patient/payer analytics, commercial strategy, and related commercially focused model development', 'The role requires both a broad knowledge of existing AI-type algorithms and the ingenuity to invent and customize when necessary', 'Ph.D. with 2+ years of experience, or M.S. with 5+ years, B.S. with 7+ years of relevant pharma experience, with degree in Computer Sciences, Statistics, Machine Learning & Artificial Intelligence, Physics, Molecular Biology, Bioinformatics, Computational Informatics, Medical Informatics, Computational Biology or a related field', 'Solid understanding of machine learning platforms/environments', 'Experience with practical applications of AI-type algorithms, including machine learning techniques such as regression, decision trees, probability networks, association rules, clustering, neural networks, and/or Bayesian models', 'Familiarity with large datasets, handling of healthcare relevant datasets and understanding of data analysis workflows', 'Proficiency with one or more programming language such as Python or R', 'Proficiency with SQL', 'Experience delivering on data science projects using Machine learning and AI technologies, data mining and/or text mining', 'Familiarity with working in a cloud-based technology stack', 'Sophisticated communication skills and ability to translate complex methods and results to diverse audiences', 'Strong ability to establish relationships with business partners and understand their needs', 'Proven track record to deliver end-to-end machine learning projects from understanding business requirements, development, deployment, and management of post-launch operations', 'Experience with vendor management – ensuring timelines and expectations', 'Experience in the Commercial Pharmaceutical business', 'Experience with Medical / Scientific Affairs functions, Evidence generation, Unmet Need identification', 'Experience in digital media and direct-to-consumer marketing', 'Familiarity of commercially available healthcare data sets', 'Experience with PySpark', 'Familiarity with usage of Generative AI for productivity improvement', 'Familiarity with open-source and gated/paid model landscape', 'This position will require up to 15% domestic travel']","['*You will be responsible for:*', 'You will lead and deliver projects and develop solutions that in turn deliver insights', 'You will also work closely with cross departmental teams across business and technology to understand how best to solve complex problems', 'You will be a member of a highly collaborative and supportive team, which is part of a broader dynamic and accomplished organization that supports multiple therapeutic areas and commercial functions', '*You will be responsible for:*', 'You will lead and deliver projects and develop solutions that in turn deliver insights', 'You will also work closely with cross departmental teams across business and technology to understand how best to solve complex problems', 'You will be a member of a highly collaborative and supportive team, which is part of a broader dynamic and accomplished organization that supports multiple therapeutic areas and commercial functions']",True,['Generative AI'],Generative AI: Familiarity with generative AI is preferred for productivity improvement in data science workflows.,"['Regression Models', 'Decision Trees', 'Probability Networks', 'Association Rules', 'Clustering', 'Neural Networks', 'Bayesian Models', 'Machine Learning Platforms', 'Python', 'R', 'SQL', 'Data Mining', 'Text Mining', 'Cloud-Based Technology Stack', 'PySpark']","Regression Models: Used as part of machine learning techniques to develop predictive models for commercial strategy and patient analytics.; Decision Trees: Applied as a machine learning method to support data science solutions in sales and marketing optimization.; Probability Networks: Utilized for modeling probabilistic relationships in healthcare and commercial data analysis.; Association Rules: Employed to discover relationships in large healthcare datasets for commercial insights.; Clustering: Used for unsupervised learning to segment data in patient/payer analytics and distribution demands.; Neural Networks: Implemented as part of machine learning algorithms to enhance predictive modeling in healthcare data.; Bayesian Models: Applied for probabilistic modeling and inference in healthcare and commercial data science projects.; Machine Learning Platforms: Platforms and environments leveraged to develop, deploy, and manage machine learning projects end-to-end.; Python: Primary programming language used for data analysis, machine learning model development, and data science workflows.; R: Programming language used for statistical analysis and data science projects.; SQL: Used for querying and managing large healthcare and commercial datasets.; Data Mining: Techniques applied to extract useful patterns and insights from healthcare and commercial data.; Text Mining: Used to analyze unstructured text data relevant to healthcare and commercial functions.; Cloud-Based Technology Stack: Infrastructure used to support scalable data science and machine learning operations.; PySpark: Tool used for big data processing and analytics within cloud environments."
0taZ7SRDFhgbfrKTAAAAAA==,Senior Data Scientist,"Senior Data Scientist

Virta Health is pioneering a new standard of care for people to reclaim their lives. We are in the midst of a public health crisis: obesity rates are at an all-time high and over half of US adults have type 2 diabetes or prediabetes, and despite billions spent on new treatments, outcomes are largely worse. Virta reverses these diseases and delivers life-changing results by pairing individualized nutrition with ongoing care from a clinical support team. We have raised over $350 million from top-tier investors, and partner with the largest health plans, employers, and government organizations to help their employees and members restore their health and take back their lives.

Role Overview

The Advanced Analytics & AI (AAA) team is accountable for both pioneering new classes of data that power our business, and ensuring that data is powerful, clear, correct and easy to use throughout the company. The team collaborates closely with the engineering, product development, commercial, and clinical teams to transform data into actionable insights that propel Virta's mission forward.

As a Senior Data Scientist on the AAA team, you will play a crucial role in shaping our data-driven decision making processes and in driving impactful insights that advance our mission. This role offers a unique blend of hands-on coding and strategic leadership, working closely in partnership with the Product Development group that supports adoption of our member-facing products. You will get a chance to work closely with stakeholders to create impactful data-driven reports and analyses that strengthen Virta’s value proposition.

Responsibilities
• Serve as data lead for the Adoption Squad:
• Understand the product – strategy, goals, roadmap, users – deeply enough to identify high-impact, strategic opportunities and risks.
• Use data to steer conversations: bring data-driven hypotheses, challenge assumptions, frame trade-offs, prioritize strategically.
• Translate vague product hunches into sharp analytical questions, and design the right approach to answer them.
• Be the source of truth for KPIs and product metrics: help define and monitor them, and identify trends and drivers.
• Drive decision making with data: Prioritize analyses that meaningfully inform product decisions and change outcomes, reframe analysis requests that won’t do that into ones that will, and design and deliver the resulting analyses properly and rapidly.
• Lead experimentation thoughtfully: guide the team on when and when not to experiment, help enable self-serve experimentation, and focus on frequent, small experiments to speed learning.
• Identify where product strategy and ideas could be better, more easily, or more quickly implemented with the help of AI (ML or GenAI), and help enable this integration.
• Show up as a collaborative leader, not simply a service provider, and help focus work on what matters most.
• Work end-to-end to translate clinical, member, and claims data from our data warehouse into actionable recommendations: work with stakeholders to design reports and dashboards that answer real business questions, design the data flows to support these, and build the required data transformation pipelines.

Must-Haves
• Experience working at a digital health or similar startup, preferably during the growth phase, in order to function effectively in a fast-paced, rapidly changing environment.
• 7+ years of experience in a Healthcare Analytics or Data Science role, working with large datasets and conducting statistical and quantitative modeling, melding analytics with strong programming, data mining, clustering and segmentation.
• 5+ years of work experience working data science and visualization tools (SQL, R, and/or Python)
• Advanced understanding of data storage, ETL frameworks, data transformation, and validation
• Experience in building BI dashboards using tools such as Looker or Tableau
• Ability to explain technology, techniques and approaches to others

Nice-to-Haves
• Experience leading cross-functional efforts to build scalable systems and data pipelines, working with complex data structures
• Understanding of Generative AI concepts and basic usage of GenAI tools (ChatGPT, Claude, etc.)
• Experience building pipelines using dbt
• Demonstrated project management experience

90 Day Plan

Within your first 90 days at Virta, we expect you will do the following:
• Familiarize yourself with the Advanced Analytics & AI team roles and responsibilities. Get a pulse on team structure, key stakeholders, and areas for opportunity with an eye towards scalability and standardization.
• Integrate with the Adoption Squad to understand team dynamics, analyze key product features and data pipelines, and familiarize yourself with the Squad’s product roadmap
• Analyze current member journey to understand Virta’s technology ecosystem
• Meet cross-functional stakeholders to understand how their business needs align with Squad and Team goals
• Identify at least 1 area of opportunity to leverage GenAI to increase team efficiency or improve our processes
• Teach and inspire your team members through knowledge sharing, pair programming, and giving feedback during code reviews

Values-driven culture

Virta’s company values drive our culture, so you’ll do well if:
• You put people first and take care of yourself, your peers, and our patients equally
• You have a strong sense of ownership and take initiative while empowering others to do the same
• You prioritize positive impact over busy work
• You have no ego and understand that everyone has something to bring to the table regardless of experience
• You appreciate transparency and promote trust and empowerment through open access of information
• You are evidence-based and prioritize data and science over seniority or dogma
• You take risks and rapidly iterate

Is this role not quite what you're looking for? Join our Talent Community and follow us on Linkedin to stay connected!

Virta has a location based compensation structure. Starting pay will be based on a number of factors and commensurate with qualifications & experience. For this role, the compensation range is $167,249 - $216,000. Information about Virta’s benefits is on our Careers page at: https://www.virtahealth.com/careers.

As part of your duties at Virta, you may come in contact with sensitive patient information that is governed by HIPAA. Throughout your career at Virta, you will be expected to follow Virta's security and privacy procedures to ensure our patients' information remains strictly confidential. Security and privacy training will be provided.

As a remote-first company, our team is spread across various locations with office hubs in Denver and San Francisco.
Clinical roles: We currently do not hire in the following states: AK, HI, RI
Corporate roles: We currently do not hire in the following states: AK, AR, DE, HI, ME, MS, NM, OK, SD, VT, WI.

#LI-remote",2025-07-19T00:00:00.000Z,2025-07-25,"['Experience working at a digital health or similar startup, preferably during the growth phase, in order to function effectively in a fast-paced, rapidly changing environment', '7+ years of experience in a Healthcare Analytics or Data Science role, working with large datasets and conducting statistical and quantitative modeling, melding analytics with strong programming, data mining, clustering and segmentation', '5+ years of work experience working data science and visualization tools (SQL, R, and/or Python)', 'Advanced understanding of data storage, ETL frameworks, data transformation, and validation', 'Experience in building BI dashboards using tools such as Looker or Tableau', 'Ability to explain technology, techniques and approaches to others', 'Experience leading cross-functional efforts to build scalable systems and data pipelines, working with complex data structures', 'Understanding of Generative AI concepts and basic usage of GenAI tools (ChatGPT, Claude, etc.)', 'Experience building pipelines using dbt', 'Demonstrated project management experience', 'You have a strong sense of ownership and take initiative while empowering others to do the same', 'You prioritize positive impact over busy work', 'You have no ego and understand that everyone has something to bring to the table regardless of experience', 'You appreciate transparency and promote trust and empowerment through open access of information', 'You are evidence-based and prioritize data and science over seniority or dogma', 'You take risks and rapidly iterate']","['As a Senior Data Scientist on the AAA team, you will play a crucial role in shaping our data-driven decision making processes and in driving impactful insights that advance our mission', 'You will get a chance to work closely with stakeholders to create impactful data-driven reports and analyses that strengthen Virta’s value proposition', 'Serve as data lead for the Adoption Squad:', 'Understand the product – strategy, goals, roadmap, users – deeply enough to identify high-impact, strategic opportunities and risks', 'Use data to steer conversations: bring data-driven hypotheses, challenge assumptions, frame trade-offs, prioritize strategically', 'Translate vague product hunches into sharp analytical questions, and design the right approach to answer them', 'Be the source of truth for KPIs and product metrics: help define and monitor them, and identify trends and drivers', 'Drive decision making with data: Prioritize analyses that meaningfully inform product decisions and change outcomes, reframe analysis requests that won’t do that into ones that will, and design and deliver the resulting analyses properly and rapidly', 'Lead experimentation thoughtfully: guide the team on when and when not to experiment, help enable self-serve experimentation, and focus on frequent, small experiments to speed learning', 'Identify where product strategy and ideas could be better, more easily, or more quickly implemented with the help of AI (ML or GenAI), and help enable this integration', 'Show up as a collaborative leader, not simply a service provider, and help focus work on what matters most', 'Work end-to-end to translate clinical, member, and claims data from our data warehouse into actionable recommendations: work with stakeholders to design reports and dashboards that answer real business questions, design the data flows to support these, and build the required data transformation pipelines', 'Familiarize yourself with the Advanced Analytics & AI team roles and responsibilities', 'Get a pulse on team structure, key stakeholders, and areas for opportunity with an eye towards scalability and standardization', 'Integrate with the Adoption Squad to understand team dynamics, analyze key product features and data pipelines, and familiarize yourself with the Squad’s product roadmap', 'Analyze current member journey to understand Virta’s technology ecosystem', 'Meet cross-functional stakeholders to understand how their business needs align with Squad and Team goals', 'Identify at least 1 area of opportunity to leverage GenAI to increase team efficiency or improve our processes', 'Teach and inspire your team members through knowledge sharing, pair programming, and giving feedback during code reviews']",True,"['Generative AI', 'GenAI Tools']",Generative AI: Identified as an opportunity to improve team efficiency and product strategy through AI integration.; GenAI Tools: Basic usage of tools like ChatGPT and Claude to support AI-driven enhancements in workflows.,"['Statistical and Quantitative Modeling', 'Data Mining', 'Clustering and Segmentation', 'SQL', 'R', 'Python', 'ETL Frameworks', 'Data Transformation and Validation', 'BI Dashboards', 'Data Pipelines', 'dbt', 'Experimentation and A/B Testing']","Statistical and Quantitative Modeling: Used to analyze large healthcare datasets and derive insights for decision making and product strategy.; Data Mining: Applied to extract meaningful patterns and segmentations from complex clinical and member data.; Clustering and Segmentation: Techniques used to group similar data points for targeted analysis and personalized healthcare insights.; SQL: Utilized for querying and managing data within Virta’s data warehouse to support reporting and analysis.; R: Used as a programming tool for statistical analysis and data visualization in healthcare analytics.; Python: Employed for data science tasks including data transformation, analysis, and building data pipelines.; ETL Frameworks: Applied to extract, transform, and load clinical and claims data into usable formats for analysis.; Data Transformation and Validation: Processes to ensure data quality and readiness for accurate reporting and decision making.; BI Dashboards: Built using tools like Looker and Tableau to visualize KPIs and product metrics for stakeholders.; Data Pipelines: Designed and maintained to automate data flows from raw sources to actionable insights and dashboards.; dbt: Used to build and manage scalable data transformation pipelines supporting analytics workflows.; Experimentation and A/B Testing: Guided to enable frequent, small experiments that inform product decisions and accelerate learning."
4xzCSCAbsA-A_pxzAAAAAA==,Sr Data Scientist,"Data Science is at the core of our business. Our Data Scientists have dedicated themselves to excellence in applied quantitative disciplines such as mathematics, statistics and physics. We are seeking Senior Data Scientists to join us in our attempt to solve the extremely challenging problem of modeling and predicting the financial markets using sophisticated machine learning techniques. If you are passionate about collaborating with a world-renowned team of Data Scientists, Engineers and Researchers Voloridge could be the home for you.

You will work alongside prominent Data Scientists, Kaggle Grandmasters and a KDD cup winner at an award-winning investment management firm managing over $8B in assets. We reward our employees with an exceptional compensation package that includes wealthy benefit plans and profit-sharing bonuses. Our office in beautiful Jupiter, Florida has water views, fully stocked kitchens with fresh fruit, snacks and salad bars, lounge and gaming areas, onsite massage rooms, free garage parking and more. We seek out only the best of the best talent to join our brilliant, collaborative, and hard-working team and boast a retention rate of 92%.

Job Responsibilities
• Building and evaluating modern numerical/modeling techniques
• Working daily with complex, large-scale datasets
• Collaborative research projects requiring deep thinking, technical skills, and ingenuity
• Keeping abreast of the latest research related to data science

Minimum Requirements
• Deep understanding of modern machine learning techniques and algorithms
• Must demonstrate exceptional aptitude in descriptive and inferential statistics
• Extremely detail-oriented and self-motivated
• Experience with time series data
• Extensive experience working with large data
• Creative thinker and self-learner, able to demonstrate extraordinary critical thinking and analytical skills
• Competent skills in programming languages such as Python, R, C/#/++
• Ability to communicate actionable results with present senior leadership
• Advanced degree in Physics, Statistics, Mathematics or other quantitative disciplines or equivalent experience
• Ability to work onsite in our Jupiter, FL office

Preferred Skills and Previous Experience
• Outstanding achievements such as Math competitions, Kaggle – Grandmaster/Master, exceptional scores on SAT/GRE/LSAT, Chess Grandmaster, etc.
• Experience with relational SQL databases

Compensation and Benefits
• Relocation assistance available for the right candidate
• Highly competitive base salary
• Profit sharing bonus
• Health, dental, vision, life, and disability insurance
• 401K

Licenses Required None required

Additional Information

Voloridge Investment Management is an SEC registered investment advisor. A private investment company founded in 2009, our mission is to deliver superior risk-adjusted returns for qualified investors, using advanced proprietary modeling technology, conservative investment tactics and sophisticated risk management. Our market neutral equities strategy takes both long and short positions in the most actively traded equities, and is designed to capture alpha while limiting exposure to directional markets risks. Our futures strategy takes both long and short positions in the most actively traded global futures and is also built to maximize alpha captured across all futures markets traded while capping exposure to any sector at a given time.

Voloridge Investment Management is an Equal Opportunity Employer. All qualified applicants are encouraged to apply and will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other legally protected characteristic or status.",,2025-07-25,"['Deep understanding of modern machine learning techniques and algorithms', 'Must demonstrate exceptional aptitude in descriptive and inferential statistics', 'Extremely detail-oriented and self-motivated', 'Experience with time series data', 'Extensive experience working with large data', 'Creative thinker and self-learner, able to demonstrate extraordinary critical thinking and analytical skills', 'Competent skills in programming languages such as Python, R, C/#/++', 'Ability to communicate actionable results with present senior leadership', 'Advanced degree in Physics, Statistics, Mathematics or other quantitative disciplines or equivalent experience', 'Ability to work onsite in our Jupiter, FL office', 'Licenses Required None required']","['Building and evaluating modern numerical/modeling techniques', 'Working daily with complex, large-scale datasets', 'Collaborative research projects requiring deep thinking, technical skills, and ingenuity', 'Keeping abreast of the latest research related to data science']",True,[],,"['Machine Learning', 'Descriptive and Inferential Statistics', 'Time Series Analysis', 'Large-Scale Data Handling', 'Python', 'R', 'SQL', 'Numerical Modeling Techniques']","Machine Learning: Used to model and predict financial markets through sophisticated algorithms and techniques.; Descriptive and Inferential Statistics: Applied to analyze and interpret data for actionable insights in financial modeling.; Time Series Analysis: Experience with time series data is essential for modeling financial market trends and forecasting.; Large-Scale Data Handling: Daily work involves managing and analyzing complex, large datasets relevant to financial markets.; Python: Programming language used for data analysis, modeling, and implementing machine learning techniques.; R: Programming language utilized for statistical analysis and data science tasks.; SQL: Used for querying and managing relational databases containing financial data.; Numerical Modeling Techniques: Building and evaluating advanced numerical models to support financial market predictions."
BBYOQrTo6n_mgd3XAAAAAA==,"Senior Data Scientist, Specialist Senior - SFL Scientific - Full-time","Senior Data Scientist, Specialist Senior - SFL Scientific

Our Deloitte Strategy & Transactions team helps guide clients through their most critical moments and transformational initiatives. From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability. Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journey-before, during, and after any major transformational projects or transactions.

SFL Scientific, a Deloitte Business, is a U.S. based, data science consulting firm specializing in building industry-specific, artificial intelligence (AI) technologies.

We are hiring a Senior Data Scientist to collaborate directly with clients to design and develop novel projects and solutions. Join a rapidly growing team of professionals working to build a world-class data science practice focused on solving complex and R&D problems.

Recruiting for this role ends on 7/31/2025.

Work You'll Do

As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services. You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions.

Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation. Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills.

+ Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production

+ Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives

+ Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization

+ Validate AI models and algorithm via code reviews, unit, and integration tests

+ Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives

+ Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives

The Team

Our Strategy offering architects bold strategies to achieve business and mission goals, enabling growth, competitive advantage, technology modernization, and continuous digital and AI transformation.

SFL Scientific, a Deloitte Business, is a data science professional services practice focused on strategy, technology, and solving business challenges with Artificial Intelligence (AI). The team has a proven track record serving large, market-leading organizations in the private and public sectors, successfully delivering high-quality, novel and complex projects, and offering deep domain and scientific capabilities. Made up of experienced AI strategists, data scientists, and AI engineers, they serve as trusted advisors to executives, helping them understand and evaluate new and essential areas for AI investment and identify unique opportunities to transform their businesses.

Qualifications:

+ Master's or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)

+ 3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)

+ 3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments

+ 3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow

+ 3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads

+ Live within commuting distance to one of Deloitte's consulting offices

+ Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve

+ Limited immigration sponsorship may be available

Preferred:

+ 2+ years of experience working in a client-facing, consulting environment

+ 2+ years of experience leading project/client engagement teams in the execution of complex AI data science solutions

+ 1+ year of experience with LLM/GenAI use cases and developing RAG solutions, tools, and services (i.e., LangChain, LangGraph, MCP, etc.)

+ 1+ year of experience with AWS Sagemaker or AWS ML Studio

Information for applicants with a need for accommodation: https://www2.deloitte.com/us/en/pages/careers/articles/join-deloitte-assistance-for-disabled-applicants.html

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $107,600 to $198,400.

You may also be eligible to participate in a discretionary annual incentive program, subject to the rules governing the program, whereby an award, if any, depends on various factors, including, without limitation, individual and organizational performance.

#MonitorDeloitte

#DeloitteJobs

#StrategyConsulting

#DeloitteStrategy

#Strategy26

#SFL26

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.

Senior Data Scientist, Specialist Senior - SFL Scientific

Our Deloitte Strategy & Transactions team helps guide clients through their most critical moments and transformational initiatives. From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability. Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journey-before, during, and after any major transformational projects or transactions.

SFL Scientific, a Deloitte Business, is a U.S. based, data science consulting firm specializing in building industry-specific, artificial intelligence (AI) technologies.

We are hiring a Senior Data Scientist to collaborate directly with clients to design and develop novel projects and solutions. Join a rapidly growing team of professionals working to build a world-class data science practice focused on solving complex and R&D problems.

Recruiting for this role ends on 7/31/2025.

Work You'll Do

As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services. You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions.

Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation. Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills.

+ Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production

+ Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives

+ Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization

+ Validate AI models and algorithm via code reviews, unit, and integration tests

+ Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives

+ Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives

The Team

Our Strategy offering architects bold strategies to achieve business and mission goals, enabling growth, competitive advantage, technology modernization, and continuous digital and AI transformation.

SFL Scientific, a Deloitte Business, is a data science professional services practice focused on strategy, technology, and solving business challenges with Artificial Intelligence (AI). The team has a proven track record serving large, market-leading organizations in the private and public sectors, successfully delivering high-quality, novel and complex projects, and offering deep domain and scientific capabilities. Made up of experienced AI strategists, data scientists, and AI engineers, they serve as trusted advisors to executives, helping them understand and evaluate new and essential areas for AI investment and identify unique opportunities to transform their businesses.

Qualifications:

+ Master's or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)

+ 3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)

+ 3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments

+ 3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow

+ 3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads

+ Live within commuting distance to one of Deloitte's consulting offices

+ Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve

+ Limited immigration sponsorship may be available

Preferred:

+ 2+ years of experience working in a client-facing, consulting environment

+ 2+ years of experience leading project/client engagement teams in the execution of complex AI data science solutions

+ 1+ year of experience with LLM/GenAI use cases and developing RAG solutions, tools, and services (i.e., LangChain, LangGraph, MCP, etc.)

+ 1+ year of experience with AWS Sagemaker or AWS ML Studio

Information for applicants with a need for accommodation: https://www2.deloitte.com/us/en/pages/careers/articles/join-deloitte-assistance-for-disabled-applicants.html

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $107,600 to $198,400.

You may also be eligible to participate in a discretionary annual incentive program, subject to the rules governing the program, whereby an award, if any, depends on various factors, including, without limitation, individual and organizational performance.

#MonitorDeloitte

#DeloitteJobs

#StrategyConsulting

#DeloitteStrategy

#Strategy26

#SFL26

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.",2025-07-25T14:00:00.000Z,2025-07-25,"[""Master's or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)"", '3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)', '3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments', '3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow', '3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads', ""Live within commuting distance to one of Deloitte's consulting offices"", 'Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve', 'Limited immigration sponsorship may be available', ""Master's or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)"", '3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)', '3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments', '3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow', '3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads', ""Live within commuting distance to one of Deloitte's consulting offices"", 'Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve', 'Limited immigration sponsorship may be available']","['From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability', 'Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journey-before, during, and after any major transformational projects or transactions', 'As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services', 'You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions', 'Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation', 'Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills', 'Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production', 'Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives', 'Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization', 'Validate AI models and algorithm via code reviews, unit, and integration tests', 'Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives', 'Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives', 'From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability', 'Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journey-before, during, and after any major transformational projects or transactions', 'As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services', 'You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions', 'Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation', 'Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills', 'Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production', 'Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives', 'Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization', 'Validate AI models and algorithm via code reviews, unit, and integration tests', 'Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives', 'Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives']",True,"['Generative AI', 'Large Language Models', 'Retrieval-Augmented Generation', 'Prompt Engineering', 'LangChain', 'LangGraph', 'MCP', 'AWS SageMaker', 'AWS ML Studio']","Generative AI: Involved in developing and deploying generative AI use cases and solutions such as LLMs.; Large Language Models: Experience with LLMs for generative AI applications and client solutions.; Retrieval-Augmented Generation: Developing RAG solutions and tools to enhance generative AI capabilities.; Prompt Engineering: Designing and optimizing prompts for effective interaction with generative AI models.; LangChain: Framework used to build applications with LLMs and generative AI.; LangGraph: Tool for managing and orchestrating generative AI workflows and data.; MCP: Platform or tool related to managing generative AI pipelines and solutions.; AWS SageMaker: Cloud service used for building, training, and deploying machine learning and AI models, including generative AI.; AWS ML Studio: Cloud-based environment for developing and deploying AI/ML models, including generative AI workflows.","['Exploratory Data Analysis', 'Machine Learning', 'Deep Learning', 'Natural Language Processing', 'Time-Series Analysis', 'Computer Vision', 'Python', 'PyTorch', 'Model Validation', 'Model Deployment', 'Kubernetes', 'Docker', 'TensorRT', 'RAPIDs', 'Kubeflow', 'MLflow', 'Cloud Platforms']","Exploratory Data Analysis: Used to understand client data sets and operational requirements to design long-term data science solutions.; Machine Learning: Applied to develop AI/ML solutions, including research and implementation of novel approaches and model tuning.; Deep Learning: Utilized techniques such as CNNs, RNNs, and GANs for real-world projects including model performance validation.; Natural Language Processing: Employed for data analysis tasks involving text data as part of AI/ML algorithm development.; Time-Series Analysis: Used for analyzing sequential data as part of AI/ML algorithm development and data analysis.; Computer Vision: Applied in projects involving image data analysis and deep learning techniques.; Python: Primary programming language used for AI/ML algorithm development and data analysis.; PyTorch: Framework used for developing AI/ML algorithms and deep learning models.; Model Validation: Includes code reviews, unit testing, and integration testing to ensure AI/ML model quality.; Model Deployment: Deploying AI/ML models into production environments to deliver business impact.; Kubernetes: Used for deploying and optimizing machine learning models in scalable production environments.; Docker: Containerization tool used to package and deploy AI/ML models and applications.; TensorRT: Tool for optimizing deep learning model inference performance in production.; RAPIDs: Library used to accelerate data science and machine learning workflows on GPUs.; Kubeflow: Platform for managing machine learning workflows and model deployment on Kubernetes.; MLflow: Tool for managing the machine learning lifecycle including experimentation, reproducibility, and deployment.; Cloud Platforms: AWS, Azure, and GCP used to deploy and manage AI/ML workloads in cloud environments."
T-qb2uw_Nq1QFMu1AAAAAA==,Senior Data Scientist,"Senior Data Scientist

Virta Health is pioneering a new standard of care for people to reclaim their lives. We are in the midst of a public health crisis: obesity rates are at an all-time high and over half of US adults have type 2 diabetes or prediabetes, and despite billions spent on new treatments, outcomes are largely worse. Virta reverses these diseases and delivers life-changing results by pairing individualized nutrition with ongoing care from a clinical support team. We have raised over $350 million from top-tier investors, and partner with the largest health plans, employers, and government organizations to help their employees and members restore their health and take back their lives.

Role Overview

The Advanced Analytics & AI (AAA) team is accountable for both pioneering new classes of data that power our business, and ensuring that data is powerful, clear, correct and easy to use throughout the company. The team collaborates closely with the engineering, product development, commercial, and clinical teams to transform data into actionable insights that propel Virta's mission forward.

As a Senior Data Scientist on the AAA team, you will play a crucial role in shaping our data-driven decision making processes and in driving impactful insights that advance our mission. This role offers a unique blend of hands-on coding and strategic leadership, working closely in partnership with the Product Development group that supports adoption of our member-facing products. You will get a chance to work closely with stakeholders to create impactful data-driven reports and analyses that strengthen Virta’s value proposition.

Responsibilities
• Serve as data lead for the Adoption Squad:
• Understand the product – strategy, goals, roadmap, users – deeply enough to identify high-impact, strategic opportunities and risks.
• Use data to steer conversations: bring data-driven hypotheses, challenge assumptions, frame trade-offs, prioritize strategically.
• Translate vague product hunches into sharp analytical questions, and design the right approach to answer them.
• Be the source of truth for KPIs and product metrics: help define and monitor them, and identify trends and drivers.
• Drive decision making with data: Prioritize analyses that meaningfully inform product decisions and change outcomes, reframe analysis requests that won’t do that into ones that will, and design and deliver the resulting analyses properly and rapidly.
• Lead experimentation thoughtfully: guide the team on when and when not to experiment, help enable self-serve experimentation, and focus on frequent, small experiments to speed learning.
• Identify where product strategy and ideas could be better, more easily, or more quickly implemented with the help of AI (ML or GenAI), and help enable this integration.
• Show up as a collaborative leader, not simply a service provider, and help focus work on what matters most.
• Work end-to-end to translate clinical, member, and claims data from our data warehouse into actionable recommendations: work with stakeholders to design reports and dashboards that answer real business questions, design the data flows to support these, and build the required data transformation pipelines.

Must-Haves
• Experience working at a digital health or similar startup, preferably during the growth phase, in order to function effectively in a fast-paced, rapidly changing environment.
• 7+ years of experience in a Healthcare Analytics or Data Science role, working with large datasets and conducting statistical and quantitative modeling, melding analytics with strong programming, data mining, clustering and segmentation.
• 5+ years of work experience working data science and visualization tools (SQL, R, and/or Python)
• Advanced understanding of data storage, ETL frameworks, data transformation, and validation
• Experience in building BI dashboards using tools such as Looker or Tableau
• Ability to explain technology, techniques and approaches to others

Nice-to-Haves
• Experience leading cross-functional efforts to build scalable systems and data pipelines, working with complex data structures
• Understanding of Generative AI concepts and basic usage of GenAI tools (ChatGPT, Claude, etc.)
• Experience building pipelines using dbt
• Demonstrated project management experience

90 Day Plan

Within your first 90 days at Virta, we expect you will do the following:
• Familiarize yourself with the Advanced Analytics & AI team roles and responsibilities. Get a pulse on team structure, key stakeholders, and areas for opportunity with an eye towards scalability and standardization.
• Integrate with the Adoption Squad to understand team dynamics, analyze key product features and data pipelines, and familiarize yourself with the Squad’s product roadmap
• Analyze current member journey to understand Virta’s technology ecosystem
• Meet cross-functional stakeholders to understand how their business needs align with Squad and Team goals
• Identify at least 1 area of opportunity to leverage GenAI to increase team efficiency or improve our processes
• Teach and inspire your team members through knowledge sharing, pair programming, and giving feedback during code reviews

Values-driven culture

Virta’s company values drive our culture, so you’ll do well if:
• You put people first and take care of yourself, your peers, and our patients equally
• You have a strong sense of ownership and take initiative while empowering others to do the same
• You prioritize positive impact over busy work
• You have no ego and understand that everyone has something to bring to the table regardless of experience
• You appreciate transparency and promote trust and empowerment through open access of information
• You are evidence-based and prioritize data and science over seniority or dogma
• You take risks and rapidly iterate

Is this role not quite what you're looking for? Join our Talent Community and follow us on Linkedin to stay connected!

Virta has a location based compensation structure. Starting pay will be based on a number of factors and commensurate with qualifications & experience. For this role, the compensation range is $167,249 - $216,000. Information about Virta’s benefits is on our Careers page at: https://www.virtahealth.com/careers.

As part of your duties at Virta, you may come in contact with sensitive patient information that is governed by HIPAA. Throughout your career at Virta, you will be expected to follow Virta's security and privacy procedures to ensure our patients' information remains strictly confidential. Security and privacy training will be provided.

As a remote-first company, our team is spread across various locations with office hubs in Denver and San Francisco.
Clinical roles: We currently do not hire in the following states: AK, HI, RI
Corporate roles: We currently do not hire in the following states: AK, AR, DE, HI, ME, MS, NM, OK, SD, VT, WI.

#LI-remote",2025-07-19T00:00:00.000Z,2025-07-25,"['Experience working at a digital health or similar startup, preferably during the growth phase, in order to function effectively in a fast-paced, rapidly changing environment', '7+ years of experience in a Healthcare Analytics or Data Science role, working with large datasets and conducting statistical and quantitative modeling, melding analytics with strong programming, data mining, clustering and segmentation', '5+ years of work experience working data science and visualization tools (SQL, R, and/or Python)', 'Advanced understanding of data storage, ETL frameworks, data transformation, and validation', 'Experience in building BI dashboards using tools such as Looker or Tableau', 'Ability to explain technology, techniques and approaches to others', 'Experience leading cross-functional efforts to build scalable systems and data pipelines, working with complex data structures', 'Understanding of Generative AI concepts and basic usage of GenAI tools (ChatGPT, Claude, etc.)', 'Experience building pipelines using dbt', 'Demonstrated project management experience', 'You have a strong sense of ownership and take initiative while empowering others to do the same', 'You prioritize positive impact over busy work', 'You have no ego and understand that everyone has something to bring to the table regardless of experience', 'You appreciate transparency and promote trust and empowerment through open access of information', 'You are evidence-based and prioritize data and science over seniority or dogma', 'You take risks and rapidly iterate']","['As a Senior Data Scientist on the AAA team, you will play a crucial role in shaping our data-driven decision making processes and in driving impactful insights that advance our mission', 'You will get a chance to work closely with stakeholders to create impactful data-driven reports and analyses that strengthen Virta’s value proposition', 'Serve as data lead for the Adoption Squad:', 'Understand the product – strategy, goals, roadmap, users – deeply enough to identify high-impact, strategic opportunities and risks', 'Use data to steer conversations: bring data-driven hypotheses, challenge assumptions, frame trade-offs, prioritize strategically', 'Translate vague product hunches into sharp analytical questions, and design the right approach to answer them', 'Be the source of truth for KPIs and product metrics: help define and monitor them, and identify trends and drivers', 'Drive decision making with data: Prioritize analyses that meaningfully inform product decisions and change outcomes, reframe analysis requests that won’t do that into ones that will, and design and deliver the resulting analyses properly and rapidly', 'Lead experimentation thoughtfully: guide the team on when and when not to experiment, help enable self-serve experimentation, and focus on frequent, small experiments to speed learning', 'Identify where product strategy and ideas could be better, more easily, or more quickly implemented with the help of AI (ML or GenAI), and help enable this integration', 'Show up as a collaborative leader, not simply a service provider, and help focus work on what matters most', 'Work end-to-end to translate clinical, member, and claims data from our data warehouse into actionable recommendations: work with stakeholders to design reports and dashboards that answer real business questions, design the data flows to support these, and build the required data transformation pipelines', 'Familiarize yourself with the Advanced Analytics & AI team roles and responsibilities', 'Get a pulse on team structure, key stakeholders, and areas for opportunity with an eye towards scalability and standardization', 'Integrate with the Adoption Squad to understand team dynamics, analyze key product features and data pipelines, and familiarize yourself with the Squad’s product roadmap', 'Analyze current member journey to understand Virta’s technology ecosystem', 'Meet cross-functional stakeholders to understand how their business needs align with Squad and Team goals', 'Identify at least 1 area of opportunity to leverage GenAI to increase team efficiency or improve our processes', 'Teach and inspire your team members through knowledge sharing, pair programming, and giving feedback during code reviews']",True,"['Generative AI', 'GenAI Tools']",Generative AI: Explored for integration opportunities to improve team efficiency and enhance product strategy.; GenAI Tools: Basic usage of tools like ChatGPT and Claude to support AI-driven enhancements in workflows and processes.,"['Statistical and Quantitative Modeling', 'Data Mining', 'Clustering and Segmentation', 'SQL', 'R', 'Python', 'ETL Frameworks', 'Data Transformation and Validation', 'BI Dashboards', 'Data Pipelines', 'dbt', 'Experimentation and A/B Testing']","Statistical and Quantitative Modeling: Used to analyze large healthcare datasets and derive insights for decision making and product strategy.; Data Mining: Applied to extract meaningful patterns and segmentations from complex clinical and member data.; Clustering and Segmentation: Techniques used to group similar data points for targeted analysis and personalized healthcare insights.; SQL: Utilized for querying and managing data within the company’s data warehouse to support reporting and analysis.; R: Used as a programming tool for statistical analysis and data visualization in healthcare analytics.; Python: Employed for data science tasks including data transformation, analysis, and building data pipelines.; ETL Frameworks: Applied to extract, transform, and load clinical and claims data into usable formats for analysis.; Data Transformation and Validation: Processes to ensure data quality and readiness for accurate reporting and decision making.; BI Dashboards: Created using tools like Looker and Tableau to visualize KPIs and product metrics for stakeholders.; Data Pipelines: Built and maintained to automate data flows from raw sources to actionable insights and dashboards.; dbt: Used to build and manage data transformation pipelines supporting scalable analytics.; Experimentation and A/B Testing: Guided and enabled to validate hypotheses and inform product decisions through frequent, small experiments."
MH0O1Q6IiBqdB79WAAAAAA==,Data Scientist - Sr. Associate,"We have an exciting opportunity for a Data Scientist - Senior Associate to join our Home Lending Data & Analytics team. This role offers the chance to drive meaningful insights that enable the firm to deliver incremental value and an outstanding customer experience. Join us to leverage your analytical skills and business acumen in a dynamic environment that fosters career growth and innovation.

As a Data Scientist - Senior Associate within the Home Lending Data & Analytics team, you will undertake advanced analytics to derive actionable insights supporting our Home Lending Sales strategy and optimization. You will combine quantitative analysis, business acumen, and a focus on problem-solving to drive meaningful insights that enable the firm to drive incremental value and an outstanding customer experience.

Collaborate with Sales, Marketing, Product, Finance, and other Data & Analytics partners to deliver data-driven solutions for complex business challenges. Your work will involve sourcing and integrating data from various platforms to narrate the story of past performance and provide guidance on enhancing Mortgage sales strategy optimization.

Job Responsibilities
• Collaborate with Sales, Marketing, Product, Finance, and other Data & Analytics partners to agree on priorities and deliver data-driven solutions for complex business challenges.
• Source and integrate data from various platforms to narrate the story of past performance and provide guidance on enhancing Mortgage sales strategy optimization.
• Perform descriptive, diagnostic, and predictive analyses to uncover trends, patterns, and actionable business insights.
• Identify opportunities to develop and enhance business intelligence dashboards & automated reporting to facilitate decision-making for business partners.
• Conduct deep-dive analyses to identify and quantify drivers of business performance and recommend actions to improve KPIs.
• Build analytical frameworks to support strategic and complex business priorities.
• Collaborate with team members and business/technical partners on the use of AI & Machine Learning to automate and develop innovative solutions for the HL business.

Required Qualifications, Capabilities, and Skills
• Undergraduate or advanced degree in an analytical field (e.g., Computer Science, Economics, Mathematics, Statistics, Engineering, Operations Research) and 2+ years of experience in data analysis/data science.
• Proficiency using SQL, MS Excel, and Tableau for data manipulation, analysis, and visualization.
• Critical thinking and proven ability to connect data analysis to business strategies and deliver results that drive measurable impact.
• Excellent communication skills to effectively summarize & deliver actionable insights to business stakeholders.
• Strong ability to analyze complex problems, dive deep into data, and design innovative solutions. A relentless curiosity to understand the ""why"" behind data patterns.

Preferred Qualifications, Capabilities, and Skills
• Experience with cloud platforms (e.g., AWS, Snowflake) for large-scale data processing, plus Salesforce for lead management & sales.
• Proficiency in Python coding.
• Background in financial services, plus experience in the Mortgage Business.
• **Relocation assistance is not available for this role.",2025-07-21T00:00:00.000Z,2025-07-25,"['Undergraduate or advanced degree in an analytical field (e.g., Computer Science, Economics, Mathematics, Statistics, Engineering, Operations Research) and 2+ years of experience in data analysis/data science', 'Proficiency using SQL, MS Excel, and Tableau for data manipulation, analysis, and visualization', 'Critical thinking and proven ability to connect data analysis to business strategies and deliver results that drive measurable impact', 'Excellent communication skills to effectively summarize & deliver actionable insights to business stakeholders', 'Strong ability to analyze complex problems, dive deep into data, and design innovative solutions', 'A relentless curiosity to understand the ""why"" behind data patterns']","['As a Data Scientist - Senior Associate within the Home Lending Data & Analytics team, you will undertake advanced analytics to derive actionable insights supporting our Home Lending Sales strategy and optimization', 'You will combine quantitative analysis, business acumen, and a focus on problem-solving to drive meaningful insights that enable the firm to drive incremental value and an outstanding customer experience', 'Collaborate with Sales, Marketing, Product, Finance, and other Data & Analytics partners to deliver data-driven solutions for complex business challenges', 'Your work will involve sourcing and integrating data from various platforms to narrate the story of past performance and provide guidance on enhancing Mortgage sales strategy optimization', 'Collaborate with Sales, Marketing, Product, Finance, and other Data & Analytics partners to agree on priorities and deliver data-driven solutions for complex business challenges', 'Source and integrate data from various platforms to narrate the story of past performance and provide guidance on enhancing Mortgage sales strategy optimization', 'Perform descriptive, diagnostic, and predictive analyses to uncover trends, patterns, and actionable business insights', 'Identify opportunities to develop and enhance business intelligence dashboards & automated reporting to facilitate decision-making for business partners', 'Conduct deep-dive analyses to identify and quantify drivers of business performance and recommend actions to improve KPIs', 'Build analytical frameworks to support strategic and complex business priorities', 'Collaborate with team members and business/technical partners on the use of AI & Machine Learning to automate and develop innovative solutions for the HL business']",True,['Machine Learning'],Machine Learning: Collaborated with team members to apply machine learning techniques for automating and innovating solutions in the Home Lending business.,"['Descriptive Analysis', 'Diagnostic Analysis', 'Predictive Analysis', 'SQL', 'Tableau', 'MS Excel', 'Python', 'Business Intelligence Dashboards', 'Data Integration', 'Analytical Frameworks', 'Cloud Platforms']",Descriptive Analysis: Used to summarize past data and understand historical performance in the Home Lending Sales strategy.; Diagnostic Analysis: Applied to investigate causes behind trends and patterns in mortgage sales data.; Predictive Analysis: Employed to forecast future trends and support optimization of mortgage sales strategies.; SQL: Used for data manipulation and querying across various data platforms.; Tableau: Utilized to create business intelligence dashboards and visualizations for decision-making.; MS Excel: Used for data analysis and manipulation tasks.; Python: Used for coding and implementing data analysis and automation solutions.; Business Intelligence Dashboards: Developed to automate reporting and facilitate data-driven decision-making for business partners.; Data Integration: Sourcing and combining data from multiple platforms to provide comprehensive insights.; Analytical Frameworks: Built to support strategic and complex business priorities in mortgage sales optimization.; Cloud Platforms: Experience with AWS and Snowflake for large-scale data processing.
Md1AP1lvzyB3sM65AAAAAA==,Senior Data Scientist (Machine Learning Engineer),"Climate X is seeking a Senior Data Scientist/Machine Learning Engineer to enhance their NLP model and collaborate with an interdisciplinary team. The role involves developing machine learning models, performing statistical analysis, and visualizing data to support climate adaptation efforts. Candidates should have experience in data science, ML algorithms, and cloud services. The position is fully remote, allowing for contributions to a purpose-driven climate data company.
Senior Data Scientist/Machine Learning Engineer

About Us

Climate X is a purpose-driven climate adaptation data company set to revolutionise how the world manages assets, property, and infrastructure. 

We apply cutting-edge, peer-reviewed science to help prevent the worst impacts of climate change. We combine climate projections, remote sensing observations, and modelling to project the frequency and severity of physical climate risks such as floods, subsidence, storms, etc.

Our SaaS platform lets financial institutions and real estate firms look at future climate pathways to:
• help identify how property/company assets could be damaged by severe weather events and
• what that damage might do to the asset valuations.
• become more resilient to climate change and make smarter investment and lending decisions.

We advocate diversity with our founders, team, and investors from various backgrounds.
We’re not building just a team but a place of innovation where problem solving, and fun coexist to address the most significant challenge our society is facing now. 

The impact you’ll own

As a Senior Data Scientist at Climate X, you will join an interdisciplinary team of other Data Scientists, Climate Scientists and Geospatial experts, collaborating closely with our Engineering and Product teams to deliver impactful products to our clients.

This role will support our NLP model, a core product within the business. This will involve developing an existing code base, research time for exploring new techniques and algorithms, fine-tuning LLM models on domain-specific datasets to enhance the performance of our existing model, perform statistical analysis and techniques for model evaluation, analyse text data to extract meaningful insights and trends and create visualizations to communicate findings and facilitate understanding of the model across the business and our clients.

Essential Skills
• Experience in a product focused Data Science role with previous experience building end-to-end machine learning models.
• Strong experience with ML algorithms and techniques (e.g., regression, classification, clustering), using ML packages in Python (such as sklearn, spaCy, NumPy, SciPy or others).
• Experience with version control systems like Git for managing code changes and collaborating with team members. Knowledge of CI/CD pipelines (e.g. GitHub Actions) is a plus.
• Experience with data visualisation tools and libraries (e.g., Matplotlib, Seaborn, Tableau, Power BI).
• Experience with cloud services (e.g., AWS, Google Cloud Platform, Azure) for data storage and processing.
• Ability to work with cross-functional teams using strong problem-solving skills and share insights to diverse audiences.

Nice to have
• Experience with web scraping using Python (such as BeautifulSoup, Scrapy, Selenium, Requests or others) is a plus.
• Exposure to MLOps frameworks (such as MLFlow, Weights and Biases).
• Knowledge of the financial services or real estate domain from a climate risk perspective, to inform a basic understanding of where data science is being applied, allowing for better context and interpretation of results.
• Experience with processing and analysing geospatial data using Python (geopandas, GDAL, etc.) and/or other GIS software (such as QGIS) is a plus.

Benefits

🌍 Contribute to a business making purposeful impact related to climate change

💡 Monthly training & conference budget to help you upskill and develop your career (£1,000 per year)

📈 6 monthly appraisals and 12 monthly pay reviews

💰 Pension contribution scheme

🏡 Flexible hours and hybrid working (3 days/week in office; core hours 10am-4pm)

🏥 Mental Health and Wellbeing support via Oliva

🏖 25 days holiday, plus Bank Holidays, annual 3-day Christmas-closure, and half day on your birthday (36.5 days total!)

🏏 Optional quarterly socials, dinners, and fun nights out

🥐 A fully stocked supply of snacks, fruit, and refreshments for the days when you are in the office

🚴 Cycle to work scheme via gogeta

🍼 Enhanced maternity and paternity

🐶 Pawternity

🐕 Dog friendly office (official residence of Alfie, Chief Mischief Officer)

Equal Opportunities

Climate X are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. We are committed to creating an inclusive environment for all employees and welcome applications from individuals of all backgrounds.",,2025-07-25,"['Candidates should have experience in data science, ML algorithms, and cloud services', 'Experience in a product focused Data Science role with previous experience building end-to-end machine learning models', 'Strong experience with ML algorithms and techniques (e.g., regression, classification, clustering), using ML packages in Python (such as sklearn, spaCy, NumPy, SciPy or others)', 'Experience with version control systems like Git for managing code changes and collaborating with team members', 'Knowledge of CI/CD pipelines (e.g', 'Experience with data visualisation tools and libraries (e.g., Matplotlib, Seaborn, Tableau, Power BI)', 'Experience with cloud services (e.g., AWS, Google Cloud Platform, Azure) for data storage and processing', 'Ability to work with cross-functional teams using strong problem-solving skills and share insights to diverse audiences', 'Exposure to MLOps frameworks (such as MLFlow, Weights and Biases)', 'Knowledge of the financial services or real estate domain from a climate risk perspective, to inform a basic understanding of where data science is being applied, allowing for better context and interpretation of results']","['The role involves developing machine learning models, performing statistical analysis, and visualizing data to support climate adaptation efforts', 'help identify how property/company assets could be damaged by severe weather events and', 'what that damage might do to the asset valuations', 'become more resilient to climate change and make smarter investment and lending decisions', 'As a Senior Data Scientist at Climate X, you will join an interdisciplinary team of other Data Scientists, Climate Scientists and Geospatial experts, collaborating closely with our Engineering and Product teams to deliver impactful products to our clients', 'This role will support our NLP model, a core product within the business', 'This will involve developing an existing code base, research time for exploring new techniques and algorithms, fine-tuning LLM models on domain-specific datasets to enhance the performance of our existing model, perform statistical analysis and techniques for model evaluation, analyse text data to extract meaningful insights and trends and create visualizations to communicate findings and facilitate understanding of the model across the business and our clients', '🏏 Optional quarterly socials, dinners, and fun nights out']",True,"['Large Language Models', 'Natural Language Processing']",Large Language Models: Fine-tuning domain-specific LLMs to enhance the performance of the company's NLP model.; Natural Language Processing: Supporting and improving the core NLP model to extract insights from text data related to climate risk.,"['Regression', 'Classification', 'Clustering', 'Machine Learning Models', 'Statistical Analysis', 'Data Visualization', 'Python Data Science Libraries', 'SQL', 'Cloud Services', 'Version Control', 'CI/CD Pipelines', 'MLOps Frameworks', 'Web Scraping', 'Geospatial Data Processing']","Regression: Used as one of the ML algorithms to build predictive models supporting climate adaptation efforts.; Classification: Applied as an ML technique to categorize data relevant to climate risk and asset damage.; Clustering: Used for unsupervised learning to identify patterns in climate and geospatial data.; Machine Learning Models: Developed end-to-end to support climate risk analysis and NLP model enhancement.; Statistical Analysis: Performed to evaluate models and extract insights from climate and text data.; Data Visualization: Utilized tools like Matplotlib, Seaborn, Tableau, and Power BI to communicate findings to stakeholders.; Python Data Science Libraries: Includes sklearn, spaCy, NumPy, and SciPy used for ML algorithms and data processing.; SQL: Implied for data storage and querying in cloud environments supporting data pipelines.; Cloud Services: AWS, Google Cloud Platform, and Azure used for data storage, processing, and model deployment.; Version Control: Git used for managing code changes and collaboration within the data science team.; CI/CD Pipelines: Implemented via tools like GitHub Actions to automate testing and deployment of ML models.; MLOps Frameworks: Exposure to MLFlow and Weights and Biases for managing machine learning lifecycle and experiments.; Web Scraping: Using Python tools like BeautifulSoup and Scrapy to collect data for analysis.; Geospatial Data Processing: Using Python libraries such as geopandas and GDAL, and GIS software like QGIS to analyze spatial climate data."
6ykd2WNVjOHLQ40DAAAAAA==,Senior Data Scientist,"Senior Data Scientist

Virta Health is pioneering a new standard of care for people to reclaim their lives. We are in the midst of a public health crisis: obesity rates are at an all-time high and over half of US adults have type 2 diabetes or prediabetes, and despite billions spent on new treatments, outcomes are largely worse. Virta reverses these diseases and delivers life-changing results by pairing individualized nutrition with ongoing care from a clinical support team. We have raised over $350 million from top-tier investors, and partner with the largest health plans, employers, and government organizations to help their employees and members restore their health and take back their lives.

Role Overview

The Advanced Analytics & AI (AAA) team is accountable for both pioneering new classes of data that power our business, and ensuring that data is powerful, clear, correct and easy to use throughout the company. The team collaborates closely with the engineering, product development, commercial, and clinical teams to transform data into actionable insights that propel Virta's mission forward.

As a Senior Data Scientist on the AAA team, you will play a crucial role in shaping our data-driven decision making processes and in driving impactful insights that advance our mission. This role offers a unique blend of hands-on coding and strategic leadership, working closely in partnership with the Product Development group that supports adoption of our member-facing products. You will get a chance to work closely with stakeholders to create impactful data-driven reports and analyses that strengthen Virta’s value proposition.

Responsibilities
• Serve as data lead for the Adoption Squad:
• Understand the product – strategy, goals, roadmap, users – deeply enough to identify high-impact, strategic opportunities and risks.
• Use data to steer conversations: bring data-driven hypotheses, challenge assumptions, frame trade-offs, prioritize strategically.
• Translate vague product hunches into sharp analytical questions, and design the right approach to answer them.
• Be the source of truth for KPIs and product metrics: help define and monitor them, and identify trends and drivers.
• Drive decision making with data: Prioritize analyses that meaningfully inform product decisions and change outcomes, reframe analysis requests that won’t do that into ones that will, and design and deliver the resulting analyses properly and rapidly.
• Lead experimentation thoughtfully: guide the team on when and when not to experiment, help enable self-serve experimentation, and focus on frequent, small experiments to speed learning.
• Identify where product strategy and ideas could be better, more easily, or more quickly implemented with the help of AI (ML or GenAI), and help enable this integration.
• Show up as a collaborative leader, not simply a service provider, and help focus work on what matters most.
• Work end-to-end to translate clinical, member, and claims data from our data warehouse into actionable recommendations: work with stakeholders to design reports and dashboards that answer real business questions, design the data flows to support these, and build the required data transformation pipelines.

Must-Haves
• Experience working at a digital health or similar startup, preferably during the growth phase, in order to function effectively in a fast-paced, rapidly changing environment.
• 7+ years of experience in a Healthcare Analytics or Data Science role, working with large datasets and conducting statistical and quantitative modeling, melding analytics with strong programming, data mining, clustering and segmentation.
• 5+ years of work experience working data science and visualization tools (SQL, R, and/or Python)
• Advanced understanding of data storage, ETL frameworks, data transformation, and validation
• Experience in building BI dashboards using tools such as Looker or Tableau
• Ability to explain technology, techniques and approaches to others

Nice-to-Haves
• Experience leading cross-functional efforts to build scalable systems and data pipelines, working with complex data structures
• Understanding of Generative AI concepts and basic usage of GenAI tools (ChatGPT, Claude, etc.)
• Experience building pipelines using dbt
• Demonstrated project management experience

90 Day Plan

Within your first 90 days at Virta, we expect you will do the following:
• Familiarize yourself with the Advanced Analytics & AI team roles and responsibilities. Get a pulse on team structure, key stakeholders, and areas for opportunity with an eye towards scalability and standardization.
• Integrate with the Adoption Squad to understand team dynamics, analyze key product features and data pipelines, and familiarize yourself with the Squad’s product roadmap
• Analyze current member journey to understand Virta’s technology ecosystem
• Meet cross-functional stakeholders to understand how their business needs align with Squad and Team goals
• Identify at least 1 area of opportunity to leverage GenAI to increase team efficiency or improve our processes
• Teach and inspire your team members through knowledge sharing, pair programming, and giving feedback during code reviews

Values-driven culture

Virta’s company values drive our culture, so you’ll do well if:
• You put people first and take care of yourself, your peers, and our patients equally
• You have a strong sense of ownership and take initiative while empowering others to do the same
• You prioritize positive impact over busy work
• You have no ego and understand that everyone has something to bring to the table regardless of experience
• You appreciate transparency and promote trust and empowerment through open access of information
• You are evidence-based and prioritize data and science over seniority or dogma
• You take risks and rapidly iterate

Is this role not quite what you're looking for? Join our Talent Community and follow us on Linkedin to stay connected!

Virta has a location based compensation structure. Starting pay will be based on a number of factors and commensurate with qualifications & experience. For this role, the compensation range is $167,249 - $216,000. Information about Virta’s benefits is on our Careers page at: https://www.virtahealth.com/careers.

As part of your duties at Virta, you may come in contact with sensitive patient information that is governed by HIPAA. Throughout your career at Virta, you will be expected to follow Virta's security and privacy procedures to ensure our patients' information remains strictly confidential. Security and privacy training will be provided.

As a remote-first company, our team is spread across various locations with office hubs in Denver and San Francisco.
Clinical roles: We currently do not hire in the following states: AK, HI, RI
Corporate roles: We currently do not hire in the following states: AK, AR, DE, HI, ME, MS, NM, OK, SD, VT, WI.

#LI-remote",2025-07-19T00:00:00.000Z,2025-07-25,"['Experience working at a digital health or similar startup, preferably during the growth phase, in order to function effectively in a fast-paced, rapidly changing environment', '7+ years of experience in a Healthcare Analytics or Data Science role, working with large datasets and conducting statistical and quantitative modeling, melding analytics with strong programming, data mining, clustering and segmentation', '5+ years of work experience working data science and visualization tools (SQL, R, and/or Python)', 'Advanced understanding of data storage, ETL frameworks, data transformation, and validation', 'Experience in building BI dashboards using tools such as Looker or Tableau', 'Ability to explain technology, techniques and approaches to others', 'Experience leading cross-functional efforts to build scalable systems and data pipelines, working with complex data structures', 'Understanding of Generative AI concepts and basic usage of GenAI tools (ChatGPT, Claude, etc.)', 'Experience building pipelines using dbt', 'Demonstrated project management experience', 'You have a strong sense of ownership and take initiative while empowering others to do the same', 'You prioritize positive impact over busy work', 'You have no ego and understand that everyone has something to bring to the table regardless of experience', 'You appreciate transparency and promote trust and empowerment through open access of information', 'You are evidence-based and prioritize data and science over seniority or dogma', 'You take risks and rapidly iterate']","['As a Senior Data Scientist on the AAA team, you will play a crucial role in shaping our data-driven decision making processes and in driving impactful insights that advance our mission', 'You will get a chance to work closely with stakeholders to create impactful data-driven reports and analyses that strengthen Virta’s value proposition', 'Serve as data lead for the Adoption Squad:', 'Understand the product – strategy, goals, roadmap, users – deeply enough to identify high-impact, strategic opportunities and risks', 'Use data to steer conversations: bring data-driven hypotheses, challenge assumptions, frame trade-offs, prioritize strategically', 'Translate vague product hunches into sharp analytical questions, and design the right approach to answer them', 'Be the source of truth for KPIs and product metrics: help define and monitor them, and identify trends and drivers', 'Drive decision making with data: Prioritize analyses that meaningfully inform product decisions and change outcomes, reframe analysis requests that won’t do that into ones that will, and design and deliver the resulting analyses properly and rapidly', 'Lead experimentation thoughtfully: guide the team on when and when not to experiment, help enable self-serve experimentation, and focus on frequent, small experiments to speed learning', 'Identify where product strategy and ideas could be better, more easily, or more quickly implemented with the help of AI (ML or GenAI), and help enable this integration', 'Show up as a collaborative leader, not simply a service provider, and help focus work on what matters most', 'Work end-to-end to translate clinical, member, and claims data from our data warehouse into actionable recommendations: work with stakeholders to design reports and dashboards that answer real business questions, design the data flows to support these, and build the required data transformation pipelines', 'Familiarize yourself with the Advanced Analytics & AI team roles and responsibilities', 'Get a pulse on team structure, key stakeholders, and areas for opportunity with an eye towards scalability and standardization', 'Integrate with the Adoption Squad to understand team dynamics, analyze key product features and data pipelines, and familiarize yourself with the Squad’s product roadmap', 'Analyze current member journey to understand Virta’s technology ecosystem', 'Meet cross-functional stakeholders to understand how their business needs align with Squad and Team goals', 'Identify at least 1 area of opportunity to leverage GenAI to increase team efficiency or improve our processes', 'Teach and inspire your team members through knowledge sharing, pair programming, and giving feedback during code reviews']",True,"['Generative AI', 'GenAI Tools']",Generative AI: Identified as an opportunity to improve team efficiency and product strategy by integrating AI-driven solutions.; GenAI Tools: Basic usage of tools like ChatGPT and Claude to explore AI applications within the analytics and product teams.,"['Statistical and Quantitative Modeling', 'Data Mining', 'Clustering and Segmentation', 'SQL', 'R', 'Python', 'ETL Frameworks', 'Data Transformation and Validation', 'BI Dashboards', 'Data Pipelines', 'dbt', 'Experimentation and A/B Testing']","Statistical and Quantitative Modeling: Used to analyze large healthcare datasets and derive insights for decision making and product strategy.; Data Mining: Applied to extract meaningful patterns and segmentations from complex clinical and member data.; Clustering and Segmentation: Techniques used to group similar data points for targeted analysis and personalized healthcare insights.; SQL: Utilized for querying and managing data within the company’s data warehouse to support reporting and analysis.; R: Used as a programming tool for statistical analysis and data visualization in healthcare analytics.; Python: Employed for data science tasks including data transformation, analysis, and building data pipelines.; ETL Frameworks: Applied to extract, transform, and load clinical, member, and claims data into usable formats for analysis.; Data Transformation and Validation: Processes to ensure data quality and readiness for accurate reporting and decision making.; BI Dashboards: Built using tools like Looker and Tableau to visualize KPIs and product metrics for stakeholders.; Data Pipelines: Designed and maintained to support data flows from raw sources to actionable insights and reports.; dbt: Used to build and manage scalable data transformation pipelines within the analytics infrastructure.; Experimentation and A/B Testing: Guided and enabled to validate hypotheses and inform product decisions through frequent, small experiments."
VZCsO5p6akLRIVwMAAAAAA==,Data Scientist / Machine Learning Engineer/LLM,"Job Title: Data Scientist / Machine Learning Engineer/LLM

Location: Reston, VA (Remote)

Duration: Long term

Job Type : FTE/W2 (Any Visa)

Key Responsibilities:
• Develop and deploy machine learning models using LLMs, NLP, and General AI techniques.
• Utilize Langchain / llamaindex for advanced language processing tasks.
• Implement solutions using Python, Vector DBs, and data analysis tools such as Jupyter Notebook, AWS SageMaker, and Scikit-learn.
• Containerize applications using Docker and manage dependencies with Anaconda/conda/venv or other Python package managers.
• Work with cloud platforms like AWS, Azure, and Google Cloud Platform to scale and deploy AI solutions.
• Perform fine-tuning of models and work with LoRa, PEFT, RAG, and Agentic Frameworks.
• Experience with ML frameworks such as TensorFlow, PyTorch, or similar.
• Collaborate with the MLOps team to ensure smooth deployment and maintenance of models.
• Engage in Multi-Modality research and development to enhance model performance.

Qualifications:
• Proven experience in machine learning, NLP, and AI, Gen AI, LLM.
• Strong programming skills in Python and familiarity with Vector DBs.
• Experience with Jupyter Notebook, AWS SageMaker, Scikit-learn, and Docker.
• Knowledge of cloud services (AWS/Azure/Google Cloud Platform) and model fine-tuning.
• Familiarity with Linux, data streaming tools, MLOps, and multi-modality in AI.
• Excellent problem-solving skills and the ability to work in a fast-paced environment.

Note: Interested Candidates share me the profile to",,2025-07-25,"['Proven experience in machine learning, NLP, and AI, Gen AI, LLM', 'Strong programming skills in Python and familiarity with Vector DBs', 'Experience with Jupyter Notebook, AWS SageMaker, Scikit-learn, and Docker', 'Knowledge of cloud services (AWS/Azure/Google Cloud Platform) and model fine-tuning', 'Familiarity with Linux, data streaming tools, MLOps, and multi-modality in AI', 'Excellent problem-solving skills and the ability to work in a fast-paced environment']","['Develop and deploy machine learning models using LLMs, NLP, and General AI techniques', 'Utilize Langchain / llamaindex for advanced language processing tasks', 'Implement solutions using Python, Vector DBs, and data analysis tools such as Jupyter Notebook, AWS SageMaker, and Scikit-learn', 'Containerize applications using Docker and manage dependencies with Anaconda/conda/venv or other Python package managers', 'Work with cloud platforms like AWS, Azure, and Google Cloud Platform to scale and deploy AI solutions', 'Perform fine-tuning of models and work with LoRa, PEFT, RAG, and Agentic Frameworks', 'Experience with ML frameworks such as TensorFlow, PyTorch, or similar', 'Collaborate with the MLOps team to ensure smooth deployment and maintenance of models', 'Engage in Multi-Modality research and development to enhance model performance']",True,"['Large Language Models', 'Natural Language Processing', 'Generative AI', 'LangChain', 'LlamaIndex', 'Low-Rank Adaptation', 'Parameter-Efficient Fine-Tuning', 'Retrieval-Augmented Generation', 'Agentic Frameworks', 'Multi-Modality AI']","Large Language Models: Developing and deploying advanced language models such as GPT for natural language understanding and generation.; Natural Language Processing: Applying AI techniques to process and analyze human language data using models like LLMs.; Generative AI: Using AI models capable of generating text or other content, including fine-tuning and deployment.; LangChain: Framework for building applications with LLMs, enabling advanced language processing workflows.; LlamaIndex: Tool for indexing and querying large datasets to support LLM-based applications.; Low-Rank Adaptation: Technique (LoRA) for efficient fine-tuning of large AI models by adapting low-rank matrices.; Parameter-Efficient Fine-Tuning: Methods (PEFT) to fine-tune large models with fewer parameters, improving efficiency.; Retrieval-Augmented Generation: Combining retrieval of relevant documents with generative AI to improve response accuracy.; Agentic Frameworks: AI frameworks that enable autonomous agents to perform complex tasks using LLMs.; Multi-Modality AI: Research and development involving AI models that process multiple data types such as text, images, and audio.","['Machine Learning', 'Python', 'Vector Databases', 'Jupyter Notebook', 'AWS SageMaker', 'Scikit-learn', 'Docker', 'Anaconda/Conda', 'Cloud Platforms', 'Model Fine-Tuning', 'TensorFlow', 'PyTorch', 'MLOps', 'Data Streaming Tools', 'Linux']","Machine Learning: Developing and deploying predictive models using traditional machine learning techniques and frameworks like Scikit-learn.; Python: Primary programming language used for implementing data analysis, machine learning models, and scripting.; Vector Databases: Used for storing and querying vector embeddings generated from data, supporting similarity search in language processing tasks.; Jupyter Notebook: Interactive environment for data analysis, experimentation, and prototyping machine learning models.; AWS SageMaker: Cloud service used to build, train, and deploy machine learning models at scale.; Scikit-learn: Machine learning library used for implementing classical ML algorithms and data preprocessing.; Docker: Containerization tool used to package applications and dependencies for consistent deployment.; Anaconda/Conda: Python package and environment management tools used to manage dependencies and virtual environments.; Cloud Platforms: AWS, Azure, and Google Cloud Platform used to scale and deploy data and machine learning solutions.; Model Fine-Tuning: Adjusting pre-trained models to improve performance on specific datasets or tasks.; TensorFlow: Machine learning framework used for building and training models, including deep learning architectures.; PyTorch: Deep learning framework used for model development and research, including neural network training.; MLOps: Practices and tools to deploy, monitor, and maintain machine learning models in production.; Data Streaming Tools: Technologies used to process and analyze real-time data streams, supporting continuous data ingestion.; Linux: Operating system environment commonly used for development, deployment, and managing data science workflows."
8tPDaK1LJ_F71gsvAAAAAA==,"Senior Data Scientist, Materials Science & Chemistry","CAS uses intuitive technology, unparalleled scientific content and unmatched human expertise to help companies create groundbreaking innovations that benefit the world. As the scientific information solutions division of the American Chemical Society, CAS manages the largest curated reservoir of scientific knowledge, and for 118 years, has helped innovators mine, assess and apply that information to keep businesses thriving. The CAS team is global, diverse, endlessly curious and strives to make scientific insights accessible to innovators worldwide.

CAS is currently seeking a Senior Data Scientist specializing in Materials Science & Chemistry applications. This position will be located in our headquarters in Columbus, Ohio.

This role requires a highly self-directed professional who can independently drive complex data science initiatives in materials science and chemistry domains. The successful candidate will provide strategic input into project ideation and implementation, manage multiple high-priority initiatives simultaneously, and demonstrate exceptional ability to translate advanced analytics into tangible business value with minimal oversight.

Key Accountabilities:

Strategic Project Leadership
• Independently conceptualize, design, and execute complex analytical projects in materials science and chemistry applications
• Provide leadership in cross-functional project teams and provide technical direction to junior data scientists
• Drive project ideation and strategic planning, translating business challenges into innovative data science solutions
• Manage multiple high-priority projects simultaneously while maintaining exceptional quality standards

Technical Excellence in Materials Science & Chemistry
• Apply advanced AI/ML techniques to solve complex problems in materials discovery, chemical reaction prediction, molecular design, and other related areas
• Synthesize and analyze chemical and materials data from diverse sources
• Solve unusual problems using a combination of appropriate statistics, machine learning, and computational methods
• Critically evaluate chemical and materials datasets for quality, completeness, and scientific validity using domain expertise

Business Impact & Communication
• Independently synthesize analytical findings and present strategic recommendations to senior executives and C-level stakeholders
• Influence organizational decision-making through compelling data-driven narratives and visualizations
• Lead client presentations and serve as the primary technical liaison for materials science and chemistry projects
• Drive organizational thought leadership through publications, conference presentations, and industry engagement

Organizational Leadership
• Serve as a technical mentor and knowledge leader within the data science team
• Influence and lead initiatives across the organization as part of our shared services model
• Establish and maintain strategic relationships with internal partners and external clients
• Champion best practices in data science methodologies and materials science applications

Qualifications:

Required:
• Master's Degree in Chemistry, Materials Science, Chemical Engineering, or related scientific field with 5-7 years of data science experience, OR Bachelor's degree with 10+ years of combined experience in chemistry/materials science and data science
• Advanced proficiency in modern data science tools and platforms (for example- SQL, Python, R, Spark, graph databases, cloud platforms)
• Proven track record of independently delivering high-impact AI/ML solutions that drive significant business results
• Deep knowledge of chemistry and materials science principles, nomenclature, and research methodologies
• Demonstrated ability to work with chemical databases, molecular representations, and materials property data
• Exceptional presentation and communication skills with proven ability to influence senior stakeholders and lead cross-functional teams
• Strong project management capabilities with experience managing multiple complex initiatives simultaneously

Preferred:
• PhD in Chemistry, Materials Science, Chemical Engineering, or related field
• Experience with cheminformatics tools and molecular modeling software
• Knowledge of materials characterization techniques and experimental design
• Experience in materials development or chemical manufacturing industries
• Track record of publications in peer-reviewed journals combining data science and chemistry/materials science
• Consulting or client-facing experience in chemical or materials sectors

CAS offers a competitive salary and comprehensive benefits package, including a generous vacation plan, medical, dental, vision insurance plans, and employee savings and retirement plans. Candidates for this position must be authorized to work in the United States and not require work authorization sponsorship by our company for this position now or in the future. EEO/Disabled/Veteran

Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities

This employer is required to notify all applicants of their rights pursuant to federal employment laws. For further information, please review the Know Your Rights notice from the Department of Labor.",2025-07-15T00:00:00.000Z,2025-07-25,"['This role requires a highly self-directed professional who can independently drive complex data science initiatives in materials science and chemistry domains', 'Critically evaluate chemical and materials datasets for quality, completeness, and scientific validity using domain expertise', ""Master's Degree in Chemistry, Materials Science, Chemical Engineering, or related scientific field with 5-7 years of data science experience, OR Bachelor's degree with 10+ years of combined experience in chemistry/materials science and data science"", 'Advanced proficiency in modern data science tools and platforms (for example- SQL, Python, R, Spark, graph databases, cloud platforms)', 'Proven track record of independently delivering high-impact AI/ML solutions that drive significant business results', 'Deep knowledge of chemistry and materials science principles, nomenclature, and research methodologies', 'Demonstrated ability to work with chemical databases, molecular representations, and materials property data', 'Exceptional presentation and communication skills with proven ability to influence senior stakeholders and lead cross-functional teams', 'Strong project management capabilities with experience managing multiple complex initiatives simultaneously']","['The successful candidate will provide strategic input into project ideation and implementation, manage multiple high-priority initiatives simultaneously, and demonstrate exceptional ability to translate advanced analytics into tangible business value with minimal oversight', 'Independently conceptualize, design, and execute complex analytical projects in materials science and chemistry applications', 'Provide leadership in cross-functional project teams and provide technical direction to junior data scientists', 'Drive project ideation and strategic planning, translating business challenges into innovative data science solutions', 'Manage multiple high-priority projects simultaneously while maintaining exceptional quality standards', 'Technical Excellence in Materials Science & Chemistry', 'Apply advanced AI/ML techniques to solve complex problems in materials discovery, chemical reaction prediction, molecular design, and other related areas', 'Synthesize and analyze chemical and materials data from diverse sources', 'Solve unusual problems using a combination of appropriate statistics, machine learning, and computational methods', 'Business Impact & Communication', 'Independently synthesize analytical findings and present strategic recommendations to senior executives and C-level stakeholders', 'Influence organizational decision-making through compelling data-driven narratives and visualizations', 'Lead client presentations and serve as the primary technical liaison for materials science and chemistry projects', 'Drive organizational thought leadership through publications, conference presentations, and industry engagement', 'Organizational Leadership', 'Serve as a technical mentor and knowledge leader within the data science team', 'Influence and lead initiatives across the organization as part of our shared services model', 'Establish and maintain strategic relationships with internal partners and external clients', 'Champion best practices in data science methodologies and materials science applications']",True,['Artificial Intelligence / Machine Learning'],Artificial Intelligence / Machine Learning: Delivered high-impact AI/ML solutions specifically tailored to materials science challenges like materials discovery and chemical reaction prediction.,"['SQL', 'Python', 'R', 'Spark', 'Graph Databases', 'Cloud Platforms', 'Machine Learning', 'Statistics', 'Computational Methods', 'Chemical Databases', 'Data Visualization']","SQL: Used as a modern data science tool for querying and managing chemical and materials datasets.; Python: Applied for data analysis, feature engineering, and implementing machine learning models in materials science and chemistry projects.; R: Utilized for statistical analysis and advanced data science workflows in chemistry and materials science domains.; Spark: Employed to process and analyze large-scale chemical and materials data efficiently.; Graph Databases: Used to represent and query complex molecular and materials relationships within chemical datasets.; Cloud Platforms: Leveraged for scalable data storage, processing, and deployment of data science solutions in materials science.; Machine Learning: Applied advanced ML techniques to solve problems such as materials discovery, chemical reaction prediction, and molecular design.; Statistics: Used to analyze chemical and materials data, ensuring quality and scientific validity.; Computational Methods: Combined with statistics and machine learning to address complex problems in materials science and chemistry.; Chemical Databases: Worked with specialized databases containing molecular representations and materials property data.; Data Visualization: Created compelling visual narratives to communicate analytical findings to senior executives and stakeholders."
uFzkLiUklwC3z9PoAAAAAA==,"Senior Data Scientist, Client Analysis","Why Socure?

At Socure, we’re on a mission—to verify 100% of good identities in real time and eliminate identity fraud from the internet.

Using predictive analytics and advanced machine learning trained on billions of signals to power RiskOS, Socure has created the most accurate identity verification and fraud prevention platform in the world. Trusted by thousands of leading organizations—from top banks and fintechs to government agencies—we solve real, high-impact problems at scale. Come join us!

About The Role

As a Senior Data Scientist, Client Analysis, you’ll play a critical role in driving Socure’s growth by partnering closely with our go-to-market (GTM) teams to demonstrate the impact of our solutions. You’ll analyze massive datasets, develop compelling data stories, and build tools that help potential and existing customers understand the full value of our identity verification and fraud prevention platform.

This is a high-visibility, high-impact role ideal for a data scientist who thrives at the intersection of data and business. You’ll bring technical excellence, storytelling ability, and a customer-centric mindset to influence key decisions and directly contribute to revenue generation. Data Scientists on the Client Analysis team are rewarded with a generous incentive bonus in addition to a competitive base salary.

What You’ll Do
• Analyze customer datasets to generate actionable insights that inform optimal risk management policies.
• Clearly articulate model performance and outcomes to both technical and non-technical stakeholders.
• Act as a data science advocate by deeply understanding Socure’s solutions and aligning them with customer needs.
• Craft compelling data narratives that demonstrate Socure’s ability to reduce identity fraud and enhance customer experience.
• Represent the customer’s voice in the development of next-generation models and products.
• Develop tools and automated workflows that increase the speed, accuracy, and reproducibility of client-facing analyses.
• Collaborate cross-functionally with Sales, Solution Consultants, Account Managers, and Technical Program Managers to identify new analysis opportunities and support upsell efforts.
• Build machine learning models when exploring alternative approaches adds value beyond existing production models.

What You’ll Bring
• 5+ years of experience in data science, data analysis, or analytics engineering.
• Advanced degree in a quantitative field or equivalent industry experience.
• Expertise in supervised and unsupervised machine learning methods, both theoretically and practically.
• Strong programming skills in Python and PySpark; experienced working with large-scale, real-world datasets.
• Proficient in SQL and comfortable querying relational databases.
• Experience with cloud-based tools and technologies (AWS, Azure, GCP, Databricks).
• Skilled at data visualization and storytelling through dashboards, presentations, and interactive formats.
• Exceptional communication skills with the ability to explain complex models and analyses to non-technical audiences.
• Self-motivated, goal-oriented, and effective in a fast-paced remote startup environment.
• Experience in identity verification and fraud prevention strongly preferred.

Tools We Use

We don’t expect you to know them all—but familiarity with some and a desire to learn others is important.
• Python ecosystem: PySpark, Pandas, NumPy, H2O, SHAP, Seaborn, Jupyter
• Databricks
• Airflow
• Redshift, Snowflake, S3
• Apache Spark, Apache Arrow
• Amazon EMR
• Looker, Tableau

Socure is an equal opportunity employer and values diversity of all kinds at our company. We do not discriminate based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

Follow Us!

YouTube | LinkedIn | X (Twitter) | Facebook

Compensation Range: $160K - $175K",2025-07-20T00:00:00.000Z,2025-07-25,"['5+ years of experience in data science, data analysis, or analytics engineering', 'Advanced degree in a quantitative field or equivalent industry experience', 'Expertise in supervised and unsupervised machine learning methods, both theoretically and practically', 'Strong programming skills in Python and PySpark; experienced working with large-scale, real-world datasets', 'Proficient in SQL and comfortable querying relational databases', 'Experience with cloud-based tools and technologies (AWS, Azure, GCP, Databricks)', 'Skilled at data visualization and storytelling through dashboards, presentations, and interactive formats', 'Exceptional communication skills with the ability to explain complex models and analyses to non-technical audiences', 'Self-motivated, goal-oriented, and effective in a fast-paced remote startup environment', 'We don’t expect you to know them all—but familiarity with some and a desire to learn others is important', 'Python ecosystem: PySpark, Pandas, NumPy, H2O, SHAP, Seaborn, Jupyter']","['As a Senior Data Scientist, Client Analysis, you’ll play a critical role in driving Socure’s growth by partnering closely with our go-to-market (GTM) teams to demonstrate the impact of our solutions', 'You’ll analyze massive datasets, develop compelling data stories, and build tools that help potential and existing customers understand the full value of our identity verification and fraud prevention platform', 'This is a high-visibility, high-impact role ideal for a data scientist who thrives at the intersection of data and business', 'You’ll bring technical excellence, storytelling ability, and a customer-centric mindset to influence key decisions and directly contribute to revenue generation', 'Analyze customer datasets to generate actionable insights that inform optimal risk management policies', 'Clearly articulate model performance and outcomes to both technical and non-technical stakeholders', 'Act as a data science advocate by deeply understanding Socure’s solutions and aligning them with customer needs', 'Craft compelling data narratives that demonstrate Socure’s ability to reduce identity fraud and enhance customer experience', 'Represent the customer’s voice in the development of next-generation models and products', 'Develop tools and automated workflows that increase the speed, accuracy, and reproducibility of client-facing analyses', 'Collaborate cross-functionally with Sales, Solution Consultants, Account Managers, and Technical Program Managers to identify new analysis opportunities and support upsell efforts', 'Build machine learning models when exploring alternative approaches adds value beyond existing production models']",True,[],,"['Supervised Learning', 'Unsupervised Learning', 'Python', 'PySpark', 'SQL', 'Pandas', 'NumPy', 'H2O', 'SHAP', 'Seaborn', 'Jupyter', 'Databricks', 'Airflow', 'Redshift', 'Snowflake', 'Amazon S3', 'Apache Spark', 'Apache Arrow', 'Amazon EMR', 'Looker', 'Tableau', 'Cloud Platforms', 'Predictive Analytics', 'Data Storytelling', 'Automated Workflows']","Supervised Learning: Used to build predictive models for identity verification and fraud prevention by learning from labeled data.; Unsupervised Learning: Applied to discover patterns and insights in customer datasets without labeled outcomes to enhance risk management.; Python: Primary programming language used for data analysis, model development, and building automated workflows.; PySpark: Utilized for processing and analyzing large-scale datasets in distributed computing environments.; SQL: Used to query relational databases for extracting and manipulating customer and operational data.; Pandas: Employed for data manipulation and analysis within Python to prepare datasets for modeling and reporting.; NumPy: Used for numerical computations and handling large arrays during data processing tasks.; H2O: Machine learning platform leveraged for building and deploying scalable predictive models.; SHAP: Applied to interpret and explain model predictions, enhancing transparency for stakeholders.; Seaborn: Used for statistical data visualization to create insightful charts and graphs for storytelling.; Jupyter: Interactive environment for developing, documenting, and sharing data analyses and models.; Databricks: Cloud-based platform used for collaborative data engineering, machine learning, and analytics workflows.; Airflow: Orchestrates automated data pipelines and workflows to increase analysis speed and reproducibility.; Redshift: Cloud data warehouse used for storing and querying large volumes of structured data.; Snowflake: Cloud data platform employed for scalable data storage and analytics.; Amazon S3: Cloud storage service used to store large datasets and support data processing tasks.; Apache Spark: Distributed computing framework used for large-scale data processing and analytics.; Apache Arrow: In-memory data format used to optimize data interchange and processing performance.; Amazon EMR: Managed cluster platform used to run big data frameworks like Apache Spark for scalable data processing.; Looker: Business intelligence tool used to create dashboards and reports for data storytelling and decision support.; Tableau: Data visualization platform used to build interactive dashboards and communicate insights effectively.; Cloud Platforms: Experience with AWS, Azure, and GCP to deploy and manage data infrastructure and analytics solutions.; Predictive Analytics: Techniques used to forecast identity fraud risk and inform risk management policies.; Data Storytelling: Crafting compelling narratives from data to influence business decisions and demonstrate solution impact.; Automated Workflows: Developed to improve speed, accuracy, and reproducibility of client-facing data analyses."
Ki-vKUxWDKEekexeAAAAAA==,Senior Data Science and Analytics Analyst - CRM Analytics,"Company description

Hi there! We’re Razorfish. We’ve been leading the marketing industry with our digital expertise since the start of the internet. But in 2020, we did a full reboot. What’s different? It all starts with people. Weird, wonderful, complex people - with diverse backgrounds in strategy, creative and technology. But no matter how different we are, we all have one thing in common. We believe our differences are our strength. So we push for inclusion, challenge convention and bring in new perspectives, to inspire new ideas. Because when we connect by understanding what makes people different, we can create unforgettable experiences that enrich lives. Join us at razorfish.com.

Overview

Razorfish is looking for a Senior Associate to join its Data Science and Analytics practice. This is an analytics, research, and consulting team that delivers data-driven insights to our clients. Each member of the team is aligned to one or more clients and works closely with other Data Science team members, our clients, and colleagues across other disciplines such as: Client Management, Strategy, Search, Social, Media, User Experience, and Technology.

In this role you will contribute to data-driven projects across one or more client accounts. You will have support from data leadership and fellow analysts.

Core areas of focus for this group include applications in measurement planning and strategy, customer segmentations, testing frameworks, measurement and optimization solutions, performance reporting and analyses, personalization, and forecasting.

Responsibilities
• Be the lead data analyst for internal and external client project work
• Experience with CRM analytics
• Be the subject matter expert (SME) in source tools, platforms, and data flow
• Understands Razorfish data capabilities and how data fits into a client's overall strategy
• Understands the breadth of data services and crafts
• Owns elements of the data process such as syntax and taxonomy management and QA
• Able to manage data team responsibilities within cross-capability projects
• Participates and presents within larger presentations to clients
• Translates data into visuals (charts and graphs) that demonstrate the finding

Qualifications

Data Strategy
• Able to identify / focus on key issues and objectives based on internal and client needs with oversight
• Effectively describes outputs and approach of analysis to internal audiences and clients

Communication Skills
• Is an active listener and thoughtful communicator within internal and client discussions
• Raises questions based on data trends and patterns, explores hypothesis on causation
• Has ownership of own materials and able to answer questions logically and appropriately
• Participates appropriately in meetings, developing confidence in offering ideas and suggestions
• Begins to play leadership role in team discussions and is more comfortable voicing alternatives appropriately (supported with facts)
• Able to independently create sections of client documents with guidance in addition to leveraging pre-existing templates
• Takes comprehensive meeting notes with clear next steps for individual owners
• Shows ability to transform data into visually appealing presentations and able to adapt new formats as necessary

Client Engagement
• Client Partnerships
• Contributes to meetings with internal and external clients
• Able to prioritize work to meet internal and external client deliverables
• ​​​​​​​Relationship Management
• ​​​​​​​Can identify when a request should be completed by the data team
• Understands how to document client feedback and recognizes when to escalate issues
• Questions and output reflect basic knowledge of client’s business – financials, industry economics, competitive dynamics, marketing channels and client strategic issues

Tools & Techniques
• Shows mastery of client-specific data tools and platforms for reporting purposes
• Has advanced Excel skills with experience in manipulating and organizing large data sets
• Has deeper knowledge of statistical concepts / coding languages for advanced analytics capabilities
• Able to assist in vendor assessments
• Proactively identifies own learning gaps and seeks to answer them through internal resources or asking experts
• Comfortable working within BI/Visualization tools
• Able to QA and maintain data integrity at collection, extraction, and activation point

Analytics
• Planning and Implementation
• Able to own sections of learning agenda / measurement plan
• Able to seamlessly implement a measurement program with minimal guidance
• Able to start and end a reporting deliverable with minimal guidance
• ​​​​​​​Insight Generation
• Able to understand the best path to extract, cleanse, manipulate, and analyze data
• Demonstrates ability to synthesize implications (""so whats?"") from analysis with minimal guidance
• Uses these insights to provide hypotheses and useful recommendations to the team

Additional information

The Power of One starts with our people! To do powerful things, we offer powerful resources. Our best-in-class wellness and benefits offerings include:
• Paid Family Care for parents and caregivers for 12 weeks or more
• Monetary assistance and support for Adoption, Surrogacy and Fertility
• Monetary assistance and support for pet adoption
• Employee Assistance Programs and Health/Wellness/Comfort reimbursements to help you invest in your future and work/life balance
• Tuition Assistance
• Paid time off that includes Flexible Time off Vacation, Annual Sick Days, Volunteer Days, Holiday and Identity days, and more
• Matching Gifts programs
• Flexible working arrangements
• ‘Work Your World’ Program encouraging employees to work from anywhere Publicis Groupe has an office for up to 6 weeks a year (based upon eligibility)
• Business Resource Groups that support multiple affinities and alliances

The benefits offerings listed are available to eligible U.S. Based employees, are reviewed on an annual basis, and are governed by the terms of the applicable plan documents.

Razorfish is an Equal Opportunity Employer. Our employment decisions are made without regard to actual or perceived race, color, ethnicity, religion, creed, sex, sexual orientation, gender, gender identity, gender expression, pregnancy, childbirth and related medical conditions, national origin, ancestry, citizenship status, age, disability, medical condition as defined by applicable state law, genetic information, marital status, military service and veteran status, or any other characteristic protected by applicable federal, state or local laws and ordinances.

If you require accommodation or assistance with the application or onboarding process specifically, please contact USMSTACompliance@publicis.com.

All your information will be kept confidential according to EEO guidelines.

Compensation Range: $72390 - $99960. This is the pay range the Company believes it will pay for this position at the time of this posting. Consistent with applicable law, compensation will be determined based on the skills, qualifications, and experience of the applicant along with the requirements of the position, and the Company reserves the right to modify this pay range at any time. Temporary roles may be eligible to participate in our freelancer/temporary employee medical plan through a third-party benefits administration system once certain criteria have been met. Temporary roles may also qualify for participation in our 401(k) plan after eligibility criteria have been met. For regular roles, the Company will offer medical coverage, dental, vision, disability, 401k, and paid time off. The Company anticipates the application deadline for this job posting will be 8/15/25.

#DNI",,2025-07-25,"['Data Strategy', 'Is an active listener and thoughtful communicator within internal and client discussions', 'Has ownership of own materials and able to answer questions logically and appropriately', 'Has advanced Excel skills with experience in manipulating and organizing large data sets', 'Has deeper knowledge of statistical concepts / coding languages for advanced analytics capabilities', 'Able to understand the best path to extract, cleanse, manipulate, and analyze data']","['This is an analytics, research, and consulting team that delivers data-driven insights to our clients', 'Each member of the team is aligned to one or more clients and works closely with other Data Science team members, our clients, and colleagues across other disciplines such as: Client Management, Strategy, Search, Social, Media, User Experience, and Technology', 'In this role you will contribute to data-driven projects across one or more client accounts', 'You will have support from data leadership and fellow analysts', 'Core areas of focus for this group include applications in measurement planning and strategy, customer segmentations, testing frameworks, measurement and optimization solutions, performance reporting and analyses, personalization, and forecasting', 'Be the lead data analyst for internal and external client project work', 'Experience with CRM analytics', 'Be the subject matter expert (SME) in source tools, platforms, and data flow', ""Understands Razorfish data capabilities and how data fits into a client's overall strategy"", 'Understands the breadth of data services and crafts', 'Owns elements of the data process such as syntax and taxonomy management and QA', 'Able to manage data team responsibilities within cross-capability projects', 'Participates and presents within larger presentations to clients', 'Translates data into visuals (charts and graphs) that demonstrate the finding', 'Able to identify / focus on key issues and objectives based on internal and client needs with oversight', 'Effectively describes outputs and approach of analysis to internal audiences and clients', 'Raises questions based on data trends and patterns, explores hypothesis on causation', 'Participates appropriately in meetings, developing confidence in offering ideas and suggestions', 'Begins to play leadership role in team discussions and is more comfortable voicing alternatives appropriately (supported with facts)', 'Able to independently create sections of client documents with guidance in addition to leveraging pre-existing templates', 'Takes comprehensive meeting notes with clear next steps for individual owners', 'Shows ability to transform data into visually appealing presentations and able to adapt new formats as necessary', 'Client Engagement', 'Client Partnerships', 'Contributes to meetings with internal and external clients', 'Able to prioritize work to meet internal and external client deliverables', '\u200b\u200b\u200b\u200b\u200b\u200b\u200bRelationship Management', '\u200b\u200b\u200b\u200b\u200b\u200b\u200bCan identify when a request should be completed by the data team', 'Understands how to document client feedback and recognizes when to escalate issues', 'Questions and output reflect basic knowledge of client’s business – financials, industry economics, competitive dynamics, marketing channels and client strategic issues', 'Shows mastery of client-specific data tools and platforms for reporting purposes', 'Able to assist in vendor assessments', 'Proactively identifies own learning gaps and seeks to answer them through internal resources or asking experts', 'Comfortable working within BI/Visualization tools', 'Able to QA and maintain data integrity at collection, extraction, and activation point', 'Planning and Implementation', 'Able to own sections of learning agenda / measurement plan', 'Able to seamlessly implement a measurement program with minimal guidance', 'Able to start and end a reporting deliverable with minimal guidance', '\u200b\u200b\u200b\u200b\u200b\u200b\u200bInsight Generation', 'Demonstrates ability to synthesize implications (""so whats?"") from analysis with minimal guidance', 'Uses these insights to provide hypotheses and useful recommendations to the team']",True,[],,"['CRM Analytics', 'Measurement Planning and Strategy', 'Customer Segmentation', 'Testing Frameworks', 'Performance Reporting and Analysis', 'Personalization', 'Forecasting', 'Data Visualization', 'Data QA and Integrity', 'Statistical Concepts and Coding Languages', 'Data Extraction, Cleansing, and Manipulation', 'BI and Visualization Tools', 'Advanced Excel']","CRM Analytics: Used to analyze customer relationship management data to derive insights for client projects.; Measurement Planning and Strategy: Applied to design and implement frameworks for evaluating marketing and business performance.; Customer Segmentation: Used to categorize customers into groups for targeted marketing and personalization.; Testing Frameworks: Employed to design and analyze experiments such as A/B testing for optimization.; Performance Reporting and Analysis: Involves generating reports and analyzing data to assess campaign or business outcomes.; Personalization: Utilized to tailor marketing and user experiences based on data insights.; Forecasting: Applied to predict future trends and outcomes based on historical data.; Data Visualization: Transforming data into charts and graphs to communicate findings effectively to clients.; Data QA and Integrity: Ensuring accuracy and consistency of data during collection, extraction, and activation.; Statistical Concepts and Coding Languages: Used for advanced analytics capabilities including data manipulation and hypothesis testing.; Data Extraction, Cleansing, and Manipulation: Processes to prepare raw data for analysis and insight generation.; BI and Visualization Tools: Tools leveraged to create dashboards and visual reports for client presentations.; Advanced Excel: Used for manipulating and organizing large datasets in client-specific data tasks."
K-7fcf6yuWkAsvXfAAAAAA==,Senior Product Data Scientist,"The Company

PayPal has been revolutionizing commerce globally for more than 25 years. Creating innovative experiences that make moving money, selling, and shopping simple, personalized, and secure, PayPal empowers consumers and businesses in approximately 200 markets to join and thrive in the global economy.

We operate a global, two-sided network at scale that connects hundreds of millions of merchants and consumers. We help merchants and consumers connect, transact, and complete payments, whether they are online or in person. PayPal is more than a connection to third-party payment networks. We provide proprietary payment solutions accepted by merchants that enable the completion of payments on our platform on behalf of our customers.

We offer our customers the flexibility to use their accounts to purchase and receive payments for goods and services, as well as the ability to transfer and withdraw funds. We enable consumers to exchange funds more safely with merchants using a variety of funding sources, which may include a bank account, a PayPal or Venmo account balance, PayPal and Venmo branded credit products, a credit card, a debit card, certain cryptocurrencies, or other stored value products such as gift cards, and eligible credit card rewards. Our PayPal, Venmo, and Xoom products also make it safer and simpler for friends and family to transfer funds to each other. We offer merchants an end-to-end payments solution that provides authorization and settlement capabilities, as well as instant access to funds and payouts. We also help merchants connect with their customers, process exchanges and returns, and manage risk. We enable consumers to engage in cross-border shopping and merchants to extend their global reach while reducing the complexity and friction involved in enabling cross-border trade.

Our beliefs are the foundation for how we conduct business every day. We live each day guided by our core values of Inclusion, Innovation, Collaboration, and Wellness. Together, our values ensure that we work together as one global team with our customers at the center of everything we do – and they push us to ensure we take care of ourselves, each other, and our communities.

Job Description Summary: What you need to know about the role: We are seeking a senior data scientist who can generate valuable insights from data through deep-dive analyses, who is experienced at supporting new product launches with robust experimentation plans, and who can guide and mentor other data scientists on the team. Meet our team: The Consumer Financial Services Analytics team plays a critical role in improving the PayPal product for customers by using the scientific method to generate insights and drive data-driven decisions. We provide product data science support for Financial Services products such as the PayPal Debit Card, PayPal Savings, PayPal Balance, as well as the various funds-in and funds-out methods associated with those.

Job Description:

Your way to impact:
• You believe in data-driven decisions and use data to answer business questions
• You are hyper-analytical, intellectually honest, and passionate about data and A/B experimentation
• You are a highly motivated, result-oriented self-starter, enjoy working in a fast-paced environment, and can deliver successful results with minimal guidance
• You are curious and inquisitive: you love digging into data and uncovering insights
• You are motivated by improving the experience customers have with the products you work on

Your day to day:
• Help to launch, measure, and scale new solutions to improve customers’ experiences with the PayPal App and website
• Identify new opportunities through deep dive analyses leveraging our rich datasets of behavioral and transactional user data
• Translate ambiguous, unstructured business problems into actionable and data-driven analyses
• Size potential impact of new ideas to help prioritize product roadmaps
• Bring clarity to the performance of our key metrics and flows through well-designed dashboards and reports
• Partner closely with product leaders to understand new product offerings being built and recommend the right metrics to measure the performance of those features
• Define and cultivate best practices in analytics instrumentation and experimentation
• Support multiple projects at the same time in a fast-paced, results-oriented environment
• Mentor other data scientists in both technical and non-technical areas

What do you need to bring:
• Bachelors in a quantitative field (math, statistics, computer science, or similar STEM fields), advanced degrees preferred
• At least 5 years of experience analyzing large, multi-dimensional data sets and synthesizing insights into actionable solutions
• Proven track record driving product strategy through analyses and data-centric presentations
• Strong understanding of statistics (e.g. hypothesis testing, statistical inference, regression) and experience designing and evaluating complex experiments
• Fluent in SQL and experience with at least one scripting language (Python or R), comfortable with working with large, complex, and potentially messy datasets
• Strong interpersonal and project management skills, ability to lead cross-functionally
• Proven ability to mentor junior data scientists
• Experience developing new visualizations in tools such as Tableau
• Prior work experience in Product Data Science (or adjacent space) preferred

PayPal is committed to fair and equitable compensation practices.

Actual Compensation is based on various factors including but not limited to work location, and relevant skills and experience.

The total compensation for this practice may include an annual performance bonus (or other incentive compensation, as applicable), equity, and medical, dental, vision, and other benefits. For more information, visit https://www.paypalbenefits.com.

The U.S. national annual pay range for this role is $123,500 to $212,850

For the majority of employees, PayPal's balanced hybrid work model offers 3 days in the office for effective in-person collaboration and 2 days at your choice of either the PayPal office or your home workspace, ensuring that you equally have the benefits and conveniences of both locations.

Our Benefits:

At PayPal, we’re committed to building an equitable and inclusive global economy. And we can’t do this without our most important asset—you. That’s why we offer benefits to help you thrive in every stage of life. We champion your financial, physical, and mental health by offering valuable benefits and resources to help you care for the whole you.

We have great benefits including a flexible work environment, employee shares options, health and life insurance and more. To learn more about our benefits please visit https://www.paypalbenefits.com

Who We Are:

To learn more about our culture and community visit https://about.pypl.com/who-we-are/default.aspx

Commitment to Diversity and Inclusion

PayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state, or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities. If you are unable to submit an application because of incompatible assistive technology or a disability, please contact us at paypalglobaltalentacquisition@paypal.com.

Belonging at PayPal:

Our employees are central to advancing our mission, and we strive to create an environment where everyone can do their best work with a sense of purpose and belonging. Belonging at PayPal means creating a workplace with a sense of acceptance and security where all employees feel included and valued. We are proud to have a diverse workforce reflective of the merchants, consumers, and communities that we serve, and we continue to take tangible actions to cultivate inclusivity and belonging at PayPal.

Any general requests for consideration of your skills, please Join our Talent Community.

We know the confidence gap and imposter syndrome can get in the way of meeting spectacular candidates. Please don’t hesitate to apply.",2025-06-28T00:00:00.000Z,2025-07-25,"['You believe in data-driven decisions and use data to answer business questions', 'You are hyper-analytical, intellectually honest, and passionate about data and A/B experimentation', 'You are a highly motivated, result-oriented self-starter, enjoy working in a fast-paced environment, and can deliver successful results with minimal guidance', 'You are curious and inquisitive: you love digging into data and uncovering insights', 'You are motivated by improving the experience customers have with the products you work on', 'At least 5 years of experience analyzing large, multi-dimensional data sets and synthesizing insights into actionable solutions', 'Proven track record driving product strategy through analyses and data-centric presentations', 'Strong understanding of statistics (e.g. hypothesis testing, statistical inference, regression) and experience designing and evaluating complex experiments', 'Fluent in SQL and experience with at least one scripting language (Python or R), comfortable with working with large, complex, and potentially messy datasets', 'Strong interpersonal and project management skills, ability to lead cross-functionally', 'Proven ability to mentor junior data scientists', 'Experience developing new visualizations in tools such as Tableau']","['We offer our customers the flexibility to use their accounts to purchase and receive payments for goods and services, as well as the ability to transfer and withdraw funds', 'We enable consumers to exchange funds more safely with merchants using a variety of funding sources, which may include a bank account, a PayPal or Venmo account balance, PayPal and Venmo branded credit products, a credit card, a debit card, certain cryptocurrencies, or other stored value products such as gift cards, and eligible credit card rewards', 'We also help merchants connect with their customers, process exchanges and returns, and manage risk', 'We enable consumers to engage in cross-border shopping and merchants to extend their global reach while reducing the complexity and friction involved in enabling cross-border trade', 'Job Description Summary: What you need to know about the role: We are seeking a senior data scientist who can generate valuable insights from data through deep-dive analyses, who is experienced at supporting new product launches with robust experimentation plans, and who can guide and mentor other data scientists on the team', 'Meet our team: The Consumer Financial Services Analytics team plays a critical role in improving the PayPal product for customers by using the scientific method to generate insights and drive data-driven decisions', 'We provide product data science support for Financial Services products such as the PayPal Debit Card, PayPal Savings, PayPal Balance, as well as the various funds-in and funds-out methods associated with those', 'Help to launch, measure, and scale new solutions to improve customers’ experiences with the PayPal App and website', 'Identify new opportunities through deep dive analyses leveraging our rich datasets of behavioral and transactional user data', 'Translate ambiguous, unstructured business problems into actionable and data-driven analyses', 'Size potential impact of new ideas to help prioritize product roadmaps', 'Bring clarity to the performance of our key metrics and flows through well-designed dashboards and reports', 'Partner closely with product leaders to understand new product offerings being built and recommend the right metrics to measure the performance of those features', 'Define and cultivate best practices in analytics instrumentation and experimentation', 'Support multiple projects at the same time in a fast-paced, results-oriented environment', 'Mentor other data scientists in both technical and non-technical areas']",True,[],,"['A/B Testing', 'Statistical Inference', 'Regression Analysis', 'Hypothesis Testing', 'SQL', 'Python', 'R', 'Data Visualization', 'Deep-Dive Data Analysis', 'Product Data Science']","A/B Testing: Used to design and evaluate experiments that measure the impact of new product features and solutions.; Statistical Inference: Applied to draw conclusions from data analyses and support data-driven decision making.; Regression Analysis: Utilized to understand relationships between variables and support product strategy through quantitative modeling.; Hypothesis Testing: Employed to validate assumptions and measure the effectiveness of product changes and experiments.; SQL: Used for querying and managing large, complex, and multi-dimensional datasets to extract actionable insights.; Python: A scripting language used for data manipulation, analysis, and building data pipelines.; R: A scripting language used for statistical analysis and data visualization.; Data Visualization: Developed through tools like Tableau to create dashboards and reports that clarify key metrics and flows.; Deep-Dive Data Analysis: Conducted to uncover insights from behavioral and transactional user data to identify new opportunities.; Product Data Science: Applied to support product launches and improve customer experience through data-driven insights."
ZnzoTWtgb1YvbDueAAAAAA==,"Senior Data Scientist, Emerging Technology and Innovation - Full-time","Sr Data Scientist - GD07AE

We’re determined to make a difference and are proud to be an insurance company that goes well beyond coverages and policies. Working here means having every opportunity to achieve your goals – and to help others accomplish theirs, too. Join our team as we help shape the future.

You are a driven and motivated problem solver ready to pursue meaningful work. You strive to make an impact every day not only at work, but at home and in the community too. If that sounds like you, then you’ve landed in the right place.

Emerging Tech and Innovation is a forward-looking team at The Hartford. We explore the frontier of AI by experimenting with emerging technologies, evaluating cutting-edge vendors, and rapidly prototyping solutions that can transform the insurance landscape.

We are seeking a Senior Data Scientist with deep expertise in computer vision and a passion for experimentation. This role is ideal for someone who thrives in early-stage R&D environments, enjoys working with novel data modalities, and is excited by the challenge of translating emerging capabilities into business value. You’ll collaborate closely with other data science and engineering teams, often handing off successful prototypes for production scaling.

Key Focus Areas

This position will build domain expertise in areas such as:

· Computer vision and convolutional neural networks (CNNs)

· Multimodal generative AI , including image-text models

· Video analytics , including facial detection

· Rapid experimentation and proof-of-concept development

· Vendor and technology evaluations in the AI/ML space

Responsibilities

+ Design and prototype machine learning models for image and video data, with a focus on insurance-relevant use cases.

+ Evaluate emerging technologies and vendors, providing technical assessments and recommendations.

+ Collaborate with business stakeholders to identify high-impact opportunities for AI innovation.

+ Translate ambiguous problems into structured experiments and communicate findings clearly.

+ Partner with engineering and data science teams to transition successful prototypes into production-ready solutions.

+ Stay current on the latest research and trends in AI, computer vision, and generative models.

+ Mentor junior team members and contribute to a culture of curiosity and continuous learning.

What’s in it for you?

+ Work on cutting-edge AI problems in a highly exploratory environment.

+ Collaborate with a high-performing, forward-focused team and engage with product owners and business stakeholders.

+ Expand your technical and strategic skills in a role that blends research, experimentation, and business impact.

+ Influence the future of AI at The Hartford by shaping how new technologies are evaluated and adopted.

+ Thrive in a supportive environment that values innovation, agility, and growth.

This role will have a Hybrid work schedule, with the expectation of working in an office (Columbus, OH, Chicago, IL, Hartford, CT or Charlotte, NC) 3 days a week (Tuesday through Thursday).

Qualifications:

+ Master’s or PhD in a quantitative field such as Data Science, Computer Science, Statistics, Applied Mathematics, or Engineering. A Bachelor’s with additional years of relevant experience can substitute for an advanced degree.

+ 5+ years of experience in data science, machine learning, or a related field.

+ Proficiency in Python and SQL; experience with cloud platforms (AWS, GCP, or Azure).

+ Strong understanding of statistical modeling, machine learning, and data visualization techniques.

+ Excellent problem-solving skills and ability to work independently and collaboratively.

+ Strong communication skills with the ability to present complex ideas to diverse audiences.

+ Self-motivated, strong sense of ownership/accountability, and results oriented with the ability to manage time and schedules effectively

+ Natural curiosity with a strong desire to learn, maintain, and apply knowledge of emerging data technologies

+ Candidate must be authorized to work in the US without company sponsorship. The company will not support the STEM OPT I-983 Training Plan endorsement for this position.

Desired Qualifications:

+ Experience with Computer Vision, Convolutional Neural Networks(CNN), Multimodal GEN AI a plus

+ Familiarity with Agile and CI/CD practices.

+ Experience in innovation and rapid prototyping with a “fail-fast” mindset.

+ Knowledge of Property & Casualty Insurance business is a plus.

Compensation

The listed annualized base pay range is primarily based on analysis of similar positions in the external market. Actual base pay could vary and may be above or below the listed range based on factors including but not limited to performance, proficiency and demonstration of competencies required for the role. The base pay is just one component of The Hartford’s total compensation package for employees. Other rewards may include short-term or annual bonuses, long-term incentives, and on-the-spot recognition. The annualized base pay range for this role is:

$110,720 - $166,080

Equal Opportunity Employer/Sex/Race/Color/Veterans/Disability/Sexual Orientation/Gender Identity or Expression/Religion/Age

About Us (https://www.thehartford.com/about-us) | Culture & Employee Insights (https://www.thehartford.com/careers/employee-stories) | Diversity, Equity and Inclusion (https://www.thehartford.com/about-us/corporate-diversity) | Benefits (https://www.thehartford.com/careers/benefits)

Every day, a day to do right.

Showing up for people isn’t just what we do. It’s who we are – and have been for more than 200 years. We’re devoted to finding innovative ways to serve our customers, communities and employees—continually asking ourselves what more we can do.

Is our policy language as simple and inclusive as it can be? Can we better help businesses navigate our ever-changing world? What else can we do to destigmatize mental health in the workplace? Can we make our communities more equitable?

That we can rise to the challenge of these questions is due in no small part to our company values that our employees have shaped and defined.

And while how we contribute looks different for each of us, it’s these values that drive all of us to do more and to do better every day.

About Us (https://www.thehartford.com/about-us)

Our Culture

What It’s Like to Work Here (https://www.thehartford.com/careers/our-employees)

Perks & Benefits

Legal Notice (https://www.thehartford.com/legal-notice)

Accessibility StatementProducer Compensation (https://www.thehartford.com/producer-compensation)

EEO

Privacy Policy (https://www.thehartford.com/online-privacy-policy)

California Privacy Policy

Your California Privacy Choices (https://www.thehartford.com/data-privacy-opt-out-form)

International Privacy Policy

Canadian Privacy Policy (https://www.thehartford.com/canadian-privacy-policy)

Unincorporated Areas of LA County, CA (Applicant Information)

MA Applicant Notice (https://www.thehartford.com/ma-lie-detector)

Sr Data Scientist - GD07AE

We’re determined to make a difference and are proud to be an insurance company that goes well beyond coverages and policies. Working here means having every opportunity to achieve your goals – and to help others accomplish theirs, too. Join our team as we help shape the future.

You are a driven and motivated problem solver ready to pursue meaningful work. You strive to make an impact every day not only at work, but at home and in the community too. If that sounds like you, then you’ve landed in the right place.

Emerging Tech and Innovation is a forward-looking team at The Hartford. We explore the frontier of AI by experimenting with emerging technologies, evaluating cutting-edge vendors, and rapidly prototyping solutions that can transform the insurance landscape.

We are seeking a Senior Data Scientist with deep expertise in computer vision and a passion for experimentation. This role is ideal for someone who thrives in early-stage R&D environments, enjoys working with novel data modalities, and is excited by the challenge of translating emerging capabilities into business value. You’ll collaborate closely with other data science and engineering teams, often handing off successful prototypes for production scaling.

Key Focus Areas

This position will build domain expertise in areas such as:

· Computer vision and convolutional neural networks (CNNs)

· Multimodal generative AI , including image-text models

· Video analytics , including facial detection

· Rapid experimentation and proof-of-concept development

· Vendor and technology evaluations in the AI/ML space

Responsibilities

+ Design and prototype machine learning models for image and video data, with a focus on insurance-relevant use cases.

+ Evaluate emerging technologies and vendors, providing technical assessments and recommendations.

+ Collaborate with business stakeholders to identify high-impact opportunities for AI innovation.

+ Translate ambiguous problems into structured experiments and communicate findings clearly.

+ Partner with engineering and data science teams to transition successful prototypes into production-ready solutions.

+ Stay current on the latest research and trends in AI, computer vision, and generative models.

+ Mentor junior team members and contribute to a culture of curiosity and continuous learning.

What’s in it for you?

+ Work on cutting-edge AI problems in a highly exploratory environment.

+ Collaborate with a high-performing, forward-focused team and engage with product owners and business stakeholders.

+ Expand your technical and strategic skills in a role that blends research, experimentation, and business impact.

+ Influence the future of AI at The Hartford by shaping how new technologies are evaluated and adopted.

+ Thrive in a supportive environment that values innovation, agility, and growth.

This role will have a Hybrid work schedule, with the expectation of working in an office (Columbus, OH, Chicago, IL, Hartford, CT or Charlotte, NC) 3 days a week (Tuesday through Thursday).

Qualifications:

+ Master’s or PhD in a quantitative field such as Data Science, Computer Science, Statistics, Applied Mathematics, or Engineering. A Bachelor’s with additional years of relevant experience can substitute for an advanced degree.

+ 5+ years of experience in data science, machine learning, or a related field.

+ Proficiency in Python and SQL; experience with cloud platforms (AWS, GCP, or Azure).

+ Strong understanding of statistical modeling, machine learning, and data visualization techniques.

+ Excellent problem-solving skills and ability to work independently and collaboratively.

+ Strong communication skills with the ability to present complex ideas to diverse audiences.

+ Self-motivated, strong sense of ownership/accountability, and results oriented with the ability to manage time and schedules effectively

+ Natural curiosity with a strong desire to learn, maintain, and apply knowledge of emerging data technologies

+ Candidate must be authorized to work in the US without company sponsorship. The company will not support the STEM OPT I-983 Training Plan endorsement for this position.

Desired Qualifications:

+ Experience with Computer Vision, Convolutional Neural Networks(CNN), Multimodal GEN AI a plus

+ Familiarity with Agile and CI/CD practices.

+ Experience in innovation and rapid prototyping with a “fail-fast” mindset.

+ Knowledge of Property & Casualty Insurance business is a plus.

Compensation

The listed annualized base pay range is primarily based on analysis of similar positions in the external market. Actual base pay could vary and may be above or below the listed range based on factors including but not limited to performance, proficiency and demonstration of competencies required for the role. The base pay is just one component of The Hartford’s total compensation package for employees. Other rewards may include short-term or annual bonuses, long-term incentives, and on-the-spot recognition. The annualized base pay range for this role is:

$110,720 - $166,080

Equal Opportunity Employer/Sex/Race/Color/Veterans/Disability/Sexual Orientation/Gender Identity or Expression/Religion/Age

About Us (https://www.thehartford.com/about-us) | Culture & Employee Insights (https://www.thehartford.com/careers/employee-stories) | Diversity, Equity and Inclusion (https://www.thehartford.com/about-us/corporate-diversity) | Benefits (https://www.thehartford.com/careers/benefits)

Every day, a day to do right.

Showing up for people isn’t just what we do. It’s who we are – and have been for more than 200 years. We’re devoted to finding innovative ways to serve our customers, communities and employees—continually asking ourselves what more we can do.

Is our policy language as simple and inclusive as it can be? Can we better help businesses navigate our ever-changing world? What else can we do to destigmatize mental health in the workplace? Can we make our communities more equitable?

That we can rise to the challenge of these questions is due in no small part to our company values that our employees have shaped and defined.

And while how we contribute looks different for each of us, it’s these values that drive all of us to do more and to do better every day.

About Us (https://www.thehartford.com/about-us)

Our Culture

What It’s Like to Work Here (https://www.thehartford.com/careers/our-employees)

Perks & Benefits

Legal Notice (https://www.thehartford.com/legal-notice)

Accessibility StatementProducer Compensation (https://www.thehartford.com/producer-compensation)

EEO

Privacy Policy (https://www.thehartford.com/online-privacy-policy)

California Privacy Policy

Your California Privacy Choices (https://www.thehartford.com/data-privacy-opt-out-form)

International Privacy Policy

Canadian Privacy Policy (https://www.thehartford.com/canadian-privacy-policy)

Unincorporated Areas of LA County, CA (Applicant Information)

MA Applicant Notice (https://www.thehartford.com/ma-lie-detector)",2025-07-25T02:00:00.000Z,2025-07-25,"['You strive to make an impact every day not only at work, but at home and in the community too', 'We are seeking a Senior Data Scientist with deep expertise in computer vision and a passion for experimentation', 'This role is ideal for someone who thrives in early-stage R&D environments, enjoys working with novel data modalities, and is excited by the challenge of translating emerging capabilities into business value', 'Computer vision and convolutional neural networks (CNNs)', 'Video analytics , including facial detection', 'Rapid experimentation and proof-of-concept development', 'Vendor and technology evaluations in the AI/ML space', 'Collaborate with a high-performing, forward-focused team and engage with product owners and business stakeholders', 'Expand your technical and strategic skills in a role that blends research, experimentation, and business impact', 'Master’s or PhD in a quantitative field such as Data Science, Computer Science, Statistics, Applied Mathematics, or Engineering', 'A Bachelor’s with additional years of relevant experience can substitute for an advanced degree', '5+ years of experience in data science, machine learning, or a related field', 'Proficiency in Python and SQL; experience with cloud platforms (AWS, GCP, or Azure)', 'Strong understanding of statistical modeling, machine learning, and data visualization techniques', 'Excellent problem-solving skills and ability to work independently and collaboratively', 'Strong communication skills with the ability to present complex ideas to diverse audiences', 'Self-motivated, strong sense of ownership/accountability, and results oriented with the ability to manage time and schedules effectively', 'Natural curiosity with a strong desire to learn, maintain, and apply knowledge of emerging data technologies', 'Candidate must be authorized to work in the US without company sponsorship', 'You are a driven and motivated problem solver ready to pursue meaningful work', 'You strive to make an impact every day not only at work, but at home and in the community too', 'We are seeking a Senior Data Scientist with deep expertise in computer vision and a passion for experimentation', 'This role is ideal for someone who thrives in early-stage R&D environments, enjoys working with novel data modalities, and is excited by the challenge of translating emerging capabilities into business value', 'Computer vision and convolutional neural networks (CNNs)', 'Multimodal generative AI , including image-text models', 'Video analytics , including facial detection', 'Rapid experimentation and proof-of-concept development', 'Vendor and technology evaluations in the AI/ML space', 'Collaborate with a high-performing, forward-focused team and engage with product owners and business stakeholders', 'Expand your technical and strategic skills in a role that blends research, experimentation, and business impact', 'Master’s or PhD in a quantitative field such as Data Science, Computer Science, Statistics, Applied Mathematics, or Engineering', 'A Bachelor’s with additional years of relevant experience can substitute for an advanced degree', '5+ years of experience in data science, machine learning, or a related field', 'Proficiency in Python and SQL; experience with cloud platforms (AWS, GCP, or Azure)', 'Strong understanding of statistical modeling, machine learning, and data visualization techniques', 'Excellent problem-solving skills and ability to work independently and collaboratively', 'Strong communication skills with the ability to present complex ideas to diverse audiences', 'Self-motivated, strong sense of ownership/accountability, and results oriented with the ability to manage time and schedules effectively', 'Natural curiosity with a strong desire to learn, maintain, and apply knowledge of emerging data technologies', 'Candidate must be authorized to work in the US without company sponsorship']","['You’ll collaborate closely with other data science and engineering teams, often handing off successful prototypes for production scaling', 'This position will build domain expertise in areas such as:', 'Multimodal generative AI , including image-text models', 'Design and prototype machine learning models for image and video data, with a focus on insurance-relevant use cases', 'Evaluate emerging technologies and vendors, providing technical assessments and recommendations', 'Collaborate with business stakeholders to identify high-impact opportunities for AI innovation', 'Translate ambiguous problems into structured experiments and communicate findings clearly', 'Partner with engineering and data science teams to transition successful prototypes into production-ready solutions', 'Stay current on the latest research and trends in AI, computer vision, and generative models', 'Mentor junior team members and contribute to a culture of curiosity and continuous learning', 'This role will have a Hybrid work schedule, with the expectation of working in an office (Columbus, OH, Chicago, IL, Hartford, CT or Charlotte, NC) 3 days a week (Tuesday through Thursday)', 'You’ll collaborate closely with other data science and engineering teams, often handing off successful prototypes for production scaling', 'This position will build domain expertise in areas such as:', 'Design and prototype machine learning models for image and video data, with a focus on insurance-relevant use cases', 'Evaluate emerging technologies and vendors, providing technical assessments and recommendations', 'Collaborate with business stakeholders to identify high-impact opportunities for AI innovation', 'Translate ambiguous problems into structured experiments and communicate findings clearly', 'Partner with engineering and data science teams to transition successful prototypes into production-ready solutions', 'Stay current on the latest research and trends in AI, computer vision, and generative models', 'Mentor junior team members and contribute to a culture of curiosity and continuous learning']",True,"['Multimodal Generative AI', 'Generative AI']","Multimodal Generative AI: Developing and experimenting with AI models that generate content across multiple data types, such as image-text models.; Generative AI: Exploring and prototyping AI models that create new data, particularly in image and video domains.","['Machine Learning', 'Computer Vision', 'Convolutional Neural Networks', 'Statistical Modeling', 'Data Visualization', 'Python', 'SQL', 'Cloud Platforms', 'Rapid Experimentation', 'Vendor and Technology Evaluation']","Machine Learning: Designing and prototyping models for image and video data to solve insurance-relevant problems.; Computer Vision: Applying techniques such as facial detection and video analytics to extract insights from visual data.; Convolutional Neural Networks: Using CNN architectures to build models for image and video analysis in insurance use cases.; Statistical Modeling: Employing statistical techniques to support data-driven decision making and model development.; Data Visualization: Communicating complex data insights effectively to diverse audiences through visual means.; Python: Programming language used for data science, machine learning model development, and prototyping.; SQL: Querying and managing structured data relevant to insurance and analytics workflows.; Cloud Platforms: Utilizing AWS, GCP, or Azure for scalable data processing, storage, and model deployment.; Rapid Experimentation: Conducting fast proof-of-concept developments to evaluate emerging data technologies and solutions.; Vendor and Technology Evaluation: Assessing AI/ML vendors and technologies to recommend suitable tools for business needs."
8KqSNGiTErw9w2nBAAAAAA==,"US E-Consulting Services-Senior Data Scientist, Specialist Senior-S&T Strategy AIDASD/SFL Scientific-WW (303712)","Senior Data Scientist, Specialist Senior SFL Scientific

Our Deloitte Strategy & Transactions team helps guide clients through their most critical moments and transformational initiatives. From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability. Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journeybefore, during, and after any major transformational projects or transactions.

SFL Scientific, a Deloitte Business, is a U.S. based, data science consulting firm specializing in building industry-specific, artificial intelligence (AI) technologies.

We are hiring a Senior Data Scientist to collaborate directly with clients to design and develop novel projects and solutions. Join a rapidly growing team of professionals working to build a world-class data science practice focused on solving complex and R&D problems.

Recruiting for this role ends on 6/30/2025.

Work Youll Do

As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services. You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions.

Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation. Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills.
• Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production
• Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives
• Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization
• Validate AI models and algorithm via code reviews, unit, and integration tests
• Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives
• Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives

The Team

Our Strategy offering architects bold strategies to achieve business and mission goals, enabling growth, competitive advantage, technology modernization, and continuous digital and AI transformation.

SFL Scientific, a Deloitte Business, is a data science professional services practice focused on strategy, technology, and solving business challenges with Artificial Intelligence (AI). The team has a proven track record serving large, market-leading organizations in the private and public sectors, successfully delivering high-quality, novel and complex projects, and offering deep domain and scientific capabilities. Made up of experienced AI strategists, data scientists, and AI engineers, they serve as trusted advisors to executives, helping them understand and evaluate new and essential areas for AI investment and identify unique opportunities to transform their businesses.

Qualifications:
• Masters or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)
• 3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)
• 3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments
• 3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow
• 3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads
• Live within commuting distance to one of Deloittes consulting offices
• Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve
• Limited immigration sponsorship may be available

Preferred:
• 2+ years of experience working in a client-facing, consulting environment
• 2+ years of experience leading project/client engagement teams in the execution of complex AI data science solutions
• 1+ year of experience with LLM/GenAI use cases and developing RAG solutions, tools, and services (i.e., LangChain, LangGraph, MCP, etc.)
• 1+ year of experience with AWS Sagemaker or AWS ML Studio

Information for applicants with a need for accommodation:

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $107,600 to $198,400.

You may also be eligible to participate in a discretionary annual incentive program, subject to the rules governing the program, whereby an award, if any, depends on various factors, including, without limitation, individual and organizational performance.

#MonitorDeloitte

#DeloitteJobs

#StrategyConsulting

#DeloitteStrategy

#Strategy26

#SFL26
Recruiting tips

From developing a stand out resume to putting your best foot forward in the interview, we want you to feel prepared and confident as you explore opportunities at Deloitte. Check out recruiting tips from Deloitte recruiters. Benefits

At Deloitte, we know that great people make a great organization. We value our people and offer employees a broad range of benefits. Learn more about what working at Deloitte can mean for you. Our people and culture

Our inclusive culture empowers our people to be who they are, contribute their unique perspectives, and make a difference individually and collectively. It enables us to leverage different ideas and perspectives, and bring more creativity and innovation to help solve our clients' most complex challenges. This makes Deloitte one of the most rewarding places to work. Our purpose
Deloittes purpose is to make an impact that matters for our people, clients, and communities. At Deloitte, purpose is synonymous with how we work every day. It defines who we are. Our purpose comes through in our work with clients that enables impact and value in their organizations, as well as through our own investments, commitments, and actions across areas that help drive positive outcomes for our communities. Learn more. Professional development

From entry-level employees to senior leaders, we believe theres always room to learn. We offer opportunities to build new skills, take on leadership opportunities and connect and grow through mentorship. From on-the-job learning experiences to formal development programs, our professionals have a variety of opportunities to continue to grow throughout their career. Position Summary

Senior Data Scientist, Specialist Senior SFL Scientific

Our Deloitte Strategy & Transactions team helps guide clients through their most critical moments and transformational initiatives. From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability. Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journeybefore, during, and after any major transformational projects or transactions.

SFL Scientific, a Deloitte Business, is a U.S. based, data science consulting firm specializing in building industry-specific, artificial intelligence (AI) technologies.

We are hiring a Senior Data Scientist to collaborate directly with clients to design and develop novel projects and solutions. Join a rapidly growing team of professionals working to build a world-class data science practice focused on solving complex and R&D problems.

Recruiting for this role ends on 6/30/2025.

Work Youll Do

As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services. You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions.

Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation. Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills.
• Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production
• Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives
• Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization
• Validate AI models and algorithm via code reviews, unit, and integration tests
• Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives
• Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives

The Team

Our Strategy offering architects bold strategies to achieve business and mission goals, enabling growth, competitive advantage, technology modernization, and continuous digital and AI transformation.

SFL Scientific, a Deloitte Business, is a data science professional services practice focused on strategy, technology, and solving business challenges with Artificial Intelligence (AI). The team has a proven track record serving large, market-leading organizations in the private and public sectors, successfully delivering high-quality, novel and complex projects, and offering deep domain and scientific capabilities. Made up of experienced AI strategists, data scientists, and AI engineers, they serve as trusted advisors to executives, helping them understand and evaluate new and essential areas for AI investment and identify unique opportunities to transform their businesses.

Qualifications:
• Masters or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)
• 3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)
• 3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments
• 3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow
• 3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads
• Live within commuting distance to one of Deloittes consulting offices
• Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve
• Limited immigration sponsorship may be available

Preferred:
• 2+ years of experience working in a client-facing, consulting environment
• 2+ years of experience leading project/client engagement teams in the execution of complex AI data science solutions
• 1+ year of experience with LLM/GenAI use cases and developing RAG solutions, tools, and services (i.e., LangChain, LangGraph, MCP, etc.)
• 1+ year of experience with AWS Sagemaker or AWS ML Studio

Information for applicants with a need for accommodation:

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $107,600 to $198,400.

You may also be eligible to participate in a discretionary annual incentive program, subject to the rules governing the program, whereby an award, if any, depends on various factors, including, without limitation, individual and organizational performance.

#MonitorDeloitte

#DeloitteJobs

#StrategyConsulting

#DeloitteStrategy

#Strategy26

#SFL26
Recruiting tips

From developing a stand out resume to putting your best foot forward in the interview, we want you to feel prepared and confident as you explore opportunities at Deloitte. Check out recruiting tips from Deloitte recruiters. Benefits

At Deloitte, we know that great people make a great organization. We value our people and offer employees a broad range of benefits. Learn more about what working at Deloitte can mean for you. Our people and culture

Our inclusive culture empowers our people to be who they are, contribute their unique perspectives, and make a difference individually and collectively. It enables us to leverage different ideas and perspectives, and bring more creativity and innovation to help solve our clients' most complex challenges. This makes Deloitte one of the most rewarding places to work. Our purpose
Deloittes purpose is to make an impact that matters for our people, clients, and communities. At Deloitte, purpose is synonymous with how we work every day. It defines who we are. Our purpose comes through in our work with clients that enables impact and value in their organizations, as well as through our own investments, commitments, and actions across areas that help drive positive outcomes for our communities. Learn more. Professional development

From entry-level employees to senior leaders, we believe theres always room to learn. We offer opportunities to build new skills, take on leadership opportunities and connect and grow through mentorship. From on-the-job learning experiences to formal development programs, our professionals have a variety of opportunities to continue to grow throughout their career.

As used in this posting, ""Deloitte"" means Deloitte Consulting LLP, a subsidiary of Deloitte LLP. Please see www.deloitte.com/us/about for a detailed description of the legal structure of Deloitte LLP and its subsidiaries.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.
Qualified applicants with criminal histories, including arrest or conviction records, will be considered for employment in accordance with the requirements of applicable state and local laws, including the Los Angeles County Fair Chance Ordinance for Employers, City of Los Angeless Fair Chance Initiative for Hiring Ordinance, San Francisco Fair Chance Ordinance, and the California Fair Chance Act. See notices of various fair chance hiring and ban-the-box laws where available. Fair Chance Hiring and Ban-the-Box Notices | Deloitte US Careers Requisition code: 303712 Job ID 303712 Qualified applicants with criminal histories, including arrest or conviction records, will be considered for employment in accordance with the requirements of applicable state and local laws, including the Los Angeles County Fair Chance Ordinance for Employers, City of Los Angeless Fair Chance Initiative for Hiring Ordinance, San Francisco Fair Chance Ordinance, and the California Fair Chance Act. See notices of various fair chance hiring and ban-the-box laws where available. Fair Chance Hiring and Ban-the-Box Notices | Deloitte US Careers Requisition code: 303712 Job ID 303712 Caution against fraudulent job offers!

We have been informed of instances where jobseekers are led to believe of fictitious job opportunities with Deloitte US (Deloitte). In one or more such cases, false promises of actual or potential selection, or initiation or completion of the recruitment formalities appear to have been or are being made. Some jobseekers appear to have been asked to pay money to specified bank accounts of individuals or entities as a condition of their selection for a job with Deloitte. These individuals or entities are in no way connected with Deloitte and do not represent or otherwise act on behalf of Deloitte.

We would like to clarify that:
• At Deloitte, ethics and integrity are fundamental and not negotiable.
• We are against corruption and neither offer bribes nor accept them, nor induce or permit any other party to make or receive bribes on our behalf.
• We have not authorized any party or person to collect any money from jobseekers in any form whatsoever for promises of getting jobs in Deloitte.
• We consider candidates on merit and that we provide an equal opportunity to eligible applicants.
• No one other than designated Deloitte personnel (e.g., a Deloitte recruiter or Deloitte hiring partner) is permitted to extend any job offer from Deloitte.

Anyone who at any time has made or makes any payment to any party in exchange for promises of job or selection for a job with Deloitte or any matter related to this (including those for registration, verification or security deposit) or otherwise engages with any such person who has made or makes fraudulent promises or offers, does so (or has done so) entirely at their own risk. Deloitte takes no responsibility or liability for any such unauthorized or fraudulent actions or engagements. We encourage jobseekers to exercise caution.",,2025-07-25,"['Masters or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)', '3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)', '3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments', '3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow', '3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads', 'Live within commuting distance to one of Deloittes consulting offices', 'Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve', 'Limited immigration sponsorship may be available', 'Senior Data Scientist, Specialist Senior SFL Scientific', 'Masters or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)', '3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)', '3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments', '3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow', '3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads', 'Live within commuting distance to one of Deloittes consulting offices', 'Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve', 'Limited immigration sponsorship may be available', 'Fair Chance Hiring and Ban-the-Box Notices | Deloitte US Careers Requisition code: 303712 Job ID 303712 Qualified applicants with criminal histories, including arrest or conviction records, will be considered for employment in accordance with the requirements of applicable state and local laws, including the Los Angeles County Fair Chance Ordinance for Employers, City of Los Angeless Fair Chance Initiative for Hiring Ordinance, San Francisco Fair Chance Ordinance, and the California Fair Chance Act']","['From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability', 'Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journeybefore, during, and after any major transformational projects or transactions', 'As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services', 'You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions', 'Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation', 'Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills', 'Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production', 'Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives', 'Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization', 'Validate AI models and algorithm via code reviews, unit, and integration tests', 'Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives', 'Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives', 'From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability', 'Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journeybefore, during, and after any major transformational projects or transactions', 'As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services', 'You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions', 'Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation', 'Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills', 'Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production', 'Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives', 'Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization', 'Validate AI models and algorithm via code reviews, unit, and integration tests', 'Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives', 'Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives']",True,"['Generative AI', 'Large Language Models', 'Retrieval-Augmented Generation', 'Prompt Engineering', 'LangChain', 'LangGraph', 'MCP', 'AWS SageMaker', 'AWS ML Studio', 'Convolutional Neural Networks', 'Recurrent Neural Networks', 'Generative Adversarial Networks', 'Edge AI', 'Autonomous Agents']","Generative AI: Focuses on developing and deploying AI services including LLM/GenAI use cases to create novel client solutions.; Large Language Models: Applied in client projects involving advanced NLP tasks and generative AI capabilities.; Retrieval-Augmented Generation: Used to develop AI tools and services that combine retrieval of information with generative models for enhanced outputs.; Prompt Engineering: Involves designing effective prompts to optimize the performance of generative AI models.; LangChain: A framework utilized for building applications with LLMs and managing AI workflows.; LangGraph: Tool used to support development of AI solutions involving LLMs and generative AI.; MCP: A platform or tool referenced for managing AI pipelines and generative AI services.; AWS SageMaker: Cloud service used to build, train, and deploy machine learning and AI models at scale.; AWS ML Studio: A cloud-based environment for developing and deploying AI/ML models.; Convolutional Neural Networks: Deep learning architecture applied to image-related AI tasks such as cancer detection.; Recurrent Neural Networks: Used for sequential data modeling in AI applications like time-series and NLP.; Generative Adversarial Networks: Applied for generating synthetic data and enhancing AI model capabilities in client projects.; Edge AI: Deployment of AI models on edge devices to enable real-time, decentralized AI solutions.; Autonomous Agents: Development of AI systems capable of independent decision-making and actions in client solutions.","['Exploratory Data Analysis', 'Time-Series Analysis', 'Natural Language Processing', 'Computer Vision', 'Traditional Machine Learning', 'Deep Learning', 'Model Tuning and Performance Validation', 'Model Deployment and Optimization', 'Cloud Computing for AI/ML', 'Kubernetes', 'Docker', 'TensorRT', 'RAPIDs', 'Kubeflow', 'MLflow', 'Python', 'PyTorch', 'AI/ML Algorithm Development']","Exploratory Data Analysis: Used to understand client data sets and operational requirements to inform long-term solution design.; Time-Series Analysis: Applied as part of data analysis techniques to extract insights from sequential data relevant to client projects.; Natural Language Processing: Utilized for analyzing and extracting information from text data as part of AI/ML algorithm development.; Computer Vision: Employed in projects involving image data, such as cancer detection and autonomous systems.; Traditional Machine Learning: Includes development and deployment of ML models for predictive analytics and business solutions.; Deep Learning: Applied for complex pattern recognition tasks using neural networks like CNNs, RNNs, and GANs in real-world projects.; Model Tuning and Performance Validation: Ensures deployed models meet performance standards and business objectives through rigorous testing.; Model Deployment and Optimization: Involves deploying ML models into production environments and optimizing them using tools like Kubernetes and Docker.; Cloud Computing for AI/ML: Leverages cloud platforms such as AWS, Azure, and GCP to deploy and manage AI/ML workloads.; Kubernetes: Used to orchestrate containerized ML model deployments for scalability and reliability.; Docker: Facilitates containerization of ML models and applications for consistent deployment.; TensorRT: Utilized for optimizing deep learning model inference performance in production.; RAPIDs: Applied to accelerate data science and ML workflows using GPU computing.; Kubeflow: Used to build and manage ML pipelines and workflows on Kubernetes.; MLflow: Employed for managing the ML lifecycle including experiment tracking and model registry.; Python: Primary programming language used for AI/ML algorithm development and data analysis.; PyTorch: Framework used for developing deep learning models and neural networks.; AI/ML Algorithm Development: Involves creating and refining algorithms to solve client-specific data science problems."
t4yVfsMzzUfK4VS3AAAAAA==,Senior Data Scientist: 24-03073 (No C2C),"Primary Skills: Python (Expert), Pandas (Proficient), Data Analysis (Expert), Statistical Design (Advanced), SQL (Expert) Contract Type: W2 Duration: 8 Months with possible extension Location: Seattle, WA (#LI-Hybrid) Pay Range: $70.00 - $80.00 Per Hour #LPJob Summary:Join client's Worldwide Sustainability (WWS) organization to play a pivotal role in achieving our ambition to become Earth's most sustainable company through innovation and technology. As a Senior Data Scientist within the Sustainability Science and Innovation (SSI) team, you will leverage cutting-edge data science, analytics, and machine learning to tackle complex sustainability challenges. Key Responsibilities:Develop advanced algorithms and models using Python, with a strong emphasis on the Pandas ecosystem for data manipulation.Ensure production-level code quality, incorporating code refactoring and Git version control.Conduct complex data analysis and statistical modeling, especially with unstructured, real-world datasets.Apply foundational statistical methods and experimental design to derive actionable insights.Handle SQL database querying and manipulation of large datasets, with a preference for those with time series forecasting experience. Must-Have Skills:5+ years experience as a data scientist with ability to translate complex analytical problems into practical solutionsProficient in Python, specifically with object-oriented programming.Extensive experience in production-level code development and version control.Strong capability in statistical modeling and data analysis with large, messy datasets. ABOUT AKRAYAAkraya is an award-winning IT staffing firm consistently recognized for our commitment toexcellence and a thriving work environment. Most recently, we were recognized Inc's Best Workplaces 2024 and Silicon Valley's Best Places to Work by the San Francisco Business Journal (2024) and Glassdoor's Best Places to Work (2023 & 2022)! Industry Leaders in IT Staffing As staffing solutions providers for Fortune 100 companies, Akraya's industry recognitions solidify our leadership position in the IT staffing space. We don't just connect you with great jobs, we connect you with a workplace that inspires! Join Akraya Today! Let us lead you to your dream career and experience the Akraya difference. Browse our open positions and join our team!",,2025-07-25,"['As a Senior Data Scientist within the Sustainability Science and Innovation (SSI) team, you will leverage cutting-edge data science, analytics, and machine learning to tackle complex sustainability challenges', 'Handle SQL database querying and manipulation of large datasets, with a preference for those with time series forecasting experience', 'Must-Have Skills:5+ years experience as a data scientist with ability to translate complex analytical problems into practical solutions', 'Proficient in Python, specifically with object-oriented programming', 'Extensive experience in production-level code development and version control', 'Strong capability in statistical modeling and data analysis with large, messy datasets']","['Key Responsibilities:Develop advanced algorithms and models using Python, with a strong emphasis on the Pandas ecosystem for data manipulation', 'Ensure production-level code quality, incorporating code refactoring and Git version control', 'Conduct complex data analysis and statistical modeling, especially with unstructured, real-world datasets', 'Apply foundational statistical methods and experimental design to derive actionable insights']",True,[],,"['Python', 'Pandas', 'Statistical Modeling', 'SQL', 'Time-Series Forecasting', 'Data Analysis', 'Experimental Design', 'Version Control (Git)', 'Object-Oriented Programming']","Python: Used as the primary programming language for developing advanced algorithms and data manipulation.; Pandas: Employed extensively for data manipulation within the Python ecosystem.; Statistical Modeling: Applied to analyze complex, unstructured datasets and derive actionable insights.; SQL: Used for querying and manipulating large datasets stored in databases.; Time-Series Forecasting: Preferred experience area for analyzing temporal data relevant to sustainability challenges.; Data Analysis: Core responsibility involving examination and interpretation of large, messy datasets.; Experimental Design: Applied foundational statistical methods to design experiments and validate findings.; Version Control (Git): Used to ensure production-level code quality and manage codebase changes.; Object-Oriented Programming: Programming paradigm used in Python to develop maintainable and scalable code."
5Hm8PKlFOHNT-sUnAAAAAA==,Senior Analytics Data Engineer,"Additional Location(s): US-MN-Arden Hills

Diversity - Innovation - Caring - Global Collaboration - Winning Spirit - High Performance

At Boston Scientific, we’ll give you the opportunity to harness all that’s within you by working in teams of diverse and high-performing employees, tackling some of the most important health industry challenges. With access to the latest tools, information and training, we’ll help you in advancing your skills and career. Here, you’ll be supported in progressing – whatever your ambitions.

About the role:

We are seeking a Data Engineer to join our Cardiology Marketing & Digital Enablement (CMDE) team. In this role, you will help build a robust, business-focused data ecosystem that enables enhanced reporting, analytics, and AI-powered marketing. This position is crucial in transforming raw marketing, commercial, and healthcare data into curated, accessible datasets that fuel performance dashboards, audience targeting, campaign optimization, and AI marketing use cases.

Work Mode:

Boston Scientific follows a hybrid work model, requiring team members to be on-site at least three days per week to foster strong collaboration and synergy.

Your responsibilities will include:

Data Engineering & Transformation
• Design, build, and maintain scalable data models and transformation workflows using Snowflake, DBT, and SQL.
• Develop and manage business-ready datasets and data marts to support dashboards, performance tracking, AI/ML use cases, and marketing/commercial applications.
• Setup, monitor and validate data workflows to ensure accuracy, reliability, and timely delivery.
• Review code written by other team members, providing constructive feedback and ensuring adherence to quality standards.
• Guide and support team members, helping them improve their coding skills and understanding coding best practices.

Cross-Functional Collaboration
• Collaborate with Data Product Owners and Business Analysts to gather requirements, translate business needs into technical solutions, and prioritize work based on value and urgency.
• Serve as a data subject matter expert (SME) working directly with marketing, analytics, digital solutions, and commercial stakeholders to quickly assess and resolve data challenges.
• Proactively provide hands-on, responsive support to evolving data needs, from exploratory investigations to production-ready pipelines.

Documentation & Governance
• Maintain clear and thorough documentation for data logic, models, lineage, and workflows.
• Ensure all data processes align with internal governance standards, privacy requirements, and documentation protocols.

Advanced Analytics Support
• Enable and enhance AI-powered marketing initiatives, including lead scoring, real-time personalization, and optimization models by delivering clean, structured, and accessible data.

Required qualifications:
• 5+ years of professional experience in data engineering or a similar technical role focused on transforming and modeling data for business use.
• Expertise in SQL, with hands-on experience designing data models and transformation pipelines in Snowflake and DBT.
• Experience in integrating and transforming data from Salesforce.
• Proven ability to work collaboratively with cross-functional partners while operating independently as a data subject matter expert (SME).
• Strong problem-solving skills and ability to provide responsive, hands-on solutions to data-related questions and requests.
• Familiarity with working in regulated industries or with sensitive business data (e.g., healthcare, life sciences).

Preferred qualifications:
• Bachelor’s degree in information technology, Computer Science, Engineering, or a related field.
• Excellent communication and documentation skills.
• Experience with marketing data (e.g., campaign performance, lead funnel, audience segmentation, web/media analytics).
• Experience with healthcare claims and prescription data.
• Experience with Python for data transformation or workflow automation.
• Knowledge of BI tools (e.g., Tableau, Power BI) and enabling data for self-service use.
• Experience supporting AI/ML applications (e.g., lead scoring, predictive modeling, personalization).

Requisition ID: 608643

Minimum Salary: $ 82600

Maximum Salary: $ 156900

The anticipated compensation listed above and the value of core and optional employee benefits offered by Boston Scientific (BSC) – see www.bscbenefitsconnect.com--will vary based on actual location of the position and other pertinent factors considered in determining actual compensation for the role. Compensation will be commensurate with demonstrable level of experience and training, pertinent education including licensure and certifications, among other relevant business or organizational needs. At BSC, it is not typical for an individual to be hired near the bottom or top of the anticipated salary range listed above.

Compensation for non-exempt (hourly), non-sales roles may also include variable compensation from time to time (e.g., any overtime and shift differential) and annual bonus target (subject to plan eligibility and other requirements).

Compensation for exempt, non-sales roles may also include variable compensation, i.e., annual bonus target and long-term incentives (subject to plan eligibility and other requirements).

For MA positions: It is unlawful to require or administer a lie detector test for employment. Violators are subject to criminal penalties and civil liability.

As a leader in medical science for more than 40 years, we are committed to solving the challenges that matter most – united by a deep caring for human life. Our mission to advance science for life is about transforming lives through innovative medical solutions that improve patient lives, create value for our customers, and support our employees and the communities in which we operate. Now more than ever, we have a responsibility to apply those values to everything we do – as a global business and as a global corporate citizen.

So, choosing a career with Boston Scientific (NYSE: BSX) isn’t just business, it’s personal. And if you’re a natural problem-solver with the imagination, determination, and spirit to make a meaningful difference to people worldwide, we encourage you to apply and look forward to connecting with you!

At Boston Scientific, we recognize that nurturing a diverse and inclusive workplace helps us be more innovative and it is important in our work of advancing science for life and improving patient health. That is why we stand for inclusion, equality, and opportunity for all. By embracing the richness of our unique backgrounds and perspectives, we create a better, more rewarding place for our employees to work and reflect the patients, customers, and communities we serve.

Boston Scientific Corporation has been and will continue to be an equal opportunity employer. To ensure full implementation of its equal employment policy, the Company will continue to take steps to assure that recruitment, hiring, assignment, promotion, compensation, and all other personnel decisions are made and administered without regard to race, religion, color, national origin, citizenship, sex, sexual orientation, gender identify, gender expression, veteran status, age, mental or physical disability, genetic information or any other protected class.

Please be advised that certain US based positions, including without limitation field sales and service positions that call on hospitals and/or health care centers, require acceptable proof of COVID-19 vaccination status. Candidates will be notified during the interview and selection process if the role(s) for which they have applied require proof of vaccination as a condition of employment. Boston Scientific continues to evaluate its policies and protocols regarding the COVID-19 vaccine and will comply with all applicable state and federal law and healthcare credentialing requirements. As employees of the Company, you will be expected to meet the ongoing requirements for your roles, including any new requirements, should the Company’s policies or protocols change with regard to COVID-19 vaccination.

Among other requirements, Boston Scientific maintains specific prohibited substance test requirements for safety-sensitive positions. This role is deemed safety-sensitive and, as such, candidates will be subject to a prohibited substance test as a requirement. The goal of the prohibited substance testing is to increase workplace safety in compliance with the applicable law.",2025-06-29T00:00:00.000Z,2025-07-25,"['5+ years of professional experience in data engineering or a similar technical role focused on transforming and modeling data for business use', 'Expertise in SQL, with hands-on experience designing data models and transformation pipelines in Snowflake and DBT', 'Experience in integrating and transforming data from Salesforce', 'Proven ability to work collaboratively with cross-functional partners while operating independently as a data subject matter expert (SME)', 'Strong problem-solving skills and ability to provide responsive, hands-on solutions to data-related questions and requests', 'Familiarity with working in regulated industries or with sensitive business data (e.g., healthcare, life sciences)']","['In this role, you will help build a robust, business-focused data ecosystem that enables enhanced reporting, analytics, and AI-powered marketing', 'This position is crucial in transforming raw marketing, commercial, and healthcare data into curated, accessible datasets that fuel performance dashboards, audience targeting, campaign optimization, and AI marketing use cases', 'Boston Scientific follows a hybrid work model, requiring team members to be on-site at least three days per week to foster strong collaboration and synergy', 'Design, build, and maintain scalable data models and transformation workflows using Snowflake, DBT, and SQL', 'Develop and manage business-ready datasets and data marts to support dashboards, performance tracking, AI/ML use cases, and marketing/commercial applications', 'Setup, monitor and validate data workflows to ensure accuracy, reliability, and timely delivery', 'Review code written by other team members, providing constructive feedback and ensuring adherence to quality standards', 'Guide and support team members, helping them improve their coding skills and understanding coding best practices', 'Cross-Functional Collaboration', 'Collaborate with Data Product Owners and Business Analysts to gather requirements, translate business needs into technical solutions, and prioritize work based on value and urgency', 'Serve as a data subject matter expert (SME) working directly with marketing, analytics, digital solutions, and commercial stakeholders to quickly assess and resolve data challenges', 'Proactively provide hands-on, responsive support to evolving data needs, from exploratory investigations to production-ready pipelines', 'Documentation & Governance', 'Maintain clear and thorough documentation for data logic, models, lineage, and workflows', 'Ensure all data processes align with internal governance standards, privacy requirements, and documentation protocols', 'Advanced Analytics Support', 'Enable and enhance AI-powered marketing initiatives, including lead scoring, real-time personalization, and optimization models by delivering clean, structured, and accessible data']",False,['AI-Powered Marketing'],AI-Powered Marketing: Enabling marketing initiatives that leverage AI techniques like lead scoring and real-time personalization to optimize campaigns.,"['Data Engineering', 'SQL', 'Snowflake', 'DBT', 'Data Pipelines', 'Business Intelligence Tools', 'Python for Data Transformation', 'Marketing Analytics', 'AI/ML Use Cases', 'Data Governance', 'Salesforce Data Integration']","Data Engineering: Designing and maintaining scalable data models and transformation workflows to support business analytics and AI/ML use cases.; SQL: Used for querying and transforming data within Snowflake and other data platforms to build business-ready datasets.; Snowflake: Cloud data platform used for building and managing scalable data models and transformation pipelines.; DBT: Tool for data transformation and modeling to create reliable, tested data workflows and marts.; Data Pipelines: Setup, monitoring, and validation of workflows to ensure accurate and timely delivery of data for analytics and AI applications.; Business Intelligence Tools: Tools like Tableau and Power BI used to create dashboards and enable self-service analytics for marketing and commercial stakeholders.; Python for Data Transformation: Used to automate data workflows and perform data transformation tasks supporting analytics and AI initiatives.; Marketing Analytics: Analyzing campaign performance, lead funnel, audience segmentation, and web/media analytics to optimize marketing efforts.; AI/ML Use Cases: Supporting AI and machine learning applications such as lead scoring, predictive modeling, and personalization by delivering clean and structured data.; Data Governance: Ensuring data processes comply with internal standards, privacy requirements, and documentation protocols.; Salesforce Data Integration: Integrating and transforming data from Salesforce to enrich datasets for marketing and commercial analytics."
kMUAZ8sBtdhk9a-cAAAAAA==,"Senior Data Scientist, Specialist Senior - SFL Scientific - Full-time","Senior Data Scientist, Specialist Senior - SFL Scientific

Our Deloitte Strategy & Transactions team helps guide clients through their most critical moments and transformational initiatives. From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability. Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journey-before, during, and after any major transformational projects or transactions.

SFL Scientific, a Deloitte Business, is a U.S. based, data science consulting firm specializing in building industry-specific, artificial intelligence (AI) technologies.

We are hiring a Senior Data Scientist to collaborate directly with clients to design and develop novel projects and solutions. Join a rapidly growing team of professionals working to build a world-class data science practice focused on solving complex and R&D problems.

Recruiting for this role ends on 7/31/2025.

Work You'll Do

As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services. You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions.

Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation. Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills.

+ Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production

+ Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives

+ Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization

+ Validate AI models and algorithm via code reviews, unit, and integration tests

+ Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives

+ Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives

The Team

Our Strategy offering architects bold strategies to achieve business and mission goals, enabling growth, competitive advantage, technology modernization, and continuous digital and AI transformation.

SFL Scientific, a Deloitte Business, is a data science professional services practice focused on strategy, technology, and solving business challenges with Artificial Intelligence (AI). The team has a proven track record serving large, market-leading organizations in the private and public sectors, successfully delivering high-quality, novel and complex projects, and offering deep domain and scientific capabilities. Made up of experienced AI strategists, data scientists, and AI engineers, they serve as trusted advisors to executives, helping them understand and evaluate new and essential areas for AI investment and identify unique opportunities to transform their businesses.

Qualifications:

+ Master's or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)

+ 3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)

+ 3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments

+ 3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow

+ 3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads

+ Live within commuting distance to one of Deloitte's consulting offices

+ Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve

+ Limited immigration sponsorship may be available

Preferred:

+ 2+ years of experience working in a client-facing, consulting environment

+ 2+ years of experience leading project/client engagement teams in the execution of complex AI data science solutions

+ 1+ year of experience with LLM/GenAI use cases and developing RAG solutions, tools, and services (i.e., LangChain, LangGraph, MCP, etc.)

+ 1+ year of experience with AWS Sagemaker or AWS ML Studio

Information for applicants with a need for accommodation: https://www2.deloitte.com/us/en/pages/careers/articles/join-deloitte-assistance-for-disabled-applicants.html

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $107,600 to $198,400.

You may also be eligible to participate in a discretionary annual incentive program, subject to the rules governing the program, whereby an award, if any, depends on various factors, including, without limitation, individual and organizational performance.

#MonitorDeloitte

#DeloitteJobs

#StrategyConsulting

#DeloitteStrategy

#Strategy26

#SFL26

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.

Senior Data Scientist, Specialist Senior - SFL Scientific

Our Deloitte Strategy & Transactions team helps guide clients through their most critical moments and transformational initiatives. From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability. Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journey-before, during, and after any major transformational projects or transactions.

SFL Scientific, a Deloitte Business, is a U.S. based, data science consulting firm specializing in building industry-specific, artificial intelligence (AI) technologies.

We are hiring a Senior Data Scientist to collaborate directly with clients to design and develop novel projects and solutions. Join a rapidly growing team of professionals working to build a world-class data science practice focused on solving complex and R&D problems.

Recruiting for this role ends on 7/31/2025.

Work You'll Do

As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services. You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions.

Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation. Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills.

+ Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production

+ Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives

+ Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization

+ Validate AI models and algorithm via code reviews, unit, and integration tests

+ Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives

+ Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives

The Team

Our Strategy offering architects bold strategies to achieve business and mission goals, enabling growth, competitive advantage, technology modernization, and continuous digital and AI transformation.

SFL Scientific, a Deloitte Business, is a data science professional services practice focused on strategy, technology, and solving business challenges with Artificial Intelligence (AI). The team has a proven track record serving large, market-leading organizations in the private and public sectors, successfully delivering high-quality, novel and complex projects, and offering deep domain and scientific capabilities. Made up of experienced AI strategists, data scientists, and AI engineers, they serve as trusted advisors to executives, helping them understand and evaluate new and essential areas for AI investment and identify unique opportunities to transform their businesses.

Qualifications:

+ Master's or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)

+ 3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)

+ 3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments

+ 3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow

+ 3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads

+ Live within commuting distance to one of Deloitte's consulting offices

+ Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve

+ Limited immigration sponsorship may be available

Preferred:

+ 2+ years of experience working in a client-facing, consulting environment

+ 2+ years of experience leading project/client engagement teams in the execution of complex AI data science solutions

+ 1+ year of experience with LLM/GenAI use cases and developing RAG solutions, tools, and services (i.e., LangChain, LangGraph, MCP, etc.)

+ 1+ year of experience with AWS Sagemaker or AWS ML Studio

Information for applicants with a need for accommodation: https://www2.deloitte.com/us/en/pages/careers/articles/join-deloitte-assistance-for-disabled-applicants.html

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $107,600 to $198,400.

You may also be eligible to participate in a discretionary annual incentive program, subject to the rules governing the program, whereby an award, if any, depends on various factors, including, without limitation, individual and organizational performance.

#MonitorDeloitte

#DeloitteJobs

#StrategyConsulting

#DeloitteStrategy

#Strategy26

#SFL26

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.",2025-07-25T02:00:00.000Z,2025-07-25,"[""Master's or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)"", '3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)', '3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments', '3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow', '3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads', ""Live within commuting distance to one of Deloitte's consulting offices"", 'Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve', 'Limited immigration sponsorship may be available', ""Master's or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)"", '3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)', '3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments', '3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow', '3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads', ""Live within commuting distance to one of Deloitte's consulting offices"", 'Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve', 'Limited immigration sponsorship may be available']","['From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability', 'Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journey-before, during, and after any major transformational projects or transactions', 'As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services', 'You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions', 'Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation', 'Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills', 'Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production', 'Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives', 'Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization', 'Validate AI models and algorithm via code reviews, unit, and integration tests', 'Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives', 'Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives', 'From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability', 'Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journey-before, during, and after any major transformational projects or transactions', 'As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services', 'You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions', 'Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation', 'Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills', 'Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production', 'Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives', 'Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization', 'Validate AI models and algorithm via code reviews, unit, and integration tests', 'Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives', 'Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives']",True,"['Generative AI', 'Large Language Models', 'Retrieval-Augmented Generation', 'Prompt Engineering', 'LangChain', 'LangGraph', 'MCP', 'AWS SageMaker', 'AWS ML Studio', 'Convolutional Neural Networks', 'Recurrent Neural Networks', 'Generative Adversarial Networks']","Generative AI: Involved in developing and deploying generative AI solutions including LLM/GenAI use cases.; Large Language Models: Experience with LLMs for advanced AI applications and client solutions.; Retrieval-Augmented Generation: Developed RAG solutions and services to enhance AI model capabilities.; Prompt Engineering: Applied in designing effective prompts for LLMs and generative AI models.; LangChain: Used as a tool for building applications with LLMs and generative AI.; LangGraph: Employed for constructing AI workflows and managing generative AI pipelines.; MCP: Utilized as part of AI services and tools for managing generative AI models.; AWS SageMaker: Cloud service used for building, training, and deploying machine learning and AI models.; AWS ML Studio: Platform for developing and deploying AI/ML models in cloud environments.; Convolutional Neural Networks: Deep learning architecture applied for computer vision tasks in AI projects.; Recurrent Neural Networks: Deep learning models used for sequential data processing in AI applications.; Generative Adversarial Networks: Deep learning technique used for generating synthetic data and advanced AI modeling.","['Exploratory Data Analysis', 'Machine Learning', 'Deep Learning', 'Natural Language Processing', 'Time-Series Analysis', 'Computer Vision', 'Python', 'PyTorch', 'Kubernetes', 'Docker', 'TensorRT', 'RAPIDs', 'Kubeflow', 'MLflow', 'Cloud Platforms', 'Valuation Modeling', 'Cost Optimization', 'Restructuring Analytics', 'Mergers and Acquisitions Analytics']","Exploratory Data Analysis: Used to understand client data sets and operational requirements to design long-term data science solutions.; Machine Learning: Applied to develop AI/ML solutions, including traditional ML algorithm development and model tuning for production environments.; Deep Learning: Utilized techniques such as CNNs, RNNs, and GANs for real-world projects including model performance validation.; Natural Language Processing: Employed for data analysis tasks involving text data as part of AI/ML algorithm development.; Time-Series Analysis: Used for analyzing sequential data as part of AI/ML algorithm development.; Computer Vision: Applied in projects involving image data analysis and model development.; Python: Primary programming language used for AI/ML algorithm development and data analysis.; PyTorch: Framework used for developing AI/ML algorithms and deep learning models.; Kubernetes: Used to deploy and optimize machine learning models in production environments.; Docker: Containerization tool used for deploying and managing ML models.; TensorRT: Tool for optimizing deep learning model inference performance.; RAPIDs: Used for accelerating data science and machine learning workflows on GPUs.; Kubeflow: Platform for deploying, orchestrating, and managing ML workflows.; MLflow: Tool for managing the ML lifecycle including experimentation, reproducibility, and deployment.; Cloud Platforms: Leveraged AWS, Azure, or GCP environments to deploy AI/ML workloads.; Valuation Modeling: Part of advisory services involving financial data analysis to support client decision-making.; Cost Optimization: Data-driven approach to improve client operational efficiency and reduce expenses.; Restructuring Analytics: Applied data science techniques to support business transformation and restructuring projects.; Mergers and Acquisitions Analytics: Used data analysis to support M&A advisory and decision-making processes."
KowIDlQ5DAMy2r0SAAAAAA==,"Senior Data Scientist, Pricing & Promotions","Are you a data-driven problem solver with a passion for pets? Do you thrive in a fast-paced and dynamic environment? Petco is looking for a Senior Data Scientist, Pricing & Promotions to join our team and drive impactful insights to optimize our pricing and promotions strategies. As a key member of our data science team, you will have the opportunity to make a significant impact on our business and help shape the future of the pet retail industry. If you have a strong background in data analysis, statistical modeling, and a knack for translating complex data into actionable business recommendations, we want to hear from you! Join us and use your expertise to help Petco continue to provide the best products and services for pet parents and their furry companions.

Conduct data analysis and develop statistical models to optimize pricing and promotions strategies for Petco.

Collaborate with cross-functional teams, including marketing, merchandising, and finance, to understand business objectives and provide data-driven recommendations.

Utilize data mining techniques to identify patterns and trends in customer behavior and purchasing habits.

Develop and maintain predictive models to forecast sales and evaluate the effectiveness of pricing and promotions strategies.

Communicate complex data and insights in a clear and concise manner to non-technical stakeholders.

Continuously monitor and analyze data to identify opportunities for improvement and provide proactive recommendations.

Stay current with industry trends and advancements in data science to drive innovation and improve processes.

Lead and mentor junior data scientists to support their professional growth and development.

Collaborate with IT teams to ensure data integrity and develop processes for data extraction and analysis.

Use advanced analytics techniques to develop pricing and promotions strategies for new products and services.

Petco is an Equal Opportunity Employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. We do not discriminate based upon race, religion, color, national origin, sex, sexual orientation, gender identity, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.",,2025-07-25,,"['If you have a strong background in data analysis, statistical modeling, and a knack for translating complex data into actionable business recommendations, we want to hear from you!', 'Join us and use your expertise to help Petco continue to provide the best products and services for pet parents and their furry companions', 'Conduct data analysis and develop statistical models to optimize pricing and promotions strategies for Petco', 'Collaborate with cross-functional teams, including marketing, merchandising, and finance, to understand business objectives and provide data-driven recommendations', 'Utilize data mining techniques to identify patterns and trends in customer behavior and purchasing habits', 'Develop and maintain predictive models to forecast sales and evaluate the effectiveness of pricing and promotions strategies', 'Communicate complex data and insights in a clear and concise manner to non-technical stakeholders', 'Continuously monitor and analyze data to identify opportunities for improvement and provide proactive recommendations', 'Stay current with industry trends and advancements in data science to drive innovation and improve processes', 'Lead and mentor junior data scientists to support their professional growth and development', 'Collaborate with IT teams to ensure data integrity and develop processes for data extraction and analysis', 'Use advanced analytics techniques to develop pricing and promotions strategies for new products and services']",True,[],,"['Data Analysis', 'Statistical Modeling', 'Data Mining', 'Predictive Modeling', 'Advanced Analytics', 'Data Extraction']",Data Analysis: Used to examine and interpret complex data sets to inform pricing and promotions strategies.; Statistical Modeling: Applied to develop models that optimize pricing and promotions based on historical data.; Data Mining: Employed to identify patterns and trends in customer behavior and purchasing habits.; Predictive Modeling: Used to forecast sales and evaluate the effectiveness of pricing and promotions strategies.; Advanced Analytics: Utilized to develop sophisticated pricing and promotions strategies for new products and services.; Data Extraction: Collaborated with IT teams to ensure data integrity and develop processes for extracting data for analysis.
JsXfvWL8uZiXqvP5AAAAAA==,"Senior Data Scientist, Product Analytics","The core responsibilities of the Senior Data Scientist entail a collaborative engagement with key business units to elevate consumer engagement, and conversion rates, and streamline the consumer journey within our ecosystem. By spearheading initiatives to enhance the quality of clickstream tracking and performing in-depth analyses, the successful candidate will unlock new understandings and track shifts in consumer behavior. This role offers a unique opportunity to make a significant, swift impact within the company.

Working in concert with leaders from Product, Design, and Engineering, this role is instrumental in guiding http://Realtor.com ‘s strategic direction. The ideal candidate will have demonstrated success in utilizing web analytics and event tracking to navigate complex data landscapes, delivering insights that drive informed decision-making across the organization. Their mastery of data science and advanced analytics will be vital in distilling valuable information from extensive datasets. Moreover, we are searching for someone who can effectively influence executives and stakeholders, fostering a culture of disciplined achievement.

Candidates should be well-versed in areas such as clickstream tracking, optimizing consumer funnels, consumer analytics, segmentation, and the execution of A/B testing. Responsibilities will also include crafting tracking plans to bolster engagement, analyzing A/B testing results, spotting product development opportunities, dissecting consumer behavior, conducting thorough pre-post analyses, and precisely measuring and reporting performance metrics across http://Realtor.com ‘s consumer internet business segments.

What you’ll do:
• Support the Product team in accomplishing the goals and objectives of the Consumer internet businesses.
• Partner with the engineering and business intelligence teams to drive improvements to track and data quality.
• Conduct deep-dive analysis of complex datasets to understand product performance using statistical techniques, machine learning algorithms, and data visualization tools.
• Identify patterns, trends, and correlations in data to uncover actionable insights and provide recommendations for business improvement.
• Develop and monitor KPIs to drive high-level oversight of business initiatives and company health, and develop regular insights from the data to enable performance management and facilitate accountabilities
• Communicate findings and insights to technical and non-technical stakeholders through clear and compelling visualizations, reports, and presentations.
• Partner with the Product organization on data-driven decision-making, idea generation, and rigorous measurement.
• Lead exploratory analysis to identify and size product development opportunities to determine tradeoffs between product features that grow and optimize the product offering
• Guide and inform OKR development with product leadership.

How we work:

We balance creativity and innovation on a foundation of in-person collaboration. For most roles, our employees work three or more days in our offices, where they have the opportunity to collaborate in-person, adding richness to our culture and knitting us closer together.

What you’ll bring:
• Bachelor’s or Master’s degree with a focus in Analytics, Product Marketing, Statistics, Applied Math, Data Science, Economics, or a related field.
• 5+ years’ experience as a Data Analyst or similar role, with a focus on web analytics or data science
• Experience with designing and executing A/B testing experiments to evaluate the effectiveness of different strategies and interventions, analyzing the results to provide actionable insights and recommendations
• Strong analytical, critical thinking, decision-making, and problem-solving skills; Experience with Product Analytics a plus.
• Solid understanding of SQL and experience working with relational databases.
• Experience in digital tools, including Adobe Analytics, Google Analytics, and data visualization tools such as Tableau, Looker, or Power BI
• Proficiency in programming languages such as Python or R for data analysis and modeling.
• Proven track record of translating business problems into an analytical framework, developing plans for answering complex problems, and delivering analytic insights.
• Experience applying advanced analytic disciplines to financial, consumer audience/user experience, and product-level modeling, forecasting, marketing, etc.
• Strong communication and presentation skills, with the ability to convey complex ideas to both technical and non-technical stakeholders.
• Ability to remain flexible and thrive in a fast-paced and often hectic environment

Do the best work of your life at Realtor.com

Building your career? Build it better at Realtor.com®. Here, you’ll partner with a diverse team of experts as you use leading-edge tech to empower everyone to meet a crucial goal: finding their way home. And you’ll find your way home too. People are our foundation—the core that drives us passionately forward. At Realtor.com, you’ll bring your full self to work as you innovate with speed, serve our consumers, and champion your teammates. In return we’ll provide you with a warm, welcoming, and inclusive culture; intellectual challenges; and the development opportunities you need to grow.

Do the best work of your life at Realtor.com®

Here, you’ll partner with a diverse team of experts as you use leading-edge tech to empower everyone to meet a crucial goal: finding their way home. And you’ll find your way home too. People are our foundation—the core that drives us passionately forward. At Realtor.com®, you’ll bring your full self to work as you innovate with speed, serve our consumers, and champion your teammates. In return we’ll provide you with a warm, welcoming, and inclusive culture; intellectual challenges; and the development opportunities you need to grow.",,2025-07-25,"['Bachelor’s or Master’s degree with a focus in Analytics, Product Marketing, Statistics, Applied Math, Data Science, Economics, or a related field', '5+ years’ experience as a Data Analyst or similar role, with a focus on web analytics or data science', 'Experience with designing and executing A/B testing experiments to evaluate the effectiveness of different strategies and interventions, analyzing the results to provide actionable insights and recommendations', 'Solid understanding of SQL and experience working with relational databases', 'Experience in digital tools, including Adobe Analytics, Google Analytics, and data visualization tools such as Tableau, Looker, or Power BI', 'Proficiency in programming languages such as Python or R for data analysis and modeling', 'Proven track record of translating business problems into an analytical framework, developing plans for answering complex problems, and delivering analytic insights', 'Experience applying advanced analytic disciplines to financial, consumer audience/user experience, and product-level modeling, forecasting, marketing, etc', 'Strong communication and presentation skills, with the ability to convey complex ideas to both technical and non-technical stakeholders', 'Ability to remain flexible and thrive in a fast-paced and often hectic environment']","['The core responsibilities of the Senior Data Scientist entail a collaborative engagement with key business units to elevate consumer engagement, and conversion rates, and streamline the consumer journey within our ecosystem', 'By spearheading initiatives to enhance the quality of clickstream tracking and performing in-depth analyses, the successful candidate will unlock new understandings and track shifts in consumer behavior', 'This role offers a unique opportunity to make a significant, swift impact within the company', 'Working in concert with leaders from Product, Design, and Engineering, this role is instrumental in guiding http://Realtor.com ‘s strategic direction', 'The ideal candidate will have demonstrated success in utilizing web analytics and event tracking to navigate complex data landscapes, delivering insights that drive informed decision-making across the organization', 'Their mastery of data science and advanced analytics will be vital in distilling valuable information from extensive datasets', 'Candidates should be well-versed in areas such as clickstream tracking, optimizing consumer funnels, consumer analytics, segmentation, and the execution of A/B testing', 'Responsibilities will also include crafting tracking plans to bolster engagement, analyzing A/B testing results, spotting product development opportunities, dissecting consumer behavior, conducting thorough pre-post analyses, and precisely measuring and reporting performance metrics across http://Realtor.com ‘s consumer internet business segments', 'Support the Product team in accomplishing the goals and objectives of the Consumer internet businesses', 'Partner with the engineering and business intelligence teams to drive improvements to track and data quality', 'Conduct deep-dive analysis of complex datasets to understand product performance using statistical techniques, machine learning algorithms, and data visualization tools', 'Identify patterns, trends, and correlations in data to uncover actionable insights and provide recommendations for business improvement', 'Develop and monitor KPIs to drive high-level oversight of business initiatives and company health, and develop regular insights from the data to enable performance management and facilitate accountabilities', 'Communicate findings and insights to technical and non-technical stakeholders through clear and compelling visualizations, reports, and presentations', 'Partner with the Product organization on data-driven decision-making, idea generation, and rigorous measurement', 'Lead exploratory analysis to identify and size product development opportunities to determine tradeoffs between product features that grow and optimize the product offering', 'Guide and inform OKR development with product leadership']",True,[],,"['Clickstream Tracking', 'Web Analytics', 'A/B Testing', 'SQL', 'Python', 'R', 'Machine Learning Algorithms', 'Data Visualization Tools', 'Adobe Analytics', 'Google Analytics', 'Consumer Analytics', 'Segmentation', 'Pre-Post Analysis', 'KPI Development and Monitoring', 'Statistical Techniques', 'Forecasting', 'Product Analytics']","Clickstream Tracking: Used to collect detailed data on user interactions within the consumer journey to analyze behavior and improve engagement.; Web Analytics: Applied to navigate complex data landscapes and deliver insights that inform strategic decision-making across the organization.; A/B Testing: Designed and executed to evaluate the effectiveness of different strategies and interventions, providing actionable insights.; SQL: Used for querying and managing relational databases to support data analysis and reporting.; Python: Utilized for data analysis, modeling, and applying machine learning algorithms to understand product performance.; R: Employed for statistical analysis and modeling to extract insights from complex datasets.; Machine Learning Algorithms: Applied to analyze product performance and identify patterns, trends, and correlations in data.; Data Visualization Tools: Tools like Tableau, Looker, and Power BI are used to communicate findings and insights effectively to stakeholders.; Adobe Analytics: Used as a digital tool to enhance data tracking and analysis for consumer internet business segments.; Google Analytics: Employed to monitor and analyze web traffic and user behavior to support product analytics.; Consumer Analytics: Focused on segmenting and understanding consumer behavior to optimize funnels and product offerings.; Segmentation: Used to categorize consumers into meaningful groups for targeted analysis and product optimization.; Pre-Post Analysis: Conducted to measure the impact of interventions or changes on consumer behavior and product performance.; KPI Development and Monitoring: Implemented to oversee business initiatives and company health through regular performance insights.; Statistical Techniques: Applied to perform deep-dive analyses and extract actionable insights from large datasets.; Forecasting: Used to predict future trends and support product-level and financial modeling.; Product Analytics: Focused on analyzing product performance and identifying development opportunities to optimize offerings."
cREQcTyFGDviP22PAAAAAA==,Senior Data Engineer,"EquipmentShare is Hiring a Senior Data Engineer.
Your role in our team

At EquipmentShare, we believe it’s more than just a job. We invest in our people and encourage you to choose the best path for your career. It’s truly about you, your future, and where you want to go.

We are looking for a Senior Data Engineer to help us continue to build the next evolution of our data platform in a scalable, performant, and customer-centric architecture.

Our main tech stack includes Snowflake, Apache Airflow, AWS cloud infrastructure (e.g., Kinesis, Kubernetes/EKS, Lambda, Aurora RDS PostgreSQL), Python and Typescript.
What you'll be doing

We are typically organized into agile cross-functional teams composed of Engineering, Product, and Design, which allows us to develop deep expertise and rapidly deliver high-value features and functionality to our next-generation T3 Platform.

You’ll be part of a close-knit team of data engineers developing and maintaining a data platform built with automation and self-service in mind to support analytics and machine learning data products for the next generation of our T3 Fleet that enable end-users to track, monitor and manage the health of their connected vehicles and deployed assets.

We'll be there to support you as you become familiar with our teams, product domains, tech stack and processes — generally how we all work together.

Primary responsibilities for a Senior Data Engineer
• Collaborate with Product Managers, Designers, Engineers, Data Scientists and Data Analysts to take ideas from concept to production at scale.
• Design, build and maintain our data platform to enable automation and self-service for data scientists, machine learning engineers and analysts.
• Design, build and maintain data product framework to support EquipmentShare application data science and analytics features.
• Design, build and maintain CI/CD pipelines and automated data and machine learning deployment processes.
• Develop data monitoring and alerting capabilities.
• Document architecture, processes and procedures for knowledge sharing and cross-team collaboration.
• Mentor peers to help them build their skills.
Why We’re a Better Place to Work

We can promise that every day will be a little different with new ideas, challenges and rewards.

We’ve been growing as a team and we are not finished just yet— there is plenty of opportunity to shape how we deliver together.

Our mission is to enable the construction industry with tools that unlock substantial increases to productivity. Together with our team and customers, we are building the future of construction.

T3 is the only cloud-based operating system that brings together construction workflows & data from constantly moving elements in one place.
• Competitive base salary and market leading equity package.
• Unlimited PTO.
• Remote first.
• True work/life balance.
• Medical, Dental, Vision and Life Insurance coverage.
• 401(k) + match.
• Opportunities for career and professional development with conferences, events, seminars and continued education.
• On-site fitness center at the Home Office in Columbia, Missouri, complete with weightlifting machines, cardio equipment, group fitness space, racquetball courts, a climbing wall, and much more!
• Volunteering and local charity support that help you nurture and grow the communities you call home through our Giving Back initiative.
• Stocked breakroom and full kitchen with breakfast and lunch provided daily by our chef and kitchen crew.
About You

You're a hands-on developer who enjoys solving complex problems and building impactful solutions. Most importantly, you care about making a difference.
• Take the initiative to own outcomes from start to finish — knowing what needs to be accomplished within your domain and how we work together to deliver the best solution.
• You are passionate about developing your craft — you understand what it takes to build quality, robust and scalable solutions.
• You’ll see the learning opportunity when things don’t quite go to plan — not only for you but for how we continuously improve as a team.
• You take a hypothesis-driven approach — knowing how to source, create and leverage data to inform decision making, using data to drive how we improve, to shape how we evaluate and make platform recommendations.
So, what is important to us?

Above all, you’ll get stuff done. More importantly, you’ll collaborate to do the right things in the right way to achieve the right outcomes.
• 7+ years of relevant data platform development experience building production-grade solutions.
• Proficient with SQL and a high-order object-oriented language (e.g., Python).
• Experience with designing and building distributed data architecture.
• Experience building and managing production-grade data pipelines using tools such as Airflow, dbt, DataHub, MLFlow
• Experience building and managing production-grade data platforms using distributed systems such as Kafka, Spark, Flink and/or others.
• Familiarity with event data streaming at scale.
• Proven track record learning new technologies and applying that learning quickly.
• Experience building observability and monitoring into data products.
• Motivated to identify opportunities for automation to reduce manual toil.

EquipmentShare is committed to a diverse and inclusive workplace. EquipmentShare is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status.

#LI-Remote",,2025-07-25,"[""You're a hands-on developer who enjoys solving complex problems and building impactful solutions"", 'Take the initiative to own outcomes from start to finish — knowing what needs to be accomplished within your domain and how we work together to deliver the best solution', 'You are passionate about developing your craft — you understand what it takes to build quality, robust and scalable solutions', 'You’ll see the learning opportunity when things don’t quite go to plan — not only for you but for how we continuously improve as a team', 'You take a hypothesis-driven approach — knowing how to source, create and leverage data to inform decision making, using data to drive how we improve, to shape how we evaluate and make platform recommendations', '7+ years of relevant data platform development experience building production-grade solutions', 'Proficient with SQL and a high-order object-oriented language (e.g., Python)', 'Experience with designing and building distributed data architecture', 'Experience building and managing production-grade data pipelines using tools such as Airflow, dbt, DataHub, MLFlow', 'Experience building and managing production-grade data platforms using distributed systems such as Kafka, Spark, Flink and/or others', 'Familiarity with event data streaming at scale', 'Experience building observability and monitoring into data products', 'Motivated to identify opportunities for automation to reduce manual toil']","['We are typically organized into agile cross-functional teams composed of Engineering, Product, and Design, which allows us to develop deep expertise and rapidly deliver high-value features and functionality to our next-generation T3 Platform', 'You’ll be part of a close-knit team of data engineers developing and maintaining a data platform built with automation and self-service in mind to support analytics and machine learning data products for the next generation of our T3 Fleet that enable end-users to track, monitor and manage the health of their connected vehicles and deployed assets', ""We'll be there to support you as you become familiar with our teams, product domains, tech stack and processes — generally how we all work together"", 'Primary responsibilities for a Senior Data Engineer', 'Collaborate with Product Managers, Designers, Engineers, Data Scientists and Data Analysts to take ideas from concept to production at scale', 'Design, build and maintain our data platform to enable automation and self-service for data scientists, machine learning engineers and analysts', 'Design, build and maintain data product framework to support EquipmentShare application data science and analytics features', 'Design, build and maintain CI/CD pipelines and automated data and machine learning deployment processes', 'Develop data monitoring and alerting capabilities', 'Document architecture, processes and procedures for knowledge sharing and cross-team collaboration', 'Mentor peers to help them build their skills', 'Volunteering and local charity support that help you nurture and grow the communities you call home through our Giving Back initiative', 'Stocked breakroom and full kitchen with breakfast and lunch provided daily by our chef and kitchen crew', 'More importantly, you’ll collaborate to do the right things in the right way to achieve the right outcomes', 'Proven track record learning new technologies and applying that learning quickly']",False,[],,"['SQL', 'Python', 'Apache Airflow', 'dbt', 'DataHub', 'MLflow', 'Kafka', 'Apache Spark', 'Apache Flink', 'Data pipelines', 'Distributed data architecture', 'Data monitoring and alerting', 'CI/CD pipelines', 'Hypothesis-driven data analysis', 'AWS cloud infrastructure', 'Snowflake']","SQL: Used for querying and managing relational data within the data platform.; Python: Primary programming language for building data pipelines and automation in the data platform.; Apache Airflow: Tool for orchestrating and managing production-grade data pipelines.; dbt: Used for data transformation and modeling within the data platform.; DataHub: Platform for metadata management and data discovery to support data governance.; MLflow: Tool for managing machine learning lifecycle including experiment tracking and deployment.; Kafka: Distributed event streaming platform used for handling real-time data streams at scale.; Apache Spark: Distributed computing system used for large-scale data processing within the data platform.; Apache Flink: Stream processing framework used for real-time data processing in the data platform.; Data pipelines: Automated workflows designed and maintained to move and transform data for analytics and machine learning.; Distributed data architecture: Design and implementation of scalable data systems across multiple nodes to support high-volume data processing.; Data monitoring and alerting: Building observability into data products to ensure data quality and system reliability.; CI/CD pipelines: Continuous integration and deployment processes for automating data and machine learning product releases.; Hypothesis-driven data analysis: Approach to leverage data for informed decision-making and continuous improvement of the data platform.; AWS cloud infrastructure: Cloud services such as Kinesis, Lambda, Aurora RDS PostgreSQL used to support scalable data platform operations.; Snowflake: Cloud data warehouse technology used for scalable data storage and analytics."
X_SgGUG8WLfcAwggAAAAAA==,"Senior Data Scientist - Retail Analytics/IT (Preferred-Austin, MN)","Job Description

SENIOR DATA SCIENTIST -RETAIL - INFORMATION TECHNOLOGY SERVICES - FLEXIBLE LOCATION - (AUSTIN, MN; WILLMAR, MN; EDEN PRAIRIE, MN; OR CHICAGO, IL)

To save time applying, Hormel Foods does not offer sponsorship of job applicants for employment-based visas for this position at this time.

Hormel Foods Corporation

ABOUT HORMEL FOODS - Inspired People. Inspired Food.™

Hormel Foods Corporation, based in Austin, Minnesota, is a global branded food company with over $12 billion in annual revenue across more than 80 countries worldwide. Its brands include Planters®, Skippy®, SPAM®, Hormel® Natural Choice®, Applegate®, Justin's®, Wholly®, Hormel® Black Label®, Columbus®, Jennie-O® and more than 30 other beloved brands. The company is a member of the S&P 500 Index and the S&P 500 Dividend Aristocrats, was named one of the best companies to work for by U.S. News & World Report, one of America's most responsible companies by Newsweek, recognized on Fast Company's list of the 100 Best Workplaces for Innovators, received a perfect score of 100 on the 2023-24 Corporate Equality Index and has received numerous other awards and accolades for its corporate responsibility and community service efforts. The company lives by its purpose statement - Inspired People. Inspired Food.™ - to bring some of the world's most trusted and iconic brands to tables across the globe. For more information, visit hormelfoods.com.

What You Will Do

As a Senior Data Scientist supporting our Retail Business Unit, you'll lead the development of advanced analytics solutions that improve how we partner with retailers and deliver value to consumers. You'll work cross-functionally to solve complex challenges in areas like demand forecasting, promotion optimization, and retail execution.
• Design, develop, and scale predictive and prescriptive models that support retail strategy and execution.
• Collaborate with sales, marketing, supply chain, and IT to identify high-impact analytics opportunities.
• Translate complex data into actionable insights and compelling visual stories for business stakeholders.
• Mentor and lead junior data scientists and foster a culture of innovation and continuous learning.
• Work with tools like Python, Google BigQuery, Oracle, Tableau, and Power BI to build scalable, production-ready solutions.

What You Bring

Required:
• Bachelor's degree in Data Science, Mathematics, Computer Science, or a related field.
• 7+ years of experience in data science, including model development and deployment.
• Strong programming skills and experience with large-scale data environments.
• Proven ability to translate business needs into data-driven solutions, especially in a CPG or retail context.
• Excellent communication and storytelling skills.
• Must be a Citizen or National of the United States, a lawful, permanent resident, or have authorization to work in the United States.
• Applicants must not now, or any time in the future, require sponsorship for an employment visa.

Preferred:
• Master's degree in a quantitative field.
• Experience with Google Cloud Platform and Oracle databases.
• Familiarity with Python IDEs (e.g., PyCharm, Jupyter, Anaconda).
• Experience developing production-grade machine learning models.
• Proficiency in data visualization tools like Tableau or Power BI.
• Experience working with syndicated retail data (e.g., Nielsen, Circona) or POS data

BENEFITS: Hormel Foods offers an excellent benefits package. Competitive base salary plus target incentive, discretionary annual merit increase, annual performance review, medical, dental, vision, non-contributory pension, profit sharing, 401(k) immediate eligible, stock purchase plan, relocation assistance, paid personal time (PTO), FREE two-year community/technical college tuition for children of employees, and more.

Ready to Make a Difference?

Join a company where your work will directly impact how millions of people experience our trusted brands. Apply today and help us continue our journey of Inspired People. Inspired Food.™

At Hormel Foods, base pay is one part of our total compensation package and is determined within a range. The base hiring pay range for this role is between $117,000 - $164,000 per year, and your actual base pay within that range will depend upon a variety of factors including, but not limited to, job-related knowledge, skill set, level of experience, and geographic market location.

At Hormel we invite difference and diversity in all aspects. We offer a space of support, understanding, and community. We are committed to the journey! Learn more about our progress here: https://www.hormelfoods.com/about/diversity-and-inclusion/

Hormel Foods Corporation is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status.",,2025-07-25,"[""Bachelor's degree in Data Science, Mathematics, Computer Science, or a related field"", '7+ years of experience in data science, including model development and deployment', 'Strong programming skills and experience with large-scale data environments', 'Proven ability to translate business needs into data-driven solutions, especially in a CPG or retail context', 'Excellent communication and storytelling skills', 'Must be a Citizen or National of the United States, a lawful, permanent resident, or have authorization to work in the United States', 'Applicants must not now, or any time in the future, require sponsorship for an employment visa']","[""As a Senior Data Scientist supporting our Retail Business Unit, you'll lead the development of advanced analytics solutions that improve how we partner with retailers and deliver value to consumers"", ""You'll work cross-functionally to solve complex challenges in areas like demand forecasting, promotion optimization, and retail execution"", 'Design, develop, and scale predictive and prescriptive models that support retail strategy and execution', 'Collaborate with sales, marketing, supply chain, and IT to identify high-impact analytics opportunities', 'Translate complex data into actionable insights and compelling visual stories for business stakeholders', 'Mentor and lead junior data scientists and foster a culture of innovation and continuous learning', 'Work with tools like Python, Google BigQuery, Oracle, Tableau, and Power BI to build scalable, production-ready solutions']",True,[],,"['Predictive Modeling', 'Prescriptive Modeling', 'Demand Forecasting', 'Promotion Optimization', 'Retail Execution Analytics', 'Python', 'Google BigQuery', 'Oracle Databases', 'Tableau', 'Power BI', 'Machine Learning Model Development', 'Syndicated Retail Data', 'Point of Sale (POS) Data']","Predictive Modeling: Used to design and develop models that forecast retail demand and support strategy execution.; Prescriptive Modeling: Applied to optimize retail promotions and execution by recommending actionable strategies.; Demand Forecasting: A key challenge area where data science techniques are applied to predict future product demand.; Promotion Optimization: Analytics methods used to improve the effectiveness of retail promotions.; Retail Execution Analytics: Analyzing retail operations data to enhance business outcomes and consumer value.; Python: Primary programming language used for data analysis, model development, and building scalable solutions.; Google BigQuery: Cloud-based data warehouse used for handling large-scale retail data environments.; Oracle Databases: Database technology used to manage and query structured retail and business data.; Tableau: Data visualization tool employed to create compelling visual stories for business stakeholders.; Power BI: Business intelligence tool used to build dashboards and visualize retail analytics insights.; Machine Learning Model Development: Experience in creating and deploying production-grade models to support retail analytics.; Syndicated Retail Data: Utilization of external retail datasets like Nielsen and Circona for enhanced analytics.; Point of Sale (POS) Data: Analysis of sales transaction data to inform retail strategies and forecasting."
q-70EhlU6v2jLM4bAAAAAA==,Sr. Data Scientist (Operations Research),"EquipmentShare is Hiring a Data Scientist (Operations Research).

EquipmentShare is searching for a Sr Data Scientist specializing in Operations Research (OR) to join our team. This position is fully remote.
Primary Responsibilities

Despite having been fundamentally altered by earlier industrial revolutions, the construction industry has hardly budged with the computer revolution. In fact, since 1970, labor productivity in the US construction industry has actually declined, despite it more than doubling in the rest of the economy. This has contributed to housing shortages and the parlous state of infrastructure in some places, and is sanding the gears of carbon reduction efforts.

We think the industry is ripe for change, and we're pushing the leading edge of that change with our next generation T3 Platform, the OS for Construction. Through T3, we help contractors to coordinate humans and (increasingly smarter) machines to build more effectively.

As a Sr Data Scientist specialized in OR in our small and quickly growing team, you will play a major role in this effort. In particular, you will
• Create and enhance fleet management practices across the company through analytical
techniques
• Develop, from scratch, simulation experiments that lead to implemented optimization
algorithms to solve our complex supply chain problems
• Assist in identifying key KPIs and metrics to measure our company's supply chain
effectiveness
• Help to identify the highest value next opportunities for OR within a big greenfield space,
work cross-functionally to plan and build, and measure your significant business impact
via experimentation
Why We're a Better Place to Work
• Competitive compensation packages
• 401 (k) and company match
• Health insurance and medical coverage benefits
• Unlimited paid time off
• Generous paid parental leave
• Volunteering and local charity initiatives that help you nurture and grow the communities you call home
• Stocked breakroom and full kitchen (corporate HQ)
• State of the art onsite gym (corporate HQ)/Gym stipend for remote employees
• Opportunities for career and professional development with conferences, events, seminars, continued education
About You

Our mission to change an entire industry is not easily achieved, so we only hire people who are inspired by the goal and up for the challenge. In turn, our employees have every opportunity to grow with us, achieve personal and professional success and enjoy making a tangible difference in an industry that's long been resistant to change.
Skills & Qualifications

Minimum Qualifications:
• Graduate degree or equivalent practical experience in statistics, computer science,
applied math, operations research or related field
• 4+ years working on technology-powered products and projects within the OR, supply
chain optimization, or data science roles
• Demonstrated understanding of the techniques and methods of modern algorithm
development
• Strong cross-functional communication skills
• Must be qualified to work in the United States - we are not sponsoring any candidates at
this time

EquipmentShare is committed to a diverse and inclusive workplace. EquipmentShare is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status.

#LI-Remote",,2025-07-25,"['Help to identify the highest value next opportunities for OR within a big greenfield space,', 'Graduate degree or equivalent practical experience in statistics, computer science,', 'applied math, operations research or related field', '4+ years working on technology-powered products and projects within the OR, supply', 'chain optimization, or data science roles', 'Demonstrated understanding of the techniques and methods of modern algorithm', 'Strong cross-functional communication skills', 'Must be qualified to work in the United States - we are not sponsoring any candidates at']","['This position is fully remote', 'Create and enhance fleet management practices across the company through analytical', 'Develop, from scratch, simulation experiments that lead to implemented optimization', 'algorithms to solve our complex supply chain problems', ""Assist in identifying key KPIs and metrics to measure our company's supply chain"", 'work cross-functionally to plan and build, and measure your significant business impact']",True,[],,"['Operations Research', 'Supply Chain Optimization', 'Simulation Experiments', 'Optimization Algorithms', 'Key Performance Indicators (KPIs)', 'Statistical Methods', 'Algorithm Development']",Operations Research: Used to develop optimization algorithms and simulation experiments to solve complex supply chain and fleet management problems.; Supply Chain Optimization: Focuses on improving supply chain effectiveness through analytical techniques and key performance indicators.; Simulation Experiments: Developed from scratch to model and analyze supply chain scenarios for optimization.; Optimization Algorithms: Implemented to enhance fleet management and supply chain operations.; Key Performance Indicators (KPIs): Identified and used to measure the effectiveness of supply chain processes.; Statistical Methods: Applied as part of the data science and operations research techniques to analyze and improve business processes.; Algorithm Development: Modern algorithmic techniques are employed to create solutions for operational challenges.
36sWFGTvdmvx5R7lAAAAAA==,Senior Data Scientist/Applied Scientist/ AI Products,"At Attentive, we're revolutionizing the way businesses connect with their customers. Our AI-driven marketing platform infuses intelligence into every stage of the consumer journey, helping brands deliver hyper-personalized messages at scale. With a mobile-first approach, engaging two-way conversations, and enterprise-grade technology, we're driving billions in online revenue for leading brands worldwide, including CB2, Urban Outfitters, GUESS, Long John Silver’s, and Wyndham Resort. But we're not just about SMS and email—by expanding our AI capabilities to enhance multiple products and channels, our goal is to help make every interaction more meaningful. As a member of our team, you'll be at the forefront of this innovation, helping to shape the future of customer communication.

Attentive’s growth has been recognized by Deloitte’s Fast 500, Linkedin’s Top Startups and Forbes Cloud 100 all thanks to the hard work from our global employees!

Who we are

Have you ever received text message marketing from your favorite brand? Did you know that effective text message marketing is by far the highest ROI marketing channel? And, did you know that customers are increasingly preferring to interact with brands through text? Now you understand our impact at Attentive. We help the world’s largest brands send 100 to 500 million messages per day, approaching 100 billion per year.

Our Data Science team is a world-class data, applied science, and ML organization that leads data-driven decision-making and the conversational AI efforts for the entire company. Joining our team offers a hockey-stick career opportunity to work with some of the world’s top data scientists in a high-performance and high-impact culture.

As a Senior Data Scientist on our AI team, you will play a crucial role in transforming data into actionable insights and models for our AI product offerings. We are looking for an experienced scientist who relishes the opportunity to develop novel approaches and apply them at Attentive’s scale. Your contributions will directly influence the development of cutting-edge ML solutions, empowering our team to craft highly effective messaging strategies.

What You'll Do
• Lead the development of statistical, econometric, optimization, and machine learning models for a range of applications in our messaging and AI product offerings.
• Design and execute experiments, interpret results, and draw actionable conclusions.
• Use data to understand product performance, identify improvement opportunities, and define product/team roadmaps.
• Present findings to senior leadership to inform and influence business decisions.
• Collaborate with cross-functional teams across product, engineering, customer success, and sales to drive business value from ideation to production.
Basic Qualifications
• Ph.D., M.S. or Bachelors degree in Statistics, Economics, Machine Learning, Operations Research, or other quantitative fields.
• Knowledge of underlying mathematical foundations of statistics, machine learning, optimization, economics, and analytics.
• Knowledge of experimental design and analysis.
• Experience with exploratory data analysis, statistical analysis and testing, and model development.
• Ability to use Python to work efficiently at scale with large data sets.
• Advanced proficiency in SQL.
Preferred Qualifications
• 4+ years of industry experience as an Applied or Data Scientist or equivalent.
• Experience in customer lifetime value modeling.
• Experience in personalization systems and cross-sectional cohort modeling.
• Experience with ads delivery and optimization systems.
• Experience with implementing insights into customer success recommendations.
• Experience with productionizing algorithms for real-time systems.
• Well-honed communication and presentation skills.
• Experience presenting findings to senior management to inform business decisions.
• Strong product and customer-oriented intuition

You'll get competitive perks and benefits, from health & wellness to equity, to help you bring your best self to work.

For US based applicants:

- The US base salary range for this full-time position is $200,000 - $280,000 annually + equity + benefits

- Our salary ranges are determined by role, level and location

#LI-MDK1

Attentive Company Values

Default to Action - Move swiftly and with purpose

Be One Unstoppable Team - Rally as each other’s champions

Champion the Customer - Our success is defined by our customers' success

Act Like an Owner - Take responsibility for Attentive’s success

Learn more about AWAKE, Attentive’s collective of employee resource groups.

If you do not meet all the requirements listed here, we still encourage you to apply! No job description is perfect, and we may also have another opportunity that closely matches your skills and experience.

At Attentive, we know that our Company's strength lies in the diversity of our employees. Attentive is an Equal Opportunity Employer and we welcome applicants from all backgrounds. Our policy is to provide equal employment opportunities for all employees, applicants and covered individuals regardless of protected characteristics. We prioritize and maintain a fair, inclusive and equitable workplace free from discrimination, harassment, and retaliation. Attentive is also committed to providing reasonable accommodations for candidates with disabilities. If you need any assistance or reasonable accommodations, please let your recruiter know.

Original job Senior Data Scientist/Applied Scientist/ AI Products posted on GrabJobs ©. To flag any issues with this job please use the Report Job button on GrabJobs.",2025-07-14T00:00:00.000Z,2025-07-25,"['Ph.D., M.S. or Bachelors degree in Statistics, Economics, Machine Learning, Operations Research, or other quantitative fields', 'Knowledge of underlying mathematical foundations of statistics, machine learning, optimization, economics, and analytics', 'Knowledge of experimental design and analysis', 'Experience with exploratory data analysis, statistical analysis and testing, and model development', 'Ability to use Python to work efficiently at scale with large data sets', 'Advanced proficiency in SQL']","['Lead the development of statistical, econometric, optimization, and machine learning models for a range of applications in our messaging and AI product offerings', 'Design and execute experiments, interpret results, and draw actionable conclusions', 'Use data to understand product performance, identify improvement opportunities, and define product/team roadmaps', 'Present findings to senior leadership to inform and influence business decisions', 'Collaborate with cross-functional teams across product, engineering, customer success, and sales to drive business value from ideation to production', 'Default to Action - Move swiftly and with purpose', 'Be One Unstoppable Team - Rally as each other’s champions', 'Act Like an Owner - Take responsibility for Attentive’s success']",True,[],,"['Statistical Modeling', 'Econometric Modeling', 'Optimization Models', 'Machine Learning', 'Experimental Design and Analysis', 'Exploratory Data Analysis', 'Statistical Testing', 'Python', 'SQL', 'Customer Lifetime Value Modeling', 'Personalization Systems', 'Cross-Sectional Cohort Modeling', 'Ads Delivery and Optimization Systems', 'Productionizing Algorithms']","Statistical Modeling: Used to develop models that analyze and interpret data for messaging and AI product applications.; Econometric Modeling: Applied to quantify economic relationships and customer behavior within marketing and messaging systems.; Optimization Models: Employed to improve ads delivery, personalization, and messaging strategies for better business outcomes.; Machine Learning: Developed and applied to create predictive models and enhance AI product offerings at scale.; Experimental Design and Analysis: Used to design and interpret experiments that inform product improvements and business decisions.; Exploratory Data Analysis: Performed to understand data patterns and support model development and product insights.; Statistical Testing: Applied to validate hypotheses and ensure robustness of models and experiments.; Python: Utilized for scalable data processing, model development, and analysis of large datasets.; SQL: Used for advanced querying and manipulation of large-scale data to support analytics and modeling.; Customer Lifetime Value Modeling: Implemented to predict and optimize long-term customer value for marketing strategies.; Personalization Systems: Developed to tailor messaging and customer interactions based on data-driven insights.; Cross-Sectional Cohort Modeling: Used to analyze customer segments and behavior over time for targeted marketing.; Ads Delivery and Optimization Systems: Built and refined to maximize the effectiveness of marketing campaigns.; Productionizing Algorithms: Implemented to deploy real-time models and algorithms into operational systems."
iipKSv4Wf8c_UHL9AAAAAA==,Sr. Data Scientist,"Overview

One Trajector. One Mission.

Trajector is where purpose meets progress. We specialize in medical evidence services that become the compass our clients rely on while navigating the intricate terrain of disability benefits. Our calling is clear: to make a real difference, infuse passion, and enhance the quality of life for the disabled community. As part of our global community, you'll join a team of over 1,800 dedicated individuals, each contributing their unique talents to streamline the path to benefits. Urgency propels us, data empowers us, and every step is tailored to ensure those with disabilities access their rightful compensation. Join us in shaping stories of transformation, one life at a time.

Job Overview

The AI/ML team at Trajector builds and productionizes NLP solutions that extract and utilize relevant information from unstructured text and audio to build efficient business solutions. We are seeking a highly experienced Staff Data Scientist specializing in Natural Language Processing (NLP) to lead the development and optimization of state-of-the-art NLP systems for medical and legal documents processing, management and creation. The ideal candidate will have 8-10 years of relevant experience in data science, machine learning, and NLP, with a strong track record of delivering impactful solutions in complex, domain-specific contexts.

About Our Perks, Compensation, & Benefits
• Competitive compensation ranging from $160,000 - $175,000 per year with total compensation ranging from $180,000 - $197,000.
• Medical, dental, vision, 401k program, and more
• Paid time off, including seven (7) federal holidays plus two (2) flex holidays for DEI
• Joining a rapidly growing organization

Responsibilities
• Design, develop, and deploy scalable NLP systems to process, analyze, and extract information from medical and legal documents.
• Lead the exploration and application of cutting-edge NLP techniques, including transformers, large language models, information retrieval, recommendation, summarization, and personalization systems, to solve domain-specific challenges.
• Collaborate with cross-functional teams, including product managers, engineers, and domain experts, to define project goals, requirements, and deliverables.
• Drive end-to-end development of AI/ML solutions, including data preprocessing, model training, evaluation, deployment, and performance monitoring.
• Ensure solutions meet high standards of data security, privacy, and compliance
• Mentor junior data scientists, fostering technical growth and knowledge-sharing within the team.
• Stay abreast of emerging trends and technologies in NLP and machine learning and identify opportunities for their application in our systems.
• Contribute to the strategic direction of technology and product development within the organization
• Contribute to the long-term AI/ML technical vision and roadmap

Qualifications
• Master's or Ph.D. in Computer Science, Data Science, Statistics, Computational Linguistics, or a related field.
• 5-8 years of professional experience in data science, preferably with a focus on natural language processing.
• Proven track record of solving business problems by delivering data science solutions at scale
• Expert in building and deploying machine learning models, including deep learning techniques and model fine-tuning
• Expert in data processing, feature engineering, analytics and visualization for structured and unstructured data
• Proficiency in Python
• Proficiency in SQL
• Proficiency in using source control systems like Github
• Proficiency in AI/ML/NLP frameworks such as Hugging Face, spaCy, scikit-learn, among others
• Proficiency in developing prompts for generative AI including evaluation of output
• Proven skills in translating complex data insights into clear, actionable business strategies
• Background of mathematical fundamentals including statistics, probability, linear algebra and optimization methods
• Experience in demonstrating the impact of data products using appropriate quantitative metrics
• Experience with cloud platforms (e.g., AWS, Azure, Google Cloud) and ML model deployment in production.
• Proven ability in contributing to complex projects and deliver results in a fast-paced environment.

Desired Qualifications
• Experience working with medical or legal documents, including familiarity with domain-specific regulations (e.g., HIPAA, GDPR).
• Familiarity with OCR (Optical Character Recognition) technologies and integrating structured and unstructured data sources.
• Background in reinforcement learning, unsupervised learning, outlier detection, or graph-based NLP techniques.
• Familiarity with Python ML frameworks such as PyTorch or TensorFlow
• Background of linear algebra and neural network architecture
• Experience with MLOps tools and philosophies
• Publications or contributions to open-source NLP projects.

EEO Statement

Trajector is an EOE/Veterans/Disabled/LGBTQ employer.",2025-07-23T00:00:00.000Z,2025-07-25,"['The ideal candidate will have 8-10 years of relevant experience in data science, machine learning, and NLP, with a strong track record of delivering impactful solutions in complex, domain-specific contexts', ""Master's or Ph.D. in Computer Science, Data Science, Statistics, Computational Linguistics, or a related field"", '5-8 years of professional experience in data science, preferably with a focus on natural language processing', 'Proven track record of solving business problems by delivering data science solutions at scale', 'Expert in building and deploying machine learning models, including deep learning techniques and model fine-tuning', 'Expert in data processing, feature engineering, analytics and visualization for structured and unstructured data', 'Proficiency in Python', 'Proficiency in SQL', 'Proficiency in using source control systems like Github', 'Proficiency in AI/ML/NLP frameworks such as Hugging Face, spaCy, scikit-learn, among others', 'Proficiency in developing prompts for generative AI including evaluation of output', 'Proven skills in translating complex data insights into clear, actionable business strategies', 'Background of mathematical fundamentals including statistics, probability, linear algebra and optimization methods', 'Experience in demonstrating the impact of data products using appropriate quantitative metrics', 'Experience with cloud platforms (e.g., AWS, Azure, Google Cloud) and ML model deployment in production', 'Proven ability in contributing to complex projects and deliver results in a fast-paced environment']","['Design, develop, and deploy scalable NLP systems to process, analyze, and extract information from medical and legal documents', 'Lead the exploration and application of cutting-edge NLP techniques, including transformers, large language models, information retrieval, recommendation, summarization, and personalization systems, to solve domain-specific challenges', 'Collaborate with cross-functional teams, including product managers, engineers, and domain experts, to define project goals, requirements, and deliverables', 'Drive end-to-end development of AI/ML solutions, including data preprocessing, model training, evaluation, deployment, and performance monitoring', 'Ensure solutions meet high standards of data security, privacy, and compliance', 'Mentor junior data scientists, fostering technical growth and knowledge-sharing within the team', 'Stay abreast of emerging trends and technologies in NLP and machine learning and identify opportunities for their application in our systems', 'Contribute to the strategic direction of technology and product development within the organization', 'Contribute to the long-term AI/ML technical vision and roadmap']",True,"['Transformers', 'Large Language Models', 'Generative AI', 'Prompt Engineering']",Transformers: Used as a cutting-edge NLP technique for processing and understanding complex language data.; Large Language Models: Applied to build scalable NLP systems capable of handling domain-specific medical and legal texts.; Generative AI: Involved in developing prompts and evaluating outputs for AI-driven text generation.; Prompt Engineering: Used to design and optimize inputs for generative AI models to improve output quality.,"['Natural Language Processing', 'Machine Learning', 'Deep Learning', 'Feature Engineering', 'Data Preprocessing', 'SQL', 'Python', 'scikit-learn', 'spaCy', 'Hugging Face', 'Model Evaluation', 'Cloud Platforms', 'MLOps', 'Information Retrieval', 'Recommendation Systems', 'Summarization', 'Personalization Systems', 'OCR (Optical Character Recognition)', 'Reinforcement Learning', 'Unsupervised Learning', 'Graph-Based NLP Techniques', 'Python ML Frameworks', 'Statistics and Probability', 'Linear Algebra and Optimization']","Natural Language Processing: Used to process, analyze, and extract information from unstructured medical and legal documents.; Machine Learning: Applied to build and deploy predictive models and solutions for domain-specific challenges.; Deep Learning: Used for advanced model training and fine-tuning in NLP systems.; Feature Engineering: Performed to prepare structured and unstructured data for model training and analytics.; Data Preprocessing: Involved in cleaning and transforming data before model training and evaluation.; SQL: Used for querying and managing structured data relevant to the business problems.; Python: Primary programming language for data processing, model development, and analytics.; scikit-learn: Utilized as a machine learning framework for building and deploying models.; spaCy: Used as an NLP framework for processing and analyzing text data.; Hugging Face: Employed for implementing state-of-the-art NLP models and transformers.; Model Evaluation: Conducted to assess the performance and impact of data science solutions.; Cloud Platforms: Used for deploying machine learning models and managing production environments.; MLOps: Applied to manage the lifecycle of machine learning models in production.; Information Retrieval: Used to extract relevant information from large collections of unstructured documents.; Recommendation Systems: Developed to personalize and improve user interactions with the system.; Summarization: Implemented to generate concise summaries from lengthy medical and legal texts.; Personalization Systems: Built to tailor outputs and recommendations to specific user needs.; OCR (Optical Character Recognition): Used to convert scanned documents into machine-readable text for further processing.; Reinforcement Learning: Applied as an advanced machine learning technique for optimizing NLP models.; Unsupervised Learning: Used for discovering patterns and outlier detection in unstructured data.; Graph-Based NLP Techniques: Employed to analyze relationships and structures within text data.; Python ML Frameworks: Includes PyTorch and TensorFlow for developing machine learning and deep learning models.; Statistics and Probability: Fundamental mathematical concepts used for data analysis and model development.; Linear Algebra and Optimization: Mathematical foundations critical for understanding and building machine learning models."
_g6t-UajKOyaY_UJAAAAAA==,Senior Data Analyst,"Company description

Hi there! We’re Razorfish. We’ve been leading the marketing industry with our digital expertise since the start of the internet. But in 2020, we did a full reboot. What’s different? It all starts with people. Weird, wonderful, complex people - with diverse backgrounds in strategy, creative and technology. But no matter how different we are, we all have one thing in common. We believe our differences are our strength. So we push for inclusion, challenge convention and bring in new perspectives, to inspire new ideas. Because when we connect by understanding what makes people different, we can create unforgettable experiences that enrich lives. Join us at razorfish.com.

Overview

Razorfish is looking for a Senior Associate to join its Data and Analytics practice. This is an analytics, research, and consulting team that delivers data-driven insights to our clients. Each member of the team is aligned to one or more clients and works closely with other Data team members, our clients, and colleagues across other disciplines such as: Client Management, Strategy, Search, Social, Media, User Experience, and Technology.

In this role you will contribute to data-driven projects across one or more client accounts. You will have support from data leadership and fellow analysts.

Core areas of focus for this group include applications in measurement planning and strategy, customer segmentations, testing frameworks, measurement and optimization solutions, performance reporting and analyses, personalization, and forecasting.

Responsibilities
• Lead data analyst for internal and external client project work
• Subject matter expert (SME) in source tools, platforms, and data flow
• Understands Razorfish data capabilities and how data fits into a client's overall strategy
• Understands the breadth of data services and crafts
• Owns elements of the data process such as syntax and taxonomy management and QA
• Able to manage data team responsibilities within cross-capability projects
• Participates and presents within larger presentations to clients
• Translates data into visuals (charts and graphs) that demonstrate the findings

Data Strategy
• Identify / focus on key issues and objectives based on internal and client needs with oversight
• Effectively describes outputs and approach of analysis to internal audiences and clients

Communication Skills
• Active listener and thoughtful communicator within internal and client discussions
• Raises questions based on data trends and patterns, explores hypotheses on causation
• Has ownership of own materials and able to answer questions logically and appropriately
• Participates appropriately in meetings, developing confidence in offering ideas and suggestions
• Begins to play leadership role in team discussions and is more comfortable voicing alternatives appropriately (supported with facts)
• Independently create sections of client documents with guidance in addition to leveraging pre-existing templates
• Takes comprehensive meeting notes with clear next steps for individual owners
• Shows ability to transform data into visually appealing presentations and able to adapt new formats as necessary

Client Engagement
• Client Partnerships
• Contributes to meetings with internal and external clients
• * Prioritize work to meet internal and external client deliverables
• ​​​​​​​Relationship Management
• * ​​​​​​​Identify when a request should be completed by the data team
• Understands how to document client feedback and recognizes when to raise issues
• Questions and output reflect basic knowledge of client’s business – financials, industry economics, competitive dynamics, marketing channels and client strategic issues

Tools & Techniques
• Shows mastery of client-specific data tools and platforms for reporting purposes
• Has advanced Excel skills with experience in manipulating and organizing large data sets
• Has deeper knowledge of statistical concepts / coding languages for advanced analytics capabilities
• Assist in vendor assessments
• Proactively identifies own learning gaps and seeks to answer them through internal resources or asking experts
• Comfortable working within BI/Visualization tools
• QA and maintain data integrity at collection, extraction, and activation point

Analytics
• Planning and Implementation
• Own sections of learning agenda / measurement plan
• Seamlessly implement a measurement program with minimal guidance
• Start and end a reporting deliverable with minimal guidance
• ​​​​​​​Insight Generation
• Fluent in standard CRM key performance metrics and approaches to measurement such as, email click-through rate, offer redemption rate, incremental sales, incremental margin
• Understand the best path to extract, cleanse, manipulate, and analyze data
• Demonstrates ability to synthesize implications (""so whats?"") from analysis with minimal guidance
• Uses insights to provide hypotheses and useful recommendations to the team

Qualifications
• 3-5+ years of industry experience in data science and marketing field
• Experience in media performance analytics such as attribution modeling, incrementality testing, and advance measurement methodologies
• Proficiency in common data science coding languages such as in SQL, Python and/or R
• Practical experience with Google Cloud Platform and services such as BigQuery, Looker, and DataProc

Additional information

The Power of One starts with our people! To do powerful things, we offer powerful resources. Our best-in-class wellness and benefits offerings include:
• Paid Family Care for parents and caregivers for 12 weeks or more
• Monetary assistance and support for Adoption, Surrogacy and Fertility
• Monetary assistance and support for pet adoption
• Employee Assistance Programs and Health/Wellness/Comfort reimbursements to help you invest in your future and work/life balance
• Tuition Assistance
• Paid time off that includes Flexible Time off Vacation, Annual Sick Days, Volunteer Days, Holiday and Identity days, and more
• Matching Gifts programs
• Flexible working arrangements
• ‘Work Your World’ Program encouraging employees to work from anywhere Publicis Groupe has an office for up to 6 weeks a year (based upon eligibility)
• Business Resource Groups that support multiple affinities and alliances

The benefits offerings listed are available to eligible U.S. Based employees, are reviewed on an annual basis, and are governed by the terms of the applicable plan documents.

Razorfish is an Equal Opportunity Employer. Our employment decisions are made without regard to actual or perceived race, color, ethnicity, religion, creed, sex, sexual orientation, gender, gender identity, gender expression, pregnancy, childbirth and related medical conditions, national origin, ancestry, citizenship status, age, disability, medical condition as defined by applicable state law, genetic information, marital status, military service and veteran status, or any other characteristic protected by applicable federal, state or local laws and ordinances.

If you require accommodation or assistance with the application or onboarding process specifically, please contact USMSTACompliance@publicis.com.

All your information will be kept confidential according to EEO guidelines.

Compensation Range: $70,000 - 95,000. This is the pay range the Company believes it will pay for this position at the time of this posting. Consistent with applicable law, compensation will be determined based on the skills, qualifications, and experience of the applicant along with the requirements of the position, and the Company reserves the right to modify this pay range at any time. Temporary roles may be eligible to participate in our freelancer/temporary employee medical plan through a third-party benefits administration system once certain criteria have been met. Temporary roles may also qualify for participation in our 401(k) plan after eligibility criteria have been met. For regular roles, the Company will offer medical coverage, dental, vision, disability, 401k, and paid time off. The Company anticipates the application deadline for this job posting will be 8/29/25.

#DNI",,2025-07-25,"['Active listener and thoughtful communicator within internal and client discussions', 'Has ownership of own materials and able to answer questions logically and appropriately', 'Has advanced Excel skills with experience in manipulating and organizing large data sets', 'Has deeper knowledge of statistical concepts / coding languages for advanced analytics capabilities', '3-5+ years of industry experience in data science and marketing field', 'Experience in media performance analytics such as attribution modeling, incrementality testing, and advance measurement methodologies', 'Proficiency in common data science coding languages such as in SQL, Python and/or R', 'Practical experience with Google Cloud Platform and services such as BigQuery, Looker, and DataProc']","['This is an analytics, research, and consulting team that delivers data-driven insights to our clients', 'Each member of the team is aligned to one or more clients and works closely with other Data team members, our clients, and colleagues across other disciplines such as: Client Management, Strategy, Search, Social, Media, User Experience, and Technology', 'In this role you will contribute to data-driven projects across one or more client accounts', 'You will have support from data leadership and fellow analysts', 'Core areas of focus for this group include applications in measurement planning and strategy, customer segmentations, testing frameworks, measurement and optimization solutions, performance reporting and analyses, personalization, and forecasting', 'Lead data analyst for internal and external client project work', 'Subject matter expert (SME) in source tools, platforms, and data flow', ""Understands Razorfish data capabilities and how data fits into a client's overall strategy"", 'Understands the breadth of data services and crafts', 'Owns elements of the data process such as syntax and taxonomy management and QA', 'Able to manage data team responsibilities within cross-capability projects', 'Participates and presents within larger presentations to clients', 'Translates data into visuals (charts and graphs) that demonstrate the findings', 'Data Strategy', 'Identify / focus on key issues and objectives based on internal and client needs with oversight', 'Effectively describes outputs and approach of analysis to internal audiences and clients', 'Raises questions based on data trends and patterns, explores hypotheses on causation', 'Participates appropriately in meetings, developing confidence in offering ideas and suggestions', 'Begins to play leadership role in team discussions and is more comfortable voicing alternatives appropriately (supported with facts)', 'Independently create sections of client documents with guidance in addition to leveraging pre-existing templates', 'Takes comprehensive meeting notes with clear next steps for individual owners', 'Shows ability to transform data into visually appealing presentations and able to adapt new formats as necessary', 'Client Engagement', 'Client Partnerships', 'Contributes to meetings with internal and external clients', 'Prioritize work to meet internal and external client deliverables', '\u200b\u200b\u200b\u200b\u200b\u200b\u200bRelationship Management', '\u200b\u200b\u200b\u200b\u200b\u200b\u200bIdentify when a request should be completed by the data team', 'Understands how to document client feedback and recognizes when to raise issues', 'Questions and output reflect basic knowledge of client’s business – financials, industry economics, competitive dynamics, marketing channels and client strategic issues', 'Shows mastery of client-specific data tools and platforms for reporting purposes', 'Assist in vendor assessments', 'Proactively identifies own learning gaps and seeks to answer them through internal resources or asking experts', 'Comfortable working within BI/Visualization tools', 'QA and maintain data integrity at collection, extraction, and activation point', 'Analytics', 'Planning and Implementation', 'Own sections of learning agenda / measurement plan', 'Seamlessly implement a measurement program with minimal guidance', 'Start and end a reporting deliverable with minimal guidance', 'Fluent in standard CRM key performance metrics and approaches to measurement such as, email click-through rate, offer redemption rate, incremental sales, incremental margin', 'Understand the best path to extract, cleanse, manipulate, and analyze data', 'Demonstrates ability to synthesize implications (""so whats?"") from analysis with minimal guidance', 'Uses insights to provide hypotheses and useful recommendations to the team']",True,[],,"['Attribution Modeling', 'Incrementality Testing', 'Measurement Planning', 'Customer Segmentation', 'Testing Frameworks', 'Performance Reporting', 'Forecasting', 'Data Visualization', 'Data Quality Assurance', 'SQL', 'Python', 'R', 'Google BigQuery', 'Looker', 'Google DataProc', 'Excel', 'Statistical Concepts', 'CRM Key Performance Metrics']","Attribution Modeling: Used to analyze media performance and understand the contribution of different marketing channels to conversions.; Incrementality Testing: Applied to measure the incremental impact of marketing efforts on sales or other key metrics.; Measurement Planning: Involves designing and implementing strategies to measure marketing and business performance effectively.; Customer Segmentation: Used to categorize customers into groups for targeted marketing and personalized experiences.; Testing Frameworks: Applied to structure experiments and tests for marketing optimization and validation.; Performance Reporting: Creating reports that track and communicate key performance indicators to clients and stakeholders.; Forecasting: Used to predict future trends and outcomes based on historical data for strategic planning.; Data Visualization: Transforming data into charts and graphs to communicate insights clearly to clients and internal teams.; Data Quality Assurance: Ensuring data integrity at collection, extraction, and activation points to maintain accuracy.; SQL: Used for querying and managing large datasets within databases to support analysis.; Python: Utilized for advanced analytics, data manipulation, and statistical analysis.; R: Applied for statistical computing and advanced data analysis tasks.; Google BigQuery: A cloud-based data warehouse service used for large-scale data querying and analysis.; Looker: A BI and data visualization platform used to create dashboards and reports for clients.; Google DataProc: A managed Spark and Hadoop service used for processing large datasets in the cloud.; Excel: Used for manipulating, organizing, and analyzing large datasets with advanced spreadsheet functions.; Statistical Concepts: Applied to perform advanced analytics and derive insights from data.; CRM Key Performance Metrics: Metrics such as email click-through rate and offer redemption rate used to evaluate marketing effectiveness."
XJ5j5Ty72RZwbOp-AAAAAA==,"Senior Data Scientist - Python, Tableau and Machine Learning","Position: Senior Data Scientist - Python, Tableau and Machine Learning - 2289596

Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by inclusion, talented peers, comprehensive benefits and career development opportunities.

Come make an impact on the communities we serve as you help us advance health optimization on a global scale. Join us to start Caring. Connecting. Growing together.

Primary Responsibilities:
• Analytics professional in payment integrity - stats and modeling data analytics team. Person will be responsible for delivering various fraud analytics statistical projects based on US healthcare data and other consulting assignment. These projects may involve model development, validation, governance, implementation and end to end delivery
• Lead and work closely with junior/senior statisticians to deliver Fraud, Waste, Abuse (FWA) statistical projects. Team builds models through advanced statistical techniques.
• Provide support to management in business development, client proposals and in building solid relationships with global analytics teams.
• Collaborates across business units with stakeholders, providing thought leadership, and driving day-to-day implementation of our analytics strategy
• Demonstrable leadership ability, superior problem solving and people management skills
• Evaluate statistical methods used to obtain the data to ensure validity, applicability, efficiency and accuracy. Interpret end-user technical requirements by specifying economic decision models, determining appropriate data sources, and performing detailed statistical analysis
• Create, analyze and maintain explanatory/predictive models of clinical behaviours on healthcare claims data. Work includes all phases of the modelling process: research design, data extraction and cleaning, model building and validation
• Research on the new fraud & abuse patterns and ideate new assignments/projects basis the secondary/data driven research
• Lead the advanced statistics domain for the team & develop/refine/improve predictive models using advance SAS, R & machine learning techniques and mentors junior/senior analysts/statisticians to develop their modeling/statistical skills
• Maintains staff by recruiting, selecting, orienting, and training employees; maintaining a safe, secure, and legal work environment; developing personal growth opportunities and accomplishes staff results by communicating job expectations; planning, monitoring, and appraising job results; coaching, counseling, and disciplining employees; developing, coordinating, and enforcing systems, policies, procedures, and productivity standards
• Co-ordinate with clinical/Coding SMEs for seeking the inputs to explore data extraction approach and road map the analysis mile stones
• Develop and maintain working relationships with key customer stakeholders
• Comply with the terms and conditions of the employment contract, company policies and procedures, and any and all directives (such as, but not limited to, transfer and/or re-assignment to different work locations, change in teams and/or work shifts, policies in regards to flexibility of work benefits and/or work environment, alternative work arrangements, and other decisions that may arise due to the changing business environment).

The Company may adopt, vary or rescind these policies and directives in its absolute discretion and without any limitation (implied or otherwise) on its ability to do so

Required Qualifications:
• Masters degree in math or statistics from top universities (Tier I/II) with solid record of achievement and approximately 6+ years of relevant work experience
• 6+ years of work experience in the area(s) of statistical analysis, data modelling
• 6+ years of project management experience
• Experience comprising analytics service delivery, solution design and client management
• Experience in data analytics, predictive & statistical modeling, strategy, project management, team management and business development
• Expert in data analytics with significant amount of project delivery skills in one or more of the following areas:
• Model Building, Model Validation, Fraud detection Analytics, Risk Analytics, Multivariate Analysis
• Expert focused on helping team improve modeling predictability, analytics driven strategy development, operational efficiency
• Knowledge of statistical tools and techniques, especially those relating to data mining & analysis. Should have ability to handle/work on large data sets
• Displays solid communication, interpersonal, and leadership ability across all levels coupled with effective problem solving, conceptual thinking, quantitative and analytical skills
• Demonstrated leadership ability and willingness to take initiative
• Excellent knowledge of SAS, R, or any other statistical software to carry out analysis and drive conclusions
• Solid…",2025-07-15T00:00:00.000Z,2025-07-25,"['Demonstrable leadership ability, superior problem solving and people management skills', 'Masters degree in math or statistics from top universities (Tier I/II) with solid record of achievement and approximately 6+ years of relevant work experience', '6+ years of work experience in the area(s) of statistical analysis, data modelling', '6+ years of project management experience', 'Experience comprising analytics service delivery, solution design and client management', 'Experience in data analytics, predictive & statistical modeling, strategy, project management, team management and business development', 'Expert in data analytics with significant amount of project delivery skills in one or more of the following areas:', 'Model Building, Model Validation, Fraud detection Analytics, Risk Analytics, Multivariate Analysis', 'Expert focused on helping team improve modeling predictability, analytics driven strategy development, operational efficiency', 'Knowledge of statistical tools and techniques, especially those relating to data mining & analysis', 'Should have ability to handle/work on large data sets', 'Displays solid communication, interpersonal, and leadership ability across all levels coupled with effective problem solving, conceptual thinking, quantitative and analytical skills', 'Demonstrated leadership ability and willingness to take initiative', 'Excellent knowledge of SAS, R, or any other statistical software to carry out analysis and drive conclusions', 'Solid…']","['Analytics professional in payment integrity - stats and modeling data analytics team', 'Person will be responsible for delivering various fraud analytics statistical projects based on US healthcare data and other consulting assignment', 'These projects may involve model development, validation, governance, implementation and end to end delivery', 'Lead and work closely with junior/senior statisticians to deliver Fraud, Waste, Abuse (FWA) statistical projects', 'Team builds models through advanced statistical techniques', 'Provide support to management in business development, client proposals and in building solid relationships with global analytics teams', 'Collaborates across business units with stakeholders, providing thought leadership, and driving day-to-day implementation of our analytics strategy', 'Evaluate statistical methods used to obtain the data to ensure validity, applicability, efficiency and accuracy', 'Interpret end-user technical requirements by specifying economic decision models, determining appropriate data sources, and performing detailed statistical analysis', 'Create, analyze and maintain explanatory/predictive models of clinical behaviours on healthcare claims data', 'Work includes all phases of the modelling process: research design, data extraction and cleaning, model building and validation', 'Research on the new fraud & abuse patterns and ideate new assignments/projects basis the secondary/data driven research', 'Lead the advanced statistics domain for the team & develop/refine/improve predictive models using advance SAS, R & machine learning techniques and mentors junior/senior analysts/statisticians to develop their modeling/statistical skills', 'Maintains staff by recruiting, selecting, orienting, and training employees; maintaining a safe, secure, and legal work environment; developing personal growth opportunities and accomplishes staff results by communicating job expectations; planning, monitoring, and appraising job results; coaching, counseling, and disciplining employees; developing, coordinating, and enforcing systems, policies, procedures, and productivity standards', 'Co-ordinate with clinical/Coding SMEs for seeking the inputs to explore data extraction approach and road map the analysis mile stones', 'Develop and maintain working relationships with key customer stakeholders', 'Comply with the terms and conditions of the employment contract, company policies and procedures, and any and all directives (such as, but not limited to, transfer and/or re-assignment to different work locations, change in teams and/or work shifts, policies in regards to flexibility of work benefits and/or work environment, alternative work arrangements, and other decisions that may arise due to the changing business environment)']",True,[],,"['Fraud Detection Analytics', 'Predictive Modeling', 'Statistical Analysis', 'Model Validation', 'Multivariate Analysis', 'Data Extraction and Cleaning', 'SAS', 'R', 'Machine Learning', 'Data Mining', 'Project Management', 'Business Intelligence Tools (Tableau)']","Fraud Detection Analytics: Used to develop statistical models to identify fraudulent activities in healthcare payment data.; Predictive Modeling: Creating and maintaining models to predict clinical behaviors and fraud patterns based on healthcare claims data.; Statistical Analysis: Applying advanced statistical techniques to analyze healthcare data and validate models for fraud, waste, and abuse detection.; Model Validation: Ensuring the accuracy and reliability of predictive models through rigorous testing and evaluation.; Multivariate Analysis: Analyzing multiple variables simultaneously to improve fraud detection and risk analytics.; Data Extraction and Cleaning: Preparing healthcare claims data for analysis by extracting relevant information and ensuring data quality.; SAS: Statistical software used for advanced analytics, model building, and data manipulation in fraud detection projects.; R: Statistical programming language employed for data analysis, model development, and validation in healthcare analytics.; Machine Learning: Applying machine learning techniques to enhance predictive models for fraud detection and risk analytics.; Data Mining: Techniques used to discover patterns and insights from large healthcare datasets to support fraud analytics.; Project Management: Managing analytics projects end-to-end, including delivery, governance, and stakeholder collaboration.; Business Intelligence Tools (Tableau): Used to create dashboards and visualizations to communicate analytics insights and support decision-making."
boY52InL9yYDLpEOAAAAAA==,Senior Data Scientist - Damage Analytics,"Join Our Innovation Team! At Hertz, we are pushing the boundaries of what's possible in damage management technology within the transportation industry. We are looking for brilliant AI & ML minds to join our Damage Science Team and help us innovate in the following areas:
• Real-Time Damage Detection: Utilize advanced computer vision techniques to accurately identify and assess damage.
• Intelligent Repair Estimation: Implement sophisticated Large Language Models to optimize repair routing decisions for efficiency and cost-effectiveness.
• Repair Forecasting: Develop predictive models for future repair and maintenance needs based on historical data.
• Quality Assurance Automation: Create models to evaluate repair quality and ensure our high standards are met.

We anticipate a starting salary around $160K, commensurate with experience.

Your Role:
• Define strategic and tactical steps for the complete model development lifecycle (including problem statement definition, exploratory data analysis, feature engineering, model development/tuning, and implementation).
• Develop and maintain a range of predictive and prescriptive models to evaluate new product and service performance.
• Conduct cross-validation of production models to ensure optimal performance and generalizability.
• Generate accurate analytics, reports, visualizations, and dashboards, effectively communicating results to both technical and non-technical stakeholders.
• Collaborate cross-functionally to identify use cases that enhance operational efficiency and drive business value.
• Adopt an owner mentality to drive business impact, supporting analytics pipeline creation and decision-making processes.
• Provide insights into how advancements in AI and machine learning can impact our business opportunities.
• Mentor and provide technical leadership to junior Data Scientists.

Requirements:
• 5-8 years of hands-on experience in a data science role.
• 5+ years of proficiency in data querying languages (like SQL) and scripting languages (like Python).
• End-to-end experience in machine learning model development (from problem definition to deployment).
• Demonstrated ability to leverage machine learning for business impact.
• Strong background in statistical analysis and modeling techniques.
• Experience mentoring junior scientists.
• Prior experience in an ML or data scientist role at a technology company.
• Master's degree in a quantitative field (statistics, mathematics, data science, economics, or computer science). PhD is preferred.

Benefits:
• Up to 40% off standard Hertz rental.
• Generous Paid Time Off.
• Comprehensive medical, dental, and vision plan options.
• 401(k) retirement plans with employer matching.
• Paid parental leave and adoption assistance.
• Employee assistance program for you and your family.
• Educational reimbursement and discounts.
• Voluntary insurance programs (pet, legal, critical illness).
• Perks and discounts on theme park tickets, gym memberships, and more.

The Hertz Corporation operates multiple car rental brands, including Hertz, Dollar, and Thrifty, across approximately 9,700 locations worldwide. We are one of the largest airport vehicle rental companies globally, and the Hertz brand is one of the most recognized.

Our Commitment to Diversity: At Hertz, we celebrate diversity and inclusion. We promote equal employment opportunities for all individuals, regardless of their unique characteristics. We encourage diverse applicants to contribute to our success!",2025-07-08T00:00:00.000Z,2025-07-25,"['5-8 years of hands-on experience in a data science role', '5+ years of proficiency in data querying languages (like SQL) and scripting languages (like Python)', 'End-to-end experience in machine learning model development (from problem definition to deployment)', 'Demonstrated ability to leverage machine learning for business impact', 'Strong background in statistical analysis and modeling techniques', 'Experience mentoring junior scientists', 'Prior experience in an ML or data scientist role at a technology company', ""Master's degree in a quantitative field (statistics, mathematics, data science, economics, or computer science)""]","['Real-Time Damage Detection: Utilize advanced computer vision techniques to accurately identify and assess damage', 'Intelligent Repair Estimation: Implement sophisticated Large Language Models to optimize repair routing decisions for efficiency and cost-effectiveness', 'Repair Forecasting: Develop predictive models for future repair and maintenance needs based on historical data', 'Quality Assurance Automation: Create models to evaluate repair quality and ensure our high standards are met', 'Define strategic and tactical steps for the complete model development lifecycle (including problem statement definition, exploratory data analysis, feature engineering, model development/tuning, and implementation)', 'Develop and maintain a range of predictive and prescriptive models to evaluate new product and service performance', 'Conduct cross-validation of production models to ensure optimal performance and generalizability', 'Generate accurate analytics, reports, visualizations, and dashboards, effectively communicating results to both technical and non-technical stakeholders', 'Collaborate cross-functionally to identify use cases that enhance operational efficiency and drive business value', 'Adopt an owner mentality to drive business impact, supporting analytics pipeline creation and decision-making processes', 'Provide insights into how advancements in AI and machine learning can impact our business opportunities', 'Mentor and provide technical leadership to junior Data Scientists']",True,['Large Language Models'],Large Language Models: Implemented to optimize repair routing decisions by leveraging advanced AI for intelligent repair estimation.,"['Computer Vision', 'Predictive Modeling', 'Feature Engineering', 'Model Development and Tuning', 'Cross-Validation', 'Data Querying with SQL', 'Python Scripting', 'Statistical Analysis and Modeling', 'Analytics and Dashboarding', 'Prescriptive Modeling']","Computer Vision: Used for real-time damage detection by analyzing images to identify and assess vehicle damage.; Predictive Modeling: Developed to forecast future repair and maintenance needs based on historical data.; Feature Engineering: Applied during the model development lifecycle to create relevant input variables for predictive and prescriptive models.; Model Development and Tuning: Involved in building and optimizing machine learning models for damage analytics and repair estimation.; Cross-Validation: Used to ensure the generalizability and optimal performance of production models.; Data Querying with SQL: Utilized for extracting and managing data necessary for analysis and model building.; Python Scripting: Used for data manipulation, model development, and automation within the analytics pipeline.; Statistical Analysis and Modeling: Applied to analyze data patterns and support the development of robust predictive models.; Analytics and Dashboarding: Generating reports and visualizations to communicate insights to stakeholders effectively.; Prescriptive Modeling: Developed to evaluate new product and service performance and optimize repair routing decisions."
81jBdaow2sVgD3jwAAAAAA==,Data Science Director,"Our ideal candidate will possess strong business acumen, coupled with the ability to communicate findings to both business and IT leaders in a way that can influence how our organization approaches a business challenge. The Data Science Director will not just address business problems; instead will be responsible for selecting the right problems that have the most value to the organization.

Responsibilities
• Lead a team of data scientists who undertake multiple client engagements
• In collaboration with the product management and engineering teams, identify opportunities to leverage data science techniques in order to create new or improve existing products
• Advocate the use and potential of data science within the organization and in particular the executive, product management and engineering teams

Qualifications
• 10+ years of experience with applied machine learning
• Strong statistical background and experience with R or other statistical packages
• Strong foundation in coding skills relevant for data science, e.g., Pig, Hive, SQL, Python, etc.
• Strong expertise in building and applying statistical/mathematical methods, machine learning / predictive modelling in real-world use cases
• Track record of successfully managing a diverse team of highly skilled individuals.
• Strong ability to build collaborative partnerships with a wide variety of internal and external stakeholders.
• PhD in a quantitative field (e.g., computer science, physics, engineering, mathematics, etc.)
• Must be inquisitive and can stare data and spot trends",,2025-07-25,"['10+ years of experience with applied machine learning', 'Strong statistical background and experience with R or other statistical packages', 'Strong foundation in coding skills relevant for data science, e.g., Pig, Hive, SQL, Python, etc', 'Strong expertise in building and applying statistical/mathematical methods, machine learning / predictive modelling in real-world use cases', 'Track record of successfully managing a diverse team of highly skilled individuals', 'Strong ability to build collaborative partnerships with a wide variety of internal and external stakeholders', 'PhD in a quantitative field (e.g., computer science, physics, engineering, mathematics, etc.)', 'Must be inquisitive and can stare data and spot trends']","['The Data Science Director will not just address business problems; instead will be responsible for selecting the right problems that have the most value to the organization', 'Lead a team of data scientists who undertake multiple client engagements', 'In collaboration with the product management and engineering teams, identify opportunities to leverage data science techniques in order to create new or improve existing products', 'Advocate the use and potential of data science within the organization and in particular the executive, product management and engineering teams']",True,[],,"['Applied Machine Learning', 'Statistical Analysis', 'SQL', 'Python', 'Pig', 'Hive', 'Predictive Modeling', 'Statistical/Mathematical Methods']",Applied Machine Learning: Experience in applying machine learning techniques to solve real-world business problems and improve products.; Statistical Analysis: Strong statistical background and use of statistical packages like R to analyze data and derive insights.; SQL: Use of SQL for querying and managing data within data science workflows.; Python: Coding skills in Python to develop data science models and perform data manipulation.; Pig: Use of Pig for processing and analyzing large datasets in a Hadoop environment.; Hive: Use of Hive for querying and managing large datasets stored in Hadoop.; Predictive Modeling: Building and applying predictive models to forecast outcomes and support decision-making.; Statistical/Mathematical Methods: Expertise in developing and applying statistical and mathematical techniques to analyze data.
dNME9zPUDS8QGAp3AAAAAA==,Senior Data Scientist – Pricing,"Siamo alla ricerca di un* Senior Data Scientist da inserire nel team di Pricing & Underwriting a Milano.
Se hai una solida esperienza nel settore assicurativo o finanziario, passione per i dati e voglia di contribuire all'evoluzione del nostro motore tecnico, potresti essere la persona giusta
Principali Attività
Valorizzerà il patrimonio dati aziendale, identificando opportunità strategiche e misurandone l'impatto.
Lavorerà allo sviluppo",2025-07-19T00:00:00.000Z,2025-07-25,,,True,[],,['Data Analysis'],"Data Analysis: The role involves leveraging company data assets to identify strategic opportunities and measure their impact, indicating a focus on data analysis."
Vi8rKqszbChnjSNrAAAAAA==,"Senior Data Analyst, External Games","Data Science and Engineering (‘DSE’) at Netflix is aimed at using data, analytics, and sciences to improve various aspects of our business. We are looking for a Senior Analytics Engineer to join our Games DSE team, leading end-to-end analytics & data needs for the Games space. This role will be partnering closely with our Game stakeholders to define key metrics, build and maintain key dashboards and analytic tools and scale data access across our stakeholder set. As an early member of the team, you will also help shape our overall Games Data Strategy at Netflix.

What You Will Do:
• Partner directly with our Game stakeholders (e.g., Netflix Games Studio, Games Product, Game Strategy, Planning & Analysis team) on data, metrics & analytics initiatives
• Lead end-to-end development of reports/dashboards/tools used by your direct stakeholders and a diverse set of teams across the company
• Proactively perform data exploration and analytical deep dives to discover insights or future testing opportunities
• Be a bridge between the business and tech, scaling access to insights that can empower better decision-making
• Maintain and rethink existing data solutions to service a wider variety of use cases
• Balance handling ad hoc requests while also driving larger projects forward

Who You Are:
• 6+ years of experience in data analytics function in gaming industry
• Extensive experience in driving Live Service performance insights
• You are an engineering-minded analyst with a strong bias towards action, delivering results quickly with iteration instead of waiting for perfection
• You are comfortable taking vague requirements and crystallizing them into valuable tools, metrics, or analysis.
• You have strong technical skills in manipulating large data sets with complex SQL and Python (or similar languages), big data technologies (e.g., Hadoop, Spark) and visualization tools (e.g., Tableau)
• You are a self-starter that can work effectively in a fast-paced, ambiguous environment with changing priorities and minimally defined processes.
• You are experienced in managing stakeholder asks, expectations, and relationships across a variety of stakeholders

Our compensation structure consists solely of an annual salary; we do not have bonuses. You choose each year how much of your compensation you want in salary versus stock options. To determine your personal top of market compensation, we rely on market indicators and consider your specific job family, background, skills, and experience to determine your compensation in the market range. The range for this role is $170,000 - $720,000.

Netflix provides comprehensive benefits including Health Plans, Mental Health support, a 401(k) Retirement Plan with employer match, Stock Option Program, Disability Programs, Health Savings and Flexible Spending Accounts, Family-forming benefits, and Life and Serious Injury Benefits. We also offer paid leave of absence programs. Full-time hourly employees accrue 35 days annually for paid time off to be used for vacation, holidays, and sick paid time off. Full-time salaried employees are immediately entitled to flexible time off. See more detail about our Benefits here.",,2025-07-25,"['6+ years of experience in data analytics function in gaming industry', 'Extensive experience in driving Live Service performance insights', 'You are an engineering-minded analyst with a strong bias towards action, delivering results quickly with iteration instead of waiting for perfection', 'You are comfortable taking vague requirements and crystallizing them into valuable tools, metrics, or analysis', 'You have strong technical skills in manipulating large data sets with complex SQL and Python (or similar languages), big data technologies (e.g., Hadoop, Spark) and visualization tools (e.g., Tableau)', 'You are a self-starter that can work effectively in a fast-paced, ambiguous environment with changing priorities and minimally defined processes', 'You are experienced in managing stakeholder asks, expectations, and relationships across a variety of stakeholders']","['This role will be partnering closely with our Game stakeholders to define key metrics, build and maintain key dashboards and analytic tools and scale data access across our stakeholder set', 'Partner directly with our Game stakeholders (e.g., Netflix Games Studio, Games Product, Game Strategy, Planning & Analysis team) on data, metrics & analytics initiatives', 'Lead end-to-end development of reports/dashboards/tools used by your direct stakeholders and a diverse set of teams across the company', 'Proactively perform data exploration and analytical deep dives to discover insights or future testing opportunities', 'Be a bridge between the business and tech, scaling access to insights that can empower better decision-making', 'Maintain and rethink existing data solutions to service a wider variety of use cases', 'Balance handling ad hoc requests while also driving larger projects forward']",True,[],,"['SQL', 'Python', 'Hadoop', 'Spark', 'Tableau', 'Data Exploration', 'Dashboard Development', 'Metrics Definition']",SQL: Used for manipulating and querying large datasets to support analytics and reporting for game stakeholders.; Python: Applied for data manipulation and analysis to build analytic tools and perform data exploration.; Hadoop: Utilized as a big data technology to handle large-scale data processing in the gaming analytics context.; Spark: Employed for distributed data processing to efficiently analyze large datasets relevant to game performance insights.; Tableau: Used to create and maintain dashboards and visualizations that communicate key metrics to stakeholders.; Data Exploration: Performed to discover insights and identify opportunities for testing and optimization in game analytics.; Dashboard Development: Led the end-to-end creation of reports and dashboards to provide actionable insights to diverse teams.; Metrics Definition: Collaborated with game stakeholders to define key performance indicators critical for business decisions.
nlyQipkD4AMrHSOaAAAAAA==,"Senior, Data Scientist - GenAI Platform - Military veterans preferred","Position Summary...

What you'll do...

Walmart employees more than 2.3 million employees worldwide, with 1.6 million associates in the U.S. Walmart hires 500,000 applicants a year to fill thousands of job profiles from engineers, designers, marketers to pilots and buyers and promotes more than 300,000 people to jobs of greater responsibility. The My Assistant platform team is responsible for developing and deploying Generative AI platform and solutions supporting associates globally.

In this role, you will be building an LLM-powered intelligent experience, inside chatbot or business application, to improve employee experience and productivity. You'll be responsible for designing and building an intelligent conversational interface that enhances communication, automates tasks, accesses data and insights, and provides personalized Q&A support to employees, ultimately creating a more efficient and engaging work environment.

What you'll do
• Work in a highly collaborative environment with a multidisciplinary team.
• Work with lead data scientists to design, architect, and build AI/ML model and model systems.
• Work with machine learning engineers to deploy, operate, and optimize scalable solutions
• Work with product managers to design user journeys, feedback loop and analyze user telemetry.
• Create opportunities to develop yourself with an end-to-end AI/ML product experience.
• Work with a set of robust work standards to ensure we build trustworthy AI/ML solutions

What you'll bring
• Ability to execute our trustworthy AI/ML practice in collaboration with stakeholders across the enterprise.
• Ability to effectively coach junior data scientists to work through technical issues and business understandings.
• Ability to communicate internally and externally through publication, presentations, and other mediums on research progress, major breakthroughs, and product innovation.
• Experience with statistical analysis and programming languages e.g. Python and mainstream machine learning frameworks, e.g. TensorFlow or PyTorch.
• Experience in building machine learning applications

About Walmart Global Tech
Imagine working in an environment where one line of code can make life easier for hundreds of millions of people. That’s what we do at Walmart Global Tech. We’re a team of software engineers, data scientists, cybersecurity expert's and service professionals within the world’s leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.

Walmart’s culture is a competitive advantage, and it’s fostered by being together. Working together in person allows us to collaborate, align quickly and innovate with greater speed. We use our campuses to create purposeful connection rooted in deepening understanding and investing in the development of our associates.
Our hubs: Walmart is a global company with offices across the United States and around the world. Our global headquarters is in Bentonville, Arkansas, with primary hubs in the San Francisco Bay area and New York/New Jersey.

Benefits
Benefits: Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.

Equal Opportunity Employer
Walmart, Inc. is an Equal Opportunity Employer – By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing diversity- unique styles, experiences, identities, ideas and opinions – while being inclusive of all people.

The above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

?

?

?
You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.

?

For information about PTO, see .

?

?
Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

?
Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

?

For information about benefits and eligibility, see .

?
The annual salary range for this position is $90,000.00-$180,000.00

?
Additional compensation includes annual or quarterly performance bonuses.

?
Additional compensation for certain positions may also include:

?

?
- Stock

?

?

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1- Bachelor’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years' experience in an analytics related field. Option 2- Master’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years' experience in an analytics related field. Option 3 - 5 years' experience in an analytics or related field.

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data science, machine learning, optimization models, Master’s degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.

Primary Location...

508 Sw 8Th St, Bentonville, AR 72712, United States of America",2025-07-05T00:00:00.000Z,2025-07-25,"['Ability to effectively coach junior data scientists to work through technical issues and business understandings', 'Ability to communicate internally and externally through publication, presentations, and other mediums on research progress, major breakthroughs, and product innovation', 'Experience with statistical analysis and programming languages e.g. Python and mainstream machine learning frameworks, e.g', 'TensorFlow or PyTorch', 'Experience in building machine learning applications', ""Option 1- Bachelor’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years' experience in an analytics related field"", ""Option 2- Master’s degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years' experience in an analytics related field"", ""Option 3 - 5 years' experience in an analytics or related field"", 'Data science, machine learning, optimization models, Master’s degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly', 'The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture']","['In this role, you will be building an LLM-powered intelligent experience, inside chatbot or business application, to improve employee experience and productivity', ""You'll be responsible for designing and building an intelligent conversational interface that enhances communication, automates tasks, accesses data and insights, and provides personalized Q&A support to employees, ultimately creating a more efficient and engaging work environment"", 'Work in a highly collaborative environment with a multidisciplinary team', 'Work with lead data scientists to design, architect, and build AI/ML model and model systems', 'Work with machine learning engineers to deploy, operate, and optimize scalable solutions', 'Work with product managers to design user journeys, feedback loop and analyze user telemetry', 'Create opportunities to develop yourself with an end-to-end AI/ML product experience', 'Work with a set of robust work standards to ensure we build trustworthy AI/ML solutions', 'Ability to execute our trustworthy AI/ML practice in collaboration with stakeholders across the enterprise']",True,"['Large Language Models', 'Generative AI', 'Conversational AI', 'Trustworthy AI']","Large Language Models: Used to build intelligent conversational interfaces and chatbots to improve employee experience.; Generative AI: Applied to develop AI-powered platforms and solutions that automate tasks and provide personalized support.; Conversational AI: Technology for designing intelligent chatbots and interfaces that enhance communication and automate workflows.; Trustworthy AI: Practices ensuring AI/ML solutions are reliable, ethical, and aligned with enterprise standards.","['Statistical Analysis', 'Python', 'Machine Learning', 'TensorFlow', 'PyTorch', 'Scikit-learn', 'Spark', 'Scala', 'R', 'Optimization Models', 'Data Science']","Statistical Analysis: Used for analyzing data patterns and supporting data-driven decision making in the role.; Python: Programming language used for data analysis, statistical modeling, and building machine learning applications.; Machine Learning: Applied to build predictive models and optimize solutions as part of AI/ML product development.; TensorFlow: Mainstream machine learning framework used for developing and deploying machine learning models.; PyTorch: Machine learning framework used for building and training models, especially neural networks.; Scikit-learn: Open source machine learning library used for building traditional ML models and data processing.; Spark: Big data processing framework used for handling large-scale data analytics and machine learning tasks.; Scala: Programming language often used with Spark for big data processing and analytics.; R: Statistical programming language used for data analysis and modeling.; Optimization Models: Mathematical models used to improve decision-making and operational efficiency.; Data Science: Core discipline involving data analysis, modeling, and interpretation to support business goals."
4M_WMfOdeE3FBSQaAAAAAA==,"Senior Data Scientist, Specialist Senior - SFL Scientific - Full-time","Senior Data Scientist, Specialist Senior - SFL Scientific

Our Deloitte Strategy & Transactions team helps guide clients through their most critical moments and transformational initiatives. From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability. Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journey-before, during, and after any major transformational projects or transactions.

SFL Scientific, a Deloitte Business, is a U.S. based, data science consulting firm specializing in building industry-specific, artificial intelligence (AI) technologies.

We are hiring a Senior Data Scientist to collaborate directly with clients to design and develop novel projects and solutions. Join a rapidly growing team of professionals working to build a world-class data science practice focused on solving complex and R&D problems.

Recruiting for this role ends on 7/31/2025.

Work You'll Do

As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services. You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions.

Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation. Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills.

+ Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production

+ Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives

+ Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization

+ Validate AI models and algorithm via code reviews, unit, and integration tests

+ Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives

+ Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives

The Team

Our Strategy offering architects bold strategies to achieve business and mission goals, enabling growth, competitive advantage, technology modernization, and continuous digital and AI transformation.

SFL Scientific, a Deloitte Business, is a data science professional services practice focused on strategy, technology, and solving business challenges with Artificial Intelligence (AI). The team has a proven track record serving large, market-leading organizations in the private and public sectors, successfully delivering high-quality, novel and complex projects, and offering deep domain and scientific capabilities. Made up of experienced AI strategists, data scientists, and AI engineers, they serve as trusted advisors to executives, helping them understand and evaluate new and essential areas for AI investment and identify unique opportunities to transform their businesses.

Qualifications:

+ Master's or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)

+ 3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)

+ 3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments

+ 3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow

+ 3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads

+ Live within commuting distance to one of Deloitte's consulting offices

+ Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve

+ Limited immigration sponsorship may be available

Preferred:

+ 2+ years of experience working in a client-facing, consulting environment

+ 2+ years of experience leading project/client engagement teams in the execution of complex AI data science solutions

+ 1+ year of experience with LLM/GenAI use cases and developing RAG solutions, tools, and services (i.e., LangChain, LangGraph, MCP, etc.)

+ 1+ year of experience with AWS Sagemaker or AWS ML Studio

Information for applicants with a need for accommodation: https://www2.deloitte.com/us/en/pages/careers/articles/join-deloitte-assistance-for-disabled-applicants.html

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $107,600 to $198,400.

You may also be eligible to participate in a discretionary annual incentive program, subject to the rules governing the program, whereby an award, if any, depends on various factors, including, without limitation, individual and organizational performance.

#MonitorDeloitte

#DeloitteJobs

#StrategyConsulting

#DeloitteStrategy

#Strategy26

#SFL26

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.

Senior Data Scientist, Specialist Senior - SFL Scientific

Our Deloitte Strategy & Transactions team helps guide clients through their most critical moments and transformational initiatives. From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability. Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journey-before, during, and after any major transformational projects or transactions.

SFL Scientific, a Deloitte Business, is a U.S. based, data science consulting firm specializing in building industry-specific, artificial intelligence (AI) technologies.

We are hiring a Senior Data Scientist to collaborate directly with clients to design and develop novel projects and solutions. Join a rapidly growing team of professionals working to build a world-class data science practice focused on solving complex and R&D problems.

Recruiting for this role ends on 7/31/2025.

Work You'll Do

As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services. You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions.

Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation. Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills.

+ Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production

+ Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives

+ Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization

+ Validate AI models and algorithm via code reviews, unit, and integration tests

+ Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives

+ Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives

The Team

Our Strategy offering architects bold strategies to achieve business and mission goals, enabling growth, competitive advantage, technology modernization, and continuous digital and AI transformation.

SFL Scientific, a Deloitte Business, is a data science professional services practice focused on strategy, technology, and solving business challenges with Artificial Intelligence (AI). The team has a proven track record serving large, market-leading organizations in the private and public sectors, successfully delivering high-quality, novel and complex projects, and offering deep domain and scientific capabilities. Made up of experienced AI strategists, data scientists, and AI engineers, they serve as trusted advisors to executives, helping them understand and evaluate new and essential areas for AI investment and identify unique opportunities to transform their businesses.

Qualifications:

+ Master's or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)

+ 3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)

+ 3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments

+ 3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow

+ 3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads

+ Live within commuting distance to one of Deloitte's consulting offices

+ Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve

+ Limited immigration sponsorship may be available

Preferred:

+ 2+ years of experience working in a client-facing, consulting environment

+ 2+ years of experience leading project/client engagement teams in the execution of complex AI data science solutions

+ 1+ year of experience with LLM/GenAI use cases and developing RAG solutions, tools, and services (i.e., LangChain, LangGraph, MCP, etc.)

+ 1+ year of experience with AWS Sagemaker or AWS ML Studio

Information for applicants with a need for accommodation: https://www2.deloitte.com/us/en/pages/careers/articles/join-deloitte-assistance-for-disabled-applicants.html

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $107,600 to $198,400.

You may also be eligible to participate in a discretionary annual incentive program, subject to the rules governing the program, whereby an award, if any, depends on various factors, including, without limitation, individual and organizational performance.

#MonitorDeloitte

#DeloitteJobs

#StrategyConsulting

#DeloitteStrategy

#Strategy26

#SFL26

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.",2025-07-24T00:00:00.000Z,2025-07-25,"[""Master's or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)"", '3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)', '3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments', '3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow', '3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads', ""Live within commuting distance to one of Deloitte's consulting offices"", 'Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve', 'Limited immigration sponsorship may be available', ""Master's or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)"", '3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)', '3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments', '3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow', '3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads', ""Live within commuting distance to one of Deloitte's consulting offices"", 'Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve', 'Limited immigration sponsorship may be available']","['From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability', 'Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journey-before, during, and after any major transformational projects or transactions', 'As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services', 'You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions', 'Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation', 'Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills', 'Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production', 'Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives', 'Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization', 'Validate AI models and algorithm via code reviews, unit, and integration tests', 'Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives', 'Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives', 'From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability', 'Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journey-before, during, and after any major transformational projects or transactions', 'As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services', 'You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions', 'Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation', 'Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills', 'Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production', 'Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives', 'Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization', 'Validate AI models and algorithm via code reviews, unit, and integration tests', 'Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives', 'Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives']",True,"['PyTorch', 'Convolutional Neural Networks', 'Recurrent Neural Networks', 'Generative Adversarial Networks', 'Kubernetes', 'Docker', 'TensorRT', 'RAPIDs', 'Kubeflow', 'MLflow', 'Large Language Models', 'Retrieval-Augmented Generation', 'LangChain', 'LangGraph', 'MCP', 'AWS SageMaker', 'AWS ML Studio']","PyTorch: Framework used for developing deep learning models and AI/ML algorithm development.; Convolutional Neural Networks: Deep learning architecture applied in computer vision projects.; Recurrent Neural Networks: Deep learning architecture used for sequential data modeling such as time-series and NLP.; Generative Adversarial Networks: Deep learning technique used for generative modeling in AI projects.; Kubernetes: Container orchestration tool used to deploy and manage AI/ML models in production.; Docker: Containerization platform used for packaging and deploying AI/ML models.; TensorRT: Optimization tool for deploying deep learning models efficiently on hardware.; RAPIDs: GPU-accelerated libraries used to optimize AI/ML model performance.; Kubeflow: Platform for deploying, orchestrating, and managing machine learning workflows.; MLflow: Tool for managing the machine learning lifecycle including experimentation, reproducibility, and deployment.; Large Language Models: Experience with LLM/GenAI use cases, including developing Retrieval-Augmented Generation solutions.; Retrieval-Augmented Generation: Developing AI solutions that combine retrieval techniques with generative AI models for enhanced performance.; LangChain: Tool used to build applications with LLMs, supporting GenAI use cases.; LangGraph: Framework for managing and orchestrating LLM-based AI workflows.; MCP: AI platform or tool referenced for managing or deploying generative AI solutions.; AWS SageMaker: Cloud service used for building, training, and deploying machine learning and AI models.; AWS ML Studio: Cloud-based environment for developing and deploying AI/ML models.","['Exploratory Data Analysis', 'Machine Learning', 'Deep Learning', 'Natural Language Processing', 'Time-Series Analysis', 'Model Validation and Performance Tuning', 'Model Deployment and Optimization', 'Cloud Computing Platforms', 'Python Programming']","Exploratory Data Analysis: Used to understand client data sets and operational requirements to design long-term data science solutions.; Machine Learning: Applied to develop AI/ML solutions, including research and implementation of novel approaches and model tuning.; Deep Learning: Utilized in real-world projects involving CNNs, RNNs, and GANs for tasks such as computer vision and time-series analysis.; Natural Language Processing: Employed for data analysis tasks, including NLP techniques as part of AI/ML algorithm development.; Time-Series Analysis: Used for analyzing sequential data as part of AI/ML algorithm development and data analysis.; Model Validation and Performance Tuning: Involves validating AI models through code reviews, unit and integration tests, and tuning models for production environments.; Model Deployment and Optimization: Deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow.; Cloud Computing Platforms: Leveraging AWS, Azure, or GCP cloud environments to deploy AI/ML workloads.; Python Programming: Core language used for AI/ML algorithm development and data analysis."
URwTuFHHXHOExfnrAAAAAA==,Data Analyst - Senior,"About the position

The Senior Data Analyst at Cayuse Federal Services plays a crucial role in supporting IRS compliance activities by leveraging data obtained from IRS systems. This position focuses on identifying trends in payment collections and taxpayer behaviors, developing systemic solutions, and documenting analytical work for transfer to appropriate agency functions. The role requires strong analytical skills, effective communication, and the ability to work collaboratively with government clients and internal teams.

Responsibilities
• Meet with Government clients to understand their business needs, define research objectives, identify data sources, and develop analysis plans
,
• Apply critical thinking and creative problem-solving skills to proactively identify and develop solutions for clients' business problems
,
• Conduct exploratory data analysis using large-scale Government data sources and develop briefings and reports to communicate key findings
,
• Work with teams of data scientists to build pipelines for data engineering and machine learning
,
• Collaborate with software developers to build tools for data visualization and analysis
,
• Develop recommendations based on completed research and analysis and present these recommendations to government clients
,
• Demonstrate superior verbal and written communication skills, explaining complex analytical concepts to stakeholders
,
• Take ownership of tasks and develop high-quality work products with minimal supervision
,
• Perform other duties as assigned

Requirements
• Bachelor's in Economics, Statistics, Mathematics, Computer Science, or other quantitative field, or equivalent experience
,
• 5+ years of professional experience
,
• 5+ years of depth understanding of data constructs, basic statistical concepts, and analytical methods
,
• 5+ years of experience formulating data-driven recommendations
,
• Must be able to pass a background check and obtain a Federal Public Trust Clearance
,
• US Citizenship or Lawful Permanent Resident status required for clearance

Nice-to-haves
• Familiarity with statistical programming languages such as SAS, R, or Stata
,
• Experience with structured databases and query languages (e.g., PL/SQL, Postgres, MySQL)

Benefits
• Competitive salary range of USD $135,000.00 - USD $146,000.00 per year
,
• Remote work flexibility
,
• Professional development opportunities
,
• Diversity and equal opportunity workplace",,2025-07-25,"[""Bachelor's in Economics, Statistics, Mathematics, Computer Science, or other quantitative field, or equivalent experience"", '5+ years of professional experience', '5+ years of depth understanding of data constructs, basic statistical concepts, and analytical methods', '5+ years of experience formulating data-driven recommendations', 'Must be able to pass a background check and obtain a Federal Public Trust Clearance', 'US Citizenship or Lawful Permanent Resident status required for clearance', 'Familiarity with statistical programming languages such as SAS, R, or Stata', 'Experience with structured databases and query languages (e.g., PL/SQL, Postgres, MySQL)']","['The Senior Data Analyst at Cayuse Federal Services plays a crucial role in supporting IRS compliance activities by leveraging data obtained from IRS systems', 'This position focuses on identifying trends in payment collections and taxpayer behaviors, developing systemic solutions, and documenting analytical work for transfer to appropriate agency functions', 'The role requires strong analytical skills, effective communication, and the ability to work collaboratively with government clients and internal teams', 'Meet with Government clients to understand their business needs, define research objectives, identify data sources, and develop analysis plans', ""Apply critical thinking and creative problem-solving skills to proactively identify and develop solutions for clients' business problems"", 'Conduct exploratory data analysis using large-scale Government data sources and develop briefings and reports to communicate key findings', 'Work with teams of data scientists to build pipelines for data engineering and machine learning', 'Collaborate with software developers to build tools for data visualization and analysis', 'Develop recommendations based on completed research and analysis and present these recommendations to government clients', 'Demonstrate superior verbal and written communication skills, explaining complex analytical concepts to stakeholders', 'Take ownership of tasks and develop high-quality work products with minimal supervision', 'Perform other duties as assigned']",True,[],,"['Exploratory Data Analysis', 'Data Pipelines', 'Machine Learning', 'Data Visualization', 'Statistical Programming Languages', 'Structured Query Languages', 'Statistical Concepts and Analytical Methods']","Exploratory Data Analysis: Used to analyze large-scale government data sources to identify trends and key insights related to payment collections and taxpayer behaviors.; Data Pipelines: Collaborating with data scientists to build pipelines that support data engineering and machine learning workflows.; Machine Learning: Working with teams to integrate machine learning models as part of data-driven solutions for government clients.; Data Visualization: Partnering with software developers to create tools that visualize data and analytical results for stakeholders.; Statistical Programming Languages: Familiarity with SAS, R, or Stata to perform statistical analysis and support data-driven decision making.; Structured Query Languages: Experience with PL/SQL, Postgres, and MySQL to query and manage structured government databases.; Statistical Concepts and Analytical Methods: Applying foundational statistical knowledge and analytical techniques to formulate data-driven recommendations."
lOCgHizrc8Tp_KfIAAAAAA==,Senior Project Manager Data Analytics,"JOB DETAILS:

Title: IT Project Manager – Data Analytics

Location: Century City, CA (Remote / Hybrid role – 1-2 days onsite, 3-4 days remote work)

Type: 06 -12 plus months contract (possible extension)

Job Description:

As a Project Manager for the Applied Data & Insights team, will lead and orchestrate projects that seamlessly blend engineering, data analytics and data science from API endpoint to strategic Insight.

Focus on; Project management, Scrum practices, change management, user engagement, user training and the creation of technical documentation.
Involve collaborating with cross-functional teams, including engineers, data analysts, data scientists, and stakeholders to deliver innovative solutions that drive our company's success across the Sports and Entertainment business units.
Key Responsibilities:

Project Planning and Scoping:
• Define and document clear project objectives, scope, and deliverables, taking into account the principles of Scrum and Agile project management.
• Develop comprehensive project plans that incorporate well-defined timelines and resource allocation.
• Engage with cross-functional teams, ensuring that they are aligned with project objectives and adhere to project timelines.

Stakeholder Engagement:
• Act as the primary point of contact for project stakeholders, maintaining open and transparent communication.
• Funnel new intake requests to the appropriate channels
• Continuously update stakeholders and senior management on project status, progress, and changes in alignment.

Change Management:
• Work to create awareness and increase adoption of products and tools provided by the data team through stakeholder communications, training, and collecting feedback to bring back to the data teams.
• Implement effective change management strategies to implement new products, and manage changes in project scope, requirements, and stakeholder expectations.
• Ensure a smooth transition when implementing changes, addressing user concerns and promoting user adoption.

Documentation & Training:
• Create and maintain user and technical documentation to support project management, user engagement, and future maintenance.
• Lead and develop instructional training sessions for stakeholders that focus on newly released products.

Qualifications:
• Bachelor's degree in a relevant field or equivalent work experience (e.g., Project Management, Engineering, Computer Science, Data Analytics or Data Science).
• PMP, Scrum Master, or similar project management and Scrum certification is a plus.
• At least 5 years experience managing projects at the intersection of engineering and analytics, while applying Scrum principles.
• Deep Understanding of linear and digital platforms
• Prior major studio project management experience is a plus

Required Skill Sets:
• Excellent communication and presentation skills.
• Strong interpersonal skills with the ability to build stakeholder relationships
• Strong analytical and problem solving skills.
• Proficiency in analytics tools: Looker & Tableau
• Familiarity with: AWS, Redshift, S3 & Snowflake
• Knowledge of engineering principles and Scrum methodologies.
• Adaptability to changing priorities in a fast-paced environment.

Thank you for your time and consideration.

Thanks & Regards

Lokesh (Luke) | Talent Acquisition Specialist

Tel: | Email:

iSpace Inc | El Segundo, CA |",,2025-07-25,"[""Bachelor's degree in a relevant field or equivalent work experience (e.g., Project Management, Engineering, Computer Science, Data Analytics or Data Science)"", 'At least 5 years experience managing projects at the intersection of engineering and analytics, while applying Scrum principles', 'Deep Understanding of linear and digital platforms', 'Excellent communication and presentation skills', 'Strong interpersonal skills with the ability to build stakeholder relationships', 'Strong analytical and problem solving skills', 'Proficiency in analytics tools: Looker & Tableau', 'Familiarity with: AWS, Redshift, S3 & Snowflake', 'Knowledge of engineering principles and Scrum methodologies', 'Adaptability to changing priorities in a fast-paced environment']","['As a Project Manager for the Applied Data & Insights team, will lead and orchestrate projects that seamlessly blend engineering, data analytics and data science from API endpoint to strategic Insight', 'Focus on; Project management, Scrum practices, change management, user engagement, user training and the creation of technical documentation', ""Involve collaborating with cross-functional teams, including engineers, data analysts, data scientists, and stakeholders to deliver innovative solutions that drive our company's success across the Sports and Entertainment business units"", 'Define and document clear project objectives, scope, and deliverables, taking into account the principles of Scrum and Agile project management', 'Develop comprehensive project plans that incorporate well-defined timelines and resource allocation', 'Engage with cross-functional teams, ensuring that they are aligned with project objectives and adhere to project timelines', 'Act as the primary point of contact for project stakeholders, maintaining open and transparent communication', 'Funnel new intake requests to the appropriate channels', 'Continuously update stakeholders and senior management on project status, progress, and changes in alignment', 'Work to create awareness and increase adoption of products and tools provided by the data team through stakeholder communications, training, and collecting feedback to bring back to the data teams', 'Implement effective change management strategies to implement new products, and manage changes in project scope, requirements, and stakeholder expectations', 'Ensure a smooth transition when implementing changes, addressing user concerns and promoting user adoption', 'Create and maintain user and technical documentation to support project management, user engagement, and future maintenance', 'Lead and develop instructional training sessions for stakeholders that focus on newly released products']",False,[],,"['Scrum', 'Looker', 'Tableau', 'AWS', 'Redshift', 'S3', 'Snowflake', 'Data Analytics', 'Data Science']","Scrum: Used as the Agile project management framework to plan, execute, and manage data analytics and data science projects.; Looker: A BI tool used for creating analytics dashboards and reports to support data-driven decision making.; Tableau: A data visualization and BI platform employed to build interactive dashboards and insights for stakeholders.; AWS: Cloud platform providing infrastructure services supporting data storage and analytics workflows.; Redshift: A cloud-based data warehouse used for storing and querying large datasets to support analytics.; S3: AWS object storage service used for storing raw and processed data assets.; Snowflake: Cloud data platform used for scalable data warehousing and analytics.; Data Analytics: Core focus area involving analyzing data to generate insights that inform business decisions.; Data Science: Applied discipline involving statistical and computational methods to extract insights from data."
YgWt9pI83ZqHguR3AAAAAA==,"Senior Data Analyst, Marketing","EXL is hiring a Senior Data Analyst, Marketing with 5 - 10 years of experience. Based in United States - Minneapolis, MN and with In-office ways of working.

Job description and responsibilities:

Location: Minneapolis, MN or New York City, NY (preferred), Other locations include New Jersey, Pennsylvania, or Delaware

Overview: We are seeking a highly skilled Senior Data Analyst to join our team. In this role, you will collaborate with clients to understand data requirements, analyze large data sets, and deliver actionable insights that drive business decisions. Your deep expertise in marketing analytics will be critical in being successful in this role.

Key Responsibilities
• Partner with business leaders to define and understand data requirements, conduct research, and present analytical solutions.
• Manage and execute large-scale data analytics projects, integrating extensive data sets to provide actionable insights and recommendations.
• Design and implement marketing campaigns, including audience selection, campaign strategies, and performance measurement.
• Develop and execute various testing strategies, including A/B testing, multivariate testing, and holdout tests, to optimize marketing efforts.
• Ideate and implement changes to digital marketing materials based on data-driven insights and testing results.
• Monitor and evaluate the outcomes of testing efforts to refine and enhance marketing strategies.
• Develop and maintain technical documentation and client-facing materials to support data-driven decision-making.
• Apply advanced statistical techniques and tools to interpret data and deliver clear, concise data visualizations.
• Ensure compliance with company standards for data acquisition, sharing, and application of recommendations.

Requirements and qualifications:

Basic Qualifications
• Bachelor’s degree in a quantitative field such as Econometrics, Computer Science, Engineering, Applied Mathematics, or a related discipline, or equivalent work experience.
• Minimum of 5 years of experience in statistics or analytics.

Preferred Skills And Experience
• Extensive experience in marketing analytics, including designing and running marketing campaigns, executing A/B tests, and ideating testing strategies.
• Deep understanding of digital marketing materials and the ability to recommend and implement changes based on analytical insights.
• Proficiency with SAS, SQL, R, or Python for data analysis.
• Expertise in data visualization tools such as Tableau, Power BI, or similar.
• Strong analytical skills with experience in querying and interpreting complex data sets.
• Master’s degree in a relevant field is advantageous.
• Proven experience in designing practical experiments and measuring marketing campaign effectiveness.
• Skilled in analytic storytelling and presentation using PowerPoint or similar tools.
• Effective communication skills for direct interaction with business lines to understand needs and present findings.
• Experience in financial services with in-depth knowledge of financial products, customer interactions, and data systems.
• Demonstrated understanding of statistical analysis methodologies.
• Proven ability to drive analytics into actionable business outcomes.
• Strong project management and organizational skills.
• Ability to work both collaboratively and independently to achieve results.",,2025-07-25,"['Bachelor’s degree in a quantitative field such as Econometrics, Computer Science, Engineering, Applied Mathematics, or a related discipline, or equivalent work experience', 'Minimum of 5 years of experience in statistics or analytics']","['In this role, you will collaborate with clients to understand data requirements, analyze large data sets, and deliver actionable insights that drive business decisions', 'Your deep expertise in marketing analytics will be critical in being successful in this role', 'Partner with business leaders to define and understand data requirements, conduct research, and present analytical solutions', 'Manage and execute large-scale data analytics projects, integrating extensive data sets to provide actionable insights and recommendations', 'Design and implement marketing campaigns, including audience selection, campaign strategies, and performance measurement', 'Develop and execute various testing strategies, including A/B testing, multivariate testing, and holdout tests, to optimize marketing efforts', 'Ideate and implement changes to digital marketing materials based on data-driven insights and testing results', 'Monitor and evaluate the outcomes of testing efforts to refine and enhance marketing strategies', 'Develop and maintain technical documentation and client-facing materials to support data-driven decision-making', 'Apply advanced statistical techniques and tools to interpret data and deliver clear, concise data visualizations', 'Ensure compliance with company standards for data acquisition, sharing, and application of recommendations']",True,[],,"['Marketing Analytics', 'A/B Testing', 'Multivariate Testing', 'Holdout Testing', 'Statistical Analysis', 'Data Visualization', 'SQL', 'Python', 'R', 'SAS', 'Data Integration', 'Experiment Design', 'Analytic Storytelling']","Marketing Analytics: Used to analyze marketing campaign data and optimize strategies based on insights.; A/B Testing: Employed to compare different marketing approaches and determine the most effective one.; Multivariate Testing: Applied to test multiple variables simultaneously in marketing campaigns to optimize performance.; Holdout Testing: Used to evaluate marketing strategies by withholding a segment of the audience as a control group.; Statistical Analysis: Advanced statistical techniques are applied to interpret data and support decision-making.; Data Visualization: Tools like Tableau and Power BI are used to create visual representations of data for clearer insights.; SQL: Used for querying and managing large datasets to extract relevant marketing data.; Python: Utilized for data analysis and statistical modeling in marketing analytics.; R: Applied for statistical computing and advanced data analysis in marketing contexts.; SAS: Used for advanced analytics, statistical modeling, and data management in marketing projects.; Data Integration: Combining extensive data sets to provide comprehensive insights for marketing decisions.; Experiment Design: Designing practical experiments to measure the effectiveness of marketing campaigns.; Analytic Storytelling: Presenting data insights effectively to business stakeholders to drive actionable outcomes."
I0EBmZc4z5e7wiLPAAAAAA==,"Senior Research Data Scientist, YouTube Search (San Bruno)","Senior Research Data Scientist, YouTube Search

Join to apply for the Senior Research Data Scientist, YouTube Search role at Google
Senior Research Data Scientist, YouTube Search

Join to apply for the Senior Research Data Scientist, YouTube Search role at Google

Get AI-powered advice on this job and more exclusive features.

Note: By applying to this position you will have an opportunity to share your preferred working location from the following: Mountain View, CA, USA; San Bruno, CA, USA.Minimum qualifications:
• Master's degree in Statistics, Data Science, Mathematics, Physics, Economics, Operations Research, Engineering, or a related quantitative field or equivalent practical experience.
• 5 years of experience using analytics to solve product or business problems, coding (e.g., Python, R, SQL), querying databases or statistical analysis, or 3 years of work experience with a PhD degree.

Preferred qualifications:
• 8 years of work experience using analytics to solve product or business problems, coding (e.g., Python, R, SQL), querying databases or statistical analysis, or 6 years of work experience with a PhD degree.

About the jobIn this role, you will develop solutions to problems faced by YouTube (YT) Search. The role also involves participating in experiments to understand issues, and contributing to foundational improvements in data quality.The US base salary range for this full-time position is $166,000-$244,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.

Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google .

Responsibilities
• Collaborate with stakeholders in cross-projects and team settings to identify business or product questions to answer. Provide feedback to translate business questions into analysis, evaluation metrics, or mathematical models.
• Use custom data infrastructure or existing data models. Design and evaluate models to mathematically express and solve defined problems.
• Gather information, business goals, priorities, and organizational context around the questions to answer, as well as the existing and upcoming data infrastructure.
• Own the process of gathering, extracting, and compiling data across sources via tools (e.g., SQL, R, Python). Format, re-structure, or validate data to ensure quality, and review the dataset to ensure it is ready for analysis.

Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .Seniority level
• Seniority levelMid-Senior level
Employment type
• Employment typeFull-time
Job function
• Job functionInformation Technology and Engineering
• IndustriesInformation Services and Technology, Information and Internet

Referrals increase your chances of interviewing at Google by 2x

Get notified about new Senior Data Scientist jobs in San Bruno, CA.

San Francisco, CA $226,085.00-$283,250.00 1 day ago

San Francisco, CA $253,000.00-$314,000.00 6 days ago

Menlo Park, CA $206,000.00-$281,000.00 2 weeks ago

San Francisco, CA $206,000.00-$281,000.00 2 weeks ago

San Francisco, CA $182,000.00-$215,000.00 4 months ago
Clinical Data Scientist (Contract to Hire)Data Science Manager, Ads Horizontal Lead

Oakland, CA $193,000.00-$329,000.00 1 month ago

San Francisco County, CA $240,000.00-$275,000.00 1 month ago

Palo Alto, CA $154,000.00-$237,150.00 2 weeks ago
Geospatial Data Scientist (Research Fellow or Part-time Consultant)

San Francisco, CA $40.00-$80.00 1 month ago
Data Science Manager, Demand Planning and Forecasting

Burlingame, CA $206,000.00-$281,000.00 12 hours ago
Geospatial Data Scientist (Research Fellow or Part-time Consultant)Director, Scientific Content Engineering/Data Science, QDISenior Manager, Infrastructure Data ScienceDirector of Data Science - Recommendations and E-Commerce

San Francisco, CA $201,700.00-$267,300.00 1 month ago
Director, Data Science/AI Product Owner (Gen AI/ Agentic AI)Director, Data Science/AI Product Owner (Predictive AI/ Agentic AI)Senior Manager, Infrastructure Data ScienceDirector, Data Science / AI Product Owner (Analytical Workbench)Manager, Data Science & Analytics - Dasher EarningsSenior/Lead Data Analyst, Paid Media Marketing

San Francisco, CA $156,300.00-$218,900.00 2 weeks ago
Director of Finance and Administration, Biomedical Data Science

Stanford, CA $205,050.00-$283,688.00 1 week ago

Palo Alto, CA $128,000.00-$178,000.00 3 weeks ago

Were unlocking community knowledge in a new way. Experts add insights directly into each article, started with the help of AI.

#J-18808-Ljbffr",2025-07-17T00:00:00.000Z,2025-07-25,"[""Master's degree in Statistics, Data Science, Mathematics, Physics, Economics, Operations Research, Engineering, or a related quantitative field or equivalent practical experience"", '5 years of experience using analytics to solve product or business problems, coding (e.g., Python, R, SQL), querying databases or statistical analysis, or 3 years of work experience with a PhD degree', 'Seniority levelMid-Senior level', 'Geospatial Data Scientist (Research Fellow or Part-time Consultant)', 'San Francisco, CA $40.00-$80.00 1 month ago', 'Data Science Manager, Demand Planning and Forecasting', 'Geospatial Data Scientist (Research Fellow or Part-time Consultant)Director, Scientific Content Engineering/Data Science, QDISenior Manager, Infrastructure Data ScienceDirector of Data Science - Recommendations and E-Commerce', 'San Francisco, CA $201,700.00-$267,300.00 1 month ago', 'Director, Data Science/AI Product Owner (Gen AI/ Agentic AI)Director, Data Science/AI Product Owner (Predictive AI/ Agentic AI)Senior Manager, Infrastructure Data ScienceDirector, Data Science / AI Product Owner (Analytical Workbench)Manager, Data Science & Analytics - Dasher EarningsSenior/Lead Data Analyst, Paid Media Marketing', 'Director of Finance and Administration, Biomedical Data Science']","['In this role, you will develop solutions to problems faced by YouTube (YT) Search', 'The role also involves participating in experiments to understand issues, and contributing to foundational improvements in data quality', 'Collaborate with stakeholders in cross-projects and team settings to identify business or product questions to answer', 'Provide feedback to translate business questions into analysis, evaluation metrics, or mathematical models', 'Use custom data infrastructure or existing data models', 'Design and evaluate models to mathematically express and solve defined problems', 'Gather information, business goals, priorities, and organizational context around the questions to answer, as well as the existing and upcoming data infrastructure', 'Own the process of gathering, extracting, and compiling data across sources via tools (e.g., SQL, R, Python)', 'Format, re-structure, or validate data to ensure quality, and review the dataset to ensure it is ready for analysis', 'IndustriesInformation Services and Technology, Information and Internet']",True,[],,"['Python', 'R', 'SQL', 'Statistical Analysis', 'Data Quality Assurance', 'Mathematical Modeling', 'Data Infrastructure', 'Experimental Design']","Python: Used as a primary programming language for coding, data extraction, and analysis in the role.; R: Utilized for statistical analysis and data manipulation to solve business and product problems.; SQL: Employed to query databases and gather data from multiple sources for analysis.; Statistical Analysis: Applied to evaluate data, design experiments, and develop mathematical models for YouTube Search problems.; Data Quality Assurance: Involves formatting, restructuring, and validating data to ensure datasets are accurate and ready for analysis.; Mathematical Modeling: Designing and evaluating models to mathematically express and solve defined business or product problems.; Data Infrastructure: Using custom or existing data infrastructure to support data gathering, extraction, and analysis processes.; Experimental Design: Participating in experiments to understand issues and improve data-driven decision making."
e1YXftmzhcWxYPZAAAAAAA==,RWE Data Scientist II,"Job description:
As a Real-World Data (RWD) Scientist , you will be part of a team powering data driven insights that lead to better, faster decisions and therapies for our patients. Acting as a lead data scientist in your project area, you will contribute RWD expertise to broader cross-functional initiatives. Candidates should be excited to drive innovation by implementing new business technology solutions that solve significant scientific or business problems through the use and understanding of complex data. Your role will be to conceive, design and execute analytical components of research studies using sources of Real-World Data and Genetics including, but not limited to large healthcare administrative databases, electronic medical records, registries and surveys. Your expertise will be critical as you investigate, identify, develop, and optimize new methods, algorithms, and technologies to derive Client, competitive insights from disparate data sources.
Responsibilities:
• Conceive, design and implement new RWD business technology solutions that solve significant scientific or business problems through the integration, visualization, and analysis of large and complex data.
• Demonstrate high proficiency across a wide range of technologies related to the integration, visualization, and analysis of large and complex real-world data sets.
• Maintain broad expertise analyzing large real-world data including medical claims data, electronic medical records, survey data, etc.
• Demonstrate the ability to resolve key project hurdles and assumptions by effectively utilizing available information and technical expertise.
• Expand advanced methodology and adopt new technology capabilities such as machine learning, RWE dashboards and visualizations, automation, etc.
• Utilize knowledge of the pharmaceutical and healthcare business in the rapid advancement of agile, impactful, and cost-effective solutions.
• Drive productivity and efficiency gains throughout multiple business areas.
• Highly autonomous and productive in performing activities, requiring only minimal direction from or interaction with supervisor.
• Proactively seek out new information and technologies in the literature/public domain and incorporate into individual project(s) as well as the overall program.
• Understand and adhere to corporate standards regarding applicable Corporate and Divisional Policies, including code of conduct, safety, GxP compliance, and data security.
Requirements:
• M.S. (Master of Science), or PhD with 2 years of experience in HEOR/Epidemiology or related area.
• Background in life sciences or work experience in the pharmaceutical industry preferred.
• Significant experience with SAS, SAS Macro SQL, or other programming for real-world data analytics (i.e. or Python).
• Experience and/or training in the application of advanced scientific and analytical methods.
• Proven implementation of creative technology solutions that advanced the business.
• Excellent written and oral English communication skills.",,2025-07-25,"['M.S. (Master of Science), or PhD with 2 years of experience in HEOR/Epidemiology or related area', 'Significant experience with SAS, SAS Macro SQL, or other programming for real-world data analytics (i.e. or Python)', 'Experience and/or training in the application of advanced scientific and analytical methods', 'Proven implementation of creative technology solutions that advanced the business', 'Excellent written and oral English communication skills']","['Acting as a lead data scientist in your project area, you will contribute RWD expertise to broader cross-functional initiatives', 'Candidates should be excited to drive innovation by implementing new business technology solutions that solve significant scientific or business problems through the use and understanding of complex data', 'Your role will be to conceive, design and execute analytical components of research studies using sources of Real-World Data and Genetics including, but not limited to large healthcare administrative databases, electronic medical records, registries and surveys', 'Your expertise will be critical as you investigate, identify, develop, and optimize new methods, algorithms, and technologies to derive Client, competitive insights from disparate data sources', 'Conceive, design and implement new RWD business technology solutions that solve significant scientific or business problems through the integration, visualization, and analysis of large and complex data', 'Demonstrate high proficiency across a wide range of technologies related to the integration, visualization, and analysis of large and complex real-world data sets', 'Maintain broad expertise analyzing large real-world data including medical claims data, electronic medical records, survey data, etc', 'Demonstrate the ability to resolve key project hurdles and assumptions by effectively utilizing available information and technical expertise', 'Expand advanced methodology and adopt new technology capabilities such as machine learning, RWE dashboards and visualizations, automation, etc', 'Utilize knowledge of the pharmaceutical and healthcare business in the rapid advancement of agile, impactful, and cost-effective solutions', 'Drive productivity and efficiency gains throughout multiple business areas', 'Highly autonomous and productive in performing activities, requiring only minimal direction from or interaction with supervisor', 'Proactively seek out new information and technologies in the literature/public domain and incorporate into individual project(s) as well as the overall program', 'Understand and adhere to corporate standards regarding applicable Corporate and Divisional Policies, including code of conduct, safety, GxP compliance, and data security']",True,[],,"['Real-World Data', 'SAS', 'SQL', 'Python', 'Machine Learning', 'Data Visualization', 'Advanced Scientific and Analytical Methods', 'Automation', 'RWE Dashboards']","Real-World Data: Used as primary data sources including healthcare administrative databases, electronic medical records, registries, and surveys for analysis and research.; SAS: A programming tool used for real-world data analytics and implementing advanced scientific and analytical methods.; SQL: Used for querying and managing large and complex real-world data sets in healthcare and pharmaceutical contexts.; Python: Programming language employed for data analytics and implementing machine learning methods on real-world data.; Machine Learning: Applied to develop and optimize new methods and algorithms for deriving insights from complex real-world data.; Data Visualization: Used to create dashboards and visualizations that support the integration and analysis of large real-world data sets.; Advanced Scientific and Analytical Methods: Techniques applied to analyze real-world data and generate insights relevant to healthcare and pharmaceutical research.; Automation: Implemented to improve efficiency and productivity in data processing and analysis workflows.; RWE Dashboards: Dashboards specifically designed for Real-World Evidence data to facilitate visualization and decision-making."
p047tmTGAAKrsnDzAAAAAA==,"Senior Data Scientist, Marketing Analytics","In order to be considered for this role, after clicking ""Apply Now"" above and being redirected, you must fully complete the application process on the follow-up screen.

At PrizePicks, we are the fastest-growing sports company in North America, as recognized by Inc. 5000. As the leading platform for Daily Fantasy Sports, we cover a diverse range of sports leagues, including the NFL, NBA, and Esports titles like League of Legends and Counter-Strike. Our team of over 450 employees thrives in an inclusive culture that values individuals from diverse backgrounds, regardless of their level of sports fandom. Ready to reimagine the DFS industry together?

We are looking for an inquisitive, highly analytical, and detail-oriented Senior Data Scientist, experienced in Acquisition Marketing. This data-centric role is vital for building and maintaining analytics tools and workflows. A passion for solving problems around marketing attribution, spend optimization, and guiding profitable growth for the business is essential for success. You're an excellent fit for this role if you're comfortable managing projects simultaneously, working with a cross-functional team, and informing and influencing stakeholders with data, using insights to drive outcomes. What you'll do:
• Support the advancement of analytical capabilities across acquisition and retention marketing
• Develop and implement advanced analytics frameworks to tell the story of marketing performance and make budget recommendations, including media mix modeling (MMM) and channel-level marginal CAC
• Drive the learning agenda related to channel strategy, e.g. geo-level testing and media mix testing, working with marketing leadership to operationalize
• Create central reporting solutions to create holistic, executive-level, and cross-functional visibility into marketing performance, and establish and communicate the narrative around performance at appropriate altitude
• Develop required data collection and transformation processes to support reporting and analytics solutions
• Create presentations and written documents with little guidance, and present to both technical and non-technical audiences in an effective way, articulating ideas and opinions clearly and efficiently
• Serve as a mentor to more junior analysts, contributing to the advancement of capabilities and work across the Marketing Analytics organization, and act as an example for the team to follow
What you have:
• Bachelor's degree in Statistics, Economics, Computer Science, Data Science, Engineering, or a related field
• 5+ years' of Marketing Data Analytics experience in an e-commerce, direct-to-consumer environment
• Advanced knowledge of SQL, including comfort with analytics functions, window functions, and common table expressions
• 3+ years' experience with scripting languages (Python) & data visualization tools (Tableau preferred)
• Professional experience with implementing statistical models into business processes
• Advanced ability to draw insights from analysis supported by data, and clearly communicate them to stakeholders, including senior management
• Intellectual curiosity, and solid understanding of data sources and ecosystems, with the ability to see from the brand's business lens
Where you'll live:
• While we prefer candidates based in Atlanta, we are open to qualified applicants from anywhere in the U.S. and are willing to consider remote candidates. #LI-Remote
Working at PrizePicks: The typical salary range for this position is $145,000 to $195,000. At PrizePicks, we consider your role, level, and where you'll be working when determining our salary ranges. The compensation info you see on our job postings gives you an idea of the starting pay range for the position. Your actual pay within that range will depend on your specific work location, as well as your skills, experience, and education. Your recruiter will be happy to chat more about the specific pay range for your location and how we arrived at it during the hiring process. This application period will remain open for 30 days. We're committed to finding the best candidate, so this date may be adjusted, and any changes will be reflected in this posting. Date Posted: May 14th, 2025 1st Extension: June 14th, 2025 2nd Extension: July 14th, 2025

Benefits you'll receive: In addition to your great compensation package, full-time employees will be eligible for the following perks:
• Company-subsidized medical, dental, & vision plans
• 401(k) plan with company match
• Annual bonus
• Flexible PTO to encourage a healthy work/life balance (2 weeks STRONGLY encouraged!)
• Generous paid leave programs, including 16-week paid parental leave and disability benefits
• Workplace flexibility and modern work schedules focused on getting the job done, not hours clocked
• Company-wide in-person events and team outings
• Lifestyle enhancement program
• Company equipment provided (Windows & Mac options)
• Annual performance reviews with opportunities for growth and career development
You must be authorized to work for any employer in the U.S. We are unable to sponsor or take over sponsorship of an employment Visa at this time. PrizePicks is an Equal Opportunity Employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.",,2025-07-25,"['We are looking for an inquisitive, highly analytical, and detail-oriented Senior Data Scientist, experienced in Acquisition Marketing', ""You're an excellent fit for this role if you're comfortable managing projects simultaneously, working with a cross-functional team, and informing and influencing stakeholders with data, using insights to drive outcomes"", ""Bachelor's degree in Statistics, Economics, Computer Science, Data Science, Engineering, or a related field"", ""5+ years' of Marketing Data Analytics experience in an e-commerce, direct-to-consumer environment"", 'Advanced knowledge of SQL, including comfort with analytics functions, window functions, and common table expressions', 'Professional experience with implementing statistical models into business processes', 'Advanced ability to draw insights from analysis supported by data, and clearly communicate them to stakeholders, including senior management', ""Intellectual curiosity, and solid understanding of data sources and ecosystems, with the ability to see from the brand's business lens"", 'You must be authorized to work for any employer in the U.S. We are unable to sponsor or take over sponsorship of an employment Visa at this time']","['This data-centric role is vital for building and maintaining analytics tools and workflows', 'A passion for solving problems around marketing attribution, spend optimization, and guiding profitable growth for the business is essential for success', 'Support the advancement of analytical capabilities across acquisition and retention marketing', 'Develop and implement advanced analytics frameworks to tell the story of marketing performance and make budget recommendations, including media mix modeling (MMM) and channel-level marginal CAC', 'Drive the learning agenda related to channel strategy, e.g. geo-level testing and media mix testing, working with marketing leadership to operationalize', 'Create central reporting solutions to create holistic, executive-level, and cross-functional visibility into marketing performance, and establish and communicate the narrative around performance at appropriate altitude', 'Develop required data collection and transformation processes to support reporting and analytics solutions', 'Create presentations and written documents with little guidance, and present to both technical and non-technical audiences in an effective way, articulating ideas and opinions clearly and efficiently', 'Serve as a mentor to more junior analysts, contributing to the advancement of capabilities and work across the Marketing Analytics organization, and act as an example for the team to follow']",True,[],,"['Media Mix Modeling', 'Marketing Attribution', 'SQL', 'Python', 'Statistical Modeling', 'Data Visualization', 'Data Collection and Transformation', 'Marketing Analytics', 'Geo-level Testing', 'Media Mix Testing']","Media Mix Modeling: Used to analyze marketing performance and optimize budget allocation across channels.; Marketing Attribution: Applied to solve problems related to attributing marketing spend to outcomes for spend optimization.; SQL: Advanced SQL skills including analytics functions, window functions, and common table expressions are used for data querying and transformation.; Python: Used for scripting and building analytics tools and workflows in marketing data analysis.; Statistical Modeling: Implemented into business processes to support marketing analytics and decision-making.; Data Visualization: Tools like Tableau are used to create reporting solutions and communicate marketing performance insights.; Data Collection and Transformation: Processes developed to support reporting and analytics solutions for marketing data.; Marketing Analytics: Focus on acquisition and retention marketing data to drive insights and business growth.; Geo-level Testing: Used to evaluate channel strategy effectiveness at geographic levels.; Media Mix Testing: Conducted to optimize marketing channel strategies and budget allocation."
ZS6TsMNJHJz7BRKwAAAAAA==,Senior Data Analyst,"We're looking for a Senior Data Analyst with expertise in core banking systems (ABS, LMS) and training junior analysts. As a Senior Data Analyst, you will be responsible for managing and enhancing our data warehouse environment, controlling data quality, fixing and restoration data for DWH key entities, developing BI solutions, and acting as a strategic partner to business units including Sales, Risk, Data Science, and Operations. You’ll ensure data quality, support integrations, and lead efforts to improve standards and governance across the data lifecycle. This role requires strong technical expertise, excellent communication skills, and a deep understanding of banking systems and processes.
Responsibilities:
Administer DWH layers (DDS/CDM) and develop BI assets (e.g., dashboards in Power BI).
Mentor junior analysts and collaborate with stakeholders (Risk, Sales, Data Science, etc.).
Ensure data quality, resolve issues, and support integration of data sources.
Document BI standards and manage data governance strategies.
Oversee task delivery via Jira and maintain data monitoring tools.
Bachelor’s in a quantitative field (Math, Stats, CompSci); Master’s preferred.
3+ years as a Data Analyst in banking/fintech.
Advanced SQL skills and experience with BI tools (Power BI, Grafana).
Strong understanding of DWH architecture, banking platforms (ABS), and CRM systems.
Excellent communication and organizational skills in English and Russian languages; detail-oriented.
Nice to Have:
Familiarity with Agile/Scrum.
Experience with real-time data monitoring and risk analytics.
Flexible and completely remote full-time role
The opportunity to work in an innovative fintech company with a global reach
Engaging tasks and the chance to influence the development of cutting-edge products
The opportunity to grow your skills in a global, distributed team environment.

#J-18808-Ljbffr Renmoney Microfinance Bank Limited",2025-07-21T00:00:00.000Z,2025-07-25,"['3+ years as a Data Analyst in banking/fintech', 'Advanced SQL skills and experience with BI tools (Power BI, Grafana)', 'Strong understanding of DWH architecture, banking platforms (ABS), and CRM systems', 'Excellent communication and organizational skills in English and Russian languages; detail-oriented', 'Familiarity with Agile/Scrum', 'Experience with real-time data monitoring and risk analytics', 'Flexible and completely remote full-time role', 'The opportunity to work in an innovative fintech company with a global reach']","['As a Senior Data Analyst, you will be responsible for managing and enhancing our data warehouse environment, controlling data quality, fixing and restoration data for DWH key entities, developing BI solutions, and acting as a strategic partner to business units including Sales, Risk, Data Science, and Operations', 'You’ll ensure data quality, support integrations, and lead efforts to improve standards and governance across the data lifecycle', 'This role requires strong technical expertise, excellent communication skills, and a deep understanding of banking systems and processes', 'Administer DWH layers (DDS/CDM) and develop BI assets (e.g., dashboards in Power BI)', 'Mentor junior analysts and collaborate with stakeholders (Risk, Sales, Data Science, etc.)', 'Ensure data quality, resolve issues, and support integration of data sources', 'Document BI standards and manage data governance strategies', 'Oversee task delivery via Jira and maintain data monitoring tools', 'Engaging tasks and the chance to influence the development of cutting-edge products']",True,[],,"['Data Warehouse (DWH)', 'Data Quality Management', 'Business Intelligence (BI) Tools', 'SQL', 'Data Governance', 'Data Integration', 'Data Monitoring', 'Data Warehouse Architecture (DDS/CDM)', 'Risk Analytics', 'Agile/Scrum']","Data Warehouse (DWH): Managing and enhancing the data warehouse environment to support data storage and retrieval for business analysis.; Data Quality Management: Controlling, fixing, and restoring data quality for key data warehouse entities to ensure reliable analytics.; Business Intelligence (BI) Tools: Developing BI solutions and dashboards using tools like Power BI and Grafana to visualize and report data insights.; SQL: Using advanced SQL skills to query and manipulate data within databases for analysis and reporting.; Data Governance: Documenting BI standards and managing governance strategies to maintain data integrity and compliance.; Data Integration: Supporting integration of multiple data sources to create unified datasets for analysis.; Data Monitoring: Maintaining real-time data monitoring tools to track data health and detect anomalies.; Data Warehouse Architecture (DDS/CDM): Administering data warehouse layers such as Data Delivery Service (DDS) and Common Data Model (CDM) to structure data effectively.; Risk Analytics: Applying analytics techniques to assess and manage financial risk within banking operations.; Agile/Scrum: Using Agile and Scrum methodologies to manage project delivery and collaboration."
vBplUZdVBH3ZtfsSAAAAAA==,"Senior Data Scientist, Pricing","About Us:
Live experiences help people cross today's digital divide and focus on what truly connects us – the here, the now, this once-in-a-lifetime moment that's bringing us together. To fulfill Gametime's mission of uniting the world through shared experiences, we make it easy for people to discover and access the live experiences that matter most.

With platforms on iOS, Android, mobile web and desktop supporting more than 60,000 events across the US and Canada, we are reimagining the event ticket industry in order to move at the speed of life.

About the Role

We're looking for a highly analytical and business-savvy Senior Pricing Data Scientist to join our Pricing Strategy team. In this role, you'll design and execute advanced pricing models, lead experimentation efforts, and uncover insights that power monetization and growth. You'll work cross-functionally with Product, Analytics, Revenue, and Engineering to ensure our pricing strategies are data-driven, rigorously tested, and aligned with customer value.

This is a high-impact opportunity for someone who thrives at the intersection of data science, economics, and strategy, and who is passionate about using data to influence pricing, product design, and long-term business outcomes.
Key ResponsibilitiesModel Development & Optimization
• Design, build, and maintain pricing and demand elasticity models using statistical and machine learning methods.
• Leverage behavioral, transactional, and marketplace data to optimize price points, discount strategies, and product bundling.
• Develop tools to support scenario modeling, revenue forecasting, and price testing simulations.
Experimentation & Testing
• Design A/B and multivariate experiments to test pricing changes, discount strategies, and offer configurations.
• Analyze test results with statistical rigor, including significance testing, confidence intervals, and causal inference techniques.
• Partner with experimentation platform owners to automate and scale pricing experiments across channels and customer segments.
Insight Generation & Strategy Support
• Conduct in-depth analyses of customer willingness to pay, price sensitivity, and competitor pricing strategies.
• Deliver insights on monetization opportunities, marketplace dynamics, and revenue optimization levers.
• Partner with strategy and product teams to develop recommendations based on model outputs and empirical evidence.
Cross-functional Collaboration
• Collaborate closely with Product Managers, Engineers, and Revenue teams to embed pricing intelligence into user experiences.
• Translate complex technical findings into actionable business recommendations for stakeholders across the org.
• Contribute to roadmap planning, strategic decision-making, and post-launch pricing reviews.

What You BringRequired Qualifications
• 5+ years of experience in data science, pricing analytics, or quantitative strategy roles.
• Advanced proficiency in Python or R, SQL, and statistical modeling techniques.
• Strong experience with A/B testing frameworks and causal inference methods (e.g., regression, matching, difference-in-differences).
• Solid understanding of pricing theory, elasticity modeling, and optimization.
Skills & Attributes
• Excellent problem-solving and critical thinking skills; able to distill ambiguity into structured analyses.
• Business-oriented mindset with the ability to prioritize impact and communicate clearly with non-technical audiences.
• Self-starter with a passion for experimentation and continuous improvement.
Preferred
• Degree in Data Science, Statistics, Economics, Applied Mathematics, or a related quantitative discipline (Master's or PhD preferred).
• Experience in a consumer-facing marketplace, e-commerce, or SaaS environment.
• Familiarity with tools such as Looker, Amplitude, dbt, or in-house experimentation platforms.

Why This Role Matters

Your work will help define how we price, scale, and monetize our products. By bringing science and experimentation to our pricing approach, you'll directly impact revenue growth, customer satisfaction, and strategic decision-making.

What We can Offer:
• Flexible PTO
• Competitive salary & equity package
• Monthly Gametime credits for any event ($1,200/yr)
• Medical, dental, & vision insurance
• Life insurance and disability benefits
• Diverse Family-forming benefits through Carrot Fertility
• 401k, HSA, pre-tax savings programs
• Company off-sites and meet-ups
• Wellness programs
• Tenure recognition

At Gametime pay ranges are subject to change and assigned to a job based on specific market median of similar jobs according to 3rd party salary benchmark surveys. Individual pay within that range can vary for several reasons including skills/capabilities, experience, and available budget.

United States - Pay Range
$140,718—$165,550 USD

Gametime is committed to bringing together individuals from different backgrounds and perspectives. We strive to create an inclusive environment where everyone can thrive, feel a sense of belonging, and do great work together. As an equal opportunity employer, we prohibit any unlawful discrimination against a job applicant on the basis of their race, color, religion, veteran status, sex, parental status, gender identity or expression, transgender status, sexual orientation, national origin, age, disability or genetic information. We respect the laws enforced by the EEOC and are dedicated to going above and beyond in fostering diversity across our company.",2025-07-02T00:00:00.000Z,2025-07-25,"['5+ years of experience in data science, pricing analytics, or quantitative strategy roles', 'Advanced proficiency in Python or R, SQL, and statistical modeling techniques', 'Strong experience with A/B testing frameworks and causal inference methods (e.g., regression, matching, difference-in-differences)', 'Solid understanding of pricing theory, elasticity modeling, and optimization', 'Excellent problem-solving and critical thinking skills; able to distill ambiguity into structured analyses', 'Business-oriented mindset with the ability to prioritize impact and communicate clearly with non-technical audiences', 'Self-starter with a passion for experimentation and continuous improvement']","[""In this role, you'll design and execute advanced pricing models, lead experimentation efforts, and uncover insights that power monetization and growth"", ""You'll work cross-functionally with Product, Analytics, Revenue, and Engineering to ensure our pricing strategies are data-driven, rigorously tested, and aligned with customer value"", 'This is a high-impact opportunity for someone who thrives at the intersection of data science, economics, and strategy, and who is passionate about using data to influence pricing, product design, and long-term business outcomes', 'Key ResponsibilitiesModel Development & Optimization', 'Design, build, and maintain pricing and demand elasticity models using statistical and machine learning methods', 'Leverage behavioral, transactional, and marketplace data to optimize price points, discount strategies, and product bundling', 'Develop tools to support scenario modeling, revenue forecasting, and price testing simulations', 'Design A/B and multivariate experiments to test pricing changes, discount strategies, and offer configurations', 'Analyze test results with statistical rigor, including significance testing, confidence intervals, and causal inference techniques', 'Partner with experimentation platform owners to automate and scale pricing experiments across channels and customer segments', 'Insight Generation & Strategy Support', 'Conduct in-depth analyses of customer willingness to pay, price sensitivity, and competitor pricing strategies', 'Deliver insights on monetization opportunities, marketplace dynamics, and revenue optimization levers', 'Partner with strategy and product teams to develop recommendations based on model outputs and empirical evidence', 'Cross-functional Collaboration', 'Collaborate closely with Product Managers, Engineers, and Revenue teams to embed pricing intelligence into user experiences', 'Translate complex technical findings into actionable business recommendations for stakeholders across the org', 'Contribute to roadmap planning, strategic decision-making, and post-launch pricing reviews', 'Your work will help define how we price, scale, and monetize our products']",True,[],,"['Pricing and Demand Elasticity Models', 'Statistical Modeling Techniques', 'Machine Learning Methods', 'Behavioral, Transactional, and Marketplace Data', 'Scenario Modeling and Revenue Forecasting', 'A/B and Multivariate Experimentation', 'Causal Inference Techniques', 'Regression Models', 'Matching and Difference-in-Differences', 'SQL', 'Python and R', 'Looker and Amplitude', 'dbt', 'Pricing Theory and Optimization']","Pricing and Demand Elasticity Models: Used to model and optimize pricing strategies and understand customer price sensitivity to maximize revenue.; Statistical Modeling Techniques: Applied to build and maintain pricing models and analyze experimental data rigorously.; Machine Learning Methods: Leveraged to enhance pricing models and optimize discount strategies and product bundling.; Behavioral, Transactional, and Marketplace Data: Utilized as input data sources to inform pricing optimization and scenario modeling.; Scenario Modeling and Revenue Forecasting: Developed tools to simulate pricing impacts and forecast revenue outcomes.; A/B and Multivariate Experimentation: Designed and executed experiments to test pricing changes and discount strategies with statistical rigor.; Causal Inference Techniques: Used to analyze experiment results and determine the causal impact of pricing interventions.; Regression Models: Employed within causal inference and pricing model development to quantify relationships between variables.; Matching and Difference-in-Differences: Specific causal inference methods applied to evaluate pricing experiments and strategies.; SQL: Used for querying and managing data relevant to pricing analytics and experimentation.; Python and R: Programming languages utilized for statistical modeling, data analysis, and building pricing models.; Looker and Amplitude: BI and analytics tools referenced for data visualization and experimentation platform integration.; dbt: Data transformation tool mentioned for managing data pipelines supporting pricing analytics.; Pricing Theory and Optimization: Conceptual frameworks guiding the development of pricing strategies and elasticity models."
gz3I4Cz8D4Gz6yTtAAAAAA==,"US E-Consulting Services-Senior Data Scientist, Specialist Senior-S&T Strategy AIDASD/SFL Scientific-WW (303712)","Senior Data Scientist, Specialist Senior SFL Scientific

Our Deloitte Strategy & Transactions team helps guide clients through their most critical moments and transformational initiatives. From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability. Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journeybefore, during, and after any major transformational projects or transactions.

SFL Scientific, a Deloitte Business, is a U.S. based, data science consulting firm specializing in building industry-specific, artificial intelligence (AI) technologies.

We are hiring a Senior Data Scientist to collaborate directly with clients to design and develop novel projects and solutions. Join a rapidly growing team of professionals working to build a world-class data science practice focused on solving complex and R&D problems.

Recruiting for this role ends on 6/30/2025.

Work Youll Do

As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services. You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions.

Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation. Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills.
• Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production
• Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives
• Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization
• Validate AI models and algorithm via code reviews, unit, and integration tests
• Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives
• Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives

The Team

Our Strategy offering architects bold strategies to achieve business and mission goals, enabling growth, competitive advantage, technology modernization, and continuous digital and AI transformation.

SFL Scientific, a Deloitte Business, is a data science professional services practice focused on strategy, technology, and solving business challenges with Artificial Intelligence (AI). The team has a proven track record serving large, market-leading organizations in the private and public sectors, successfully delivering high-quality, novel and complex projects, and offering deep domain and scientific capabilities. Made up of experienced AI strategists, data scientists, and AI engineers, they serve as trusted advisors to executives, helping them understand and evaluate new and essential areas for AI investment and identify unique opportunities to transform their businesses.

Qualifications:
• Masters or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)
• 3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)
• 3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments
• 3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow
• 3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads
• Live within commuting distance to one of Deloittes consulting offices
• Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve
• Limited immigration sponsorship may be available

Preferred:
• 2+ years of experience working in a client-facing, consulting environment
• 2+ years of experience leading project/client engagement teams in the execution of complex AI data science solutions
• 1+ year of experience with LLM/GenAI use cases and developing RAG solutions, tools, and services (i.e., LangChain, LangGraph, MCP, etc.)
• 1+ year of experience with AWS Sagemaker or AWS ML Studio

Information for applicants with a need for accommodation:

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $107,600 to $198,400.

You may also be eligible to participate in a discretionary annual incentive program, subject to the rules governing the program, whereby an award, if any, depends on various factors, including, without limitation, individual and organizational performance.

#MonitorDeloitte

#DeloitteJobs

#StrategyConsulting

#DeloitteStrategy

#Strategy26

#SFL26
Recruiting tips

From developing a stand out resume to putting your best foot forward in the interview, we want you to feel prepared and confident as you explore opportunities at Deloitte. Check out recruiting tips from Deloitte recruiters. Benefits

At Deloitte, we know that great people make a great organization. We value our people and offer employees a broad range of benefits. Learn more about what working at Deloitte can mean for you. Our people and culture

Our inclusive culture empowers our people to be who they are, contribute their unique perspectives, and make a difference individually and collectively. It enables us to leverage different ideas and perspectives, and bring more creativity and innovation to help solve our clients' most complex challenges. This makes Deloitte one of the most rewarding places to work. Our purpose
Deloittes purpose is to make an impact that matters for our people, clients, and communities. At Deloitte, purpose is synonymous with how we work every day. It defines who we are. Our purpose comes through in our work with clients that enables impact and value in their organizations, as well as through our own investments, commitments, and actions across areas that help drive positive outcomes for our communities. Learn more. Professional development

From entry-level employees to senior leaders, we believe theres always room to learn. We offer opportunities to build new skills, take on leadership opportunities and connect and grow through mentorship. From on-the-job learning experiences to formal development programs, our professionals have a variety of opportunities to continue to grow throughout their career. Position Summary

Senior Data Scientist, Specialist Senior SFL Scientific

Our Deloitte Strategy & Transactions team helps guide clients through their most critical moments and transformational initiatives. From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability. Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journeybefore, during, and after any major transformational projects or transactions.

SFL Scientific, a Deloitte Business, is a U.S. based, data science consulting firm specializing in building industry-specific, artificial intelligence (AI) technologies.

We are hiring a Senior Data Scientist to collaborate directly with clients to design and develop novel projects and solutions. Join a rapidly growing team of professionals working to build a world-class data science practice focused on solving complex and R&D problems.

Recruiting for this role ends on 6/30/2025.

Work Youll Do

As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services. You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions.

Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation. Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills.
• Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production
• Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives
• Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization
• Validate AI models and algorithm via code reviews, unit, and integration tests
• Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives
• Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives

The Team

Our Strategy offering architects bold strategies to achieve business and mission goals, enabling growth, competitive advantage, technology modernization, and continuous digital and AI transformation.

SFL Scientific, a Deloitte Business, is a data science professional services practice focused on strategy, technology, and solving business challenges with Artificial Intelligence (AI). The team has a proven track record serving large, market-leading organizations in the private and public sectors, successfully delivering high-quality, novel and complex projects, and offering deep domain and scientific capabilities. Made up of experienced AI strategists, data scientists, and AI engineers, they serve as trusted advisors to executives, helping them understand and evaluate new and essential areas for AI investment and identify unique opportunities to transform their businesses.

Qualifications:
• Masters or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)
• 3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)
• 3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments
• 3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow
• 3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads
• Live within commuting distance to one of Deloittes consulting offices
• Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve
• Limited immigration sponsorship may be available

Preferred:
• 2+ years of experience working in a client-facing, consulting environment
• 2+ years of experience leading project/client engagement teams in the execution of complex AI data science solutions
• 1+ year of experience with LLM/GenAI use cases and developing RAG solutions, tools, and services (i.e., LangChain, LangGraph, MCP, etc.)
• 1+ year of experience with AWS Sagemaker or AWS ML Studio

Information for applicants with a need for accommodation:

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $107,600 to $198,400.

You may also be eligible to participate in a discretionary annual incentive program, subject to the rules governing the program, whereby an award, if any, depends on various factors, including, without limitation, individual and organizational performance.

#MonitorDeloitte

#DeloitteJobs

#StrategyConsulting

#DeloitteStrategy

#Strategy26

#SFL26
Recruiting tips

From developing a stand out resume to putting your best foot forward in the interview, we want you to feel prepared and confident as you explore opportunities at Deloitte. Check out recruiting tips from Deloitte recruiters. Benefits

At Deloitte, we know that great people make a great organization. We value our people and offer employees a broad range of benefits. Learn more about what working at Deloitte can mean for you. Our people and culture

Our inclusive culture empowers our people to be who they are, contribute their unique perspectives, and make a difference individually and collectively. It enables us to leverage different ideas and perspectives, and bring more creativity and innovation to help solve our clients' most complex challenges. This makes Deloitte one of the most rewarding places to work. Our purpose
Deloittes purpose is to make an impact that matters for our people, clients, and communities. At Deloitte, purpose is synonymous with how we work every day. It defines who we are. Our purpose comes through in our work with clients that enables impact and value in their organizations, as well as through our own investments, commitments, and actions across areas that help drive positive outcomes for our communities. Learn more. Professional development

From entry-level employees to senior leaders, we believe theres always room to learn. We offer opportunities to build new skills, take on leadership opportunities and connect and grow through mentorship. From on-the-job learning experiences to formal development programs, our professionals have a variety of opportunities to continue to grow throughout their career.

As used in this posting, ""Deloitte"" means Deloitte Consulting LLP, a subsidiary of Deloitte LLP. Please see www.deloitte.com/us/about for a detailed description of the legal structure of Deloitte LLP and its subsidiaries.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.
Qualified applicants with criminal histories, including arrest or conviction records, will be considered for employment in accordance with the requirements of applicable state and local laws, including the Los Angeles County Fair Chance Ordinance for Employers, City of Los Angeless Fair Chance Initiative for Hiring Ordinance, San Francisco Fair Chance Ordinance, and the California Fair Chance Act. See notices of various fair chance hiring and ban-the-box laws where available. Fair Chance Hiring and Ban-the-Box Notices | Deloitte US Careers Requisition code: 303712 Job ID 303712 Qualified applicants with criminal histories, including arrest or conviction records, will be considered for employment in accordance with the requirements of applicable state and local laws, including the Los Angeles County Fair Chance Ordinance for Employers, City of Los Angeless Fair Chance Initiative for Hiring Ordinance, San Francisco Fair Chance Ordinance, and the California Fair Chance Act. See notices of various fair chance hiring and ban-the-box laws where available. Fair Chance Hiring and Ban-the-Box Notices | Deloitte US Careers Requisition code: 303712 Job ID 303712 Caution against fraudulent job offers!

We have been informed of instances where jobseekers are led to believe of fictitious job opportunities with Deloitte US (Deloitte). In one or more such cases, false promises of actual or potential selection, or initiation or completion of the recruitment formalities appear to have been or are being made. Some jobseekers appear to have been asked to pay money to specified bank accounts of individuals or entities as a condition of their selection for a job with Deloitte. These individuals or entities are in no way connected with Deloitte and do not represent or otherwise act on behalf of Deloitte.

We would like to clarify that:
• At Deloitte, ethics and integrity are fundamental and not negotiable.
• We are against corruption and neither offer bribes nor accept them, nor induce or permit any other party to make or receive bribes on our behalf.
• We have not authorized any party or person to collect any money from jobseekers in any form whatsoever for promises of getting jobs in Deloitte.
• We consider candidates on merit and that we provide an equal opportunity to eligible applicants.
• No one other than designated Deloitte personnel (e.g., a Deloitte recruiter or Deloitte hiring partner) is permitted to extend any job offer from Deloitte.

Anyone who at any time has made or makes any payment to any party in exchange for promises of job or selection for a job with Deloitte or any matter related to this (including those for registration, verification or security deposit) or otherwise engages with any such person who has made or makes fraudulent promises or offers, does so (or has done so) entirely at their own risk. Deloitte takes no responsibility or liability for any such unauthorized or fraudulent actions or engagements. We encourage jobseekers to exercise caution.",,2025-07-25,"['Masters or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)', '3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)', '3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments', '3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow', '3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads', 'Live within commuting distance to one of Deloittes consulting offices', 'Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve', 'Limited immigration sponsorship may be available', 'Senior Data Scientist, Specialist Senior SFL Scientific', 'Masters or Ph.D. in a relevant STEM field (Data Science, Computer Science, Engineering, Physics, Mathematics, etc.)', '3+ years of experience in AI/ML algorithm development using core data science languages and frameworks (Python, PyTorch, etc.) and data analysis (NLP, time-series analysis, computer vision)', '3+ years of experience and a proven track record applying traditional ML and deep learning techniques (CNNs, RNNs, GANs) across real-world projects, including model tuning and performance validation in production environments', '3+ years of experience deploying and optimizing ML models using tools like Kubernetes, Docker, TensorRT/Trion, RAPIDs, Kubeflow, and MLflow', '3+ years of experience in leveraging cloud environments (AWS, Azure, or GCP) to deploy AI/ML workloads', 'Live within commuting distance to one of Deloittes consulting offices', 'Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve', 'Limited immigration sponsorship may be available', 'Fair Chance Hiring and Ban-the-Box Notices | Deloitte US Careers Requisition code: 303712 Job ID 303712 Qualified applicants with criminal histories, including arrest or conviction records, will be considered for employment in accordance with the requirements of applicable state and local laws, including the Los Angeles County Fair Chance Ordinance for Employers, City of Los Angeless Fair Chance Initiative for Hiring Ordinance, San Francisco Fair Chance Ordinance, and the California Fair Chance Act']","['From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability', 'Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journeybefore, during, and after any major transformational projects or transactions', 'As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services', 'You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions', 'Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation', 'Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills', 'Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production', 'Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives', 'Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization', 'Validate AI models and algorithm via code reviews, unit, and integration tests', 'Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives', 'Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives', 'From strategy to execution, this team delivers integrated, end-to-end support and advisory services covering valuation modeling, cost optimization, restructuring, business design and transformation, infrastructure and real estate, mergers and acquisitions (M&A), and sustainability', 'Work alongside clients every step of the way, helping them navigate new challenges, avoid financial pitfalls, and provide practical solutions at every stage of their journeybefore, during, and after any major transformational projects or transactions', 'As a Senior Data Scientist at SFL Scientific, a Deloitte Business, you will define data strategy, drive technical development, and help us create the next generation of tools, products, and AI services', 'You will work closely with clients to understand their data sets, strategy, and operational requirements, in order to drive exploratory analysis and design long-term solutions', 'Working with a team of interdisciplinary data scientists, engineers, architects, and consultants, our work includes novel areas such as cancer detection, drug discovery, optimizing population health and clinical trials, autonomous systems and edge AI, agentic solutions, and consumer product innovation', 'Join us to expand your technical career through the lens of consulting and work on novel projects and use cases to expand your data science & AI skills', 'Guide clients with high autonomy in AI strategy and development, including understanding organizational needs, performing exploratory data analysis, building and validating models, and deploying models into production', 'Lead client initiatives to deliver AI/ML solutions, including providing thought leadership, long-term maintenance, and AI strategy objectives', 'Research and implement novel machine learning approaches, including advancing state of the art training, solution design, network design, and hardware optimization', 'Validate AI models and algorithm via code reviews, unit, and integration tests', 'Support prioritization of project performance and model development and ensure AI solutions are delivered to maximize business impact and new initiatives', 'Collaborate with data engineers, data scientists, project managers, and business teams to make sure delivery and presentations align with business objectives']",True,"['Generative AI', 'Large Language Models', 'Retrieval-Augmented Generation', 'Prompt Engineering', 'Deep Learning Frameworks', 'Convolutional Neural Networks', 'Recurrent Neural Networks', 'Generative Adversarial Networks', 'AI Model Validation and Testing', 'AI Strategy and Consulting', 'AI Model Deployment on Cloud', 'Edge AI and Autonomous Systems', 'Multi-Modal AI and Agentic Solutions']","Generative AI: Involves developing and deploying generative AI solutions including LLM/GenAI use cases to create novel AI services.; Large Language Models: Experience with LLMs is required for building advanced AI applications and RAG solutions.; Retrieval-Augmented Generation: Developing RAG solutions and tools like LangChain and LangGraph to enhance AI model capabilities.; Prompt Engineering: Applied in designing effective prompts for LLMs to improve AI model outputs and interactions.; Deep Learning Frameworks: Use of PyTorch specifically for neural network development and training in AI projects.; Convolutional Neural Networks: Applied in deep learning models for image-related AI tasks such as cancer detection.; Recurrent Neural Networks: Used for sequence modeling tasks within AI solutions.; Generative Adversarial Networks: Employed for generating synthetic data or enhancing model training in AI projects.; AI Model Validation and Testing: Includes code reviews, unit, and integration tests to ensure AI model reliability and performance.; AI Strategy and Consulting: Guiding clients on AI adoption, strategy development, and delivering AI/ML solutions with business impact.; AI Model Deployment on Cloud: Deploying and managing AI models using cloud services like AWS Sagemaker and AWS ML Studio.; Edge AI and Autonomous Systems: Working on AI solutions deployed on edge devices and autonomous agentic systems.; Multi-Modal AI and Agentic Solutions: Developing AI systems that integrate multiple data modalities and autonomous agent capabilities.","['Exploratory Data Analysis', 'Time-Series Analysis', 'Natural Language Processing', 'Computer Vision', 'Traditional Machine Learning', 'Deep Learning', 'Model Validation and Performance Tuning', 'Model Deployment and Optimization', 'Data Science Programming Languages and Frameworks', 'Cloud Computing Platforms', 'MLOps Tools']","Exploratory Data Analysis: Used to understand client data sets and operational requirements to design long-term data science solutions.; Time-Series Analysis: Applied as part of data analysis techniques to extract insights from sequential data in client projects.; Natural Language Processing: Utilized for analyzing and extracting information from text data as part of AI/ML algorithm development.; Computer Vision: Employed in projects involving image data, such as cancer detection and drug discovery.; Traditional Machine Learning: Includes applying classical ML algorithms and techniques for model building, tuning, and validation in production.; Deep Learning: Used for advanced modeling techniques including CNNs, RNNs, and GANs to solve complex real-world problems.; Model Validation and Performance Tuning: Ensures AI/ML models meet performance standards and are production-ready through testing and tuning.; Model Deployment and Optimization: Involves deploying ML models into production environments and optimizing them using tools like Kubernetes and Docker.; Data Science Programming Languages and Frameworks: Includes Python and PyTorch used for AI/ML algorithm development and data analysis.; Cloud Computing Platforms: Leverages AWS, Azure, or GCP to deploy and manage AI/ML workloads in scalable environments.; MLOps Tools: Utilizes Kubeflow, MLflow, RAPIDs, TensorRT/Trion for managing machine learning lifecycle and model optimization."
6NV_1aLYhYL-zyNRAAAAAA==,"Senior Data Scientist ; Minneapolis, MN","Position: Senior Data Scientist New Charlotte, North Carolina, United States; Minneapolis, MN

RVO Health is building a suite of integrated products that enable data-driven, digital experiences for our brands and partners. You will work with cutting-edge technologies that change how millions of users connect, explore, and work with these brands. As a Senior Data Scientist at RVO Health, you will play a crucial role in designing, implementing, and maintaining our recommendation systems.
What You’ll Do
• Model Development: Use your expertise in machine learning and predictive analytics to design, build, and deploy robust recommendation models. Your work will directly influence the company's decision-making and strategic direction.
• Engage with Business Stakeholders: Regularly communicate and collaborate with key business stakeholders to identify valuable opportunities to leverage data science techniques.
• Model Optimization: Continuously strive for the improvement of existing models by incorporating new data, refining algorithms, or utilizing innovative data science techniques. Your focus will be on enhancing the predictive accuracy of our models to make them more reliable and efficient.
• Results Communication: Communicate complex data science concepts and the model outcomes to non-technical stakeholders in a clear and effective manner.
• Collaborative Teamwork: Collaborate with other data scientists, data engineers, and cross-functional teams in an agile environment to ensure the smooth and timely execution of projects.
What We’re Looking For
• 4+ years of experience as a Data Scientist
• Expert knowledge of machine learning and statistical modeling with experience in at least one of the following areas: recommender systems, NLP, deep learning, or graph theory applications.
• Capability of communicating effectively with business and data science leaders on project status, timeline and technical results.
• Proficient at collecting and mining data from disparate data sources, and willing to dig deeper and understand the process that creates the data.
• Analytical and detail oriented with the ability to prioritize, execute, and deliver projects on time
• Capable of translating business opportunities into data science problems and defining the right project scope and performance metric to measure success
• Must be comfortable with unstructured, fast moving and constantly evolving high-growth environment
• Committed team player who is proactive, takes ownership over the success of their projects, and works hard to support those around them
• Comfortable working onsite in Charlotte or Minneapolis twice a week

Pursuant to various state Fair Pay Acts, below is a summary of compensation elements for this role at the company. The following benefits are provided by RVO Health, subject to eligibility requirements.
• Starting Salary: $93,000 - $120,000
• Note actual salary is based on geographic location, qualifications and experience
• Access to a Free Udemy for Business subscription—thousands of hours of learning content on hundreds of different subjects at your fingertips
• Health Insurance Coverage (medical, dental, and vision)
• Life Insurance
• Short and Long-Term Disability Insurance
• Flexible Spending Accounts
• Paid Time Off
• Holiday Pay
• 401(k) with match
• Employee Assistance Program
• Income Protection Plans
• Pet Services Plans
• Mental Health Support
• Wellness Coaching
• HSA
- Health Savings Account
• Gym & Fitness Center Discount Program

Who We Are:

Founded in 2022, RVO Health is a new healthcare platform of digital media brands, services and technologies focused on building relationships with people throughout their health & wellness journey. We meet people where they are in their personal health journeys and connect them with both the information and the care they need. RVO Health was created by joining teams from both Red Ventures and United Health Group’s Optum Health.

Together we’re focused on delivering on our vision of a stronger and healthier world.

RVO Health is comprised of Healthline Media (Healthline, Medical News Today, Psych Central, Greatist and Bezzy), Health grades, Find Care and Plate Joy;
Optum Perks, Optum Store and the virtual coaching platforms Real Appeal, Wellness Coaching, and Quit For Life .

We offer competitive salaries and a comprehensive…",,2025-07-25,"['4+ years of experience as a Data Scientist', 'Expert knowledge of machine learning and statistical modeling with experience in at least one of the following areas: recommender systems, NLP, deep learning, or graph theory applications', 'Capability of communicating effectively with business and data science leaders on project status, timeline and technical results', 'Proficient at collecting and mining data from disparate data sources, and willing to dig deeper and understand the process that creates the data', 'Analytical and detail oriented with the ability to prioritize, execute, and deliver projects on time', 'Capable of translating business opportunities into data science problems and defining the right project scope and performance metric to measure success', 'Must be comfortable with unstructured, fast moving and constantly evolving high-growth environment', 'Committed team player who is proactive, takes ownership over the success of their projects, and works hard to support those around them', 'Comfortable working onsite in Charlotte or Minneapolis twice a week']","['As a Senior Data Scientist at RVO Health, you will play a crucial role in designing, implementing, and maintaining our recommendation systems', 'Model Development: Use your expertise in machine learning and predictive analytics to design, build, and deploy robust recommendation models', ""Your work will directly influence the company's decision-making and strategic direction"", 'Engage with Business Stakeholders: Regularly communicate and collaborate with key business stakeholders to identify valuable opportunities to leverage data science techniques', 'Model Optimization: Continuously strive for the improvement of existing models by incorporating new data, refining algorithms, or utilizing innovative data science techniques', 'Your focus will be on enhancing the predictive accuracy of our models to make them more reliable and efficient', 'Results Communication: Communicate complex data science concepts and the model outcomes to non-technical stakeholders in a clear and effective manner', 'Collaborative Teamwork: Collaborate with other data scientists, data engineers, and cross-functional teams in an agile environment to ensure the smooth and timely execution of projects']",True,[],,"['Machine Learning', 'Predictive Analytics', 'Recommendation Systems', 'Statistical Modeling', 'Natural Language Processing', 'Deep Learning', 'Graph Theory Applications']","Machine Learning: Used to design, build, and deploy recommendation models that influence company decision-making.; Predictive Analytics: Applied to develop models that forecast outcomes and improve recommendation systems.; Recommendation Systems: Core focus of the role, involving designing and maintaining models to provide personalized suggestions.; Statistical Modeling: Expertise required to build robust models for data-driven decision-making.; Natural Language Processing: Experience in NLP is relevant for handling unstructured data within recommendation or related models.; Deep Learning: Experience in deep learning techniques is valued for advanced model development.; Graph Theory Applications: Used as part of modeling techniques potentially for relationship or network-based recommendations."
Y2EnjmLLHhIxktFWAAAAAA==,Data Analyst - Visualization - Entry Level,"Job Summary:

Merchants Bancorp is ranked as one of the top-performing banks in the U.S., and they are seeking a highly skilled Data Analyst with expertise in Power BI visualization and data analytics. The role involves translating complex business requirements into interactive dashboards and reports, collaborating with stakeholders to align visual analytics with business objectives.

Responsibilities:

• Design, develop, and optimize Power BI dashboards and reports to visualize key business metrics.

• Collaborate with business leaders to gather and understand requirements and transform them into effective visualizations.

• Ensure data integrity, accuracy, and consistency by working closely with data engineers and stakeholders.

• Develop data models that support business intelligence reporting.

• Implement best practices in visualization design, ensuring clarity, usability, and impact.

• Identify and recommend improvements for business performance through data-driven insights.

• Stay ahead of industry trends and innovations in Power BI and business intelligence tools.

Qualifications:

Required:

• A bachelor’s or master’s degree in data Analytics, Business Intelligence, Computer Science, or a related field.

• Minimum experience requirements: At least one year of relevant experience with a master’s degree, or three years with a bachelor’s degree, in data analytics, business intelligence, or visualization development.

• Proven expertise in Power BI dashboard development and design.

• Strong business acumen with an ability to align visualizations with operational goals.

• Advanced proficiency in DAX, Power Query, SQL, and data modeling.

• Experience working with large datasets and ensuring efficient data processing.

• Excellent communication skills to translate technical findings into business-friendly insights.

• Strong analytical thinking and problem-solving abilities.

Company:

Ranked as one of the top-performing banks in the U.S. Founded in 1990, the company is headquartered in Carmel, Indiana, USA, with a team of 501-1000 employees. The company is currently Public Company.",2025-07-22T00:00:00.000Z,2025-07-25,"['A bachelor’s or master’s degree in data Analytics, Business Intelligence, Computer Science, or a related field', 'Minimum experience requirements: At least one year of relevant experience with a master’s degree, or three years with a bachelor’s degree, in data analytics, business intelligence, or visualization development', 'Proven expertise in Power BI dashboard development and design', 'Strong business acumen with an ability to align visualizations with operational goals', 'Advanced proficiency in DAX, Power Query, SQL, and data modeling', 'Experience working with large datasets and ensuring efficient data processing', 'Excellent communication skills to translate technical findings into business-friendly insights', 'Strong analytical thinking and problem-solving abilities']","['The role involves translating complex business requirements into interactive dashboards and reports, collaborating with stakeholders to align visual analytics with business objectives', 'Design, develop, and optimize Power BI dashboards and reports to visualize key business metrics', 'Collaborate with business leaders to gather and understand requirements and transform them into effective visualizations', 'Ensure data integrity, accuracy, and consistency by working closely with data engineers and stakeholders', 'Develop data models that support business intelligence reporting', 'Implement best practices in visualization design, ensuring clarity, usability, and impact', 'Identify and recommend improvements for business performance through data-driven insights', 'Stay ahead of industry trends and innovations in Power BI and business intelligence tools']",True,[],,"['Power BI', 'DAX', 'Power Query', 'SQL', 'Data Modeling', 'Business Intelligence']","Power BI: Used for developing and optimizing interactive dashboards and reports to visualize key business metrics.; DAX: Applied for advanced data analysis expressions within Power BI to create complex calculations and data models.; Power Query: Utilized for data transformation and preparation to ensure efficient data processing in visualization workflows.; SQL: Used to query and manage large datasets, supporting data extraction and integration for reporting.; Data Modeling: Developed to support business intelligence reporting and ensure data integrity and consistency.; Business Intelligence: The overall practice of analyzing data and creating visualizations to inform business decisions."
uDm6xPwvq22iQBueAAAAAA==,"(USA) Principal, Data Scientist","Position Summary...

What you'll do...About TeamThe data science team at the Enterprise Business Services Pillar at Walmart Global Tech focuses on using the latest research in machine learning, statistics, and optimization to solve business problems. We mine data, distill insights, extract information, build analytical models, deploy machine learning algorithms, and use the latest technology to empower business decision-making. Additionally, we work with engineers to build reference architectures and machine learning pipelines in a big data ecosystem to productize our solutions. Advanced analytical algorithms driven by our team help Walmart optimize business operations, improve business practices, and change the way our customers shop. The data science community at Walmart Global Tech is active in most hack events, utilizing the petabytes of data at our disposal to build some of the coolest ideas. All the work we do at Walmart Labs will eventually benefit our operations and associates, helping customers save money and live better. Your OpportunityAs a Principal Data Scientist for Walmart Global Tech, you'll have the opportunity to: Drive data-derived insights across a wide range of retail and finance divisions by developing advanced statistical models, machine learning algorithms, and computational algorithms based on business initiatives. Direct the gathering of data, assess data validity, and synthesize data into large analytics datasets to support project goals. Build and train AI/ML models for replication in future projects. Communicate recommendations to business partners and influence future plans based on insights. What You Will Do Consult with business stakeholders regarding algorithm-based recommendations and be a thought leader to develop these into business actions. Closely partner with the Senior Manager and Director of Data Science to drive data science adoption in the domain. Guide data scientists, senior data scientists, and staff data scientists across multiple sub-domains to ensure on-time delivery of ML products. Drive efficiency across the domain in terms of DS and ML best practices, ML Ops practices, resource utilization, reusability, and multi-tenancy. Lead multiple complex ML products and guide senior tech leads in the domain in efficiently leading their products. Drive synergies across different products in terms of algorithmic innovation and sharing of best practices. Proactively identify complex business problems that can be solved using advanced ML, finding opportunities and gaps in the current business domain. Evaluate proposed business cases for projects and initiatives. Translate business requirements into strategies, initiatives, and projects, align them with business strategy and objectives, and drive the execution of deliverables. Set relevant deliverables based on established success criteria and define key metrics to measure progress and effectiveness of the solution. Quantify business impact and ensure regular impact measurement of all ML products in the domain. Identify and review model evaluation metrics based on analytical requirements. Ensure testing information is documented and maintained by the team. Play a key role in solving complex problems pivotal to Walmarts business and driving actionable insights. Utilize a product mindset to build, scale, and deploy holistic data science products after successful prototyping. Demonstrate an incremental solution approach with agile and flexible ability to overcome practical problems. Articulate and present recommendations to business partners and influence plans based on insights. Partner and engage with associates in other regions to deliver the best services to customers around the globe. Work with a customer-centric mindset to deliver high-quality business-driven analytic solutions. Drive innovation in approach, method, practices, process, outcome, delivery, or any component of end-to-end problem solving. Proactively engage in the external community to build Walmarts brand and learn more about industry practices. Promote and support company policies, procedures, mission, values, and standards of ethics and integrity. What You Will Bring Bachelors, Masters, or Ph.D. with 10-15 years of relevant experience. Educational qualifications should be in Computer Science, Statistics, Mathematics, or a related area. Minimum 10 years of experience as a data science technical lead. Ability to lead multiple data science projects end-to-end. Deep experience in building data science solutions in areas like fraud prevention, forecasting, shrink and waste reduction, inventory management, recommendation, assortment, and price optimization. Deep experience in simultaneously leading multiple data science initiatives end-to-end from translating business needs to analytical asks, leading the process of building solutions, and the eventual act of deployment and maintenance of them. Strong experience in machine learning: classification models, regression models, NLP, forecasting, unsupervised models, optimization, graph ML, causal inference, causal ML, statistical learning, experimentation, and Gen-AI. In Gen-AI, it is desirable to have experience in embedding generation from training materials, storage and retrieval from vector databases, setup and provisioning of managed LLM gateways, development of retrieval-augmented generation-based LLM agents, model selection, iterative prompt engineering and fine-tuning based on accuracy and user feedback, monitoring, and governance. Ability to scale and deploy data science solutions. Strong experience with one or more of Python and R. Experience in GCP/Azure. Strong experience in Python, Py Spark. Google Cloud Platform, Vertex AI, Kubeflow, model deployment. Strong experience with big data platforms Hadoop (Hive, Map Reduce, HQL, Scala). Experience with GPU/CUDA for computational efficiency. About Walmart Global TechFrom entry-level to executive positions, Walmart provides limitless opportunities for growth and career development. Walmart started small, with a single discount store and the simple philosophy of selling more for less. Today, we are a growing technology-enabled company founded on the same values as our first store. We establish clear expectations, empower associates to manage their work, and hold ourselves and one another to a high standard. Walmarts scale enables us to have an unmatched reach, with 2.3 million associates worldwide and over 230 million weekly customers. Walmart is reshaping retail by investing in an expanding workforce. While technology is at the heart of our digital transformation, people are the reason we succeed and the force behind our innovations. We train our team in the skillsets of the future and bring in experts like you to help us grow. Flexible, Hybrid WorkWe use a hybrid way of working with primary in-office presence coupled with an optimal mix of virtual presence. We use our campuses to collaborate and be together in person, as business needs require, and for development and networking opportunities. This approach helps us make quicker decisions, remove location barriers across our global team, and be more flexible in our personal lives. BenefitsBeyond our great compensation package, you can receive incentive awards for your performance. Other great perks include a host of best-in-class benefits such as maternity and parental leave, PTO, health benefits, and much more. Equal Opportunity EmployerWalmart, Inc. is an Equal Opportunity Employer by choice. We believe we are best equipped to help our associates, customers, and the communities we serve live better when we really know them. That means understanding, respecting, and valuing Belonging unique styles, experiences, identities, ideas, and opinions while being welcoming of all people.

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

‎

‎

‎
You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.

‎

For information about PTO, see https://one.walmart.com/notices.

‎

‎
Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

‎
Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

‎

For information about benefits and eligibility, see One.Walmart.

‎
The annual salary range for this position is $110,000.00-$220,000.00

‎
Additional compensation includes annual or quarterly performance bonuses.

‎
Additional compensation for certain positions may also include:

‎

‎
- Stock

‎

‎

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 5 years' experience in an analytics related field. Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 3 years' experience in an analytics related field. Option 3: 7 years' experience in an analytics or related field

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data science, machine learning, optimization models, PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Publications or active peer reviewer in related journals or conference, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.

Primary Location...

805 Se Moberly Ln, Bentonville, AR 72712, United States of America",2025-07-23T00:00:00.000Z,2025-07-25,"['What You Will Bring Bachelors, Masters, or Ph.D. with 10-15 years of relevant experience', 'Educational qualifications should be in Computer Science, Statistics, Mathematics, or a related area', 'Minimum 10 years of experience as a data science technical lead', 'Ability to lead multiple data science projects end-to-end', 'Deep experience in building data science solutions in areas like fraud prevention, forecasting, shrink and waste reduction, inventory management, recommendation, assortment, and price optimization', 'Deep experience in simultaneously leading multiple data science initiatives end-to-end from translating business needs to analytical asks, leading the process of building solutions, and the eventual act of deployment and maintenance of them', 'Strong experience in machine learning: classification models, regression models, NLP, forecasting, unsupervised models, optimization, graph ML, causal inference, causal ML, statistical learning, experimentation, and Gen-AI', 'Ability to scale and deploy data science solutions', 'Strong experience with one or more of Python and R', 'Experience in GCP/Azure', 'Strong experience in Python, Py Spark', 'Google Cloud Platform, Vertex AI, Kubeflow, model deployment', 'Strong experience with big data platforms Hadoop (Hive, Map Reduce, HQL, Scala)', 'Experience with GPU/CUDA for computational efficiency', 'That means understanding, respecting, and valuing Belonging unique styles, experiences, identities, ideas, and opinions while being welcoming of all people', ""Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 5 years' experience in an analytics related field"", ""Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 3 years' experience in an analytics related field"", ""Option 3: 7 years' experience in an analytics or related field"", 'Data science, machine learning, optimization models, PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Publications or active peer reviewer in related journals or conference, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly', 'The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture']","['Direct the gathering of data, assess data validity, and synthesize data into large analytics datasets to support project goals', 'Build and train AI/ML models for replication in future projects', 'Communicate recommendations to business partners and influence future plans based on insights', 'What You Will Do Consult with business stakeholders regarding algorithm-based recommendations and be a thought leader to develop these into business actions', 'Closely partner with the Senior Manager and Director of Data Science to drive data science adoption in the domain', 'Guide data scientists, senior data scientists, and staff data scientists across multiple sub-domains to ensure on-time delivery of ML products', 'Drive efficiency across the domain in terms of DS and ML best practices, ML Ops practices, resource utilization, reusability, and multi-tenancy', 'Lead multiple complex ML products and guide senior tech leads in the domain in efficiently leading their products', 'Drive synergies across different products in terms of algorithmic innovation and sharing of best practices', 'Proactively identify complex business problems that can be solved using advanced ML, finding opportunities and gaps in the current business domain', 'Evaluate proposed business cases for projects and initiatives', 'Translate business requirements into strategies, initiatives, and projects, align them with business strategy and objectives, and drive the execution of deliverables', 'Set relevant deliverables based on established success criteria and define key metrics to measure progress and effectiveness of the solution', 'Quantify business impact and ensure regular impact measurement of all ML products in the domain', 'Identify and review model evaluation metrics based on analytical requirements', 'Ensure testing information is documented and maintained by the team', 'Play a key role in solving complex problems pivotal to Walmarts business and driving actionable insights', 'Utilize a product mindset to build, scale, and deploy holistic data science products after successful prototyping', 'Demonstrate an incremental solution approach with agile and flexible ability to overcome practical problems', 'Articulate and present recommendations to business partners and influence plans based on insights', 'Partner and engage with associates in other regions to deliver the best services to customers around the globe', 'Work with a customer-centric mindset to deliver high-quality business-driven analytic solutions', 'Drive innovation in approach, method, practices, process, outcome, delivery, or any component of end-to-end problem solving', 'Proactively engage in the external community to build Walmarts brand and learn more about industry practices', 'Promote and support company policies, procedures, mission, values, and standards of ethics and integrity']",True,"['Generative AI', 'Large Language Models', 'Retrieval-Augmented Generation', 'Prompt Engineering', 'LLM Fine-Tuning', 'Managed LLM Gateways', 'AI Model Monitoring and Governance']","Generative AI: Applied for embedding generation, vector database retrieval, and development of LLM-based agents.; Large Language Models: Used in building AI agents with retrieval-augmented generation and fine-tuning for business applications.; Retrieval-Augmented Generation: Implemented to enhance LLM responses by integrating external knowledge bases.; Prompt Engineering: Practiced to iteratively improve LLM accuracy and user feedback in AI model deployment.; LLM Fine-Tuning: Performed to customize large language models for specific business needs and improve performance.; Managed LLM Gateways: Set up and provisioned to facilitate scalable and secure access to large language models.; AI Model Monitoring and Governance: Ensured ongoing performance tracking and compliance of deployed AI models.","['Statistical Models', 'Machine Learning', 'Natural Language Processing', 'Forecasting', 'Optimization Models', 'Graph Machine Learning', 'Causal Inference', 'Experimentation', 'Feature Engineering', 'Data Pipelines', 'SQL and Hive Query Language', 'Python', 'R', 'PySpark', 'Scala', 'Hadoop Ecosystem', 'MapReduce', 'Machine Learning Operations', 'Google Cloud Platform', 'Azure', 'Vertex AI', 'Kubeflow', 'GPU and CUDA', 'Scikit-learn', 'TensorFlow', 'PyTorch']","Statistical Models: Used to develop advanced analytical models for business insights and decision-making.; Machine Learning: Applied to build and deploy predictive models such as classification, regression, and unsupervised learning to solve business problems.; Natural Language Processing: Utilized for text data analysis and modeling as part of machine learning solutions.; Forecasting: Implemented to predict future trends and support inventory and financial planning.; Optimization Models: Used to improve business operations like price optimization, inventory management, and waste reduction.; Graph Machine Learning: Applied to analyze relationships and networks within data for enhanced insights.; Causal Inference: Employed to understand cause-effect relationships in business data for better decision-making.; Experimentation: Used to design and analyze A/B tests and other experiments to validate business hypotheses.; Feature Engineering: Involved in preparing and transforming data features to improve model performance.; Data Pipelines: Built and maintained to process and synthesize large analytics datasets supporting project goals.; SQL and Hive Query Language: Used for querying and managing large datasets in big data platforms like Hadoop.; Python: Primary programming language for data science, model development, and deployment.; R: Used for statistical analysis and data modeling.; PySpark: Utilized for big data processing and analytics on distributed computing platforms.; Scala: Applied in big data environments, especially with Hadoop and Spark ecosystems.; Hadoop Ecosystem: Used as the big data platform for data storage, processing, and analytics.; MapReduce: Employed for distributed data processing within the Hadoop framework.; Machine Learning Operations: Practiced to ensure efficient deployment, monitoring, and maintenance of ML models.; Google Cloud Platform: Cloud infrastructure used for data storage, processing, and model deployment.; Azure: Cloud platform experience for data science and analytics workloads.; Vertex AI: Google Cloud service used for building, deploying, and managing ML models.; Kubeflow: Platform for deploying and managing machine learning workflows on Kubernetes.; GPU and CUDA: Used to accelerate computational efficiency for large-scale data processing and model training.; Scikit-learn: Open-source machine learning library used for building traditional ML models.; TensorFlow: Framework used for building machine learning models, including deep learning.; PyTorch: Deep learning framework used for model development and experimentation."
Ph1NAgFmz4qnW5v0AAAAAA==,Senior Data Analyst / Data Modeler,"About ngrok Inc.

At ngrok, we believe that doing networking the right way should also be the easy way. Over the last 10 years, we've given developers and engineers simple interfaces for getting traffic into their apps and APIs without forcing them to deal with legacy proxies, external load balancers, or VPNs, and we're now part of the standard stack for more than 9 million developers at some of the world's top technology brands, like GitHub, Okta, HashiCorp, and Twilio.

Over the last few years, we've completely changed how that interface looks and works to make it easier, more composable, and infinitely flexible. We now give anyone who needs a ""front door"" to their apps or APIs powerful tools to orchestrate traffic, secure public endpoints, accelerate their services on a global network, observe all traffic passing to/from their network, and much more. The ngrok that millions love and trust has been completely transformed for the better.

About the Role

As we continue transforming how developers orchestrate and secure their networks, we're building out a world-class data team to help us understand usage patterns, optimize product performance, and guide key business decisions with evidence-not assumptions.

We're looking for a Senior Data Analyst/Modeler who will be instrumental in building our data models, defining key metrics, and uncovering insights that guide both product innovation and go-to-market strategies. You'll work closely with cross-functional teams-from engineering and product to marketing and growth-to help us make smarter, faster decisions backed by data. We expect you to become the resident expert on the product and our customers.

This is a remote position for candidates outside of the Bay Area and a hybrid role for candidates within commuting distance to San Francisco. Our Bay Area employees commute to the office on Tuesdays and Wednesdays.
What You'll Do
• Design, implement, and maintain clean, reusable, and scalable data models using dbt for all teams across ngrok, from product to GTM and finance.
• Analyze user behavior, product adoption, and performance across ngrok's core services.
• Partner with Product, Engineering, and GTM teams to define KPIs and deliver actionable insights.
• Create dashboards in Superset and reports to communicate trends and uncover opportunities for optimization.
• Build predictive and diagnostic models to support business planning and user segmentation.
• Help maintain data integrity and drive best practices in data governance and quality.
What We're Looking For
• 7+ years of experience in data analytics, business intelligence, or data science.
• Strong proficiency in SQL and hands-on experience working with business and product teams to build self-service analytics datasets and dashboards.
• Experience working with high volume, high velocity data sets that model complex, real-world systems
• Experience with a data modeling tool such as dbt or SQLMesh and an orchestration tool such as Dagster or Airbyte for managing data pipelines.
• Experience being part of or working with engineering teams and navigating version control (e.g. git), command line tools, and CI
• Strong experience with BI tools (Superset, Looker, Mode, Metabase, or similar).
• Ability to translate complex data into clear, actionable insights.
• Solid communication and collaboration skills-especially in a remote environment.
• Bonus: Background in supporting product-led growth (PLG) or developer-focused SaaS.
Why ngrok?
• Work on a product loved by millions of developers around the world.
• Join a small, high-impact team where your voice matters.
• Flexible work hours and strong async culture.
• Competitive compensation, equity, and benefits.
• A culture that values autonomy, transparency, and deep respect for builders.
Compensation

Tier 1 (SF, LA, Seattle, NYC): Minimum salary of $172,000 to maximum $215,000

Tier 2: Minimum salary of $158,000 to maximum $197,000

Job level and actual compensation will be evaluated based on factors including, but not limited to, qualifications objectively assessed during the interview process (including skills and prior relevant experience, potential impact, and scope of role), internal equity with other team members, market data, and specific work location. We provide an attractive mix of salary and equity.

#LI-Remote

All candidates must be US-based, and legally authorized to work in the United States.

If your experience is close but doesn't fulfill all requirements, please apply. ngrok is on a mission to build a special company. To achieve our goal, we are focused on hiring people with different backgrounds, perspectives, and experiences!
Benefits

Compensation for this role depends on level, but we provide a competitive mix of salary and equity.

We provide a 401(k) with a 100% match up to 3% of your salary and a 50% match up to another 2%.

We provide healthcare, dental, and vision with premiums fully covered on the base plan for employees. Half of premiums are covered for dependents.

We offer unlimited PTO and a culture in which the overwhelming majority of employees take more than four weeks. Your manager is also on the hook for encouraging you to do the same.",,2025-07-25,"['7+ years of experience in data analytics, business intelligence, or data science', 'Strong proficiency in SQL and hands-on experience working with business and product teams to build self-service analytics datasets and dashboards', 'Experience working with high volume, high velocity data sets that model complex, real-world systems', 'Experience with a data modeling tool such as dbt or SQLMesh and an orchestration tool such as Dagster or Airbyte for managing data pipelines', 'Experience being part of or working with engineering teams and navigating version control (e.g. git), command line tools, and CI', 'Strong experience with BI tools (Superset, Looker, Mode, Metabase, or similar)', 'Ability to translate complex data into clear, actionable insights', 'Solid communication and collaboration skills-especially in a remote environment', 'Bonus: Background in supporting product-led growth (PLG) or developer-focused SaaS', 'Job level and actual compensation will be evaluated based on factors including, but not limited to, qualifications objectively assessed during the interview process (including skills and prior relevant experience, potential impact, and scope of role), internal equity with other team members, market data, and specific work location', 'All candidates must be US-based, and legally authorized to work in the United States']","[""You'll work closely with cross-functional teams-from engineering and product to marketing and growth-to help us make smarter, faster decisions backed by data"", 'We expect you to become the resident expert on the product and our customers', 'Design, implement, and maintain clean, reusable, and scalable data models using dbt for all teams across ngrok, from product to GTM and finance', ""Analyze user behavior, product adoption, and performance across ngrok's core services"", 'Partner with Product, Engineering, and GTM teams to define KPIs and deliver actionable insights', 'Create dashboards in Superset and reports to communicate trends and uncover opportunities for optimization', 'Build predictive and diagnostic models to support business planning and user segmentation', 'Help maintain data integrity and drive best practices in data governance and quality']",True,[],,"['SQL', 'Data Modeling', 'Data Pipelines Orchestration', 'Business Intelligence (BI) Tools', 'Predictive and Diagnostic Modeling', 'Data Governance and Quality', 'Version Control and CI']","SQL: Used for querying and managing high volume, high velocity data sets to build self-service analytics datasets and dashboards.; Data Modeling: Designing, implementing, and maintaining clean, reusable, and scalable data models using tools like dbt or SQLMesh to support various teams.; Data Pipelines Orchestration: Managing data workflows and pipelines using orchestration tools such as Dagster or Airbyte to ensure reliable data processing.; Business Intelligence (BI) Tools: Creating dashboards and reports with tools like Superset, Looker, Mode, or Metabase to communicate trends and uncover optimization opportunities.; Predictive and Diagnostic Modeling: Building models to support business planning and user segmentation by analyzing user behavior and product adoption.; Data Governance and Quality: Maintaining data integrity and driving best practices to ensure reliable and accurate data for decision-making.; Version Control and CI: Collaborating with engineering teams using version control systems like git and continuous integration tools to manage data workflows."
Ws41jgUNn9uFXim5AAAAAA==,Data Scientist,"Company Description

Implify, Inc is a Global IT Solutions and services firm. Since it's inception, Implify, Inc has been providing best-quality and cost-effective IT solutions to fortune 1000 companies, mid-range companies and upcoming companies via its onsite, Offshore and in-house service models.

IMPLIFY is an IT consulting services and software development firm dedicated to business success through long-term relationships with our clients and staff. IMPLIFY has built a dynamic, profitable, service-oriented enterprise, and is positioned to successfully respond to trends and changes in the information technology industry.

Job Description

Data Scientist
Location: Newark NJ
Interview process: Phone and In Person (face to face)

Job Descripction
As a Data Scientist, you solve complex challenges and identify new opportunities using a combination of analytical expertise, business acumen, strategic thinking, and project and relationship management skills. This is an exciting opportunity to be a part of a new strategic initiative & this position is located in Newark, N.J., a quick, easy 15-minute train ride from New York Penn Station.

RESPONSIBILITIES
Integrate and mine large data sets, connecting data from disparate sources to identify insights and patterns using predictive and prescriptive analytics, and machine learning techniques
Conduct intermediate and advanced statistical analysis, such as linear regression, ANOVA, time-series analysis, classification models, neural networks, decision trees, as well as analysis of unstructured data (e.g., social media listening, digital footprints, speech analytics)
Prepare and present written and verbal reports, findings, and presentations to key stakeholders, distilling complex statistical information into easy-to-understand business language
Apply knowledge of U.S. businesses and corporate groups and relevant industry knowledge to analysis and insights
Manage project budgets and timelines, ensuring times and on-budget completion
QUALIFICATIONS
Experience analyzing large data sets using statistical software, such as SAS, R, Python, and SPSS, to discover new business insights
Excel and PowerPoint a must. SQL Programming and experience of at least one DBMS such as IBM DB2, Oracle, SQL Server or Sybase are required. Java strongly desired
Prior experience with building models, analyzing unstructured data, and/or machine learning
Relevant academic experience and work experience in Statistics, with exposure to data structures and data visualization
Master's degree in Mathematics, Statistics, Engineering, Computer Science, or a quantitative discipline plus a minimum of 2-3 years of work experience, or bachelor's degree plus 5 years work experience
Well-developed written and oral communication skills, with ability to present and explain data to business manager
Strong project management skills / experience managing projects, budgets, and schedules to successful completion
Some prior exposure to financial services or insurance industry desired

Additional Information

All your information will be kept confidential according to EEO guidelines.",,2025-07-25,"['As a Data Scientist, you solve complex challenges and identify new opportunities using a combination of analytical expertise, business acumen, strategic thinking, and project and relationship management skills', 'Experience analyzing large data sets using statistical software, such as SAS, R, Python, and SPSS, to discover new business insights', 'Excel and PowerPoint a must', 'SQL Programming and experience of at least one DBMS such as IBM DB2, Oracle, SQL Server or Sybase are required', 'Prior experience with building models, analyzing unstructured data, and/or machine learning', 'Relevant academic experience and work experience in Statistics, with exposure to data structures and data visualization', ""Master's degree in Mathematics, Statistics, Engineering, Computer Science, or a quantitative discipline plus a minimum of 2-3 years of work experience, or bachelor's degree plus 5 years work experience"", 'Well-developed written and oral communication skills, with ability to present and explain data to business manager', 'Strong project management skills / experience managing projects, budgets, and schedules to successful completion']","['Integrate and mine large data sets, connecting data from disparate sources to identify insights and patterns using predictive and prescriptive analytics, and machine learning techniques', 'Conduct intermediate and advanced statistical analysis, such as linear regression, ANOVA, time-series analysis, classification models, neural networks, decision trees, as well as analysis of unstructured data (e.g., social media listening, digital footprints, speech analytics)', 'Prepare and present written and verbal reports, findings, and presentations to key stakeholders, distilling complex statistical information into easy-to-understand business language', 'Apply knowledge of U.S. businesses and corporate groups and relevant industry knowledge to analysis and insights', 'Manage project budgets and timelines, ensuring times and on-budget completion']",True,[],,"['Predictive Analytics', 'Prescriptive Analytics', 'Machine Learning', 'Linear Regression', 'ANOVA', 'Time-Series Analysis', 'Classification Models', 'Neural Networks', 'Decision Trees', 'Unstructured Data Analysis', 'Statistical Software (SAS, R, Python, SPSS)', 'SQL Programming', 'Database Management Systems (IBM DB2, Oracle, SQL Server, Sybase)', 'Data Visualization', 'Feature Engineering']","Predictive Analytics: Used to identify insights and patterns from large data sets to forecast future trends and behaviors.; Prescriptive Analytics: Applied to recommend actions based on data analysis to solve complex business challenges.; Machine Learning: Employed to build models that analyze data and improve decision-making processes.; Linear Regression: Used as a statistical method to model relationships between variables for predictive analysis.; ANOVA: Applied for statistical comparison of means across multiple groups to identify significant differences.; Time-Series Analysis: Used to analyze data points collected or recorded at specific time intervals to identify trends and seasonal patterns.; Classification Models: Implemented to categorize data into predefined classes for decision-making.; Neural Networks: Utilized as a machine learning technique to model complex patterns in data, including unstructured data.; Decision Trees: Used for classification and regression tasks to model decisions and their possible consequences.; Unstructured Data Analysis: Involves analyzing data types like social media listening, digital footprints, and speech analytics to extract meaningful insights.; Statistical Software (SAS, R, Python, SPSS): Tools used for data analysis, statistical modeling, and discovering business insights.; SQL Programming: Required for querying and managing data within relational database management systems.; Database Management Systems (IBM DB2, Oracle, SQL Server, Sybase): Experience with these DBMS is necessary for handling and integrating large datasets.; Data Visualization: Used to present complex statistical information in an understandable format for stakeholders.; Feature Engineering: Implied in building models and preparing data for machine learning and statistical analysis."
WforHCgGe6I1LGvvAAAAAA==,Junior Data Scientist,"Role: Junior Data Scientist

About Us: Synergistic IT is a full-service staffing and placement firm servicing client in America for the past 12+ years. We are dedicated towards fulfilling the IT needs of our clients. From staffing to full implementation of projects we provide the highest quality IT Services. We Intend to deliver exceptional student outcome. We don't just help you secure a tech job but build a solid career in technology.

Job description

Roles Responsibilities:

Help extract data from multiple sources and join it together to prepare a datapool for the project.

Analyze and recommend the best strategy to develop a powerful model based in the current data generated by our business.

Optimize the current Model to make it scalable and easily configurable for other projects

Develop the explanations to explain models recommendations to the team.

Be prepared for changes in business direction and understand when to adjust designs.

Skills Required:

Specialist in datasets management

Very fluent in SQL data bases for complex queries.

Able to carry on with data conversion from different sources

Ability to use Microsoft Power BI

Notions of Machine learning algorithms

Problem-solving aptitude

Excellent communication and presentation skills

Education Requirement: -

· Bachelors in Computer Science, Engineering or relevant field; graduate degree in Data Science or another quantitative field is preferred.

Benefits:

· On Job Technical support

· E- verified

· Filing of H1b.

· Full time position

Candidate who are missing the required skills, might be provided an option to enhance their skills, so that they can also apply for the role and can make a career in IT industry.

If you do respond via e-mail, please include a daytime phone number so that we can reach you. In considering candidates, time is of the essence, so please respond ASAP.

Thank you",,2025-07-25,"['Specialist in datasets management', 'Very fluent in SQL data bases for complex queries', 'Able to carry on with data conversion from different sources', 'Ability to use Microsoft Power BI', 'Notions of Machine learning algorithms', 'Problem-solving aptitude', 'Excellent communication and presentation skills', 'Filing of H1b']","['Help extract data from multiple sources and join it together to prepare a datapool for the project', 'Analyze and recommend the best strategy to develop a powerful model based in the current data generated by our business', 'Optimize the current Model to make it scalable and easily configurable for other projects', 'Develop the explanations to explain models recommendations to the team', 'Be prepared for changes in business direction and understand when to adjust designs']",True,[],,"['SQL', 'Data Integration', 'Machine Learning Algorithms', 'Power BI', 'Model Optimization']",SQL: Used for writing complex queries to extract and manage data from databases as required by the role.; Data Integration: Involves extracting data from multiple sources and joining it to prepare a unified datapool for modeling.; Machine Learning Algorithms: Basic knowledge of machine learning methods is needed to develop and optimize predictive models based on business data.; Power BI: Used to create dashboards and visualizations to communicate model recommendations and data insights to the team.; Model Optimization: Improving existing models to be scalable and configurable for different projects within the business context.
HHZH0mYYs6nJHLBrAAAAAA==,"(USA) Principal, Data Scientist","Position Summary...

What you'll do...Position Summary:
Walmart Marketplace is seeking a Principal Scientist with a strong educational background in Data-Science, Mathematics, Statistics, or a related field. With at least 10+ years of industry experience (or 7+ years with a master’s degree), you'll bring extensive knowledge of machine learning, data-science, and statistics to develop innovative products/solutions while applying causal learning and anomaly detection in the ecommerce domain

.Team: Walmart’s Seller Fulfilled Services (SFS) team builds products that connect sellers across the world to buyers enabling access to over 350M+ items, and growing selection. Excellence in the end-to-end shipping and delivery experience is the cornerstone of our promise to our sellers and buyers. We use AI/ML-based products for delivery promise optimization and other touchpoints within the seller and customer journeys, creating a positive experience and impact. We are responsible for providing the best in-class marketplace experience for our sellers and customers through the design, development, and operations of highly scalable systems. We interact with multiple teams within the company to develop scalable, robust technical solutions. This scientist role will be part of the business technology team and will play a key role working along with others program managers, product managers, data scientists, engineers, and business stakeholders to build end-to-end machine learning based predictive products/solutions.
More about Marketplace: https://marketplace.walmart.com/

What you'll do:As a Principal Data Scientist, you'll have the opportunity to:
• Lead the development and deployment of machine learning models across Walmart’s Marketplace but with core focus on offerings which are fulfilled by the sellers themselves. Drawing on your extensive experience, you will work on large-scale data challenges, design innovative algorithms, and collaborate with cross-functional teams to drive measurable business outcomes.
• Lead the end-to-end lifecycle of AI/ML projects, from ideation to deployment, ensuring alignment with Walmart’s Marketplace strategic goals.
• Develop novel algorithms and leverage data science frameworks (e.g., TensorFlow, PyTorch, Sagemaker, etc.) to solve complex problems in promise optimization, abuse detection, return optimization and other business areas.
• Drive data-derived insights across a wide range of retail challenges by developing advanced statistical models, machine learning algorithms and computational algorithms/.
• Direct the gathering of data, assessing data validity and synthesizing data into large analytics datasets to support project goals
• Utilize big data analytics and advanced data science techniques to identify trends, patterns, and discrepancies in data. Determine additional data needed to support insights
• Build and train statistical models and machine learning algorithms, ready for deployment
• Monitor model performance and refine/tune the model parameters to achieve pre-defined outputs at scale. Communicate insights to business partners in WBRs/MBR’s/QBRs, and influence future data-science roadmap.
• Collaborate with teams across business, product, and engineering to understand forward-looking roadmap, and integrate data science solutions seamlessly.
• Advocate for best practices in software development, including continuous integration/continuous deployment, unit testing, and documentation, to ensure robust and reliable systems.
• Mentor junior data scientists and contribute to building a culture of innovation and learning within the data science community at Walmart.
What you'll bring:
• Bachelor’s degree with 10+ years of experience / master’s degree with 7+ years of experience. Educational qualifications should be preferably in Computer Science/ Data Science/ Industrial Engineering/ Mathematics/ Statistics or a related area.
• Proven track record in designing and implementing AI/ML solutions for large-scale, high-performance systems.
• Proven track record of building and maintaining APIs for machine learning or data-driven applications.
• Hands on experience building data-science, machine learning or AI based products/solutions.
• Experience in applying causal learning and anomaly detection in ecommerce domain.
• Experience in machine learning, supervised and unsupervised and deep learning.
• Experience in analyzing complex/ambiguous problems and translating it into data science algorithms/solutions.
• Experience in Python with excellent knowledge of Data Structures
• Experience with big data analytics and platforms (using software like PyTorch, TensorFlor, Hive, Spark)
• Experience with SQL and relational databases, data warehouse.
Preferred Qualifications:
• Masters or Ph.D. in a related discipline.
• 5+ years' experience in e-commerce, Marketplace, or Supply Chain/ Operations optimization.
• Experience with Neural Networks, LLMs, AI is a plus.
• Hands-on experience in network optimization or distributed computing framework like Spark.

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

‎

‎

‎
You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.

‎

For information about PTO, see https://one.walmart.com/notices.

‎

‎
Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

‎
Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

‎

For information about benefits and eligibility, see One.Walmart.

‎
The annual salary range for this position is $143,000.00-$286,000.00

‎
Additional compensation includes annual or quarterly performance bonuses.

‎
Additional compensation for certain positions may also include:

‎

‎
- Stock

‎

‎

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 5 years' experience in an analytics related field. Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 3 years' experience in an analytics related field. Option 3: 7 years' experience in an analytics or related field

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data science, machine learning, optimization models, PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Publications or active peer reviewer in related journals or conference, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.

Primary Location...

840 W California Ave, Sunnyvale, CA 94086-4828, United States of America",2025-07-19T00:00:00.000Z,2025-07-25,"['Walmart Marketplace is seeking a\u202fPrincipal Scientist\u202fwith a\u202fstrong educational background in Data-Science, Mathematics, Statistics, or a related field', ""With at least 10+ years of industry experience (or 7+ years with a master’s degree), you'll bring\u202fextensive knowledge of machine learning, data-science, and statistics\u202fto develop innovative\u202fproducts/solutions while applying causal learning and anomaly detection in the ecommerce domain"", 'Bachelor’s degree with 10+ years of experience / master’s degree with 7+ years of experience.\u202fEducational qualifications should be preferably in\u202fComputer Science/ Data Science/ Industrial Engineering/ Mathematics/ Statistics\u202for a related area', 'Proven track record in designing and implementing AI/ML solutions for large-scale, high-performance systems', 'Proven track record of building and maintaining APIs for machine learning or data-driven applications', 'Hands on experience building\u202fdata-science, machine learning or AI based products/solutions', 'Experience in\u202fapplying causal learning and anomaly detection in ecommerce domain', 'Experience in machine learning, supervised and unsupervised and deep learning', 'Experience in analyzing complex/ambiguous problems and translating it into data science algorithms/solutions', 'Experience in Python with excellent knowledge of Data Structures', 'Experience with big data analytics and platforms (using software like PyTorch, TensorFlor, Hive, Spark)', 'Experience with SQL and relational databases, data warehouse', ""Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 5 years' experience in an analytics related field"", ""Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 3 years' experience in an analytics related field"", ""Option 3: 7 years' experience in an analytics or related field"", 'Data science, machine learning, optimization models, PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Publications or active peer reviewer in related journals or conference, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly', 'The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture']","['.Team:\u202fWalmart’s Seller Fulfilled Services (SFS) team builds products that connect sellers across the world to buyers enabling access to over 350M+ items, and growing selection', 'Excellence in the end-to-end shipping and delivery experience is the cornerstone of our promise to our sellers and buyers', 'We use AI/ML-based products for delivery promise optimization and other touchpoints within the seller and customer journeys, creating a positive experience and impact', 'This scientist role will be part of the business technology team and will play a key role working along with others program managers, product managers, data scientists, engineers, and business stakeholders to build end-to-end machine learning based predictive products/solutions', 'Lead the development and deployment of machine learning models across Walmart’s Marketplace but with core focus on offerings which are fulfilled by the sellers themselves', 'Drawing on your extensive experience, you will work on large-scale data challenges, design innovative algorithms, and collaborate with cross-functional teams to drive measurable business outcomes', 'Lead the end-to-end lifecycle of AI/ML projects, from ideation to deployment, ensuring alignment with Walmart’s Marketplace strategic goals', 'Develop novel algorithms and leverage data science frameworks (e.g., TensorFlow, PyTorch, Sagemaker, etc.)', 'to solve complex problems in promise optimization, abuse detection, return optimization and other business areas', 'Drive data-derived insights across a wide range of retail challenges by developing advanced statistical models, machine learning algorithms and computational algorithms/', 'Direct the gathering of data, assessing data validity and synthesizing data into large analytics datasets to support project goals', 'Utilize big data analytics and advanced data science techniques to identify trends, patterns, and discrepancies in data', 'Determine additional data needed to support insights', 'Build and train statistical models and machine learning algorithms, ready for deployment', 'Monitor model performance and refine/tune the model parameters to achieve pre-defined outputs at scale', 'Communicate insights to business partners in WBRs/MBR’s/QBRs, and influence future data-science roadmap', 'Collaborate with teams across business, product, and engineering to understand forward-looking roadmap, and integrate data science solutions seamlessly', 'Advocate for best practices in software development, including continuous integration/continuous deployment, unit testing, and documentation, to ensure robust and reliable systems', 'Mentor junior data scientists and contribute to building a culture of innovation and learning within the data science community at Walmart']",True,"['Deep Learning', 'Neural Networks', 'Large Language Models', 'AI/ML Lifecycle Management', 'SageMaker']","Deep Learning: Used for building neural network models, including experience with frameworks like TensorFlow and PyTorch.; Neural Networks: Applied in advanced AI/ML solutions for complex problem solving in Walmart Marketplace.; Large Language Models: Experience with LLMs is considered a plus, indicating potential use of modern AI for natural language understanding or generation.; AI/ML Lifecycle Management: Leading end-to-end AI/ML project lifecycle from ideation to deployment, ensuring alignment with strategic goals.; SageMaker: Cloud-based machine learning platform used to develop, train, and deploy ML models at scale.","['Machine Learning', 'Causal Learning', 'Anomaly Detection', 'Statistical Models', 'Big Data Analytics', 'Data Pipelines', 'SQL and Relational Databases', 'Python', 'Spark', 'Hive', 'Scikit-learn', 'Optimization Models']","Machine Learning: Used extensively to develop predictive products and solutions for Walmart Marketplace, including supervised and unsupervised learning methods.; Causal Learning: Applied to understand cause-effect relationships in ecommerce data to improve decision-making and optimize business outcomes.; Anomaly Detection: Used to identify unusual patterns or outliers in ecommerce data, such as abuse detection and return optimization.; Statistical Models: Developed and trained to derive insights and support various retail challenges within Walmart Marketplace.; Big Data Analytics: Utilized to process and analyze large-scale datasets from Walmart’s Marketplace to identify trends and patterns.; Data Pipelines: Built and managed to gather, validate, and synthesize large analytics datasets supporting project goals.; SQL and Relational Databases: Used for querying and managing structured data within data warehouses supporting analytics and modeling.; Python: Primary programming language used for data science, machine learning model development, and algorithm implementation.; Spark: Distributed computing framework employed for big data processing and analytics at scale.; Hive: Used as a data warehouse infrastructure to facilitate querying and managing large datasets.; Scikit-learn: Open-source machine learning library used for building and deploying traditional ML models.; Optimization Models: Applied to improve supply chain, delivery promise, and other operational efficiencies in ecommerce."
wK-RaE65kRZyZKBrAAAAAA==,Lead Data Scientist - Operations Research,"McKesson is an impact-driven, Fortune 10 company that touches virtually every aspect of healthcare. We are known for delivering insights, products, and services that make quality care more accessible and affordable. Here, we focus on the health, happiness, and well-being of you and those we serve - we care.

What you do at McKesson matters. We foster a culture where you can grow, make an impact, and are empowered to bring new ideas. Together, we thrive as we shape the future of health for patients, our communities, and our people. If you want to be part of tomorrow's health today, we want to hear from you.

The Lead Data Scientist, Operations Research role is responsible for architecting and implementing AI/ML, simulation and/or optimization products to enhance the efficiency and effectiveness of McKesson's supply chain operations as part of a McKesson's Supply Chain Operations Research COE.

Our team applies data science methodologies to interdisciplinary business problems across Operations & Supply Chain. This position will primarily work on strategic in-flight use cases around inventory and operating expense management. The position's objectives are:
• Develop stochastic process models and/or optimization models to provide data-driven recommendations to business unit stakeholders
• Lead development and enhancement of enterprise-scale digital twins for network management and control

The candidate should possess the ability to perform statistical modelling techniques and derive business insights that are required to drive analytic innovation at McKesson. The candidate should also be an active learner able to grasp and apply new analytic approaches, as well as mentor junior / developing resources.

Position Description

The purpose of this position is to architect, implement, drive adoption, and measure impact of innovative analytic solutions at McKesson, as well as make significant improvements to existing solutions.

Analytic Responsibilities
• Develop supply chain network design, inventory, and/or transportation cost optimization solutions
• Develop statistical simulation decision frameworks
• Development of AI/ML-based solutions and enhancements where needed in support of simulation and optimization workstreams

Other Responsibilities
• Support stakeholders' analytic needs, gather user requirements, and help drive adoption of developed methodologies
• Cultivate business development opportunities
• Assist in developing and maintaining long-term stakeholder relationships

Education:

Bachelor's degree in technical fields such as Operations Research, Statistics, Computer Science, Applied Mathematics, Engineering or related quantitative majors. Master's and/or PhD preferred.

Minimum Requirements
• A degree or equivalent and typically requires 10+ years of relevant experience. Fewer years required if they have relevant Master's or Doctorate qualifications

Critical Skills
• 7+ years of operations research/data science experience based on a combination of industry and academic experience
• Demonstrated experience with solving enterprise network design, inventory, and/or transportation optimization problems
• Experience with Gurobi, Xpress, CPLEX or open-source solvers (CBC, GLPK)
• Experience with local search techniques and advanced mathematical programming techniques such as column generation and decomposition.
• Knowledge of statistical programming (Python or R)
• Fundamental statistical knowledge (i.e., random variables, probability distributions, confidence intervals, outlier detection)
• Experience with Monte Carlo simulation
• Demonstrated ability in data extraction and wrangling using SQL
• Ability to communicate technical concepts to non-technical audiences

Additional Knowledge & Skills
• Team player
• Strong verbal and written communication
• Proficient with Excel spreadsheets, financial modeling, and reporting
• Knowledge of relational databases (e.g. MS SQL Server, Snowflake, Oracle)
• Knowledge of data warehousing & ETL best practices is a plus
• Knowledge of cloud computing platforms (e.g. Azure, AWS, Databricks) is a plus
• Prior data mining experience using enterprise systems (SAP or JD Edwards preferred) is a plus

Please note that only candidates authorized to work in the US will be considered for this position. Sponsorship is not available.

We are proud to offer a competitive compensation package at McKesson as part of our Total Rewards. This is determined by several factors, including performance, experience and skills, equity, regular job market evaluations, and geographical markets. The pay range shown below is aligned with McKesson's pay philosophy, and pay will always be compliant with any applicable regulations. In addition to base pay, other compensation, such as an annual bonus or long-term incentive opportunities may be offered. For more information regarding benefits at McKesson, please click here.

Our Base Pay Range for this position

$158,000 - $263,300

McKesson is an Equal Opportunity Employer

McKesson provides equal employment opportunities to applicants and employees and is committed to a diverse and inclusive environment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, age or genetic information. For additional information on McKesson's full Equal Employment Opportunity policies, visit our Equal Employment Opportunity page.

Join us at McKesson!",2025-06-25T00:00:00.000Z,2025-07-25,"['The candidate should possess the ability to perform statistical modelling techniques and derive business insights that are required to drive analytic innovation at McKesson', 'The candidate should also be an active learner able to grasp and apply new analytic approaches, as well as mentor junior / developing resources', ""Bachelor's degree in technical fields such as Operations Research, Statistics, Computer Science, Applied Mathematics, Engineering or related quantitative majors"", 'A degree or equivalent and typically requires 10+ years of relevant experience', ""Fewer years required if they have relevant Master's or Doctorate qualifications"", '7+ years of operations research/data science experience based on a combination of industry and academic experience', 'Demonstrated experience with solving enterprise network design, inventory, and/or transportation optimization problems', 'Experience with Gurobi, Xpress, CPLEX or open-source solvers (CBC, GLPK)', 'Experience with local search techniques and advanced mathematical programming techniques such as column generation and decomposition', 'Knowledge of statistical programming (Python or R)', 'Fundamental statistical knowledge (i.e., random variables, probability distributions, confidence intervals, outlier detection)', 'Experience with Monte Carlo simulation', 'Demonstrated ability in data extraction and wrangling using SQL', 'Ability to communicate technical concepts to non-technical audiences', 'Team player', 'Strong verbal and written communication', 'Proficient with Excel spreadsheets, financial modeling, and reporting', 'Knowledge of relational databases (e.g. MS SQL Server, Snowflake, Oracle)']","[""The Lead Data Scientist, Operations Research role is responsible for architecting and implementing AI/ML, simulation and/or optimization products to enhance the efficiency and effectiveness of McKesson's supply chain operations as part of a McKesson's Supply Chain Operations Research COE"", 'Our team applies data science methodologies to interdisciplinary business problems across Operations & Supply Chain', 'This position will primarily work on strategic in-flight use cases around inventory and operating expense management', 'Develop stochastic process models and/or optimization models to provide data-driven recommendations to business unit stakeholders', 'Lead development and enhancement of enterprise-scale digital twins for network management and control', 'The purpose of this position is to architect, implement, drive adoption, and measure impact of innovative analytic solutions at McKesson, as well as make significant improvements to existing solutions', 'Develop supply chain network design, inventory, and/or transportation cost optimization solutions', 'Develop statistical simulation decision frameworks', 'Development of AI/ML-based solutions and enhancements where needed in support of simulation and optimization workstreams', ""Support stakeholders' analytic needs, gather user requirements, and help drive adoption of developed methodologies"", 'Cultivate business development opportunities', 'Assist in developing and maintaining long-term stakeholder relationships']",True,[],,"['Operations Research', 'Stochastic Process Models', 'Optimization Models', 'Digital Twins', 'Statistical Modelling', 'Monte Carlo Simulation', 'AI/ML (Machine Learning)', 'Mathematical Programming Techniques', 'Local Search Techniques', 'Gurobi', 'Xpress', 'CPLEX', 'Open-Source Solvers', 'Python', 'R', 'SQL', 'Relational Databases', 'Data Warehousing & ETL', 'Cloud Computing Platforms', 'Excel']","Operations Research: Used to develop optimization and simulation models to improve supply chain efficiency and decision-making.; Stochastic Process Models: Applied to model uncertainty and variability in supply chain operations for data-driven recommendations.; Optimization Models: Developed to solve network design, inventory, and transportation cost problems in supply chain management.; Digital Twins: Enterprise-scale digital replicas of supply chain networks used for management and control.; Statistical Modelling: Used to derive business insights and support analytic innovation through techniques like probability distributions and confidence intervals.; Monte Carlo Simulation: Employed to create statistical simulation decision frameworks for supply chain scenarios.; AI/ML (Machine Learning): Implemented to enhance simulation and optimization products within supply chain operations.; Mathematical Programming Techniques: Includes advanced methods such as column generation and decomposition for solving complex optimization problems.; Local Search Techniques: Used as heuristic methods to improve optimization solutions in supply chain problems.; Gurobi: A commercial solver used for mathematical optimization in supply chain models.; Xpress: An optimization solver applied to solve enterprise network design and inventory problems.; CPLEX: A solver used for linear and integer optimization in supply chain operations.; Open-Source Solvers: Includes CBC and GLPK, used for solving optimization problems in supply chain contexts.; Python: Used for statistical programming and data science tasks including data extraction and modeling.; R: Employed for statistical analysis and modeling in supply chain analytics.; SQL: Used for data extraction and wrangling from relational databases to support analytics.; Relational Databases: Includes MS SQL Server, Snowflake, and Oracle, used to store and manage supply chain data.; Data Warehousing & ETL: Best practices for managing and transforming large-scale supply chain data.; Cloud Computing Platforms: Platforms like Azure, AWS, and Databricks used to support scalable data processing and analytics.; Excel: Used for financial modeling, reporting, and data analysis in supply chain operations."
3NVf2GeHN199af05AAAAAA==,"Data Scientist, Marketing","Benefits Start Day 1 for Full-Time Colleagues - No Waiting Period!

For more information about our benefits, see below!

We are proud to be a member of the Rentokil family of companies, the global leader in Pest Control and other services across more than 90 countries. We pride ourselves on being a trusted partner to many of the world's leading brands and serve consumer and business customers across multiple industries. We are extremely proud of our legacy of excellence and constantly work to fulfill our mission to ""protect people, enhance lives, and preserve the planet.""

NO SPONSORSHIP OR OPT AVAILABLE

This role will be responsible to apply their analytical and technical skills to solve real-world business problems. The Data Scientist will work closely with stakeholders to collect, clean, analyze, and interpret data, and contribute to the development and deployment of ML models and data-driven solutions. This role requires a strong foundation in statistical analysis, machine learning concepts, and programming, along with a passion for learning and exploring data.

Duties & Responsibilities
• Assist in the collection, cleaning, and preprocessing of large and complex datasets from various sources.
• Conduct exploratory data analysis (EDA) to identify patterns, trends, and insights in the data.
• Apply statistical techniques and machine learning algorithms to build predictive models, perform classification, clustering, and other data analysis tasks.
• Development and validation of machine learning models (Supervised and Unsupervised), and other categories such as Ensemble Methods, and Time-series models.
• Collaborate with other data scientists and other team members to define project requirements and objectives.
• Communicate findings and insights effectively through visualizations, reports, and presentations.
• Stay up-to-date with the latest advancements in data science, machine learning, and related technologies.
• Document code, methodologies, and results clearly and concisely.
• Participate in the deployment and monitoring of data science models and solutions.
• Contribute to the development of data-driven products and features.
• Assist in the evaluation of new data sources and technologies.
• Independently plan and execute work across multiple projects, stakeholders, and functional areas

Candidate Requirements

Education
• Bachelor's or Master's degree in a quantitative field such as Data Science, Statistics, Mathematics, Computer Science, Engineering, Economics, or a related discipline.

Experience
• 3+ years of relevant experience in data analysis, statistical modeling, or machine learning.
• Strong understanding of statistical concepts, probability theory, and experimental design.
• Familiarity with machine learning algorithms (e.g., regression, classification, clustering, dimensionality reduction).
• Proficiency in at least one programming language commonly used in data science (e.g., Python, R).
• Experience with data manipulation and analysis libraries (e.g., Pandas, NumPy, SciPy in Python; dplyr, tidyr in R).
• Familiarity with data visualization libraries (e.g., Matplotlib, Seaborn, Plotly in Python; ggplot2 in R).
• Basic understanding of database concepts and SQL.
• Strong analytical and problem-solving skills with the ability to work with imperfect data.
• Excellent written and verbal communication skills, with the ability to explain technical concepts to non-technical audiences.
• Ability to work independently and collaboratively within a team environment.
• A strong desire to learn and grow in the field of data science.
• Experience with cloud computing platforms (e.g., AWS, Azure, GCP). (preferred)
• Familiarity with big data technologies (e.g., Spark, Hadoop). (preferred)
• Experience with version control systems (e.g., Git). (preferred)
• Knowledge of specific industry domains relevant to the company. (preferred)
• Experience with deploying machine learning models into production. (preferred)

Physical Demands and Working Conditions

The physical demands are representative of those that must be met by an employee to perform the essential function to this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

Incumbent must be prepared to:
• Move up to 10 pounds occasionally, by lifting, carrying, pushing, pulling, or otherwise repositioning objects.
• Sitting for long periods of time while using office equipment such as computers, phones and etc.
• Performing repetitive motions involving the wrists, hands, and fingers, such as typing, picking, and pinching, within your regular work environment.
• Express or exchange ideas with others through the use of spoken word, quickly, accurately, and at an easily audible volume, and receive detailed information through oral communication at usual speaking levels without correction, and/or make fine discriminations in the nature of sounds in the environment.

Incumbent is required to have:
• Near-range visual acuity for detailed tasks and ability to perform activities with precision such as analyzing data, viewing computer screens or reading extensively.

Incumbent will be subject to:
• Inside working conditions: The change of building environment such as with or without air conditioning and heating.

Annual Earning Potential: $102,000 - $132,600 / year .
While starting pay falls within the given range, it can vary based on factors like geographic location, skills, education, and experience. Total earnings may also be affected by overtime, incentives, commissions, performance, and route assignment (where applicable).

Why Choose Us?

A career with the Rentokil family of companies can be a professional trajectory filled with opportunity. We pride ourselves on being a world-class team that rewards high performance, and we love to promote from within. We offer competitive pay and many of our roles offer performance incentives.

Below you'll find information about some of what we have to offer. All Full-Time Colleagues qualify for the following and Part-Time Colleagues qualify for most benefits after they meet certain criteria.

Click here to read more about our Total Rewards Program which includes:

Professional and Personal Growth
• Multiple avenues to grow your career
• Training and development programs available
• Tuition Reimbursement benefits (for FT Colleagues)

Health and Wellness
• Health benefits including Medical, Dental, Vision, Disability, and Life Insurance plus much more
• Full-time colleagues are eligible to begin enrollment immediately upon hire with benefits starting on day 1

Savings and Retirement
• 401(k) retirement plan with company-matching contributions

Work-Life Balance
• Vacation days & sick days
• Company-paid holidays & floating holidays
• A company mindset that prioritizes health, safety, and flexibility

We are looking for individuals who want to make a difference where our customers live and work. Is that you?

This company is a Drug Free workplace.

Rentokil is committed to complying with all Federal, State, and local laws related to the employment of qualified individuals with disabilities.

Know Your Rights - Workplace Discrimination is Illegal

Pay Transparency - Nondiscrimination Provision

California residents click here to review your privacy rights.

It is unlawful in Massachusetts to require or administer a lie detector test as a condition of employment or continued employment. An employer who violates this law shall be subject to criminal penalties and civil liability.

By applying to this job, you agree to receive initial texts from systems used on behalf of Rentokil North America, Inc., possibly including Workday, Loop, and HireVue. These systems utilize text messages to communicate with you throughout the application, interview, and pre-hire processes. You can set your communication preferences or opt out of text messages from each system at any time following the initial message. Message and data rates may apply.",,2025-07-25,"[""Bachelor's or Master's degree in a quantitative field such as Data Science, Statistics, Mathematics, Computer Science, Engineering, Economics, or a related discipline"", '3+ years of relevant experience in data analysis, statistical modeling, or machine learning', 'Strong understanding of statistical concepts, probability theory, and experimental design', 'Familiarity with machine learning algorithms (e.g., regression, classification, clustering, dimensionality reduction)', 'Proficiency in at least one programming language commonly used in data science (e.g., Python, R)', 'Experience with data manipulation and analysis libraries (e.g., Pandas, NumPy, SciPy in Python; dplyr, tidyr in R)', 'Familiarity with data visualization libraries (e.g., Matplotlib, Seaborn, Plotly in Python; ggplot2 in R)', 'Basic understanding of database concepts and SQL', 'Strong analytical and problem-solving skills with the ability to work with imperfect data', 'Excellent written and verbal communication skills, with the ability to explain technical concepts to non-technical audiences', 'Ability to work independently and collaboratively within a team environment', 'A strong desire to learn and grow in the field of data science', 'Experience with cloud computing platforms (e.g., AWS, Azure, GCP)', 'Sitting for long periods of time while using office equipment such as computers, phones and etc', 'Performing repetitive motions involving the wrists, hands, and fingers, such as typing, picking, and pinching, within your regular work environment', 'Express or exchange ideas with others through the use of spoken word, quickly, accurately, and at an easily audible volume, and receive detailed information through oral communication at usual speaking levels without correction, and/or make fine discriminations in the nature of sounds in the environment', 'Near-range visual acuity for detailed tasks and ability to perform activities with precision such as analyzing data, viewing computer screens or reading extensively']","['This role will be responsible to apply their analytical and technical skills to solve real-world business problems', 'The Data Scientist will work closely with stakeholders to collect, clean, analyze, and interpret data, and contribute to the development and deployment of ML models and data-driven solutions', 'This role requires a strong foundation in statistical analysis, machine learning concepts, and programming, along with a passion for learning and exploring data', 'Assist in the collection, cleaning, and preprocessing of large and complex datasets from various sources', 'Conduct exploratory data analysis (EDA) to identify patterns, trends, and insights in the data', 'Apply statistical techniques and machine learning algorithms to build predictive models, perform classification, clustering, and other data analysis tasks', 'Development and validation of machine learning models (Supervised and Unsupervised), and other categories such as Ensemble Methods, and Time-series models', 'Collaborate with other data scientists and other team members to define project requirements and objectives', 'Communicate findings and insights effectively through visualizations, reports, and presentations', 'Stay up-to-date with the latest advancements in data science, machine learning, and related technologies', 'Document code, methodologies, and results clearly and concisely', 'Participate in the deployment and monitoring of data science models and solutions', 'Contribute to the development of data-driven products and features', 'Assist in the evaluation of new data sources and technologies', 'Independently plan and execute work across multiple projects, stakeholders, and functional areas', 'The physical demands are representative of those that must be met by an employee to perform the essential function to this job', 'Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions', 'Move up to 10 pounds occasionally, by lifting, carrying, pushing, pulling, or otherwise repositioning objects', 'Inside working conditions: The change of building environment such as with or without air conditioning and heating']",True,[],,"['Exploratory Data Analysis', 'Statistical Analysis', 'Machine Learning Algorithms', 'Regression', 'Classification', 'Clustering', 'Dimensionality Reduction', 'Ensemble Methods', 'Time-Series Models', 'Python', 'R', 'Pandas', 'NumPy', 'SciPy', 'dplyr', 'tidyr', 'Matplotlib', 'Seaborn', 'Plotly', 'ggplot2', 'SQL', 'Cloud Computing Platforms', 'Big Data Technologies', 'Version Control Systems', 'Model Deployment and Monitoring']","Exploratory Data Analysis: Used to identify patterns, trends, and insights in large and complex datasets as part of the data scientist's analysis process.; Statistical Analysis: Applied to interpret data and support the development of predictive models and data-driven solutions.; Machine Learning Algorithms: Used to build predictive models including supervised and unsupervised learning, classification, clustering, ensemble methods, and time-series models.; Regression: A machine learning algorithm mentioned as part of the predictive modeling techniques used in the role.; Classification: A supervised learning technique applied to categorize data as part of model development.; Clustering: An unsupervised learning method used to group data points based on similarity.; Dimensionality Reduction: Used to reduce the number of variables under consideration in data preprocessing and modeling.; Ensemble Methods: Applied to improve model performance by combining multiple machine learning models.; Time-Series Models: Used for analyzing and forecasting data points collected or sequenced over time.; Python: A primary programming language used for data manipulation, analysis, and machine learning model development.; R: An alternative programming language used for statistical analysis and data science tasks.; Pandas: A Python library used for data manipulation and analysis.; NumPy: A Python library used for numerical computing and handling large arrays.; SciPy: A Python library used for scientific and technical computing.; dplyr: An R package used for data manipulation.; tidyr: An R package used for data tidying and reshaping.; Matplotlib: A Python library used for creating static, animated, and interactive visualizations.; Seaborn: A Python visualization library based on Matplotlib, used for statistical graphics.; Plotly: A Python library used for interactive data visualization.; ggplot2: An R package used for data visualization based on the grammar of graphics.; SQL: Used for querying and managing relational databases as part of data extraction and manipulation.; Cloud Computing Platforms: Platforms like AWS, Azure, and GCP are used to support data storage, processing, and deployment of machine learning models.; Big Data Technologies: Technologies such as Spark and Hadoop are used to handle and process large-scale datasets.; Version Control Systems: Tools like Git are used to manage code versions and collaboration in data science projects.; Model Deployment and Monitoring: Involves deploying machine learning models into production and monitoring their performance."
j6OnCVQhiKTpop8TAAAAAA==,People Tech - System Architect-Data Science Senior Manager,"Industry/Sector
Not Applicable

Specialism
Data Science

Management Level
Senior Manager

Job Description & Summary
At PwC, our people in data and analytics engineering focus on leveraging advanced technologies and techniques to design and develop robust data solutions for clients. They play a crucial role in transforming raw data into actionable insights, enabling informed decision-making and driving business growth.

Those in data science and machine learning engineering at PwC will focus on leveraging advanced analytics and machine learning techniques to extract insights from large datasets and drive data-driven decision making. You will work on developing predictive models, conducting statistical analysis, and creating data visualisations to solve complex business problems.

Growing as a strategic advisor, you leverage your influence, expertise, and network to deliver quality results. You motivate and coach others, coming together to solve complex problems. As you increase in autonomy, you apply sound judgment, recognising when to take action and when to escalate. You are expected to solve through complexity, ask thoughtful questions, and clearly communicate how things fit together. Your ability to develop and sustain high performing, diverse, and inclusive teams, and your commitment to excellence, contributes to the success of our Firm.

Examples of the skills, knowledge, and experiences you need to lead and deliver value at this level include but are not limited to:
• Craft and convey clear, impactful and engaging messages that tell a holistic story.
• Apply systems thinking to identify underlying problems and/or opportunities.
• Validate outcomes with clients, share alternative perspectives, and act on client feedback.
• Direct the team through complexity, demonstrating composure through ambiguous, challenging and uncertain situations.
• Deepen and evolve your expertise with a focus on staying relevant.
• Initiate open and honest coaching conversations at all levels.
• Make difficult decisions and take action to resolve issues hindering team effectiveness.
• Model and reinforce professional and technical standards (e.g. refer to specific PwC tax and audit guidance), the Firm's code of conduct, and independence requirements.

The Opportunity
As part of the Data Platform's Data Solution team you are expected to work closely with leaders across product functions to design the analytics roadmap and to support and implement top quality data driven decisions and deliverables. As a Senior Manager you are expected to lead large projects, innovate processes, and maintain operational excellence while interacting with clients at a senior level to drive project success. You are expected to develop and implement quality controls and standards to confirm data integrity and quality.

Responsibilities
- Design the analytics roadmap in collaboration with leaders
- Support and implement data-driven decisions
- Lead large projects confirming operational excellence
- Interact with clients at a strategic level to drive success
- Develop and implement quality controls for data integrity
- Innovate processes to enhance data quality
- Deliver top-quality data solutions
- Foster relationships with product function leaders

What You Must Have
- High School Diploma
- 6 years of progressive roles managing IT architecture and engineering designs and domains

What Sets You Apart
- Bachelor's Degree in Information Technology, Computer Systems Analysis, Management Information Systems, Computer Applications, Computer Engineering, Computer Programming preferred
- Building relationships with clients and developing requests for information
- Prioritizing and handling multiple tasks
- Coaching and collaborating with colleagues
- Understanding application of analytical techniques
- Selecting necessary analytical techniques
- Designing analytics roadmap and supporting data-driven decisions
- Implementing quality controls and standards
- Programming with Python and Java

Travel Requirements
Up to 20%

Job Posting End Date

Learn more about how we work: https://pwc.to/how-we-work

PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.

As PwC is anequal opportunity employer, all qualified applicants will receive consideration for employment at PwC without regard to race; color; religion; national origin; sex (including pregnancy, sexual orientation, and gender identity); age; disability; genetic information (including family medical history); veteran, marital, or citizenship status; or, any other status protected by law.

For only those qualified applicants that are impacted by the Los Angeles County Fair Chance Ordinance for Employers, the Los Angeles' Fair Chance Initiative for Hiring Ordinance, the San Francisco Fair Chance Ordinance, San Diego County Fair Chance Ordinance, and the California Fair Chance Act, where applicable, arrest or conviction records will be considered for Employment in accordance with these laws. At PwC, we recognize that conviction records may have a direct, adverse, and negative relationship to responsibilities such as accessing sensitive company or customer information, handling proprietary assets, or collaborating closely with team members. We evaluate these factors thoughtfully to establish a secure and trusted workplace for all.

Applications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https://pwc.to/us-application-deadlines

The salary range for this position is: $91,000 - $321,500, plus individuals may be eligible for an annual discretionary bonus. For roles that are based in Maryland, this is the listed salary range for this position. Actual compensation within the range will be dependent upon the individual's skills, experience, qualifications and location, and applicable employment laws. PwC offers a wide range of benefits, including medical, dental, vision, 401k, holiday pay, vacation, personal and family sick leave, and more. To view our benefits at a glance, please visit the following link: https://pwc.to/benefits-at-a-glance",2025-07-16T00:00:00.000Z,2025-07-25,"['Your ability to develop and sustain high performing, diverse, and inclusive teams, and your commitment to excellence, contributes to the success of our Firm', 'Craft and convey clear, impactful and engaging messages that tell a holistic story', 'Deepen and evolve your expertise with a focus on staying relevant', 'High School Diploma', '6 years of progressive roles managing IT architecture and engineering designs and domains', 'Building relationships with clients and developing requests for information', 'Prioritizing and handling multiple tasks', 'Coaching and collaborating with colleagues', 'Understanding application of analytical techniques', 'Selecting necessary analytical techniques', 'Designing analytics roadmap and supporting data-driven decisions', 'Programming with Python and Java', 'Travel Requirements']","['They play a crucial role in transforming raw data into actionable insights, enabling informed decision-making and driving business growth', 'Those in data science and machine learning engineering at PwC will focus on leveraging advanced analytics and machine learning techniques to extract insights from large datasets and drive data-driven decision making', 'You will work on developing predictive models, conducting statistical analysis, and creating data visualisations to solve complex business problems', 'Growing as a strategic advisor, you leverage your influence, expertise, and network to deliver quality results', 'You motivate and coach others, coming together to solve complex problems', 'As you increase in autonomy, you apply sound judgment, recognising when to take action and when to escalate', 'You are expected to solve through complexity, ask thoughtful questions, and clearly communicate how things fit together', 'Apply systems thinking to identify underlying problems and/or opportunities', 'Validate outcomes with clients, share alternative perspectives, and act on client feedback', 'Direct the team through complexity, demonstrating composure through ambiguous, challenging and uncertain situations', 'Initiate open and honest coaching conversations at all levels', 'Make difficult decisions and take action to resolve issues hindering team effectiveness', ""Model and reinforce professional and technical standards (e.g. refer to specific PwC tax and audit guidance), the Firm's code of conduct, and independence requirements"", ""As part of the Data Platform's Data Solution team you are expected to work closely with leaders across product functions to design the analytics roadmap and to support and implement top quality data driven decisions and deliverables"", 'As a Senior Manager you are expected to lead large projects, innovate processes, and maintain operational excellence while interacting with clients at a senior level to drive project success', 'You are expected to develop and implement quality controls and standards to confirm data integrity and quality', 'Design the analytics roadmap in collaboration with leaders', 'Support and implement data-driven decisions', 'Lead large projects confirming operational excellence', 'Interact with clients at a strategic level to drive success', 'Develop and implement quality controls for data integrity', 'Innovate processes to enhance data quality', 'Deliver top-quality data solutions', 'Foster relationships with product function leaders', 'Implementing quality controls and standards']",True,[],,"['Predictive Modeling', 'Statistical Analysis', 'Data Visualization', 'Machine Learning', 'Advanced Analytics', 'Data Quality Controls', 'Analytics Roadmap Design', 'Python Programming', 'Java Programming']","Predictive Modeling: Used to develop models that forecast outcomes from large datasets to support data-driven decision making.; Statistical Analysis: Applied to analyze data and extract insights for solving complex business problems.; Data Visualization: Creating visual representations of data to communicate insights effectively.; Machine Learning: Leveraged to extract insights from data and build models that support business growth.; Advanced Analytics: Utilized to perform sophisticated data analysis and support strategic decision making.; Data Quality Controls: Implemented to ensure data integrity and maintain high standards in data solutions.; Analytics Roadmap Design: Collaborating with leaders to plan and guide analytics initiatives and data-driven strategies.; Python Programming: Used for data analysis, model development, and engineering data solutions.; Java Programming: Applied in programming tasks related to data engineering and system architecture."
2M3Q5hJ8jDS_BFwMAAAAAA==,Staff Data Scientist - Damages,"A Day in the Life:

At Hertz, we are at the forefront of innovation, leveraging cutting-edge technologies to build the best damage management technologies in the transportation industry. We want the brightest AI & ML minds to join our Damage Science Team to help us develop and/or maintain capabilities to:
• Detect Damage via Machine Vision: Utilize computer vision techniques to accurately detect and assess damage in real-time.
• Rationalize Repair Estimates and Invoices with Large Language Models (LLMs): Implement sophisticated LLMs to make intelligent repair routing decisions, ensuring repairs are conducted efficiently and cost-effectively.
• Forecast Repair Needs: Develop models to predict future repair & maintenance needs based on historical data and trends.
• Automate Quality Assurance: Create models to evaluate the quality of repairs and ensure they meet our high standards.

We anticipate the salary to start around 160K; commensurate with experience.

What You Will Do:
• Formulate the strategic and tactical steps to carry out the model development lifecycle end-to-end (i.e. problem statement definition, exploratory data analysis, feature engineering, model development / tuning, and model implementation).
• Build and maintain descriptive, predictive, and prescriptive models to measure the performance of the new products and services.
• Cross validating production models to ensure high performance and generalizability
• Define and implement best practices to generate accurate analytics, reports, visualizations, and dashboards to explain results simply and succinctly to technical, non-technical, and senior management
• Build partnerships and work cross-functionally to identify use cases and opportunities to enhance operational efficiency and drive business value through positive impact on OKRs.
• Work with an owner mentality to drive business impact even if that means supporting pipeline creation or decision support analytics.
• Serve as a voice on how technological advancements in AI and machine learning may impact our business and the opportunities they may create.
• Provide technical leadership to more junior Data Scientist team members.

What We are Looking For:
• 5-8 years hands-on experience in a data science role
• 5+ years of data querying languages (e.g. SQL) and scripting languages (e.g. Python)
• 5+ years of end-to-end machine learning model development experience (e.g. problem statement definition, exploratory data analysis, feature engineering, model development / tuning, and deployment)
• Demonstrated experience using machine learning to drive a business impact
• Strong experience with statistical analysis, statistical modeling, and machine learning techniques
• Experience mentoring and supporting development of more junior scientists
• Experience in a ML or data scientist role with a technology company
• Master's degree in a quantitative field such as statistics, mathematics, data science, economics, or computer science
• Preferred PhD in a quantitative field such as statistics, mathematics, data science, economics, or computer science

What You'll Get:
• Up to 40% off any standard Hertz Rental
• Paid Time Off
• Medical, Dental & Vision plan options
• Retirement programs, including 401(k) employer matching
• Paid Parental Leave & Adoption Assistance
• Employee Assistance Program for employees & family
• Educational Reimbursement & Discounts
• Voluntary Insurance Programs - Pet, Legal/Identity Theft, Critical Illness
• Perks & Discounts -Theme Park Tickets, Gym Discounts & more
The Hertz Corporation operates the Hertz, Dollar Car Rental, Thrifty Car Rental brands in approximately 9,700 corporate and franchisee locations throughout North America, Europe, The Caribbean, Latin America, Africa, the Middle East, Asia, Australia and New Zealand. The Hertz Corporation is one of the largest worldwide airport general use vehicle rental companies, and the Hertz brand is one of the most recognized in the world.
US EEO STATEMENT At Hertz, we champion and celebrate a culture of diversity and inclusion. We take affirmative steps to promote employment and advancement opportunities. The endless variety of perspectives, experiences, skills and talents that our employees invest in their work every day represent a significant part of our culture - and our success and reputation as a company.
Individuals are encouraged to apply for positions because of the characteristics that make them unique.
EOE, including disability/veteran",,2025-07-25,"['5-8 years hands-on experience in a data science role', '5+ years of data querying languages (e.g. SQL) and scripting languages (e.g. Python)', '5+ years of end-to-end machine learning model development experience (e.g. problem statement definition, exploratory data analysis, feature engineering, model development / tuning, and deployment)', 'Demonstrated experience using machine learning to drive a business impact', 'Strong experience with statistical analysis, statistical modeling, and machine learning techniques', 'Experience mentoring and supporting development of more junior scientists', 'Experience in a ML or data scientist role with a technology company', ""Master's degree in a quantitative field such as statistics, mathematics, data science, economics, or computer science""]","['Detect Damage via Machine Vision: Utilize computer vision techniques to accurately detect and assess damage in real-time', 'Rationalize Repair Estimates and Invoices with Large Language Models (LLMs): Implement sophisticated LLMs to make intelligent repair routing decisions, ensuring repairs are conducted efficiently and cost-effectively', 'Forecast Repair Needs: Develop models to predict future repair & maintenance needs based on historical data and trends', 'Automate Quality Assurance: Create models to evaluate the quality of repairs and ensure they meet our high standards', 'Formulate the strategic and tactical steps to carry out the model development lifecycle end-to-end (i.e. problem statement definition, exploratory data analysis, feature engineering, model development / tuning, and model implementation)', 'Build and maintain descriptive, predictive, and prescriptive models to measure the performance of the new products and services', 'Cross validating production models to ensure high performance and generalizability', 'Define and implement best practices to generate accurate analytics, reports, visualizations, and dashboards to explain results simply and succinctly to technical, non-technical, and senior management', 'Build partnerships and work cross-functionally to identify use cases and opportunities to enhance operational efficiency and drive business value through positive impact on OKRs', 'Work with an owner mentality to drive business impact even if that means supporting pipeline creation or decision support analytics', 'Serve as a voice on how technological advancements in AI and machine learning may impact our business and the opportunities they may create', 'Provide technical leadership to more junior Data Scientist team members']",True,['Large Language Models'],Large Language Models: Implemented to enhance repair routing decisions by leveraging advanced AI language understanding.,"['Machine Vision', 'Large Language Models', 'Predictive Modeling', 'Quality Assurance Modeling', 'Model Development Lifecycle', 'Descriptive, Predictive, and Prescriptive Models', 'Cross Validation', 'Statistical Analysis and Modeling', 'SQL', 'Python', 'Data Visualization and Dashboards']","Machine Vision: Used to detect and assess vehicle damage in real-time through computer vision techniques.; Large Language Models: Applied to rationalize repair estimates and invoices by making intelligent repair routing decisions.; Predictive Modeling: Developed to forecast future repair and maintenance needs based on historical data and trends.; Quality Assurance Modeling: Created models to evaluate the quality of repairs ensuring they meet company standards.; Model Development Lifecycle: Involves problem definition, exploratory data analysis, feature engineering, model development, tuning, and deployment.; Descriptive, Predictive, and Prescriptive Models: Built and maintained to measure performance of new products and services.; Cross Validation: Used to ensure high performance and generalizability of production models.; Statistical Analysis and Modeling: Applied to analyze data and build robust machine learning models.; SQL: Used for data querying to support data science workflows.; Python: Used as a scripting language for data analysis, model development, and automation.; Data Visualization and Dashboards: Created to explain analytics results clearly to technical and non-technical stakeholders."
adtj_7QRa5DaMfKcAAAAAA==,"Principal, Data Scientist - Converse","Position Summary...

What you'll do...

We are looking for an experiencedPrincipal Data Scientist to join our emerging tech team. At Walmart Global Tech, we are leading the way in revolutionizing retail throughadvanced technology and data science. Our team of experts is committed to solving current supply chain challenges and conducting research and development to create models thataddress the future requirements of our complex omni-channel international business.

About Team:
Cortex Team is Walmarts core A.I. conversational platform, powering the vision of delivering the worlds best personal assistants to Walmarts customers, accessible via natural voice commands, text messages, rich UI interactions, and a mix of all of the above via multi-modal experiences. We believe /conversations/ are a natural and powerful user interface for interacting with technology and enable a richer customer experience -- both online and in-store. We are building and designing the next generation of Natural Language Understanding (NLU) services that other teams can easily integrate and leverage, and build rich experiences: from pure voice and text shopping assistants (Siri, [[https://tech.walmart.com/content/walmart-global-tech/en_us/blog/post/walmart-is-building-a-genai-powered-shopping-assistant.html][Sparky]]), to customer care channels, to mobile apps with rich, intertwined, multi-modal interaction modes ([[https://apps.apple.com/us/app/me-walmart/id1459898418][Me@Walmart]]).

Whatyou'lldo:

We need passionate and seasoned NLP data-scientists to help us improve and evolve our capabilities, considering the full conversational context, multi-modal interactions, and an ever-increasing list of use cases. Come at the right time, and you will have an enormous opportunity to make a massive impact on the design, architecture, and implementation of an innovative, mission critical product, driven by data-science, used every day, by people you know, and which customers love. As part of the emerging tech group, you will also have the additional opportunity of building demos, proof of concepts, creating white papers, writing blogs, etc.

Whatyou'llbring:
• Proficient in Python; solid knowledge of SQL
• Hands on experience with classical ML models, test/train/evaluation metrics, key parameters/techniques that affect model performance
• Understanding of relevant statistical measures such as confidence intervals, significance of error measurements, development and evaluation data sets
• Familiar with NLU/NLP, more recent deep ML models (e.g., Transformers, BERT, Llama, Gpts, Gemini) including safe fine-tuning of these
• Ability to communicate with model consumers and present results intuitively
• Experience in identifying patterns, conducting error/ deviation analysis, and optimizing data representation
• Bachelors degree or certification in Machine Learning, Computer Science, Engineering, Mathematics, Statistics or any other related field

Preferred Qualifications:
• Exposure to real-world, production grade agentic systems
• Familiarity with LLMs serving optimizations and multi-Lo Ra
• Ability to develop experimental and analytic plans for data modeling processes, use of strong baselines, ability to accurately determine cause and effect relations
• Strong attention to detail and exceptional organizational skills
• Proven ability to achieve results in a fast paced, highly collaborative and dynamic work environment
• Hands-on expertise across the full model lifecycle, including data pipelines, extraction, model training, model serving, labeling tools, ML-ops and ad-hoc tooling.
• Ph D in a relevant field (Machine Learning, Computer Science, Engineering, Mathematics, Physics, Statistics or a related field)

About Walmart Global Tech

Imagine working where one line of code can make life easier for hundreds of millions of people. Thats what we do at Walmart Global Tech. Were a team of software engineers, data scientists, cybersecurity experts and service professionals within the worlds leading retailer who make epic impact and are leading the next retail disruption. People are why we innovate, and people power our innovations.

Who We Are:

Join Walmart and your work could help approximately 220 million global customers live better every week. Yes, we are the Fortune #1 company. But you'll quickly find were a company who wants you to feel comfortable bringing your whole self to work. Our mission spreads far beyond the walls of our stores. Here at the worlds leading retailer, you can make career defining accomplishments, learn new skills, gain experience from virtually every industry and leverage your expertise to innovate at scale, impact millions and reimagine the future of retail. Discover why we are a world leader in technology, culture of belonging, sustainability and community involvement. careers.walmart.com.

Equal Opportunity Employer:

Walmart, Inc. is an Equal Opportunity Employer By Choice. We believe we are best equipped to help our associates, customers, and the communities we serve live better when we really know them. That means understanding, respecting, and valuing unique styles, experiences, identities, ideas, and opinions while being welcoming of all people.

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

‎

‎

‎
You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.

‎

For information about PTO, see https://one.walmart.com/notices.

‎

‎
Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

‎
Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

‎

For information about benefits and eligibility, see One.Walmart.

‎
The annual salary range for this position is $143,000.00-$286,000.00

‎
Additional compensation includes annual or quarterly performance bonuses.

‎
Additional compensation for certain positions may also include:

‎

‎
- Stock

‎

‎

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 5 years' experience in an analytics related field. Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 3 years' experience in an analytics related field. Option 3: 7 years' experience in an analytics or related field

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data science, machine learning, optimization models, PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Publications or active peer reviewer in related journals or conference, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.

Primary Location...

680 West California Avenue, Sunnyvale, CA 94086-4834, United States of America",2025-07-22T00:00:00.000Z,2025-07-25,"['Proficient in Python; solid knowledge of SQL', 'Hands on experience with classical ML models, test/train/evaluation metrics, key parameters/techniques that affect model performance', 'Understanding of relevant statistical measures such as confidence intervals, significance of error measurements, development and evaluation data sets', 'Familiar with NLU/NLP, more recent deep ML models (e.g., Transformers, BERT, Llama, Gpts, Gemini) including safe fine-tuning of these', 'Ability to communicate with model consumers and present results intuitively', 'Experience in identifying patterns, conducting error/ deviation analysis, and optimizing data representation', 'Bachelors degree or certification in Machine Learning, Computer Science, Engineering, Mathematics, Statistics or any other related field', 'That means understanding, respecting, and valuing unique styles, experiences, identities, ideas, and opinions while being welcoming of all people', ""Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 5 years' experience in an analytics related field"", ""Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 3 years' experience in an analytics related field"", ""Option 3: 7 years' experience in an analytics or related field"", 'Data science, machine learning, optimization models, PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Publications or active peer reviewer in related journals or conference, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch), We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly', 'The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture']","['Come at the right time, and you will have an enormous opportunity to make a massive impact on the design, architecture, and implementation of an innovative, mission critical product, driven by data-science, used every day, by people you know, and which customers love', 'As part of the emerging tech group, you will also have the additional opportunity of building demos, proof of concepts, creating white papers, writing blogs, etc']",True,"['Natural Language Understanding', 'Transformers', 'BERT', 'Large Language Models', 'Fine-tuning of Large Language Models', 'Agentic Systems', 'LLM Serving Optimization', 'Multi-Modal AI Interactions']","Natural Language Understanding: Developing and improving NLU services to enable conversational AI platforms and multi-modal user interactions.; Transformers: Utilized as advanced deep learning architectures for NLP tasks within conversational AI systems.; BERT: A transformer-based model used for understanding language context in NLP applications.; Large Language Models: Including GPT, LLaMA, and Gemini, these models are fine-tuned and optimized for conversational AI and personal assistant functionalities.; Fine-tuning of Large Language Models: Adapting pre-trained LLMs safely to specific retail and conversational use cases.; Agentic Systems: Experience with production-grade autonomous AI agents that interact with users or systems.; LLM Serving Optimization: Techniques to efficiently deploy and serve large language models in production environments.; Multi-Modal AI Interactions: Enabling AI systems to process and respond to inputs across voice, text, and rich UI for enhanced user experience.","['Python', 'SQL', 'Classical Machine Learning Models', 'Statistical Measures', 'Data Pipelines', 'Model Training and Evaluation', 'Error and Deviation Analysis', 'Feature Engineering', 'Scikit-learn', 'Spark', 'Scala', 'R', 'Optimization Models', 'Machine Learning Lifecycle Management']","Python: Used as a primary programming language for data science tasks including data manipulation and model development.; SQL: Utilized for querying and managing structured data within databases to support analytics and modeling.; Classical Machine Learning Models: Applied for predictive modeling and data-driven decision making using traditional ML algorithms.; Statistical Measures: Employed to evaluate model performance and ensure statistical validity through confidence intervals and error significance.; Data Pipelines: Implemented to automate data extraction, transformation, and loading processes supporting model training and deployment.; Model Training and Evaluation: Involves developing, testing, and validating models to optimize performance and accuracy.; Error and Deviation Analysis: Used to identify patterns and improve model robustness by analyzing prediction errors and deviations.; Feature Engineering: Optimizing data representation to enhance model input quality and predictive power.; Scikit-learn: An open-source ML framework used for implementing classical machine learning algorithms.; Spark: Used for large-scale data processing and analytics to handle big data workloads.; Scala: Programming language often used with Spark for scalable data processing.; R: Statistical programming language used for data analysis and modeling.; Optimization Models: Applied to improve decision-making processes and operational efficiencies.; Machine Learning Lifecycle Management: Managing the end-to-end process of model development, deployment, and monitoring including MLOps tools."
D4HPJ8yoWAUX3-1AAAAAAA==,"Data Scientist / Senior Data Scientist, Analytics","About the Team

The Analytics team is looking for experienced Data Scientists and Senior Data Scientists to guide measurement, strategy, and tactical decision-making across the company across a variety of teams and levels. Data Scientists at DoorDash work to uncover insights and turn them into relevant recommendations, driving decisions for the entire organization. Analytics is integral to all operational areas at DoorDash.

Please apply here for all non-managerial levels within the following analytics teams:
• Consumer & Growth
• Business Operations
• Dasher & Logistics
• Customer Experience & Integrity
• Merchant, Ads & Sales
• New Verticals
• International Data Science

About the Role

As a Data Scientist at DoorDash, you'll use your quantitative background to mentor other scientists and dive into large datasets to guide decision-making. We solve a multitude of exciting challenges including customer acquisition, fraud and support, marketing, balancing supply and demand, new city launches, marketplace efficiency, and more. If you enjoy finding patterns amidst chaos, and have experience using analytics to affect revenue, growth, operations or beyond, we're looking for someone like you!

You're excited about this opportunity because you will…
• Use quantitative analysis and the presentation of data to see beyond the numbers and understand what drives our business
• Build full-cycle analytics experiments, reports, and dashboards using SQL, R, Python, or other scripting and statistical tools
• Work with and mentor junior analysts on how to use more advanced methods and solve challenges
• Produce recommendations and use statistical techniques and hypothesis testing to validate your findings
• Provide insights to help business and product leaders understand marketplace dynamics, user behaviors, and long-term trends
• Identify and measure levers to help move essential metrics and make recommendations
• Work backwards from understanding and sizing problems to ideating solutions
• Report against our goals by identifying essential metrics and building executive-facing dashboards to track progress
• Collaborate with engineering to implement, document, validate, and monitor our logging

We're excited about you because you have…
• A degree in Math, Physics, Statistics, Economics, Computer Science, or a similar domain
• 2+ years of experience in data analytics, consulting, or related role
• Experience working with funnel optimization, user segmentation, cohort analyses, time series analyses, regression models, etc
• Expertise of SQL queries, ETL, A/B Testing, and statistical analysis (e.g. hypothesis testing, experimentation, regressions) with statistical packages, such as Matlab, R, SAS or Python
• Proficiency in one or more analytics & visualization tools (e.g. Chartio, Looker, Tableau)
• The insight to take ambiguous problems and solve them in a structured, hypothesis-driven, data-supported way

Notice to Applicants for Jobs Located in NYC or Remote Jobs Associated With Office in NYC Only

We use Covey as part of our hiring and/or promotional process for jobs in NYC and certain features may qualify it as an AEDT in NYC. As part of the hiring and/or promotion process, we provide Covey with job requirements and candidate submitted applications. We began using Covey Scout for Inbound from August 21, 2023, through December 21, 2023, and resumed using Covey Scout for Inbound again on June 29, 2024.

The Covey tool has been reviewed by an independent auditor. Results of the audit may be viewed here: Covey

About DoorDash

At DoorDash, our mission to empower local economies shapes how our team members move quickly, learn, and reiterate in order to make impactful decisions that display empathy for our range of users—from Dashers to merchant partners to consumers. We are a technology and logistics company that started with door-to-door delivery, and we are looking for team members who can help us go from a company that is known for delivering food to a company that people turn to for any and all goods.

DoorDash is growing rapidly and changing constantly, which gives our team members the opportunity to share their unique perspectives, solve new challenges, and own their careers. We're committed to supporting employees' happiness, healthiness, and overall well-being by providing comprehensive benefits and perks including premium healthcare, wellness expense reimbursement, paid parental leave and more.

Our Commitment to Diversity and Inclusion

We're committed to growing and empowering a more inclusive community within our company, industry, and cities. That's why we hire and cultivate diverse teams of people from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunity to excel.

Statement of Non-Discrimination: In keeping with our beliefs and goals, no employee or applicant will face discrimination or harassment based on: race, color, ancestry, national origin, religion, age, gender, marital/domestic partner status, sexual orientation, gender identity or expression, disability status, or veteran status. Above and beyond discrimination and harassment based on ""protected categories,"" we also strive to prevent other subtler forms of inappropriate behavior (i.e., stereotyping) from ever gaining a foothold in our office. Whether blatant or hidden, barriers to success have no place at DoorDash. We value a diverse workforce – people who identify as women, non-binary or gender non-conforming, LGBTQIA+, American Indian or Native Alaskan, Black or African American, Hispanic or Latinx, Native Hawaiian or Other Pacific Islander, differently-abled, caretakers and parents, and veterans are strongly encouraged to apply. Thank you to the Level Playing Field Institute for this statement of non-discrimination.

Pursuant to the San Francisco Fair Chance Ordinance, Los Angeles Fair Chance Initiative for Hiring Ordinance, and any other state or local hiring regulations, we will consider for employment any qualified applicant, including those with arrest and conviction records, in a manner consistent with the applicable regulation.

If you need any accommodations, please inform your recruiting contact upon initial connection.",,2025-07-25,"['Build full-cycle analytics experiments, reports, and dashboards using SQL, R, Python, or other scripting and statistical tools', 'A degree in Math, Physics, Statistics, Economics, Computer Science, or a similar domain', '2+ years of experience in data analytics, consulting, or related role', 'Experience working with funnel optimization, user segmentation, cohort analyses, time series analyses, regression models, etc', 'Expertise of SQL queries, ETL, A/B Testing, and statistical analysis (e.g. hypothesis testing, experimentation, regressions) with statistical packages, such as Matlab, R, SAS or Python', 'Proficiency in one or more analytics & visualization tools (e.g. Chartio, Looker, Tableau)', 'The insight to take ambiguous problems and solve them in a structured, hypothesis-driven, data-supported way', 'Notice to Applicants for Jobs Located in NYC or Remote Jobs Associated With Office in NYC Only']","[""As a Data Scientist at DoorDash, you'll use your quantitative background to mentor other scientists and dive into large datasets to guide decision-making"", 'We solve a multitude of exciting challenges including customer acquisition, fraud and support, marketing, balancing supply and demand, new city launches, marketplace efficiency, and more', 'Use quantitative analysis and the presentation of data to see beyond the numbers and understand what drives our business', 'Work with and mentor junior analysts on how to use more advanced methods and solve challenges', 'Produce recommendations and use statistical techniques and hypothesis testing to validate your findings', 'Provide insights to help business and product leaders understand marketplace dynamics, user behaviors, and long-term trends', 'Identify and measure levers to help move essential metrics and make recommendations', 'Work backwards from understanding and sizing problems to ideating solutions', 'Report against our goals by identifying essential metrics and building executive-facing dashboards to track progress', 'Collaborate with engineering to implement, document, validate, and monitor our logging']",True,[],,"['SQL', 'R', 'Python', 'Regression Models', 'Time-Series Analysis', 'A/B Testing', 'Hypothesis Testing', 'ETL', 'Statistical Packages', 'Data Visualization Tools', 'User Segmentation', 'Cohort Analysis', 'Funnel Optimization']","SQL: Used for querying and managing large datasets to build analytics experiments, reports, and dashboards.; R: Applied as a statistical tool and programming language for data analysis, hypothesis testing, and regression modeling.; Python: Used for scripting, statistical analysis, and building data-driven solutions including funnel optimization and cohort analyses.; Regression Models: Employed to analyze relationships between variables and support predictive analytics for business decisions.; Time-Series Analysis: Used to analyze trends and patterns over time to inform marketplace dynamics and operational strategies.; A/B Testing: Implemented to validate hypotheses and measure the impact of changes on key business metrics.; Hypothesis Testing: Applied to statistically validate findings and support data-driven recommendations.; ETL: Used to extract, transform, and load data for analysis and reporting purposes.; Statistical Packages: Includes Matlab, R, SAS, and Python libraries used for advanced statistical analysis and experimentation.; Data Visualization Tools: Tools like Chartio, Looker, and Tableau used to create dashboards and reports for executive and stakeholder communication.; User Segmentation: Technique to categorize users into groups for targeted analysis and marketing strategies.; Cohort Analysis: Method to analyze user behavior and trends over specific time periods to inform growth and retention strategies.; Funnel Optimization: Analyzing and improving conversion rates across different stages of the user journey."
J2E6bP-FHYgAVybHAAAAAA==,Senior Data Analyst (NSWC-Dahlgren),"Responsibilities

Sabre Systems is seeking a Senior Data Analyst to join our team in support of the Naval Surface Warfare Center Dahlgren Division (NSWCDD) in Dahlgren, VA. This role plays a critical part in NSWCDD’s strategic initiative to modernize, optimize, and simplify its IT infrastructure while advancing IT Service Management (ITSM) practices to deliver measurable, mission-focused outcomes.

This initiative not only includes the continued operation and maintenance of the existing IT environment but also emphasizes digital transformation, information management, infrastructure engineering, and the implementation of modern development, deployment, and automation technologies. The selected candidate will be essential to enhancing IT service delivery and ensuring efficient, customer-focused support in a dynamic and evolving environment.

Responsibilities include but are not limited to:
• Applies mathematics, statistics, predictive modelling and machine learning techniques to discover meaningful patterns and knowledge in recorded data
• Develops definition and application designs in the form of logical data models, data interface specifications, on-line query, and reports specifications
• Uses structured query languages (SQL)
• Presents findings and data insights in creative ways to facilitate the understanding of data across a range of technical and non-technical audiences
• Identifies, validates, and exploits internal and external data sets generated from a diverse range of processes
• Manages data and information in all its forms and the analysis of information structure (including logical analysis of taxonomies, data and metadata)

Qualifications

Qualifications:
• Bachelor’s degree in a business-related field from an accredited college or university
• Minimum of six (6) years of professional experience in relation to analysis, design, and development related to data warehousing and integration capabilities.
• Experience with help desk tools, such as ServiceNow
• Experience with requirements developing definition and application designs in the form of logical data models, data interface specifications, on-line query and report specifications, structured query language (SQL), database performance loading specifications, and data validation specifications.
• Experience with data warehouse development and design, data knowledge acquisition, legacy conversion specifications and design of data structures/load specifications, and knowledge of Working Capital Fund and Enterprise Resource Planning (ERP), financial, and human resources systems methods and strategies for data warehousing.
• Advanced proficiency in Cybersecurity Workforce (CWF) to focuses on building, managing, and operationalizing data pipelines.
• Must be a U.S. Citizen with an active DoD Secret clearance or higher
• Must be available to work onsite in Dahlgren, VA daily
• This position is contingent upon contract award and/or customer approval.

#LI-EN1

Compensation

Senior Level: At Sabre Systems, LLC, compensation is based on factors such as location, qualifications, experience, and contract-specific requirements. The general salary range for this position is $70,000-$200,000; however, final compensation will be determined by individual qualifications and applicable contract terms.

Sabre Overview

Sabre Systems, LLC, has been providing innovative technological solutions and services for Department of Defense, Federal Civilian, and commercial customers for more than 35 years. We support the ever-evolving areas of advanced communication technologies, cyber, systems and software engineering, and digital transformation.

With over three decades in business, Sabre Systems, LLC remains committed to our small business values and a people-first philosophy. We foster a welcoming, inclusive culture that values diverse perspectives and encourages open communication. Our collaborative environment supports continuous learning and professional growth at all levels. We prioritize the health, well-being, and success of our employees, offering comprehensive, evolving benefits designed to meet their diverse needs. Join us and be part of a thriving, people-driven culture.

We respect the unique perspectives that a diverse workforce of minorities, women, individuals with disabilities, and protected veterans brings not only to our company, but also to our customers. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex (including pregnancy, gender identity and sexual orientation), national origin, age, disability or genetic information.

EOE Minorities/Females/Disability/Veterans; VEVRAA Federal Contractor

Beware of employment scams—Sabre Systems will never request payment, extend offers without an interview, or contact you from an email that doesn’t end in @sabresystems.com; always apply directly at https://careers.sabresystems.com/.
Qualifications:

Qualifications:
• Bachelor’s degree in a business-related field from an accredited college or university
• Minimum of six (6) years of professional experience in relation to analysis, design, and development related to data warehousing and integration capabilities.
• Experience with help desk tools, such as ServiceNow
• Experience with requirements developing definition and application designs in the form of logical data models, data interface specifications, on-line query and report specifications, structured query language (SQL), database performance loading specifications, and data validation specifications.
• Experience with data warehouse development and design, data knowledge acquisition, legacy conversion specifications and design of data structures/load specifications, and knowledge of Working Capital Fund and Enterprise Resource Planning (ERP), financial, and human resources systems methods and strategies for data warehousing.
• Advanced proficiency in Cybersecurity Workforce (CWF) to focuses on building, managing, and operationalizing data pipelines.
• Must be a U.S. Citizen with an active DoD Secret clearance or higher
• Must be available to work onsite in Dahlgren, VA daily
• This position is contingent upon contract award and/or customer approval.

#LI-EN1
Education:UNAVAILABLEEmployment Type: FULL_TIME",2025-07-14T00:00:00.000Z,2025-07-25,"['Bachelor’s degree in a business-related field from an accredited college or university', 'Minimum of six (6) years of professional experience in relation to analysis, design, and development related to data warehousing and integration capabilities', 'Experience with help desk tools, such as ServiceNow', 'Experience with requirements developing definition and application designs in the form of logical data models, data interface specifications, on-line query and report specifications, structured query language (SQL), database performance loading specifications, and data validation specifications', 'Experience with data warehouse development and design, data knowledge acquisition, legacy conversion specifications and design of data structures/load specifications, and knowledge of Working Capital Fund and Enterprise Resource Planning (ERP), financial, and human resources systems methods and strategies for data warehousing', 'Advanced proficiency in Cybersecurity Workforce (CWF) to focuses on building, managing, and operationalizing data pipelines', 'Must be a U.S. Citizen with an active DoD Secret clearance or higher', 'Must be available to work onsite in Dahlgren, VA daily', 'This position is contingent upon contract award and/or customer approval', 'Bachelor’s degree in a business-related field from an accredited college or university', 'Minimum of six (6) years of professional experience in relation to analysis, design, and development related to data warehousing and integration capabilities', 'Experience with help desk tools, such as ServiceNow', 'Experience with requirements developing definition and application designs in the form of logical data models, data interface specifications, on-line query and report specifications, structured query language (SQL), database performance loading specifications, and data validation specifications', 'Experience with data warehouse development and design, data knowledge acquisition, legacy conversion specifications and design of data structures/load specifications, and knowledge of Working Capital Fund and Enterprise Resource Planning (ERP), financial, and human resources systems methods and strategies for data warehousing', 'Advanced proficiency in Cybersecurity Workforce (CWF) to focuses on building, managing, and operationalizing data pipelines', 'Must be a U.S. Citizen with an active DoD Secret clearance or higher', 'Must be available to work onsite in Dahlgren, VA daily', 'This position is contingent upon contract award and/or customer approval']","['Sabre Systems is seeking a Senior Data Analyst to join our team in support of the Naval Surface Warfare Center Dahlgren Division (NSWCDD) in Dahlgren, VA', 'This role plays a critical part in NSWCDD’s strategic initiative to modernize, optimize, and simplify its IT infrastructure while advancing IT Service Management (ITSM) practices to deliver measurable, mission-focused outcomes', 'This initiative not only includes the continued operation and maintenance of the existing IT environment but also emphasizes digital transformation, information management, infrastructure engineering, and the implementation of modern development, deployment, and automation technologies', 'The selected candidate will be essential to enhancing IT service delivery and ensuring efficient, customer-focused support in a dynamic and evolving environment', 'Applies mathematics, statistics, predictive modelling and machine learning techniques to discover meaningful patterns and knowledge in recorded data', 'Develops definition and application designs in the form of logical data models, data interface specifications, on-line query, and reports specifications', 'Uses structured query languages (SQL)', 'Presents findings and data insights in creative ways to facilitate the understanding of data across a range of technical and non-technical audiences', 'Identifies, validates, and exploits internal and external data sets generated from a diverse range of processes', 'Manages data and information in all its forms and the analysis of information structure (including logical analysis of taxonomies, data and metadata)']",True,[],,"['Predictive Modeling', 'Machine Learning', 'Mathematics and Statistics', 'Logical Data Models', 'Data Interface Specifications', 'SQL', 'Data Warehousing', 'Data Pipelines', 'Data Validation', 'Data Knowledge Acquisition', 'ServiceNow', 'Enterprise Resource Planning (ERP) Systems']","Predictive Modeling: Used to discover meaningful patterns and knowledge in recorded data to support decision-making.; Machine Learning: Applied to analyze data and extract insights for improving IT service delivery and operational outcomes.; Mathematics and Statistics: Fundamental techniques employed to analyze data and support predictive modeling efforts.; Logical Data Models: Developed to define and design data structures and application interfaces for effective data management.; Data Interface Specifications: Created to standardize data exchange and integration between systems and applications.; SQL: Used for querying and managing structured data within databases to support reporting and analysis.; Data Warehousing: Involved in the design and development of centralized repositories for integrated data storage and retrieval.; Data Pipelines: Built and managed to automate the flow and processing of data across systems, enhancing data availability.; Data Validation: Performed to ensure accuracy and integrity of data used in analysis and reporting.; Data Knowledge Acquisition: Process of gathering and understanding data from various sources to support analysis and decision-making.; ServiceNow: Help desk tool experience used to support IT service management and incident tracking.; Enterprise Resource Planning (ERP) Systems: Knowledge applied to integrate financial and human resources data within data warehousing solutions."
Se3xX3nIzCVGQVCxAAAAAA==,Senior Data Analyst,"Join or sign in to find your next job Join to apply for the Senior Data Analyst role at Circle Join to apply for the Senior Data Analyst role at Circle Circle is a financial technology company at the epicenter of the emerging internet of money, where value can finally travel like other digital data — globally, nearly instantly and less expensively than legacy settlement systems. This ground-breaking new internet layer opens up previously unimaginable possibilities for payments, commerce and markets that can help raise global economic prosperity and enhance inclusion. Our infrastructure – including USDC, a blockchain-based dollar – helps businesses, institutions and developers harness these breakthroughs and capitalize on this major turning point in the evolution of money and technology. What You’ll Be Part Of Circle is committed to visibility and stability in everything we do. As we grow as an organization, we're expanding into some of the world's strongest jurisdictions. Speed and efficiency are motivators for our success and our employees live by our company values: High Integrity, Future Forward, Multistakeholder, Mindful, and Driven by Excellence. We have built a flexible and diverse work environment where new ideas are encouraged and everyone is a stakeholder. What You’ll Be Responsible For As a Data Analyst at Circle, you’ll work closely with business partners to better understand our products, better understand the ecosystem, and enable better decision-making with data. We are a passionate team with a deeply analytical approach and your work will support our mission to be a world-class company driven by data. If you are curious about data, enjoy deriving insights, have experience improving data insights, and are motivated by impacting business, we want to hear from you. What You'll Work On Partner with the business by translating the business needs to design and develop core tables, build dashboards, define metrics, conduct ad hoc analyses, and do deep dive investigations to create situational awareness and derive insights Perform strategic analysis and research to identify new opportunities where business can be improved Create data visualizations to translate analytic results for broad understanding across the business Build scalable automation solutions using SQL, dashboards, and other tools to create leverage for yourself and the organization Partner with leaders effectively employing clear and structured communication to tell a “story” focused on business insights & data Develop strategic problem-solving, quantitative analytics, and communication skills What You'll Bring To Circle Senior Data Analyst (III) 4+ years of industry experience in data analytics Bachelor’s Degree or equivalent experience in a quantitative major (Finance, Accounting, Economics, Mathematics, Engineering) Strong analytical and data skills, including top notch SQL skills. Ideally (but not necessary to apply), you will also be able to build simple pipelines to help scale yourself Good communication skills - be able partner across the organization and identify business needs and difficulties, articulate issues clearly and concisely, and present effectively in both oral and written presentations to all levels in the organization Strong business sense and the ability to work through complex and ambiguous business requirements Self-starter - an entrepreneurial spirit that thrives in a fast-paced environment, deals well with ambiguity and focuses on driving impact Prior experience with visualization using Superset, Tableau or similar BI tools Expert in data analyses using SQL Basic understanding of Python is an added advantage Good understanding of statistics and experience applying them to solve business problems Domain experience in one of the following areas: financial services, business banking, product analytics, marketing, crypto ecosystem, or risk analytics Lead Data Analyst (IV) Includes All Senior Data Analyst Requirements, Plus 8+ years of industry experience in data analytics Deep understanding of statistics and experience applying them to solve business problems Circle is on a mission to create an inclusive financial future, with transparency at our core. We consider a wide variety of elements when crafting our compensation ranges and total compensation packages. Starting pay is determined by various factors, including but not limited to: relevant experience, skill set, qualifications, and other business and organizational needs. Please note that compensation ranges may differ for candidates in other locations. Base Pay Range Senior Data Analyst: $122,500 - $162,500 Lead Data Analyst: $145,000 - $192,500 We are an equal opportunity employer and value diversity at Circle. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. Additionally, Circle participates in the E-Verify Program in certain locations, as required by law. Should you require accommodations or assistance in our interview process because of a disability, please reach out to accommodations@circle.com for support. We respect your privacy and will connect with you separately from our interview process to accommodate your needs. Seniority level Seniority level Mid-Senior level Employment type Employment type Full-time Job function Job function Information Technology Referrals increase your chances of interviewing at Circle by 2x Get notified about new Senior Data Analyst jobs in Portland, Oregon Metropolitan Area . Senior Business Analyst - Operations (Remote) Business Analyst I (User Subject Matter Expert) Portland, OR $59,562.00-$89,057.00 4 months ago Business Intelligence Analyst (System Application Analyst) We’re unlocking community knowledge in a new way. Experts add insights directly into each article, started with the help of AI. #J-18808-Ljbffr",2025-07-22T00:00:00.000Z,2025-07-25,,,True,[],,"['SQL', 'Data Visualization', 'Statistical Analysis', 'Data Pipelines', 'Business Intelligence Tools', 'Python']","SQL: Used extensively for data analysis, building scalable automation solutions, and querying core tables to support business decision-making.; Data Visualization: Creating dashboards and visual representations of analytic results using tools like Superset and Tableau to communicate insights across the business.; Statistical Analysis: Applying statistical methods to solve business problems and perform strategic analysis and research.; Data Pipelines: Building simple pipelines to scale data processes and automate workflows within the organization.; Business Intelligence Tools: Utilizing BI tools such as Superset and Tableau to develop dashboards and support data-driven decision-making.; Python: Basic understanding used as an added advantage for data analysis and potentially building automation or pipelines."
82c7Q47tRU65uhP7AAAAAA==,Senior Data Analyst,"Visa is hiring a Senior Data Analyst with 5 - 10 years of experience. Based in United States - Foster City, CA and with Hybrid ways of working.

Job description and responsibilities:

The Sr. Data Analyst will be responsible for leading the data analysis function end-to-end (from requirements to report/dashboard delivery) for the Reimage Work (RW) Portfolio Reporting Automation effort. This includes upfront requirements gathering, followed by detailed data analysis, identification of data sources, creating of Entity-Relationship Diagrams, as well as metrics calculations. In addition, this position will also liaison with the Enterprise Architect, as well as various teams involved (UX Design, Data Hub buildout, Analytics), and will interact with a wide range of stakeholders both within Technology and also with cross-functional teams (Transformation Office, Finance, Product, Legal, HR, and Regulatory). This position will report to the Sr. Director of Technology Strategic Initiatives. Responsibilities Lead all aspects of the Reimagine Work (RW) Portfolio Reporting Automation data analysis function. Lead problem solving sessions to develop analytical solutions which help product & technology leaders to make data driven decisions Lead reporting automation requirements gathering for report/dashboard automation Drive detailed data analysis including the identification of data sources and data elements, creating of Entity-Relationship Diagrams, as well as detailed metrics calculations Support other allied architecture and integration activities. Assist in developing documentation around system integration, data flows, data dictionary, user guides and best practices. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, evaluating our infrastructure for greater scalability, etc. Obtain data steward approvals for data access for various data sources, and help establish connectivity of data sources with the data warehouse and data lake Support the creation of UX wireframes as well as the actual reports and dashboards and perform appropriate quality checks to ensure accuracy Lead other ad-hoc business management initiatives as needed.

This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office two days a week, Tuesdays and Wednesdays with a general guidepost of being in the office 50% of the time based on business needs.

Travel Requirements: This position requires travel 5-10% of the time.

Requirements and qualifications:
• 5 or more years of relevant work experience with a Bachelors Degree or at least 2 years of work experience with an Advanced degree (e.g. Masters, MBA, JD, MD) or 0 years of work experience with a PhD Preferred Qualifications
• 6 or more years of work experience with a Bachelors Degree or 4 or more years of relevant experience with an Advanced Degree (e.g. Masters, MBA, JD, MD) or up to 3 years of relevant experience with a PhD
• The ideal candidate would demonstrate a blend of a data analysis / process improvement skillset, with a management consulting background, transformation program experience, and a bias for action.
• 7-10 years of work experience in the data management space, driving data analysis for complex, cross-functional programs, experience in financial / Banking, Management Consulting, and/or technology industries a plus but not required.
• Advanced working knowledge and experience in SQL and relational databases. Experience with MS-SQL & data virtualization technologies like Denodo would be plus.
• Excellent verbal, written, and presentation skills. In particular, a demonstrated ability to effectively communicate technical and business issues and/or solutions to multiple organizational levels internally and externally as needed.
• Solid analytical and problem-solving skills, ability to think strategically and drive decision making.
• Ability to work independently with strong time management and ability to execute on multiple concurrent deliverables
• Demonstrated ability to manage through influence, but without direct management authority.",,2025-07-25,"['6 or more years of work experience with a Bachelors Degree or 4 or more years of relevant experience with an Advanced Degree (e.g. Masters, MBA, JD, MD) or up to 3 years of relevant experience with a PhD', 'The ideal candidate would demonstrate a blend of a data analysis / process improvement skillset, with a management consulting background, transformation program experience, and a bias for action', 'Advanced working knowledge and experience in SQL and relational databases', 'Experience with MS-SQL & data virtualization technologies like Denodo would be plus', 'Excellent verbal, written, and presentation skills', 'In particular, a demonstrated ability to effectively communicate technical and business issues and/or solutions to multiple organizational levels internally and externally as needed', 'Solid analytical and problem-solving skills, ability to think strategically and drive decision making', 'Ability to work independently with strong time management and ability to execute on multiple concurrent deliverables', 'Demonstrated ability to manage through influence, but without direct management authority']","['Data Analyst will be responsible for leading the data analysis function end-to-end (from requirements to report/dashboard delivery) for the Reimage Work (RW) Portfolio Reporting Automation effort', 'This includes upfront requirements gathering, followed by detailed data analysis, identification of data sources, creating of Entity-Relationship Diagrams, as well as metrics calculations', 'In addition, this position will also liaison with the Enterprise Architect, as well as various teams involved (UX Design, Data Hub buildout, Analytics), and will interact with a wide range of stakeholders both within Technology and also with cross-functional teams (Transformation Office, Finance, Product, Legal, HR, and Regulatory)', 'This position will report to the Sr', 'Director of Technology Strategic Initiatives', 'Responsibilities Lead all aspects of the Reimagine Work (RW) Portfolio Reporting Automation data analysis function', 'Lead problem solving sessions to develop analytical solutions which help product & technology leaders to make data driven decisions Lead reporting automation requirements gathering for report/dashboard automation Drive detailed data analysis including the identification of data sources and data elements, creating of Entity-Relationship Diagrams, as well as detailed metrics calculations Support other allied architecture and integration activities', 'Assist in developing documentation around system integration, data flows, data dictionary, user guides and best practices', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, evaluating our infrastructure for greater scalability, etc', 'Obtain data steward approvals for data access for various data sources, and help establish connectivity of data sources with the data warehouse and data lake Support the creation of UX wireframes as well as the actual reports and dashboards and perform appropriate quality checks to ensure accuracy Lead other ad-hoc business management initiatives as needed', 'Employees in hybrid roles are expected to work from the office two days a week, Tuesdays and Wednesdays with a general guidepost of being in the office 50% of the time based on business needs', 'Travel Requirements: This position requires travel 5-10% of the time']",True,[],,"['SQL', 'Relational Databases', 'Entity-Relationship Diagrams', 'Data Analysis', 'Metrics Calculations', 'Data Virtualization', 'Data Warehouse', 'Data Lake', 'Reporting Automation', 'Dashboards', 'Process Improvement', 'Data Stewardship']","SQL: Used for querying and managing relational databases to support data analysis and reporting automation.; Relational Databases: The job involves working with relational database systems to organize and retrieve data for analysis.; Entity-Relationship Diagrams: Created to model data sources and their relationships, aiding in data analysis and integration.; Data Analysis: Core responsibility involving detailed examination of data to support decision-making and reporting.; Metrics Calculations: Performed to quantify key performance indicators and support reporting automation.; Data Virtualization: Experience with technologies like Denodo to integrate data from multiple sources without physical consolidation.; Data Warehouse: Supports data storage and retrieval for reporting and analytics purposes.; Data Lake: Used as a centralized repository to store large volumes of raw data for analysis.; Reporting Automation: Automating the generation and delivery of reports and dashboards to improve efficiency.; Dashboards: Created and maintained to visualize data insights and support business decisions.; Process Improvement: Identifying and implementing automation and optimization opportunities in data delivery and workflows.; Data Stewardship: Managing data access approvals and ensuring data governance compliance."
tpeZ1K8W5U18X7saAAAAAA==,"Senior Data Analyst, Project Management","At CVS Health, we're building a world of health around every consumer and surrounding ourselves with dedicated colleagues who are passionate about transforming health care.As the nation's leading health solutions company, we reach millions of Americans through our local presence, digital channels and more than 300,000 purpose-driven colleagues - caring for people where, when and how they choose in a way that is uniquely more connected, more convenient and more compassionate. And we do it all with heart, each and every day.Position SummaryDevelops and manages program operations focused on improving clinical and financial outcomes, member engagement, and satisfaction.Develops strategies to mitigate high cost/high need utilization of services and assist members with assuming self-management of their conditions.Formulates and implements strategy for achieving applicable department/unit metrics and provides operational direction.Serves as technical, professional, and business resource (may cross multiple business functions).Directs/provides enhancements to business processes, policies, and infrastructure to improve operational efficiency (may cross multiple business functions).Develops, implements, and evaluates business analysis, which meet business needs (may cross multiple business functions).Creates reports needed to support business operations.Collaborates and partners with other business areas across/within regions or segments and within other centralized corporate areas to ensure all workflow processes and interdependencies are identified and addressed on an on-going basis.Promotes a clear vision aligned with company values and direction; sets specific challenging and achievable objectives and action plans; motivates others to balance customer needs and business success; challenges self and others to look to the future to create quality products, services, and solutions.Collaborates with licensed staff from other areas that assist with oversight of clinical staff and activities of licensed personnel.Support state-driven deliverablesRequired Qualifications5-7 years work experience in informatics/data analysis2+ years experience with execution and delivery (planning, delivering, and supporting)2+ years experience communicating in a highly effective manner with internal and external constituents in both written and oral format.2+ years experience evaluating and interpreting data for the purpose of developing new programs and processes to meet business demands (Quantitative and Qualitative analysis)2+ years experience synthesizing program performance and clinical outcomes.Adept at problem solving and decision making skillsAdept at collaboration and teamworkAdept at growth mindset (agility and developing yourself and others) skillsPreferred QualificationsLTSS, NCQA, and Managed Care experienceManaging QuickBase and PowerBIEducationBachelor's Degree RequiredAnticipated Weekly Hours40Time TypeFull timePay RangeThe typical pay range for this role is:$46,988.00 - $112,200.00This pay range represents the base hourly rate or base annual full-time salary for all positions in the job grade within which this position falls. The actual base salary offer will depend on a variety of factors including experience, education, geography and other relevant factors. This position is eligible for a CVS Health bonus, commission or short-term incentive program in addition to the base pay range listed above. Our people fuel our future. Our teams reflect the customers, patients, members and communities we serve and we are committed to fostering a workplace where every colleague feels valued and that they belong.Great benefits for great peopleWe take pride in our comprehensive and competitive mix of pay and benefits - investing in the physical, emotional and financial wellness of our colleagues and their families to help them be the healthiest they can be. In addition to our competitive wages, our great benefits include:Affordable medical plan options, a 401(k) plan (including matching company contributions), and an employee stock purchase plan.No-cost programs for all colleagues including wellness screenings, tobacco cessation and weight management programs, confidential counseling and financial coaching.Benefit solutions that address the different needs and preferences of our colleagues including paid time off, flexible work schedules, family leave, dependent care resources, colleague assistance programs, tuition assistance, retiree medical access and many other benefits depending on eligibility.For more information, visit https://jobs.cvshealth.com/us/en/benefitsWe anticipate the application window for this opening will close on: 04/28/2025Qualified applicants with arrest or conviction records will be considered for employment in accordance with all federal, state and local laws.",,2025-07-25,"['Support state-driven deliverablesRequired Qualifications5-7 years work experience in informatics/data analysis2+ years experience with execution and delivery (planning, delivering, and supporting)2+ years experience communicating in a highly effective manner with internal and external constituents in both written and oral format.2+ years experience evaluating and interpreting data for the purpose of developing new programs and processes to meet business demands (Quantitative and Qualitative analysis)2+ years experience synthesizing program performance and clinical outcomes', 'Adept at problem solving and decision making skills', 'Adept at collaboration and teamwork', 'Adept at growth mindset (agility and developing yourself and others) skills', ""Managing QuickBase and PowerBIEducationBachelor's Degree RequiredAnticipated Weekly Hours40Time TypeFull time""]","['Position SummaryDevelops and manages program operations focused on improving clinical and financial outcomes, member engagement, and satisfaction', 'Develops strategies to mitigate high cost/high need utilization of services and assist members with assuming self-management of their conditions', 'Formulates and implements strategy for achieving applicable department/unit metrics and provides operational direction', 'Serves as technical, professional, and business resource (may cross multiple business functions).Directs/provides enhancements to business processes, policies, and infrastructure to improve operational efficiency (may cross multiple business functions).Develops, implements, and evaluates business analysis, which meet business needs (may cross multiple business functions)', 'Creates reports needed to support business operations', 'Collaborates and partners with other business areas across/within regions or segments and within other centralized corporate areas to ensure all workflow processes and interdependencies are identified and addressed on an on-going basis', 'Promotes a clear vision aligned with company values and direction; sets specific challenging and achievable objectives and action plans; motivates others to balance customer needs and business success; challenges self and others to look to the future to create quality products, services, and solutions', 'Collaborates with licensed staff from other areas that assist with oversight of clinical staff and activities of licensed personnel']",False,[],,"['Quantitative and Qualitative Analysis', 'Program Performance Synthesis', 'Business Analysis', 'Reporting and Dashboards', 'Power BI', 'QuickBase']","Quantitative and Qualitative Analysis: Used to evaluate and interpret data for developing new programs and processes to meet business demands.; Program Performance Synthesis: Synthesizing program performance and clinical outcomes to inform decision-making and strategy.; Business Analysis: Developing, implementing, and evaluating business analysis to meet operational and strategic needs.; Reporting and Dashboards: Creating reports to support business operations and monitor key metrics.; Power BI: A BI tool used for data visualization and reporting to support business insights.; QuickBase: A platform used for managing workflows and data to improve operational efficiency."
QRaerQP-yQ4HsNzyAAAAAA==,Senior Data Analyst (multiple openings),"Job Location:

InnovAccer, Inc.101 Mission Street, Suite 1950, San Francisco, CA 94105 (travel to unanticipated client sites in U.S. and allows for telecommuting)

Job Duties

With a high level of independent decision-making capability and minimum supervision, the Senior Data Analyst will be responsible for the following job duties:
• Building complex data pipelines from different source to map to data warehouse schema;
• Performing ETL logic as per required by building complex data pipelines;
• Analyzing data and visualization using tools like Power BI or Tableau.
• Engaging with business and technical client teams to document and explain technical problems and concepts concisely;
• Leading junior engineer teams;
• Supporting customer incidents to resolutions;
• Working with relational database and AWS; and Engaging in SQL programming and writing on a fly query to complete complex data analysis.

This position requires travel to unanticipated client sites throughout the U.S and allows for telecommuting

Education:

U.S. Master’s degree or foreign equivalent in Bus Analytics, IS, CS, or closely related/equivalent.

Experience:

Three (3) years of experience as an App Dev/Data Analyst, or closely related.

Skills:
• Must have experience with:
• Data processing;
• Data analysis;
• Python;
• SQL;
• Git Version Control;
• Power BI or Tableau or Si-Sense;
• Linux/Unix or Powershell;
• IntelliJ, Pycharm, or DE Beaver;
• Agile or scrum methodology; and
• ML models

Contact:

Kimberly Saied, Director, People eXperience,

kimberley.saied@innovaccer.com",,2025-07-25,"['U.S. Master’s degree or foreign equivalent in Bus Analytics, IS, CS, or closely related/equivalent', 'Three (3) years of experience as an App Dev/Data Analyst, or closely related', 'Must have experience with:', 'Data processing;', 'Python;', 'SQL;', 'Git Version Control;', 'Power BI or Tableau or Si-Sense;', 'Linux/Unix or Powershell;', 'IntelliJ, Pycharm, or DE Beaver;', 'Agile or scrum methodology; and', 'ML models']","['With a high level of independent decision-making capability and minimum supervision, the Senior Data Analyst will be responsible for the following job duties:', 'Building complex data pipelines from different source to map to data warehouse schema;', 'Performing ETL logic as per required by building complex data pipelines;', 'Analyzing data and visualization using tools like Power BI or Tableau', 'Engaging with business and technical client teams to document and explain technical problems and concepts concisely;', 'Leading junior engineer teams;', 'Supporting customer incidents to resolutions;', 'Working with relational database and AWS; and Engaging in SQL programming and writing on a fly query to complete complex data analysis', 'This position requires travel to unanticipated client sites throughout the U.S and allows for telecommuting', 'Data analysis;']",True,[],,"['Data Pipelines', 'ETL (Extract, Transform, Load)', 'Data Visualization', 'SQL', 'Python', 'Relational Databases', 'AWS', 'Machine Learning Models', 'Git Version Control', 'Agile/Scrum Methodology']","Data Pipelines: Building complex data pipelines from various sources to map data into a warehouse schema for analysis.; ETL (Extract, Transform, Load): Performing ETL logic to process and prepare data as part of pipeline construction.; Data Visualization: Using BI tools like Power BI and Tableau to create visual representations of data for insights.; SQL: Writing on-the-fly queries and programming in SQL to perform complex data analysis on relational databases.; Python: Utilizing Python for data processing and analysis tasks.; Relational Databases: Working with relational database systems to store and query structured data.; AWS: Using Amazon Web Services infrastructure to support data storage and processing.; Machine Learning Models: Applying machine learning models as part of data analysis and predictive tasks.; Git Version Control: Using Git for version control to manage code and collaboration.; Agile/Scrum Methodology: Following Agile or Scrum frameworks for project management and iterative development."
DUfnR_OQQwQvdtj_AAAAAA==,"(USA) Senior, Data Analyst - Transportation Strategy","Position Summary...

What you'll do...

This Senior Data Analyst will be a part of the Portfolio Optimization team within transportation. This role will make an impact by identifying new workload opportunities, areas of top loss in execution and ways to drive improved profitability. This role supports operational stakeholders across the E2E delivery network with heavy cross-functional engagement with transportation planning and procurement teams. This role is based in Bentonville, AR.

 

You’ll sweep us off our feet if…
• You have finance, supply chain and/or transportation experience.
• You possess strong skills in SQL and Python, and have experience in advanced analytics, including advanced exploratory data analysis skills, and the ability to make analytical, data-driven recommendations and solutions.
• Data visualization experience with tools like Tableau or PowerBI.
• You have extreme ownership and Intellectual curiosity that leads to process and business improvement.
• You are comfortable with shifting priorities in fast moving and sometimes ambiguous environment.

 

You’ll make an impact by…
• Advanced Analytics: In-depth investigation of key drivers of transportation dynamic optimization and data quality. Work with large, disparate datasets to measure business KPIs and to conduct strategic analyses to inform critical business decisions. Create data visualizations to monitor and quantify the impact of changes and unique business challenges and use data to influence strategic decision making. Develop advanced logic to identify cost savings opportunities to drive improved execution and recommendations for process improvement.
• Partnership and Collaboration: Engaging with team members and cross-functional partners on a consistent basis and establish credibility and influence change. Drive process optimization and collaboration across teams. Conduct exploratory analysis and inform team of findings.
• Continuous Improvement: Analyze and improve processes by leveraging lean, six sigma, and zero-loss principles. Identify opportunities to positively impact cost and growth plans. Lead efforts to improve data integrity and quality by proactively identifying and addressing issues. Formulate technical problems and solutions for data related challenges.

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

‎

‎

‎
You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.

‎

For information about PTO, see https://one.walmart.com/notices.

‎

‎
Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

‎
Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

‎

For information about benefits and eligibility, see One.Walmart.

‎
The annual salary range for this position is $80,000.00-$155,000.00

‎
Additional compensation includes annual or quarterly performance bonuses.

‎
Additional compensation for certain positions may also include:

‎

‎
- Stock

‎

‎

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelor's degree in Business, Engineering, Statistics, Economics, Analytics, Mathematics, Arts, Finance or related field and 2 years' experience in data analysis, data science, statistics, or related field. Option 2: Master's degree in Business, Engineering, Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field. Option 3: 4 years' experience in data analysis, data science, statistics, or related field.

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data science, data analysis, statistics, or related field, Master’s degree in Business, Computer Science, Engineering, Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field, Related industry experience (for example, retail, merchandising, healthcare, eCommerce), Successful completion of assessments in data analysis and Business Intelligence tools and scripting languages (for example, SQL, Python, Spark, Scala, R, Power BI, or Tableau)

Primary Location...

311 North Walton Boulevard, Bentonville, AR 72716, United States of America",2025-07-21T00:00:00.000Z,2025-07-25,"['You have finance, supply chain and/or transportation experience', 'You possess strong skills in SQL and Python, and have experience in advanced analytics, including advanced exploratory data analysis skills, and the ability to make analytical, data-driven recommendations and solutions', 'Data visualization experience with tools like Tableau or PowerBI', 'You have extreme ownership and Intellectual curiosity that leads to process and business improvement', 'You are comfortable with shifting priorities in fast moving and sometimes ambiguous environment', ""Option 1: Bachelor's degree in Business, Engineering, Statistics, Economics, Analytics, Mathematics, Arts, Finance or related field and 2 years' experience in data analysis, data science, statistics, or related field"", ""Option 2: Master's degree in Business, Engineering, Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field"", ""Option 3: 4 years' experience in data analysis, data science, statistics, or related field"", 'Data science, data analysis, statistics, or related field, Master’s degree in Business, Computer Science, Engineering, Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field, Related industry experience (for example, retail, merchandising, healthcare, eCommerce), Successful completion of assessments in data analysis and Business Intelligence tools and scripting languages (for example, SQL, Python, Spark, Scala, R, Power BI, or Tableau)']","['This Senior Data Analyst will be a part of the Portfolio Optimization team within transportation', 'This role will make an impact by identifying new workload opportunities, areas of top loss in execution and ways to drive improved profitability', 'This role supports operational stakeholders across the E2E delivery network with heavy cross-functional engagement with transportation planning and procurement teams', 'Advanced Analytics: In-depth investigation of key drivers of transportation dynamic optimization and data quality', 'Work with large, disparate datasets to measure business KPIs and to conduct strategic analyses to inform critical business decisions', 'Create data visualizations to monitor and quantify the impact of changes and unique business challenges and use data to influence strategic decision making', 'Develop advanced logic to identify cost savings opportunities to drive improved execution and recommendations for process improvement', 'Partnership and Collaboration: Engaging with team members and cross-functional partners on a consistent basis and establish credibility and influence change', 'Drive process optimization and collaboration across teams', 'Conduct exploratory analysis and inform team of findings', 'Continuous Improvement: Analyze and improve processes by leveraging lean, six sigma, and zero-loss principles', 'Identify opportunities to positively impact cost and growth plans', 'Lead efforts to improve data integrity and quality by proactively identifying and addressing issues', 'Formulate technical problems and solutions for data related challenges']",True,[],,"['SQL', 'Python', 'Tableau', 'Power BI', 'Advanced Exploratory Data Analysis', 'Business Intelligence Tools', 'Lean Six Sigma', 'Data Integrity and Quality Management', 'Exploratory Analysis', 'Spark', 'Scala', 'R']","SQL: Used for querying and managing large, disparate datasets to measure business KPIs and support strategic analyses.; Python: Applied for advanced analytics, exploratory data analysis, and developing logic to identify cost savings and process improvements.; Tableau: Employed to create data visualizations that monitor and quantify the impact of changes and business challenges.; Power BI: Used as a data visualization tool to support monitoring and strategic decision making.; Advanced Exploratory Data Analysis: Conducted to investigate key drivers of transportation optimization and data quality.; Business Intelligence Tools: Utilized for data visualization and reporting to influence strategic decision making.; Lean Six Sigma: Applied as continuous improvement methodologies to analyze and improve transportation and operational processes.; Data Integrity and Quality Management: Led efforts to proactively identify and address data issues to improve accuracy and reliability.; Exploratory Analysis: Performed to inform teams of findings and support data-driven recommendations.; Spark: Mentioned as a preferred scripting language for handling large-scale data processing.; Scala: Included as a preferred scripting language for data analysis and processing.; R: Referenced as a preferred language for statistical analysis and data science tasks."
v14PJcF50YHncd3BAAAAAA==,Senior Data Analytics Analyst,"At U.S. Bank, we're on a journey to do our best. Helping the customers and businesses we serve to make better and smarter financial decisions and enabling the communities we support to grow and succeed. We believe it takes all of us to bring our shared ambition to life, and each person is unique in their potential. A career with U.S. Bank gives you a wide, ever-growing range of opportunities to discover what makes you thrive at every stage of your career. Try new things, learn new skills and discover what you excel at-all from Day One.

Job Description

Responsible for working on big data/analytics projects that gather and integrate large volumes of data, performs analysis, interprets results and develops actionable insights and recommendations for use across the company. Acquires data from multiple data sources in order to perform analysis. Identifies, analyzes and interprets trends or patterns in complex data in order to provide answers to business questions as well as provide recommendations for action. Interprets data and analyze results using various statistical techniques and tools. Presents data and analysis in a clear and concise manner allowing the audience to quickly understand the results and recommendations so they activate upon them and make data driven decisions. Collaborate with various partners to provide a holistic view of the analysis. Measures and monitors results of applied recommendations and present adjustments. Ensures all data acquisition, sharing and results of applied recommendations are compliant with company standards.

Basic Qualifications
• Bachelor's degree in a related field, or equivalent work experience
• Six to eight years of statistical and/or data analytics experience

Preferred Skills/Experience
• Working knowledge of analytics and statistical software such as SQL, R, Python, Excel, Hadoop, SAS, SPSS, Geo-spatial tools and others to perform analysis and interpret data
• Experience in analytics, advanced analytics/statistics, predictive modeling
• Strong analytic skills with the ability to extract, collect, organize, analyze and interpret trends or patterns in complex data sets
• Demonstrated project management skills
• Effective interpersonal, verbal and written communication skills
• Experience using a variety of different systems including but not limited to: Salesforce, Precision Lender and nCino
• Experience using a variety of different tools including but not limited to: SQL Server Management Studio, Tableau, Analytics, PowerBI and on-platform reporting

If there's anything we can do to accommodate a disability during any portion of the application or hiring process, please refer to our disability accommodations for applicants.

Benefits:

Our approach to benefits and total rewards considers our team members' whole selves and what may be needed to thrive in and outside work. That's why our benefits are designed to help you and your family boost your health, protect your financial security and give you peace of mind. Our benefits include the following (some may vary based on role, location or hours):
• Healthcare (medical, dental, vision)
• Basic term and optional term life insurance
• Short-term and long-term disability
• Pregnancy disability and parental leave
• 401(k) and employer-funded retirement plan
• Paid vacation (from two to five weeks depending on salary grade and tenure)
• Up to 11 paid holiday opportunities
• Adoption assistance
• Sick and Safe Leave accruals of one hour for every 30 worked, up to 80 hours per calendar year unless otherwise provided by law

U.S. Bank is an equal opportunity employer. We consider all qualified applicants without regard to race, religion, color, sex, national origin, age, sexual orientation, gender identity, disability or veteran status, and other factors protected under applicable law.

E-Verify

U.S. Bank participates in the U.S. Department of Homeland Security E-Verify program in all facilities located in the United States and certain U.S. territories. The E-Verify program is an Internet-based employment eligibility verification system operated by the U.S. Citizenship and Immigration Services. Learn more about the E-Verify program.

The salary range reflects figures based on the primary location, which is listed first. The actual range for the role may differ based on the location of the role. In addition to salary, U.S. Bank offers a comprehensive benefits package, including incentive and recognition programs, equity stock purchase 401(k) contribution and pension (all benefits are subject to eligibility requirements). Pay Range: $119,765.00 - $140,900.00

U.S. Bank will consider qualified applicants with arrest or conviction records for employment. U.S. Bank conducts background checks consistent with applicable local laws, including the Los Angeles County Fair Chance Ordinance and the California Fair Chance Act as well as the San Francisco Fair Chance Ordinance. U.S. Bank is subject to, and conducts background checks consistent with the requirements of Section 19 of the Federal Deposit Insurance Act (FDIA). In addition, certain positions may also be subject to the requirements of FINRA, NMLS registration, Reg Z, Reg G, OFAC, the NFA, the FCPA, the Bank Secrecy Act, the SAFE Act, and/or federal guidelines applicable to an agreement, such as those related to ethics, safety, or operational procedures.

Applicants must be able to comply with U.S. Bank policies and procedures including the Code of Ethics and Business Conduct and related workplace conduct and safety policies.

Posting may be closed earlier due to high volume of applicants.",2025-07-12T00:00:00.000Z,2025-07-25,"[""Bachelor's degree in a related field, or equivalent work experience"", 'Six to eight years of statistical and/or data analytics experience', 'In addition, certain positions may also be subject to the requirements of FINRA, NMLS registration, Reg Z, Reg G, OFAC, the NFA, the FCPA, the Bank Secrecy Act, the SAFE Act, and/or federal guidelines applicable to an agreement, such as those related to ethics, safety, or operational procedures', 'Applicants must be able to comply with U.S. Bank policies and procedures including the Code of Ethics and Business Conduct and related workplace conduct and safety policies']","['Responsible for working on big data/analytics projects that gather and integrate large volumes of data, performs analysis, interprets results and develops actionable insights and recommendations for use across the company', 'Acquires data from multiple data sources in order to perform analysis', 'Identifies, analyzes and interprets trends or patterns in complex data in order to provide answers to business questions as well as provide recommendations for action', 'Interprets data and analyze results using various statistical techniques and tools', 'Presents data and analysis in a clear and concise manner allowing the audience to quickly understand the results and recommendations so they activate upon them and make data driven decisions', 'Collaborate with various partners to provide a holistic view of the analysis', 'Measures and monitors results of applied recommendations and present adjustments', 'Ensures all data acquisition, sharing and results of applied recommendations are compliant with company standards']",True,[],,"['Big Data Analytics', 'Data Integration', 'Statistical Analysis', 'Predictive Modeling', 'SQL', 'R', 'Python', 'Excel', 'Hadoop', 'SAS', 'SPSS', 'Geo-spatial Analysis Tools', 'Tableau', 'Power BI', 'SQL Server Management Studio', 'Advanced Analytics']","Big Data Analytics: The role involves working on projects that gather and integrate large volumes of data for analysis and actionable insights.; Data Integration: Acquiring and combining data from multiple sources to perform comprehensive analysis.; Statistical Analysis: Using various statistical techniques to interpret data and identify trends or patterns relevant to business questions.; Predictive Modeling: Applying advanced analytics and statistical methods to forecast outcomes and support decision-making.; SQL: Utilized for querying and managing data within relational databases as part of data acquisition and analysis.; R: Used as a statistical software tool for data analysis and interpretation.; Python: Employed for data manipulation, analysis, and statistical computations.; Excel: Used for data organization, analysis, and presentation.; Hadoop: A big data framework used to process and analyze large datasets.; SAS: Statistical software used for advanced analytics and data management.; SPSS: Statistical software applied for data analysis and interpretation.; Geo-spatial Analysis Tools: Used to analyze spatial data patterns relevant to business insights.; Tableau: A BI tool used to create dashboards and visualize data for clear communication of insights.; Power BI: A business intelligence platform used for data visualization and reporting.; SQL Server Management Studio: A tool for managing SQL Server databases and performing data queries.; Advanced Analytics: Applying sophisticated analytical techniques to extract deeper insights from data."
fRysXtQWXytn9LlHAAAAAA==,Mergers and Acquisitions Data Analyst Senior or Lead,"Progressive is dedicated to helping employees move forward and live fully in their careers. Your journey has already begun. Apply today and take the first step to Destination: Progress.

As a data analyst senior or lead on the Corporate Finance Merger & Acquisitions (M&A) team, you’ll prioritize a data-driven approach to end-to-end finance integration activities for mergers, acquisitions, and other business initiatives. You’ll work independently on a multitude of projects for the Corporate Finance organization, including accounting and finance due diligence, discovery and planning for merger activities, and supporting execution of post-merger integration projects. In this role, you’ll seek to understand the data, processes, systems, people, technology, contracts and assets of both Progressive and the acquired company. You’ll also identify current state for every finance related function, perform gap analysis, and develop a commonality roadmap. Additionally, you’ll drive solutions, collaborate across functions resolve project issues, dependencies, and risks, resolve issues, and advance critical problems.

Must-have qualifications
• A minimum of six years of analytical work experience.
• {OR} Bachelor's degree or higher and a minimum of five years of analytical work experience.
• {OR} Bachelor's degree or higher in a quantitative field of study and a minimum of three years analytical work experience.

Preferred skills
• Experience with financial integration activities
• Understanding of treasury functions such as banking, cash management, and pay operations
• Strong organization and collaboration skills to present insights to partners for alignment
• Aptitude to learn and understand the various areas of discipline within a finance organization, including their dependencies.

Compensation
• $79,200 - $127,700/year depending on position level and experience
• Gainshare annual cash incentive payment up to 30% your eligible earnings based on company performance

Benefits
• 401(k) with dollar-for-dollar company match up to 6%
• Medical, dental & vision, including free preventative care
• Wellness & mental health programs
• Health care flexible spending accounts, health savings accounts, & life insurance
• Paid time off, including volunteer time off
• Paid & unpaid sick leave where applicable, as well as short & long-term disability
• Parental & family leave; military leave & pay
• Diverse, inclusive & welcoming culture with Employee Resource Groups
• Career development & tuition assistance
• Onsite gym & healthcare at large locations

Energage recognizes Progressive as a 2025 Top Workplace for: Innovation, Purposes & Values, Work-Life Flexibility, Compensation & Benefits, and Leadership.

Sponsorship for work authorization for foreign national candidates is not available for this position.

Equal Opportunity Employer

For ideas about how you might be able to protect yourself from job scams, visit our scam-awareness page at https://careers.progressive.com/pages/how-we-hire-faq-job-scams/",2025-07-21T00:00:00.000Z,2025-07-25,"['A minimum of six years of analytical work experience', ""{OR} Bachelor's degree or higher and a minimum of five years of analytical work experience"", ""{OR} Bachelor's degree or higher in a quantitative field of study and a minimum of three years analytical work experience""]","['As a data analyst senior or lead on the Corporate Finance Merger & Acquisitions (M&A) team, you’ll prioritize a data-driven approach to end-to-end finance integration activities for mergers, acquisitions, and other business initiatives', 'You’ll work independently on a multitude of projects for the Corporate Finance organization, including accounting and finance due diligence, discovery and planning for merger activities, and supporting execution of post-merger integration projects', 'In this role, you’ll seek to understand the data, processes, systems, people, technology, contracts and assets of both Progressive and the acquired company', 'You’ll also identify current state for every finance related function, perform gap analysis, and develop a commonality roadmap', 'Additionally, you’ll drive solutions, collaborate across functions resolve project issues, dependencies, and risks, resolve issues, and advance critical problems']",False,[],,"['Data-Driven Finance Integration', 'Gap Analysis', 'Financial Due Diligence', 'Cross-Functional Collaboration']",Data-Driven Finance Integration: Used to guide end-to-end finance integration activities during mergers and acquisitions by analyzing financial data and processes.; Gap Analysis: Applied to identify differences between current and desired finance-related functions to develop a commonality roadmap.; Financial Due Diligence: Involves analyzing accounting and finance data to support merger activities and ensure accurate financial assessment.; Cross-Functional Collaboration: Engaged to resolve project issues and dependencies by working with multiple teams across the organization.
KGwdgfxpOFbJ4d2aAAAAAA==,Senior Data Analyst Job at Corporate Tools LLC in Post Falls,"Corporate Tools is looking for a Senior Data Analyst to join our finance team located in Post Falls, ID. Corporate Tools is a privately held, debt-free, growing company. We don’t answer to shareholders or investors. Because of this, we focus on taking the time to provide solutions for our clients, not maximizing profits for shareholders. As an employer, we recognize that you’ve been gracious enough to give us 40 hours of your week. We want to respect that time commitment and be able to provide you with a job that you enjoy coming to and a work schedule that allows you to maintain a healthy work/life balance.Are you a data wizard with a passion for numbers? Then we want to talk to you! In this position, you won’t just be running numbers through a system and handing the results off to someone else. You will be running the numbers, understanding the results, and then using the final data sets to direct the company towards impactful moments for our customers.This position is coded as “Hybrid,” which means after initial training and onboarding in the office, occasional remote work is available. However, this role will be expected to continue to work in our Post Falls, Idaho office or our Spokane, WA office 2-3 days/week.Wage:$100,000 - $125,000 depending on meeting requirements100% employer-paid medical, dental, and vision for employeesAnnual review with raise option22 days Paid Time Off accrued annually, and 4 holidaysAfter 3 years, PTO increases to 29 days. Employees transition to flexible time off after 5 years with the company—not accrued, not capped, take time off when you wantThe 4 holidays are: New Year’s Day, Fourth of July, Thanksgiving, and Christmas DayPaid Maternity and Paternity Leave4% company matching 401(k) with no vesting periodQuarterly ""Work Wherever"" allowanceUse to make your remote work wherever set up more comfortable, for continuing education classes, a plant for your desk, coffee for your coworker, a massage for yourself... really, whateverOpen concept office with friendly coworkersCreative environment where you can make a differenceTrail Mix BarResponsibilities:Data Analysis Product leader facilitating product planning and prioritization, execution, and reporting for the overall product - incorporating product mindset throughout.Primary contact responsible for communication management throughout the organization for Data Analysis Product.Effectively communicate complex information to a variety of stakeholders to help inform business decisions.Collaborates with the analytics team to plan and scale analytics, working to harvest and grow the data culture across the company.Consults stakeholders in the development of KPIs, ad hoc analyses, and automated reporting to best fit their needs and act as a leader in promoting data literacy.Works with the data engineering team to plan, build, and maintain data structures to support analysis and reporting needs.Conduct complex data analysis to support strategic initiatives, leveraging your unique expertise in analytics tools and statistical methods.Leverage advanced SQL and Python/R expertise to wrangle even the most elusive sets of data—capturing trends, patterns, and anomalies.Create and maintain beautiful, intuitive business intelligence dashboards, making it easy for teams to see the stories hidden in the data.Develop models that help us predict market trends, customer behavior, and data migrations, improving decision-making across the organization.Partner with cross-functional teams to understand their data needs, translating these into actionable insights and recommendations.Ensure the highest quality and accuracy of all data by developing processes and standards that keep the data pristine.Organizes and prioritizes tickets using Jira and Confluence.As a Senior Data Analyst, you’ll mentor the analyst team and share best practices.Requirements:5+ years in data analytics or a related field, ideally with experience working for fast-growing, high-impact organizations.Bachelor’s (BA or BS) in business, accounting, or related field, or relevant experience.Advanced experience using SQL to extract data from relational databases (Postgres, MySQL, T-SQL, etc.).Proficient in advanced programming languages (Python, R, etc.) for data manipulation, analysis, and visualization in various contexts such as statistical analysis, machine learning, and data mining.Demonstrated analytical and problem-solving skills.Experience extracting meaning from large data sets.Experience building dashboards and reports using business intelligence tools (Tableau, PowerBI, Looker, Metabase, etc.). Metabase experience would be a plus.Exceptional skills in data modeling, statistical analysis, and predictive modeling.Ability to think outside the box, constantly seeking new ways to interpret and use data.Ability to translate complex data findings into narratives for both technical and non-technical audiences.Ability to act as a consultant to help stakeholders create relevant KPIs and understand the meaning behind the data.Team management/leadership experience including developing others.Preferred experience presenting insights to executive leadership.Bonus Points: Experience working on ETL processes and data modeling. DBT experience is highly preferred.Data is what you do, it’s your niche. Finding ways to move the company forward using data as your storyboard excites you!
#J-18808-Ljbffr",2025-07-22T00:00:00.000Z,2025-07-25,"['Organizes and prioritizes tickets using Jira and Confluence.As a Senior Data Analyst, you’ll mentor the analyst team and share best practices.Requirements:5+ years in data analytics or a related field, ideally with experience working for fast-growing, high-impact organizations.Bachelor’s (BA or BS) in business, accounting, or related field, or relevant experience', 'Advanced experience using SQL to extract data from relational databases (Postgres, MySQL, T-SQL, etc.).Proficient in advanced programming languages (Python, R, etc.) for data manipulation, analysis, and visualization in various contexts such as statistical analysis, machine learning, and data mining', 'Demonstrated analytical and problem-solving skills', 'Experience extracting meaning from large data sets', 'Experience building dashboards and reports using business intelligence tools (Tableau, PowerBI, Looker, Metabase, etc.)', 'Exceptional skills in data modeling, statistical analysis, and predictive modeling', 'Ability to think outside the box, constantly seeking new ways to interpret and use data', 'Ability to translate complex data findings into narratives for both technical and non-technical audiences', 'Ability to act as a consultant to help stakeholders create relevant KPIs and understand the meaning behind the data', 'Team management/leadership experience including developing others', 'Bonus Points: Experience working on ETL processes and data modeling']","['In this position, you won’t just be running numbers through a system and handing the results off to someone else', 'You will be running the numbers, understanding the results, and then using the final data sets to direct the company towards impactful moments for our customers', 'Trail Mix BarResponsibilities:Data Analysis Product leader facilitating product planning and prioritization, execution, and reporting for the overall product - incorporating product mindset throughout', 'Primary contact responsible for communication management throughout the organization for Data Analysis Product', 'Effectively communicate complex information to a variety of stakeholders to help inform business decisions', 'Collaborates with the analytics team to plan and scale analytics, working to harvest and grow the data culture across the company', 'Consults stakeholders in the development of KPIs, ad hoc analyses, and automated reporting to best fit their needs and act as a leader in promoting data literacy', 'Works with the data engineering team to plan, build, and maintain data structures to support analysis and reporting needs', 'Conduct complex data analysis to support strategic initiatives, leveraging your unique expertise in analytics tools and statistical methods', 'Leverage advanced SQL and Python/R expertise to wrangle even the most elusive sets of data—capturing trends, patterns, and anomalies', 'Create and maintain beautiful, intuitive business intelligence dashboards, making it easy for teams to see the stories hidden in the data', 'Develop models that help us predict market trends, customer behavior, and data migrations, improving decision-making across the organization', 'Partner with cross-functional teams to understand their data needs, translating these into actionable insights and recommendations', 'Ensure the highest quality and accuracy of all data by developing processes and standards that keep the data pristine']",True,[],,"['SQL', 'Python', 'R', 'Statistical Analysis', 'Predictive Modeling', 'Business Intelligence Tools', 'Data Modeling', 'ETL Processes', 'Data Pipelines', 'Ad Hoc Analysis', 'KPI Development', 'Data Visualization', 'Machine Learning', 'Data Quality Management', 'Jira', 'Confluence']","SQL: Used extensively to extract and manipulate data from relational databases such as Postgres, MySQL, and T-SQL to support analysis and reporting.; Python: Applied for data manipulation, statistical analysis, and building predictive models to uncover trends and support strategic initiatives.; R: Utilized for advanced data analysis, statistical modeling, and visualization to derive insights from complex datasets.; Statistical Analysis: Employed to interpret data patterns and support decision-making through rigorous examination of data sets.; Predictive Modeling: Developed models to forecast market trends, customer behavior, and data migrations to improve organizational decision-making.; Business Intelligence Tools: Used tools like Tableau, PowerBI, Looker, and Metabase to create dashboards and reports that visualize data insights for stakeholders.; Data Modeling: Involved in designing and maintaining data structures to support analysis, reporting, and data quality standards.; ETL Processes: Experience in extracting, transforming, and loading data to ensure clean and usable datasets for analysis.; Data Pipelines: Collaborated with data engineering to build and maintain pipelines that facilitate data flow for analytics and reporting.; Ad Hoc Analysis: Performed customized analyses to address specific business questions and support stakeholder needs.; KPI Development: Consulted with stakeholders to create relevant key performance indicators that align with business objectives.; Data Visualization: Created intuitive visual representations of data to communicate complex findings effectively to technical and non-technical audiences.; Machine Learning: Applied machine learning techniques within Python/R environments to enhance data mining and predictive capabilities.; Data Quality Management: Developed processes and standards to ensure accuracy and integrity of data used across the organization.; Jira: Used for organizing and prioritizing work tickets related to data analysis projects.; Confluence: Utilized as a collaboration tool to document and share best practices within the data analyst team."
OKOzvEm3BJJAS-RpAAAAAA==,Senior Data Analyst,"About Arlo: At Arlo, we're passionate about creating innovative and reliable solutions that help people protect what matters most to them. Our team is dedicated to delivering products that exceed our customers' expectations, while always pushing the boundaries of what's possible in the world of protection technology. We believe that everyone deserves to feel safe and secure, whether they're at home or away, and we're committed to providing our customers with the peace of mind they need to live their lives without worry. Arlo’s deep expertise in AI- and CV-powered analytics, cloud services, user experience, product design, and innovative wireless and RF connectivity enables the delivery of a seamless, smart security experience for Arlo users that is easy to set up and interact with every day. We’re looking for a Senior Data Analyst to join our analytics team. This is a great opportunity for someone with a few years of experience under their belt who’s ready to take on more responsibility and grow their impact in a fast-paced, data-led environment. As a Senior Data Analyst, you’ll work across our product, subscription, and hardware ecosystem to deliver insights that directly influence how we design experiences, retain users, and grow our business. You'll have the space to operate independently on well-scoped projects while learning from experienced analysts and collaborating with product, engineering, and marketing teams across Europe and the US. What You’ll Be Doing Analyse user behavior across our cameras, doorbells, and subscription plans to uncover patterns, identify opportunities, and highlight risks Build dashboards and reports using SQL and tools like Tableau or Looker to track key business metrics, such as: Subscription conversion Monthly active users (MAU) Customer churn Lifetime value (LTV) Average revenue per user (ARPU) Partner with product teams to measure feature performance and run A/B tests Work with our marketing and lifecycle teams to understand campaign performance and customer segmentation Support instrumentation and data QA by partnering with engineers to improve tracking and event quality Share insights with stakeholders through compelling storytelling and clear data visualization What You’ll Bring 7+ years of hands-on experience in a data analyst, BI analyst, or similar role with a bachelor's degree 5+ years with a master's degree or equivalent Strong SQL skills – able to write clean, efficient queries and handle large datasets Experience with data visualization tools: Tableau desired; Looker, Power BI, or equivalent will be considered. A solid grasp of subscription metrics and familiarity with mobile Business-to-Consumer (b2c) audiences. Very comfortable working independently to scope and identify problems, form and execute solutions, and managing your own workflow. Strong communicator – you know how to explain findings to non-technical stakeholders clearly and confidently. Curious, methodical, and interested in how people use technology in everyday life. Ideal to Have: Background in a connected device, smart home, or hardware + SaaS business Exposure to tools like Python or R for deeper analysis or prototyping Experience with event-based analytics tools (e.g. Mixpanel, Amplitude) Familiarity with experimentation frameworks and A/B testing basics The pay range for this position reflects the minimum and maximum target for new hire salaries at commencement of employment and is expected to be between CAD $115,000-170,000/year. However, base pay offered may vary depending on multiple factors, including role, job-related knowledge, skills, relevant education and experience. The total compensation package for this position may also include other elements, including bonus, equity, and a full range of benefits. Details of all benefits will be provided if an employee receives an offer of employment. We’re committed to inclusivity and selecting the strongest candidate—no matter their background. Even if you don’t meet every listed qualification, we encourage you to apply. We’re happy to support growth in areas essential to the role. Interested in learning more about our workplace? Visit and follow our LinkedIn, and Glassdoor pages to read employee insights and get updates of what it’s like to be part of Arlo. Arlo is proud to be an Equal Opportunity Employer. We value inclusion and are committed to inclusive, and harassment-free workplace. We prohibit discrimination and harassment based on all legally protected statuses in all hiring and employment. We provide reasonable accommodations to applicants and employees with disabilities, who are pregnant or have a related medical condition, or who have sincerely held religious beliefs, observances, and practices. Pursuant to applicable state and municipal Fair Chance Laws and Ordinances, the Company will consider for employment qualified applicants with arrest and conviction records. We are a passionate and diverse group of thought leaders, creators, and developers across all disciplines dedicated to changing how people protect and connect with the people and things they love. Our talented employees, located throughout the United States, Canada, Asia, Australia, and Europe communicate, connect and work together to lead the industry in delivering a world-class end-to-end connected lifestyle solution. At every location, passionate and innovative employees work together to shape the future of connectivity. At Arlo, our employees are recognized as central to our business success, now and into the future.",2025-06-25T00:00:00.000Z,2025-07-25,,,True,[],,"['SQL', 'Data Visualization Tools', 'A/B Testing', 'Event-Based Analytics', 'Subscription Metrics', 'Data Quality Assurance', 'Customer Segmentation', 'Python or R']","SQL: Used to write clean, efficient queries and handle large datasets for analysis and reporting.; Data Visualization Tools: Tools like Tableau, Looker, and Power BI are used to build dashboards and reports to track key business metrics and share insights.; A/B Testing: Employed to measure feature performance and understand campaign effectiveness through experimentation frameworks.; Event-Based Analytics: Tools such as Mixpanel and Amplitude are used to analyze user behavior and event tracking data.; Subscription Metrics: Metrics like subscription conversion, monthly active users, customer churn, lifetime value, and average revenue per user are analyzed to drive business decisions.; Data Quality Assurance: Partnering with engineers to improve tracking and event quality ensures reliable data for analysis.; Customer Segmentation: Used to understand marketing campaign performance and target different user groups effectively.; Python or R: Utilized for deeper analysis or prototyping beyond standard SQL and BI tools."
zR9q3DsgnW1GJNv7AAAAAA==,"Senior Data Analyst, Global S&O","Gartner is hiring a Senior Data Analyst, Global S&O with 3 - 5 years of experience. Based in United States - Irving, TX and with Hybrid ways of working.

Job description and responsibilities:

Hiring near our Irving, TX, Stamford CT or Fort Myers, FL - Hybrid Work Environment.

Join our dynamic team within Gartner's Global Strategy and Operations (GSO) division, where innovation meets impact. Our Service Analytics & Productivity team is at the forefront of driving automated data solutions across Gartner’s Global Services & Delivery team, leveraging data to uncover new insights and strategies to enhance productivity and boost client retention. This is your chance to be part of a high-impact analytics team dedicated to automation, problem-solving, and stakeholder management, ultimately delivering significant business outcomes.

Key Responsibilities:
• Strategic Collaboration: Partner with business stakeholders to transform strategic needs into actionable automated data insights, driving informed decision-making across the organization.
• Business Intelligence Development: Design, develop, and maintain robust business intelligence solutions using Power BI, ensuring scalability and stability to support evolving business needs.
• Initiative Leadership: Spearhead automation initiatives to streamline data processes, enhancing business efficiency and agility through innovative solutions
• Stakeholder Management: Cultivate strong relationships with stakeholders by effectively communicating automation strategies and priorities, ensuring alignment and understanding.
• Ethical Standards & Teamwork: Uphold the highest ethical standards while fostering a culture of teamwork and collaboration, contributing to a positive and productive work environment.

Requirements and qualifications:

Qualifications:
• Educational Background: 4-6 years of professional experience with a degree in Engineering, Math, Statistics, or related fields.
• Data Visualization Expertise: Mastery of data visualization techniques and tools for impactful storytelling through dashboards, with a primary focus on Power BI.
• Technical Proficiency: Proficiency in Python and essential libraries such as NumPy and Pandas, with a proven track record of creating efficient ETL processes, preferably in Databricks.
• SQL skills for data extraction and manipulation, enabling the creation of innovative data solutions.
• Problem-Solving Skills: A knack for creative problem-solving, with sharp qualitative and quantitative abilities and a keen eye for detail and accuracy.
• Communication Skills: Exceptional communication skills, with the ability to engage with senior leaders and manage multiple stakeholders effectively.
• Microsoft Office Proficiency: Advanced proficiency in Microsoft Office suite, particularly Excel and PowerPoint, to support data analysis and presentation.",,2025-07-25,"['Gartner is hiring a Senior Data Analyst, Global S&O with 3 - 5 years of experience', 'Educational Background: 4-6 years of professional experience with a degree in Engineering, Math, Statistics, or related fields', 'Data Visualization Expertise: Mastery of data visualization techniques and tools for impactful storytelling through dashboards, with a primary focus on Power BI', 'Technical Proficiency: Proficiency in Python and essential libraries such as NumPy and Pandas, with a proven track record of creating efficient ETL processes, preferably in Databricks', 'SQL skills for data extraction and manipulation, enabling the creation of innovative data solutions', 'Problem-Solving Skills: A knack for creative problem-solving, with sharp qualitative and quantitative abilities and a keen eye for detail and accuracy', 'Communication Skills: Exceptional communication skills, with the ability to engage with senior leaders and manage multiple stakeholders effectively', 'Microsoft Office Proficiency: Advanced proficiency in Microsoft Office suite, particularly Excel and PowerPoint, to support data analysis and presentation']","['This is your chance to be part of a high-impact analytics team dedicated to automation, problem-solving, and stakeholder management, ultimately delivering significant business outcomes', 'Strategic Collaboration: Partner with business stakeholders to transform strategic needs into actionable automated data insights, driving informed decision-making across the organization', 'Business Intelligence Development: Design, develop, and maintain robust business intelligence solutions using Power BI, ensuring scalability and stability to support evolving business needs', 'Initiative Leadership: Spearhead automation initiatives to streamline data processes, enhancing business efficiency and agility through innovative solutions', 'Stakeholder Management: Cultivate strong relationships with stakeholders by effectively communicating automation strategies and priorities, ensuring alignment and understanding', 'Ethical Standards & Teamwork: Uphold the highest ethical standards while fostering a culture of teamwork and collaboration, contributing to a positive and productive work environment']",True,[],,"['Power BI', 'Python', 'NumPy', 'Pandas', 'ETL Processes', 'Databricks', 'SQL', 'Data Visualization', 'Quantitative Analysis', 'Business Intelligence']","Power BI: Used for designing, developing, and maintaining scalable business intelligence dashboards to support decision-making.; Python: Utilized for data processing and automation, including building efficient ETL processes.; NumPy: A Python library employed for numerical computations within data analysis workflows.; Pandas: A Python library used for data manipulation and analysis, supporting the creation of automated data insights.; ETL Processes: Developed and automated to streamline data extraction, transformation, and loading for analytics.; Databricks: Preferred platform for implementing ETL pipelines and managing data workflows.; SQL: Applied for data extraction and manipulation to create innovative data solutions.; Data Visualization: Mastered to create impactful storytelling dashboards that communicate insights effectively.; Quantitative Analysis: Used to support problem-solving and ensure accuracy in data-driven decision-making.; Business Intelligence: Focused on developing automated solutions that drive strategic insights and operational efficiency."
2jQUGnt__tj0nxC2AAAAAA==,Senior Data Analyst,"At Oshkosh, we build, serve and protect people and communities around the world by designing and manufacturing some of the toughest specialty trucks and access equipment. We employ over 18,000 team members all united by a common purpose. Our engineering and product innovation help keep soldiers and firefighters safe, is critical in building and keeping communities clean and helps people do their jobs every day.

SUMMARY:

PLEASE NOTE: This role is an onsite role located in Oshkosh, WI.

As a member of the Data Analyst team, your primary responsibilities will be to identify, collect, process, and analyze datasets to help make informed business decisions. You will also assist with data analysis assignments, projects, visualization tasks, data quality improvements, and troubleshooting of data incidents.

YOUR IMPACT:
• Discover, acquire, explore, prepare, assess and maintain datasets from a variety of data sources (including external sources) to support analyses and ad-hoc investigative requests for project and products covering multiple related functions or related business units
• Perform data analysis assignments, projects, visualization tasks, data quality improvements, and troubleshooting of data incidents, including the resolution of root causes.
• Serve as a Subject Matter Expert in the application of SQL and statistical techniques to the acquisition, enrichment, and analysis of data.
• Resolve and document solutions to track and manage incidents, changes, problems, tasks, and demands
• Review and approve data views, design, and documentation by other team members to ensure governance standards and the utilization of appropriate technical components and techniques.
• Serve as subject matter expert in the process, people, product, data, and systems of related business functions across a variety of business units and/or unrelated business functions within related business units (i.e. Oshkosh Segment)
• Pursue and Define Business Problems & Opportunities
• Propose and Define Relevant Dimensions & Measures
• Collaborating with Data Engineers, draft and test data views to meet business needs for projects and products
• Collaborating with Data Scientists, identify opportunities to incorporate predictive and prescriptive analytics, as well as machine learning and artificial intelligence into projects and products
• Facilitate Conversations to Confirm Problems & Opportunities
• Propose and Align Goals, Roles, and Sustainment Plans with Leaders
• Coaches Leaders on Projects & Programs
• Collaborate with cross-functional teams (e.g. scientists, data engineers, business operations support, consultants) on data needs for business requirements on solutions which may be projects/products focused on a single business function that spans multiple business units or multiple related functions within a single business unit (Medium Complexity)
• Apply technical writing and verbal communication skills to drive the change management (e.g. training plan, communications plan) and on-going management of data solutions.
• Serve as a subject matter expert in Function/Business Unit/Digital Technology participation in Analytics Communities of Practice
• Coach and teach business citizen analysts in building views and in analyzing, interpreting, and communicating data insights.

MINIMUM QUALIFICATIONS:
• Bachelor's degree in Computer Science, Information Systems or equivalent.
• Five (5) or more years of experience in Data Analysis, Information Technology, or in a related area.
• Proficient with various web-based software applications including Power Bi Microsoft Office Word, Excel, PowerPoint, SharePoint, etc.
• Ability to travel 20%
• Experience in data analysis, analytics
• Ability influence and storytelling
• Attention to detail, problem solving, and decision-making skills.
• Advanced Analytical, written, and verbal communication skills.

Pay Range:
$82,000.00 - $132,800.00

The above pay range reflects the minimum and maximum target pay for the position across all U.S. locations. Within this range, individual pay is determined by various factors, including the scope and responsibilities of the role, the candidate's experience, education and skills, as well as the equity of pay among team members in similar positions. Beyond offering a competitive total rewards package, we prioritize a people-first culture and offer various opportunities to support team member growth and success.

Oshkosh is committed to working with and offering reasonable accommodation to job applicants with disabilities. If you need assistance or an accommodation due to disability for any part of the employment process, please contact us at corporatetalentacquisition@oshkoshcorp.com.

Oshkosh Corporation is a merit-based Equal Opportunity Employer. Job opportunities are open for application to all qualified individuals and selection decisions are made without regard to race, color, religion, sex, national origin, age, disability, veteran status, or other protected characteristic. To the extent that information is provided or collected regarding categories as provided by law it will in no way affect the decision regarding an employment application.

Oshkosh Corporation will not discharge or in any manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with Oshkosh Corporation's legal duty to furnish information.

Certain positions with Oshkosh Corporation require access to controlled goods and technologies subject to the International Traffic in Arms Regulations or the Export Administration Regulations. Applicants for these positions may need to be ""U.S. Persons,"" as defined in these regulations. Generally, a ""U.S. Person"" is a U.S. citizen, lawful permanent resident, or an individual who has been admitted as a refugee or granted asylum.",,2025-07-25,"[""Bachelor's degree in Computer Science, Information Systems or equivalent"", 'Five (5) or more years of experience in Data Analysis, Information Technology, or in a related area', 'Proficient with various web-based software applications including Power Bi Microsoft Office Word, Excel, PowerPoint, SharePoint, etc', 'Ability to travel 20%', 'Experience in data analysis, analytics', 'Ability influence and storytelling', 'Attention to detail, problem solving, and decision-making skills', 'Advanced Analytical, written, and verbal communication skills', 'Generally, a ""U.S. Person"" is a U.S. citizen, lawful permanent resident, or an individual who has been admitted as a refugee or granted asylum']","['As a member of the Data Analyst team, your primary responsibilities will be to identify, collect, process, and analyze datasets to help make informed business decisions', 'You will also assist with data analysis assignments, projects, visualization tasks, data quality improvements, and troubleshooting of data incidents', 'Discover, acquire, explore, prepare, assess and maintain datasets from a variety of data sources (including external sources) to support analyses and ad-hoc investigative requests for project and products covering multiple related functions or related business units', 'Perform data analysis assignments, projects, visualization tasks, data quality improvements, and troubleshooting of data incidents, including the resolution of root causes', 'Serve as a Subject Matter Expert in the application of SQL and statistical techniques to the acquisition, enrichment, and analysis of data', 'Resolve and document solutions to track and manage incidents, changes, problems, tasks, and demands', 'Review and approve data views, design, and documentation by other team members to ensure governance standards and the utilization of appropriate technical components and techniques', 'Serve as subject matter expert in the process, people, product, data, and systems of related business functions across a variety of business units and/or unrelated business functions within related business units (i.e', 'Pursue and Define Business Problems & Opportunities', 'Propose and Define Relevant Dimensions & Measures', 'Collaborating with Data Engineers, draft and test data views to meet business needs for projects and products', 'Collaborating with Data Scientists, identify opportunities to incorporate predictive and prescriptive analytics, as well as machine learning and artificial intelligence into projects and products', 'Facilitate Conversations to Confirm Problems & Opportunities', 'Propose and Align Goals, Roles, and Sustainment Plans with Leaders', 'Coaches Leaders on Projects & Programs', 'Collaborate with cross-functional teams (e.g. scientists, data engineers, business operations support, consultants) on data needs for business requirements on solutions which may be projects/products focused on a single business function that spans multiple business units or multiple related functions within a single business unit (Medium Complexity)', 'Apply technical writing and verbal communication skills to drive the change management (e.g. training plan, communications plan) and on-going management of data solutions', 'Serve as a subject matter expert in Function/Business Unit/Digital Technology participation in Analytics Communities of Practice', 'Coach and teach business citizen analysts in building views and in analyzing, interpreting, and communicating data insights']",True,['Artificial Intelligence'],Artificial Intelligence: Identified as a potential area to incorporate into projects and products in collaboration with data scientists.,"['SQL', 'Statistical Techniques', 'Data Visualization', 'Data Quality Improvement', 'Predictive Analytics', 'Prescriptive Analytics', 'Power BI', 'Data Governance', 'Data Collaboration']","SQL: Used as a core tool for data acquisition, enrichment, and analysis to support business decision-making.; Statistical Techniques: Applied to analyze data and improve data quality, supporting investigative requests and troubleshooting.; Data Visualization: Performed to communicate insights and support data analysis assignments and projects.; Data Quality Improvement: Involved in identifying and resolving data incidents to maintain reliable datasets.; Predictive Analytics: Collaborated with data scientists to identify opportunities for incorporating predictive models into projects.; Prescriptive Analytics: Considered alongside predictive analytics to enhance decision-making in business projects.; Power BI: Used as a web-based software application for data visualization and reporting.; Data Governance: Ensured through review and approval of data views, design, and documentation to maintain standards.; Data Collaboration: Worked cross-functionally with data engineers, scientists, and business teams to meet data needs."
ny-9dTFQI_8p29_YAAAAAA==,Sr Data Reporting Analyst,"Use our easy apply form to send your application to Lisa Maloney, the Jobot Pro hosting this job. Compensation Based on Experience.

Sr Data Reporting Analyst

$100000 - $125000 per year | Johnstown, OH | On-Site | Permanent

Hybrid - Sr Data Reporting Analyst for Established Manufacturer - Base + Bonus!

A bit about us:

We are a family owned, international manufacturer and distributor of more than 10,000 automotive and industrial rubber products that support customers in 95 countries. We create and extract value from materials that were formerly considered to be at the end of their useful life. We serve the end-to-end needs of our customers who implement earth-friendly, sustainable solutions using our products.

Why join us?

We offer the following benefits:
• Medical/dental/vision insurance
• 401k with a 4% match that is immediately 100% vested
• Profit sharing plan
• Competitive salary and bonus structure
• 3 weeks of paid time off, 40 hours of sick time, 2 personal days, and 9 paid holidays
• Employee of the quarter with incentives, recognized throughout the year
• A family oriented culture with employee engagement lunches, holiday parties, and more!

Job Details

We are seeking a highly motivated and experienced Sr Data Reporting Analyst to join our dynamic team in the Manufacturing industry. As a Sr Data Reporting Analyst, you will be responsible for analyzing complex data sets, creating insightful reports, and presenting findings to key stakeholders. You will work closely with cross-functional teams to identify business opportunities, develop strategies, and drive business growth.

Responsibilities:

• Analyze complex data sets using SQL and other analytical tools to identify trends, patterns, and insights
• Develop and maintain reports and dashboards using Tableau and Excel to provide actionable insights to stakeholders
• Collaborate with cross-functional teams to understand business requirements and translate them into data-driven solutions
• Develop and maintain data models to support business analysis and reporting
• Create process flow diagrams and visualizations using Visio to improve business processes
• Manage and maintain SharePoint sites and libraries to ensure data accuracy and accessibility
• Provide ERP analyst support to ensure data accuracy and integrity
• Identify opportunities for process improvements and automation to increase efficiency and reduce errors

Qualifications:

• Bachelor's degree in Computer Science, Mathematics, Statistics, or related field
• 3+ years of experience in data analysis, reporting, and visualization
• Proficient in SQL, Tableau, Visio, SharePoint, Excel, and ERP systems
• Strong analytical and problem-solving skills with the ability to work with large data sets
• Excellent communication and presentation skills with the ability to effectively communicate complex data insights to stakeholders
• Strong attention to detail and ability to work independently and in a team environment
• Experience in the Manufacturing industry is a plus

If you are passionate about data analysis, reporting, and visualization and want to work in a fast-paced and dynamic environment, we encourage you to apply for this exciting opportunity as a Sr Data Reporting Analyst in the Manufacturing industry.

Jobot is an Equal Opportunity Employer. We provide an inclusive work environment that celebrates diversity and all qualified candidates receive consideration for employment without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.

Sometimes Jobot is required to perform background checks with your authorization. Jobot will consider qualified candidates with criminal histories in a manner consistent with any applicable federal, state, or local law regarding criminal backgrounds, including but not limited to the Los Angeles Fair Chance Initiative for Hiring and the San Francisco Fair Chance Ordinance.",,2025-07-25,"['We are seeking a highly motivated and experienced Sr Data Reporting Analyst to join our dynamic team in the Manufacturing industry', ""Bachelor's degree in Computer Science, Mathematics, Statistics, or related field"", '3+ years of experience in data analysis, reporting, and visualization', 'Proficient in SQL, Tableau, Visio, SharePoint, Excel, and ERP systems', 'Strong analytical and problem-solving skills with the ability to work with large data sets', 'Excellent communication and presentation skills with the ability to effectively communicate complex data insights to stakeholders', 'Strong attention to detail and ability to work independently and in a team environment', 'Sometimes Jobot is required to perform background checks with your authorization', 'Jobot will consider qualified candidates with criminal histories in a manner consistent with any applicable federal, state, or local law regarding criminal backgrounds, including but not limited to the Los Angeles Fair Chance Initiative for Hiring and the San Francisco Fair Chance Ordinance']","['As a Sr Data Reporting Analyst, you will be responsible for analyzing complex data sets, creating insightful reports, and presenting findings to key stakeholders', 'You will work closely with cross-functional teams to identify business opportunities, develop strategies, and drive business growth', 'Analyze complex data sets using SQL and other analytical tools to identify trends, patterns, and insights', 'Develop and maintain reports and dashboards using Tableau and Excel to provide actionable insights to stakeholders', 'Collaborate with cross-functional teams to understand business requirements and translate them into data-driven solutions', 'Develop and maintain data models to support business analysis and reporting', 'Create process flow diagrams and visualizations using Visio to improve business processes', 'Manage and maintain SharePoint sites and libraries to ensure data accuracy and accessibility', 'Provide ERP analyst support to ensure data accuracy and integrity', 'Identify opportunities for process improvements and automation to increase efficiency and reduce errors']",True,[],,"['SQL', 'Tableau', 'Excel', 'Data Modeling', 'Data Analysis', 'Data Visualization', 'Visio', 'SharePoint', 'ERP Systems']","SQL: Used to analyze complex data sets and extract trends and patterns for reporting and insights.; Tableau: Employed to develop and maintain interactive reports and dashboards for stakeholders.; Excel: Utilized for creating reports and data visualizations to support business analysis.; Data Modeling: Developed and maintained to support business analysis and reporting needs.; Data Analysis: Performed on complex data sets to identify trends, patterns, and actionable insights.; Data Visualization: Created using tools like Tableau, Excel, and Visio to communicate data-driven insights and improve business processes.; Visio: Used to create process flow diagrams and visualizations to enhance understanding of business processes.; SharePoint: Managed to ensure data accuracy and accessibility across teams.; ERP Systems: Supported to maintain data accuracy and integrity within enterprise resource planning environments."
MY7BQj-ZMRRZ-_o6AAAAAA==,Senior Data Analyst,"Summary

World Insurance Associates is a unique insurance organization offering top products and services from major providers, combined with attentive service from local agents.

Founded in 2011, World is one of the fastest-growing insurance brokers in the U.S. with over 2,200 employees in over 260 offices across North America. We specialize in personal and commercial insurance lines, surety and bonding, employee benefits, financial and retirement services, and human capital management solutions.

Our rapid growth and market leading presence has created opportunities throughout the state and we offer top talent the choice to work from one of our multiple offices throughout the region.

Position Overview

This position’s primary responsibility will be to provide technical expertise, coordinate day-to-day deliverables for the data analysis & data governance team, manage junior data analysts, and interpret and analyze large datasets. The candidate should be well versed in the fields of analytics, testing, programming, and development; able to research technologies independently to recommend appropriate solutions & should contribute to technology-specific best practices & standards; contribute to success criteria from design through deployment; contribute expertise on significant application components, program languages, databases, operating systems, testing phases etc.

Key Responsibilities
• Conduct in-depth analysis of large datasets to identify trends, patterns, and anomalies
• Data cleansing and preparation, including cleaning and preprocessing raw data to ensure accuracy and reliability, developing and implement data quality standards and working with a team to integrate and automate data pipelines
• Create and maintain comprehensive dashboards and reports for key performance indicators
• Use visualization tools (e.g., Tableau, Power BI) to present complex data in an understandable format
• Provide training and guidance to junior analysts on data visualization best practices
• Self-motivated with ability to work effectively with limited supervision, enthusiasm for collaboration, continuous learning, and a team player.
• Advanced Excel expertise (pivot tables, VLOOKUPS, Power Pivot, functions, etc.)
• Understand importance of code review and automated testing and different levels at which these need to be performed and write and implement tests as required.
• Bachelor’s degree or foreign equivalent from an accredited institution.

Preferred Qualifications
• Experience in design, development, and deployment of BI solutions using PowerBI (DAX, RLS), Python, Pyspark, Google Big query.
• Knowledge or experience in implementing solutions with Microsoft PowerApps, Power Automate, and/or Common Data Service (Power Platform).
• Data Governance, Data Quality, Master Data Management knowledge.
• 5 years of proven experiences as a data analyst
• 5 years of T-SQL language/query experience with data manipulation (SQL) like stored procedures, functions etc.
• Knowledge of data models, data modelling (Relational and Dimensional), Data profiling and working with large data environments.
• Strong communication, team player and advance analytical skills to analyze data issues and drive appropriate actions with data operations and business processes.

Equal Employment Opportunity

At World Insurance Associates (WIA), we celebrate and support our differences. We know employing a team rich in diverse thoughts, experiences, and opinions allows our employees, our products, and our community to flourish. WIA is honored to be an equal opportunity workplace. We are dedicated to equal employment opportunities regardless of race, color, ancestry, religion, sex, national orientation, age, citizenship, marital status, disability, gender identity, sexual orientation, or Veteran status. In addition, WIA makes reasonable accommodations to known physical or mental limitations of an otherwise qualified applicant or employee with a disability, unless the accommodation would impose an undue hardship on the operation of our business.

To Executive Search Firms And Staffing Agencies

World does not accept unsolicited resumes from any agencies that have not signed a mutual service agreement. All unsolicited resumes will be considered World’s property, and World will not be obligated to pay a referral fee. This includes resumes submitted directly to Hiring Managers without contacting World’s Human Resources Talent Department.",2025-07-05T00:00:00.000Z,2025-07-25,"['The candidate should be well versed in the fields of analytics, testing, programming, and development; able to research technologies independently to recommend appropriate solutions & should contribute to technology-specific best practices & standards; contribute to success criteria from design through deployment; contribute expertise on significant application components, program languages, databases, operating systems, testing phases etc', 'Advanced Excel expertise (pivot tables, VLOOKUPS, Power Pivot, functions, etc.)', 'Bachelor’s degree or foreign equivalent from an accredited institution']","['This position’s primary responsibility will be to provide technical expertise, coordinate day-to-day deliverables for the data analysis & data governance team, manage junior data analysts, and interpret and analyze large datasets', 'Conduct in-depth analysis of large datasets to identify trends, patterns, and anomalies', 'Data cleansing and preparation, including cleaning and preprocessing raw data to ensure accuracy and reliability, developing and implement data quality standards and working with a team to integrate and automate data pipelines', 'Create and maintain comprehensive dashboards and reports for key performance indicators', 'Use visualization tools (e.g., Tableau, Power BI) to present complex data in an understandable format', 'Provide training and guidance to junior analysts on data visualization best practices', 'Self-motivated with ability to work effectively with limited supervision, enthusiasm for collaboration, continuous learning, and a team player', 'Understand importance of code review and automated testing and different levels at which these need to be performed and write and implement tests as required']",True,[],,"['Data Analysis', 'Data Cleansing and Preparation', 'Data Quality Standards', 'Data Pipelines', 'Dashboards and Reporting', 'Business Intelligence Tools', 'Advanced Excel', 'Python', 'PySpark', 'Google BigQuery', 'T-SQL', 'Data Modeling', 'Data Governance', 'Data Quality Management', 'Master Data Management', 'Code Review and Automated Testing', 'Power Platform']","Data Analysis: The role involves interpreting and analyzing large datasets to identify trends, patterns, and anomalies.; Data Cleansing and Preparation: Responsibilities include cleaning and preprocessing raw data to ensure accuracy and reliability.; Data Quality Standards: Developing and implementing standards to maintain high data quality within the team.; Data Pipelines: Integrating and automating data pipelines to streamline data processing workflows.; Dashboards and Reporting: Creating and maintaining dashboards and reports for key performance indicators using BI tools.; Business Intelligence Tools: Using visualization tools such as Tableau and Power BI to present complex data effectively.; Advanced Excel: Utilizing advanced Excel features like pivot tables, VLOOKUP, Power Pivot, and functions for data manipulation.; Python: Preferred experience includes using Python for data analysis and BI solution development.; PySpark: Experience with PySpark for handling large-scale data processing is preferred.; Google BigQuery: Preferred experience with Google BigQuery for querying and managing large datasets.; T-SQL: Five years of experience with T-SQL for data manipulation, including stored procedures and functions.; Data Modeling: Knowledge of relational and dimensional data modeling to structure and organize data effectively.; Data Governance: Involvement in data governance practices to ensure data integrity and compliance.; Data Quality Management: Managing and maintaining data quality as part of governance and operational processes.; Master Data Management: Knowledge of master data management to maintain consistent and accurate core data.; Code Review and Automated Testing: Understanding and implementing code reviews and automated testing to ensure software quality.; Power Platform: Experience with Microsoft PowerApps, Power Automate, and Common Data Service for solution implementation."
HGiZwhznwxKGCuoLAAAAAA==,"BlueSnap, Inc is hiring: Senior Data Analyst in Snowflake","Appnext offers end-to-end discovery solutions covering all the touchpoints users have with their devices. Thanks to Appnext’s direct partnerships with top OEM brands and carriers, user engagement is achieved from the moment they personalize their device for the first time and throughout their daily mobile journey.Appnext ‘Timeline’, a patented behavioral analytics technology, is uniquely capable of predicting the apps users are likely to need next. This innovative solution means app developers and marketers can seamlessly engage with users directly on their smartphones through personalized, contextual recommendations.Established in 2012 and now with 12 offices globally, Appnext is the fastest-growing and largest independent mobile discovery platform in emerging markets.We’re looking for a Senior Data Analyst to join our data-driven team at an ad-tech company that thrives on turning complexity into clarity. Our analysts play a critical role in transforming raw, noisy data into accurate, actionable signals that drive real-time decision-making and long-term strategy. You’ll work closely with product, engineering, and business teams to uncover insights, shape KPIs, and guide performance optimization.Responsibilities:Analyze large-scale datasets from multiple sources to uncover actionable insights and drive business impact.Design, monitor, and maintain key performance indicators (KPIs) across ad delivery, bidding, and monetization systems.Partner with product, engineering, and operations teams to define metrics, run deep-dive analyses, and influence strategic decisions.Develop and maintain dashboards, automated reports, and data pipelines to ensure data accessibility and accuracy.Lead investigative analysis of anomalies or unexpected trends in campaign performance, traffic quality, or platform behavior.RequirementsBA / BSc in Industrial Engineering and Management / Information Systems Engineering / Economics / Statistics / Mathematics / similar background.3+ years of experience in Data Analysis and interpretation (Marketing/ Business/ Product).High proficiency in SQL.Experience with data visualization of large data sets using BI systems (Qlik Sense, Sisense, Tableau, Looker, etc.).Experience working with data warehouse/data lake tools like Athena / Redshift / Snowflake /BigQuery.Knowledge of Python - An advantage.Experience building ETL processes – An advantage.Fluent in English both written and spoken - Must
#J-18808-Ljbffr",2025-07-18T00:00:00.000Z,2025-07-25,"['RequirementsBA / BSc in Industrial Engineering and Management / Information Systems Engineering / Economics / Statistics / Mathematics / similar background.3+ years of experience in Data Analysis and interpretation (Marketing/ Business/ Product)', 'High proficiency in SQL', 'Experience with data visualization of large data sets using BI systems (Qlik Sense, Sisense, Tableau, Looker, etc.).Experience working with data warehouse/data lake tools like Athena / Redshift / Snowflake /BigQuery', 'Knowledge of Python - An advantage', 'Experience building ETL processes – An advantage', 'Fluent in English both written and spoken - Must']","['This innovative solution means app developers and marketers can seamlessly engage with users directly on their smartphones through personalized, contextual recommendations', 'You’ll work closely with product, engineering, and business teams to uncover insights, shape KPIs, and guide performance optimization.Responsibilities:Analyze large-scale datasets from multiple sources to uncover actionable insights and drive business impact.Design, monitor, and maintain key performance indicators (KPIs) across ad delivery, bidding, and monetization systems', 'Partner with product, engineering, and operations teams to define metrics, run deep-dive analyses, and influence strategic decisions', 'Develop and maintain dashboards, automated reports, and data pipelines to ensure data accessibility and accuracy', 'Lead investigative analysis of anomalies or unexpected trends in campaign performance, traffic quality, or platform behavior']",True,[],,"['SQL', 'Data Visualization', 'Data Warehousing', 'ETL Processes', 'Python', 'KPI Design and Monitoring', 'Anomaly Detection']","SQL: Used for querying and managing large-scale datasets to support data analysis and reporting.; Data Visualization: Creating dashboards and reports using BI tools like Qlik Sense, Sisense, Tableau, and Looker to communicate insights effectively.; Data Warehousing: Working with data warehouse and data lake platforms such as Snowflake, Athena, Redshift, and BigQuery to store and access large datasets.; ETL Processes: Building and maintaining data pipelines to extract, transform, and load data for analysis and reporting.; Python: Utilized as a programming language to support data analysis and potentially automate data workflows.; KPI Design and Monitoring: Defining and tracking key performance indicators across ad delivery, bidding, and monetization systems to guide business decisions.; Anomaly Detection: Investigating unexpected trends or anomalies in campaign performance and platform behavior to ensure data quality and optimize outcomes."
SGkqMM25VxWMZYIlAAAAAA==,Senior Health Data Analyst I,"Overview

The Senior Healthcare Data Analyst I contributes to the overall success of the organization bydeveloping analytic solutions that support activities related to health services utilizationmanagement, care coordination, quality improvement and population health. Through analyzingpatient claims, member enrollment, and other data, the Senior Healthcare Data Analystparticipates in identifying progress, performance and opportunities for improvement onprograms, quality of care, patient experience, and other metrics. This position requires athorough understanding of healthcare data and workflows, combined with an extensiveexperience working with large data sets, conducting data analysis, including standard statisticalsoftware (SAS), and creating reports using Tableau.

Responsibilities
• Works collaboratively with business partners, other analysts, and IT to gather andintegrate data from disparate sources.
• Responds to ad hoc data requests from business units and leadership
• Assists in design and development of data collection strategies, aggregation, analysis,and reporting to ensure data integrity and enhance information value.
• Participates in design and interpretation of data analyses; provides recommendations forimprovement of data quality and reporting.
• Helps build, manage, and/or enhance predictive models
• Assesses reporting and automation requirements and develops appropriate solutions.
• Maintains in-depth knowledge of health plan operations, including claims processing,utilization management, quality improvement activities and pay for performance programs.
• Critically analyzes data, draws conclusions and effectively articulates results.
• Presents data and conclusions to non-technical audience; uses data visualizations andsummaries to highlight key findings.
• Creates and maintains thorough and consistent documentation of programs used tocreate reports.
• Manages and prioritizes workload while meeting deliverables and expectations.
• Works autonomously and collaboratively with report requestors, providing guidance todefine report requirements and validate results.
• Works collaboratively across departments to understand and meet the organization’sanalytic needs.

SECONDARY DUTIES AND RESPONSIBILITIES
• Performs other assigned or needed activities required to assure success of theorganization.
• Participates in special projects as needed.
• Performs other duties as assigned.

General Traits
• Passionate about data, willing to acquire new skills and knowledge, flexible, selfmotivated, and very curious.
• Creative problem-solver, critical thinker, independent worker, data-driven mentality.
• Communicates clearly and directly, relates well to others, engages people, provides and seeks feedback, articulates clearly, actively listens.

Qualifications

Education and Experience

Bachelor’s degree with concentration in health informatics, health administration, public health, computing, epidemiology, statistics or related field, Master’s degree preferred. Minimum four (4) years ofexperience in data analysis and reporting. Knowledge of major health plan operations: healthcare claims processing, membership, provider, and benefits; or equivalent combination of education and experience.Excellent knowledge of data collection, analysis, statistics and data presentation with experience in data mining techniques and procedures. Experience using statistical packages for analyzing large data sets, SAS and/or SQL a plus. Experience working with administrative data, ideally health care data (Medicaid data a plus). Understanding of health data formats including claims, lab and pharmacy. Knowledge of clinical coding systems (e.g., ICD9, ICD10, CPT).

Special Skills, Licenses and Certifications

Proficiency in inferential and predictive statistical analysis. MS Office, Excel, SQL, SAS, Tableau.Ability to present complex information in an understandable and compelling manner.

Performance Based Competencies

Ability to quickly acquire in-depth knowledge of various systems related to claims processing, membership, provider, and benefits at PHC. Strong written and oral communication skills with ability to interpret andunderstand technical requirements. Excellent analytical skills to troubleshoot and resolve data issues. Must be highly organized and proficient at multi-tasking. Must be willing and able to provide gracious assistance to users, providers, and other constituents of PHC.

Work Environment And Physical Demands

More than 50% of work time is spent at a video display terminal.

All HealthPlan employees are expected to:
• Provide the highest possible level of service to clients;
• Promote teamwork and cooperative effort among employees;
• Maintain safe practices; and
• Abide by the HealthPlan’s policies and procedures, as they may from time to time be updated.

HIRING RANGE:

$103,059.95 - $133,977.94

IMPORTANT DISCLAIMER NOTICE

The job duties, elements, responsibilities, skills, functions, experience, educational factors and the requirements and conditions listed in this job description are representative only and not exhaustive or definitive of the tasks that an employee may be required to perform. The employer reserves the right to revise this job description at any time and to require employees to perform other tasks as circumstances or conditions of its business, competitive considerations, or work environment change.",,2025-07-25,"['Passionate about data, willing to acquire new skills and knowledge, flexible, selfmotivated, and very curious', 'Creative problem-solver, critical thinker, independent worker, data-driven mentality', 'Minimum four (4) years ofexperience in data analysis and reporting', 'Knowledge of major health plan operations: healthcare claims processing, membership, provider, and benefits; or equivalent combination of education and experience', 'Excellent knowledge of data collection, analysis, statistics and data presentation with experience in data mining techniques and procedures', 'Understanding of health data formats including claims, lab and pharmacy', 'Knowledge of clinical coding systems (e.g., ICD9, ICD10, CPT)', 'Special Skills, Licenses and Certifications', 'Proficiency in inferential and predictive statistical analysis', 'MS Office, Excel, SQL, SAS, Tableau', 'Ability to present complex information in an understandable and compelling manner', 'Ability to quickly acquire in-depth knowledge of various systems related to claims processing, membership, provider, and benefits at PHC', 'Strong written and oral communication skills with ability to interpret andunderstand technical requirements', 'Excellent analytical skills to troubleshoot and resolve data issues', 'Must be highly organized and proficient at multi-tasking', 'Must be willing and able to provide gracious assistance to users, providers, and other constituents of PHC', 'The employer reserves the right to revise this job description at any time and to require employees to perform other tasks as circumstances or conditions of its business, competitive considerations, or work environment change']","['The Senior Healthcare Data Analyst I contributes to the overall success of the organization bydeveloping analytic solutions that support activities related to health services utilizationmanagement, care coordination, quality improvement and population health', 'Through analyzingpatient claims, member enrollment, and other data, the Senior Healthcare Data Analystparticipates in identifying progress, performance and opportunities for improvement onprograms, quality of care, patient experience, and other metrics', 'This position requires athorough understanding of healthcare data and workflows, combined with an extensiveexperience working with large data sets, conducting data analysis, including standard statisticalsoftware (SAS), and creating reports using Tableau', 'Works collaboratively with business partners, other analysts, and IT to gather andintegrate data from disparate sources', 'Responds to ad hoc data requests from business units and leadership', 'Assists in design and development of data collection strategies, aggregation, analysis,and reporting to ensure data integrity and enhance information value', 'Participates in design and interpretation of data analyses; provides recommendations forimprovement of data quality and reporting', 'Helps build, manage, and/or enhance predictive models', 'Assesses reporting and automation requirements and develops appropriate solutions', 'Maintains in-depth knowledge of health plan operations, including claims processing,utilization management, quality improvement activities and pay for performance programs', 'Critically analyzes data, draws conclusions and effectively articulates results', 'Presents data and conclusions to non-technical audience; uses data visualizations andsummaries to highlight key findings', 'Creates and maintains thorough and consistent documentation of programs used tocreate reports', 'Manages and prioritizes workload while meeting deliverables and expectations', 'Works autonomously and collaboratively with report requestors, providing guidance todefine report requirements and validate results', 'Works collaboratively across departments to understand and meet the organization’sanalytic needs', 'SECONDARY DUTIES AND RESPONSIBILITIES', 'Performs other assigned or needed activities required to assure success of theorganization', 'Participates in special projects as needed', 'Performs other duties as assigned', 'Communicates clearly and directly, relates well to others, engages people, provides and seeks feedback, articulates clearly, actively listens', 'Provide the highest possible level of service to clients;', 'Promote teamwork and cooperative effort among employees;', 'Maintain safe practices; and', 'Abide by the HealthPlan’s policies and procedures, as they may from time to time be updated']",True,[],,"['Healthcare Data Analysis', 'Predictive Modeling', 'Statistical Software (SAS)', 'SQL', 'Data Visualization (Tableau)', 'Data Collection and Integration', 'Inferential and Predictive Statistical Analysis', 'Data Mining Techniques', 'Clinical Coding Systems', 'Health Plan Operations Knowledge', 'Data Reporting and Automation', 'Data Documentation']","Healthcare Data Analysis: Analyzing patient claims, member enrollment, and other healthcare data to identify performance and improvement opportunities.; Predictive Modeling: Building, managing, and enhancing predictive models to support health services utilization and quality improvement.; Statistical Software (SAS): Using SAS for conducting statistical analysis on large healthcare datasets.; SQL: Querying and managing healthcare data from disparate sources to support analysis and reporting.; Data Visualization (Tableau): Creating reports and visualizations to present complex healthcare data insights to non-technical audiences.; Data Collection and Integration: Designing and developing strategies to collect, aggregate, and integrate data from multiple sources ensuring data integrity.; Inferential and Predictive Statistical Analysis: Applying statistical methods to draw conclusions and make predictions based on healthcare data.; Data Mining Techniques: Employing data mining procedures to extract valuable insights from large healthcare datasets.; Clinical Coding Systems: Utilizing ICD9, ICD10, and CPT coding systems to interpret and analyze clinical healthcare data.; Health Plan Operations Knowledge: Understanding claims processing, utilization management, and pay-for-performance programs to contextualize data analysis.; Data Reporting and Automation: Developing automated reporting solutions to meet organizational analytic needs efficiently.; Data Documentation: Maintaining thorough documentation of data programs and reports to ensure consistency and reproducibility."
0xpyTuMSpUirqR2vAAAAAA==,Sr. Data Analyst (Excel Modeler) - Locals Only,"Duties:
Develop and maintain complex Excel models for forecasting, planning, and analysis.
Automate data processing and reporting tasks using advanced Excel functions and VBA.
Create dynamic dashboards and visualizations to support decision-making processes.
Ability to consume various data sets and build user friendly excel models for business users.
Develop models to support demand forecasting, supply planning (safety stock/buffer calc.), EOL/NPI Planning and Inventory Reporting.
Assist in the creation of S&OP meeting materials, including data analysis.
Write and optimize SQL queries to extract and manipulate data from various databases (Google Cloud Platform).
Integrate SQL data with Excel models and Tableau to ensure accurate and up-to-date reporting.
Assist in the maintenance and improvement of SQL databases to support business needs.
Ensure data accuracy and consistency across various reporting tools and platforms.
Collaborate with stakeholders to understand requirements and build excel models that can support the business.
Document processes and logic behind automation.

Key Skills:
Advanced proficiency in Excel, including functions, pivot tables, and VBA.
Ability to write SQL Queries
Ability to consume and analyze large sets of data
Understanding of Supply Chain Planning is a plus
Excellent Analytical and Problem-Solving Skills
Strong Communication skills and should be able to collaborate with multiple teams
Knowledge of statistical analysis and forecasting models

Education:
Bachelor's in business, Supply Chain, Data Science or related field",,2025-07-25,"['Advanced proficiency in Excel, including functions, pivot tables, and VBA', 'Ability to write SQL Queries', 'Ability to consume and analyze large sets of data', 'Excellent Analytical and Problem-Solving Skills', 'Strong Communication skills and should be able to collaborate with multiple teams', 'Knowledge of statistical analysis and forecasting models', ""Bachelor's in business, Supply Chain, Data Science or related field""]","['Develop and maintain complex Excel models for forecasting, planning, and analysis', 'Automate data processing and reporting tasks using advanced Excel functions and VBA', 'Create dynamic dashboards and visualizations to support decision-making processes', 'Ability to consume various data sets and build user friendly excel models for business users', 'Develop models to support demand forecasting, supply planning (safety stock/buffer calc.), EOL/NPI Planning and Inventory Reporting', 'Assist in the creation of S&OP meeting materials, including data analysis', 'Write and optimize SQL queries to extract and manipulate data from various databases (Google Cloud Platform)', 'Integrate SQL data with Excel models and Tableau to ensure accurate and up-to-date reporting', 'Assist in the maintenance and improvement of SQL databases to support business needs', 'Ensure data accuracy and consistency across various reporting tools and platforms', 'Collaborate with stakeholders to understand requirements and build excel models that can support the business', 'Document processes and logic behind automation']",True,[],,"['Excel Modeling', 'VBA Automation', 'SQL', 'Tableau', 'Statistical Analysis', 'Data Integration', 'Forecasting Models', 'Data Visualization']","Excel Modeling: Developing and maintaining complex Excel models for forecasting, planning, and analysis to support business decision-making.; VBA Automation: Using VBA to automate data processing and reporting tasks within Excel to improve efficiency.; SQL: Writing and optimizing SQL queries to extract and manipulate data from databases, including Google Cloud Platform.; Tableau: Integrating SQL data with Tableau to create dashboards and visualizations for accurate and up-to-date reporting.; Statistical Analysis: Applying statistical methods and forecasting models to analyze data and support supply chain planning and demand forecasting.; Data Integration: Combining data from SQL databases with Excel models and BI tools to ensure data accuracy and consistency.; Forecasting Models: Developing models to support demand forecasting, supply planning, and inventory reporting.; Data Visualization: Creating dynamic dashboards and visualizations to support decision-making processes."
H_0d6MgIKt-jSxCtAAAAAA==,Senior Data Analyst,"The Scaled Solutions and Insights Data Analyst mission is to empower the Operations Service Center stakeholders with a range of data products and technical solutions to help them gather deeper insights and intelligence to amplify business outcomes in alignment to core priorities and strategic planning.

We are looking for aSenior Data Analyst who is willing to work in a dynamic environment. You will need to be adept at managing business change, evolving requirements, adjustments in a strategic direction, and emerging technologies. This is an amazing opportunity to be at the center of building a showcase worthy data capability, the successful candidates should have proven experience in working with ambiguity, program management, a understanding of business and engineering priorities, analytical, financial, organizational and delivery skills.

Microsoft's mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.

Responsibilities:
• Business and Data Landscape: Apply in-depth knowledge of the business, evolving data landscape, tools, and technologies to link business topics to relevant data sources and external trends. Anticipate data and business requirements, develop data frames and analytical solutions, and identify opportunities to enhance or automate data infrastructure and analyses .
• Customer/Stakeholder Orientation: Understand customer needs and perspectives, validate requirements, and deliver accessible data insights and tools. Build trust by leveraging knowledge of Microsoft products and solutions, interpreting data within relevant contexts, and articulating key details to drive realistic customer expectations.
• Expertise in Data: Applies expertise in data sources, formats, and quality to identify and leverage data across multiple sources, understands data requirements, and evaluates the sufficiency of data for addressing relevant and impactful business questions. Determines and leverages optimal methods and tools for integrating data and proactively works to identify and address data integrity, quality, and/or access issues. Recommends opportunities to build new data pipelines or integrations to better meet requirements, and initiates collaborative action to source additional data. Develops and/or recommends initial/prototype data models and/or tools for others' consumption, leverages relevant data and frameworks from other teams, and escalates complex issues with data or data models to appropriate Engineering or Data-Science teams.
• Data Analysis: Applies expertise in data, business, and customer needs to evaluate and determine ideal analytical and statistical techniques to address business and/or research questions. Guides and establishes partnerships with others to execute complex analyses, resolve analytical challenges, interpret results across relevant contexts, and provide actionable recommendations. Critically evaluates the choice of tools, techniques, and assumptions to highlight potential gaps and ensure they are utilized appropriately within context, that outcomes align with business and/or research needs, and provides feedback on features and functions of analytical tools and/or models. Anticipates the risks of data leakage, analytical tradeoffs, methodological limitations, etc., and can guide teammates on solutions.
• Reporting and Sharing Results: Share insights through dashboards, reports, data visualizations, and interactive self-service platforms. Synthesize and simplify details across analyses to highlight relevant findings and inform business decisions.
• Experimentation and Innovation: Design and execute formal experiments or prototypes to evaluate the impact of new features or processes. Partner cross-functionally to advise on experimental design and evaluation frameworks, and make data-driven recommendations for strategic business goals.
• Improvement and Efficiency: Promote methods for efficient analytics and reporting, automate ad-hoc analyses, and participate in peer reviews to ensure quality and relevance. Recommend and socialize optimal methods for operationalizing, sharing, and scaling insights . Shares critical domain expertise to create clarity, ensure readiness to appropriately consume and leverage data and/or insights, and evaluate the viability of automated methods for use in data collection, reporting, and/or analysis.
• Data Model Evaluation: Understands and evaluates the relationship between analytical model(s) and business objectives , highlight gaps, and present s findings to senior stakeholders. Establish clear linkage between generated data models and desired business objectives . Coaches and mentors less experienced analysts as needed.
• O rchestration and Collaboration: Collaborate with internal stakeholders to ensure quality execution of data sourcing, analysis, and the adoption of best practices. Leverage expertise to identify areas for innovation and address evolving business needs .
• Data Privacy and Governance: Maintain expertise in data privacy and security requirements, ensure compliance with regulations, and enforce standards related to data usage and handling. Guide others to uphold and apply updated data privacy and governance standards.
Other
• E mbody our culture and values

Qualifications:

Required/Minimum Qualifications
• Bachelor's Degree in Statistics, Mathematics, Analytics, Data Science, Engineering, Computer Science, Business, Economics or related field AND 4+ years experience in data analysis and reporting, data science, business intelligence, or business and financial analysis
• *
• OR Master's Degree in Mathematics, Analytics, Engineering, Computer Science, Marketing, Business, Economics or related field AND 2+ years' experience in data analysis and reporting, business intelligence, or business and financial analysis
• OR equivalent experience.
• 4+ years experience managing business change, evolving requirements, adjustments in a strategic direction, OR emerging technologies (ie. Artificial Intelligence).
Additional/ Preferred Qualifications
• Bachelor's Degree in Statistics, Mathematics, Analytics, Engineering, Computer Science, Marketing, Business, Economics or related field AND 6+ years' experience in data analysis and reporting, business intelligence, or business and financial analysis
• * OR Master's Degree in Mathematics, Analytics, Engineering, Computer Science, Marketing, Business, Economics or related field AND 4+ years experience in data analysis and reporting, business intelligence, or business and financial analysis
• OR equivalent experience

Business Analytics IC4 - The typical base pay range for this role across the U.S. is USD $106,400 - $203,600 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $137,600 - $222,600 per year.

Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here: https://careers.microsoft.com/us/en/us-corporate-pay

Microsoft will accept applications for the role until May 30,2025

Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form .

Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.",,2025-07-25,"['You will need to be adept at managing business change, evolving requirements, adjustments in a strategic direction, and emerging technologies', 'This is an amazing opportunity to be at the center of building a showcase worthy data capability, the successful candidates should have proven experience in working with ambiguity, program management, a understanding of business and engineering priorities, analytical, financial, organizational and delivery skills', 'O rchestration and Collaboration: Collaborate with internal stakeholders to ensure quality execution of data sourcing, analysis, and the adoption of best practices', 'Data Privacy and Governance: Maintain expertise in data privacy and security requirements, ensure compliance with regulations, and enforce standards related to data usage and handling', ""Bachelor's Degree in Statistics, Mathematics, Analytics, Data Science, Engineering, Computer Science, Business, Economics or related field AND 4+ years experience in data analysis and reporting, data science, business intelligence, or business and financial analysis"", ""OR Master's Degree in Mathematics, Analytics, Engineering, Computer Science, Marketing, Business, Economics or related field AND 2+ years' experience in data analysis and reporting, business intelligence, or business and financial analysis"", 'OR equivalent experience', '4+ years experience managing business change, evolving requirements, adjustments in a strategic direction, OR emerging technologies (ie']","['The Scaled Solutions and Insights Data Analyst mission is to empower the Operations Service Center stakeholders with a range of data products and technical solutions to help them gather deeper insights and intelligence to amplify business outcomes in alignment to core priorities and strategic planning', 'We are looking for aSenior Data Analyst who is willing to work in a dynamic environment', 'Business and Data Landscape: Apply in-depth knowledge of the business, evolving data landscape, tools, and technologies to link business topics to relevant data sources and external trends', 'Anticipate data and business requirements, develop data frames and analytical solutions, and identify opportunities to enhance or automate data infrastructure and analyses ', 'Customer/Stakeholder Orientation: Understand customer needs and perspectives, validate requirements, and deliver accessible data insights and tools', 'Build trust by leveraging knowledge of Microsoft products and solutions, interpreting data within relevant contexts, and articulating key details to drive realistic customer expectations', 'Expertise in Data: Applies expertise in data sources, formats, and quality to identify and leverage data across multiple sources, understands data requirements, and evaluates the sufficiency of data for addressing relevant and impactful business questions', 'Determines and leverages optimal methods and tools for integrating data and proactively works to identify and address data integrity, quality, and/or access issues', 'Recommends opportunities to build new data pipelines or integrations to better meet requirements, and initiates collaborative action to source additional data', ""Develops and/or recommends initial/prototype data models and/or tools for others' consumption, leverages relevant data and frameworks from other teams, and escalates complex issues with data or data models to appropriate Engineering or Data-Science teams"", 'Data Analysis: Applies expertise in data, business, and customer needs to evaluate and determine ideal analytical and statistical techniques to address business and/or research questions', 'Guides and establishes partnerships with others to execute complex analyses, resolve analytical challenges, interpret results across relevant contexts, and provide actionable recommendations', 'Critically evaluates the choice of tools, techniques, and assumptions to highlight potential gaps and ensure they are utilized appropriately within context, that outcomes align with business and/or research needs, and provides feedback on features and functions of analytical tools and/or models', 'Anticipates the risks of data leakage, analytical tradeoffs, methodological limitations, etc., and can guide teammates on solutions', 'Reporting and Sharing Results: Share insights through dashboards, reports, data visualizations, and interactive self-service platforms', 'Synthesize and simplify details across analyses to highlight relevant findings and inform business decisions', 'Experimentation and Innovation: Design and execute formal experiments or prototypes to evaluate the impact of new features or processes', 'Partner cross-functionally to advise on experimental design and evaluation frameworks, and make data-driven recommendations for strategic business goals', 'Improvement and Efficiency: Promote methods for efficient analytics and reporting, automate ad-hoc analyses, and participate in peer reviews to ensure quality and relevance', 'Recommend and socialize optimal methods for operationalizing, sharing, and scaling insights ', 'Shares critical domain expertise to create clarity, ensure readiness to appropriately consume and leverage data and/or insights, and evaluate the viability of automated methods for use in data collection, reporting, and/or analysis', 'Data Model Evaluation: Understands and evaluates the relationship between analytical model(s) and business objectives , highlight gaps, and present s findings to senior stakeholders', 'Establish clear linkage between generated data models and desired business objectives ', 'Coaches and mentors less experienced analysts as needed', 'Leverage expertise to identify areas for innovation and address evolving business needs ', 'Guide others to uphold and apply updated data privacy and governance standards']",True,[],,"['Data Pipelines', 'Data Analysis', 'Data Models', 'Dashboards and Data Visualization', 'Experimentation and A/B Testing', 'Data Privacy and Governance', 'Business Intelligence', 'Data Quality and Integrity']","Data Pipelines: Recommends and builds new data pipelines or integrations to better meet business requirements and improve data infrastructure.; Data Analysis: Applies analytical and statistical techniques to address business and research questions, guiding complex analyses and interpreting results.; Data Models: Develops, evaluates, and links prototype or analytical data models to business objectives, highlighting gaps and presenting findings.; Dashboards and Data Visualization: Shares insights through dashboards, reports, and interactive self-service platforms to inform business decisions.; Experimentation and A/B Testing: Designs and executes formal experiments or prototypes to evaluate impacts of new features or processes and advise on experimental design.; Data Privacy and Governance: Maintains expertise in data privacy and security requirements, ensuring compliance and enforcing standards related to data usage.; Business Intelligence: Leverages business intelligence tools and methods to deliver accessible data insights and support strategic planning.; Data Quality and Integrity: Identifies and addresses data integrity, quality, and access issues to ensure sufficiency and reliability of data for analysis."
XBuBBdrd6I1FWh3EAAAAAA==,"Senior Data Analyst, Demand Modeling (Revenue Growth Management)","McDonald's is a global leader in the Quick Service Restaurant industry focusing on revenue growth through innovative pricing strategies and advanced analytics. The company is looking for a highly skilled analyst to address complex challenges in revenue management. This role involves managing pricing tests across various markets and utilizing advanced analytical techniques for pricing strategies. Additionally, it includes applying machine learning methods to develop solutions that drive revenue growth.",,2025-07-25,,"['This role involves managing pricing tests across various markets and utilizing advanced analytical techniques for pricing strategies', 'Additionally, it includes applying machine learning methods to develop solutions that drive revenue growth']",True,[],,"['Pricing Tests', 'Advanced Analytical Techniques', 'Machine Learning']",Pricing Tests: Managing and analyzing pricing experiments across markets to optimize revenue strategies.; Advanced Analytical Techniques: Applying sophisticated data analysis methods to inform pricing strategies and revenue growth.; Machine Learning: Using machine learning methods to develop predictive models that support revenue growth initiatives.
dzZVz-TjVghNE55KAAAAAA==,Senior Data Analyst,"Headquartered in Dublin, Ohio, Cardinal Health, Inc. (NYSE: CAH) is a global, integrated healthcare services and products company, providing customized solutions for hospitals, health systems, pharmacies, ambulatory surgery centers, clinical laboratories and physician offices worldwide.
• *Department Overview:**

At Navista, our mission is to empower community oncology practices to deliver patient-centered cancer care. Navista, a Cardinal Health company, is an oncology practice alliance co-created with oncologists and practice leaders that offers advanced support services and technology to help practices remain independent and thrive. True to our name, our experienced team is passionate about helping oncology practices navigate the future.

We are currently hiring for a **Senior Data Analyst** within Navista - Data & Advanced Analytics team to support the growth of our Navista Application Suite and the Integrated Oncology Network (IoN).

The Data & Analytics Function oversees the analytics lifecycle to identify, analyze and present relevant insights that drive business decisions and anticipate opportunities to achieve a competitive advantage. This function manages analytic data platforms, the access, design and implementation of reporting/business intelligence solutions, and the application of advanced quantitative modeling.
• *Job Overview:**

As a **Senior Data Analyst** , you will work cross-functionally to solve problems by performing analysis, recommending solutions, and building analytic products to enable better decision making in the following areas:

+ Revenue Cycle Management

+ Practice Performance Insights

+ Metrics/Performance reporting
• *Responsibilities:**

+ Applies knowledge of business processes, systems, data, and analytical tools to explore and identify root causes of problems.

+ System monitoring to ensure processes are executing as expected and correcting issue to ensure purchase orders and receiving not impacted by errors.

+ Partner with cross-functional project teams to ideate, develop, and recommend solutions. Listen to partners and ask questions to clearly define and document business problems.

+ Perform exploratory analysis to determine root causes of problems and confirm / reject hypotheses.

+ Apply advanced analytics methodologies to model, analyze and clean datasets

+ Recommend ways to improve performance and assist with rationalization of the multi-cloud platform.

+ Summarize the financial and operational impact of the recommendation and pros/cons of alternatives considered.

+ Work with Data Engineers to create data models for analysis, reporting and help create standard reporting of metrics.

+ Lead analytics projects and initiatives that drive meaningful ROI. Guide business teams/partners towards solving their analytical problems.

+ Acts as a mentor to less experienced colleagues

+ Independently determines method for completion of new projects

+ Works on or may lead complex projects of large scope

+ Problem solver, Self-Starter, team player, high EQ.
• *Qualifications:**

Required proven experience in the following:

+ Bachelor's Degree in related field, or equivalent work experience, preferred

+ Strong SQL background required.

+ Multi Cloud experience - GCP, Azure preferred.

+ 8-12 years of experience, preferred

+ 5+ years of experience in Business Intelligence tools such as Power BI preferred.

+ Healthcare analytics, value-based care experience preferred

+ Experience in writing complex SQL queries, stored procedures, etc.

+ Have excellent verbal and oral communication skills

+ Experience in Agile methodologies preferred

+ Experience in Version control and CI/CD pipelines.

+ Oncology data experience preferred

+ RCM experience is a plus
• *Anticipated salary range:** $103,500 - $147,900
• *Bonus eligible:** Yes
• *Benefits:** Cardinal Health offers a wide variety of benefits and programs to support health and well-being.

+ Medical, dental and vision coverage

+ Paid time off plan

+ Health savings account (HSA)

+ 401k savings plan

+ Access to wages before pay day with myFlexPay

+ Flexible spending accounts (FSAs)

+ Short- and long-term disability coverage

+ Work-Life resources

+ Paid parental leave

+ Healthy lifestyle programs
• *Application window anticipated to close:** 7/28/2025 *if interested in opportunity, please submit application as soon as possible.

The salary range listed is an estimate. Pay at Cardinal Health is determined by multiple factors including, but not limited to, a candidate's geographical location, relevant education, experience and skills and an evaluation of internal pay equity.

_Candidates who are back-to-work, people with disabilities, without a college degree, and Veterans are encouraged to apply._

_Cardinal Health supports an inclusive workplace that values diversity of thought, experience and background. We celebrate the power of our differences to create better solutions for our customers by ensuring employees can be their authentic selves each day. Cardinal Health is an Equal_ _Opportunity/Affirmative_ _Action employer. All qualified applicants will receive consideration for employment without regard to race, religion, color, national origin, ancestry, age, physical or mental disability, sex, sexual orientation, gender identity/expression, pregnancy, veteran status, marital status, creed, status with regard to public assistance, genetic status or any other status protected by federal, state or local law._

_To read and review this privacy notice click_ here (https://www.cardinalhealth.com/content/dam/corp/email/documents/corp/cardinal-health-online-application-privacy-policy.pdf)",,2025-07-25,"['Required proven experience in the following:', 'Strong SQL background required', 'Experience in writing complex SQL queries, stored procedures, etc', 'Have excellent verbal and oral communication skills', 'Experience in Version control and CI/CD pipelines', 'Medical, dental and vision coverage', 'Flexible spending accounts (FSAs)', 'Short- and long-term disability coverage', 'Healthy lifestyle programs', '*Application window anticipated to close:*']","['The Data & Analytics Function oversees the analytics lifecycle to identify, analyze and present relevant insights that drive business decisions and anticipate opportunities to achieve a competitive advantage', 'This function manages analytic data platforms, the access, design and implementation of reporting/business intelligence solutions, and the application of advanced quantitative modeling', 'As a **Senior Data Analyst** , you will work cross-functionally to solve problems by performing analysis, recommending solutions, and building analytic products to enable better decision making in the following areas:', 'Revenue Cycle Management', 'Practice Performance Insights', 'Metrics/Performance reporting', 'Applies knowledge of business processes, systems, data, and analytical tools to explore and identify root causes of problems', 'System monitoring to ensure processes are executing as expected and correcting issue to ensure purchase orders and receiving not impacted by errors', 'Partner with cross-functional project teams to ideate, develop, and recommend solutions', 'Listen to partners and ask questions to clearly define and document business problems', 'Perform exploratory analysis to determine root causes of problems and confirm / reject hypotheses', 'Apply advanced analytics methodologies to model, analyze and clean datasets', 'Recommend ways to improve performance and assist with rationalization of the multi-cloud platform', 'Summarize the financial and operational impact of the recommendation and pros/cons of alternatives considered', 'Work with Data Engineers to create data models for analysis, reporting and help create standard reporting of metrics', 'Lead analytics projects and initiatives that drive meaningful ROI', 'Guide business teams/partners towards solving their analytical problems', 'Acts as a mentor to less experienced colleagues', 'Independently determines method for completion of new projects', 'Works on or may lead complex projects of large scope', 'Problem solver, Self-Starter, team player, high EQ']",True,[],,"['SQL', 'Business Intelligence', 'Advanced Analytics', 'Data Modeling', 'Multi-Cloud Platforms', 'Exploratory Data Analysis', 'Revenue Cycle Management Analytics', 'Performance Metrics Reporting', 'Agile Methodologies', 'Version Control and CI/CD Pipelines']","SQL: Used extensively for querying and managing data, including writing complex queries and stored procedures to support analytics and reporting.; Business Intelligence: Involves designing and implementing reporting solutions and dashboards, such as Power BI, to present insights that drive business decisions.; Advanced Analytics: Applied to model, analyze, and clean datasets to identify root causes and recommend solutions for business problems.; Data Modeling: Collaborating with data engineers to create data models that support analysis and standard reporting of key metrics.; Multi-Cloud Platforms: Experience with cloud environments like GCP and Azure to manage and rationalize data infrastructure supporting analytics.; Exploratory Data Analysis: Performing analysis to investigate data, confirm or reject hypotheses, and uncover insights relevant to business challenges.; Revenue Cycle Management Analytics: Analyzing financial and operational data related to revenue cycle processes to improve performance and decision-making.; Performance Metrics Reporting: Developing and maintaining metrics and performance reports to monitor practice performance and operational efficiency.; Agile Methodologies: Utilizing Agile practices to manage analytics projects and collaborate effectively across teams.; Version Control and CI/CD Pipelines: Applying version control and continuous integration/continuous deployment processes to ensure reliable delivery of analytics solutions."
Qu0mEm0SXfGskamgAAAAAA==,Sr. Financial Data Analyst x  100K - 110K + bonus + equity x East LA,"Senior Financial Analyst – Sr. Financial Analyst – Senior Business Analyst – Sr. Business Analyst – SQL – Senior Data Analyst – Salesforce – Alteryx – Power BI – Tableau – Lookr

Are you an experienced data savvy Financial Analyst OR Data Analyst who understands the ins and outs around finance? If so, then we are working on a Senior Financial Data Analyst opportunity that would be a great fit for your skillsets. Read more about the opportunity below!

An East LA start up is looking for a Senior Financial Data Analyst to join their team. Reporting to the VP of Finance, the Senior Financial Data Analyst will be responsible for analyzing large datasets, trend analysis, working with SQL databases, elevating processes, and supporting strategy. To be successful in this Senior Financial Data Analyst role, this person should have executive presentation, be detail-oriented, and be very data analytical. Does this sound like you or someone you know? If so, then please read the Senior Financial Data Analyst full job description below to see if this could be your next role!

What do you need for this Senior Financial Data Analyst role?
• Bachelor’s Degree in Computer Science, Economics, Finance, or related degree
• 4+ years of experience
• MUST be savvy with SQL and Salesforce
• Data visualization software experience is a plus

What will you do in this Senior Financial Data Analyst role?
• Create, upkeep, and verify data integrity, process efficiencies, and related reporting
• Analyze and clean up data to resolve disparities, and verify data integrity, reliability, and accuracy
• Load, change, and take data from multiple areas into our database to be used by finance and accounting teams
• Provide insights and recommendations through data utilization
• Assist with trend forecasts, risk assessment, and financial projections
• Analyze revenue and cost date to create margin analysis for reporting
• Assist with budgeting, forecasting, planning, and resource allocation
• Prepare data visualization and create dashboards
• Conduct cost-benefit analysis and analyze ROI
• Support strategic initiatives with financial evaluations
• Maintain accuracy and organization of data
• Support design of ERP solutions and integrations to maintain data integrity and consistency
• Act as a solutions design and architecture lead while looking for ways to optimize platforms
• Outline and maintain compliance around governance policies for the company’s systems

What is in this Senior Financial Data Analyst role for you?
• Company operates on a unique model within their business
• More than 100 locations and growing
• In series C (and has other funding) and on an exit path
• Unlimited PTO, holiday shut down, 401K match
• Bonus and equity
• Lots of room for growth

So, if you are a financial-minded Data Analyst looking for your next opportunity, then we would like to see your resume for this Senior Financial Data Analyst role. Please send it our way as we would love to connect!",,2025-07-25,"['To be successful in this Senior Financial Data Analyst role, this person should have executive presentation, be detail-oriented, and be very data analytical', 'Bachelor’s Degree in Computer Science, Economics, Finance, or related degree', '4+ years of experience', 'MUST be savvy with SQL and Salesforce']","['Reporting to the VP of Finance, the Senior Financial Data Analyst will be responsible for analyzing large datasets, trend analysis, working with SQL databases, elevating processes, and supporting strategy', 'Create, upkeep, and verify data integrity, process efficiencies, and related reporting', 'Analyze and clean up data to resolve disparities, and verify data integrity, reliability, and accuracy', 'Load, change, and take data from multiple areas into our database to be used by finance and accounting teams', 'Provide insights and recommendations through data utilization', 'Assist with trend forecasts, risk assessment, and financial projections', 'Analyze revenue and cost date to create margin analysis for reporting', 'Assist with budgeting, forecasting, planning, and resource allocation', 'Prepare data visualization and create dashboards', 'Conduct cost-benefit analysis and analyze ROI', 'Support strategic initiatives with financial evaluations', 'Maintain accuracy and organization of data', 'Support design of ERP solutions and integrations to maintain data integrity and consistency', 'Act as a solutions design and architecture lead while looking for ways to optimize platforms', 'Outline and maintain compliance around governance policies for the company’s systems']",True,[],,"['SQL', 'Salesforce', 'Data Visualization', 'Trend Analysis', 'Data Integrity and Cleaning', 'Financial Forecasting', 'Cost-Benefit Analysis', 'Budgeting and Planning', 'ERP Solutions and Integrations', 'Dashboard Tools']","SQL: Used for querying and managing large financial datasets within databases to support analysis and reporting.; Salesforce: Utilized as a CRM platform to manage and analyze customer and financial data relevant to business operations.; Data Visualization: Creating dashboards and visual reports to communicate financial insights and trends effectively.; Trend Analysis: Analyzing historical financial data to identify patterns and support forecasting and strategic decision-making.; Data Integrity and Cleaning: Ensuring accuracy, reliability, and consistency of financial data by resolving disparities and maintaining data quality.; Financial Forecasting: Assisting with predicting future financial performance based on historical data and trend analysis.; Cost-Benefit Analysis: Evaluating financial implications of projects or initiatives to support ROI and resource allocation decisions.; Budgeting and Planning: Supporting financial planning processes including budgeting, forecasting, and resource allocation.; ERP Solutions and Integrations: Supporting the design and integration of enterprise resource planning systems to maintain data consistency and streamline financial processes.; Dashboard Tools: Using BI tools like Power BI, Tableau, or Looker to create interactive financial dashboards for executive reporting."
oZYCoKZJuovlcPk8AAAAAA==,Senior Data Analyst,"Join to apply for the Senior Data Analyst role at HCSS Join to apply for the Senior Data Analyst role at HCSS We’re HCSS . We’re a software company based in Sugar Land, TX and we provide innovative solutions for the construction industry that helps streamline their operations. Our mission at HCSS is helping customers achieve excellence through our proven, customer-centric, end-to-end solutions and exceptionally helpful service, while providing a great life for our employees. With this mission at the forefront of everything we do, we’re recognized as a pioneer and leader in our market and have been recognized for our award-winning culture year after year, earning honors for 16 consecutive years as one of the best places to work in Texas. WHO WE NEED : We are seeking an experienced Senior Data Analyst to lead our data-driven initiatives and drive strategic decision-making across the organization. The ideal candidate will have 5+ years of experience in data analytics , with expertise in advanced data modeling, automation, and business intelligence solutions. This role requires a deep understanding of data architecture, the ability to mentor junior analysts, and strong collaboration with cross-functional teams to deliver impactful insights. Qualifications Bachelor’s or Master’s degree in Business Intelligence, Data Science, Computer Science, Statistics, or a related field. Advanced proficiency in Power BI, including DAX, Power Query, and Power BI Report Builder. Strong SQL skills, with experience in database management, performance tuning, and optimization. Hands-on experience with Microsoft Azure services such as Azure Synapse, Azure Data Factory, and Databricks. Familiarity with CI/CD pipelines and version control systems such as Git for analytics workflow management. Demonstrated ability to translate business requirements into scalable, data-driven solutions and communicate insights effectively to both technical and non-technical stakeholders. Preferred Skills Experience with Python for automation or predictive analytics. Understanding of machine learning techniques, including classification, regression, and clustering. Knowledge of data governance, compliance, and security best practices. Certifications such as Microsoft Certified: Data Analyst Associate or relevant Azure/cloud certifications. Proven ability to coach and mentor junior analysts, fostering a culture of learning and data excellence. What You’ll Do Requirements Gathering – Partner with stakeholders to understand reporting needs and deliver targeted analytical solutions. Data Visualization & Storytelling – Build interactive dashboards that clearly communicate insights and drive action. Data Integration – Work closely with data engineering teams to ensure accurate and consistent data from multiple sources. Data Governance – Maintain high standards of data quality, consistency, and security in reporting and analysis. Collaboration – Engage with cross-functional teams, including product, operations, and leadership, to identify opportunities for data-driven improvement. Continuous Improvement – Stay current with BI and analytics trends, tools, and best practices to enhance team capabilities continuously. BENEFITS & PERKS :Part of our mission statement is to provide a great life for our employees. We believe that happy employees make for a better company, so we take care of them. Here are a few of the perks we offer: Flexibility for you to work in-office, remote or hybrid. Medical and Dental Premiums. On-site amenities include a covered basketball court, soccer field, 200-meter track, etc. 401K with match. Tuition reimbursement. And more! Seniority level Seniority level Mid-Senior level Employment type Employment type Full-time Job function Job function Information Technology Industries Software Development Referrals increase your chances of interviewing at HCSS by 2x Sign in to set job alerts for “Senior Data Analyst” roles. Sr Analyst Supply Chain Data and Analytics Foundation Senior IT Data Specialist - Hybrid Greater Houston $85,000.00-$110,000.00 11 hours ago Middle Office / Business Analyst - Aviation Houston, TX $50,000.00-$80,000.00 3 weeks ago Senior Business Analyst - AOCT Administration Houston, TX $50,200.00-$107,400.00 2 weeks ago Houston, TX $65,000.00-$70,000.00 1 day ago Business Analyst with data modeling and system integration across platforms like RADAR, GMAS, and B Houston, TX $72,821.00-$83,745.00 1 week ago Houston, TX $77,500.00-$131,500.00 14 hours ago Senior Business Analyst - Energy Trading Risk Management Systems Houston, TX $90,000.00-$140,000.00 1 week ago Senior Business Analyst Hybrid Role Fortune 100 CO Direct Hire (Hiring ASAP) Houston, TX $110,000.00-$115,000.00 4 weeks ago Business Analyst - Default Systems and Support - (On - Site) Business Analyst With Oracle JDE/EBS - Full Time Business Analyst - Digital Transformation- Relocate to Saudi Arabia Business Analyst - Hosp Ops - Day Shift - Ben Taub We’re unlocking community knowledge in a new way. Experts add insights directly into each article, started with the help of AI. #J-18808-Ljbffr",2025-07-17T00:00:00.000Z,2025-07-25,,,True,[],,"['Data Modeling', 'Automation', 'Business Intelligence', 'Power BI', 'SQL', 'Microsoft Azure Data Services', 'CI/CD Pipelines', 'Git', 'Python', 'Machine Learning Techniques', 'Data Governance']","Data Modeling: Used to create advanced data structures that support analytics and reporting for strategic decision-making.; Automation: Applied to streamline data processes and improve efficiency in analytics workflows.; Business Intelligence: Involves building dashboards and reports to communicate insights and support business decisions.; Power BI: Primary BI tool used for data visualization, including expertise in DAX, Power Query, and Report Builder.; SQL: Used for database management, querying, performance tuning, and optimization of data retrieval.; Microsoft Azure Data Services: Includes Azure Synapse, Azure Data Factory, and Databricks for data integration and processing.; CI/CD Pipelines: Implemented to manage analytics workflow automation and version control.; Git: Version control system used to manage code and analytics workflow collaboration.; Python: Used for automation and predictive analytics tasks within the data analysis scope.; Machine Learning Techniques: Includes classification, regression, and clustering methods applied for predictive analytics.; Data Governance: Ensures data quality, consistency, compliance, and security in reporting and analysis."
ZtzBT9B1LQq8HckrAAAAAA==,Data Analyst (Senior),"Join to apply for the Data Analyst (Senior) role at ProSoDel (Professional Solutions Delivered, LLC)
2 months ago Be among the first 25 applicants
Join to apply for the Data Analyst (Senior) role at ProSoDel (Professional Solutions Delivered, LLC)
Get AI-powered advice on this job and more exclusive features.
Professional Solutions Delivered, LLC (ProSoDel) is a total solutions provider for government and commercial customers in the areas of Program Management, Logistics, Organizational Change Management, Communications, Training, and Information Technology (IT) Support Services. We are currently seeking a Data Analyst (Senior) to join our team of professionals in support of the USMC MCICOM G-9 Directorate.
Essential Duties & Job Functions
Develop and refine the COLS framework installation function and subfunction capabilities, performance risk levels, and measures (COLS Refresh).
Facilitate the development and implementation of the annual COLS other than labor costing, manpower costing, and performance management data collection efforts, including determining changes, analyzing and updating business rules, obtaining feedback, and responding to information requests.
Determine and manage detailed requirements for refining and developing the LFS Apps COLS Application, ensuring accurate data imports from other systems, and developing reports, splash pages, and dashboards for improved staff review.
Refine and develop the COLS Power BI Dashboard, incorporating analyses and visuals using COLS data, PBIS data, and DAI data for organizational use.
Provide administrative support for managing and maintaining the COLS App and COLS aspects of the Manpower App.
Facilitate COLS functional communities of interest (HQ and regional experts) in refining COLS definitions, cost estimates, and performance data.
Support the development and implementation of the COLS Executive Resource and Risk Management system for MCICOM COLS levels, aiding in leadership reviews and feedback loops.
Analyze COLS OTL and Labor out-year cost estimate data for all organizational levels, ensuring validation, consistency, and decision-making accuracy, coordinated with BOS Study efforts.
Review analytic results with subject matter experts for consistency with empirical data.
Use DoD cost estimation techniques, statistical methods, and cost driver data for analysis.
Recommendations must adhere to MIL-STD-3022 guidelines for VV&A for decision support.
Develop approaches to limit error and implement them as directed.
Analyze COLS cost estimates against PBIS, DAI, and COLS data to validate alignment and improve understanding.
Update and administer COLS 101, COLS App, COLS cost estimates, COLS performance, and training as needed.
Conduct reviews and propose updates to orders, directives, and policies governing COLS programs, ensuring effective communication with G-5 leads.
Facilitate development of the Commander’s Organizational Risk Estimate (CORE) report annually, including tool creation, data collection, training, analysis, and reporting.
Perform related work as assigned.
Job Requirements (Education, Experience, Professional Associations)
Education
Education: Must have at least ten (10) years of relevant experience and a Bachelor’s degree or at least five ( 5) years of experience and a Master’s degree.
Experience
Must be able to travel both CONUS and OCONUS as required/necessary.
Must be skilled in developing executive-level correspondence and management programs involving executive-level participants.
Must have proficiency in briefing and communication skills to senior Military (e.g., O-6 level and above), Military Commanders and their staff, organizational leaders, and peers.
Must have experience working with a diverse and often conflicting group of stakeholders from a cross section of all staff divisions/efforts.
USMC or other Military service experience a HUGE PLUS.
Clearance
Must be a United States Citizen.
Must be able to obtain and maintain a Common Access Card (CAC); active DoD clearance highly desired.
As a condition of employment, employee must successfully complete a background investigation and a drug screen in accordance with all federal, state, and local laws.
Seniority level Seniority level Mid-Senior level
Employment type Employment type Full-time
Job function Job function Information Technology
Industries Defense & Space
Referrals increase your chances of interviewing at ProSoDel (Professional Solutions Delivered, LLC) by 2x
Get notified about new Senior Data Analyst jobs in Arlington, VA .
Senior Data Analyst/VBA(Excel)_Onsite Full time role Chantilly, VA $90,300.00-$189,600.00 2 days ago
Senior Data Analyst - Talent Acquisition Senior Benefits Data & Operations Analyst Washington, DC $85,100.00-$127,700.00 2 days ago
Senior Enterprise Data Analyst - Must hold an active BI/NACLC Public Trust security clearance Washington, DC $115,000.00-$130,000.00 1 month ago
Senior Data Analyst (TRICARE Encounter Data) Sr. Manager, Data Analyst - Small Business Bank Washington, DC $122,000.00-$169,000.00 2 weeks ago
McLean, VA $70,000.00-$78,000.00 2 weeks ago
Manager Data Analyst - Retail Bank, Small Business Bank Senior Business Analyst (Infrastructure) Bethesda, MD $97,000.00-$120,150.00 5 months ago
McLean, VA $115,000.00-$151,500.00 1 week ago
Business Analyst (Technical Writing & Azure Data Focus) Senior Business Systems Analyst, Quote to Cash Washington, DC $135,300.00-$200,400.00 3 days ago
Senior Business Process & Performance Analyst Senior Analyst, Business Process Innovation Senior Analyst, Risk Advisory, Production eDiscovery Specialist Business Intelligence Analyst – Remote (DC Locals Preferred) We’re unlocking community knowledge in a new way. Experts add insights directly into each article, started with the help of AI.
#J-18808-Ljbffr",2025-07-10T00:00:00.000Z,2025-07-25,"['Education: Must have at least ten (10) years of relevant experience and a Bachelor’s degree or at least five ( 5) years of experience and a Master’s degree', 'Must be able to travel both CONUS and OCONUS as required/necessary', 'Must be skilled in developing executive-level correspondence and management programs involving executive-level participants', 'Must have proficiency in briefing and communication skills to senior Military (e.g., O-6 level and above), Military Commanders and their staff, organizational leaders, and peers', 'Must have experience working with a diverse and often conflicting group of stakeholders from a cross section of all staff divisions/efforts', 'USMC or other Military service experience a HUGE PLUS', 'Must be a United States Citizen', 'As a condition of employment, employee must successfully complete a background investigation and a drug screen in accordance with all federal, state, and local laws', 'Seniority level Seniority level Mid-Senior level', 'Senior Enterprise Data Analyst - Must hold an active BI/NACLC Public Trust security clearance Washington, DC $115,000.00-$130,000.00 1 month ago', 'Senior Data Analyst (TRICARE Encounter Data) Sr']","['Develop and refine the COLS framework installation function and subfunction capabilities, performance risk levels, and measures (COLS Refresh)', 'Facilitate the development and implementation of the annual COLS other than labor costing, manpower costing, and performance management data collection efforts, including determining changes, analyzing and updating business rules, obtaining feedback, and responding to information requests', 'Determine and manage detailed requirements for refining and developing the LFS Apps COLS Application, ensuring accurate data imports from other systems, and developing reports, splash pages, and dashboards for improved staff review', 'Refine and develop the COLS Power BI Dashboard, incorporating analyses and visuals using COLS data, PBIS data, and DAI data for organizational use', 'Provide administrative support for managing and maintaining the COLS App and COLS aspects of the Manpower App', 'Facilitate COLS functional communities of interest (HQ and regional experts) in refining COLS definitions, cost estimates, and performance data', 'Support the development and implementation of the COLS Executive Resource and Risk Management system for MCICOM COLS levels, aiding in leadership reviews and feedback loops', 'Analyze COLS OTL and Labor out-year cost estimate data for all organizational levels, ensuring validation, consistency, and decision-making accuracy, coordinated with BOS Study efforts', 'Review analytic results with subject matter experts for consistency with empirical data', 'Use DoD cost estimation techniques, statistical methods, and cost driver data for analysis', 'Recommendations must adhere to MIL-STD-3022 guidelines for VV&A for decision support', 'Develop approaches to limit error and implement them as directed', 'Analyze COLS cost estimates against PBIS, DAI, and COLS data to validate alignment and improve understanding', 'Update and administer COLS 101, COLS App, COLS cost estimates, COLS performance, and training as needed', 'Conduct reviews and propose updates to orders, directives, and policies governing COLS programs, ensuring effective communication with G-5 leads', 'Facilitate development of the Commander’s Organizational Risk Estimate (CORE) report annually, including tool creation, data collection, training, analysis, and reporting', 'Perform related work as assigned']",True,[],,"['Power BI', 'Statistical Methods', 'Data Collection and Analysis', 'Cost Estimation Techniques', 'Dashboards and Reporting', 'Data Validation and Consistency Checks']","Power BI: Used to develop dashboards and visual analytics for organizational data review and decision-making.; Statistical Methods: Applied for analyzing cost estimation data and validating performance metrics within the COLS framework.; Data Collection and Analysis: Involved in gathering and analyzing manpower, labor costing, and performance management data to support organizational risk and resource management.; Cost Estimation Techniques: Used to analyze and validate labor and cost estimates in alignment with DoD standards for decision support.; Dashboards and Reporting: Creation and refinement of reports, splash pages, and dashboards to improve staff review and leadership feedback.; Data Validation and Consistency Checks: Ensuring accuracy and alignment of COLS data with other datasets like PBIS and DAI for reliable decision-making."
DHEqVg1KpOlHVDgLAAAAAA==,Sr Data Analyst Brand Consultant,"The Opportunity:

Do you thrive on uncovering insights through data are a seasoned data storyteller and looking for an exciting career supporting brands like Hot Wheels Barbie and Fisher Price The Product Quality Analytics team is seeking a highly skilled Senior Data Analyst with a strong focus on data storytelling to join our dynamic analytics team that supports global Quality Safety and Sustainability. This role involves collaboration with Global Brand teams Quality Engineering partners and various stakeholders to ensure datadriven decisionmaking and continuous improvement. The ideal candidate will be a relationship builder and excel in translating complex data into insights.

What Your Impact Will Be:
• Prepare and deliver highimpact insights to stakeholders to drive the development of highquality products.
• Data analysis and interpretation: Conduct thorough data analysis to identify key trends patterns and insights and present findings in a clear and visually engaging manner.
• Collaborate with stakeholders: Work closely with crossfunctional teams including Quality Engineering Global Brand teams and leadership understand their data needs and translate them into effective insights for future development.
• Lead defective product returns process: Drive continuous improvement by standardizing workflows assist in tool enhancements for automation standardize documentation of defective analysis and coordination of defective sample disposition.
• Collaborate with Product Quality Analytics team to design and develop selfservice dashboards and implement advanced analytic (AI) solutions.
• Innovation and experimentation: Continuously improving on tools and technologies to introduce new ways to work using AI.
• Project management: Manage multiple projects simultaneously ensuring timely delivery and alignment with business objectives.

Qualifications :

What Were Looking For:
• Experience: Minimum of 2 years of experience in data storytelling and data analysis with a demonstrated success of influence on actionable decisions made through datadriven insights.
• Technical Skills: Tableau knowledge strong analytical and visualization skills. Has a curiosity of AI and what it can do to enhance our capabilities and tools.
• Presentation Skills: Ability to present complex information clearly and concisely while tailoring the narrative to specific needs and knowledge level of the audience. Excellent verbal and written communication skills.
• ProblemSolving: Strong problemsolving skills with the ability to think critically and creatively.
• Team Player: Ability to work collaboratively in a team environment and manage relationships with stakeholders at all levels.
• Demonstrated a growth mindset by staying curious and continuously learning embracing challenges and improving themselves.

The annual base salary range for this position is between $69800 and $87300.
• *This range is indicative of projected hiring range however annual base salary will be determined based on a candidates work location skills and experience. Mattel offers competitive total pay programs comprehensive benefits and resources to help empower a culture where every employee can reach their full potential.

Additional Information :

Dont meet every single requirement At Mattel we are dedicated to an inclusive workplace and a culture of belonging. If youre excited about this role but your past experience doesnt align perfectly with every qualification in the job description we still encourage you to apply. You may be just the right candidate for this or other roles.
How We Work:
We are a purpose driven company aiming to empower generations to explore the wonder of childhood and reach their full potential. We live up to our purpose employing the following behaviors:
• We collaborate: Being a part of Mattel means being part of one team with shared values and common goals. Every person counts and working closely together always brings better results. Partnership is our process and our collective capabilities is our superpower.
• We innovate: At Mattel we always aim to find new and better ways to create innovative products and experiences. No matter where you work in the organization you can always make a difference and have real impact. We welcome new ideas and value new initiatives that challenge conventional thinking.
• We execute: We are a performancedriven company. We strive for excellence and are focused on pursuing bestinclass outcomes. We believe in accountability and ownership and know that our people are at their best when they are empowered to create and deliver results.

Who We Are:
Mattel is a leading global toy and family entertainment company and owner of one of the most iconic brand portfolios in the world. We engage consumers and fans through our franchise brands including Barbie Hot Wheels FisherPrice American Girl Thomas & Friends UNO Masters of the Universe Matchbox Monster High MEGA and Polly Pocket as well as other popular properties that we own or license in partnership with global entertainment companies. Our offerings include toys content consumer products digital and live experiences. Our products are sold in collaboration with the worlds leading retail and ecommerce companies. Since its founding in 1945 Mattel is proud to be a trusted partner in empowering generations to explore the wonder of childhood and reach their full potential.

Mattels awardwinning workplace culture has been recognized by Forbes Fast Company Newsweek Great Place to Work TIME and more.

Visit us at is an Affirmative Action/Equal Opportunity Employer where we want you to bring your authentic self to work every day. We welcome all job seekers and all applicants will receive consideration for employment without regard to race ethnicity color national origin religion sex gender gender identity or expression sexual orientation veteran and protected veteran status disability status and or any other basis protected by applicable federal state or local law.

Pursuant to the Los Angeles Fair Chance Ordinance and the California Fair Chance Act qualified applicants with arrest or conviction records will be considered for employment.

Videos to watch:
The Culture at Mattel
Mattel Investor Highlights

Remote Work :

No

Employment Type :

Fulltime",,2025-07-25,"['The ideal candidate will be a relationship builder and excel in translating complex data into insights', 'Experience: Minimum of 2 years of experience in data storytelling and data analysis with a demonstrated success of influence on actionable decisions made through datadriven insights', 'Technical Skills: Tableau knowledge strong analytical and visualization skills', 'Has a curiosity of AI and what it can do to enhance our capabilities and tools', 'Presentation Skills: Ability to present complex information clearly and concisely while tailoring the narrative to specific needs and knowledge level of the audience', 'Excellent verbal and written communication skills', 'ProblemSolving: Strong problemsolving skills with the ability to think critically and creatively', 'Team Player: Ability to work collaboratively in a team environment and manage relationships with stakeholders at all levels', 'Demonstrated a growth mindset by staying curious and continuously learning embracing challenges and improving themselves']","['Do you thrive on uncovering insights through data are a seasoned data storyteller and looking for an exciting career supporting brands like Hot Wheels Barbie and Fisher Price The Product Quality Analytics team is seeking a highly skilled Senior Data Analyst with a strong focus on data storytelling to join our dynamic analytics team that supports global Quality Safety and Sustainability', 'This role involves collaboration with Global Brand teams Quality Engineering partners and various stakeholders to ensure datadriven decisionmaking and continuous improvement', 'Prepare and deliver highimpact insights to stakeholders to drive the development of highquality products', 'Data analysis and interpretation: Conduct thorough data analysis to identify key trends patterns and insights and present findings in a clear and visually engaging manner', 'Collaborate with stakeholders: Work closely with crossfunctional teams including Quality Engineering Global Brand teams and leadership understand their data needs and translate them into effective insights for future development', 'Lead defective product returns process: Drive continuous improvement by standardizing workflows assist in tool enhancements for automation standardize documentation of defective analysis and coordination of defective sample disposition', 'Collaborate with Product Quality Analytics team to design and develop selfservice dashboards and implement advanced analytic (AI) solutions', 'Innovation and experimentation: Continuously improving on tools and technologies to introduce new ways to work using AI', 'Project management: Manage multiple projects simultaneously ensuring timely delivery and alignment with business objectives']",True,"['Advanced Analytics', 'Artificial Intelligence']",Advanced Analytics: Implementing advanced analytic solutions involving AI to improve tools and capabilities within the Product Quality Analytics team.; Artificial Intelligence: Exploring AI technologies to enhance data analysis and automation processes in product quality and safety.,"['Data Storytelling', 'Data Analysis', 'Data Visualization', 'Tableau', 'Workflow Automation', 'Cross-functional Collaboration', 'Project Management']","Data Storytelling: Used to translate complex data into actionable insights for stakeholders to support decision-making and product quality improvements.; Data Analysis: Conducting thorough analysis to identify key trends, patterns, and insights relevant to product quality and safety.; Data Visualization: Creating clear and visually engaging presentations of data findings to communicate insights effectively.; Tableau: A BI tool used to design and develop self-service dashboards for data visualization and reporting.; Workflow Automation: Enhancing tools to automate processes related to defective product returns and analysis.; Cross-functional Collaboration: Working with various teams such as Quality Engineering and Global Brand teams to align data insights with business needs.; Project Management: Managing multiple analytics projects to ensure timely delivery and alignment with business objectives."
_6FHbm4E5CPyDyMJAAAAAA==,Senior Data Protection Analyst - Cyber,"Are you passionate about technology and interested in joining a community of collaborative colleagues who respectfully and courageously seek to challenge the status quo? If so, read on to learn more about an exciting opportunity with Deloitte Technology US (DT - US). We are curious and life-long learners focused on technology and innovation.

Recruiting for this role ends on 7/31/2025.

Work you'll do

DT-US Cyber Data Protection team is responsible for securing and protecting confidential data of Deloitte US Member Firm, our clients, and our employees. The team's core mission is to implement consistent security controls to protect Firm's data and data entrusted to us by our clients to build their trust and protect our brand. We are seeking an experienced and energetic Senior Data Protection Analyst with outstanding communication, analytical and cyber security technical skills to join our Cyber Data Protection team within Deloitte Technology US (DT - US).

If you're an experienced, hands-on IT professional with strong systems administration, engineering, IT technical support and/or cyber security technical skills who's interested in growing in the cybersecurity field, this may be the job for you. As part of our Cyber Data Protection team, you will be assisting in designing, deploying, and managing cyber technology and process solutions to reduce the potential of data compromise. You will be assisting with testing of data protection and data security solutions. You will work to enhance and mature existing cyber security data protection capabilities for Deloitte US Member Firm and provide on-going support for them. You will require an understanding of the ecosystem of data protection including well-rounded understanding of the information security domains and their inter-relations across that ecosystem. You will be responsible for providing technical product and troubleshooting assistance to Deloitte Employees. You will work closely with management, lead analysts, peers, development teams, business analysts, and end users to ensure data protection technologies and data protection controls for systems are operating appropriately without causing business impact.

As part of the DT- US Cyber Data Protection team, you will have the following core responsibilities:
• Assist with the development, deployment and support of cyber data protection solutions.
• Assist with the implementation of data security controls and design principles.
• Provide Tier 2 technical support to Deloitte end users for several of the cyber data protection services supported by the team that includes but not limited to Data Loss Prevention, Data Minimization, Data Classification and Rights Management, CASB, Web Security, Web Application Firewall, Next Generation Anti-virus and Endpoint Detection and Response technology, Endpoint Admin Rights Management/Privilege Management technology, PKI Certificate Lifecycle Management, Encryption Key Management, Digital Code Signing, Removable Media Protection, Data Discovery Roll Off Scans etc.
• Assist in maturing existing data protection solutions protecting against data exfiltration.
• Assist in rolling out new data protection services to employees, getting them adopted and providing on-going support for those services.
• Assist with technology and software reviews based on data protection and endpoint risks.
• Provide technical engineering and troubleshooting support to employees for data protection services.

Experience working with various data protection technologies:
• Data Loss Prevention (DLP) technology
• Data Classification and Rights Management technology
• Cloud Access Security Broker (CASB)
• Secure Web Gateway/Proxy (SWG) technology
• Next Generation Anti-virus and Endpoint Detection and Response technology
• Endpoint Admin Rights Management/Privilege Management technology
• PKI Certificate Management technology
• Encryption Key Management technology
• Web Application Firewall technology
• Confidential Data Reduction technology
• Data Access Governance technology
• Removable Media Protection technology
• Database Encryption technologies

The team

Deloitte Technology US (DT - US) helps power Deloitte's success, which serves many of the world's largest, most respected organizations. We develop and deploy cutting-edge internal and go-to-market solutions that help Deloitte operate effectively and lead in the market. Our reputation is built on a tradition of delivering with excellence.

The ~3,000 professionals in DT - US deliver services including:
• Cyber Security
• Technology Support
• Technology & Infrastructure
• Applications
• Relationship Management
• Strategy & Communications
• Project Management
• Financials

Cyber Security

Cyber Security vigilantly protects Deloitte and client data. The team leads a strategic cyber risk program that adapts to a rapidly changing threat landscape, changes in business strategies, risks, and vulnerabilities. Using situational awareness, threat intelligence, and building a security culture across the organization, the team helps to protect the Deloitte brand.

Areas of focus include:
• Risk & Compliance
• Identity & Access Management
• Data Protection
• Cyber Design
• Incident Response
• Security Architecture
• Business Partnership

Required Qualifications:
• Bachelor's degree or equivalent in Computer Science or Engineering.
• Minimum 5 years of combined experience in the Information Security/Cybersecurity domain.
• Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future

Preferred Qualifications:
• Experienced with implementing and managing data protection strategies across data at rest, data in motion, and data in use.
• Experience with troubleshooting issues and assisting end users to mitigate technical challenges.
• Familiarity with change management and deployment processes in large IT organizations.
• Working knowledge with common IT technologies such as Windows Server, Linux/Unix, Databases, Active Directory/LDAP, virtualization, end-user devices etc.
• Working knowledge of IT/security principles such as encryption, identity, cloud, etc.
• Experience with PowerShell command-line scripting is a plus.
• Professional security certification desirable, such as Security+ or CISSP.
• Understanding of industry best practices related to risk assessment, mitigation, and incident response.
• Knowledge of data protection regulations and standards (e.g., ISO 27001, ISO 27018, NIST 800-171).
• Understanding of networking and core networking protocols (e.g., TCP/IP, UDP, DNS, SMTP, HTTP, TLS, and distributed networks).
• Knowledge in different types of VPN, Encryption Standards, Certificates.
• Understanding of security controls in public cloud environments (i.e., Amazon Web Services (AWS), Microsoft Azure, Google Cloud Platform) and SaaS services hardening.
• Ability to write technical reports and communicate technical content to business users.
• Self-motivated with a strong willingness to learn and grow with changing cloud technologies.
• Experience working in a virtual team.
• Troubleshooting and problem analysis skills.
• Understanding of information security frameworks, incident management/response, security operations, and application security best practices.
• Competency with Microsoft Windows and/or MacOS Operating Systems

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $84,300 - $173,300.

You may also be eligible to participate in a discretionary annual incentive program, subject to the rules governing the program, whereby an award, if any, depends on various factors, including, without limitation, individual and organizational performance.

Information for applicants with a need for accommodation: https://www2.deloitte.com/us/en/pages/careers/articles/join-deloitte-assistance-for-disabled-applicants.html

EA_ExpHire

RITM9065907

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.",2025-07-17T00:00:00.000Z,2025-07-25,"['Data Loss Prevention (DLP) technology', 'Secure Web Gateway/Proxy (SWG) technology', 'Next Generation Anti-virus and Endpoint Detection and Response technology', 'Endpoint Admin Rights Management/Privilege Management technology', 'PKI Certificate Management technology', 'Encryption Key Management technology', 'Web Application Firewall technology', 'Confidential Data Reduction technology', 'Data Access Governance technology', 'Removable Media Protection technology', 'Database Encryption technologies', 'Identity & Access Management', ""Bachelor's degree or equivalent in Computer Science or Engineering"", 'Minimum 5 years of combined experience in the Information Security/Cybersecurity domain', 'Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future', 'The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs']","['As part of our Cyber Data Protection team, you will be assisting in designing, deploying, and managing cyber technology and process solutions to reduce the potential of data compromise', 'You will be assisting with testing of data protection and data security solutions', 'You will work to enhance and mature existing cyber security data protection capabilities for Deloitte US Member Firm and provide on-going support for them', 'You will require an understanding of the ecosystem of data protection including well-rounded understanding of the information security domains and their inter-relations across that ecosystem', 'You will be responsible for providing technical product and troubleshooting assistance to Deloitte Employees', 'You will work closely with management, lead analysts, peers, development teams, business analysts, and end users to ensure data protection technologies and data protection controls for systems are operating appropriately without causing business impact', 'As part of the DT- US Cyber Data Protection team, you will have the following core responsibilities:', 'Assist with the development, deployment and support of cyber data protection solutions', 'Assist with the implementation of data security controls and design principles', 'Provide Tier 2 technical support to Deloitte end users for several of the cyber data protection services supported by the team that includes but not limited to Data Loss Prevention, Data Minimization, Data Classification and Rights Management, CASB, Web Security, Web Application Firewall, Next Generation Anti-virus and Endpoint Detection and Response technology, Endpoint Admin Rights Management/Privilege Management technology, PKI Certificate Lifecycle Management, Encryption Key Management, Digital Code Signing, Removable Media Protection, Data Discovery Roll Off Scans etc', 'Assist in maturing existing data protection solutions protecting against data exfiltration', 'Assist in rolling out new data protection services to employees, getting them adopted and providing on-going support for those services', 'Assist with technology and software reviews based on data protection and endpoint risks', 'Provide technical engineering and troubleshooting support to employees for data protection services', 'Cloud Access Security Broker (CASB)', 'Strategy & Communications', 'Project Management']",False,[],,"['Data Loss Prevention', 'Data Classification and Rights Management', 'Cloud Access Security Broker', 'Secure Web Gateway', 'Endpoint Detection and Response', 'Endpoint Privilege Management', 'PKI Certificate Management', 'Encryption Key Management', 'Web Application Firewall', 'Confidential Data Reduction', 'Data Access Governance', 'Removable Media Protection', 'Database Encryption', 'Identity and Access Management', 'Encryption', 'Networking Protocols', 'Security Frameworks and Standards', 'PowerShell Scripting']","Data Loss Prevention: Used to prevent unauthorized data exfiltration and protect sensitive information within the organization's cyber data protection framework.; Data Classification and Rights Management: Applied to categorize data and enforce access controls to ensure data security and compliance.; Cloud Access Security Broker: Used to monitor and enforce security policies for cloud services as part of data protection strategies.; Secure Web Gateway: Implemented to protect users from web-based threats and enforce web security policies.; Endpoint Detection and Response: Deployed to detect, investigate, and respond to endpoint security threats as part of cyber data protection.; Endpoint Privilege Management: Used to control and manage administrative rights on endpoints to reduce security risks.; PKI Certificate Management: Manages digital certificates to ensure secure communications and authentication.; Encryption Key Management: Handles the lifecycle of encryption keys to protect data confidentiality.; Web Application Firewall: Protects web applications by filtering and monitoring HTTP traffic to prevent attacks.; Confidential Data Reduction: Techniques used to minimize the amount of sensitive data stored or transmitted to reduce risk.; Data Access Governance: Controls and monitors access to data to ensure compliance with security policies.; Removable Media Protection: Secures data on removable media devices to prevent unauthorized data transfer.; Database Encryption: Encrypts data stored in databases to protect against unauthorized access.; Identity and Access Management: Manages user identities and access rights to secure systems and data.; Encryption: Applied as a fundamental security principle to protect data confidentiality across systems.; Networking Protocols: Knowledge of protocols like TCP/IP, UDP, DNS, SMTP, HTTP, TLS is essential for securing data in transit.; Security Frameworks and Standards: Utilized to guide risk assessment, mitigation, and compliance with regulations such as ISO 27001 and NIST 800-171.; PowerShell Scripting: Used for automating administrative and security tasks within Windows environments."
zKKin4SP6joHQ8cuAAAAAA==,"Senior Data Analyst, Program Integration","Strategy Development: Collaborate with senior management, stakeholders and colleagues to understand business needs, define strategies, identify opportunities and address key challenges. Provide advanced analysis of existing data and structures, consultation, interpretation, and presentation of complex data environments. Develop innovative data-driven solutions for strategic decision-making and business growth.Clinical Program Integration and Evaluation: Evaluate the effectiveness, impact, and use of clinical programs and present to requesting stakeholders. Analyze program performance metrics, key performance indicators (KPIs), and outcome measures to assess program effectiveness and identify areas for improvement.Team Leadership: Provide leadership, guidance, and mentorship to a team of data analysts and data management technicians, fostering a collaborative and high-performance work environment. Assign tasks, set goals, and monitor progress to ensure timely and successful project completion. Lead recruitment, onboarding, training, and professional development efforts for the data team. Supervise full-time staff and student assistants. Technical Expertise: Perform and review complex (senior-level) data analysis and data research work. Provide advanced analysis of existing data and satisfies ad-hoc reporting/analysis requests; serve as a first point of escalation for leadership.Quality Assurance/Compliance: Oversee regular reviews and audits to identify and address data integrity issues. Define, develop, and implement data and reporting standards, best practices, and quality assurance processes to ensure accuracy, consistency, and reliability of analytical findings and deliverables. Implement necessary changes to ensure data quality improvement.Documentation and Reporting: Ensure comprehensive documentation of data analysis methodologies, specifications, tools, processes, and outcomes. Deliver clear, concise, and actionable reports, presentations, and dashboards to communicate analytical findings, key insights, and recommendations to stakeholders at all levels of the organization. Oversee development of technical workflows, project plans, and timelines to ensure scalable data management processes and increase efficiencies across platforms, departments, teams, and institutions.Relationship Management: Build and maintain strong relationships with internal and external stakeholders, foster trust, transparency, and collaboration. Act as a liaison between the data analytics team and other units, clinics, and programs, facilitate communication and resolve conflicts, across the organization. Support continued collaboration with program coordinators and clinical staff, analyze quantitative and qualitative data from satisfaction surveys, focus groups, and other sources to monitor quality, assess fidelity of program implementation, and drive continuous improvement. Represent Dell Medical School in inter-institutional data governance committees and represent DMS TCMHCP at Consortium level.Perform other related duties as assigned.",,2025-07-25,,"['Strategy Development: Collaborate with senior management, stakeholders and colleagues to understand business needs, define strategies, identify opportunities and address key challenges', 'Provide advanced analysis of existing data and structures, consultation, interpretation, and presentation of complex data environments', 'Develop innovative data-driven solutions for strategic decision-making and business growth', 'Clinical Program Integration and Evaluation: Evaluate the effectiveness, impact, and use of clinical programs and present to requesting stakeholders', 'Analyze program performance metrics, key performance indicators (KPIs), and outcome measures to assess program effectiveness and identify areas for improvement', 'Team Leadership: Provide leadership, guidance, and mentorship to a team of data analysts and data management technicians, fostering a collaborative and high-performance work environment', 'Assign tasks, set goals, and monitor progress to ensure timely and successful project completion', 'Lead recruitment, onboarding, training, and professional development efforts for the data team', 'Supervise full-time staff and student assistants', 'Technical Expertise: Perform and review complex (senior-level) data analysis and data research work', 'Provide advanced analysis of existing data and satisfies ad-hoc reporting/analysis requests; serve as a first point of escalation for leadership', 'Quality Assurance/Compliance: Oversee regular reviews and audits to identify and address data integrity issues', 'Define, develop, and implement data and reporting standards, best practices, and quality assurance processes to ensure accuracy, consistency, and reliability of analytical findings and deliverables', 'Implement necessary changes to ensure data quality improvement', 'Documentation and Reporting: Ensure comprehensive documentation of data analysis methodologies, specifications, tools, processes, and outcomes', 'Deliver clear, concise, and actionable reports, presentations, and dashboards to communicate analytical findings, key insights, and recommendations to stakeholders at all levels of the organization', 'Oversee development of technical workflows, project plans, and timelines to ensure scalable data management processes and increase efficiencies across platforms, departments, teams, and institutions', 'Relationship Management: Build and maintain strong relationships with internal and external stakeholders, foster trust, transparency, and collaboration', 'Act as a liaison between the data analytics team and other units, clinics, and programs, facilitate communication and resolve conflicts, across the organization', 'Support continued collaboration with program coordinators and clinical staff, analyze quantitative and qualitative data from satisfaction surveys, focus groups, and other sources to monitor quality, assess fidelity of program implementation, and drive continuous improvement', 'Represent Dell Medical School in inter-institutional data governance committees and represent DMS TCMHCP at Consortium level', 'Perform other related duties as assigned']",True,[],,"['Data Analysis', 'Key Performance Indicators (KPIs)', 'Data Quality Assurance', 'Reporting and Dashboards', 'Data Documentation', 'Data Governance', 'Quantitative and Qualitative Data Analysis']","Data Analysis: Performing and reviewing complex senior-level data analysis and research work to support decision-making and program evaluation.; Key Performance Indicators (KPIs): Analyzing program performance metrics and KPIs to assess effectiveness and identify improvement areas.; Data Quality Assurance: Overseeing reviews and audits to ensure data integrity, accuracy, consistency, and reliability of analytical findings.; Reporting and Dashboards: Delivering clear, actionable reports, presentations, and dashboards to communicate insights to stakeholders.; Data Documentation: Ensuring comprehensive documentation of data analysis methodologies, tools, processes, and outcomes for transparency and reproducibility.; Data Governance: Participating in inter-institutional data governance committees to maintain standards and collaboration across organizations.; Quantitative and Qualitative Data Analysis: Analyzing both quantitative and qualitative data from surveys, focus groups, and other sources to monitor quality and program fidelity."
8ZeIbLlifPuIpR6sAAAAAA==,Sr. Data Privacy Analyst,"Job Description

Location: Open to market areas outside of Dallas/Fort Worth

Your role

We are seeking an experienced Data Protection (Privacy) Senior Analyst to join our organization. The IT function at Digital Realty takes responsibility to manage and secure some of the world’s most critical infrastructure on behalf of our customers. The Data Protection (Privacy) Senior Analyst will be detail-oriented, self-driven and forward-thinking individual who is well versed in implementing and maintaining Data Protection policies and procedures, monitoring compliance with relevant regulatory requirements, analyzing privacy & security risks, and responsible for supporting the IT Data Protection/Privacy maturity efforts. The candidate will work closely with the existing Privacy and Data Governance Programs.

What You’ll Do
• Collaborate closely with the Privacy program, Data Governance and other business functions involved in driving Data Protection requirements at DLR.
• Support with performing privacy impact assessments (PIA) and data mapping activities.
• Assist in ensuring successful and effective execution of IT data protection goals, implementation, as well as exceptional services in ongoing operation of DLR’s IT Data Protection objectives.
• Support the implementation of privacy policies and procedures across the organization and provide guidance to ensure business processes adhere to policies and procedures.
• Works closely with internal stakeholders to evaluate and identify any gaps and supports finding solutions & strategies to ensure full compliance with data protection & privacy regulations and requirements.
• Identifies and reports privacy risks appropriately and assist with the implementation of risk mitigation strategies.
• Support Data Subject Access Requests (DSARs) within the IT organization.
• Assists in the preparation, maintenance, and implementation of data protection policies and standard operating procedures.
• Ensures business strategies, plans and initiatives are driven/delivered in compliance with governing regulations, internal policies, and procedures.
• Participate in projects to verify business practices align with company privacy program including regulatory requirements.
• Facilitates discussions with the business on privacy/data protection Awareness & Requirements, including those relevant to cybersecurity controls.
• Stays abreast of applicable Global, Federal and State privacy Regulations and accreditation standards and monitors advancements in information governance technologies to ensure that they support the Data Protection (Privacy) program and organization in adaptation and compliance efforts.
• Support the development and Implementation of metrics and dashboards for reporting and monitoring the effectiveness of the IT data protection program.
• Completes other duties as assigned.

What You’ll Need
• Bachelor’s degree in computer science, information Technology, Data Science, or related fields.
• 4+ years of experience in a Data Protection or Privacy role or Cybersecurity with a focus on data protection.
• Experience with regulatory compliance frameworks such as GDPR, CCPA, HIPAA, PCI DSS, ISO 27001, SOX, NIST CSF, etc. Ability to support IT assessment and audit efforts is a strong bonus.
• Experience performing Privacy Impact Assessments (PIA) and Data Protection Impact Assessments (DPIA).
• Experience responding to and adhering to Data Subject Access Requests (DSARs).
• Experience implementing privacy design into information systems and recommending appropriate technical design to adequately protect data.
• Experience supporting privacy training and privacy compliance activities.
• Excellent communication and partnering skills.
• Ability to build a strong data protection and privacy culture mindset framed by risk management and operational consistency across technical teams and business units.
• Good project management, multitasking and organizational skills.
• Relevant certifications such as CIPP, CIPT, CIPM, CDPSE, are highly desirable.
• Proficiency in Microsoft Excel, PowerPoint, Power BI and other Microsoft Tools.
• Good understanding of global privacy and data protection regulations and frameworks, such as the GDPR, CCPA, CPRA, HIPAA, NIST, ISO, and more.
• Experience with tools such as OneTrust, Securiti.ai, WireWheel, and BigID across use cases such as data mapping, data discovery, privacy impact assessments, consent/preference management, cookie compliance, data subject rights, and more, is preferred.
• Ability to clearly communicate data protection and privacy issues verbally on both a formal and informal basis to all levels of the organization.
• Possessing a working understanding of risk management, organization-wide compliance programs, and corporate communications.
• Data privacy, governance/risk/ compliance, and/or information security operations background is required.
• Proactivity and an ability to work independently.
• Excellent attention to detail and strong organizational skills.
• A strong technology background is needed.
• Good research skills with an ability to analyze and interpret complex information.
• Understanding of data security in the cloud is desired.

A Bit About Us

Digital Realty supports the world's leading enterprises and service providers by delivering the full spectrum of data center, colocation and interconnection solutions. PlatformDIGITAL®, our global data center platform, gives customers a reliable foundation for scaling their digital business and efficiently managing data gravity challenges. The size and scale of our business puts us in a unique position to offer customers access to 300+ facilities in 50+ metros across 25+ countries and six continents.

A Bit About Our Digital Team

IT

Our IT team is at the heart of our business. We develop infrastructures, design and build networks, support servers and provide the first line of support by delivering rich connectivity for our customers. With new data centers coming online all the time, it’s a rapidly changing technical environment so our team is always ready to innovate and take the lead on projects. We constantly develop, deploy and support vital networks and data services that drive business performance and improve life for customers around the globe.

What We Can Offer You

Our rapidly evolving business sector offers the opportunity to be part of a courageous and passionate team who work together to understand and meet the changing needs of our global customers.

Join us and you’ll be part of a supportive and inclusive environment where you can bring your whole self to work. As part of our team, you’ll get to work with people from different business areas, challenge the way we do things and put your ideas into action. We’ll also give you plenty of development opportunities so you can build a rewarding and successful career with us.

Our Compensation Philosophy

Digital Realty offers its employees a highly competitive compensation package, excellent benefits, and an environment that recognizes and rewards your contributions. Central to our compensation philosophy is rewarding our employees for achieving the values and objectives aligned to the company's overall goals and values.

This is an exciting time to join our business so apply now and make your mark on our future.

Notes

The above statements are intended to describe the general nature and level of work being performed by people assigned to this job. They are not intended to be an exhaustive list of all responsibilities, duties, and skills required of personnel so classified.

Digital Realty is an equal opportunity employer, EOE/AA/M/F/Vets/Disabled. All applicants will receive consideration for employment and will not be discriminated against on the basis of race, color, religion, sex, sexual orientation, gender identity, age, national origin, disability or protected veteran status, or other status protected by law or Company policy.

Digital Realty is a publicly traded company (NYSE: DLR) with investment grade ratings from all three major ratings agencies.

Please do not forward unsolicited resumes to any employee of Digital Realty and its subsidiaries. Digital Realty is not responsible for any fees related to unsolicited referrals.",2025-07-17T00:00:00.000Z,2025-07-25,"['Bachelor’s degree in computer science, information Technology, Data Science, or related fields', '4+ years of experience in a Data Protection or Privacy role or Cybersecurity with a focus on data protection', 'Experience with regulatory compliance frameworks such as GDPR, CCPA, HIPAA, PCI DSS, ISO 27001, SOX, NIST CSF, etc', 'Ability to support IT assessment and audit efforts is a strong bonus', 'Experience performing Privacy Impact Assessments (PIA) and Data Protection Impact Assessments (DPIA)', 'Experience responding to and adhering to Data Subject Access Requests (DSARs)', 'Experience implementing privacy design into information systems and recommending appropriate technical design to adequately protect data', 'Experience supporting privacy training and privacy compliance activities', 'Excellent communication and partnering skills', 'Ability to build a strong data protection and privacy culture mindset framed by risk management and operational consistency across technical teams and business units', 'Good project management, multitasking and organizational skills', 'Proficiency in Microsoft Excel, PowerPoint, Power BI and other Microsoft Tools', 'Good understanding of global privacy and data protection regulations and frameworks, such as the GDPR, CCPA, CPRA, HIPAA, NIST, ISO, and more', 'Ability to clearly communicate data protection and privacy issues verbally on both a formal and informal basis to all levels of the organization', 'Possessing a working understanding of risk management, organization-wide compliance programs, and corporate communications', 'Data privacy, governance/risk/ compliance, and/or information security operations background is required', 'Proactivity and an ability to work independently', 'Excellent attention to detail and strong organizational skills', 'A strong technology background is needed', 'Good research skills with an ability to analyze and interpret complex information']","['The Data Protection (Privacy) Senior Analyst will be detail-oriented, self-driven and forward-thinking individual who is well versed in implementing and maintaining Data Protection policies and procedures, monitoring compliance with relevant regulatory requirements, analyzing privacy & security risks, and responsible for supporting the IT Data Protection/Privacy maturity efforts', 'The candidate will work closely with the existing Privacy and Data Governance Programs', 'Collaborate closely with the Privacy program, Data Governance and other business functions involved in driving Data Protection requirements at DLR', 'Support with performing privacy impact assessments (PIA) and data mapping activities', 'Assist in ensuring successful and effective execution of IT data protection goals, implementation, as well as exceptional services in ongoing operation of DLR’s IT Data Protection objectives', 'Support the implementation of privacy policies and procedures across the organization and provide guidance to ensure business processes adhere to policies and procedures', 'Works closely with internal stakeholders to evaluate and identify any gaps and supports finding solutions & strategies to ensure full compliance with data protection & privacy regulations and requirements', 'Identifies and reports privacy risks appropriately and assist with the implementation of risk mitigation strategies', 'Support Data Subject Access Requests (DSARs) within the IT organization', 'Assists in the preparation, maintenance, and implementation of data protection policies and standard operating procedures', 'Ensures business strategies, plans and initiatives are driven/delivered in compliance with governing regulations, internal policies, and procedures', 'Participate in projects to verify business practices align with company privacy program including regulatory requirements', 'Facilitates discussions with the business on privacy/data protection Awareness & Requirements, including those relevant to cybersecurity controls', 'Stays abreast of applicable Global, Federal and State privacy Regulations and accreditation standards and monitors advancements in information governance technologies to ensure that they support the Data Protection (Privacy) program and organization in adaptation and compliance efforts', 'Support the development and Implementation of metrics and dashboards for reporting and monitoring the effectiveness of the IT data protection program', 'Completes other duties as assigned']",False,[],,"['Privacy Impact Assessment', 'Data Protection Impact Assessment', 'Data Subject Access Requests', 'Data Mapping', 'Regulatory Compliance Frameworks', 'Risk Management', 'Data Governance', 'Privacy Policies and Procedures', 'Metrics and Dashboards', 'Microsoft Power BI', 'OneTrust', 'Securiti.ai', 'WireWheel', 'BigID', 'Microsoft Excel', 'Microsoft PowerPoint']","Privacy Impact Assessment: Used to evaluate privacy risks and compliance in data protection processes as part of the job responsibilities.; Data Protection Impact Assessment: Performed to assess and mitigate risks related to data protection in IT systems.; Data Subject Access Requests: Handling and responding to DSARs to comply with privacy regulations.; Data Mapping: Supporting data mapping activities to understand data flows and ensure compliance with privacy policies.; Regulatory Compliance Frameworks: Experience with GDPR, CCPA, HIPAA, PCI DSS, ISO 27001, SOX, NIST CSF to ensure data protection and privacy compliance.; Risk Management: Analyzing privacy and security risks and implementing mitigation strategies within data protection programs.; Data Governance: Collaborating with data governance programs to drive data protection requirements and compliance.; Privacy Policies and Procedures: Implementing and maintaining privacy policies to ensure organizational adherence to data protection standards.; Metrics and Dashboards: Developing and implementing reporting tools to monitor the effectiveness of IT data protection programs.; Microsoft Power BI: Utilized for creating dashboards and reports to support data protection monitoring.; OneTrust: Used as a tool for data mapping, privacy impact assessments, and managing privacy compliance.; Securiti.ai: Applied for data discovery, consent management, and privacy compliance activities.; WireWheel: Employed for privacy management including data subject rights and cookie compliance.; BigID: Used for data discovery and privacy impact assessments to support data protection efforts.; Microsoft Excel: Used for data analysis and reporting related to privacy and data protection.; Microsoft PowerPoint: Used to communicate data protection and privacy issues across the organization."
WBpigE1EQGpRhE3aAAAAAA==,Senior Data Scientist,"Company Description

By working at Harvard University, you join a vibrant community that
advances Harvard's world-changing mission in meaningful ways,
inspires innovation and collaboration, and builds skills and
expertise. We are dedicated to creating a diverse and welcoming
environment where everyone can thrive.

Why join the Harvard Graduate School of Education?

The Harvard Graduate School of Education (HGSE) is a diverse
community of learners, teachers, and employees who are passionate
about changing the world through education and striving for maximum
impact in the field of education.

Many choose to work at the Harvard Graduate School of Education
because they believe in our mission and are excited by our vision
for the future. We have a reputation as a great place to work, for
our excellent leadership, and we are a strong community that values
diversity. For more information about HGSE, its programs, research,
and faculty, please visit: www.gse.harvard.edu .

Job Description

Job Summary:

Design, plan, and implement software and data services that support
and enrich research productivity and reliability. Develop software
and data services with researchers to ensure that modern standards
of reproducible research are kept.

Position Description:

HGSE is a diverse community of learners, teachers, and
employees who are passionate about changing the world through
education and striving for maximum impact in the field of
education. The Senior Data Scientist at the Center for Education
Policy Research (CEPR) at Harvard University leads statistical
programming, collaborates with Principal Investigators to develop
advanced models and analysis tools, develops data architecture and
data processing pipelines, works with multiple stakeholders and
develops visualizations to communicate key findings to
non-technical audiences, and advises projects on state-of-the-art
software and data solutions to support the research. CEPR partners
with school districts, charter school networks, and state education
agencies to bring high quality research methods and data analysis
to bear on strategic management and policy decisions. We believe
that (1) policy and management decisions directly influence the
ability of schools and teachers to improve student achievement; and
(2) valid and reliable data analysis significantly improves the
quality of decision-making. We design our work around the theory of
action that if we bring together the right people, the right data,
and the right analysis, significantly better decision-making will
occur, and student outcomes will be improved.

The Senior Data Scientist reports to CEPR’s Director of Research
who will identify specific projects and tasks that would benefit
from the Senior Data Scientist’s expertise.

Job-Specific Responsibilities:
• Develops advanced models and performs complex statistical
programming to support the research.
• Advises research projects on state-of-the-art technical
solutions to analytic and data challenges.
• Translates complex analyses for policy and practitioner
audiences and develop visualizations that help people understand
key findings and new insights.
• Mentors research analysts on statistical programming and
informally supervise the analyst on any tasks that the Senior Data
Scientist assigns to them.
• Serves as a resource to the team for computer programming and
statistics. Occasionally, group training on specific tools or
models.
• Builds internal code design and development guides for future
contributors,
• Conducts quality assurance to ensure the reproducibility of
analyses, documentation of methods and algorithms, and use of
appropriate statistical tests.
• Collaborates with Principal Investigators and Project Directors
to develop research plans and statistical analyses.
• Contributes to papers and reports.

Please Note: Any candidate wishing to be considered must supply
a cover letter in addition to their resume showing that they meet
the required basic qualifications. Any candidate invited to an
initial round of interview will be asked to submit a sample
program. Any candidate invited to a second round of interview will
be asked to complete a case. This is a one-year term position from
the date of hire, with the possibility of extension, contingent
upon work performance and continued funding to support the
position.

Physical Requirements:

Working Conditions:

HGSE is currently developing dynamic workplace models which will
actively support a combination of on-campus and remote work (within
a state in which Harvard is registered to do business) where
business and operational needs allow. You and your manager will
discuss the best schedule based on your role and operational need.
If your role allows for remote work, please note that all remote
work must be performed within a state in which Harvard is
registered to do business (CA (Only Exempt), CT, GA, IL, MA, MD,
ME, NH, NJ, NY, RI, VA, VT, and WA). Please also note that Harvard
will withhold each applicable state’s required tax and other
withholdings from your paycheck for the time you work there.

The health of our workforce is a priority for Harvard University.
With that in mind, we strongly encourage all employees to be
up-to-date on CDC-recommended vaccines.

We regret that the Harvard Graduate School of Education does not
provide Visa sponsorship.

Qualifications

Basic Qualifications:
• Minimum of seven years’ post-secondary education or relevant
work experience

Additional Qualifications and Skills:

Bachelor’s degree in computer science, Statistics, Data Science,
Economics, Mathematics, or a related field.

7+ years of relevant experience or post-secondary education.

3+ years’ experience in advanced statistical programming using
Stata or R.

Additional Qualifications and Skills:

Master’s degree preferred.

5+ years experience in statistical programming preferred.

3+ years experience supporting social science research projects
preferred.

Experience with Bayesian estimation, machine learning, natural
language processing, cloud-based computing, and/or Artificial
Intelligence strongly preferred.

Experience with managing and analyzing large datasets, scaling
processes, developing data architectures, and developing R packages
preferred.

Experience with version control software (such as Git), code
reviews, and unit testing preferred.

Ability to translate technical topics for non-technical audiences
and to develop analyses and visualizations that convey key findings
clearly.

Demonstrated creative ability to solve challenges in novel ways
using state-of-the-art statistical and data processing
techniques.

Experience working with K-12 or postsecondary education data a
plus.

Certificates and Licenses:

Additional Information
• Standard Hours/Schedule: 35 hours per week
• Visa Sponsorship Information: Harvard University is
unable to provide visa sponsorship for this position
• Pre-Employment Screening:Education,Identity
• Other Information:

HGSE Human Resources values diversity in all forms and believes
that each employee brings a set of diverse experiences and
identities to the workplace that makes us stronger, encourages
innovation, and enhances our collective contributions. We continue
to develop and support a workforce that reflects the diversity of
those we serve; fosters an environment that allows everyone to
belong and to bring their best self to work; and creates the
conditions that empower employees to contribute their full
potential to advancing the work of the school.

We do this by:
• Hiring and retaining staff reflecting the diversity of those we
serve
• Providing employees opportunities to learn, grow, and be
challenged
• Reviewing and ensuring fairness and equity in HR practices and
policies including but not limited to hiring, promotion, and
compensation
• Developing strong relationships and partnerships internal and
external to our community to advance diversity and inclusion
• Communicating transparently and respectfully; and
• Fostering an inclusive, respectful, and professional work
environment

About the Harvard Graduate School of Education

Many choose to work at the Harvard Graduate School of Education
because they believe in our mission and are excited by our vision
for the future. We have a reputation as a great place to work, for
our excellent leadership, and we are a strong community that values
diversity. For more information about HGSE, its programs, research,
and faculty, please visit: www.gse.harvard.edu

Work Format Details

This is a position that is based at a Harvard campus location with
some remote work options available. Additional details will be
discussed during the interview process. All remote work must be
performed within one of the Harvard Registered Payroll States,
which currently includes Massachusetts, Connecticut, Maine, New
Hampshire, Rhode Island, Vermont, Georgia, Illinois, Maryland, New
Jersey, New York, Virginia, Washington, and California (CA for
exempt positions only). Certain visa types and funding sources may
limit work location. Individuals must meet work location
sponsorship requirements prior to employment.

Salary Grade and Ranges

This position is salary grade level 058. Please visit  Harvard's Salary Ranges
  to view the corresponding salary range and related
information.

Benefits

Harvard offers a comprehensive benefits package that is designed to
support a healthy work-life balance and your physical, mental and
financial wellbeing. Because here, you are what matters. Our
benefits include, but are not limited to:
• Generous paid time off including parental leave
• Medical, dental, and vision health insurance coverage starting
on day one
• Retirement plans with university contributions
• Wellbeing and mental health resources
• Support for families and caregivers
• Professional development opportunities including tuition
assistance and reimbursement
• Commuter benefits, discounts and campus perks

Learn more about these and additional benefits on our Benefits &
Wellbeing Page .

EEO/Non-Discrimination Commitment Statement

Harvard University is committed to
equal opportunity and
non-discrimination . We seek talent from all parts of society
and the world, and we strive to ensure everyone at Harvard thrives.
Our differences help our community advance Harvard’s academic
purposes.

Harvard has an
equal employment opportunity policy that outlines our
commitment to prohibiting discrimination on the basis of race, sex,
ethnicity, color, national origin, religion, disability, or any
other characteristic protected by law or identified in the
university’s
non-discrimination policy . Harvard’s
equal employment opportunity policy and
non-discrimination policy help all community members
participate fully in work and campus life free from harassment and
discrimination.",2025-07-16T00:00:00.000Z,2025-07-25,"['ability of schools and teachers to improve student achievement; and', '(2) valid and reliable data analysis significantly improves the', 'a state in which Harvard is registered to do business) where', 'business and operational needs allow', 'work must be performed within a state in which Harvard is', 'registered to do business (CA (Only Exempt), CT, GA, IL, MA, MD,', 'Minimum of seven years’ post-secondary education or relevant', 'Bachelor’s degree in computer science, Statistics, Data Science,', 'Economics, Mathematics, or a related field', '7+ years of relevant experience or post-secondary education', '3+ years’ experience in advanced statistical programming using', 'Stata or R', '3+ years experience supporting social science research projects', 'Experience with Bayesian estimation, machine learning, natural', 'language processing, cloud-based computing, and/or Artificial', 'Experience with managing and analyzing large datasets, scaling', 'processes, developing data architectures, and developing R packages', 'Experience with version control software (such as Git), code', 'Ability to translate technical topics for non-technical audiences', 'Demonstrated creative ability to solve challenges in novel ways', 'using state-of-the-art statistical and data processing', 'Experience working with K-12 or postsecondary education data a', 'Visa Sponsorship Information: Harvard University is', 'Reviewing and ensuring fairness and equity in HR practices and']","['about changing the world through education and striving for maximum', 'Design, plan, and implement software and data services that support', 'and enrich research productivity and reliability', 'Develop software', 'and data services with researchers to ensure that modern standards', 'of reproducible research are kept', 'education and striving for maximum impact in the field of', 'programming, collaborates with Principal Investigators to develop', 'advanced models and analysis tools, develops data architecture and', 'data processing pipelines, works with multiple stakeholders and', 'develops visualizations to communicate key findings to', 'non-technical audiences, and advises projects on state-of-the-art', 'software and data solutions to support the research', 'agencies to bring high quality research methods and data analysis', 'to bear on strategic management and policy decisions', 'We design our work around the theory of', 'and the right analysis, significantly better decision-making will', 'occur, and student outcomes will be improved', 'The Senior Data Scientist reports to CEPR’s Director of Research', 'who will identify specific projects and tasks that would benefit', 'Develops advanced models and performs complex statistical', 'programming to support the research', 'Advises research projects on state-of-the-art technical', 'solutions to analytic and data challenges', 'Translates complex analyses for policy and practitioner', 'audiences and develop visualizations that help people understand', 'Mentors research analysts on statistical programming and', 'informally supervise the analyst on any tasks that the Senior Data', 'Scientist assigns to them', 'Serves as a resource to the team for computer programming and', 'Occasionally, group training on specific tools or', 'Builds internal code design and development guides for future', 'Conducts quality assurance to ensure the reproducibility of', 'analyses, documentation of methods and algorithms, and use of', 'appropriate statistical tests', 'Collaborates with Principal Investigators and Project Directors', 'to develop research plans and statistical analyses', 'Contributes to papers and reports', 'upon work performance and continued funding to support the', 'HGSE is currently developing dynamic workplace models which will', 'actively support a combination of on-campus and remote work (within', 'discuss the best schedule based on your role and operational need', 'If your role allows for remote work, please note that all remote', 'will withhold each applicable state’s required tax and other', 'and to develop analyses and visualizations that convey key findings', 'Standard Hours/Schedule: 35 hours per week', 'conditions that empower employees to contribute their full', 'Providing employees opportunities to learn, grow, and be', 'Developing strong relationships and partnerships internal and', 'external to our community to advance diversity and inclusion', 'Communicating transparently and respectfully; and', 'Fostering an inclusive, respectful, and professional work']",True,[],,"['Statistical Programming', 'Bayesian Estimation', 'Machine Learning', 'Natural Language Processing', 'Data Architecture', 'Data Processing Pipelines', 'R Programming', 'Stata', 'Version Control (Git)', 'Data Visualization', 'Quality Assurance in Data Analysis']","Statistical Programming: Used to develop advanced models and perform complex statistical analyses supporting education research.; Bayesian Estimation: Applied as a statistical method to improve model accuracy and inference in research projects.; Machine Learning: Utilized to develop predictive models and support data-driven decision-making in education policy research.; Natural Language Processing: Employed to analyze textual data relevant to social science and education research.; Data Architecture: Designed and developed to manage and scale large datasets for research purposes.; Data Processing Pipelines: Implemented to automate and streamline data workflows supporting reproducible research.; R Programming: Used for statistical programming, model development, and creating R packages to support research.; Stata: Applied for advanced statistical programming in social science and education research.; Version Control (Git): Used to manage code versions, facilitate collaboration, and ensure reproducibility of analyses.; Data Visualization: Developed to communicate complex analysis results clearly to non-technical audiences.; Quality Assurance in Data Analysis: Conducted to ensure reproducibility, proper documentation, and use of appropriate statistical tests."
XrGXmWQT_mRCZOTmAAAAAA==,Senior Data Analyst and Engineer,"Senior Data Analyst and Engineer to join our dynamic team. In this role, you will play a key role in analyzing large datasets, building data pipelines, and developing innovative solutions to extract actionable insights. The ideal candidate is highly skilled in both data analysis and engineering, with a passion for turning data into valuable business intelligence.

Responsibilities:
Analyze complex datasets to identify trends, patterns, and opportunities for optimizationDesign and develop robust data pipelines to extract, transform, and load (ETL) data from various sourcesCollaborate with cross-functional teams to understand business requirements and translate them into technical solutionsBuild predictive models and algorithms to support data-driven decision-makingPerform exploratory data analysis to uncover insights and inform strategic initiativesOptimize and maintain existing data infrastructure to ensure scalability, reliability, and performanceMentor and provide guidance to junior team membersStay updated on emerging technologies and trends in data an
Minimum Requirements:
Proficiency in SQL and experience with relational databases (e.g., MySQL, PostgreSQL)Strong programming skills in languages such as Python, R, or JavaExperience with data visualization tools (e.g., Tableau, Power BI)Knowledge of statistical analysis and machine learning techniquesFamiliarity with cloud platforms (e.g., AWS, Azure, Google Cloud) and big data technologies (e.g., Hadoop, Spark)Excellent analytical and problem-solving skillsStrong communication and collaboration skills",2025-07-02T00:00:00.000Z,2025-07-25,"['The ideal candidate is highly skilled in both data analysis and engineering, with a passion for turning data into valuable business intelligence', 'Proficiency in SQL and experience with relational databases (e.g., MySQL, PostgreSQL)Strong programming skills in languages such as Python, R, or JavaExperience with data visualization tools (e.g., Tableau, Power BI)Knowledge of statistical analysis and machine learning techniques', 'Familiarity with cloud platforms (e.g., AWS, Azure, Google Cloud) and big data technologies (e.g., Hadoop, Spark)Excellent analytical and problem-solving skills', 'Strong communication and collaboration skills']","['In this role, you will play a key role in analyzing large datasets, building data pipelines, and developing innovative solutions to extract actionable insights', 'Analyze complex datasets to identify trends, patterns, and opportunities for optimization', 'Design and develop robust data pipelines to extract, transform, and load (ETL) data from various sources', 'Collaborate with cross-functional teams to understand business requirements and translate them into technical solutions', 'Build predictive models and algorithms to support data-driven decision-makingPerform exploratory data analysis to uncover insights and inform strategic initiatives', 'Optimize and maintain existing data infrastructure to ensure scalability, reliability, and performance', 'Mentor and provide guidance to junior team members', 'Stay updated on emerging technologies and trends in data an']",True,[],,"['Data Pipelines', 'SQL', 'Relational Databases', 'Python', 'R', 'Java', 'Data Visualization Tools', 'Statistical Analysis', 'Machine Learning', 'Cloud Platforms', 'Big Data Technologies', 'Exploratory Data Analysis', 'Data Infrastructure Optimization']","Data Pipelines: Designing and developing ETL processes to efficiently extract, transform, and load data from various sources.; SQL: Using SQL to query and manage relational databases such as MySQL and PostgreSQL.; Relational Databases: Experience with structured data storage and management using systems like MySQL and PostgreSQL.; Python: Programming language used for data analysis, building models, and scripting data workflows.; R: Statistical programming language applied for data analysis and modeling.; Java: Programming language used for data engineering tasks and building scalable data solutions.; Data Visualization Tools: Utilizing tools like Tableau and Power BI to create dashboards and visual representations of data insights.; Statistical Analysis: Applying statistical methods to analyze data trends and support decision-making.; Machine Learning: Building predictive models and algorithms to enable data-driven decision-making.; Cloud Platforms: Using cloud services such as AWS, Azure, and Google Cloud for data storage, processing, and infrastructure.; Big Data Technologies: Employing tools like Hadoop and Spark to process and analyze large-scale datasets.; Exploratory Data Analysis: Performing initial investigations on data to discover patterns and insights.; Data Infrastructure Optimization: Maintaining and improving data systems to ensure scalability, reliability, and performance."
RFznnWszOvS3d7z7AAAAAA==,Senior Data Analyst - Data Modeler,"Description:
• At ngrok, we believe that doing networking the right way should also be the easy way.
• As we continue transforming how developers orchestrate and secure their networks, we’re building out a world-class data team to help us understand usage patterns, optimize product performance, and guide key business decisions with evidence-not assumptions.
• We’re looking for a Senior Data Analyst/Modeler who will be instrumental in building our data models, defining key metrics, and uncovering insights that guide both product innovation and go-to-market strategies.
• You’ll work closely with cross-functional teams-from engineering and product to marketing and growth-to help us make smarter, faster decisions backed by data.
• Help maintain data integrity and drive best practices in data governance and quality.

Requirements:
• 7+ years of experience in data analytics, business intelligence, or data science.
• Strong proficiency in SQL and hands-on experience working with business and product teams to build self-service analytics datasets and dashboards.
• Experience working with high volume, high velocity data sets that model complex, real-world systems
• Experience with a data modeling tool such as dbt or SQLMesh and an orchestration tool such as Dagster or Airbyte for managing data pipelines.
• Experience being part of or working with engineering teams and navigating version control (e.g. git), command line tools, and CI
• Strong experience with BI tools (Superset, Looker, Mode, Metabase, or similar).
• Ability to translate complex data into clear, actionable insights.
• Solid communication and collaboration skills-especially in a remote environment.
• Bonus: Background in supporting product-led growth (PLG) or developer-focused SaaS.

Benefits:
• Compensation for this role depends on level, but we provide a competitive mix of salary and equity.
• We provide a 401(k) with a 100% match up to 3% of your salary and a 50% match up to another 2%.
• We provide healthcare, dental, and vision with premiums fully covered on the base plan for employees. Half of premiums are covered for dependents.
• We offer unlimited PTO and a culture in which the overwhelming majority of employees take more than four weeks. Your manager is also on the hook for encouraging you to do the same.",,2025-07-25,"['7+ years of experience in data analytics, business intelligence, or data science', 'Strong proficiency in SQL and hands-on experience working with business and product teams to build self-service analytics datasets and dashboards', 'Experience working with high volume, high velocity data sets that model complex, real-world systems', 'Experience with a data modeling tool such as dbt or SQLMesh and an orchestration tool such as Dagster or Airbyte for managing data pipelines', 'Experience being part of or working with engineering teams and navigating version control (e.g. git), command line tools, and CI', 'Strong experience with BI tools (Superset, Looker, Mode, Metabase, or similar)', 'Ability to translate complex data into clear, actionable insights', 'Solid communication and collaboration skills-especially in a remote environment', 'Bonus: Background in supporting product-led growth (PLG) or developer-focused SaaS']","['You’ll work closely with cross-functional teams-from engineering and product to marketing and growth-to help us make smarter, faster decisions backed by data', 'Help maintain data integrity and drive best practices in data governance and quality']",True,[],,"['SQL', 'Data Modeling', 'dbt', 'SQLMesh', 'Dagster', 'Airbyte', 'Business Intelligence (BI) Tools', 'Data Governance and Quality', 'Version Control (git)', 'Continuous Integration (CI)']","SQL: Used for querying and managing high volume, high velocity datasets to build self-service analytics datasets and dashboards.; Data Modeling: Building data models to define key metrics and represent complex, real-world systems for analysis and decision-making.; dbt: A data modeling tool used to transform and organize data within the analytics workflow.; SQLMesh: A data modeling tool used to manage and version control SQL-based data transformations.; Dagster: An orchestration tool used to manage data pipelines and workflows.; Airbyte: A data integration and orchestration tool used to manage data pipelines.; Business Intelligence (BI) Tools: Tools like Superset, Looker, Mode, and Metabase used to create dashboards and visualize data insights.; Data Governance and Quality: Practices to maintain data integrity and ensure reliable, high-quality data for analysis.; Version Control (git): Used to collaborate with engineering teams and manage changes in data-related code and pipelines.; Continuous Integration (CI): Applied to automate testing and deployment of data workflows and analytics code."
9NDG4fJBUaNoAxDoAAAAAA==,Business Data Analyst,"Overview

Grow With Us! At Hilb Group, we recognize that our associates are our greatest asset. We promote a service-driven culture of high performance that encourages career and professional development. The Hilb Group is currently seeking a motivated and ambitious Business Data Analyst to join our team. This position will report to our agency located in Roseland, NJ. The ideal candidate will be motivated to succeed, is well organized, able to prioritize, and able to work well with a team. This is an in-office position. Responsibilities: Risk Management support Manage vendor certificate, analyze compliance, analyze loss trends, create client claim reports, perform claim task workflows. Participate as a Team member in a fast-paced, growing sales environment open to continuous improvement. Qualifications: Minimum High School degree required, college preferred Licensing not required. Demonstrated analytical skills. Strong time management skills Benefits: Company Paid Life Insurance, Long-Term and Short-Term Disability. Medical, Dental, Vision and FSA/HSA plans. 401(k) with company match. Additional voluntary benefits including Critical Illness, Accident Insurance, Hospital Indemnity and Supplemental Life Insurance, Legal and Identity Protection, and Pet benefits. Generous PTO. An awesome team of professionals! The Hilb Group is an equal opportunity employer, and we actively support and comply with all applicable federal, state, and local laws prohibiting all forms of discrimination in employment. Additionally, we have a zero-tolerance policy for all forms of harassment in violation of federal, state, and local laws.",2025-07-22T00:00:00.000Z,2025-07-25,"['The ideal candidate will be motivated to succeed, is well organized, able to prioritize, and able to work well with a team', 'Demonstrated analytical skills']","['Responsibilities: Risk Management support Manage vendor certificate, analyze compliance, analyze loss trends, create client claim reports, perform claim task workflows', 'Participate as a Team member in a fast-paced, growing sales environment open to continuous improvement']",False,[],,"['Data Analysis', 'Reporting']","Data Analysis: The role involves analyzing compliance, loss trends, and creating client claim reports, which are core data analysis tasks.; Reporting: Creating client claim reports is a key responsibility, indicating the use of reporting tools or methods."
TJy5OnpWfXBgyiJWAAAAAA==,Marketing Data Analyst II – Pricing,"The role's responsibilities will encompass a blend of pricing strategy, promotional analysis, category management, and budgeting insights.

OVERVIEW

Assist in creating and driving business value and growth though the effective use of Sheetz’ most valuable resource: Data. Responsible for leading Sheetz’ data and information strategy through data analysis and visualization in order to facilitate and enhance organizational decision-making and data utilization across the company. Provides advanced data analytics support to the Senior Data Analyst while providing mentorship to the Data Analyst I around data analytics and information strategy.

RESPONSIBILITIES (other duties may be assigned)
• Cultivate data-driven insights that help support exploitation of strategic and tactical business opportunities, and be a champion for a data-driven, decision-making culture.
• Support data strategy leadership in the development, assessment, refinement and implementation of corporate strategy through effective use of data analytics.
• Provide enterprise-wide data science and business intelligence services as well as recommendations to decentralized, embedded data scientists and analysts throughout the business.
• Assist Senior Data Analysts and management in providing training for departmental and distributed data analysts.
• Oversee and present robust ad-hoc reports, data models, and deep dive analysis to provide clear observations so that managers can make more informed decisions.
• Develop and mentor future data-driven, analytical leaders and strategists within the team.
• Assist with a wide array of analytical tasks and projects requested by other departments.
• Supports the Senior Data Analyst position with ad-hoc advanced analytics.
• Assist in the creation of policies and procedures for the access, analysis and visualization of data and associated business insights; partnering with IT and RISC.
• Responsible for the documenting and classifying data assets and making accessible and discoverable across the organization.

QUALIFICATIONS

(Equivalent combinations of education, licenses, certifications and/or experience may be considered)

Education
• Bachelor’s degree in Economics, Statistics, Mathematics, Actuarial /Data / Computer Science or related field required

Experience
• Minimum 3 years demonstrated experience in data modeling, optimization, and application to business strategies required.
• Minimum 3 years demonstrated experience in integrating complex, inter-departmental processes and information strategies, and/or designing strategic metrics and scorecards required.
• Thorough understanding of the latest data mining, machine learning and/or artificial intelligence techniques required.
• In-depth experience with or coursework in designing and implementing information solutions required.

Licenses/Certifications
• None required

Tools & Equipment (Other than general office equipment):
• General Office Equipment

ACCOMMODATIONS

Sheetz is committed to the full inclusion of all qualified individuals. Sheetz is committed to considering all applicants regardless of disability who can perform all essential job duties with or without accommodations.",2025-07-25T00:00:00.000Z,2025-07-25,"['(Equivalent combinations of education, licenses, certifications and/or experience may be considered)', 'Bachelor’s degree in Economics, Statistics, Mathematics, Actuarial /Data / Computer Science or related field required', 'Minimum 3 years demonstrated experience in data modeling, optimization, and application to business strategies required', 'Minimum 3 years demonstrated experience in integrating complex, inter-departmental processes and information strategies, and/or designing strategic metrics and scorecards required', 'Thorough understanding of the latest data mining, machine learning and/or artificial intelligence techniques required', 'In-depth experience with or coursework in designing and implementing information solutions required']","[""The role's responsibilities will encompass a blend of pricing strategy, promotional analysis, category management, and budgeting insights"", 'Assist in creating and driving business value and growth though the effective use of Sheetz’ most valuable resource: Data', 'Responsible for leading Sheetz’ data and information strategy through data analysis and visualization in order to facilitate and enhance organizational decision-making and data utilization across the company', 'Provides advanced data analytics support to the Senior Data Analyst while providing mentorship to the Data Analyst I around data analytics and information strategy', 'RESPONSIBILITIES (other duties may be assigned)', 'Cultivate data-driven insights that help support exploitation of strategic and tactical business opportunities, and be a champion for a data-driven, decision-making culture', 'Support data strategy leadership in the development, assessment, refinement and implementation of corporate strategy through effective use of data analytics', 'Provide enterprise-wide data science and business intelligence services as well as recommendations to decentralized, embedded data scientists and analysts throughout the business', 'Assist Senior Data Analysts and management in providing training for departmental and distributed data analysts', 'Oversee and present robust ad-hoc reports, data models, and deep dive analysis to provide clear observations so that managers can make more informed decisions', 'Develop and mentor future data-driven, analytical leaders and strategists within the team', 'Assist with a wide array of analytical tasks and projects requested by other departments', 'Supports the Senior Data Analyst position with ad-hoc advanced analytics', 'Assist in the creation of policies and procedures for the access, analysis and visualization of data and associated business insights; partnering with IT and RISC', 'Responsible for the documenting and classifying data assets and making accessible and discoverable across the organization']",True,[],,"['Data Analysis', 'Data Visualization', 'Data Modeling', 'Optimization', 'Machine Learning', 'Data Mining', 'Business Intelligence', 'Ad-hoc Reporting', 'Strategic Metrics and Scorecards', 'Data Strategy']",Data Analysis: Used to facilitate and enhance organizational decision-making and data utilization across the company.; Data Visualization: Applied to present data insights clearly to support business decisions and strategy.; Data Modeling: Involved in creating data models to support pricing strategy and business optimization.; Optimization: Used to improve business strategies and processes through data-driven approaches.; Machine Learning: Understanding of machine learning techniques is required to support advanced analytics and data mining.; Data Mining: Applied to extract useful patterns and insights from complex data sets to inform business strategies.; Business Intelligence: Providing enterprise-wide BI services and recommendations to support decentralized data scientists and analysts.; Ad-hoc Reporting: Creating and presenting robust ad-hoc reports and deep dive analyses to inform management decisions.; Strategic Metrics and Scorecards: Designing and integrating strategic metrics to measure and track business performance.; Data Strategy: Leading and supporting the development and implementation of corporate data and information strategies.
7sn8sBGbUiK7rVLwAAAAAA==,"Data Analyst, Health","GoldBelt is hiring a Data Analyst, Health with 5 - 10 years of experience. Based in United States - Rockville, MD and with In-office ways of working.

Job description and responsibilities:

Goldbelt Frontier fosters a collaborative environment where employees are encouraged to utilize and employ their operational and leadership skills. Many senior project managers and business analysts are subject matter experts in their respective fields. Frontier understands how to support multiple stakeholders to aid in developing and implementing national policies, strategies, and doctrine.

Summary:

We are looking for a Health Data Analyst to provide support for the National Action Alliance to Advance Patient Safety contract within partnership with Health and Human Services (HHS). This position shall support the Action Alliance the identification, dissemination and utilization of evidence based practices and best practices.

Essential Job Functions:
• Conduct routine analysis on process and outcome data and share recommendations and insights at the direction of AHRQ
• Assist in preparing reports and materials that demonstrate program impact for internal and external stakeholders
• Leverage public/external data sources to benchmark and inform program outcomes and objectives
• Evaluate pilot programs and strategic initiatives at both the program and organizational level
• Maintain and periodically update core evaluation infrastructure such as evaluation manuals, data dictionaries, etc.
• Support the continuous improvement of evaluation methods, systems, and practices Data Management
• Maintain internal data systems to ensure high quality data processes and analysis
• Develop meaningful data dashboards that can be easily accessed, understood and utilized by frontline staff to drive a continuous improvement process
• In collaboration with ARQ, conduct periodic review, analysis, and reporting of data needed to measure program impact, Action Alliance progress, establish program priorities, and support continuous improvement of all Center programs and initiatives

Requirements and qualifications:

Necessary Skills and Knowledge:
• Your ability to exude a strong executive presence while also managing tactical execution by internal and external stakeholders will be critical to success in the role
• Ability to contribute to projects across practice areas and divisions to help troubleshoot and problem solve on complex issues
• Strategic, consultative presence with a problem-solving mentality
• Experience communicating directly and effectively to executive leadership.
• Demonstrated knowledge of client priorities, preferences, and regulations
• Demonstrated expertise in MS Office, with excellent Excel skills
• Demonstrated knowledge of relevant systems, processes, and approaches, with excellent financial management skills
• Effective communicator with internal and external clients
• Strong research skills, including knowledge of research methodologies, data analysis, and statistics.
• Advanced analytical knowledge of data
• Proficiency with data visualization software such as Tableau or similar 5. High level of facility with data management, imports, and exports through MS Excel. Ability to summarize data through use of formulas, run reports and queries, generate mailing lists, and perform similar tasks
• Strong observational, analytical and critical thinking skills, coupled with ability to discern trends and deduce reasons for results
• Strong organizational and communication skills (written, oral and presentation)
• Familiarity with creating and managing online surveys
• Motivated self-starter with demonstrated ability to work independently and collaboratively within a systematic program approach.

Minimum Qualifications:
• Bachelor’s degree, including successful completion of coursework in statistics and research/survey methods.
• 5- 7 years conducting program evaluation (process and outcome) and developing reports that examine and disseminate findings regarding impact and recommendations for improvement
• 5-7 years of experience managing and presenting data using Microsoft Office and Google Suite / G Suite (docs, sheets, forms, presentations, etc.)

Experience with the following:
• Conducting big data analysis
• Developing software and data models
• Developing algorithms
• Business analysis
• Business process modeling—enterprise to department level
• Process oriented with great documentation skills

Preferred Qualifications:
• Master's degree in statistics or a PhD in a specific area of health research or clinical practice.
• Familiarity with student information systems and experience working with sensitive, protected data preferred.",,2025-07-25,"['Your ability to exude a strong executive presence while also managing tactical execution by internal and external stakeholders will be critical to success in the role', 'Ability to contribute to projects across practice areas and divisions to help troubleshoot and problem solve on complex issues', 'Strategic, consultative presence with a problem-solving mentality', 'Experience communicating directly and effectively to executive leadership', 'Demonstrated knowledge of client priorities, preferences, and regulations', 'Demonstrated expertise in MS Office, with excellent Excel skills', 'Demonstrated knowledge of relevant systems, processes, and approaches, with excellent financial management skills', 'Effective communicator with internal and external clients', 'Strong research skills, including knowledge of research methodologies, data analysis, and statistics', 'Advanced analytical knowledge of data', 'Proficiency with data visualization software such as Tableau or similar 5', 'High level of facility with data management, imports, and exports through MS Excel', 'Ability to summarize data through use of formulas, run reports and queries, generate mailing lists, and perform similar tasks', 'Strong observational, analytical and critical thinking skills, coupled with ability to discern trends and deduce reasons for results', 'Strong organizational and communication skills (written, oral and presentation)', 'Familiarity with creating and managing online surveys', 'Motivated self-starter with demonstrated ability to work independently and collaboratively within a systematic program approach', 'Bachelor’s degree, including successful completion of coursework in statistics and research/survey methods', '5- 7 years conducting program evaluation (process and outcome) and developing reports that examine and disseminate findings regarding impact and recommendations for improvement', '5-7 years of experience managing and presenting data using Microsoft Office and Google Suite / G Suite (docs, sheets, forms, presentations, etc.)', 'Conducting big data analysis', 'Developing software and data models', 'Developing algorithms', 'Business process modeling—enterprise to department level', 'Process oriented with great documentation skills']","['Many senior project managers and business analysts are subject matter experts in their respective fields', 'This position shall support the Action Alliance the identification, dissemination and utilization of evidence based practices and best practices', 'Conduct routine analysis on process and outcome data and share recommendations and insights at the direction of AHRQ', 'Assist in preparing reports and materials that demonstrate program impact for internal and external stakeholders', 'Leverage public/external data sources to benchmark and inform program outcomes and objectives', 'Evaluate pilot programs and strategic initiatives at both the program and organizational level', 'Maintain and periodically update core evaluation infrastructure such as evaluation manuals, data dictionaries, etc', 'Support the continuous improvement of evaluation methods, systems, and practices Data Management', 'Maintain internal data systems to ensure high quality data processes and analysis', 'Develop meaningful data dashboards that can be easily accessed, understood and utilized by frontline staff to drive a continuous improvement process', 'In collaboration with ARQ, conduct periodic review, analysis, and reporting of data needed to measure program impact, Action Alliance progress, establish program priorities, and support continuous improvement of all Center programs and initiatives']",True,[],,"['Program Evaluation', 'Data Analysis', 'Data Visualization', 'Data Management', 'Statistical Methods', 'Big Data Analysis', 'Algorithm Development', 'Business Process Modeling', 'Survey Design and Management', 'Excel Advanced Features', 'Reporting and Communication']","Program Evaluation: Used to assess process and outcome data to measure program impact and support continuous improvement.; Data Analysis: Conducting routine analysis on health-related data to generate insights and recommendations.; Data Visualization: Developing dashboards using tools like Tableau to present data in an accessible way for frontline staff.; Data Management: Maintaining internal data systems and ensuring high-quality data processes and analysis.; Statistical Methods: Applying research methodologies and statistical techniques to analyze health data and support evidence-based practices.; Big Data Analysis: Handling and analyzing large datasets to inform program outcomes and strategic initiatives.; Algorithm Development: Creating software and data models to support data-driven decision making.; Business Process Modeling: Modeling enterprise and department-level processes to improve operational efficiency.; Survey Design and Management: Creating and managing online surveys to collect data for program evaluation.; Excel Advanced Features: Using formulas, queries, and data summarization techniques in Excel for data management and reporting.; Reporting and Communication: Preparing reports and materials to communicate findings and program impact to stakeholders."
hqBDLRuo4rlY4DXHAAAAAA==,Senior Financial Data Analyst,"Job Title: Senior Financial Data Analyst

Company: GPFS is the fund administrator of choice for a wide range of clients in the US, UK, and EU. Every day, with every decision and every client interaction, our values serve as guideposts, to improve the quality of our work, and strengthen our employee and client relationships.

As a business that is all about people; culture isn't an initiative, it's an innate value that's critical to every decision we make. At GPFS, people come first.

At GPFS, diversity is a source of strength, both from our people and ideas. GPFS is a collaborative team-oriented organization where we support each other both personally and professionally. Our culture is defined by our behavior, our curiosity and our support of innovative ideas and perspectives.

Our inclusive culture supports and encourages our team members to try new things, share ideas openly and always ask the question why. It brings us together and makes the team stronger by inspiring all to connect, belong and thrive.

Location: Latham, NY - In office

Job Type: Full-time

This position is part of a growing team at GPFS which focuses on providing comprehensive data and reporting solutions for Private Market clients. In this role you will focus on the ingestion, normalization, and enhancement of data (i.e., accounting, financial, regulatory) from multiple sources to support / maintain reporting needs for various organizational stakeholders.

Essential Duties:
• Support the cleansing, preparation, and enhancement of large / complex datasets for clients and internal teams.
• Carry out exploratory data analysis.
• Support reporting environment by maintaining and updating reports and records as needed.
• Reconcile reporting output to source documents.
• Identify areas for process improvement or automation.
• Demonstrate attention to detail and accuracy.
• Strong multi-tasking and organizational skills in a project-based environment.
• Ability to research and resolve issues with various degrees of complexity.
• Strong written and verbal communication skills
• Ability to work as a strong team member as well as an independent contributor.
• Flexibility to work hours needed to complete client deliverables.

Qualifications
• Degree: 4 Year with master's preferred
• Years of experience: 3+

Additional Eligibility Qualifications
• Excel / VBA
• SQL / SSRS
• R / Python
• Business Intelligence / visualization software
• Finance or Economics background a plus

Competencies
• Intellectual curiosity - researching methods or ideas that could benefit the group or project.
• Self-motivating - ability to work independently.
• Analytical skills - understanding relationships within the data and disseminating information accurately.
• Organized
• Highly flexible - adapting to new formats, tools, and sometimes ambiguous work environment.
• Results Driven - working through multiple iterations to achieve success.
• Collaborative - working with multiple groups both within and outside the organization.
• Detailed Orientated
• Ethical

GPFS Vision

Our purpose is to create enduring relationships with our employees and clients by constantly delivering exceptional opportunities and service.

GPFS Value Statement

Investing in people and culture

Core Values

Camaraderie: Being supportive of one another and celebrating each other's successes

Excellence: Consistently delivering exceptional work and going above and beyond

Empowerment: Fostering a deep sense of agency and ownership over one's choices and actions

Innovation: The drive to think differently and solve problems creatively

Inclusion: Recognizing individual's unique strengths and perspectives with mutual trust and respect

#LI-GP1",,2025-07-25,"['Strong multi-tasking and organizational skills in a project-based environment', 'Ability to research and resolve issues with various degrees of complexity', 'Strong written and verbal communication skills', 'Ability to work as a strong team member as well as an independent contributor', 'Years of experience: 3+', 'Excel / VBA', 'SQL / SSRS', 'R / Python', 'Business Intelligence / visualization software', 'Intellectual curiosity - researching methods or ideas that could benefit the group or project', 'Self-motivating - ability to work independently', 'Analytical skills - understanding relationships within the data and disseminating information accurately', 'Organized', 'Highly flexible - adapting to new formats, tools, and sometimes ambiguous work environment', 'Results Driven - working through multiple iterations to achieve success', 'Collaborative - working with multiple groups both within and outside the organization', 'Detailed Orientated', 'Ethical', ""Camaraderie: Being supportive of one another and celebrating each other's successes"", 'Excellence: Consistently delivering exceptional work and going above and beyond', 'Innovation: The drive to think differently and solve problems creatively', ""Inclusion: Recognizing individual's unique strengths and perspectives with mutual trust and respect""]","['This position is part of a growing team at GPFS which focuses on providing comprehensive data and reporting solutions for Private Market clients', 'In this role you will focus on the ingestion, normalization, and enhancement of data (i.e., accounting, financial, regulatory) from multiple sources to support / maintain reporting needs for various organizational stakeholders', 'Support the cleansing, preparation, and enhancement of large / complex datasets for clients and internal teams', 'Carry out exploratory data analysis', 'Support reporting environment by maintaining and updating reports and records as needed', 'Reconcile reporting output to source documents', 'Identify areas for process improvement or automation', 'Demonstrate attention to detail and accuracy', 'Flexibility to work hours needed to complete client deliverables']",True,[],,"['Data Ingestion', 'Data Normalization', 'Data Cleansing', 'Exploratory Data Analysis', 'SQL', 'SSRS (SQL Server Reporting Services)', 'Excel / VBA', 'R', 'Python', 'Business Intelligence / Visualization Software', 'Process Improvement and Automation']","Data Ingestion: Refers to the process of collecting and importing data from multiple sources to support reporting needs for organizational stakeholders.; Data Normalization: Involves standardizing and structuring data from various sources to ensure consistency and usability in reporting and analysis.; Data Cleansing: The task of preparing and cleaning large and complex datasets to improve data quality for clients and internal teams.; Exploratory Data Analysis: Conducting initial investigations on data to discover patterns, spot anomalies, and check assumptions to support decision-making.; SQL: Used for querying and managing relational databases to support data extraction and reporting.; SSRS (SQL Server Reporting Services): A reporting tool used to create, manage, and deliver reports to support the reporting environment.; Excel / VBA: Utilized for data manipulation, automation, and reporting tasks within spreadsheets.; R: A programming language used for statistical analysis and data visualization.; Python: A programming language employed for data analysis, scripting, and automation.; Business Intelligence / Visualization Software: Tools used to create dashboards and visual reports to communicate data insights effectively.; Process Improvement and Automation: Identifying and implementing ways to enhance data workflows and automate repetitive tasks."
phqd2bATrSnCJjrHAAAAAA==,Senior Data Analytics Specialist - Relocate to Saudi Arabia,"Candidate must relocate to Saudi Arabia.

Aramco energizes the world economy.

Aramco occupies a special position in the global energy industry. We are one of the world’s largest producers of hydrocarbon energy and chemicals, with among the lowest Upstream carbon intensities of any major producer. With our significant investment in technology and infrastructure, we strive to maximize the value of the energy we produce for the world along with a commitment to enhance Aramco’s value to society.

Headquartered in the Kingdom of Saudi Arabia, and with offices around the world, we combine market discipline with a generations’ spanning view of the future, born of our nine decades experience as responsible stewards of the Kingdom’s vast hydrocarbon resources. This responsibility has driven us to deliver significant societal and economic benefits to not just the Kingdom, but also to a vast number of communities, economies, and countries that rely on the vital and reliable energy that we supply.

We are one of the most profitable companies in the world, as well as amongst the top five global companies by market capitalization.

Position description

We are seeking Data Analytics Specialist to join our Digital Engineering Solutions Division under Process & Control Systems Department. Process and Control Systems Department provides services in the field of process engineering, automation, new energy and digitalization to various entities within Aramco.

As a Data Analytics Engineer your role will be to lead innovation within the business and define how the business creates additional value through the utilization of its data assets and analytics. You will identify and solve strategic and tactical analytic business problems to enhance operational efficiency.

Duties and Responsibilities

As a successful candidate you will be required to perform the following:
• Identify and develop advanced analytics use cases to resolve complex technical challenges, optimize processes, enhance revenue, ensure environmental sustainability, and improve safety.
• Drive ideas from conception to production using best-in-class Machine Learning Operations (MLOps) and Development Operations (DevOps) practices.
• Develop and optimize Machine Learning (ML) models and pipelines, ensuring their efficient deployment, monitoring, and scaling.
• Explore diverse data sources to improve predictive modeling and optimize business strategies.
• Assess Artificial Intelligence (AI) tools and methods for data analysis, enhancing business impact and decision-making.
• Implement predictive modeling techniques to optimize production facilities, revenue streams, and operational efficiencies.
• Generate documentation in line with established standards to support the development and deployment process.
• Collaborate with cross-functional teams, including IT, engineering, and business stakeholders, to drive data-driven solutions.
• Contribute to technical task forces investigating incidents and solving domain-specific problems using AI/ML techniques.
• Publish research papers for peer-reviewed journals and presents findings to other organizations and conferences to advance industry knowledge.
• Promotes a learning environment through knowledge-sharing, and fosters a culture of continuous learning and innovation.
• Provide leadership and mentorship to junior team members and specialists.

Minimum Requirements

As a successful candidate you will hold a:
• Bachelor’s degree in Data Science, Computer Science, Engineering, or a related field. An advanced degree (Master’s or PhD) focused on Data Science, AI, or ML Engineering with a background in Engineering is highly preferred.
• 20 years of overall experience, with hands-on experience in Data Science, Natural Language Processing (NLP), Computer Vision, and/or ML projects in the industry.
• Expertise in MLOps, DevOps, AIOps, DataOps and related operational frameworks for model deployment, monitoring, and automation.
• Experience in data collection, cleaning, preprocessing, and wrangling for industry-related problems based on domain knowledge.
• Proficiency in Platforms such as Python, R, SQL, SAS, Scala, and cloud platforms such as Azure and Google Cloud (Vertex AI).
• Expertise in visualization tools and packages; User Interface (UI) experience with Power Business Intelligence (Power BI) or similar tools.
• Experience with IT architecture and deploying models in on-prem environments.
• Strong understanding of continuous integration / continuous deployment (CI/CD) pipelines, containerization (Docker, Kubernetes), and automation frameworks.
• Demonstrated ability to publish research or contribute to industry knowledge through journal papers, conference proceedings, or whitepapers.

Working environment

Our high-performing employees are drawn by the challenging and rewarding professional, technical and industrial opportunities we offer, and are remunerated accordingly. At Aramco, our people work on truly world-scale projects, supported by investment in capital and technology that is second to none. And because, as a global energy company, we are faced with addressing some of the world’s biggest technical, logistical and environmental challenges, we invest heavily in talent development. We have a proud history of educating and training our workforce over many decades. Employees at all levels are encouraged to improve their sector-specific knowledge and competencies through our workforce development programs – one of the largest in the world.",2025-07-21T00:00:00.000Z,2025-07-25,"['Identify and develop advanced analytics use cases to resolve complex technical challenges, optimize processes, enhance revenue, ensure environmental sustainability, and improve safety', 'Bachelor’s degree in Data Science, Computer Science, Engineering, or a related field']","['Process and Control Systems Department provides services in the field of process engineering, automation, new energy and digitalization to various entities within Aramco', 'As a Data Analytics Engineer your role will be to lead innovation within the business and define how the business creates additional value through the utilization of its data assets and analytics', 'You will identify and solve strategic and tactical analytic business problems to enhance operational efficiency', 'Drive ideas from conception to production using best-in-class Machine Learning Operations (MLOps) and Development Operations (DevOps) practices', 'Develop and optimize Machine Learning (ML) models and pipelines, ensuring their efficient deployment, monitoring, and scaling', 'Explore diverse data sources to improve predictive modeling and optimize business strategies', 'Assess Artificial Intelligence (AI) tools and methods for data analysis, enhancing business impact and decision-making', 'Implement predictive modeling techniques to optimize production facilities, revenue streams, and operational efficiencies', 'Generate documentation in line with established standards to support the development and deployment process', 'Collaborate with cross-functional teams, including IT, engineering, and business stakeholders, to drive data-driven solutions', 'Contribute to technical task forces investigating incidents and solving domain-specific problems using AI/ML techniques', 'Publish research papers for peer-reviewed journals and presents findings to other organizations and conferences to advance industry knowledge', 'Promotes a learning environment through knowledge-sharing, and fosters a culture of continuous learning and innovation', 'Provide leadership and mentorship to junior team members and specialists']",True,"['Natural Language Processing', 'Computer Vision', 'Artificial Intelligence Tools', 'AIOps']",Natural Language Processing: Apply NLP techniques in industry projects to extract insights and enhance data analysis capabilities.; Computer Vision: Utilize computer vision methods for analyzing visual data as part of AI and ML initiatives.; Artificial Intelligence Tools: Assess and implement AI tools and methods to improve data analysis and business impact.; AIOps: Employ AIOps frameworks to automate and enhance IT operations through AI-driven analytics.,"['Machine Learning', 'MLOps', 'DevOps', 'Predictive Modeling', 'Data Collection and Preprocessing', 'SQL', 'Python', 'R', 'SAS', 'Scala', 'Cloud Platforms', 'Data Visualization', 'CI/CD Pipelines', 'Containerization', 'Data-Driven Decision Making']","Machine Learning: Develop and optimize ML models and pipelines to enhance operational efficiency and business strategies.; MLOps: Use best-in-class MLOps practices for deployment, monitoring, and scaling of machine learning models.; DevOps: Apply DevOps practices to support the production lifecycle of analytics and ML solutions.; Predictive Modeling: Implement predictive modeling techniques to optimize production facilities, revenue streams, and operational efficiencies.; Data Collection and Preprocessing: Perform data collection, cleaning, preprocessing, and wrangling for industry-related problems based on domain knowledge.; SQL: Utilize SQL for querying and managing data from diverse sources to support analytics and modeling.; Python: Use Python as a primary programming language for data analysis, model development, and pipeline creation.; R: Employ R for statistical analysis and data science tasks within the analytics workflow.; SAS: Leverage SAS for advanced analytics and statistical modeling in industry applications.; Scala: Use Scala for data engineering and analytics tasks, particularly in big data environments.; Cloud Platforms: Utilize cloud platforms such as Azure and Google Cloud (Vertex AI) for scalable data processing and model deployment.; Data Visualization: Create visualizations and dashboards using tools like Power BI to communicate insights and support decision-making.; CI/CD Pipelines: Implement continuous integration and continuous deployment pipelines to automate model and software delivery.; Containerization: Use container technologies like Docker and Kubernetes to deploy and manage analytics and ML applications.; Data-Driven Decision Making: Collaborate with cross-functional teams to drive solutions based on data analytics and insights."
aIf525Bn8ViIxXsSAAAAAA==,Sr. Data Standardization Analyst,"Location: Hybrid arrangement, with office located in Pittsburgh, PA; 100% Remote candidates also considered

Job Type: Full-time

Work Authorization: U.S. Citizen or Green Card

The A.C. Coy Company is currently hiring for a full-time Sr. Data Standardization Analyst role. This individual will work with cross-functional teams and manufacturers to develop and apply standards to the product data they supply. Our ideal candidate will have 5+ years of experience in a Data Analytics role and a strong background in data normalization, data flows, data quality, and data risk management.

Our Client is offering flexible hours and a hybrid or remote work arrangement, as well as an attractive benefits package including health coverage, 401K, and unlimited PTO.
• Collaborate closely with assortment and merchandising managers to understand the strategy for the category and define requirements for product data to support that strategy
• Establish standardization rules for the attributes belonging to your assigned product categories
• Design the functional logic for data transformation and conformation to those rules
• Define detailed requirements for technical developers to implement transformation rules
• Perform hands-on data analysis and manipulation to assess gaps in existing data and develop strategies for improving data content and quality
• Work with manufacturer data teams to communicate our data standards and guide them in conforming their data to those standards Save
• Create functional definitions for data transformation to our standards for data elements that cannot be conformed by the manufacturers
• Identify opportunities for improved efficiency in product data standardization processes

Required:
• Bachelor’s Degree in Business, Information Systems, Computer Science or a related field
• 5+ years of experience in a Data Analytics role, including 2+ years of data standardization
• Strong understanding of data, data flows and how data supports various business processes in a supply chain environment
• Understanding of data quality and data risk management, including understanding of standards, methods, processes, tools, and controls
• Excellent organizational and time management skills with the ability to juggle multiple priorities
• Ability to conduct root cause analysis and communicate recommendations to resolve
• Ability to travel 25-50% of the time

Preferred:
• Master's Degree in Business, Information Systems, Computer Science or a related field",2025-07-18T00:00:00.000Z,2025-07-25,"['Work Authorization: U.S. Citizen or Green Card', 'Our ideal candidate will have 5+ years of experience in a Data Analytics role and a strong background in data normalization, data flows, data quality, and data risk management', 'Bachelor’s Degree in Business, Information Systems, Computer Science or a related field', '5+ years of experience in a Data Analytics role, including 2+ years of data standardization', 'Strong understanding of data, data flows and how data supports various business processes in a supply chain environment', 'Understanding of data quality and data risk management, including understanding of standards, methods, processes, tools, and controls', 'Excellent organizational and time management skills with the ability to juggle multiple priorities', 'Ability to conduct root cause analysis and communicate recommendations to resolve', 'Ability to travel 25-50% of the time']","['Data Standardization Analyst role', 'This individual will work with cross-functional teams and manufacturers to develop and apply standards to the product data they supply', 'Collaborate closely with assortment and merchandising managers to understand the strategy for the category and define requirements for product data to support that strategy', 'Establish standardization rules for the attributes belonging to your assigned product categories', 'Design the functional logic for data transformation and conformation to those rules', 'Define detailed requirements for technical developers to implement transformation rules', 'Perform hands-on data analysis and manipulation to assess gaps in existing data and develop strategies for improving data content and quality', 'Work with manufacturer data teams to communicate our data standards and guide them in conforming their data to those standards Save', 'Create functional definitions for data transformation to our standards for data elements that cannot be conformed by the manufacturers', 'Identify opportunities for improved efficiency in product data standardization processes']",True,[],,"['Data Standardization', 'Data Normalization', 'Data Quality Management', 'Data Risk Management', 'Data Transformation', 'Data Analysis', 'Root Cause Analysis', 'Data Flows']","Data Standardization: Central to the role, involving developing and applying standards to product data to ensure consistency and quality across datasets.; Data Normalization: Used to transform and conform product data attributes to standardized formats for improved data quality and usability.; Data Quality Management: Focuses on assessing and improving the accuracy, completeness, and reliability of product data within the supply chain.; Data Risk Management: Involves identifying and mitigating risks related to data integrity and compliance in product data handling.; Data Transformation: Designing and implementing functional logic to convert raw product data into standardized formats as per defined rules.; Data Analysis: Hands-on examination and manipulation of product data to identify gaps and develop strategies for data improvement.; Root Cause Analysis: Used to diagnose underlying issues in data quality or standardization processes and recommend corrective actions.; Data Flows: Understanding and managing how product data moves through various business processes and systems in the supply chain."
pMuqDWepe6FzERL2AAAAAA==,Customer Experience Insights - Data Analyst,"AppFolio is more than a company. We’re a community of dreamers, big thinkers, problem solvers, active listeners, and multipliers. At every opportunity, we set the pace while delivering innovation built to carry real estate into the future. One in which every experience feels effortless, yet meaningful. Where customers are empowered to take on any opportunity. We show up as one team, connected by our values to be a force for good. Because together, we have the power to create extraordinary outcomes for our customers, our communities, and ourselves.

We’re seeking a data-driven, customer-obsessed Customer Experience Insights expert to help us better understand our customers and optimize their experience across every touchpoint. You’ll be a critical partner in uncovering actionable insights that guide cross-functional decisions and fuel exceptional customer journeys.

Your impact
• Drive strategic decision-making by identifying customer insights, opportunities, and pain points through the analysis of structured and unstructured data from multiple sources (e.g. surveys, support tickets, call transcripts, NPS/CSAT/Customer Effort scores, behavioral data)
• Socialize insights and influence organizational strategies using tools like Tableau and reports with effective data visualizations and clear narratives
• Enhance cross-functional collaboration by acting as a central hub for customer insights, fostering a shared understanding of the customer across all departments, and promoting a customer-centric culture
• Partner across Services teams to inform and support efforts to build customer experiences based on customer expectations, needs, preferences, and behaviors

Qualifications
• 3–5+ years of experience in customer insights, data analysis, or customer experience strategy roles.
• Familiarity with survey tools (Qualtrics, Alchemer (fka SurveyGizmo)) and VoC platforms.
• Excellent communication skills with the ability to translate data into clear, actionable recommendations.
• Experience interacting cross-functionally with teams such as Product, Customer Support, and Marketing.
• Experience working in a fast-paced, data-driven B2B SaaS environment is preferred.
• Bachelor's degree or equivalent experience.

Must have
• Expertise in analyzing customer feedback data, using tools like Excel/GSheets and SQL, including text analytics experience.
• Experience leveraging data warehouses to extract and transform raw data.
• Strong experience building visualizations in Google Slides or PowerPoint and dashboards in Tableau.
• Strong attention to detail and data accuracy in reporting.
• Curiosity, empathy, and a passion for improving the customer experience.

Location

Find out more about our locations by visiting our site.

Compensation & Benefits

The compensation that we reasonably expect to pay for this role is: $80,000 - $103,000 [base pay / OTE].

The actual compensation for this role will be determined by a variety of factors, including but not limited to the candidate’s skills, education, experience, and internal equity.

Please note that compensation is just one aspect of a comprehensive Total Rewards package. The compensation range listed here does not include additional benefits or any discretionary bonuses you may be eligible for based on your role and/or employment type.

Regular full-time employees are eligible for benefits - see here.",2025-07-14T00:00:00.000Z,2025-07-25,"['3–5+ years of experience in customer insights, data analysis, or customer experience strategy roles', 'Familiarity with survey tools (Qualtrics, Alchemer (fka SurveyGizmo)) and VoC platforms', 'Excellent communication skills with the ability to translate data into clear, actionable recommendations', 'Experience interacting cross-functionally with teams such as Product, Customer Support, and Marketing', ""Bachelor's degree or equivalent experience"", 'Expertise in analyzing customer feedback data, using tools like Excel/GSheets and SQL, including text analytics experience', 'Experience leveraging data warehouses to extract and transform raw data', 'Strong experience building visualizations in Google Slides or PowerPoint and dashboards in Tableau', 'Strong attention to detail and data accuracy in reporting', 'Curiosity, empathy, and a passion for improving the customer experience']","['You’ll be a critical partner in uncovering actionable insights that guide cross-functional decisions and fuel exceptional customer journeys', 'Drive strategic decision-making by identifying customer insights, opportunities, and pain points through the analysis of structured and unstructured data from multiple sources (e.g. surveys, support tickets, call transcripts, NPS/CSAT/Customer Effort scores, behavioral data)', 'Socialize insights and influence organizational strategies using tools like Tableau and reports with effective data visualizations and clear narratives', 'Enhance cross-functional collaboration by acting as a central hub for customer insights, fostering a shared understanding of the customer across all departments, and promoting a customer-centric culture', 'Partner across Services teams to inform and support efforts to build customer experiences based on customer expectations, needs, preferences, and behaviors']",True,[],,"['Customer Insights Analysis', 'SQL', 'Text Analytics', 'Data Visualization', 'Survey Tools', 'Data Warehousing', 'Behavioral Data Analysis']","Customer Insights Analysis: Used to identify customer opportunities and pain points by analyzing structured and unstructured data such as surveys, support tickets, and behavioral data.; SQL: Employed to extract and transform raw data from data warehouses for analysis.; Text Analytics: Applied to analyze unstructured customer feedback data like call transcripts and support tickets.; Data Visualization: Utilized tools like Tableau, Google Slides, and PowerPoint to create dashboards and reports that communicate insights effectively.; Survey Tools: Familiarity with Qualtrics and Alchemer is required to gather and analyze customer feedback data.; Data Warehousing: Experience leveraging data warehouses to access and prepare data for customer experience analysis.; Behavioral Data Analysis: Analyzing customer behavior data to inform strategic decision-making and improve customer journeys."
yoPki0mc0ZKhQjdQAAAAAA==,Data Analyst & Data Modeler,"Candidates must have an active U.S. government security clearance, or the ability to obtain one to be considered for this position. Please read the “Security Clearance Eligibility” section below before applying to this position.

NineTwelve is seeking an individual to fill a Data Analyst & Modeler position for a hybrid role in Crane, Indiana. This position requires working onsite in Crane, Indiana, at least 50% of the time and occasionally in Indianapolis. This is a junior-level position that supports a government hypersonic testing program in the gathering and analysis of hypersonic testing data. Ideal candidates have prior government experience in sensor packages, data collection, recovery, and analytics. Additionally, candidates must be self-motivated and highly organized, have the ability to engage and collaborate with key internal and external stakeholders, and take initiative on developing, implementing, and maintaining processes and deliverables.

Security Clearance Eligibility

A candidate must have an active U.S. government security clearance OR be eligible to obtain and hold a security clearance.

Candidates must:
• Be a U.S. citizen.
• Not be considered a dual citizen, AND are not currently holding a passport from a country other than the U.S.
• Not have been dishonorably discharged from the military.
• Not be currently involved in illegal drug use.
• Not had a clearance revoked for security reasons.

DUTIES AND RESPONSIBILITIES
• Create Data Handling and Management Plan (DHMP) Review Template
• Coordinate with the tech Team to get DHMP for a flight test
• Coordinate review of flight test platform DHMPs with all teams/companies represented on HyperLink
• Identify HyperLink data of interest, gaps in data collection, and data uncertainties from the DHMP
• Coordinate with Tech Team to influence instrumentation on the flight to get relevant data from the flight and close gaps identified from DHMP
• Participate in DARs
• Collect documentation from hypersonic community on sensor packages available, whether through MACH-TB or experiments or other programs
• Identify what parameters affect M&S models the most and what flight-testing instrumentation are being used to measure those parameters. Account for data uncertainty introduced by the instrumentation itself
• Populate sensor matrix
• Document data discovery process and storage requirements

QUALIFICATIONS & SKILLS
• Bachelor's degree in engineering, Computer Science, or related field
• 1-2 years of Data Analytics experience in government (preferred)
• Knowledge or awareness of flight-testing sensors, on and off-board
• Experience reading and using DHMPs
• Data entry and/or engineering skills
• Data analysis experience
• Excellent oral and written communication and interpersonal skills
• Highly organized
• Ability to interface, collaborate, and build working relationships with government representatives, internal personnel, contractors, and other stakeholders

EDUCATION

Bachelor's degree in engineering, computer science, or related field

REQUIRED QUALIFICATIONS

Active U.S. government security clearance, or the ability to obtain one (see SECURITY CLEARANCE ELIGIBILITY)

COMPENSATION

The salary range is $60,000-$85,000 (per year) and is based on experience and qualifications. Benefits include company sponsored health insurance, 401k, and two weeks’ PTO for full-time employees.",2025-07-24T00:00:00.000Z,2025-07-25,"['Candidates must have an active U.S. government security clearance, or the ability to obtain one to be considered for this position', 'Ideal candidates have prior government experience in sensor packages, data collection, recovery, and analytics', 'Additionally, candidates must be self-motivated and highly organized, have the ability to engage and collaborate with key internal and external stakeholders, and take initiative on developing, implementing, and maintaining processes and deliverables', 'A candidate must have an active U.S. government security clearance OR be eligible to obtain and hold a security clearance', 'Be a U.S. citizen', 'Not be considered a dual citizen, AND are not currently holding a passport from a country other than the U.S', 'Not have been dishonorably discharged from the military', 'Not be currently involved in illegal drug use', 'Not had a clearance revoked for security reasons', 'Document data discovery process and storage requirements', ""Bachelor's degree in engineering, Computer Science, or related field"", 'Knowledge or awareness of flight-testing sensors, on and off-board', 'Experience reading and using DHMPs', 'Data entry and/or engineering skills', 'Data analysis experience', 'Excellent oral and written communication and interpersonal skills', 'Highly organized', 'Ability to interface, collaborate, and build working relationships with government representatives, internal personnel, contractors, and other stakeholders', ""Bachelor's degree in engineering, computer science, or related field"", 'Active U.S. government security clearance, or the ability to obtain one (see SECURITY CLEARANCE ELIGIBILITY)']","['Create Data Handling and Management Plan (DHMP) Review Template', 'Coordinate with the tech Team to get DHMP for a flight test', 'Coordinate review of flight test platform DHMPs with all teams/companies represented on HyperLink', 'Identify HyperLink data of interest, gaps in data collection, and data uncertainties from the DHMP', 'Coordinate with Tech Team to influence instrumentation on the flight to get relevant data from the flight and close gaps identified from DHMP', 'Participate in DARs', 'Collect documentation from hypersonic community on sensor packages available, whether through MACH-TB or experiments or other programs', 'Identify what parameters affect M&S models the most and what flight-testing instrumentation are being used to measure those parameters', 'Account for data uncertainty introduced by the instrumentation itself', 'Populate sensor matrix']",True,[],,"['Data Handling and Management Plan', 'Data Collection', 'Data Analysis', 'Sensor Data', 'Data Uncertainty', 'Modeling and Simulation (M&S) Parameters', 'Data Documentation', 'Data Entry']","Data Handling and Management Plan: Used to create and review templates for managing and organizing flight test data effectively.; Data Collection: Involves gathering hypersonic testing data from sensor packages and flight instrumentation.; Data Analysis: Analyzing collected hypersonic test data to identify gaps, uncertainties, and relevant parameters.; Sensor Data: Data obtained from flight-testing sensors, both onboard and off-board, used for modeling and analysis.; Data Uncertainty: Accounting for inaccuracies or variability introduced by instrumentation in the collected data.; Modeling and Simulation (M&S) Parameters: Identifying key parameters affecting simulation models based on flight test data.; Data Documentation: Documenting data discovery processes and storage requirements for hypersonic testing data.; Data Entry: Inputting data related to sensor matrices and flight test parameters for further analysis."
9ZfVslBUqr53kvS6AAAAAA==,Lead Data Analyst,"Overview

Come join Bethesda Game Studios, the award-winning development team behind Starfield, The Elder Scrolls and Fallout. Bethesda Game Studios strives to offer its employees a well-balanced home and work life by providing competitive salaries, a generous benefits program, and offices located in some of North America’s best cities.

With a goal of creating a culture as fun and diverse as our games and our players, we welcome applicants with unique skillsets, experience levels and backgrounds. If you are passionate about making a meaningful contribution to some of the most significant games in the industry, we’d love to hear from you!

We will consider candidates for any of our four Bethesda Game Studios office locations: Rockville, MD; Montreal, Quebec; Austin, TX; Dallas, TX.

Responsibilities

Your Daily Life at Bethesda Game Studios

As Lead Data Analyst, you will…
• Lead a small team of data analysts focused on engagement, performance, and stability for a portfolio of Bethesda’s games (usually 2-3 related titles)
• Partner with design, production, and business counterparts to elicit and document data needs, gather requirements, and translate them into product specifications and development priorities.
• Establish guidelines and documentation for the data analytics workflow; act as a bridge between technical and non-technical stakeholders to ensure alignment on the use of analytics to support product vision and goals.
• Mentor team members on analytics and communication best practices; conduct feedback and reviews to ensure their growth and smooth integration of new team members.
• Identify trends in game and business data to advise development team and senior leadership on product strategy and opportunities based on technical expertise, quantitative and qualitative analysis, and forecasting.
• Provide actionable insights and analysis to our development and business teams to facilitate the full cycle of game development
• Act as a subject matter expert and resource for best practices in accessing and analyzing data using available reporting methods
• Own the roadmap for data analytics products supporting the product strategy for assigned portfolio of titles. Assist with task assignment towards that goal, when necessary.
• Work with data and gameplay programmers to design, develop, launch, and maintain scalable data products, ensuring that they meet high standards of performance, usability, and accuracy

Qualifications

What Makes You S.P.E.C.I.A.L.
• You have 5 or more years of experience in a data analyst role.
• You have 3 or more years of experience in a lead or manager role
• You possess management skills, including the capacity to provide feedback to and help direct a team of data analysts as well as manage programs for data collection.
• You have applied knowledge of current data analysis visualization techniques, including practical experience with data visualization software (e.g. Tableau, Looker)
• You have strong critical thinking skills with knowledge and experience in analytic techniques and statistics
• You have strong to advanced SQL knowledge, including familiarity with statistical, aggregate, and windowing functions
• You are able to gather requirements and define business needs for data collection and analysis, especially within the game development field
• You have excellent verbal and written communication skills
• You have a passion for Bethesda Game Studios titles

Salary Range

Lead Data Analyst - The typical base pay range for this position at the start of employment is expected to be between $115,000 - $220,000 per year.

ZeniMax has different base pay ranges for different work locations within the United States, which allows us to pay employees competitively and consistently in different geographic markets. The range above reflects the potential base pay across the U.S. for this role; the applicable base pay range will depend on what ultimately is determined to be the candidate’s primary work location. Individual base pay depends on various factors, in addition to primary work location, such as complexity and responsibility of role, job duties/requirements, and relevant experience and skills. Base pay ranges are reviewed and typically updated each year. Offers are made within the base pay range applicable at the time.

At ZeniMax certain roles are eligible for additional rewards, such as merit increases and discretionary bonuses. These awards are allocated based on individual performance and are not guaranteed. Benefits/perks listed here may vary depending on the nature of employment with ZeniMax and the country work location. U.S.-based employees have access to healthcare benefits, a 401(k) plan and company match, short-term and long-term disability coverage, basic life insurance, wellbeing benefits, paid vacation time, paid sick and mental health time, and several paid holidays, among others.

This position is in a union and represented by the Communication Workers of America.

We embrace diversity, equity, and inclusion in everything we do – from recruiting for our studios, publishing and operations to fostering safe and respectful workplaces that encourage collaboration. Our culture is based on principles of respect, inclusion, and fair treatment and we welcome anyone into our family without regard to race, religion, gender identity, sexual orientation, or age.

Our diversity fuels our innovation and inspires us to create game worlds that bring us closer to the global community of players we serve.",,2025-07-25,"['You have 5 or more years of experience in a data analyst role', 'You have 3 or more years of experience in a lead or manager role', 'You possess management skills, including the capacity to provide feedback to and help direct a team of data analysts as well as manage programs for data collection', 'You have applied knowledge of current data analysis visualization techniques, including practical experience with data visualization software (e.g', 'You have strong critical thinking skills with knowledge and experience in analytic techniques and statistics', 'You have strong to advanced SQL knowledge, including familiarity with statistical, aggregate, and windowing functions', 'You are able to gather requirements and define business needs for data collection and analysis, especially within the game development field', 'You have excellent verbal and written communication skills']","['Lead a small team of data analysts focused on engagement, performance, and stability for a portfolio of Bethesda’s games (usually 2-3 related titles)', 'Partner with design, production, and business counterparts to elicit and document data needs, gather requirements, and translate them into product specifications and development priorities', 'Establish guidelines and documentation for the data analytics workflow; act as a bridge between technical and non-technical stakeholders to ensure alignment on the use of analytics to support product vision and goals', 'Mentor team members on analytics and communication best practices; conduct feedback and reviews to ensure their growth and smooth integration of new team members', 'Identify trends in game and business data to advise development team and senior leadership on product strategy and opportunities based on technical expertise, quantitative and qualitative analysis, and forecasting', 'Provide actionable insights and analysis to our development and business teams to facilitate the full cycle of game development', 'Act as a subject matter expert and resource for best practices in accessing and analyzing data using available reporting methods', 'Own the roadmap for data analytics products supporting the product strategy for assigned portfolio of titles', 'Assist with task assignment towards that goal, when necessary', 'Work with data and gameplay programmers to design, develop, launch, and maintain scalable data products, ensuring that they meet high standards of performance, usability, and accuracy']",True,[],,"['SQL', 'Data Visualization Tools', 'Data Analytics Workflow', 'Quantitative and Qualitative Analysis', 'Forecasting', 'Data Product Development', 'Team Leadership and Mentorship']","SQL: Used extensively for querying and analyzing game and business data, including statistical, aggregate, and windowing functions.; Data Visualization Tools: Practical experience with tools like Tableau and Looker to create visual analytics supporting game development and business decisions.; Data Analytics Workflow: Establishing guidelines and documentation to standardize data analysis processes across teams for consistent insights.; Quantitative and Qualitative Analysis: Analyzing game engagement, performance, and stability data to identify trends and inform product strategy.; Forecasting: Applying predictive techniques to anticipate game and business performance trends to guide development priorities.; Data Product Development: Collaborating with programmers to design, develop, and maintain scalable data products that support game analytics.; Team Leadership and Mentorship: Leading and mentoring a team of data analysts to ensure best practices in analytics and communication."
zQ9-rN43aeJNuHiIAAAAAA==,Senior Digital Data Analyst,"Overview

You have a passion for data—finding answers, creating stories, and driving business results. Come, love what you do as a Senior Digital Data Analyst at Room & Board.

As a Senior Digital Data Analyst at Room & Board, you’ll play a pivotal role in advancing our e-commerce strategy, which has grown from basic reporting to sophisticated, data-driven personalization and optimization powered by Adobe Experience Cloud tools. You’ll lead initiatives in analytics, personalization, and data pipeline development—bridging technical implementation with business strategy to deliver scalable, personalized customer experiences that drive measurable outcomes.

You’ll work hands-on with Adobe Analytics SDK, Adobe Target Premium, Adobe Tags, and Alteryx, collaborating with teams across brand experience, product, web development, and business systems. With approximately 10–20% of your time focused on data science and the rest dedicated to implementation and analytics, you’ll be a key leader in shaping our data-driven approach to e-commerce.

Location: Our Central Office

4600 Olson Memorial Highway, Golden Valley, MN 55422

Please note: This is a hybrid role working 3 days in our office. We are not currently considering fully remote candidates.

You’ll share your talents as a Senior Digital Data Analyst in the following ways:
• Lead the implementation and maintenance of digital analytics tools and infrastructure, applying strong hands-on experience to ensure scalable, reliable data systems.
• Shape and evolve our personalization strategy by defining audience segments, setting conversion goals, and executing A/B testing and targeted experiences.
• Build and optimize data pipelines that support reporting, personalization, and marketing strategies.
• Serve as the primary analytics and personalization contact, collaborating across web development, digital experience, branding, product, and business systems teams.
• Ensure data accuracy and governance through tag management, tagging audits, and data quality initiatives.
• Manage analytics projects aligned with marketing campaigns, product launches, and development timelines, balancing strategic priorities with execution.
• Develop predictive models and segmentation strategies to support business goals and enhance customer experiences.
• Deliver ongoing and ad hoc reporting, translating complex data into actionable insights for stakeholders.
• Foster a culture of continuous learning by sharing best practices and encouraging data-driven decision-making.
• Partner with the Director of Business Intelligence to define and execute long-term analytics and personalization strategies, including regular audits and roadmap development.

The attributes you’ll bring as a Senior Digital Data Analyst:

You exemplify our Staff Member Attributes – Inclusive, Authentic, Work Ethic, Collaborative, and Curious.
• You build inclusive environments by aligning analytics efforts with diverse team needs.
• You communicate transparently and align your work with Room & Board’s customer-centric values.
• You demonstrate accountability and a commitment to delivering high-quality, data-driven outcomes.
• You collaborate effectively across departments to drive shared goals.
• You’re curious and proactive in exploring new technologies and personalization strategies.
• You support others by sharing expertise, offering feedback, and fostering a culture of innovation.
• You have excellent verbal and written communication skills and can convey complex data clearly to diverse audiences.

The knowledge, education, and experience you’ll bring as a Senior Digital Data Analyst:
• Bachelor’s degree in Data Science, Statistics, Computer Science, or a related quantitative field.
• 5+ years of experience in e-commerce or digital marketing as a Data Scientist or similar role.
• Certifications (preferred): Adobe Analytics Data Analyst/Developer, Adobe Experience Platform Data Engineer, Adobe Target Business Practitioner.
• Proficiency in Adobe Tags, Adobe Analytics SDK, and Adobe Target.
• Expertise in predictive modeling, statistical analysis, and machine learning.
• Experience with ETL tools like Alteryx and API data connections.
• Strong programming skills in Python or R, Java, REGEX, and SQL.
• Familiarity with A4T integration and e-commerce metrics.

What you'll find working here as a Senior Digital Data Analyst:
• Salary: $120,000 - $160,000 / year based on experience/qualifications.
• Benefits that focus on holistic well-being. The whole person matters, not just the one who shows up for work. That's why we invest in holistic well-being that supports and encourages you to live a full life. Besides a competitive paycheck, we offer several awesome perks to help you thrive in every aspect of life. Picture this: three weeks paid vacation, a generous 401(k) match, profit-sharing, and a whole bunch of cool extras. And here's something we're especially proud of - we're a 100% employee-owned company. Through our Employee Stock Ownership Plan, every staff member shares in our growth and success. These are benefits that support you physically, emotionally, and financially - from head to toe!
• Meaningful work. We create a meaningful work experience by empowering everyone to contribute, taking pride in everything we do, and making the world sustainable, inclusive and beautiful.
• A culture of respect. We sustain a culture of respect by relying on our shared values, building supportive and kind teams, and ensuring all voices are heard and celebrated. To view our benefits in detail and to learn more about our culture, please visit our career site at https://www.roomanboard.com/careers.

Application Deadline: The position will remain open until filled; there is no specified deadline.

Room and Board is a modern furniture and home decor retailer committed to creating beautiful, well-made products while providing exceptional customer service. Our mission is to help people create homes they love through timeless designs, sustainable practices, and a focus on quality craftsmanship. To view our benefits in detail and to learn more about our culture, please visit our career site at https://www.roomanboard.com/careers.

Room & Board is an equal employment opportunity employer. Our policy is not to unlawfully discriminate against any applicant or staff member on the basis of age, race, color, sex, sexual orientation, gender identity or expression, religion, national origin, disability, or any other consideration made unlawful by applicable federal, state, or local laws. We also prohibit harassment of applicants and staff members based on any protected category, characteristic or status. It is also our policy to comply with all applicable state, federal and local laws respecting consideration of unemployment status in making hiring decisions.

As an applicant, you have rights under Federal Employment Laws, and your state may offer additional protections. To view applicable laws, visit our partner site.

Discover a career designed to be different.

Salary",2025-07-25T04:00:00.000Z,2025-07-25,"['You support others by sharing expertise, offering feedback, and fostering a culture of innovation', 'You have excellent verbal and written communication skills and can convey complex data clearly to diverse audiences', 'The knowledge, education, and experience you’ll bring as a Senior Digital Data Analyst:', 'Bachelor’s degree in Data Science, Statistics, Computer Science, or a related quantitative field', '5+ years of experience in e-commerce or digital marketing as a Data Scientist or similar role', 'Proficiency in Adobe Tags, Adobe Analytics SDK, and Adobe Target', 'Expertise in predictive modeling, statistical analysis, and machine learning', 'Experience with ETL tools like Alteryx and API data connections', 'Strong programming skills in Python or R, Java, REGEX, and SQL', 'Familiarity with A4T integration and e-commerce metrics']","['As a Senior Digital Data Analyst at Room & Board, you’ll play a pivotal role in advancing our e-commerce strategy, which has grown from basic reporting to sophisticated, data-driven personalization and optimization powered by Adobe Experience Cloud tools', 'You’ll lead initiatives in analytics, personalization, and data pipeline development—bridging technical implementation with business strategy to deliver scalable, personalized customer experiences that drive measurable outcomes', 'You’ll work hands-on with Adobe Analytics SDK, Adobe Target Premium, Adobe Tags, and Alteryx, collaborating with teams across brand experience, product, web development, and business systems', 'With approximately 10–20% of your time focused on data science and the rest dedicated to implementation and analytics, you’ll be a key leader in shaping our data-driven approach to e-commerce', 'Lead the implementation and maintenance of digital analytics tools and infrastructure, applying strong hands-on experience to ensure scalable, reliable data systems', 'Shape and evolve our personalization strategy by defining audience segments, setting conversion goals, and executing A/B testing and targeted experiences', 'Build and optimize data pipelines that support reporting, personalization, and marketing strategies', 'Serve as the primary analytics and personalization contact, collaborating across web development, digital experience, branding, product, and business systems teams', 'Ensure data accuracy and governance through tag management, tagging audits, and data quality initiatives', 'Manage analytics projects aligned with marketing campaigns, product launches, and development timelines, balancing strategic priorities with execution', 'Develop predictive models and segmentation strategies to support business goals and enhance customer experiences', 'Deliver ongoing and ad hoc reporting, translating complex data into actionable insights for stakeholders', 'Foster a culture of continuous learning by sharing best practices and encouraging data-driven decision-making', 'Partner with the Director of Business Intelligence to define and execute long-term analytics and personalization strategies, including regular audits and roadmap development', 'You exemplify our Staff Member Attributes – Inclusive, Authentic, Work Ethic, Collaborative, and Curious', 'You build inclusive environments by aligning analytics efforts with diverse team needs', 'You communicate transparently and align your work with Room & Board’s customer-centric values', 'You demonstrate accountability and a commitment to delivering high-quality, data-driven outcomes', 'You collaborate effectively across departments to drive shared goals', 'You’re curious and proactive in exploring new technologies and personalization strategies']",True,[],,"['Predictive Modeling', 'Statistical Analysis', 'Machine Learning', 'A/B Testing', 'Data Pipelines', 'ETL Tools', 'SQL', 'Python', 'R', 'Java', 'Regular Expressions', 'Adobe Analytics SDK', 'Adobe Target', 'Adobe Tags', 'Audience Segmentation', 'Data Governance', 'Reporting and Dashboards', 'E-commerce Metrics']","Predictive Modeling: Used to develop models that forecast customer behavior and support business goals in e-commerce personalization.; Statistical Analysis: Applied to analyze data patterns and support decision-making in marketing and personalization strategies.; Machine Learning: Utilized for building models that enhance personalization and optimization of customer experiences.; A/B Testing: Executed to evaluate the effectiveness of different personalization and marketing strategies.; Data Pipelines: Built and optimized to support reporting, personalization, and marketing data flows.; ETL Tools: Used Alteryx and API data connections to extract, transform, and load data for analytics and reporting.; SQL: Employed for querying and managing data within relational databases to support analytics.; Python: Used for programming tasks related to data analysis, modeling, and pipeline development.; R: Applied for statistical computing and data analysis in support of predictive modeling.; Java: Utilized for programming related to data processing and integration within analytics systems.; Regular Expressions: Used for pattern matching and data cleaning within analytics and tagging processes.; Adobe Analytics SDK: Leveraged to collect and analyze digital data for e-commerce performance and personalization.; Adobe Target: Used to create and manage personalized customer experiences and conduct A/B testing.; Adobe Tags: Managed for accurate data collection and governance through tag management and audits.; Audience Segmentation: Defined to target specific customer groups for personalized marketing and experiences.; Data Governance: Ensured through tagging audits and data quality initiatives to maintain reliable analytics.; Reporting and Dashboards: Delivered ongoing and ad hoc reports translating complex data into actionable business insights.; E-commerce Metrics: Monitored and analyzed to measure performance and optimize digital marketing strategies."
Da7J1WaGX3sj9qDgAAAAAA==,Data Analyst,"Odyssey Reinsurance Company (OdysseyRe) is the global reinsurance arm of Odyssey Group, one of the world’s leading providers of reinsurance and specialty insurance. OdysseyRe offers a broad range of property, casualty, and specialty reinsurance products, providing capital and risk management solutions for clients to efficiently manage economic risk through a network of branch and representative offices across North America, Latin America, EMEA (Europe, Middle East & Africa), AsiaPacific and London.

OdysseyRe is an equal opportunity employer with excellent benefits and a strong commitment to providing training and opportunities for our staff. We provide employees an innovative, enriching environment and take great pride in their career growth.

OdysseyRe is rated A+ (Superior) by AM Best and A+ (Strong) by Standard and Poor’s. Odyssey Group is a subsidiary of Fairfax Financial Holdings Limited, which is traded on the Toronto Stock Exchange under the symbol FFH.

Data Analyst

We are an E-Verify employer - all hired positions require successfully passing an E-Verify Check.

Navigate the links below to learn more about careers at OdysseyRe.

Workplace Initiatives

Career Areas for Professionals

A Rewarding Workplace

Follow us on LinkedIn for company highlights",2025-07-20T00:00:00.000Z,2025-07-25,,,False,[],,['Data Analysis'],"Data Analysis: The role involves analyzing data to support reinsurance and risk management solutions, which is central to the data analyst position."
cmKgYTV8VSvb052yAAAAAA==,Lead Data Analyst,"Vanguard is looking for a senior level data analyst with experience presenting recommendations to senior management, developing innovative solutions, and is technically skilled in data quality & analytics tools. You will become an expert in the critical data managed, provide thought leadership into transformative decisions and initiatives, and deepen relationships and business acumen while consulting with stakeholders and partners, inclusive of our external data vendors. By innovating new ways to improve our data management processes to enable AI ready data, we want to leverage evolving data management capabilities and analytics tools to move our clients forward creating trusted data to support AI and BI solutions.

Core Responsibilities
• Serves as a subject matter expert (SME) of data sets for a given industry, data storage systems, and the operational processes being supported. Maintains awareness of changing business needs to create appropriate project solutions.
• Leads process design efforts to support new offerings, business initiatives, or improvement projects. Performs root cause analyses of complex data errors. Identifies opportunities to eliminate future occurrences, prioritizes initiatives, mitigates risk, leverages technology, and recommends short- and long-term solutions for issues.
• Focuses on improving Data Management's service offer and communicates with stakeholders and management to obtain their input and buy-in as appropriate. Recommends, coordinates, documents, and implements changes that will enhance work-flows and procedures. Integrates new or existing technologies into work-flows and communicates to all team members. Analyzes impacts and prepares environment for change.
• Builds and maintains relationships with internal and external partners to define data requirements, develop project specifications, and execute data projects to ensure that the expected outputs are delivered. Provides validation and approval of project deliverables.
• Identifies solutions independently and with input from internal and external partners, external vendors, and industry contacts to enable best-in-class data management practices, scalability, and cost effectiveness. Leads and consults on new projects to ensure operational readiness upon implementation into the live environment.
• Participates in special projects and performs other duties as assigned.

Qualifications
• Intermediate to advanced technical skills required – SQL, Python, AWS, Tableau
• Strong consultation, data storytelling, and stakeholder management skills
• Strong professional presence and experience presenting recommendations to senior management.
• Strong data analysis and problem-solving skills.
• Skilled and passionate about developing innovative solutions.
• Expertise in Data Management & Data Quality best practices.
• Financial or Investment data background is a plus.
• Minimum of five years of related work experience.
• Undergraduate degree or equivalent combination of training and experience. Graduate degree preferred.
• Nice to have- MS Dynamics

Special Factors

Sponsorship
Vanguard is not offering visa sponsorship for this position.

About Vanguard

At Vanguard, we don't just have a mission—we're on a mission.

To work for the long-term financial wellbeing of our clients. To lead through product and services that transform our clients' lives. To learn and develop our skills as individuals and as a team. From Malvern to Melbourne, our mission drives us forward and inspires us to be our best.

How We Work

Vanguard has implemented a hybrid working model for the majority of our crew members, designed to capture the benefits of enhanced flexibility while enabling in-person learning, collaboration, and connection. We believe our mission-driven and highly collaborative culture is a critical enabler to support long-term client outcomes and enrich the employee experience.",2025-07-18T00:00:00.000Z,2025-07-25,"['Vanguard is looking for a senior level data analyst with experience presenting recommendations to senior management, developing innovative solutions, and is technically skilled in data quality & analytics tools', 'Intermediate to advanced technical skills required – SQL, Python, AWS, Tableau', 'Strong consultation, data storytelling, and stakeholder management skills', 'Strong professional presence and experience presenting recommendations to senior management', 'Strong data analysis and problem-solving skills', 'Skilled and passionate about developing innovative solutions', 'Expertise in Data Management & Data Quality best practices', 'Minimum of five years of related work experience', 'Undergraduate degree or equivalent combination of training and experience']","['You will become an expert in the critical data managed, provide thought leadership into transformative decisions and initiatives, and deepen relationships and business acumen while consulting with stakeholders and partners, inclusive of our external data vendors', 'By innovating new ways to improve our data management processes to enable AI ready data, we want to leverage evolving data management capabilities and analytics tools to move our clients forward creating trusted data to support AI and BI solutions', 'Serves as a subject matter expert (SME) of data sets for a given industry, data storage systems, and the operational processes being supported', 'Maintains awareness of changing business needs to create appropriate project solutions', 'Leads process design efforts to support new offerings, business initiatives, or improvement projects', 'Performs root cause analyses of complex data errors', 'Identifies opportunities to eliminate future occurrences, prioritizes initiatives, mitigates risk, leverages technology, and recommends short- and long-term solutions for issues', ""Focuses on improving Data Management's service offer and communicates with stakeholders and management to obtain their input and buy-in as appropriate"", 'Recommends, coordinates, documents, and implements changes that will enhance work-flows and procedures', 'Integrates new or existing technologies into work-flows and communicates to all team members', 'Analyzes impacts and prepares environment for change', 'Builds and maintains relationships with internal and external partners to define data requirements, develop project specifications, and execute data projects to ensure that the expected outputs are delivered', 'Provides validation and approval of project deliverables', 'Identifies solutions independently and with input from internal and external partners, external vendors, and industry contacts to enable best-in-class data management practices, scalability, and cost effectiveness', 'Leads and consults on new projects to ensure operational readiness upon implementation into the live environment', 'Participates in special projects and performs other duties as assigned']",True,[],,"['SQL', 'Python', 'AWS', 'Tableau', 'Data Quality Management', 'Data Management', 'Root Cause Analysis', 'Data Storytelling', 'Business Intelligence (BI)']","SQL: Used for querying and managing data within relational databases to support data analysis and reporting.; Python: Utilized for data analysis, scripting, and developing innovative data management solutions.; AWS: Cloud platform leveraged for data storage, processing, and analytics infrastructure.; Tableau: Business Intelligence tool used to create dashboards and visualize data insights for stakeholders.; Data Quality Management: Practices focused on ensuring accuracy, consistency, and reliability of data used in analytics and decision-making.; Data Management: Overseeing data storage systems, operational processes, and workflows to maintain and improve data accessibility and usability.; Root Cause Analysis: Methodology applied to identify and resolve complex data errors and prevent future occurrences.; Data Storytelling: Communicating data insights effectively to senior management and stakeholders to support decision-making.; Business Intelligence (BI): Creating trusted data solutions and dashboards to support business decision processes."
sAxzYOVGt9V0xvF9AAAAAA==,Systems and Data Analyst (Systems and Data Analyst-General),"Job Description

At Boeing, we innovate and collaborate to make the world a better place. We’re committed to fostering an environment for every teammate that’s welcoming, respectful and inclusive, with great opportunity for professional growth. Find your future with us.

Boeing Global Services, Digital Solutions & Analytics (DS&A) is seeking a level 2 Technical Product Support Analyst for 24x7x365 technical customer support. The scope of support covers Boeing’s current and next generation Software as a Service (SaaS) platforms, licensed software products, Identity and Access Management services spanning large-scale hybrid cloud environments. This includes e-Commerce, traditional web application and native mobile application delivery channels.

This position may be based out of our Seattle Washington and/or Englewood Colorado offices.

Your primary job responsibilities include technical product support investigating, analyzing, troubleshooting, and resolving high/medium/low priority service requests from our internal (Boeing) and external Customers (Aircraft Owner, Operator, MRO, Partners and Suppliers) as defined in our Licensed Software Support Policy.

This is a variable shift position and shift slotting will be determined by business and customer needs.

Position Responsibilities:
• Provide responsive 24x7x365 world class technical customer service and support for service requests, phone calls and email inquiries.
• Utilize and maintain knowledge, troubleshooting guides and self-help resources for internal team and external customer usage.
• Contribute to continuous improvement, problem management, root cause and corrective action (RCCA) activities to improve customer satisfaction, reduce repetitive issues, and eliminate negative impacting events.
• Draft and publish global communications for hardware/software related changes, upgrades, issues, known defects and high/medium priority alerts.
• Continuous learning by staying up to date with new software/hardware products, features and Information Technology (IT) support methods.
• Be a resource and partner with cross functional and matrix organization team members in delivering superior customer service and support.

Basic Qualifications (Required Skills/Experience):
• Experience and competency in troubleshooting, analysis and problem solving strategies to address simple to complex customer inquiries.
• Effective written and speaking skills to communicate with individuals with English as a primary language and those with English as a second language.
• Willingness to work in 24x7x365 technical customer support environment.

Preferred Qualifications (Desired Skills/Experience):
• Associate’s degree or higher
• IT support or equivalent background across one or more of the software systems development / sustaining disciplines a plus.
• Project management tools and practices as well as knowledge of project and software implementation a plus.
• Knowledge and/or experience within the aviation industry
• Knowledge of Aviation training practices and protocols.

Drug Free Workplace:

Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

Pay & Benefits:

At Boeing, we strive to deliver a Total Rewards package that will attract, engage and retain the top talent. Elements of the Total Rewards package include competitive base pay and variable compensation opportunities.

The Boeing Company also provides eligible employees with an opportunity to enroll in a variety of benefit programs, generally including health insurance, flexible spending accounts, health savings accounts, retirement savings plans, life and disability insurance programs, and a number of programs that provide for both paid and unpaid time away from work.

The specific programs and options available to any given employee may vary depending on eligibility factors such as geographic location, date of hire, and the applicability of collective bargaining agreements.

Pay is based upon candidate experience and qualifications, as well as market and business considerations.

Summary Pay Range: $75,650.00-$102,350.00

Applications for this position will be accepted until Jul. 24, 2025

Export Control Requirements: This position must meet export control compliance requirements. To meet export control compliance requirements, a “U.S. Person” as defined by 22 C.F.R. §120.15 is required. “U.S. Person” includes U.S. Citizen, lawful permanent resident, refugee, or asylee.

Export Control Details: US based job, US Person required

Relocation

Relocation assistance is not a negotiable benefit for this position.

Visa Sponsorship

Employer will not sponsor applicants for employment visa status.

Shift

This position is for 2nd shift

Equal Opportunity Employer:

Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.",2025-07-08T00:00:00.000Z,2025-07-25,"['Experience and competency in troubleshooting, analysis and problem solving strategies to address simple to complex customer inquiries', 'Effective written and speaking skills to communicate with individuals with English as a primary language and those with English as a second language', 'Willingness to work in 24x7x365 technical customer support environment', 'To meet export control compliance requirements, a “U.S. Person” as defined by 22 C.F.R. §120.15 is required', '“U.S. Person” includes U.S. Citizen, lawful permanent resident, refugee, or asylee', 'Export Control Details: US based job, US Person required']","['The scope of support covers Boeing’s current and next generation Software as a Service (SaaS) platforms, licensed software products, Identity and Access Management services spanning large-scale hybrid cloud environments', 'Your primary job responsibilities include technical product support investigating, analyzing, troubleshooting, and resolving high/medium/low priority service requests from our internal (Boeing) and external Customers (Aircraft Owner, Operator, MRO, Partners and Suppliers) as defined in our Licensed Software Support Policy', 'This is a variable shift position and shift slotting will be determined by business and customer needs', 'Provide responsive 24x7x365 world class technical customer service and support for service requests, phone calls and email inquiries', 'Utilize and maintain knowledge, troubleshooting guides and self-help resources for internal team and external customer usage', 'Contribute to continuous improvement, problem management, root cause and corrective action (RCCA) activities to improve customer satisfaction, reduce repetitive issues, and eliminate negative impacting events', 'Draft and publish global communications for hardware/software related changes, upgrades, issues, known defects and high/medium priority alerts', 'Continuous learning by staying up to date with new software/hardware products, features and Information Technology (IT) support methods', 'Be a resource and partner with cross functional and matrix organization team members in delivering superior customer service and support', 'Export Control Requirements: This position must meet export control compliance requirements']",False,[],,"['Troubleshooting and Problem Solving', 'Root Cause and Corrective Action (RCCA)', 'Software as a Service (SaaS) Platforms', 'Identity and Access Management', 'Technical Customer Support', 'Continuous Improvement', 'Project Management Tools and Practices']","Troubleshooting and Problem Solving: Used to investigate, analyze, and resolve technical service requests and customer inquiries in software and IT support.; Root Cause and Corrective Action (RCCA): Applied to identify underlying issues and implement corrective measures to improve customer satisfaction and reduce recurring problems.; Software as a Service (SaaS) Platforms: Supported and maintained as part of the technical product support scope, including next-generation cloud-based software delivery.; Identity and Access Management: Managed within large-scale hybrid cloud environments to ensure secure access and authentication for software products.; Technical Customer Support: Provided 24x7x365 support for internal and external customers involving software, hardware, and IT service requests.; Continuous Improvement: Engaged in ongoing enhancement of support processes and knowledge resources to improve service quality.; Project Management Tools and Practices: Utilized to assist in software implementation and support project coordination."
yc4y5bmxG1zHCC8fAAAAAA==,"Analyst, Data Analytics, US Portfolio Transformation","At Johnson & Johnson, we believe health is everything. Our strength in healthcare innovation empowers us to build a world where complex diseases are prevented, treated, and cured, where treatments are smarter and less invasive, and solutions are personal. Through our expertise in Innovative Medicine and MedTech, we are uniquely positioned to innovate across the full spectrum of healthcare solutions today to deliver the breakthroughs of tomorrow, and profoundly impact health for humanity. Learn more at https://www.jnj.com

Job Function:
Sales Enablement

Job Sub Function:
Sales Operations & Administration

Job Category:
Professional

All Job Posting Locations:
Cincinnati, Ohio, United States of America, Raritan, New Jersey, United States of America

Job Description:

Johnson & Johnson is recruiting for an Analyst, Data Analytics, US Portfolio Transformation to join our MedTech Surgery business located at our Raritan, NJ or Cincinnati, OH sites.

#Li-Hybrid

This is a limited duration role. (12/31/2026 end date)

Eligibility for severance.

About Surgery

Fueled by innovation at the intersection of biology and technology, we're developing the next generation of smarter, less invasive, more personalized treatments.

Are you passionate about improving and expanding the possibilities of surgery? Ready to join a team that's reimagining how we heal? Our Surgery team will give you the chance to deliver surgical technologies and solutions to surgeons and healthcare professionals around the world. Your contributions will help effectively treat some of the world's most prevalent conditions such as obesity, cardiovascular disease and cancer. Patients are waiting!

Your unique talents will help patients on their journey to wellness. Learn more at https://www.jnj.com/medtech

The Analyst, Data Analytics - US Portfolio Transformation, will deliver data driven insights and develop analytics resources to support the Medtech Surgery transformation. Will partner and collaborate closely with the Supply Chain, Marketing, FSO, KAM, and Customer Solutions teams. Key responsibilities include:
• Deliver the metrics and reporting tools linked to transformation execution inclusive of financial indicators, conversion progress, performance vs plan, and other key information to commercial leadership including Director, US Portfolio Transformation.
• Delivers National, Area, Regional, and Account level analytics and insights related to transformation activities.
• Responsible for KPI measurement and reporting for all related transformation initiatives.
• Collaborates with multidisciplinary partners to drive Surgery transformation forward in a timely manner.
• Execution of innovative initiatives aligned to the HIT Next needs of the commercial organization.
• Ensures data analytics are integrated at all levels (National, GPO, IDN, Area, Region, Territory, Account) to monitor and ultimately improve execution, speed to next action, and accountability across the organization.

This job is salaried.

Qualifications
• Bachelor's degree required

Experience:
• 2+ years professional business experience across Commercial or Supply Chain roles preferred
• Data Analytics experience required
• Technical Skills including Tableau, MS Office, Power BI and other data tool sets required.
• Strong knowledge of Excel (i.e. vLookups, pivot tables) is required.
• Experience in Medical Devices/Technology preferred
• Experience partnering with multi-functional business partners preferred.

Knowledge, Skills and Abilities:
• The ability to manage multiple projects and initiatives and work independently while demonstrating initiative.
• The ability to work across functions (Sales, Marketing, KAM, Supply Chain, Finance) where priorities change rapidly and strict timelines exist is required
• Deep knowledge of MedTech Industry and US Hospital Systems
• Understanding of data analysis, US sales/ contracting landscape to build out meaningful and actionable reporting and metrics.
• Understanding of US Medtech Surgery systems and data workflows.
• Creative thinking to develop effective strategies and translate into actionable insights to monitor and drive commercial effectiveness.
• Ability to establish a strategy, a complex project plan and then complete proactively, be it independently or within a team
• Exceptional interpersonal, professionalism, communication and presentation skills.
• Lean, Six-Sigma or Process Excellence training and/or certification is appreciated.

Benefits Summary:
• Employees and/or eligible dependents may be eligible to participate in the following Company sponsored employee benefit programs: medical, dental, vision, life insurance, short- and long-term disability, business accident insurance, and group legal insurance.
• Employees may be eligible to participate in the Company's consolidated retirement plan (pension) and savings plan (401(k)).
• This position is eligible to participate in the Company's long-term incentive program.
• Employees are eligible for the following time off benefits:
• Vacation - up to 120 hours per calendar year
• Sick time - up to 40 hours per calendar year; for employees who reside in the State of Washington - up to 56 hours per calendar year
• Holiday pay, including Floating Holidays - up to 13 days per calendar year
• Work, Personal and Family Time - up to 40 hours per calendar year

Additional information can be found through the link below!

https://www.careers.jnj.com/employee-benefits

Johnson & Johnson is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, national origin, disability, protected veteran status or other characteristics protected by federal, state or local law. We actively seek qualified candidates who are protected veterans and individuals with disabilities as defined under VEVRAA and Section 503 of the Rehabilitation Act.

Johnson & Johnson is committed to providing an interview process that is inclusive of our applicants' needs. If you are an individual with a disability and would like to request an accommodation, please contact us via https://www.jnj.com/contact-us/careers or contact AskGS to be directed to your accommodation resource.

The anticipated base pay range for this position is :
$63,000 - $102,350

Additional Description for Pay Transparency:
The Company maintains highly competitive, performance-based compensation programs. Under current guidelines, this position is eligible for an annual performance bonus in accordance with the terms of the applicable plan. The annual performance bonus is a cash bonus intended to provide an incentive to achieve annual targeted results by rewarding for individual and the corporation's performance over a calendar/performance year. Bonuses are awarded at the Company's discretion on an individual basis.",2025-07-10T00:00:00.000Z,2025-07-25,"[""Bachelor's degree required"", 'Data Analytics experience required', 'Technical Skills including Tableau, MS Office, Power BI and other data tool sets required', 'Strong knowledge of Excel (i.e', 'vLookups, pivot tables) is required', 'The ability to manage multiple projects and initiatives and work independently while demonstrating initiative', 'The ability to work across functions (Sales, Marketing, KAM, Supply Chain, Finance) where priorities change rapidly and strict timelines exist is required', 'Deep knowledge of MedTech Industry and US Hospital Systems', 'Understanding of data analysis, US sales/ contracting landscape to build out meaningful and actionable reporting and metrics', 'Understanding of US Medtech Surgery systems and data workflows', 'Creative thinking to develop effective strategies and translate into actionable insights to monitor and drive commercial effectiveness', 'Ability to establish a strategy, a complex project plan and then complete proactively, be it independently or within a team', 'Exceptional interpersonal, professionalism, communication and presentation skills', 'Lean, Six-Sigma or Process Excellence training and/or certification is appreciated']","[""Your contributions will help effectively treat some of the world's most prevalent conditions such as obesity, cardiovascular disease and cancer"", 'The Analyst, Data Analytics - US Portfolio Transformation, will deliver data driven insights and develop analytics resources to support the Medtech Surgery transformation', 'Will partner and collaborate closely with the Supply Chain, Marketing, FSO, KAM, and Customer Solutions teams', 'Deliver the metrics and reporting tools linked to transformation execution inclusive of financial indicators, conversion progress, performance vs plan, and other key information to commercial leadership including Director, US Portfolio Transformation', 'Delivers National, Area, Regional, and Account level analytics and insights related to transformation activities', 'Responsible for KPI measurement and reporting for all related transformation initiatives', 'Collaborates with multidisciplinary partners to drive Surgery transformation forward in a timely manner', 'Execution of innovative initiatives aligned to the HIT Next needs of the commercial organization', 'Ensures data analytics are integrated at all levels (National, GPO, IDN, Area, Region, Territory, Account) to monitor and ultimately improve execution, speed to next action, and accountability across the organization']",True,[],,"['Data Analytics', 'KPI Measurement and Reporting', 'Metrics and Reporting Tools', 'Tableau', 'Power BI', 'Excel (vLookups, Pivot Tables)', 'Data Integration Across Organizational Levels', 'Cross-Functional Collaboration', 'Lean Six Sigma / Process Excellence']","Data Analytics: Core responsibility involving delivering data-driven insights and developing analytics resources to support MedTech Surgery transformation.; KPI Measurement and Reporting: Tracking and reporting key performance indicators related to transformation initiatives to monitor progress and performance.; Metrics and Reporting Tools: Creating and delivering tools for financial indicators, conversion progress, and performance versus plan to commercial leadership.; Tableau: Used as a data visualization tool to create dashboards and reports for analytics and insights.; Power BI: Employed for business intelligence reporting and visualization to support decision-making processes.; Excel (vLookups, Pivot Tables): Utilized for data manipulation, analysis, and reporting through advanced spreadsheet functions.; Data Integration Across Organizational Levels: Ensuring analytics are applied at multiple levels (National, GPO, IDN, Area, Region, Territory, Account) to improve execution and accountability.; Cross-Functional Collaboration: Partnering with teams such as Supply Chain, Marketing, FSO, KAM, and Customer Solutions to drive transformation efforts.; Lean Six Sigma / Process Excellence: Applying process improvement methodologies to enhance operational efficiency and effectiveness."
FLrA7FAa0FoXbqFaAAAAAA==,Mid-Level Data Analyst,"Patterned Learning AI is hiring a Mid-Level Data Analyst with 0 - 3 years of experience. Based in United States - Remote and with Remote ways of working.

Job description and responsibilities:

Role Responsibilities
• Work in close collaboration with the Business Intelligence Lead, Federal Data Lead and other Program teams
• Develop, maintain, and improve BI tools, build and enhance standard operating procedures (SOPs)
• Manage various data sets and active Google workbooks with adjacent contract teams, monitor and analyze financial health information at the project and program levels
• Communicate with client leadership to assess data needs and emerging requirements
• Lead Tableau projects for the BI team - will be responsible for developing new (custom) dashboards, maintaining and enhancing existing tools, and driving the adoption and growth of dashboard-based data consumption throughout the organization.
• Work with large data sets, workbooks and spreadsheets to manipulate and manage program-level information using macros, queries, scripts, etc.
• Gather requirements and lead development of long-term data management tools, processes and solutions based on organizational needs.
• Be comfortable working with collaboration tools such as; Google Suite, Microsoft Office
• Providing general support to the client including, but not limited to, analysis, data calls, financial management, risk management, audits, and project management related tasks.

Requirements and qualifications:

Qualifications
• Bachelor's Degree in business, business intelligence, data or information management, or similar.
• Proficient in Google Scripts
• Minimum 2 years of data or information management and/or data analysis experience.
• Minimum 2 years of experience working with data visualization tools (Tableau/Power BI, ideally focused in developing custom dashboards).
• Experience using Microsoft Excel and Google Sheets (macros, imports, query functions).
• Experience with developing in Google App Script is a plus.
• Experience using SQL Developer is a plus.
• Excellent written and verbal communication skills.
• Consulting / client management experience recommended.
• Willing to work in an administratively manual environment while working towards automation of processes in the future.
• Clearable (able to pass both a criminal background check and credit check).",,2025-07-25,"['Patterned Learning AI is hiring a Mid-Level Data Analyst with 0 - 3 years of experience', ""Bachelor's Degree in business, business intelligence, data or information management, or similar"", 'Proficient in Google Scripts', 'Minimum 2 years of data or information management and/or data analysis experience', 'Minimum 2 years of experience working with data visualization tools (Tableau/Power BI, ideally focused in developing custom dashboards)', 'Experience using Microsoft Excel and Google Sheets (macros, imports, query functions)', 'Excellent written and verbal communication skills', 'Consulting / client management experience recommended', 'Willing to work in an administratively manual environment while working towards automation of processes in the future', 'Clearable (able to pass both a criminal background check and credit check)']","['Based in United States - Remote and with Remote ways of working', 'Work in close collaboration with the Business Intelligence Lead, Federal Data Lead and other Program teams', 'Develop, maintain, and improve BI tools, build and enhance standard operating procedures (SOPs)', 'Manage various data sets and active Google workbooks with adjacent contract teams, monitor and analyze financial health information at the project and program levels', 'Communicate with client leadership to assess data needs and emerging requirements', 'Lead Tableau projects for the BI team - will be responsible for developing new (custom) dashboards, maintaining and enhancing existing tools, and driving the adoption and growth of dashboard-based data consumption throughout the organization', 'Work with large data sets, workbooks and spreadsheets to manipulate and manage program-level information using macros, queries, scripts, etc', 'Gather requirements and lead development of long-term data management tools, processes and solutions based on organizational needs', 'Be comfortable working with collaboration tools such as; Google Suite, Microsoft Office', 'Providing general support to the client including, but not limited to, analysis, data calls, financial management, risk management, audits, and project management related tasks']",True,[],,"['Business Intelligence', 'Tableau', 'Power BI', 'Google Sheets', 'Microsoft Excel', 'Google Apps Script', 'SQL', 'Data Analysis', 'Data Management', 'Macros and Scripting', 'Dashboards']","Business Intelligence: The role involves developing and improving BI tools and dashboards to support organizational data consumption and decision-making.; Tableau: Used for leading projects to develop custom dashboards and maintain existing BI visualization tools.; Power BI: Experience with this data visualization tool is preferred for creating and enhancing dashboards.; Google Sheets: Used for managing and manipulating large data sets with macros, imports, and query functions.; Microsoft Excel: Utilized for data manipulation and analysis, including use of macros and advanced spreadsheet functions.; Google Apps Script: Proficiency required for automating tasks and managing data workflows within Google Suite.; SQL: Experience with SQL Developer is a plus for querying and managing data sets.; Data Analysis: Core responsibility includes analyzing financial health information and program-level data to support client needs.; Data Management: Involves managing various data sets and developing long-term data management tools and processes.; Macros and Scripting: Used to automate and manipulate data within spreadsheets and workbooks.; Dashboards: Creation and maintenance of custom dashboards to visualize data and support business intelligence."
NUZLYaLrF9ZTpUygAAAAAA==,"Analyst, Data Visualization & Business Intelligence","This position is on – site in our Royal Caribbean Miami 1050 Building

Journey with us! Combine your career goals and sense of adventure by joining our incredible team of employees at Royal Caribbean Group. We are proud to offer a competitive compensation and benefits package, and excellent career development opportunities, each offering unique ways to explore the world.

We are proud to be the vacation-industry leader with global brands — including Royal Caribbean International, Celebrity Cruises and Silversea Cruises — the most innovative fleet and private destinations, and the best people. Together, we are dedicated to turning the vacation of a lifetime into a lifetime of vacations for our guests.

Royal Caribbean team has an exciting career opportunity for a full-time Analyst, Data Visualization and Business Intelligence reporting to the Sr Manager, Business Intelligence.

Position Summary

Responsibilities include the design, implementation, and development of reporting and analytics solutions, with particular emphasis on Data Visualizations. Candidate must have strong understanding of data visualization and an ability to deliver engaging, informative data stories using a variety of techniques and tools. This individual is capable of working under minimal supervision. He/She will be responsible for interacting with various departments within Royal Caribbean to find, consolidate & manipulate data from multiple large data sets; to analyze and understand results; and to create reports, presentations and/or dashboards.

Essential Duties and Responsibilities
• Designs, implements and develops Data Visualizations using Power BI, Custom Visuals, and R Visualizations
• Meet with business stakeholders to clarify and document reporting requirements
• Meet with technical stakeholders to perform code reviews and elicit feedback
• Recommend data architecture and engineering structures necessary to support reports and dashboards
• Works autonomously and with little direction to complete assignments, coordinating business processes, programs and projects based on the outlined strategies and defined directives.
• Aggregates large data sets in SAS, Excel and other analytical tools for analysis. Develops data strategies
• Specifically, around data structures, identifying critical information, as well as the tools used to retrieve and analyze the data. Performs research and analysis on large data sets - data exploration, trending, modeling, etc.
• Works with management & other team members to understand & clarify data analysis and reporting needs. Provides guidance and insight on data visualization options for report design.
• Influences business decisions through analytics and identifies actionable, data-driven insights. Makes recommendations and influences the direction of the business by effectively communicating results to a cross functional group as well as department executives.
• Creates dashboards, automated reports, report templates and presentations. Uses advanced data visualization tools, such as PowerBI, to provide an easy-to-understand interface for end users to quickly identify key themes within data. Responsible for daily/weekly/monthly reporting on business trends and the status of digital experience initiatives for senior management

This position description in no way states or implies that these are the only duties to be performed by the employee occupying this position. Employee will be required to perform any other job-related duties assigned by their supervisor or management.

Qualifications, Knowledge & Skills
• Four-year Bachelor’s degree preferably in Mathematics/Statistics/Computer Science/ Economics /Analytics/Business/Engineering or BS/BA with combination thereof and related analytic work experience/ and or relevant certifications.
• 2 years of work experience in data analysis, data mining, business case development or other related analytical projects.
• Strong proficiency in query/reporting tools, SQL, Advanced Excel, Tableau (or similar visualization tool), R/SAS/Python or other statistical tools.
• 2 years of work experience required, with experience performing either strategic digital analysis, financial analysis or business intelligence/marketing analytics highly preferred
• Experience working with very large data sets (on relational as well as non-relational data stores)
• Understanding of Forecasting, Data cleansing and Transformations
• Understanding of SQL and DAX, R and R Scripting of visualizations in Power BI
• Experience working with databases, including Oracle, SQL Server, and AS400
• Ability to work on complex development BI projects including the proactive identification of issues and coordination of resolutions.
• Ability to work independently to implement solutions with minimal guidance and communicate effectively with both business and technical stakeholders.

Physical Requirement

The physical demands described here are representative of those requirements employees must meet to perform the essential functions of this job with or without reasonable accommodations. While performing job functions the employee is regularly required to sit, stand, write, review and type reports, compile data, operate a pc, communicate, listen, and assess information. The employee may move about the office complex, may travel to other office locations and may lift, push, pull or move 10 - 15 pounds. Visual requirements include distant, close and color vision, and ability to adjust focus.

Working Conditions

Miami based position with some travel. The work environment characteristics described here are representative of those an employee encounters while performing the essential functions of the job with or without reasonable accommodations. The environment includes office locations, and/or moving inside/outside the office.

We know there's a lot to consider.

As you go through the application process, our recruiters will be glad to provide guidance, and more relevant details to answer any additional questions. Thank you again for your interest in Royal Caribbean Group. We'll hope to see you onboard soon!

It is the policy of the Company to ensure equal employment and promotion opportunity to qualified candidates without discrimination or harassment on the basis of race, color, religion, sex, age, national origin, disability, sexual orientation, sexuality, gender identity or expression, marital status, or any other characteristic protected by law. Royal Caribbean Group and each of its subsidiaries prohibit and will not tolerate discrimination or harassment.

#LI-FM1",2025-06-27T00:00:00.000Z,2025-07-25,"['Candidate must have strong understanding of data visualization and an ability to deliver engaging, informative data stories using a variety of techniques and tools', 'Responsible for daily/weekly/monthly reporting on business trends and the status of digital experience initiatives for senior management', 'Four-year Bachelor’s degree preferably in Mathematics/Statistics/Computer Science/ Economics /Analytics/Business/Engineering or BS/BA with combination thereof and related analytic work experience/ and or relevant certifications', '2 years of work experience in data analysis, data mining, business case development or other related analytical projects', 'Strong proficiency in query/reporting tools, SQL, Advanced Excel, Tableau (or similar visualization tool), R/SAS/Python or other statistical tools', 'Experience working with very large data sets (on relational as well as non-relational data stores)', 'Understanding of Forecasting, Data cleansing and Transformations', 'Understanding of SQL and DAX, R and R Scripting of visualizations in Power BI', 'Experience working with databases, including Oracle, SQL Server, and AS400', 'Ability to work on complex development BI projects including the proactive identification of issues and coordination of resolutions', 'Ability to work independently to implement solutions with minimal guidance and communicate effectively with both business and technical stakeholders', 'The physical demands described here are representative of those requirements employees must meet to perform the essential functions of this job with or without reasonable accommodations', 'Visual requirements include distant, close and color vision, and ability to adjust focus', 'Miami based position with some travel']","['Responsibilities include the design, implementation, and development of reporting and analytics solutions, with particular emphasis on Data Visualizations', 'This individual is capable of working under minimal supervision', 'He/She will be responsible for interacting with various departments within Royal Caribbean to find, consolidate & manipulate data from multiple large data sets; to analyze and understand results; and to create reports, presentations and/or dashboards', 'Designs, implements and develops Data Visualizations using Power BI, Custom Visuals, and R Visualizations', 'Meet with business stakeholders to clarify and document reporting requirements', 'Meet with technical stakeholders to perform code reviews and elicit feedback', 'Recommend data architecture and engineering structures necessary to support reports and dashboards', 'Works autonomously and with little direction to complete assignments, coordinating business processes, programs and projects based on the outlined strategies and defined directives', 'Aggregates large data sets in SAS, Excel and other analytical tools for analysis', 'Develops data strategies', 'Specifically, around data structures, identifying critical information, as well as the tools used to retrieve and analyze the data', 'Performs research and analysis on large data sets - data exploration, trending, modeling, etc', 'Works with management & other team members to understand & clarify data analysis and reporting needs', 'Provides guidance and insight on data visualization options for report design', 'Influences business decisions through analytics and identifies actionable, data-driven insights', 'Makes recommendations and influences the direction of the business by effectively communicating results to a cross functional group as well as department executives', 'Creates dashboards, automated reports, report templates and presentations', 'Uses advanced data visualization tools, such as PowerBI, to provide an easy-to-understand interface for end users to quickly identify key themes within data', 'Employee will be required to perform any other job-related duties assigned by their supervisor or management', 'While performing job functions the employee is regularly required to sit, stand, write, review and type reports, compile data, operate a pc, communicate, listen, and assess information', 'The employee may move about the office complex, may travel to other office locations and may lift, push, pull or move 10 - 15 pounds']",True,[],,"['Data Visualization', 'Power BI', 'R Visualizations', 'SQL', 'DAX', 'SAS', 'Excel', 'Tableau', 'Python', 'Data Cleansing and Transformation', 'Forecasting', 'Data Exploration and Trending', 'Data Architecture and Engineering', 'Business Intelligence Reporting']","Data Visualization: Designing and developing visual representations of data to create engaging and informative data stories for business stakeholders.; Power BI: Using Power BI to create dashboards, automated reports, and custom visuals to support business intelligence reporting.; R Visualizations: Employing R scripting to develop visualizations within Power BI and for data analysis purposes.; SQL: Querying and manipulating data from relational databases such as Oracle, SQL Server, and AS400 to support reporting and analysis.; DAX: Using Data Analysis Expressions (DAX) for data modeling and calculations within Power BI reports.; SAS: Aggregating and analyzing large data sets using SAS for statistical analysis and reporting.; Excel: Utilizing advanced Excel features for data aggregation, cleansing, transformation, and analysis.; Tableau: Applying Tableau or similar visualization tools to create interactive dashboards and reports.; Python: Using Python for statistical analysis, data mining, and scripting to support data analytics projects.; Data Cleansing and Transformation: Performing data preparation tasks to ensure data quality and readiness for analysis and visualization.; Forecasting: Applying forecasting techniques to analyze business trends and support decision-making.; Data Exploration and Trending: Analyzing large data sets to identify patterns, trends, and insights relevant to business objectives.; Data Architecture and Engineering: Recommending and designing data structures and engineering solutions to support reporting and analytics.; Business Intelligence Reporting: Developing and delivering reports and dashboards that provide actionable insights to business and technical stakeholders."
zrG9xsRw8Feq-thIAAAAAA==,"Data Transformation Analyst (US, remote)","Data Transformation Analyst (US, remote)

Summary:

GTreasury, the leading innovator of integrated SaaS treasury and risk management solutions for the digital treasurer is currently looking to hire a motivated Account Manager to join our growing global sales organization to support our EMEA region. Developed using the latest technology, GTreasury helps empower organizations on their path to strategic treasury, by enabling total visibility into their cash, liquidity, payments and financial risk management. With enterprise clients spanning North America, EMEA and APAC, GTreasury is headquartered in Chicago with offices in London, Sydney and Manila.

GTreasury is currently seeking a dynamic Data Transformation Analyst to join our growing Data Services team. This role is ideal for someone who is passionate about data integration, automation, and scripting. You will play a key role in transforming and mapping financial data to support our clients' treasury operations.

Key Responsibilities:
• Design, develop, and maintain data transformation workflows using PowerShell and Liquid scripting.
• Build, test and deploy API's for banking and ERP applications
• Create and maintain documentation for API's built
• Collaborate with implementation consultants, banks and clients to understand data requirements and deliver tailored solutions.
• Analyze and troubleshoot data issues, ensuring accuracy and consistency across systems.
• Automate data ingestion and transformation processes to improve efficiency and scalability.
• Integrate and interact with APIs to support data exchange and automation.
• Document transformation logic and maintain best practices for scripting and data handling.

Qualifications:
• 2+ years of experience in data transformation, scripting, or ETL processes.
• Proficiency in PowerShell and experience with Liquid templating language (preferred).
• Experience working with APIs for data integration and automation.
• Experience with XSLT for XML data transformation is a plus.
• Strong analytical and problem-solving skills with attention to detail.
• Familiarity with financial systems or treasury management software is a plus.
• Excellent communication skills and the ability to work independently in a remote environment.

What You Will Get:
• A high impact, high visibility role at a growing SaaS company that values personal growth, accountability, and the concept of ""good work.""
• This is a great opportunity for someone who wants to make a big impact, work in a fast-paced and collaborative environment, and win as a team to scale a growing business.
• A culture of open collaboration and problem solving.
• An empowered role on our transforms team, responsible for implementing best practices and delivering critical results for our global customers.
• Great benefits, culture, and the ability to work remotely.
• Our benefits include:
• Salary: The expected annual median salary for this role is $85,000. Actual compensation for an individual may vary depending on skills, performance, qualifications, experience, and location.
Excellent medical, dental and vision insurance options
• HSA and FSA options + company HSA contributions
• 401K matching
• 100% paid parental leave
• 15 paid holidays + competitive PTO
• 100% remote working

About GTreasury:

GTreasury believes there is opportunity in complexity. We connect treasury and finance teams with industry-leading experts, technology solutions and untapped possibility. By simplifying complexity, teams can unleash their organization's potential to gain strategic advantages and grow. GTreasury helps organizations reach that potential by connecting treasury and digital finance operations through a world-class SaaS treasury and risk management platform and integrated ecosystem where cash, debt, investments, and exposures are seamlessly managed within the office of the CFO. GTreasury delivers intelligent insights, while connecting financial value chains and extending workflows to third-party systems, exchanges, portals, and services. Headquartered in Chicago, with locations serving EMEA (London) and APAC (Sydney and Manila), GTreasury's global community includes more than 800 customers and 30+ industries reaching 160+ countries worldwide.

At GTreasury / Hedge Trackers, we know that our people are what makes GTreasury great and we celebrate the unique perspectives and experiences that our diverse teams bring to the table. GTreasury does not discriminate against employees or prospective candidates based on race, color, religion, sex, national origin, gender identity or expression, age, disability, pregnancy (including childbirth, breastfeeding, or related medical condition), genetic information, protected military or veteran status, sexual orientation, or any other characteristic protected by applicable federal, state or local laws and we strongly encourage people from underrepresented groups to apply!

To learn more about GTreasury: https://gtreasury.com/",2025-07-19T00:00:00.000Z,2025-07-25,"['2+ years of experience in data transformation, scripting, or ETL processes', 'Experience working with APIs for data integration and automation', 'Strong analytical and problem-solving skills with attention to detail', 'Excellent communication skills and the ability to work independently in a remote environment', 'This is a great opportunity for someone who wants to make a big impact, work in a fast-paced and collaborative environment, and win as a team to scale a growing business']","['This role is ideal for someone who is passionate about data integration, automation, and scripting', ""You will play a key role in transforming and mapping financial data to support our clients' treasury operations"", 'Design, develop, and maintain data transformation workflows using PowerShell and Liquid scripting', ""Build, test and deploy API's for banking and ERP applications"", ""Create and maintain documentation for API's built"", 'Collaborate with implementation consultants, banks and clients to understand data requirements and deliver tailored solutions', 'Analyze and troubleshoot data issues, ensuring accuracy and consistency across systems', 'Automate data ingestion and transformation processes to improve efficiency and scalability', 'Integrate and interact with APIs to support data exchange and automation', 'Document transformation logic and maintain best practices for scripting and data handling']",False,[],,"['Data Transformation', 'ETL Processes', 'PowerShell Scripting', 'Liquid Templating Language', 'API Development and Integration', 'XSLT', 'Data Automation', 'Data Troubleshooting and Quality Assurance']","Data Transformation: Central to the role, involving designing and maintaining workflows to convert and map financial data for treasury operations.; ETL Processes: Experience required in extracting, transforming, and loading data to support integration and automation tasks.; PowerShell Scripting: Used to develop and automate data transformation workflows and scripting tasks.; Liquid Templating Language: Applied for scripting and templating in data transformation workflows.; API Development and Integration: Building, testing, deploying, and integrating APIs to enable data exchange between banking, ERP, and treasury systems.; XSLT: Used for XML data transformation to support data integration and mapping.; Data Automation: Automating data ingestion and transformation processes to improve efficiency and scalability.; Data Troubleshooting and Quality Assurance: Analyzing and resolving data issues to ensure accuracy and consistency across systems."
_RSyd7-vmOinX-TgAAAAAA==,Data Scientist,"Job Title: Data Scientist

Work Location: Remote (preference for candidates located in the National Capital Region - DMV)

Clearance Required: TS or CBP BI or DHS Suitability tier 4 (clearance adjudicated within the past 4 years)

People Centered. Data Driven

Elder Research Inc. is a Data Science consulting firm specialized in providing analytic solutions to clients in Commercial and Government industries. Providing analytic solutions to hundreds of companies across numerous industries, our team enjoys a great variety in the type of work they do and exposure to a wide range of techniques and tools

We are trusted advisors to our clients, building lasting relationships and partnering as preferred analytics providers. We use a variety of programming languages and tools to create analytic solutions, often fitting within our clients’ environment and needs.

Join our team and find great opportunities to hone your analytic skills, work on complex problems with amazing teammates, and gain valuable analytics consulting experience.?

Summary of Position:

We are looking for a talented and motivated data scientist experienced in working directly with clients, managers, and technical staff to understand business needs, develop technical plans, and deliver data-driven analytical solutions that solve client problems. This role will assist the client in integrating data analytics into their daily operations. You will create and deploy predictive models from a variety of data sources and types using the latest mathematical and statistical methods. You will also have the freedom to grow a team to support the client's data analytics needs.

Job Specifications/Requirements:
• Six (6) years of relevant experience in applied research, big data analytics, statistics, applied mathematics, data science, computer science, operations research or other closely related other quantitative or mathematical discipline. At least three (3) years of direct experience in machine learning.
• Advanced Degree (Masters or PhD) in Statistics, Applied Mathematics, Data Science, Computer
• Science, Operations Research or other closely related other quantitative or mathematical discipline. A PhD degree may be substituted for up to three (3) years of relevant experience.
• Demonstrates knowledge of data mining methods, databases, data visualization and machine learning.
• Ability to communicate analysis techniques, concepts and products.
• Ability to develop data-driven solutions, data models, and visualizations

Desired Skills
• Experience building AI/ML solutions from large JSON data stores
• Experience with graph technologies and tools
• Experience with analysis and visualization of worldwide data flows
• Experience in developing algorithms in support of fraud detection
• Familiarity with Databricks or similar cloud-based distributed database technologies
• Familiarity with PySpark and Python
• Comfortable developing complex SQL queries to extract, transform, and load data
• Experience with analytic techniques such as Anomaly detection, Clustering, and Time-series (e.g., ARIMA)
• Experience implementing NLP concepts including preprocessing (stemming, etc.), TF-IDF, Named Entity Recognition, and LLMs.

About Elder Research, Inc

Elder Research is a fast growing consulting firm specializing in predictive analytics. Being in the data mining business almost 30 years, we pride ourselves in our ability to find creative, cutting edge solutions to real-world problems. We work hard to provide the best value to our clients and allow each person to contribute their ideas and put their skills to use immediately.

Our team members are passionate, curious, life-long learners. We value humility, servant-leadership, teamwork, and integrity. We seek to serve our clients and our teammates to the best of our abilities. In keeping with our entrepreneurial spirit, we want candidates who are self-motivated with an innate curiosity and strong team work.

Elder Research believes in continuous learning - along with providing time for professional development, each week the entire company attends a “Tech Talk”. Elder Research provides a supportive work environment with established parental, bereavement, and PTO policies. By prioritizing a healthy work-life balance - with reasonable hours, solid pay, low travel, and extremely flexible time off - Elder Research enables and encourages its employees to serve others and enjoy their lives.

Elder Research, Inc. is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability.

Elder Research is a Government contractor and many positions require US Citizenship.

Equal Opportunity Employer, including disability/protected veterans

Equal employment opportunity, including veterans and individuals with disabilities.

PI276149450",2025-07-25T12:00:00.000Z,2025-07-25,"['Clearance Required: TS or CBP BI or DHS Suitability tier 4 (clearance adjudicated within the past 4 years)', 'Six (6) years of relevant experience in applied research, big data analytics, statistics, applied mathematics, data science, computer science, operations research or other closely related other quantitative or mathematical discipline', 'At least three (3) years of direct experience in machine learning', 'Advanced Degree (Masters or PhD) in Statistics, Applied Mathematics, Data Science, Computer', 'Science, Operations Research or other closely related other quantitative or mathematical discipline', 'A PhD degree may be substituted for up to three (3) years of relevant experience', 'Demonstrates knowledge of data mining methods, databases, data visualization and machine learning', 'Ability to communicate analysis techniques, concepts and products', 'Ability to develop data-driven solutions, data models, and visualizations', 'In keeping with our entrepreneurial spirit, we want candidates who are self-motivated with an innate curiosity and strong team work']","['We are looking for a talented and motivated data scientist experienced in working directly with clients, managers, and technical staff to understand business needs, develop technical plans, and deliver data-driven analytical solutions that solve client problems', 'This role will assist the client in integrating data analytics into their daily operations', 'You will create and deploy predictive models from a variety of data sources and types using the latest mathematical and statistical methods', ""You will also have the freedom to grow a team to support the client's data analytics needs""]",True,['Large Language Models'],"Large Language Models: Experience with LLMs for advanced NLP tasks, indicating use of modern AI techniques.","['Predictive Modeling', 'Machine Learning', 'Data Mining', 'Data Visualization', 'Big Data Analytics', 'SQL', 'Python', 'PySpark', 'Databricks', 'Graph Technologies', 'Anomaly Detection', 'Clustering', 'Time-Series Analysis', 'Natural Language Processing']","Predictive Modeling: Creating and deploying models to forecast outcomes based on various data sources, as required to solve client problems.; Machine Learning: Applying machine learning techniques with at least three years of direct experience to develop data-driven solutions.; Data Mining: Using data mining methods to extract useful patterns and insights from large datasets.; Data Visualization: Developing visual representations of data to communicate analysis results effectively.; Big Data Analytics: Handling and analyzing large-scale data sets to support analytic solutions.; SQL: Writing complex SQL queries to extract, transform, and load data for analysis.; Python: Using Python programming language, including libraries like PySpark, for data processing and analysis.; PySpark: Utilizing PySpark for distributed data processing in cloud-based environments.; Databricks: Working with Databricks or similar cloud-based distributed database technologies for scalable data analytics.; Graph Technologies: Applying graph-based tools and methods to analyze relationships within data.; Anomaly Detection: Implementing techniques to identify unusual patterns or outliers in data.; Clustering: Using clustering algorithms to group similar data points for analysis.; Time-Series Analysis: Applying time-series models such as ARIMA to analyze data indexed over time.; Natural Language Processing: Implementing NLP concepts like preprocessing, TF-IDF, and Named Entity Recognition to analyze text data."
RJMAzVpuaAdM1qcVAAAAAA==,Data Analyst / Financial Engineer – Treasury Dept. (Associate),"Key Responsibilities
• Collaborate with and support the Treasury desk, Financial Technology, model validation and project management team in model creation, methodology and testing documentation, validation and remediation, signoff, maintenance and production deployment
• Use quantitative and technological techniques to solve complex business problems
• Build analysis, data visualization tool, and create information report that reflects the business requirement
• Enhance and maintain the existing Treasury system for PL analysis and monitoring, scenario analysis, process automation
• Planning and developing new tools and systems being valuable for our business, not only Treasury but including corporate-wide in the future.
• Conduct research on cutting edge technologies in AI/BI/ML/NLP, alternative data, FinTech, high performance computing (e.g. GPU, quantum computing) to discover the potential opportunities to the business applications
• Conduct quantitative research and predictive modeling for market related businesses by sourcing, integrating and analyzing traditional and alternative dataset to discover new insights and strategies
• Collaborate with and support the Treasury desk, Financial Technology, model validation and Risk management in model creation, methodology and testing documentation, validation and remediation, signoff, maintenance and production deployment
• Use quantitative and technological techniques to solve complex business problems.

Required Qualifications
• Master’s degree or higher in a quantitative field such as mathematics, statistics, engineering, physics strongly desired
• Strong, clear and concise written and oral communication skills
• 2-5+ years of hands-on Python, SQL, Typescript/Javascript and Linux development experience.
• 2-5+ years of experience in wide range of statistical and machine-learning techniques (e.g. time series analysis, NLP, deep learning and etc.)
• Experience developing or working with REST APIs
• Experience working with BI tools (e.g. PowerBI, Tableau)
• Knowledge of financial mathematics (e.g. stochastic calculus, interest rate models), capital market and derivative products (e.g. interest rate swaps, cross currency swaps, options and etc.)

The expected base salary ranges from $79,000 - $151,500. Salary offers are based on a wide range of factors including relevant skills, training, experience, education, and, where applicable, certifications and licenses obtained. Market and organizational factors are also considered. In addition to salary and a generous employee benefits package, successful candidates are eligible to receive a discretionary bonus.

#Hybrid

Other requirements

Mizuho has in place a hybrid working program, with varying opportunities for remote work depending on the nature of the role, needs of your department, as well as local laws and regulatory obligations. Roles in some of our departments have greater in-office requirements that will be communicated to you as part of the recruitment process.

Company Overview

Mizuho Financial Group, Inc. is the 15th largest bank in the world as measured by total assets of ~$2 trillion. Mizuho's 60,000 employees worldwide offer comprehensive financial services to clients in 35 countries and 800 offices throughout the Americas, EMEA and Asia. Mizuho Americas is a leading provider of corporate and investment banking services to clients in the US, Canada, and Latin America. Through its acquisition of Greenhill​, Mizuho provides M&A, restructuring and private capital advisory capabilities across Americas, Europe and Asia. Mizuho Americas employs approximately 3,500 professionals, and its capabilities span corporate and investment banking, capital markets, equity and fixed income sales & trading, derivatives, FX, custody and research. Visit www.mizuhoamericas.com.​​

Mizuho Americas offers a competitive total rewards package.

We are an EEO/AA Employer - M/F/Disability/Veteran.

We participate in the E-Verify program.

We maintain a drug-free workplace and reserve the right to require pre- and post-hire drug testing as permitted by applicable law.

#LI-MIZUHO",,2025-07-25,"['Strong, clear and concise written and oral communication skills', '2-5+ years of hands-on Python, SQL, Typescript/Javascript and Linux development experience', '2-5+ years of experience in wide range of statistical and machine-learning techniques (e.g. time series analysis, NLP, deep learning and etc.)', 'Experience developing or working with REST APIs', 'Experience working with BI tools (e.g. PowerBI, Tableau)', 'Knowledge of financial mathematics (e.g. stochastic calculus, interest rate models), capital market and derivative products (e.g. interest rate swaps, cross currency swaps, options and etc.)']","['Collaborate with and support the Treasury desk, Financial Technology, model validation and project management team in model creation, methodology and testing documentation, validation and remediation, signoff, maintenance and production deployment', 'Use quantitative and technological techniques to solve complex business problems', 'Build analysis, data visualization tool, and create information report that reflects the business requirement', 'Enhance and maintain the existing Treasury system for PL analysis and monitoring, scenario analysis, process automation', 'Planning and developing new tools and systems being valuable for our business, not only Treasury but including corporate-wide in the future', 'Conduct research on cutting edge technologies in AI/BI/ML/NLP, alternative data, FinTech, high performance computing (e.g. GPU, quantum computing) to discover the potential opportunities to the business applications', 'Conduct quantitative research and predictive modeling for market related businesses by sourcing, integrating and analyzing traditional and alternative dataset to discover new insights and strategies', 'Collaborate with and support the Treasury desk, Financial Technology, model validation and Risk management in model creation, methodology and testing documentation, validation and remediation, signoff, maintenance and production deployment', 'Use quantitative and technological techniques to solve complex business problems']",True,"['Natural Language Processing', 'Deep Learning']",Natural Language Processing: Mentioned explicitly as a cutting-edge AI technology researched for potential business applications.; Deep Learning: Included as an AI technique explored for advanced modeling and research opportunities.,"['Python', 'SQL', 'Typescript/Javascript', 'Linux', 'Statistical and Machine Learning Techniques', 'Time-Series Analysis', 'Natural Language Processing', 'Deep Learning', 'REST APIs', 'Business Intelligence Tools', 'Financial Mathematics', 'Predictive Modeling', 'Scenario Analysis', 'Process Automation', 'Alternative Data']","Python: Used for hands-on development and implementing statistical and machine learning techniques.; SQL: Used for querying and managing traditional and alternative datasets for analysis.; Typescript/Javascript: Used in development tasks, likely for building data visualization tools and interfaces.; Linux: Operating system environment for development and deployment of data and analytical tools.; Statistical and Machine Learning Techniques: Applied for quantitative research, predictive modeling, and solving complex business problems.; Time-Series Analysis: Used for analyzing market-related data and forecasting in financial contexts.; Natural Language Processing: Applied as part of statistical and machine learning techniques for analyzing textual data.; Deep Learning: Used as part of advanced machine learning methods for predictive modeling and research.; REST APIs: Used for integrating and accessing data and services in development and deployment.; Business Intelligence Tools: Tools like PowerBI and Tableau used for data visualization and reporting to reflect business requirements.; Financial Mathematics: Knowledge applied in modeling financial instruments and market-related quantitative research.; Predictive Modeling: Used to discover new insights and strategies by analyzing traditional and alternative datasets.; Scenario Analysis: Used for PL analysis and monitoring within Treasury systems to assess potential outcomes.; Process Automation: Implemented to enhance and maintain Treasury systems and improve operational efficiency.; Alternative Data: Sourced and integrated alongside traditional data to enrich quantitative research and modeling."
0vCgYbJlilJjeSuIAAAAAA==,Data Analytics Consultant (Insights Analyst),"We're Hiring: Data Analytics Consultant (Insights Analyst) | San Jose, CA - Who can work 2 3 days from the office weekly

Are you passionate about turning complex data into meaningful insights that drive real business impact? Join us as an Insights Analyst / Manager supporting the customer Cloud domain an exciting and fast-paced space that s constantly evolving.

We re looking for a data-driven storyteller with strong business acumen and technical expertise who can deep-dive into data, stitch together multiple sources, and build scalable reporting solutions.
Location: San Jose, California (Onsite/Hybrid options may vary)

What You ll Do
• Lead strategic analytics projects and deliver actionable insights to key stakeholders
• Build robust data pipelines and reporting solutions (primarily using Adobe Analytics clickstream data)
• Co-design and analyze A/B tests to measure impact and optimize strategies
• Conduct ad-hoc analyses and explore customer behavior patterns
• Collaborate with cross-functional teams to ensure data quality and validation
• Translate business requirements into scalable datasets and visualizations
• Navigate complex data landscapes and solve problems creatively

What You ll Bring
• 5+ years of relevant professional experience
• Bachelor s in CS, Engineering, Info Systems (Master s preferred)
• Strong skills in SQL, Apache Hadoop, Hive, Presto, or similar technologies
• Proficiency in Python, Excel, and data visualization tools (Tableau, Power BI)
• Web analytics and A/B testing experience highly desired
• Experience with Adobe Analytics Workspace is a big plus
• Detail-oriented with strong problem-solving and stakeholder management abilities
• Understanding of statistical modeling, machine learning, or data mining is a bonus",2025-07-21T00:00:00.000Z,2025-07-25,"['5+ years of relevant professional experience', 'Strong skills in SQL, Apache Hadoop, Hive, Presto, or similar technologies', 'Proficiency in Python, Excel, and data visualization tools (Tableau, Power BI)', 'Experience with Adobe Analytics Workspace is a big plus', 'Detail-oriented with strong problem-solving and stakeholder management abilities', 'Understanding of statistical modeling, machine learning, or data mining is a bonus']","['Lead strategic analytics projects and deliver actionable insights to key stakeholders', 'Build robust data pipelines and reporting solutions (primarily using Adobe Analytics clickstream data)', 'Co-design and analyze A/B tests to measure impact and optimize strategies', 'Conduct ad-hoc analyses and explore customer behavior patterns', 'Collaborate with cross-functional teams to ensure data quality and validation', 'Translate business requirements into scalable datasets and visualizations', 'Navigate complex data landscapes and solve problems creatively']",True,[],,"['SQL', 'Apache Hadoop', 'Hive', 'Presto', 'Python', 'Excel', 'Tableau', 'Power BI', 'Adobe Analytics', 'A/B Testing', 'Data Pipelines', 'Statistical Modeling', 'Machine Learning', 'Data Mining']","SQL: Used for querying and managing data within relational databases to support analytics and reporting.; Apache Hadoop: Employed as a big data framework to process and store large-scale datasets relevant to customer analytics.; Hive: Utilized as a data warehouse infrastructure built on Hadoop for querying and managing large datasets.; Presto: Used as a distributed SQL query engine to perform fast analytics on large data sources.; Python: Applied for data manipulation, analysis, and building scalable reporting solutions.; Excel: Used for data analysis, visualization, and ad-hoc reporting tasks.; Tableau: A data visualization tool employed to create dashboards and visual insights for stakeholders.; Power BI: Used to develop interactive reports and dashboards to communicate data insights.; Adobe Analytics: Leveraged for analyzing clickstream data to understand customer behavior and web analytics.; A/B Testing: Designed and analyzed experiments to measure the impact of strategies and optimize business decisions.; Data Pipelines: Built to automate the extraction, transformation, and loading of data for scalable reporting.; Statistical Modeling: Applied to analyze data patterns and support decision-making, mentioned as a desirable skill.; Machine Learning: Understanding of machine learning techniques is considered a bonus for advanced data analysis.; Data Mining: Used to discover patterns and insights from large datasets, noted as a beneficial skill."
jEzrv_10Ou-QJBYaAAAAAA==,Senior Systems Analyst (Data Analyst),"Senior Systems Analyst (Data Analyst)

Lead II - Software Engineering

Who We Are:

Born digital, UST transforms lives through the power of technology. We walk alongside our clients and partners, embedding innovation and agility into everything they do. We help them create transformative experiences and human-centered solutions for a better world.

UST is a mission-driven group of 29,000+ practical problem solvers and creative thinkers in more than 30 countries. Our entrepreneurial teams are empowered to innovate, act nimbly, and create a lasting and sustainable impact for our clients, their customers, and the communities in which we live.

With us, you’ll create a boundless impact that transforms your career—and the lives of people across the world.

Visit us at UST.com.

You Are:

We are seeking a highly skilled and experienced Senior Systems Analyst (Data Analyst) to support data analysis and architecture initiatives within a healthcare payer clinical data ecosystem. This role requires a detail-oriented, proactive professional with a strong background in data management, data warehousing, and healthcare analytics.

The opportunity:

· Data Analysis & Design: Contribute to the design, modeling, implementation, and maintenance of data solutions within the clinical data ecosystem.

· ETL Process Understanding: Interpret ETL terminologies and processes including jobs, Psets, graphs, schedules, and job series (100, 300, 500).

· Data Modeling: Follow data model standards and understand entity-relationship (ER) modeling using tools like Erwin.

· PHI/PII Data Handling: Ensure compliance with data privacy standards by preventing exposure to PHI/PII and applying data masking techniques.

· SA Deliverables: Create and maintain key deliverables such as Source-to-Target (S2T) mappings, Data Element Dictionaries (DED), Functional Requirement Specifications (FRS), data models, design documents, and impact analyses.

· Performance Optimization: Optimize performance through index creation, efficient SQL writing, and process design.

This position description identifies the responsibilities and tasks typically associated with the performance of the position. Other relevant essential functions may be required.

What you need:

· Proficiency in dimensional modeling, SQL, and data warehousing concepts.

· Experience with DB2, ETL tools (Ab Initio), and reporting tools (Cognos, Tableau).

· Familiarity with data modeling tools like Erwin.

· Strong understanding of ETL processes, data governance, and metadata management.

· Knowledge of healthcare payer systems, including claims and clinical decision support.

· Soft Skills

· Strong analytical and problem-solving abilities.

· Excellent verbal and written communication skills.

· Ability to work independently and collaboratively in a team environment.

· Education & Experience

· Bachelor’s or Master’s degree in Computer Science, Information Systems, or a related field.

· 7–10 years of experience in systems analysis, with a focus on data warehousing in the healthcare payer sector.

Compensation can differ depending on factors including but not limited to the specific office location, role, skill set, education, and level of experience. UST provides a reasonable range of compensation for roles that may be hired in various U.S. markets as set forth below.

Role Location: Remote

Compensation Range: $82,000-$123,000

Benefits

Full-time, regular employees accrue a minimum of 10 days of paid vacation per year, receive 6 days of paid sick leave each year (pro-rated for new hires throughout the year), 10 paid holidays, and are eligible for paid bereavement leave and jury duty. They are eligible to participate in the Company’s 401(k) Retirement Plan with employer matching. They and their dependents residing in the US are eligible for medical, dental, and vision insurance, as well as the following Company-paid Employee Only benefits: basic life insurance, accidental death and disability insurance, and short- and long-term disability benefits. Regular employees may purchase additional voluntary short-term disability benefits, and participate in a Health Savings Account (HSA) as well as a Flexible Spending Account (FSA) for healthcare, dependent child care, and/or commuting expenses as allowable under IRS guidelines. Benefits offerings vary in Puerto Rico.

Part-time employees receive 6 days of paid sick leave each year (pro-rated for new hires throughout the year) and are eligible to participate in the Company’s 401(k) Retirement Plan with employer matching.

Full-time temporary employees receive 6 days of paid sick leave each year (pro-rated for new hires throughout the year) and are eligible to participate in the Company’s 401(k) program with employer matching. They and their dependents residing in the US are eligible for medical, dental, and vision insurance.

Part-time temporary employees receive 6 days of paid sick leave each year (pro-rated for new hires throughout the year).

All US employees who work in a state or locality with more generous paid sick leave benefits than specified here will receive the benefit of those sick leave laws.

What we believe:

We proudly embrace the values that have shaped UST since day one. We build our culture of Humility, Humanity, and Integrity. These values inspire us to nurture a people-first, human centric culture that fosters belonging, prioritizes sustainable solutions, and keeps our people and clients at the forefront of all decisions.

Humility:

We will listen, learn, be empathetic and help selflessly in our interactions with everyone.

Humanity:

Through business, we will better the lives of those less fortunate than ourselves.

Integrity:

We honor our commitments and act with responsibility in all our relationships.

Equal Employment Opportunity Statement

UST is an Equal Opportunity Employer.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other applicable characteristics protected by law. We will consider qualified applicants with arrest or conviction records in accordance with state and local laws and “fair chance” ordinances.

UST reserves the right to periodically redefine your roles and responsibilities based on the requirements of the organization and/or your performance.

#UST

#CB

#LI-IS1

#LI-Remote",2025-07-21T00:00:00.000Z,2025-07-25,"['We are seeking a highly skilled and experienced Senior Systems Analyst (Data Analyst) to support data analysis and architecture initiatives within a healthcare payer clinical data ecosystem', 'This role requires a detail-oriented, proactive professional with a strong background in data management, data warehousing, and healthcare analytics', 'Proficiency in dimensional modeling, SQL, and data warehousing concepts', 'Experience with DB2, ETL tools (Ab Initio), and reporting tools (Cognos, Tableau)', 'Familiarity with data modeling tools like Erwin', 'Strong understanding of ETL processes, data governance, and metadata management', 'Knowledge of healthcare payer systems, including claims and clinical decision support', 'Soft Skills', 'Strong analytical and problem-solving abilities', 'Excellent verbal and written communication skills', 'Ability to work independently and collaboratively in a team environment', 'Education & Experience', 'Bachelor’s or Master’s degree in Computer Science, Information Systems, or a related field', '7–10 years of experience in systems analysis, with a focus on data warehousing in the healthcare payer sector', 'UST reserves the right to periodically redefine your roles and responsibilities based on the requirements of the organization and/or your performance']","['Data Analysis & Design: Contribute to the design, modeling, implementation, and maintenance of data solutions within the clinical data ecosystem', 'ETL Process Understanding: Interpret ETL terminologies and processes including jobs, Psets, graphs, schedules, and job series (100, 300, 500)', 'Data Modeling: Follow data model standards and understand entity-relationship (ER) modeling using tools like Erwin', 'PHI/PII Data Handling: Ensure compliance with data privacy standards by preventing exposure to PHI/PII and applying data masking techniques', 'SA Deliverables: Create and maintain key deliverables such as Source-to-Target (S2T) mappings, Data Element Dictionaries (DED), Functional Requirement Specifications (FRS), data models, design documents, and impact analyses', 'Performance Optimization: Optimize performance through index creation, efficient SQL writing, and process design', 'This position description identifies the responsibilities and tasks typically associated with the performance of the position', 'Other relevant essential functions may be required']",True,[],,"['Data Analysis', 'Data Modeling', 'ETL Processes', 'Dimensional Modeling', 'SQL', 'Data Warehousing', 'DB2', 'ETL Tool - Ab Initio', 'Reporting Tools', 'Data Governance', 'PHI/PII Data Handling', 'Source-to-Target Mapping', 'Data Element Dictionary', 'Functional Requirement Specifications', 'Performance Optimization', 'Healthcare Analytics']","Data Analysis: Involved in analyzing clinical data within the healthcare payer ecosystem to support data-driven decision making.; Data Modeling: Designing and implementing data models using entity-relationship (ER) modeling standards and tools like Erwin to structure clinical data.; ETL Processes: Understanding and interpreting ETL workflows, including jobs, Psets, graphs, and schedules, to manage data extraction, transformation, and loading.; Dimensional Modeling: Applying dimensional modeling techniques to organize data warehouses for efficient querying and reporting in healthcare data.; SQL: Writing efficient SQL queries and creating indexes to optimize data retrieval and performance in clinical data systems.; Data Warehousing: Managing and maintaining data warehouse environments, particularly in healthcare payer systems, to support analytics and reporting.; DB2: Using the DB2 database system as part of the data storage and management infrastructure.; ETL Tool - Ab Initio: Utilizing Ab Initio ETL tool to design and manage data integration workflows within the clinical data ecosystem.; Reporting Tools: Employing BI and reporting tools such as Cognos and Tableau to create dashboards and reports for healthcare analytics.; Data Governance: Ensuring compliance with data privacy standards and managing metadata to maintain data quality and security.; PHI/PII Data Handling: Applying data masking and privacy techniques to protect sensitive healthcare information in compliance with regulations.; Source-to-Target Mapping: Documenting data lineage and transformations through Source-to-Target mappings to support ETL and data integration processes.; Data Element Dictionary: Maintaining a dictionary of data elements to standardize definitions and usage across the clinical data ecosystem.; Functional Requirement Specifications: Creating detailed documentation of system requirements to guide data solution design and implementation.; Performance Optimization: Improving system efficiency through index creation, optimized SQL, and process design in data workflows.; Healthcare Analytics: Applying analytics techniques to healthcare payer data, including claims and clinical decision support systems."
W-poE1bKK2KGnW48AAAAAA==,"Senior Analytics Strategist, Industry Insights","Responsibilities: Engages with internal partners to understand business strategy, questions and goals. Brings structure to business requests, translates requirements into an analytical project approach, and leads complex projects through completion. Delegates tasks and provides tactical and strategic guidance to peers. Serves as the analytics expert on cross-functional teams for large strategic initiatives. Acquires and compiles structured and unstructured data and verifies its quality, accuracy and reasonableness. Performs analyses of historical data to surface trends and insights using advanced analytical methods. Validates analytical techniques employed by other analysts. Prepares and delivers expert level visualizations and internal presentations that translate analytic insights into tangible, actionable solutions for business partners to implement. Develops, owns and manages recurring analytic or reporting processes. Actively develops the analytics community at Vanguard by mentoring, coaching and connecting others with resources and training. Participates and presents during scheduled analytics seminars. Participates in special projects and performs other duties as assigned. What it takes: This role is central to FAS’s vision of being the “advisor to the advisor,” using data to anticipate client needs and deliver the right products and services at the right time. The analyst will play a key role in shaping how FAS understands and responds to industry dynamics. Minimum of 8–10 years of related work experience in analytics, strategy, or financial services. Proven experience in delivering insights from structured and unstructured data using advanced statistical and machine learning methods (e.g., regression, segmentation, time series analysis, Bayesian methods). Familiarity with financial products such as ETFs and mutual funds, and experience working with broker-dealers, RIAs, and bank trust departments. Ability to translate business questions into analytical projects and deliver insights that influence decision-making Experience in scenario planning, forecasting, and ROI analysis for marketing or distribution strategies Consultative approach with business functional and technical skills with Validated experience in building and delivering data & analytics products and insights. Experience working with Morningstar and Bloomberg data is highly valued, especially for competitive and market trend analysis. Proficiency in data analysis tools such as SQL, Python, R, and Tableau . Experience with data visualization, dashboard creation, and storytelling with data. Strong understanding of data modeling, predictive analytics, and scenario analysis. Special Factors Sponsorship Vanguard is offering visa sponsorship for this position. About Vanguard At Vanguard, we don't just have a mission—we're on a mission. To work for the long-term financial wellbeing of our clients. To lead through product and services that transform our clients' lives. To learn and develop our skills as individuals and as a team. From Malvern to Melbourne, our mission drives us forward and inspires us to be our best. How We Work Vanguard has implemented a hybrid working model for the majority of our crew members, designed to capture the benefits of enhanced flexibility while enabling in-person learning, collaboration, and connection. We believe our mission-driven and highly collaborative culture is a critical enabler to support long-term client outcomes and enrich the employee experience. Vanguard, one of the world's largest investment management companies, serves individual investors, institutions, employer-sponsored retirement plans, and financial professionals. We have a diverse and talented crew with a culture that promotes teamwork, along with an unwavering focus on serving our clients' best interests. This website uses ""cookies"" to distinguish you from other users. A cookie is a small file of letters and numbers placed on your computer or device. This helps us to provide you with a good experience when you browse our website and also allows us to improve our site and services. The cookies are stored locally on your computer or mobile device. To accept cookies you can continue browsing as normal. Or you can go to our Privacy Policy to read more information and learn how to change your preferences.",2025-07-14T00:00:00.000Z,2025-07-25,"['Minimum of 8–10 years of related work experience in analytics, strategy, or financial services', 'Proven experience in delivering insights from structured and unstructured data using advanced statistical and machine learning methods (e.g., regression, segmentation, time series analysis, Bayesian methods)', 'Familiarity with financial products such as ETFs and mutual funds, and experience working with broker-dealers, RIAs, and bank trust departments', 'Ability to translate business questions into analytical projects and deliver insights that influence decision-making Experience in scenario planning, forecasting, and ROI analysis for marketing or distribution strategies Consultative approach with business functional and technical skills with Validated experience in building and delivering data & analytics products and insights', 'Experience working with Morningstar and Bloomberg data is highly valued, especially for competitive and market trend analysis', 'Proficiency in data analysis tools such as SQL, Python, R, and Tableau ', 'Experience with data visualization, dashboard creation, and storytelling with data', 'Strong understanding of data modeling, predictive analytics, and scenario analysis']","['Responsibilities: Engages with internal partners to understand business strategy, questions and goals', 'Brings structure to business requests, translates requirements into an analytical project approach, and leads complex projects through completion', 'Delegates tasks and provides tactical and strategic guidance to peers', 'Serves as the analytics expert on cross-functional teams for large strategic initiatives', 'Acquires and compiles structured and unstructured data and verifies its quality, accuracy and reasonableness', 'Performs analyses of historical data to surface trends and insights using advanced analytical methods', 'Validates analytical techniques employed by other analysts', 'Prepares and delivers expert level visualizations and internal presentations that translate analytic insights into tangible, actionable solutions for business partners to implement', 'Develops, owns and manages recurring analytic or reporting processes', 'Actively develops the analytics community at Vanguard by mentoring, coaching and connecting others with resources and training', 'Participates and presents during scheduled analytics seminars', 'Participates in special projects and performs other duties as assigned', 'What it takes: This role is central to FAS’s vision of being the “advisor to the advisor,” using data to anticipate client needs and deliver the right products and services at the right time', 'The analyst will play a key role in shaping how FAS understands and responds to industry dynamics', ""To lead through product and services that transform our clients' lives""]",True,[],,"['Regression', 'Segmentation', 'Time-Series Analysis', 'Bayesian Methods', 'SQL', 'Python', 'R', 'Tableau', 'Data Visualization', 'Predictive Analytics', 'Scenario Analysis', 'Data Modeling', 'Machine Learning', 'Morningstar Data', 'Bloomberg Data']","Regression: Used as an advanced statistical method to analyze historical data and deliver insights for business decision-making.; Segmentation: Applied to categorize data into meaningful groups to support strategic initiatives and market analysis.; Time-Series Analysis: Employed for forecasting and scenario planning based on historical financial and market data.; Bayesian Methods: Utilized as part of advanced analytical techniques to validate models and improve predictive accuracy.; SQL: Used for querying and managing structured data from databases to support analytics projects.; Python: A programming language leveraged for data analysis, statistical modeling, and building analytics products.; R: Used for statistical computing and advanced data analysis within the analytics team.; Tableau: A BI tool employed to create visualizations, dashboards, and storytelling with data for internal presentations.; Data Visualization: Critical for translating analytic insights into actionable solutions through expert-level visual presentations.; Predictive Analytics: Applied to anticipate client needs and support decision-making through forecasting and ROI analysis.; Scenario Analysis: Used to evaluate potential outcomes and support strategic planning in marketing and distribution.; Data Modeling: Involves structuring data to enable effective analysis and insight generation for business strategies.; Machine Learning: Implemented as part of advanced methods to extract insights from structured and unstructured data.; Morningstar Data: Utilized as a data source for competitive and market trend analysis in financial services.; Bloomberg Data: Used for accessing financial market data to inform analytics and strategic insights."
3vfOErC4TqhPs8CnAAAAAA==,Data Quality Analyst,"Welcome to the American Red Cross, where our mission is to alleviate human suffering in the face of emergencies. We are seeking a highly motivated and detail-oriented Data Quality Analyst to join our team. As a Data Quality Analyst, you will play a critical role in ensuring the accuracy and integrity of our data, ultimately helping us make informed decisions and better serve those in need. If you are passionate about using your analytical skills to make a meaningful impact, have a strong attention to detail, and thrive in a fast-paced environment, we encourage you to apply. Join us in our mission to provide aid and relief to those affected by disasters and emergencies across the country.

Conduct regular audits of data to identify any errors, inconsistencies, or anomalies.
Collaborate with cross-functional teams to establish data quality standards and protocols.
Develop and implement data cleansing and data validation procedures.
Monitor data entry processes and ensure adherence to data quality standards.
Identify and resolve data quality issues in a timely manner.
Develop and maintain data quality reports and metrics to track and communicate data accuracy.
Stay up-to-date with industry best practices and recommend improvements to data quality processes.
Train and support staff on data entry protocols and procedures.
Investigate and troubleshoot data discrepancies and provide solutions.
Communicate and escalate data quality issues to appropriate stakeholders.
Ensure compliance with data privacy and security regulations.
Participate in data governance initiatives and contribute to the development of data quality policies and procedures.
Use data analysis techniques to identify trends and patterns and provide insights to improve data quality.
Continuously monitor and evaluate data quality processes and make recommendations for improvements.
Collaborate with IT teams to implement data quality tools and technologies.
Support data migration initiatives and ensure data integrity during the process.
Provide support and guidance to colleagues regarding data quality issues and procedures.
Participate in team meetings and contribute to the overall goals and objectives of the organization.

American Red Cross is an Equal Opportunity Employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. We do not discriminate based upon race, religion, color, national origin, sex, sexual orientation, gender identity, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.",,2025-07-25,,"['As a Data Quality Analyst, you will play a critical role in ensuring the accuracy and integrity of our data, ultimately helping us make informed decisions and better serve those in need', 'If you are passionate about using your analytical skills to make a meaningful impact, have a strong attention to detail, and thrive in a fast-paced environment, we encourage you to apply', 'Join us in our mission to provide aid and relief to those affected by disasters and emergencies across the country', 'Conduct regular audits of data to identify any errors, inconsistencies, or anomalies', 'Collaborate with cross-functional teams to establish data quality standards and protocols', 'Develop and implement data cleansing and data validation procedures', 'Monitor data entry processes and ensure adherence to data quality standards', 'Identify and resolve data quality issues in a timely manner', 'Develop and maintain data quality reports and metrics to track and communicate data accuracy', 'Stay up-to-date with industry best practices and recommend improvements to data quality processes', 'Train and support staff on data entry protocols and procedures', 'Investigate and troubleshoot data discrepancies and provide solutions', 'Communicate and escalate data quality issues to appropriate stakeholders', 'Ensure compliance with data privacy and security regulations', 'Participate in data governance initiatives and contribute to the development of data quality policies and procedures', 'Use data analysis techniques to identify trends and patterns and provide insights to improve data quality', 'Continuously monitor and evaluate data quality processes and make recommendations for improvements', 'Collaborate with IT teams to implement data quality tools and technologies', 'Support data migration initiatives and ensure data integrity during the process', 'Provide support and guidance to colleagues regarding data quality issues and procedures', 'Participate in team meetings and contribute to the overall goals and objectives of the organization']",True,[],,"['Data Quality Auditing', 'Data Cleansing', 'Data Validation', 'Data Quality Metrics and Reporting', 'Data Governance', 'Data Analysis', 'Data Migration Support', 'Data Quality Tools and Technologies']","Data Quality Auditing: Conducting regular audits to identify errors, inconsistencies, or anomalies in data to ensure accuracy and integrity.; Data Cleansing: Developing and implementing procedures to clean data, removing inaccuracies and inconsistencies to improve data quality.; Data Validation: Establishing and applying validation procedures to ensure data meets quality standards before use.; Data Quality Metrics and Reporting: Creating and maintaining reports and metrics to track and communicate the accuracy and quality of data.; Data Governance: Participating in initiatives and policy development to manage data quality standards and compliance.; Data Analysis: Using analytical techniques to identify trends and patterns that inform improvements in data quality.; Data Migration Support: Ensuring data integrity during migration processes by supporting and validating data transfers.; Data Quality Tools and Technologies: Collaborating with IT teams to implement technologies that support data quality monitoring and improvement."
TD41iLrpCk_xL4BOAAAAAA==,Psychometric Data Analyst II,"When you join Renaissance®, you join a global leader in pre-K-12 education technology! Renaissance's solutions help educators analyze, customize, and plan personalized learning paths for students, allowing time for what matters-creating energizing learning experiences in the classroom.

Our fiercely passionate employees and educational partners have helped drive phenomenal student growth, with Renaissance solutions being used in over one-third of US schools and in more than 100 countries worldwide.

Every day, we are connected to our mission by exemplifying our values: trust each other, win together, strive for the best, own our actions, and grow and evolve.

This role is related to Renaissance's educational technology products, with a primary focus on the assessment products that include the Star Computerized Adaptive tests (CAT) and the Star curriculum-based measures (CBM).
• *In this role as a Psychometric Data Analyst II, you will: **

+ Extract assessment data from Snowflake and/or MongoDB as needed for various analyses

+ Analyze psychometric data related to item and test content, quality, and performance from a variety of sources, both structured and unstructured

+ Define and track assessment quality and performance related metrics

+ Design and implement research, testing, and data mining projects, including scenarios and simulations

+ Communicate results of analyses through written reports, visual displays, and verbal communication

+ Support the psychometricians with statistical analyses related to advanced psychometric work.

+ Maintain an accurate and up-to-date knowledge on statistical analysis techniques and applications
• *For this role as a Psychometric Data Analyst II, you must have:**

+ Bachelor's degree in statistics, mathematics, data science, or a related field from four-year accredited college or university, and

+ Minimum 6 years' experience implementing analysis and testing plans and defining and tracking metrics, OR

+ Equivalent combination of education and experience

+ Extensive database management experience in both structured (SQL) and unstructured (NoSQL) databases especially MongoDB.

+ Ability to manipulate and analyze data in SAS, r, and Python.

+ Exceptional attention to detail.

+ Demonstrated ability to work well within a team and cross functionally.
• *Bonus points for:**

+ Master's degree in Statistics or a related field

All your information will be kept confidential according to EEO guidelines.

Salary Range: $61,800 to $85,000 This range is based on national market data and may vary by experience and location.
• *Benefits for eligible employees include:**

+ World Class Health Benefits: Medical, Prescription, Dental, Vision, Telehealth

+ Health Savings and Flexible Spending Accounts

+ 401(k) and Roth 401(k) with company match

+ Paid Vacation and Sick Time Off

+ 12 Paid Holidays

+ Parental Leave (20 total weeks with 14 weeks paid) & Milk Stork program

+ Tuition Reimbursement

+ Life & Disability Insurance

+ Well-being and Employee Assistance Programs

Frequently cited statistics show that some women, underrepresented individuals, protected veterans and individuals with disabilities may only apply to roles if they meet 100% of the qualifications. At Renaissance, we encourage all applications! Roles evolve over time, especially with innovation, and you may be just the person we need for the future!

EQUAL OPPORTUNITY EMPLOYER

Renaissance is an equal opportunity employer and does not discriminate with respect to any term, condition or privilege of employment based on race, color, religion, sex, sexual orientation, gender identity or expression, age, disability, military or veteran status, marital status, or status of an individual in any group or class protected by applicable federal, state, or local law.

REASONABLE ACCOMMODATIONS

Renaissance also provides reasonable accommodations for qualified individuals with disabilities in accordance with the Americans with Disabilities Act and applicable state and local laws. If accommodation is needed to participate in the job application or interview process, please contact Talent Acquisition (TATeam@renlearnCRM.onmicrosoft.com) .

EMPLOYMENT AUTHORIZATION

Applicants must be authorized to work for any employer in the United States. We are unable to sponsor or take over sponsorship of an employment Visa at this time.

For information about Renaissance, visit: https://www.renaissance.com/",2025-07-21T00:00:00.000Z,2025-07-25,"['Maintain an accurate and up-to-date knowledge on statistical analysis techniques and applications', '*For this role as a Psychometric Data Analyst II, you must have:**', ""Bachelor's degree in statistics, mathematics, data science, or a related field from four-year accredited college or university, and"", ""Minimum 6 years' experience implementing analysis and testing plans and defining and tracking metrics, OR"", 'Equivalent combination of education and experience', 'Extensive database management experience in both structured (SQL) and unstructured (NoSQL) databases especially MongoDB', 'Ability to manipulate and analyze data in SAS, r, and Python', 'Exceptional attention to detail', 'Demonstrated ability to work well within a team and cross functionally', ""Master's degree in Statistics or a related field"", 'Applicants must be authorized to work for any employer in the United States']","['*In this role as a Psychometric Data Analyst II, you will: **', 'Extract assessment data from Snowflake and/or MongoDB as needed for various analyses', 'Analyze psychometric data related to item and test content, quality, and performance from a variety of sources, both structured and unstructured', 'Define and track assessment quality and performance related metrics', 'Design and implement research, testing, and data mining projects, including scenarios and simulations', 'Communicate results of analyses through written reports, visual displays, and verbal communication', 'Support the psychometricians with statistical analyses related to advanced psychometric work']",True,[],,"['SQL', 'NoSQL', 'MongoDB', 'SAS', 'R', 'Python', 'Statistical Analysis', 'Data Mining', 'Metrics Tracking', 'Data Extraction', 'Data Visualization']","SQL: Used for extracting and managing structured assessment data from databases like Snowflake.; NoSQL: Used for handling unstructured assessment data, particularly with MongoDB.; MongoDB: A NoSQL database employed to store and retrieve unstructured psychometric data.; SAS: A statistical software tool used for manipulating and analyzing psychometric data.; R: A programming language used for statistical analysis and data mining in psychometric research.; Python: Used for data manipulation, analysis, and supporting advanced psychometric statistical work.; Statistical Analysis: Applied to evaluate assessment quality, item and test performance, and support psychometric research.; Data Mining: Used to design and implement projects that explore psychometric data for insights and testing.; Metrics Tracking: Defining and monitoring assessment quality and performance metrics to ensure data reliability.; Data Extraction: Retrieving assessment data from databases to support various analyses and reporting.; Data Visualization: Communicating analysis results through visual displays to support decision-making."
CFCiDRKk1ZL6XOfbAAAAAA==,Senior Data Protection Analyst - Cyber,"Are you passionate about technology and interested in joining a community of collaborative colleagues who respectfully and courageously seek to challenge the status quo? If so, read on to learn more about an exciting opportunity with Deloitte Technology US (DT - US). We are curious and life-long learners focused on technology and innovation.

Recruiting for this role ends on 7/31/2025.

Work you'll do

DT-US Cyber Data Protection team is responsible for securing and protecting confidential data of Deloitte US Member Firm, our clients, and our employees. The team's core mission is to implement consistent security controls to protect Firm's data and data entrusted to us by our clients to build their trust and protect our brand. We are seeking an experienced and energetic Senior Data Protection Analyst with outstanding communication, analytical and cyber security technical skills to join our Cyber Data Protection team within Deloitte Technology US (DT - US).

If you're an experienced, hands-on IT professional with strong systems administration, engineering, IT technical support and/or cyber security technical skills who's interested in growing in the cybersecurity field, this may be the job for you. As part of our Cyber Data Protection team, you will be assisting in designing, deploying, and managing cyber technology and process solutions to reduce the potential of data compromise. You will be assisting with testing of data protection and data security solutions. You will work to enhance and mature existing cyber security data protection capabilities for Deloitte US Member Firm and provide on-going support for them. You will require an understanding of the ecosystem of data protection including well-rounded understanding of the information security domains and their inter-relations across that ecosystem. You will be responsible for providing technical product and troubleshooting assistance to Deloitte Employees. You will work closely with management, lead analysts, peers, development teams, business analysts, and end users to ensure data protection technologies and data protection controls for systems are operating appropriately without causing business impact.

As part of the DT- US Cyber Data Protection team, you will have the following core responsibilities:
• Assist with the development, deployment and support of cyber data protection solutions.
• Assist with the implementation of data security controls and design principles.
• Provide Tier 2 technical support to Deloitte end users for several of the cyber data protection services supported by the team that includes but not limited to Data Loss Prevention, Data Minimization, Data Classification and Rights Management, CASB, Web Security, Web Application Firewall, Next Generation Anti-virus and Endpoint Detection and Response technology, Endpoint Admin Rights Management/Privilege Management technology, PKI Certificate Lifecycle Management, Encryption Key Management, Digital Code Signing, Removable Media Protection, Data Discovery Roll Off Scans etc.
• Assist in maturing existing data protection solutions protecting against data exfiltration.
• Assist in rolling out new data protection services to employees, getting them adopted and providing on-going support for those services.
• Assist with technology and software reviews based on data protection and endpoint risks.
• Provide technical engineering and troubleshooting support to employees for data protection services.

Experience working with various data protection technologies:
• Data Loss Prevention (DLP) technology
• Data Classification and Rights Management technology
• Cloud Access Security Broker (CASB)
• Secure Web Gateway/Proxy (SWG) technology
• Next Generation Anti-virus and Endpoint Detection and Response technology
• Endpoint Admin Rights Management/Privilege Management technology
• PKI Certificate Management technology
• Encryption Key Management technology
• Web Application Firewall technology
• Confidential Data Reduction technology
• Data Access Governance technology
• Removable Media Protection technology
• Database Encryption technologies

The team

Deloitte Technology US (DT - US) helps power Deloitte's success, which serves many of the world's largest, most respected organizations. We develop and deploy cutting-edge internal and go-to-market solutions that help Deloitte operate effectively and lead in the market. Our reputation is built on a tradition of delivering with excellence.

The ~3,000 professionals in DT - US deliver services including:
• Cyber Security
• Technology Support
• Technology & Infrastructure
• Applications
• Relationship Management
• Strategy & Communications
• Project Management
• Financials

Cyber Security

Cyber Security vigilantly protects Deloitte and client data. The team leads a strategic cyber risk program that adapts to a rapidly changing threat landscape, changes in business strategies, risks, and vulnerabilities. Using situational awareness, threat intelligence, and building a security culture across the organization, the team helps to protect the Deloitte brand.

Areas of focus include:
• Risk & Compliance
• Identity & Access Management
• Data Protection
• Cyber Design
• Incident Response
• Security Architecture
• Business Partnership

Required Qualifications:
• Bachelor's degree or equivalent in Computer Science or Engineering.
• Minimum 5 years of combined experience in the Information Security/Cybersecurity domain.
• Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future

Preferred Qualifications:
• Experienced with implementing and managing data protection strategies across data at rest, data in motion, and data in use.
• Experience with troubleshooting issues and assisting end users to mitigate technical challenges.
• Familiarity with change management and deployment processes in large IT organizations.
• Working knowledge with common IT technologies such as Windows Server, Linux/Unix, Databases, Active Directory/LDAP, virtualization, end-user devices etc.
• Working knowledge of IT/security principles such as encryption, identity, cloud, etc.
• Experience with PowerShell command-line scripting is a plus.
• Professional security certification desirable, such as Security+ or CISSP.
• Understanding of industry best practices related to risk assessment, mitigation, and incident response.
• Knowledge of data protection regulations and standards (e.g., ISO 27001, ISO 27018, NIST 800-171).
• Understanding of networking and core networking protocols (e.g., TCP/IP, UDP, DNS, SMTP, HTTP, TLS, and distributed networks).
• Knowledge in different types of VPN, Encryption Standards, Certificates.
• Understanding of security controls in public cloud environments (i.e., Amazon Web Services (AWS), Microsoft Azure, Google Cloud Platform) and SaaS services hardening.
• Ability to write technical reports and communicate technical content to business users.
• Self-motivated with a strong willingness to learn and grow with changing cloud technologies.
• Experience working in a virtual team.
• Troubleshooting and problem analysis skills.
• Understanding of information security frameworks, incident management/response, security operations, and application security best practices.
• Competency with Microsoft Windows and/or MacOS Operating Systems

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $84,300 - $173,300.

You may also be eligible to participate in a discretionary annual incentive program, subject to the rules governing the program, whereby an award, if any, depends on various factors, including, without limitation, individual and organizational performance.

Information for applicants with a need for accommodation: https://www2.deloitte.com/us/en/pages/careers/articles/join-deloitte-assistance-for-disabled-applicants.html

EA_ExpHire

RITM9065907

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.",2025-07-17T00:00:00.000Z,2025-07-25,"['Data Loss Prevention (DLP) technology', 'Secure Web Gateway/Proxy (SWG) technology', 'Next Generation Anti-virus and Endpoint Detection and Response technology', 'Endpoint Admin Rights Management/Privilege Management technology', 'PKI Certificate Management technology', 'Encryption Key Management technology', 'Web Application Firewall technology', 'Confidential Data Reduction technology', 'Data Access Governance technology', 'Removable Media Protection technology', 'Database Encryption technologies', 'Identity & Access Management', ""Bachelor's degree or equivalent in Computer Science or Engineering"", 'Minimum 5 years of combined experience in the Information Security/Cybersecurity domain', 'Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future', 'The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs']","['As part of our Cyber Data Protection team, you will be assisting in designing, deploying, and managing cyber technology and process solutions to reduce the potential of data compromise', 'You will be assisting with testing of data protection and data security solutions', 'You will work to enhance and mature existing cyber security data protection capabilities for Deloitte US Member Firm and provide on-going support for them', 'You will require an understanding of the ecosystem of data protection including well-rounded understanding of the information security domains and their inter-relations across that ecosystem', 'You will be responsible for providing technical product and troubleshooting assistance to Deloitte Employees', 'You will work closely with management, lead analysts, peers, development teams, business analysts, and end users to ensure data protection technologies and data protection controls for systems are operating appropriately without causing business impact', 'As part of the DT- US Cyber Data Protection team, you will have the following core responsibilities:', 'Assist with the development, deployment and support of cyber data protection solutions', 'Assist with the implementation of data security controls and design principles', 'Provide Tier 2 technical support to Deloitte end users for several of the cyber data protection services supported by the team that includes but not limited to Data Loss Prevention, Data Minimization, Data Classification and Rights Management, CASB, Web Security, Web Application Firewall, Next Generation Anti-virus and Endpoint Detection and Response technology, Endpoint Admin Rights Management/Privilege Management technology, PKI Certificate Lifecycle Management, Encryption Key Management, Digital Code Signing, Removable Media Protection, Data Discovery Roll Off Scans etc', 'Assist in maturing existing data protection solutions protecting against data exfiltration', 'Assist in rolling out new data protection services to employees, getting them adopted and providing on-going support for those services', 'Assist with technology and software reviews based on data protection and endpoint risks', 'Provide technical engineering and troubleshooting support to employees for data protection services', 'Cloud Access Security Broker (CASB)', 'Strategy & Communications', 'Project Management']",False,[],,"['Data Loss Prevention', 'Data Classification and Rights Management', 'Cloud Access Security Broker', 'Secure Web Gateway', 'Endpoint Detection and Response', 'Endpoint Privilege Management', 'PKI Certificate Management', 'Encryption Key Management', 'Web Application Firewall', 'Confidential Data Reduction', 'Data Access Governance', 'Removable Media Protection', 'Database Encryption', 'Identity and Access Management', 'Encryption', 'PowerShell Scripting', 'Information Security Frameworks', 'Incident Response', 'Networking Protocols', 'Public Cloud Security']","Data Loss Prevention: Used to prevent unauthorized data exfiltration and protect sensitive information within the organization's cyber data protection strategy.; Data Classification and Rights Management: Applied to categorize data and enforce access controls to ensure proper handling and protection of sensitive data.; Cloud Access Security Broker: Employed to monitor and enforce security policies for cloud services as part of data protection controls.; Secure Web Gateway: Used to protect users from web-based threats and enforce corporate security policies on web traffic.; Endpoint Detection and Response: Implemented to detect, investigate, and respond to advanced threats on endpoint devices.; Endpoint Privilege Management: Used to control and manage administrative rights on endpoints to reduce security risks.; PKI Certificate Management: Manages digital certificates lifecycle to secure communications and authenticate users and devices.; Encryption Key Management: Handles the creation, distribution, and storage of encryption keys to protect data confidentiality.; Web Application Firewall: Protects web applications by filtering and monitoring HTTP traffic to prevent attacks.; Confidential Data Reduction: Techniques used to minimize the amount of sensitive data stored or transmitted to reduce risk.; Data Access Governance: Controls and audits access to data to ensure compliance with security policies and regulations.; Removable Media Protection: Secures data on removable storage devices to prevent unauthorized data transfer or loss.; Database Encryption: Encrypts data stored in databases to protect sensitive information from unauthorized access.; Identity and Access Management: Manages user identities and access rights to ensure only authorized users can access data and systems.; Encryption: Fundamental security principle applied to protect data confidentiality across various systems and communications.; PowerShell Scripting: Used for automating administrative and security tasks related to data protection and system management.; Information Security Frameworks: Guides the implementation of security controls and risk management practices relevant to data protection.; Incident Response: Processes and actions taken to detect, respond to, and recover from security incidents affecting data.; Networking Protocols: Knowledge of protocols like TCP/IP, DNS, HTTP, TLS is essential for securing data in transit and network communications.; Public Cloud Security: Applies security controls and best practices to protect data and services hosted on cloud platforms like AWS, Azure, and GCP."
d2U_5v716K_r4I5AAAAAAA==,"Associate, Data Analytics","About Us

Social Finance is a national nonprofit and a registered investment advisor (SF Advisors, LLC). We work with the public, private, and social sectors to create partnerships and investments that measurably improve lives. Since our founding in 2011, we have mobilized over $400 million in new investments designed to help people and communities realize improved outcomes in workforce and economic mobility, health, and housing.

We are driven by the belief that social and economic systems should enable all people to thrive, and the conviction that we can create the most meaningful and measurable change in our communities when governments and markets work together. Our organization is built upon five core values: people, performance, integrity, collaboration, and inclusion.

Our work spans four areas: Impact-first Investing, Workforce and Education Investments, Advisory & Public Sector Practice, and the Social Finance Institute. Our Impact-first Investment team designs, launches, and manages investments that provide solutions for effectively deploying impact capital across a range of social outcomes. Our Workforce and Education Investments team designs, launches and manages financial solutions focused on addressing workforce challenges, including skills acquisition and training access. Our Advisory team partners with government and philanthropy leaders to implement data-driven programs for advancing social impact. And through the Social Finance Institute, we aim to build the field and change systems through actionable research, communities of practice, and educational outreach.

Note: To be considered for our open roles, candidates must hold permanent U.S. work authorization at the time of application, which will not require employer sponsorship at point-of-hire or in the future.

The Opportunity

The Data Analytics team works across the organization to deepen our development and execution of data analysis and visualization, data management and strategy, and program assessment and learning workstreams. We are seeking a dedicated, driven and team-oriented Associate, Data Analytics to serve as an integral member of the Social Finance team and help us deliver on our Data Solutions service offerings, joining a team of four other data analytics professionals. While the data analytics team works across all areas of our business, this role will initially focus on data analytics efforts within our Impact Advisory & Public Sector Practice team. The early portfolio for this position may include:
• Impact Advisory & Public Sector Practice: Analyzing administrative data, developing and updating data dashboards, supporting primary quantitative and qualitative data collection, and assessing and providing recommendations on data management strategies.

Project allocation may evolve over time to support other data analytics needs across the Social Finance team. This position reports to the Director, Data Analytics & Evaluation.

Responsibilities
• Data analysis. Use statistical software (such as Stata or R) to validate, structure, clean, and analyze public sector data
• Visualizing and presenting data. Create effective visual storytelling through data dashboards, interactive figures, and internal and external communication materials
• Data collection. Support primary data collection by developing surveys and interview guides, including programming surveys in programs such as Qualtrics
• Data management. Assessing and providing recommendations to clients on best practices for organizing, structuring, storing, and accessing data
• Program assessment. Support assessment of program performance through identifying key research questions and analyzing performance using quantitative and qualitative data
• Drive stakeholder engagement in data analytics efforts. Develop and manage internal and external stakeholder relationships and engagement on data analytics workstreams
• Implementing data equity principles. Ensure data analysis and data visualization workstreams follow best practices in data equity in terms of design, structure, and format
• Provide support to teams carrying out data analysis and data visualization tasks, including troubleshooting challenges and conducting testing and quality assurance on coding and product development
• Contribute to firm capacity-building initiatives, such as recruiting, professional development, knowledge management, fundraising, or other internal projects

Qualifications
• 2 to 5 years of full-time professional experience with relevant and transferable skills related to data analysis, data visualization, program assessment, and data collection
• Bachelor's degree or related certificate in computer science, data analytics, economics, finance, engineering, political science, or related field
• Experience coding in Stata or R, or experience with another statistical analysis program and willingness and demonstrated capacity to learn Stata or R
• Experience developing data dashboards in Tableau or PowerBi, or experience with another data visualization software and willingness and demonstrated capacity to learn Tableau.
• Experience with or an understanding of the public sector and social service delivery
• Experience or familiarity with at least one of our core issue areas: children and families, workforce development and economic mobility, housing and homelessness, or public safety.
• Detail-oriented and adept at instituting quality control checks and ensuring accuracy in data analysis
• Strong oral and written communications skills, with the ability to summarize and explain research studies in a compelling way, including through well-written memos and PowerPoint presentations.
• Ability to communicate, work closely with, and build relationships with many types of partners across multiple sectors
• Ability to adapt, be flexible, and work independently to complete high-quality project work
• Commitment to enhancing a team culture of inclusion, belonging and equity

Benefits

At Social Finance, we strive to deliver a benefits program that will enhance our overall value proposition to employees. Our current benefit offerings include:
• Comprehensive health care coverage: medical, dental and vision insurance, flexible spending accounts, and more
• Retirement savings plan with employer contribution
• Short-term, long-term and life insurance policies
• Commuter benefits and cell phone reimbursements
• Hybrid work model (in office at least two days per week)
• Dedicated budgets for team building and employee recognition
• Annual budget for external professional development opportunities
• Mentorship and onboarding programs
• Collaborative and energizing workspaces in downtown Boston, MA; San Francisco, CA; Austin, TX; Washington, D.C.; and New York, NY
• Paid vacation and paid holidays (with 12/24-1/1 off every year)
• Paid parental leave
• A truly stellar team of high performing, values-driven and fun (!) professionals

Salary

Social Finance uses a lockstep compensation model for purposes of equity and transparency - we strive for everyone coming in at a given level to be paid equitably. For this position, at the Associate level, the starting base salary is $81,000; however, during the interview process, we will take into account a candidate's full work experience and may adjust the job title, and commensurate starting salary, as appropriate. At this level, employees typically receive a $2,500 salary increase annually and are eligible to participate in our firmwide annual bonus program. Bonuses are typically between 5-10%, though bonuses are not guaranteed and are dependent on both organizational and individual performance.

If joining our San Francisco office, this hire would receive a cost of living adjustment, which includes an additional $1,000 for every month they are residing in the state of California within a commutable distance of our office in San Francisco

Review of applications will begin immediately. No phone calls, please.

Applicants must be permanently authorized to work in the United States on a full-time basis.

Please note that, at this time, to be in-person at a Social Finance office, client location or Social Finance-sponsored event, you must be fully vaccinated against COVID-19, including receiving a booster shot.

Social Finance, Inc. is an equal opportunity employer, and all qualified applicants will be afforded equal employment opportunities without discrimination because of actual or perceived race, color, national origin, sex, age, religion, creed, disability, marital status, citizenship, ancestry, personal appearance, sexual orientation, gender identity or expression, political affiliation, military status, status as a protected veteran, genetic information or any other legally protected status.

It is unlawful in Massachusetts to require or administer a lie detector test as a condition of employment or continued employment. An employer who violates this law shall be subject to criminal penalties and civil liability.

When submitting your resume below, please submit as a PDF. Thank you!",,2025-07-25,"['2 to 5 years of full-time professional experience with relevant and transferable skills related to data analysis, data visualization, program assessment, and data collection', ""Bachelor's degree or related certificate in computer science, data analytics, economics, finance, engineering, political science, or related field"", 'Experience coding in Stata or R, or experience with another statistical analysis program and willingness and demonstrated capacity to learn Stata or R', 'Experience developing data dashboards in Tableau or PowerBi, or experience with another data visualization software and willingness and demonstrated capacity to learn Tableau', 'Experience with or an understanding of the public sector and social service delivery', 'Experience or familiarity with at least one of our core issue areas: children and families, workforce development and economic mobility, housing and homelessness, or public safety', 'Detail-oriented and adept at instituting quality control checks and ensuring accuracy in data analysis', 'Strong oral and written communications skills, with the ability to summarize and explain research studies in a compelling way, including through well-written memos and PowerPoint presentations', 'Ability to communicate, work closely with, and build relationships with many types of partners across multiple sectors', 'Ability to adapt, be flexible, and work independently to complete high-quality project work', 'Commitment to enhancing a team culture of inclusion, belonging and equity', 'Applicants must be permanently authorized to work in the United States on a full-time basis', 'Please note that, at this time, to be in-person at a Social Finance office, client location or Social Finance-sponsored event, you must be fully vaccinated against COVID-19, including receiving a booster shot']","['The Data Analytics team works across the organization to deepen our development and execution of data analysis and visualization, data management and strategy, and program assessment and learning workstreams', 'While the data analytics team works across all areas of our business, this role will initially focus on data analytics efforts within our Impact Advisory & Public Sector Practice team', 'Impact Advisory & Public Sector Practice: Analyzing administrative data, developing and updating data dashboards, supporting primary quantitative and qualitative data collection, and assessing and providing recommendations on data management strategies', 'Project allocation may evolve over time to support other data analytics needs across the Social Finance team', 'This position reports to the Director, Data Analytics & Evaluation', 'Data analysis', 'Use statistical software (such as Stata or R) to validate, structure, clean, and analyze public sector data', 'Visualizing and presenting data', 'Create effective visual storytelling through data dashboards, interactive figures, and internal and external communication materials', 'Data collection', 'Support primary data collection by developing surveys and interview guides, including programming surveys in programs such as Qualtrics', 'Data management', 'Assessing and providing recommendations to clients on best practices for organizing, structuring, storing, and accessing data', 'Program assessment', 'Support assessment of program performance through identifying key research questions and analyzing performance using quantitative and qualitative data', 'Drive stakeholder engagement in data analytics efforts', 'Develop and manage internal and external stakeholder relationships and engagement on data analytics workstreams', 'Implementing data equity principles', 'Ensure data analysis and data visualization workstreams follow best practices in data equity in terms of design, structure, and format', 'Provide support to teams carrying out data analysis and data visualization tasks, including troubleshooting challenges and conducting testing and quality assurance on coding and product development', 'Contribute to firm capacity-building initiatives, such as recruiting, professional development, knowledge management, fundraising, or other internal projects']",True,[],,"['Statistical Software (Stata, R)', 'Data Dashboards (Tableau, Power BI)', 'Data Collection (Surveys, Qualtrics)', 'Data Management Strategies', 'Program Assessment', 'Data Visualization', 'Data Equity Principles']","Statistical Software (Stata, R): Used for validating, structuring, cleaning, and analyzing public sector data to support data analysis efforts.; Data Dashboards (Tableau, Power BI): Developed and updated to visualize data effectively and support internal and external communication.; Data Collection (Surveys, Qualtrics): Supports primary quantitative and qualitative data collection by developing surveys and interview guides.; Data Management Strategies: Assesses and provides recommendations on best practices for organizing, structuring, storing, and accessing data.; Program Assessment: Analyzes program performance using quantitative and qualitative data to identify key research questions and evaluate outcomes.; Data Visualization: Creates interactive figures and visual storytelling to communicate data insights clearly to stakeholders.; Data Equity Principles: Ensures data analysis and visualization follow best practices in design, structure, and format to promote equity."
H0I1lCNDyz3fz5iFAAAAAA==,Junior Data Analyst,"For more than 15 years Synergisticit has helped Jobseekers stand out from other Jobseekers by providing candidates the requisite skills, experience and technical competence to outperform at interviews and at clients.
Here at SynergisticIT We just don't focus on getting you a tech Job we make careers.
In this market also our candidates get multiple job offers and $100k + salaries.

please check the below links :
https://www.synergisticit.com/candidate-outcomes/

https://synergisticit.wistia.com/medias/o5gmv7i9eu

https://www.youtube.com/playlist?list=PLJgkOBQ51j5AHT5I6n29glr0q6trzkxYD

https://synergisticit.wistia.com/medias/k6t6a1n4kb

Why do Tech Companies not Hire recent Computer Science Graduates | SynergisticIT

Technical Skills or Experience? | Which one is important to get a Job? | SynergisticIT

All Positions are open for all visas and US citizens
We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.
Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Engineers/Data Scientists, Machine Learning engineers for full time positions with clients.
Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.
We assist in filing for STEM extension and also for H1b and Green card filing to Candidates
We want Data Science/Machine learning/Data Analyst and Java Full stack candidates
For data Science/Machine learning Positions
REQUIRED SKILLS
Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
Project work on the technologies needed
Highly motivated, self-learner, and technically inquisitive
Experience in programming language Java and understanding of the software development life cycle
Knowledge of Statistics, Python, Computer Vision, data visualization tools
Excellent written and verbal communication skills
Preferred skills: Snowflake, Databricks, Text mining, Tableau, PowerBI, Databricks, Tensorflow

REQUIRED SKILLS For Java /Full stack/Software Positions
Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
Highly motivated, self-learner, and technically inquisitive
Experience in programming language Java and understanding of the software development life cycle
Project work on the skills
Knowledge of Core Java , javascript , C++ or software programming
Spring boot, AWS Microservices, Docker, Jenkins and REST API's experience
Excellent written and verbal communication skills

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",,2025-07-25,"['Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry', 'For data Science/Machine learning Positions', 'Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT', 'Project work on the technologies needed', 'Highly motivated, self-learner, and technically inquisitive', 'Experience in programming language Java and understanding of the software development life cycle', 'Knowledge of Statistics, Python, Computer Vision, data visualization tools', 'Excellent written and verbal communication skills', 'REQUIRED SKILLS For Java /Full stack/Software Positions', 'Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT', 'Highly motivated, self-learner, and technically inquisitive', 'Experience in programming language Java and understanding of the software development life cycle', 'Project work on the skills', 'Knowledge of Core Java , javascript , C++ or software programming', ""Spring boot, AWS Microservices, Docker, Jenkins and REST API's experience"", 'Excellent written and verbal communication skills']",,True,[],,"['Statistics', 'Python', 'Data Visualization Tools', 'Tableau', 'PowerBI', 'Snowflake', 'Databricks', 'Text Mining', 'Java', 'Computer Vision', 'Machine Learning', 'TensorFlow']","Statistics: Used as foundational knowledge for data analysis and modeling tasks in the data science and analyst roles.; Python: Programming language used for data manipulation, analysis, and building data science projects.; Data Visualization Tools: Tools like Tableau and PowerBI mentioned for creating dashboards and visual insights from data.; Tableau: A BI tool specified for data visualization and dashboard creation.; PowerBI: A business intelligence tool used for data visualization and reporting.; Snowflake: Cloud data platform mentioned as a preferred skill for managing and querying large datasets.; Databricks: Unified analytics platform referenced for data engineering and collaborative data science work.; Text Mining: Technique for extracting useful information from text data, relevant for data analysis tasks.; Java: Programming language experience required, relevant for software development and data engineering.; Computer Vision: Knowledge area mentioned, indicating experience with image data processing and analysis.; Machine Learning: General skill area required for data science and machine learning engineer positions.; TensorFlow: Preferred skill listed, used for building machine learning models and neural networks."
QBRYVs0WAtDhm7rAAAAAAA==,Business Data Analyst,"An employer is seeking a Business Data Analyst for a large financial client sitting in Jacksonville, FL. This person will be responsible for ensuring that all sites are compliant with all bank regulations. They will be responsible for debugging the UI on the backend, onboarding new applications and new websites, publishing the cookies as well as links that need to be added to the websites. This role is responsible for assessing policies, procedures, and operations to ensure the organization meets privacy requirements. They will work with stakeholders to determine requirements derived from privacy legislation. They will collaborate with a variety of groups to manage the workflow from privacy requirements to technical deliverables. Individuals in this role possess a working knowledge of the business/technical domain and the main applications within that domain.
Determine project scope documentation and identify/refine requirements.
Track and report on project status/deliverables and produce project artifacts.
Understand stakeholder needs to help envision and create a solution to solve a problem.
Gather and catalogue functional, non-functional, and technical requirements for stakeholder requests.
Provide subject matter expertise within the business / technical domain to support scope and requirement decisions.
Ensure changes to the application are compliant with bank standards and policies

We are a company committed to creating diverse and inclusive environments where people can bring their full, authentic selves to work every day. We are an equal opportunity/affirmative action employer that believes everyone matters. Qualified candidates will receive consideration for employment regardless of their race, color, ethnicity, religion, sex (including pregnancy), sexual orientation, gender identity and expression, marital status, national origin, ancestry, genetic factors, age, disability, protected veteran status, military or uniformed service member status, or any other status or characteristic protected by applicable laws, regulations, and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application or recruiting process, please send a request to HR@insightglobal.com.

To learn more about how we collect, keep, and process your private information, please review Insight Global's Workforce Privacy Policy: https://insightglobal.com/workforce-privacy-policy/ .",,2025-07-25,,"['This person will be responsible for ensuring that all sites are compliant with all bank regulations', 'They will be responsible for debugging the UI on the backend, onboarding new applications and new websites, publishing the cookies as well as links that need to be added to the websites', 'This role is responsible for assessing policies, procedures, and operations to ensure the organization meets privacy requirements', 'They will work with stakeholders to determine requirements derived from privacy legislation', 'They will collaborate with a variety of groups to manage the workflow from privacy requirements to technical deliverables', 'Individuals in this role possess a working knowledge of the business/technical domain and the main applications within that domain', 'Determine project scope documentation and identify/refine requirements', 'Track and report on project status/deliverables and produce project artifacts', 'Understand stakeholder needs to help envision and create a solution to solve a problem', 'Gather and catalogue functional, non-functional, and technical requirements for stakeholder requests', 'Provide subject matter expertise within the business / technical domain to support scope and requirement decisions', 'Ensure changes to the application are compliant with bank standards and policies']",False,[],,"['Requirements Gathering', 'Compliance Monitoring', 'Project Tracking and Reporting', 'Stakeholder Collaboration', 'Technical Debugging']","Requirements Gathering: Collecting and cataloguing functional, non-functional, and technical requirements from stakeholders to define project scope and deliverables.; Compliance Monitoring: Ensuring that websites and applications adhere to bank regulations and privacy legislation as part of data governance.; Project Tracking and Reporting: Tracking project status and producing artifacts to report progress and ensure alignment with business goals.; Stakeholder Collaboration: Working with various groups to translate privacy requirements into technical deliverables and solutions.; Technical Debugging: Debugging backend UI issues and managing onboarding of new applications and websites to maintain data integrity."
jWLfCiK47FmY1HOVAAAAAA==,Marketing Analyst,"This role is hybrid in Union Square, NY
The Marketing Data Analytics Consultant will be an integral component of the Market Research Team within the Marketing Department. This person will report to the Analytics Sr Specialist whose job it is to work closely with market researchers, brand managers, marketing specialists, and social media managers to collect and analyze data that will be used to assess the impact of marketing activities in market and craft marketing strategies.
Key Responsibilities, Skills and Qualifications
• Pull data from various sources (internal, ad agency, Sprinkler, Google Analytics, Questline).
• Ensure data integrity. Mine raw data files and structure data to prepare for input into dashboards.
• Set up API connections with vendor platforms to automate data transfers
• Work with Analytics Sr. Specialist to: set up data pipelines and create new reports leveraging various data sources
• Proficient with query languages such as SQL, Python, R.
• Proficient with data visualization tools such as Power BI, Tableau, Data Studio
• Proficient with data platforms such as Google Analytics, Oracle, Azure
• Undergrad degree in data science, analytics or related field required.
• Previous experience in data analytics, data science or similar role.
• Machine Learning and Modeling experience preferred
• Experience working with large customer databases
• Experience working with marketing data preferred
The target hiring compensation range for this role is $40 to $45 an hour. Compensation is based on several factors including, but not limited to education, relevant work experience, relevant certifications, and location.",2025-06-30T00:00:00.000Z,2025-07-25,"['Proficient with query languages such as SQL, Python, R', 'Proficient with data visualization tools such as Power BI, Tableau, Data Studio', 'Proficient with data platforms such as Google Analytics, Oracle, Azure', 'Undergrad degree in data science, analytics or related field required', 'Previous experience in data analytics, data science or similar role', 'Experience working with large customer databases']","['The Marketing Data Analytics Consultant will be an integral component of the Market Research Team within the Marketing Department', 'This person will report to the Analytics Sr Specialist whose job it is to work closely with market researchers, brand managers, marketing specialists, and social media managers to collect and analyze data that will be used to assess the impact of marketing activities in market and craft marketing strategies', 'Pull data from various sources (internal, ad agency, Sprinkler, Google Analytics, Questline)', 'Ensure data integrity', 'Mine raw data files and structure data to prepare for input into dashboards', 'Set up API connections with vendor platforms to automate data transfers', 'Work with Analytics Sr', 'Specialist to: set up data pipelines and create new reports leveraging various data sources']",True,[],,"['SQL', 'Python', 'R', 'Power BI', 'Tableau', 'Google Data Studio', 'Google Analytics', 'Oracle', 'Azure', 'Data Pipelines', 'Machine Learning', 'Data Integrity']","SQL: Used for querying and managing data from various sources to support marketing data analysis.; Python: Utilized for data manipulation, analysis, and possibly building data pipelines in marketing analytics.; R: Applied for statistical analysis and modeling within marketing data science tasks.; Power BI: A data visualization tool used to create dashboards and reports for marketing data insights.; Tableau: Used to visualize marketing data and generate interactive reports for stakeholders.; Google Data Studio: Employed to build dashboards and visualize marketing data from various sources.; Google Analytics: A data platform providing web and marketing analytics data for performance assessment.; Oracle: A data platform used to manage and analyze large customer databases relevant to marketing.; Azure: Cloud platform supporting data storage and analytics for marketing data processing.; Data Pipelines: Set up to automate data transfer and integration from multiple marketing data sources.; Machine Learning: Applied for modeling and predictive analytics to enhance marketing strategies.; Data Integrity: Ensuring accuracy and consistency of marketing data used for analysis and reporting."
kE8oPxNiUE-RX-IvAAAAAA==,Junior Data Analyst,"Responsibilities Scrutinize and validate revenue data collected from third-party delivery platforms. Ensure accuracy completeness and consistency of financial information. Analyze revenue trends and patterns to identify discrepancies or anomalies. Provide actionable insights to optimize revenue streams and enhance operational efficiency. Generate regular reports detailing revenue metrics and key performance indicators. Work closely with cross-functional teams including finance operations and IT to address data-related challenges and implement improvements. Implement quality assurance measures to guarantee the reliability of data sources.

Qualifications Associate's degree in Data Science Statistics Business Analytics or related field. Proven experience in data analysis preferably in the context of restaurants. Intermediate level of Excel. Strong analytical and problem-solving skills. Excellent communication skills with the ability to convey complex findings to non-technical stakeholders.

Key Skills Statistics. Excel. SQL. Python. Data Visualization. Presentation skills. Problem-solving and critical thinking skills.",,2025-07-25,"[""Qualifications Associate's degree in Data Science Statistics Business Analytics or related field"", 'Proven experience in data analysis preferably in the context of restaurants', 'Intermediate level of Excel', 'Strong analytical and problem-solving skills', 'Excellent communication skills with the ability to convey complex findings to non-technical stakeholders', 'Key Skills Statistics', 'Excel', 'SQL', 'Python', 'Presentation skills', 'Problem-solving and critical thinking skills']","['Responsibilities Scrutinize and validate revenue data collected from third-party delivery platforms', 'Ensure accuracy completeness and consistency of financial information', 'Analyze revenue trends and patterns to identify discrepancies or anomalies', 'Provide actionable insights to optimize revenue streams and enhance operational efficiency', 'Generate regular reports detailing revenue metrics and key performance indicators', 'Work closely with cross-functional teams including finance operations and IT to address data-related challenges and implement improvements', 'Implement quality assurance measures to guarantee the reliability of data sources']",True,[],,"['Data Validation', 'Revenue Trend Analysis', 'Reporting and Dashboards', 'SQL', 'Excel', 'Python', 'Statistics', 'Data Visualization', 'Quality Assurance in Data']","Data Validation: Ensuring accuracy, completeness, and consistency of revenue data collected from third-party platforms.; Revenue Trend Analysis: Analyzing revenue patterns to identify discrepancies or anomalies for actionable insights.; Reporting and Dashboards: Generating regular reports detailing revenue metrics and key performance indicators.; SQL: Using SQL to query and manipulate financial and operational data.; Excel: Applying intermediate Excel skills for data analysis and validation.; Python: Utilizing Python for data analysis and problem-solving tasks.; Statistics: Applying statistical methods to analyze revenue data and support decision-making.; Data Visualization: Creating visual representations of data to communicate insights effectively.; Quality Assurance in Data: Implementing measures to guarantee the reliability of data sources."
hJeVOiPwVMxk7jSZAAAAAA==,Data Analytics Power BI Developer,"Are you passionate about leveraging data to drive business decisions? Do you have experience with Power BI and a strong understanding of data analytics? State Street is seeking a talented Data Analytics Power BI Developer to join our dynamic team. In this role, you will have the opportunity to work with cutting-edge technology and collaborate with cross-functional teams to deliver data-driven solutions. We are looking for a highly motivated individual with a strong technical background and a proven track record of implementing complex BI solutions. If you are a self-starter with a passion for data and a desire to make an impact, we want to hear from you!

Develop and maintain data analytics solutions using Power BI to support business decision-making processes.
Collaborate with cross-functional teams to understand business requirements and design data models and visualizations that meet their needs.
Utilize strong technical skills to build and optimize data pipelines, dashboards, and reports.
Conduct data analysis to identify trends, patterns, and insights to inform business strategies.
Ensure data quality and accuracy by performing regular audits and troubleshooting any issues.
Stay up-to-date with advancements in data analytics, BI tools, and techniques to continuously improve solutions.
Communicate complex data and analytical findings to non-technical stakeholders in a clear and concise manner.
Manage and prioritize multiple projects and deadlines effectively.
Collaborate with team members to identify areas for improvement and implement process enhancements.
Act as a subject matter expert and provide technical support and guidance to team members as needed.
Proactively identify and resolve data-related issues and troubleshoot technical problems.
Continuously monitor and evaluate the performance of BI solutions and make recommendations for optimization.
Adhere to data security and privacy standards to protect sensitive information.
Document and maintain data analytics processes, procedures, and best practices.
Conduct training and knowledge-sharing sessions for colleagues to promote a data-driven culture.

State Street is an Equal Opportunity Employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. We do not discriminate based upon race, religion, color, national origin, sex, sexual orientation, gender identity, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.",,2025-07-25,"['Do you have experience with Power BI and a strong understanding of data analytics?', 'We are looking for a highly motivated individual with a strong technical background and a proven track record of implementing complex BI solutions']","['Develop and maintain data analytics solutions using Power BI to support business decision-making processes', 'Collaborate with cross-functional teams to understand business requirements and design data models and visualizations that meet their needs', 'Utilize strong technical skills to build and optimize data pipelines, dashboards, and reports', 'Conduct data analysis to identify trends, patterns, and insights to inform business strategies', 'Ensure data quality and accuracy by performing regular audits and troubleshooting any issues', 'Stay up-to-date with advancements in data analytics, BI tools, and techniques to continuously improve solutions', 'Communicate complex data and analytical findings to non-technical stakeholders in a clear and concise manner', 'Manage and prioritize multiple projects and deadlines effectively', 'Collaborate with team members to identify areas for improvement and implement process enhancements', 'Act as a subject matter expert and provide technical support and guidance to team members as needed', 'Proactively identify and resolve data-related issues and troubleshoot technical problems', 'Continuously monitor and evaluate the performance of BI solutions and make recommendations for optimization', 'Adhere to data security and privacy standards to protect sensitive information', 'Document and maintain data analytics processes, procedures, and best practices', 'Conduct training and knowledge-sharing sessions for colleagues to promote a data-driven culture']",True,[],,"['Power BI', 'Data Pipelines', 'Data Models', 'Data Visualization', 'Data Analysis', 'Data Quality Assurance', 'Business Intelligence (BI) Solutions']","Power BI: Used to develop and maintain data analytics solutions, dashboards, and reports to support business decision-making.; Data Pipelines: Built and optimized to ensure smooth data flow and integration for analytics and reporting.; Data Models: Designed to structure data effectively for visualization and analysis based on business requirements.; Data Visualization: Created to communicate complex data insights clearly to non-technical stakeholders.; Data Analysis: Performed to identify trends, patterns, and insights that inform business strategies.; Data Quality Assurance: Ensured through regular audits and troubleshooting to maintain accuracy and reliability of data.; Business Intelligence (BI) Solutions: Implemented complex BI solutions to enable data-driven decision-making across the organization."
vf1g4kXS6JowF5X8AAAAAA==,Associate Research/Data Analyst-OEWS,"You will be joining a Department committed to a culture of TEAMWORK to accomplish our goals together, where we deliver excellence through COLLABORATION with partners and stakeholders, embody ACCOUNTABILITY through trust and professionalism, and embrace WORK-LIFE BALANCE by prioritizing respect, boundaries, and time. While working at DHEWD you will be helping to develop the workforce of the future! Join us as we pursue our vision of “Every Missourian empowered with the skills and education needed for success.”

This position works within Missouri’s Occupational Employment and Wage Statistics (OEWS) team, a program administered by the Bureau of Labor Statistics (BLS). OEWS collects data related to the number of workers in Missouri and the wage ranges by occupation. This information is used for analysis of the occupational composition of different industries, for determining national policy related to structural unemployment, and for other purposes such as training and employment planning at state and local levels. As a member of this team, you will be responsible for reaching out to Missouri employers to gather their data. Contacts will be made through phone calls, emails, and mailings. The position allows an opportunity to both work together as a team and to work independently to get assigned tasks completed. Candidates interested in this position should be flexible and able to adjust as the demand and focus on work shifts.

To perform this job successfully, an individual must be able to perform each essential function of the job with or without reasonable accommodation.
• Collect detailed occupational employment and wage information for Missouri employers by conducting a high volume of phone calls, emails, and other collection methods.
• Analyze job classification information by understanding and utilizing the Standard Occupational Classification (SOC) system and industry classification information by using the North American Classification System (NAICS) received from the US Department of Labor, Bureau of Labor Statistics.
• Properly track and enter activity into the data collection software system.
• Analyze returned employer reports for data quality, accuracy, and completeness.
• Develop and maintain working knowledge of staffing patterns, occupational differences, and occupational coding systems, as well as industry classifications, to solicit and properly code survey responses.
• Proficiently use programs used in the OEWS Program, including Word, Excel, and other program specific software.
• Follow guidelines and requirements put forth by the U.S. Bureau of Labor Statistics in the Cooperative Agreement with the State of Missouri.
• Answer questions regarding the program and how the data is used and the importance of it.
• Research employers to find information related to them, including contact information and industry details.
• Other duties related to the collection and coding of data for the OEWS program.
• Perform other related work as assigned.
• Demonstrate regular and reliable attendance.

Beneficial education and/or work-related experience includes technical or professional experience in business, personnel, public administration or closely related area, including military service.

The State of Missouri offers an excellent benefits package that includes a defined pension plan, generous amounts of leave and holiday time, and eligibility for health insurance coverage. Your total compensation is more than the dollars you receive in your paycheck. To help demonstrate the value of working for the State of Missouri, we have created an interactive Total Compensation Calculator. This tool provides a comprehensive view of benefits and more that are offered to prospective employees. The Total Compensation Calculator and other applicant resources can be found here .

The State of Missouri is an equal opportunity employer.

DHEWDHR@dhewd.mo.gov",,2025-07-25,"['Candidates interested in this position should be flexible and able to adjust as the demand and focus on work shifts', 'To perform this job successfully, an individual must be able to perform each essential function of the job with or without reasonable accommodation', 'Proficiently use programs used in the OEWS Program, including Word, Excel, and other program specific software', 'Follow guidelines and requirements put forth by the U.S. Bureau of Labor Statistics in the Cooperative Agreement with the State of Missouri', 'Beneficial education and/or work-related experience includes technical or professional experience in business, personnel, public administration or closely related area, including military service']","['This information is used for analysis of the occupational composition of different industries, for determining national policy related to structural unemployment, and for other purposes such as training and employment planning at state and local levels', 'As a member of this team, you will be responsible for reaching out to Missouri employers to gather their data', 'Contacts will be made through phone calls, emails, and mailings', 'The position allows an opportunity to both work together as a team and to work independently to get assigned tasks completed', 'Collect detailed occupational employment and wage information for Missouri employers by conducting a high volume of phone calls, emails, and other collection methods', 'Analyze job classification information by understanding and utilizing the Standard Occupational Classification (SOC) system and industry classification information by using the North American Classification System (NAICS) received from the US Department of Labor, Bureau of Labor Statistics', 'Properly track and enter activity into the data collection software system', 'Analyze returned employer reports for data quality, accuracy, and completeness', 'Develop and maintain working knowledge of staffing patterns, occupational differences, and occupational coding systems, as well as industry classifications, to solicit and properly code survey responses', 'Answer questions regarding the program and how the data is used and the importance of it', 'Research employers to find information related to them, including contact information and industry details', 'Other duties related to the collection and coding of data for the OEWS program', 'Perform other related work as assigned', 'Demonstrate regular and reliable attendance']",False,[],,"['Occupational Employment and Wage Statistics', 'Standard Occupational Classification (SOC)', 'North American Industry Classification System (NAICS)', 'Data Collection Software', 'Data Quality Analysis', 'Survey Coding and Classification', 'Microsoft Excel', 'Data Analysis for Workforce Planning']","Occupational Employment and Wage Statistics: Collecting and analyzing employment and wage data to understand workforce composition and support policy and planning.; Standard Occupational Classification (SOC): Utilizing SOC codes to classify and analyze job roles within collected employment data.; North American Industry Classification System (NAICS): Using NAICS codes to categorize industry data for analysis of occupational employment patterns.; Data Collection Software: Tracking and entering employer data and survey responses into specialized software for data management.; Data Quality Analysis: Reviewing returned employer reports to ensure accuracy, completeness, and reliability of collected data.; Survey Coding and Classification: Applying occupational and industry coding systems to properly categorize survey responses.; Microsoft Excel: Using Excel for data organization, analysis, and reporting within the OEWS program.; Data Analysis for Workforce Planning: Analyzing employment and wage data to inform workforce development and training initiatives."
CUnGbokAezvJeakTAAAAAA==,Cloud Data & Analytics Implementation Senior Associate (Insurance),"Industry/Sector
Insurance

Specialism
Data, Analytics & AI

Management Level
Senior Associate

Job Description & Summary
A career within Data and Analytics services will provide you with the opportunity to help organisations uncover enterprise insights and drive business results using smarter data analytics. We focus on a collection of organisational technology capabilities, including business intelligence, data management, and data assurance that help our clients drive innovation, growth, and change within their organisations in order to keep up with the changing nature of customers and technology. We make impactful decisions by mixing mind and machine to leverage data, understand and navigate risk, and help our clients gain a competitive edge.

You'll focus on aligning client data strategies to their business strategy. You will assist clients in choosing a platform, defining their data needs and migrating them to a modern cloud data environment using cloud providers such as Azure, Google Cloud Platform, Amazon Web Services, Snowflake, Databricks or Teradata.

To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.

As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:
• Use feedback and reflection to develop self awareness, personal strengths and address development areas.
• Delegate to others to provide stretch opportunities, coaching them to deliver results.
• Demonstrate critical thinking and the ability to bring order to unstructured problems.
• Use a broad range of tools and techniques to extract insights from current industry or sector trends.
• Review your work and that of others for quality, accuracy and relevance.
• Know how and when to use tools available for a given situation and can explain the reasons for this choice.
• Seek and embrace opportunities which give exposure to different situations, environments and perspectives.
• Use straightforward communication, in a structured way, when influencing and connecting with others.
• Able to read situations and modify behavior to build quality relationships.
• Uphold the firm's code of ethics and business conduct.

Job Requirements and Preferences:

Basic Qualifications:

Minimum Degree Required:
Bachelor Degree

Minimum Years of Experience:
4 year(s)

Preferred Qualifications:

Certification(s) Preferred:
• Certification in one of the following cloud platform - AWS/Azure/GCP
• Certification in Snowflake
• Certification in any ETL/ELT tool

Preferred Knowledge/Skills:

Demonstrates thorough knowledge and success as both team leader and member roles within a professional services firm or large enterprise.
• Understanding and experience with modern cloud data architectures and engineering for one or more of the following cloud providers - AWS, Azure, GCP;
• Implementing cloud data architecture and data integration patterns for one or more of the cloud providers (AWS Glue, Azure Data Factory, Event Hub, Databricks,Snowflake etc.), storage and processing (Redshift, Azure Synapse, BigQuery, Snowflake); Infrastructure as code (CloudFormation, Terraform);
• Understanding and thorough knowledge of Data Warehousing concepts (normalization, OLAP, OLTP, Vault data model, graphs, star & snowflake schemas);
• Applying knowledge and relevant work experience in Big data engineering (Hadoop, Spark, Scala, Kafka) and ETL pipeline development tools (tools: IICS/AWS Glue/Matillion/Abinitio SSIS/SnapLogic); preferable in P&C/L&A Insurance data warehouse;
• Developing file and object-based storage solutions using Azure ADLS 2.0 or AWS S3;
• Applying knowledge in SQL, report generation using visualization tools such as Tableau/Power BI/Cognos
• Programming using Python/Spark
• Understanding of enterprise data concepts such as Master Data Management Data Governance and Enterprise Data Warehouse;
• Support cross-functional teams to understand their workflow and automation needs.
• Design and develop scalable data warehouse solutions that meet the organization's data storage, retrieval, and analysis requirements.
• Understanding and familiarity of one or more is a big plus - CI/CD, cloud devops, containers (kubernetes/Docker, etc.);
• Understanding of insurance data, underlying KPIs and how they are used; and,
• Demonstrating prior P&C/L&A Insurance industry experience.

Demonstrates thorough abilities success with managing the identification and addressing of client needs:
• Applying modern, cloud-based technology skills, ability to research emerging trends, analyst publications, and adoption of modern technologies in solution architectures;
• Contributing as a team member by understanding personal and team roles, contributing to a positive working environment by building proven relationships with team members, proactively seeking guidance, clarification and feedback;and,
• Prioritizing and handling multiple tasks, researching and analyzing pertinent client, industry and technical matters, utilizing problem-solving skills, and communicating effectively in written and verbal formats to various audiences (including various levels of management and external clients) in a professional business environment.

Travel Requirements
Up to 80%

Job Posting End Date

Learn more about how we work: https://pwc.to/how-we-work

PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.

As PwC is anequal opportunity employer, all qualified applicants will receive consideration for employment at PwC without regard to race; color; religion; national origin; sex (including pregnancy, sexual orientation, and gender identity); age; disability; genetic information (including family medical history); veteran, marital, or citizenship status; or, any other status protected by law.

For only those qualified applicants that are impacted by the Los Angeles County Fair Chance Ordinance for Employers, the Los Angeles' Fair Chance Initiative for Hiring Ordinance, the San Francisco Fair Chance Ordinance, San Diego County Fair Chance Ordinance, and the California Fair Chance Act, where applicable, arrest or conviction records will be considered for Employment in accordance with these laws. At PwC, we recognize that conviction records may have a direct, adverse, and negative relationship to responsibilities such as accessing sensitive company or customer information, handling proprietary assets, or collaborating closely with team members. We evaluate these factors thoughtfully to establish a secure and trusted workplace for all.

Applications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https://pwc.to/us-application-deadlines

The salary range for this position is: $77,000 - $202,000, plus individuals may be eligible for an annual discretionary bonus. For roles that are based in Maryland, this is the listed salary range for this position. Actual compensation within the range will be dependent upon the individual's skills, experience, qualifications and location, and applicable employment laws. PwC offers a wide range of benefits, including medical, dental, vision, 401k, holiday pay, vacation, personal and family sick leave, and more. To view our benefits at a glance, please visit the following link: https://pwc.to/benefits-at-a-glance",2025-07-16T00:00:00.000Z,2025-07-25,"['Bachelor Degree', '4 year(s)', 'Demonstrates thorough knowledge and success as both team leader and member roles within a professional services firm or large enterprise', 'Understanding and experience with modern cloud data architectures and engineering for one or more of the following cloud providers - AWS, Azure, GCP;', 'Implementing cloud data architecture and data integration patterns for one or more of the cloud providers (AWS Glue, Azure Data Factory, Event Hub, Databricks,Snowflake etc.), storage and processing (Redshift, Azure Synapse, BigQuery, Snowflake); Infrastructure as code (CloudFormation, Terraform);', 'Understanding and thorough knowledge of Data Warehousing concepts (normalization, OLAP, OLTP, Vault data model, graphs, star & snowflake schemas);', 'Applying knowledge and relevant work experience in Big data engineering (Hadoop, Spark, Scala, Kafka) and ETL pipeline development tools (tools: IICS/AWS Glue/Matillion/Abinitio SSIS/SnapLogic); preferable in P&C/L&A Insurance data warehouse;', 'Developing file and object-based storage solutions using Azure ADLS 2.0 or AWS S3;', 'Applying knowledge in SQL, report generation using visualization tools such as Tableau/Power BI/Cognos', 'Programming using Python/Spark', 'Understanding of enterprise data concepts such as Master Data Management Data Governance and Enterprise Data Warehouse;', 'Understanding and familiarity of one or more is a big plus - CI/CD, cloud devops, containers (kubernetes/Docker, etc.);', 'Demonstrating prior P&C/L&A Insurance industry experience', 'Demonstrates thorough abilities success with managing the identification and addressing of client needs:', 'Applying modern, cloud-based technology skills, ability to research emerging trends, analyst publications, and adoption of modern technologies in solution architectures;', 'Contributing as a team member by understanding personal and team roles, contributing to a positive working environment by building proven relationships with team members, proactively seeking guidance, clarification and feedback;and,', 'Prioritizing and handling multiple tasks, researching and analyzing pertinent client, industry and technical matters, utilizing problem-solving skills, and communicating effectively in written and verbal formats to various audiences (including various levels of management and external clients) in a professional business environment']","['We make impactful decisions by mixing mind and machine to leverage data, understand and navigate risk, and help our clients gain a competitive edge', ""You'll focus on aligning client data strategies to their business strategy"", 'You will assist clients in choosing a platform, defining their data needs and migrating them to a modern cloud data environment using cloud providers such as Azure, Google Cloud Platform, Amazon Web Services, Snowflake, Databricks or Teradata', ""As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution"", 'PwC Professional skills and responsibilities for this management level include but are not limited to:', 'Use feedback and reflection to develop self awareness, personal strengths and address development areas', 'Delegate to others to provide stretch opportunities, coaching them to deliver results', 'Demonstrate critical thinking and the ability to bring order to unstructured problems', 'Use a broad range of tools and techniques to extract insights from current industry or sector trends', 'Review your work and that of others for quality, accuracy and relevance', 'Know how and when to use tools available for a given situation and can explain the reasons for this choice', 'Seek and embrace opportunities which give exposure to different situations, environments and perspectives', 'Use straightforward communication, in a structured way, when influencing and connecting with others', 'Able to read situations and modify behavior to build quality relationships', ""Uphold the firm's code of ethics and business conduct"", 'Support cross-functional teams to understand their workflow and automation needs', ""Design and develop scalable data warehouse solutions that meet the organization's data storage, retrieval, and analysis requirements"", 'Understanding of insurance data, underlying KPIs and how they are used; and,']",True,[],,"['Cloud Data Architecture', 'Data Integration Patterns', 'Data Warehousing Concepts', 'Big Data Engineering', 'ETL Pipeline Development', 'Cloud Storage Solutions', 'SQL and Data Visualization', 'Python and Spark Programming', 'Enterprise Data Concepts', 'Infrastructure as Code', 'Containerization and DevOps', 'Insurance Data and KPIs', 'Business Intelligence']","Cloud Data Architecture: Designing and implementing modern cloud data environments using platforms like AWS, Azure, GCP, Snowflake, Databricks, and Teradata to support client data strategies.; Data Integration Patterns: Implementing data integration workflows using cloud-native tools such as AWS Glue, Azure Data Factory, Event Hub, and Databricks to migrate and process data.; Data Warehousing Concepts: Applying knowledge of normalization, OLAP, OLTP, Vault data model, and star & snowflake schemas to design scalable data warehouse solutions.; Big Data Engineering: Utilizing big data technologies like Hadoop, Spark, Scala, and Kafka for processing large-scale insurance data warehouses.; ETL Pipeline Development: Developing and managing ETL/ELT pipelines using tools such as IICS, AWS Glue, Matillion, Abinitio, SSIS, and SnapLogic to automate data workflows.; Cloud Storage Solutions: Building file and object-based storage solutions using Azure ADLS 2.0 and AWS S3 to support data storage needs.; SQL and Data Visualization: Using SQL for data querying and generating reports with visualization tools like Tableau, Power BI, and Cognos to extract insights.; Python and Spark Programming: Programming with Python and Spark to develop data processing scripts and analytics workflows.; Enterprise Data Concepts: Applying Master Data Management, Data Governance, and Enterprise Data Warehouse principles to ensure data quality and compliance.; Infrastructure as Code: Using tools like CloudFormation and Terraform to automate cloud infrastructure deployment supporting data environments.; Containerization and DevOps: Familiarity with CI/CD pipelines, Kubernetes, and Docker to support cloud data platform operations and automation.; Insurance Data and KPIs: Understanding insurance-specific data and key performance indicators to tailor data solutions for P&C and L&A insurance sectors.; Business Intelligence: Leveraging BI tools and dashboards to help clients make data-driven decisions and gain competitive advantage."
lVstnHrIi1w40Nb-AAAAAA==,Actuarial Support Analyst III (Entry Level),"About the position

At USAA, we have an important mission: facilitating the financial security of millions of U.S. military members and their families. We are seeking a dedicated Actuarial Support Analyst III (Entry Level) to support actuarial and loss reserving work through various activities such as data manipulation, validation, and analysis. This position requires an individual to be in the office 4 days per week and can be based in several locations including Phoenix, AZ; San Antonio, TX; Plano, TX; Chesapeake, VA; Charlotte, NC; Colorado Springs, CO or Tampa, FL. Relocation assistance is not available for this position.

Responsibilities
• Supports actuarial and loss reserving work through data manipulation, validation, and analysis.
,
• Performs research and prepares and validates reports to support actuarial staff.
,
• Compiles data and provides technical and analytical support for studies, projects, or reviews.
,
• Seeks guidance from team members to resolve issues and to identify appropriate issues for escalation.

Requirements
• Bachelor's degree (4 additional years of related experience beyond the minimum required may be substituted in lieu of a Degree)
,
• Up to 2 years relevant business and/or general analysis experience
,
• Foundational knowledge of Microsoft Office tools including Word, Excel, PowerPoint, and Access
,
• Foundational knowledge of relevant data analysis tools; Basic knowledge of relevant data extraction tools.

Nice-to-haves
• Prior property insurance product or pricing experience
,
• Strong problem-solving, innovation, and process improvement skills
,
• Advanced level knowledge of Microsoft Excel
,
• Work experience with data analytics
,
• Work experience with Python, SQL, or other programming language
,
• Work experience with Earnix
,
• US military experience through military service or a military spouse/domestic partner

Benefits
• Comprehensive medical, dental and vision plans
,
• 401(k)
,
• Pension
,
• Life insurance
,
• Parental benefits
,
• Adoption assistance
,
• Paid time off program with paid holidays plus 16 paid volunteer hours
,
• Various wellness programs
,
• Career path planning and continuing education assistance",,2025-07-25,"['This position requires an individual to be in the office 4 days per week and can be based in several locations including Phoenix, AZ; San Antonio, TX; Plano, TX; Chesapeake, VA; Charlotte, NC; Colorado Springs, CO or Tampa, FL', ""Bachelor's degree (4 additional years of related experience beyond the minimum required may be substituted in lieu of a Degree)"", 'Up to 2 years relevant business and/or general analysis experience', 'Foundational knowledge of Microsoft Office tools including Word, Excel, PowerPoint, and Access', 'Foundational knowledge of relevant data analysis tools; Basic knowledge of relevant data extraction tools', 'Prior property insurance product or pricing experience', 'Strong problem-solving, innovation, and process improvement skills', 'Advanced level knowledge of Microsoft Excel', 'Work experience with data analytics', 'Work experience with Python, SQL, or other programming language', 'Work experience with Earnix', 'US military experience through military service or a military spouse/domestic partner']","['We are seeking a dedicated Actuarial Support Analyst III (Entry Level) to support actuarial and loss reserving work through various activities such as data manipulation, validation, and analysis', 'Supports actuarial and loss reserving work through data manipulation, validation, and analysis', 'Performs research and prepares and validates reports to support actuarial staff', 'Compiles data and provides technical and analytical support for studies, projects, or reviews', 'Seeks guidance from team members to resolve issues and to identify appropriate issues for escalation']",False,[],,"['Data Manipulation', 'Data Validation', 'Data Analysis', 'Python', 'SQL', 'Microsoft Excel', 'Earnix']","Data Manipulation: Used to support actuarial and loss reserving work by preparing and validating data for analysis.; Data Validation: Ensures accuracy and integrity of data used in actuarial studies and reports.; Data Analysis: Applied to analyze actuarial data and support technical and analytical studies.; Python: Programming language used for data analytics and possibly automating data processing tasks.; SQL: Used for data extraction and querying databases to support actuarial analysis.; Microsoft Excel: Advanced Excel skills are used for data manipulation, analysis, and reporting in actuarial tasks.; Earnix: A pricing and product analytics tool used in insurance, relevant for actuarial pricing and product analysis."
h3gffiseL3cHej7oAAAAAA==,"Senior Analyst, Revenue Data Analytics","Join Axon and be a Force for Good.

At Axon, we're on a mission to Protect Life. We're explorers, pursuing society's most critical safety and justice issues with our ecosystem of devices and cloud software. Like our products, we work better together. We connect with candor and care, seeking out diverse perspectives from our customers, communities and each other.

Life at Axon is fast-paced, challenging and meaningful. Here, you'll take ownership and drive real change. Constantly grow as you work hard for a mission that matters at a company where you matter.

Your Impact

As a Senior Analyst, Revenue Data Analytics at Axon and a member of the Revenue Transformation team you will support the Revenue Accounting org in advancing their reporting and analytics maturity by building scalable reporting solutions, enhancing data governance, and ensuring analytical insights are effectively used in strategic decision-making. You will partner cross-functionally with Accounting, Finance, Data Engineering, IT, and Business Intelligence teams to drive reporting excellence and elevate Axon's revenue analytics capabilities. You will be expected to own key datasets, develop insightful reports and dashboards, and collaborate with stakeholders to define analytical needs and implement effective solutions tailored to the business's specifications. Your work will fuel operational improvements, data-driven decisions, and help scale a high-performing finance and accounting ecosystem.

What You'll Do
Location: Hybrid at a US Hub Location (Scottsdale, Seattle, San Francisco, Denver, Sterling, Washington DC, Atlanta, Boston)
Reports to: Sr, Director Revenue Transformation
Direct Reports: 0
• Revenue Analytics Development: Design, build, and maintain robust, user-friendly dashboards and reports to support revenue and accounting teams. Ensure outputs are actionable, scalable, and aligned with strategic goals.
• Data Governance: Partner with business stakeholders to implement and uphold data governance standards across key revenue data assets, contributing to data accuracy and consistency.
• Data Integration & Collaboration: Work closely with Data Engineering to define data pipelines, ensure seamless integration between source systems (Microsoft Dynamics 365, RevStream, Salesforce), and optimize end-to-end data workflows.
• Process Optimization: Support transformation initiatives by identifying bottlenecks, proposing enhancements, and contributing to continuous improvement efforts in revenue-related processes.
• Business Partnership: Serve as a strategic partner to revenue, finance, and accounting leaders by translating business questions into analytical problems and delivering impactful insights.
• Ad Hoc Reporting & Analysis: Execute timely and accurate reporting for ad hoc needs, internal audits, and executive reviews.
• Technology Enablement: Contribute to the advancement of analytics platforms and tools by supporting adoption of solutions such as Power BI, DBT, and Snowflake.
• Documentation & Testing: Maintain documentation for analytics solutions and ensure rigorous testing standards to preserve data integrity.
What You Bring
• Bachelor's degree in Accounting, Finance, Computer Science, Information Systems, or a related field
• 5+ years of experience in FP&A, data analytics or a similar analytical role, preferably supporting revenue, accounting, or finance teams
• Proficiency in SQL with demonstrated ability to write complex queries across large datasets. Python is a strong plus.
• Hands-on experience with Power BI and/or other dashboarding tools (e.g., Tableau, Looker, Sigma Computing)
• Exposure to enterprise data warehouses (Snowflake preferred), cloud ecosystems, and modern ELT tools (DBT)
• Understanding of ERP and CRM systems, particularly Microsoft Dynamics 365, RevStream, and Salesforce
• Familiarity with data pipeline integration and cross-functional system connectivity
• Demonstrated ability to work autonomously in a fast-paced, agile environment
• Strong communication skills and high contextual business acumen
• Ability to pull business requirements from SMEs and translate to technical requirements
• Passion for data quality, governance, and scalable design
• Python experience a strong plus
Benefits that Benefit You
• Competitive salary and 401k with employer match
• Discretionary paid time off
• Paid parental leave for all
• Medical, Dental, Vision plans
• Fitness Programs
• Emotional & Mental Wellness support
• Learning & Development programs
• And yes, we have snacks in our offices

Benefits listed herein may vary depending on the nature of your employment and the location where you work.

The Pay: Axon is a total compensation company, meaning compensation is made up of base pay, bonus, and stock awards. The starting base pay for this role is between USD 74,550 in the lowest geographic market and USD 119,280 in the highest geographic market. The actual base pay is dependent upon many factors, such as: level, function, training, transferable skills, work experience, business needs, geographic market, and often a combination of all these factors. Our benefits offer an array of options to help support you physically, financially and emotionally through the big milestones and in your everyday life. To see more details on our benefits offerings please visit www.axon.com/careers/benefits.

Don't meet every single requirement? That's ok. At Axon, we Aim Far. We think big with a long-term view because we want to reinvent the world to be a safer, better place. We are also committed to building diverse teams that reflect the communities we serve.

Studies have shown that women and people of color are less likely to apply to jobs unless they check every box in the job description. If you're excited about this role and our mission to Protect Life but your experience doesn't align perfectly with every qualification listed here, we encourage you to apply anyways. You may be just the right candidate for this or other roles.

Important Notes

The above job description is not intended as, nor should it be construed as, exhaustive of all duties, responsibilities, skills, efforts, or working conditions associated with this job. The job description may change or be supplemented at any time in accordance with business needs and conditions.

Some roles may also require legal eligibility to work in a firearms environment.

Axon's mission is to Protect Life and is committed to the well-being and safety of its employees as well as Axon's impact on the environment. All Axon employees must be aware of and committed to the appropriate environmental, health, and safety regulations, policies, and procedures. Axon employees are empowered to report safety concerns as they arise and activities potentially impacting the environment.

We are an equal opportunity employer that promotes justice, advances equity, values diversity and fosters inclusion. We're committed to hiring the best talent - regardless of race, creed, color, ancestry, religion, sex (including pregnancy), national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, genetic information, veteran status, or any other characteristic protected by applicable laws, regulations and ordinances - and empowering all of our employees so they can do their best work. If you have a disability or special need that requires assistance or accommodation during the application or the recruiting process, please email recruitingops@axon.com. Please note that this email address is for accommodation purposes only. Axon will not respond to inquiries for other purposes.#J-18808-Ljbffr",2025-07-22T00:00:00.000Z,2025-07-25,"[""Bachelor's degree in Accounting, Finance, Computer Science, Information Systems, or a related field"", '5+ years of experience in FP&A, data analytics or a similar analytical role, preferably supporting revenue, accounting, or finance teams', 'Proficiency in SQL with demonstrated ability to write complex queries across large datasets', 'Python is a strong plus', 'Hands-on experience with Power BI and/or other dashboarding tools (e.g., Tableau, Looker, Sigma Computing)', 'Understanding of ERP and CRM systems, particularly Microsoft Dynamics 365, RevStream, and Salesforce', 'Familiarity with data pipeline integration and cross-functional system connectivity', 'Demonstrated ability to work autonomously in a fast-paced, agile environment', 'Strong communication skills and high contextual business acumen', 'Ability to pull business requirements from SMEs and translate to technical requirements', 'Passion for data quality, governance, and scalable design', 'Python experience a strong plus', 'Some roles may also require legal eligibility to work in a firearms environment']","['As a Senior Analyst, Revenue Data Analytics at Axon and a member of the Revenue Transformation team you will support the Revenue Accounting org in advancing their reporting and analytics maturity by building scalable reporting solutions, enhancing data governance, and ensuring analytical insights are effectively used in strategic decision-making', ""You will partner cross-functionally with Accounting, Finance, Data Engineering, IT, and Business Intelligence teams to drive reporting excellence and elevate Axon's revenue analytics capabilities"", ""You will be expected to own key datasets, develop insightful reports and dashboards, and collaborate with stakeholders to define analytical needs and implement effective solutions tailored to the business's specifications"", 'Your work will fuel operational improvements, data-driven decisions, and help scale a high-performing finance and accounting ecosystem', 'Location: Hybrid at a US Hub Location (Scottsdale, Seattle, San Francisco, Denver, Sterling, Washington DC, Atlanta, Boston)', 'Reports to: Sr, Director Revenue Transformation', 'Revenue Analytics Development: Design, build, and maintain robust, user-friendly dashboards and reports to support revenue and accounting teams', 'Ensure outputs are actionable, scalable, and aligned with strategic goals', 'Data Governance: Partner with business stakeholders to implement and uphold data governance standards across key revenue data assets, contributing to data accuracy and consistency', 'Data Integration & Collaboration: Work closely with Data Engineering to define data pipelines, ensure seamless integration between source systems (Microsoft Dynamics 365, RevStream, Salesforce), and optimize end-to-end data workflows', 'Process Optimization: Support transformation initiatives by identifying bottlenecks, proposing enhancements, and contributing to continuous improvement efforts in revenue-related processes', 'Business Partnership: Serve as a strategic partner to revenue, finance, and accounting leaders by translating business questions into analytical problems and delivering impactful insights', 'Ad Hoc Reporting & Analysis: Execute timely and accurate reporting for ad hoc needs, internal audits, and executive reviews', 'Technology Enablement: Contribute to the advancement of analytics platforms and tools by supporting adoption of solutions such as Power BI, DBT, and Snowflake', 'Documentation & Testing: Maintain documentation for analytics solutions and ensure rigorous testing standards to preserve data integrity']",True,[],,"['SQL', 'Python', 'Power BI', 'Tableau', 'Looker', 'Sigma Computing', 'Snowflake', 'DBT (Data Build Tool)', 'Data Governance', 'Data Pipelines', 'ERP and CRM Systems', 'Reporting and Dashboards']","SQL: Used for writing complex queries across large datasets to support revenue and accounting analytics.; Python: Utilized as a programming language to enhance data analytics capabilities and support automation or advanced analysis.; Power BI: A dashboarding tool employed to design and maintain user-friendly reports and dashboards for revenue analytics.; Tableau: Mentioned as an alternative dashboarding tool for creating visual analytics to support business decisions.; Looker: Listed as a BI tool option for building reports and dashboards to analyze revenue data.; Sigma Computing: Included as a dashboarding tool to facilitate data visualization and reporting for revenue teams.; Snowflake: An enterprise data warehouse platform used to store and manage large revenue datasets for analytics.; DBT (Data Build Tool): A modern ELT tool used to build and manage data transformation pipelines supporting revenue data workflows.; Data Governance: Implemented to ensure data accuracy, consistency, and quality across key revenue data assets.; Data Pipelines: Defined and optimized to enable seamless integration and flow of revenue data between source systems and analytics platforms.; ERP and CRM Systems: Systems like Microsoft Dynamics 365, RevStream, and Salesforce are integrated as data sources for revenue analytics.; Reporting and Dashboards: Developed to provide actionable, scalable insights supporting strategic decision-making in revenue and accounting."
VDurN2eyRv7WzJG2AAAAAA==,Data Analyst Co-op,This job listing in Suffolk - MA has been recently added. Tallo will add a summary here for this job shortly.,,2025-07-25,,,False,[],,['Data Analysis'],"Data Analysis: The role involves analyzing data to support business decisions, which is fundamental to a data analyst position."
6ORuhMAMyhhWFGJ3AAAAAA==,Associate Data Analyst - Temp,"Are you passionate about data integrity and analysis? Join our dynamic team and help shape the future of reporting!

At FedPoint, we are looking for a Data Integrity Specialist to play a key role in maintaining accurate, insightful, and timely data reporting for our diverse range of stakeholders. This is an exciting opportunity to make an impact through your analytical skills and contribute to our business success.

About The Role

As a Data Integrity Specialist, you’ll be responsible for managing data collection processes and maintaining the accuracy of key performance metrics. You will work closely with business owners to resolve discrepancies, create reporting templates, perform trend analysis, and provide valuable insights that will guide decision-making at all levels of the organization.

You Will
• Administer data collection for recurring metrics and resolve any discrepancies with business owners.
• Create and update reporting templates, ensuring accuracy and consistency.
• Perform quality assurance checks to ensure data integrity and conduct trend analysis to identify insights.
• Draft business requirements and recommend improvements for data gathering and reporting processes.

Key Responsibilities:

Data integrity projects for reporting and metrics as assigned.

What We’re Looking For

Education and Experience:
• High school diploma or equivalent required; college or certificate course work in accounting, business, or related field preferred.
• 1+ years’ experience handling performance measurements such as Key Performance Indicators (KPI’s), and or other quality assurance measurements and calculations, including performing quality control audits and peer review.
• 1+ years’ experience performing data analysis, using data visualization to convey findings; experience narrating findings a plus.
• Exposure to gathering and writing business requirements preferred.
• Experience documenting procedures.
• Experience working in a project planning environment a plus; demonstrated ability to work toward specific milestones and meet deliverables.

Location: Portsmouth, NH - Hybrid Role

Schedule: Hybrid 2 days in the office, 3 days telework - Monday-Friday

Compensation: The typical starting salary would be between $23-$25/hr, based on qualifications and experience as it relates to our requirements. This position is eligible for an annual discretionary employee bonus plan based on company metric performance as well as a full suite of benefits, listed below.

About FedPoint

FedPoint creates and operates digital benefits marketplaces that make it easy for our millions of federal and military customers to understand, select, and use their benefits. A subsidiary of John Hancock Life & Health Insurance Company, FedPoint was founded in 2002 and is headquartered in Portsmouth, NH. To learn more, visit fedpointusa.com.

Why Join Us?",,2025-07-25,"['1+ years’ experience handling performance measurements such as Key Performance Indicators (KPI’s), and or other quality assurance measurements and calculations, including performing quality control audits and peer review', 'Experience documenting procedures']","['Join our dynamic team and help shape the future of reporting!', 'At FedPoint, we are looking for a Data Integrity Specialist to play a key role in maintaining accurate, insightful, and timely data reporting for our diverse range of stakeholders', 'As a Data Integrity Specialist, you’ll be responsible for managing data collection processes and maintaining the accuracy of key performance metrics', 'You will work closely with business owners to resolve discrepancies, create reporting templates, perform trend analysis, and provide valuable insights that will guide decision-making at all levels of the organization', 'Administer data collection for recurring metrics and resolve any discrepancies with business owners', 'Create and update reporting templates, ensuring accuracy and consistency', 'Perform quality assurance checks to ensure data integrity and conduct trend analysis to identify insights', 'Draft business requirements and recommend improvements for data gathering and reporting processes', 'Data integrity projects for reporting and metrics as assigned']",True,[],,"['Key Performance Indicators', 'Data Collection', 'Data Integrity', 'Trend Analysis', 'Reporting Templates', 'Quality Assurance', 'Business Requirements Documentation', 'Data Visualization']",Key Performance Indicators: Used to measure and monitor performance metrics critical for business reporting and decision-making.; Data Collection: Managing the process of gathering data for recurring metrics to ensure accurate and consistent reporting.; Data Integrity: Ensuring accuracy and consistency of data through quality assurance checks and resolving discrepancies.; Trend Analysis: Analyzing data trends to extract insights that inform business decisions.; Reporting Templates: Creating and updating standardized formats for presenting data and metrics clearly.; Quality Assurance: Performing audits and peer reviews to maintain high standards in data accuracy and reporting.; Business Requirements Documentation: Drafting and recommending improvements for data gathering and reporting processes based on stakeholder needs.; Data Visualization: Using visual tools to convey analytical findings effectively to stakeholders.
WpAHQdHE1-8aYJgAAAAAAA==,SENIOR HEALTH ECONOMICS ANALYST,"Senior Health Economics Analyst

Location: Remote

Supervisor/Reporting to: Director, Performance Reliability

Job Purpose: The Senior Health Economics Analyst is responsible for identifying and delivering data-driven insights and analytical support to senior leadership of IVIRMA North America. Success in the role will be achieved through the ability to leverage both qualitative and quantitative data to create business intelligence to guide strategic execution. This role serves to create and deliver reliable, insightful and actionable insight to improvements and opportunities for performance reliability – supporting our teammates in delivering a world-class patient experience.

Essential Functions and Accountabilities:
• Supports the design, development, and implementation of reporting to support data-driven decision making and insight. Partners with finance, commercial and business leaders to translate needs and requirements into dashboards and reporting with high utility.
• Assists in the design and evaluation of organizational KPIs for potential replacement or evolution as the organization grows.
• Prepares and analyzes medical cost and leading indicator data to develop presentations for executive and senior leadership. Interpret results and articulate actionable recommendations that maximize outcomes and ensures organizational targets are met.
• Tracks performance of key performance indicators for outlined regions and teams as requested.
• Supports finance, commercial and operations in the annual and multi-year planning processes including market durability
• Performs data validation to ensure completeness and accuracy of queries and reports and reconciles discrepancies.
• Participates in the maintenance of existing queries and reports, re-writing and enhancing these queries as needed.
• Participates in the presentation of complex concepts and results to end users and stakeholders

Academic Training:
• Bachelor’s degree in Computer Science, Information Services, or other technical or healthcare field – highly preferred
• Studies level: University Education (Bachelor’s Degree)
• Studies area: Computer Science/Engineering or other related field

Position Requirements/Experience:
• Experience working in medical/healthcare industry - preferred
• Knowledge of data collection, storage, and maintenance concepts - required
• Knowledge in predictive modeling - a plus
• Database organization, design, and maintenance skills.
• Ability to troubleshoot database programs

Technical Skills:
• Knowledge of PowerBI - required
• Knowledge of Microsoft Office Suite: Word, Excel (Pivot Tables/Look-Ups), Access, and OneNote – required
• Knowledge of Tableau - preferred

IVI-RMA offers a comprehensive benefits package to all employees who work a minimum of 30 hours per week.
• Medical, Dental, Vision Insurance Options
• Retirement 401K Plan
• Paid Time Off & Paid Holidays
• Company Paid: Life Insurance & Long-Term Disability & AD&D
• Flexible Spending Accounts
• Employee Assistance Program
• Tuition Reimbursement

About IVIRMA Global:

IVIRMA is the largest group in the world devoted exclusively to human Assisted Reproduction Technology. Along with the great privilege of providing fertility care to our patients, IVIRMA embraces the great responsibility of advancing the field of human reproduction. IVIRMA Innovation, as one of the pillars of IVIRMA Global, is a renowned leader in fertility research and science. Check out our websites at: https://rmanetwork.com/ & https://www.ivirma.com/

EEO

“IVIRMA is an Equal Opportunity Employer and Prohibits Discrimination and Harassment of Any Kind: IVIRMA is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at IVIRMA are based on business needs, job requirements and individual qualifications, without regard to race, color, religion and/or belief, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. IVIRMA will not tolerate discrimination or harassment based on any of these characteristics. IVIRMA encourages applicants of all ages.”",2025-07-03T00:00:00.000Z,2025-07-25,"['Studies level: University Education (Bachelor’s Degree)', 'Studies area: Computer Science/Engineering or other related field', 'Knowledge of data collection, storage, and maintenance concepts - required', 'Database organization, design, and maintenance skills', 'Ability to troubleshoot database programs', 'Knowledge of PowerBI - required', 'Knowledge of Microsoft Office Suite: Word, Excel (Pivot Tables/Look-Ups), Access, and OneNote – required']","['Supervisor/Reporting to: Director, Performance Reliability', 'Job Purpose: The Senior Health Economics Analyst is responsible for identifying and delivering data-driven insights and analytical support to senior leadership of IVIRMA North America', 'Success in the role will be achieved through the ability to leverage both qualitative and quantitative data to create business intelligence to guide strategic execution', 'This role serves to create and deliver reliable, insightful and actionable insight to improvements and opportunities for performance reliability – supporting our teammates in delivering a world-class patient experience', 'Supports the design, development, and implementation of reporting to support data-driven decision making and insight', 'Partners with finance, commercial and business leaders to translate needs and requirements into dashboards and reporting with high utility', 'Assists in the design and evaluation of organizational KPIs for potential replacement or evolution as the organization grows', 'Prepares and analyzes medical cost and leading indicator data to develop presentations for executive and senior leadership', 'Interpret results and articulate actionable recommendations that maximize outcomes and ensures organizational targets are met', 'Tracks performance of key performance indicators for outlined regions and teams as requested', 'Supports finance, commercial and operations in the annual and multi-year planning processes including market durability', 'Performs data validation to ensure completeness and accuracy of queries and reports and reconciles discrepancies', 'Participates in the maintenance of existing queries and reports, re-writing and enhancing these queries as needed', 'Participates in the presentation of complex concepts and results to end users and stakeholders']",True,[],,"['Business Intelligence', 'Key Performance Indicators', 'Data Validation', 'Data Reporting and Dashboards', 'Predictive Modeling', 'Database Design and Maintenance', 'Power BI', 'Tableau', 'Microsoft Excel (Pivot Tables and Look-Ups)']","Business Intelligence: Used to create actionable insights and guide strategic execution through data-driven decision making.; Key Performance Indicators: Designed and evaluated to measure organizational performance and support decision making.; Data Validation: Performed to ensure completeness and accuracy of queries and reports.; Data Reporting and Dashboards: Developed and implemented to translate business needs into high-utility visualizations and reports.; Predictive Modeling: Applied as a plus skill to analyze medical cost and leading indicator data for forecasting outcomes.; Database Design and Maintenance: Involved in organizing, designing, maintaining, and troubleshooting database programs.; Power BI: Used as a primary tool for creating dashboards and reports to support data-driven insights.; Tableau: Preferred tool for data visualization and reporting.; Microsoft Excel (Pivot Tables and Look-Ups): Utilized for data analysis and manipulation to support reporting and insights."
M0w2cQAtRxfPuuXsAAAAAA==,Data Analytics Consulting Staff (Finance & Accounting),"**Data Analytics Consulting Staff \(Finance & Accounting\)**
• *Description**

At Moss Adams, we champion authenticity. For us, that means fostering a culture of talented people who care-about you, about our clients, and about our communities. Here, you'll work towards our mission of empowering others to embrace opportunity, growing as a leader along the way. Our firm's size, middle-market clients, customized career paths, and supportive culture make this a reality. Join a values-driven firm where you'll have fun while solving complex and interesting business challenges.

As a member of the Data Analytics Consulting Staff at Moss Adams, your primary role will be to analyze data to identify actionable insights that support our clients' business objectives. You will collaborate with other team members to develop and implement data-driven solutions that enhance operational efficiency and provide strategic business insights. Your responsibilities will include interpreting complex datasets, recommending process improvements, and contributing to the enhancement of our analytics infrastructure. The success of this position is measured by your ability to effectively support decision-making processes, improve client satisfaction through accurate data analysis, and the tangible improvements seen in client operations.

Individuals who thrive at Moss Adams exhibit the following success skills - Collaboration, Critical Thinking, Emotional Intelligence, Executive Presence, Growth Mindset, Intellectual Curiosity, and Results Focus.
• *Responsibilities:**

+ Collaborate with Moss Adams cross-functional teams and clients to gather business requirements and develop tailored analytics strategies

+ Analyze data, processes, and technologies to identify operational inefficiencies and critical business challenges

+ Design and implement data-driven solutions to enhance business processes and improve decision-making

+ May perform other consulting activities that include conducting interviews, reviewing documents, performing a variety of analysis, and preparing client deliverables such as findings, recommendations, and draft and final reports

+ Create and present insights through dashboards, reports, and data visualizations to communicate findings and drive action

+ Evaluate and refine data collection methods and tools to ensure high-quality data inputs for analysis
• *Qualifications:**

+ Bachelor's degree required; emphasis in Accounting or Finance, Business or related fields preferred. Technology course work is also desired

+ Ability to adapt to a changing work environment, including the use of software systems and technology

+ Experience in Accounting or Finance preferred

+ Proven commitment to providing exceptional client service

+ Ability to think critically, identify creative solutions and provide research or other information in a well organized and logical fashion

+ Strong verbal and written communication skills

+ Ability to collaborate and work effectively across functions/departments/teams while building trusted relationships and positively influencing others

+ Self-directed professional with strong interpersonal skills

+ Executes effectively by using resources efficiently; meeting deadlines and keeping others informed of work plans and progress toward goals

+ Proficiency in Microsoft Office \(Word, Excel, PowerPoint, Outlook, and SharePoint\), experience with Tableau, Power BI, and/or Alteryx highly desirable

+ Ability to work overtime and travel as needed, approximately 5%

- - -
• *Moss Adams is an Equal Opportunity Employer as to all protected groups, including protected veterans and individuals with disabilities.**
• *Moss Adams complies with federal and state disability laws and makes reasonable accommodations for applicants and employees with disabilities. If reasonable accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment, please contact** **careers@mossadams.com** **.**
• *Certain jurisdictions in the United States require employers to disclose the pay range in job postings. This is the typical range of pay for the position. Actual compensation may depend on factors such as qualifications, work experience, skills, and geographic location. This position may be eligible for an annual discretionary bonus. For more information about our benefit offerings and other total rewards, visit our** **careers** **page.**

\#LI-MD1
• *Compensation Range \(Denver Market ONLY\):** Washington State: $84,000 - $105,000, California State: $90,000-$108,000, Colorado State: $80,000 - $105,000
• *Primary Location** Seattle, WA
• *Other Locations** Napa, CA, Pasadena, CA, Woodland Hills, CA, San Diego, CA, Bellingham, WA, Denver, CO, Walnut Creek, CA, El Segundo, CA, San Francisco, CA, Everett, WA, Phoenix, AZ, Healdsburg, CA, Tri-Cities, WA, Santa Rosa, CA, Albuquerque, NM, Salinas, CA, Salt Lake City, UT, Spokane, WA, Orange County, CA, Eugene, OR, Tacoma, WA, Wenatchee, WA, Medford, OR, Dallas, TX, Yakima, WA, Stockton, CA, Silicon Valley, CA, Sacramento, CA, Portland, OR, Fresno, CA, Houston, TX
• *Employee Status:** Regular
• *Schedule:** Full Time
• *Req ID:** 28200",2025-07-18T00:00:00.000Z,2025-07-25,"['Individuals who thrive at Moss Adams exhibit the following success skills - Collaboration, Critical Thinking, Emotional Intelligence, Executive Presence, Growth Mindset, Intellectual Curiosity, and Results Focus', '*Certain jurisdictions in the United States require employers to disclose the pay range in job postings']","[""As a member of the Data Analytics Consulting Staff at Moss Adams, your primary role will be to analyze data to identify actionable insights that support our clients' business objectives"", 'You will collaborate with other team members to develop and implement data-driven solutions that enhance operational efficiency and provide strategic business insights', 'Your responsibilities will include interpreting complex datasets, recommending process improvements, and contributing to the enhancement of our analytics infrastructure', 'The success of this position is measured by your ability to effectively support decision-making processes, improve client satisfaction through accurate data analysis, and the tangible improvements seen in client operations', 'Collaborate with Moss Adams cross-functional teams and clients to gather business requirements and develop tailored analytics strategies', 'Analyze data, processes, and technologies to identify operational inefficiencies and critical business challenges', 'Design and implement data-driven solutions to enhance business processes and improve decision-making', 'May perform other consulting activities that include conducting interviews, reviewing documents, performing a variety of analysis, and preparing client deliverables such as findings, recommendations, and draft and final reports', 'Create and present insights through dashboards, reports, and data visualizations to communicate findings and drive action', 'Evaluate and refine data collection methods and tools to ensure high-quality data inputs for analysis']",True,[],,"['Data Analysis', 'Data-Driven Solutions', 'Data Visualization', 'Analytics Infrastructure', 'Business Intelligence Tools', 'Data Collection Methods', 'Microsoft Excel', 'Alteryx']","Data Analysis: Analyzing data to identify actionable insights that support clients' business objectives and improve decision-making.; Data-Driven Solutions: Developing and implementing solutions based on data to enhance operational efficiency and business processes.; Data Visualization: Creating and presenting insights through dashboards and reports to communicate findings and drive action.; Analytics Infrastructure: Contributing to the enhancement of systems and tools that support data analytics within client operations.; Business Intelligence Tools: Using tools such as Tableau and Power BI to create dashboards and reports for data visualization and business insights.; Data Collection Methods: Evaluating and refining methods and tools to ensure high-quality data inputs for analysis.; Microsoft Excel: Utilizing Excel for data manipulation, analysis, and reporting as part of the analytics workflow.; Alteryx: Employing Alteryx for data preparation, blending, and advanced analytics to support consulting activities."
sfm1iZKL7DgOl0eoAAAAAA==,Data Analyst,"Location: Water Mill
About

The Role

Grade Level (for internal use):

09

Job Description Summary

Business Intelligence Analysts within the automotive

Mastermind (aM) Product Insights team play a critical role in measuring the effects of aM in the market, communicating the value each product within the portfolio delivers, and identifying opportunities to strengthen the products and the processes by which they are created.

a Successful Business Intelligence Analyst Will
• Rigorous identification, analysis, and interpretation of trends or patterns in complex data sets
• Application of deep, creative, rigorous thinking to solve broad, platform-wide technical and/or business problems
• Design and develop management reports and supporting ad hoc analyses answering key questions such as… Is the product performance aligned with the sales pitch? Are key product components delivering value? Is marketing outreach effective? Are results consistent across clients?
• Identify key value drivers and key opportunities for/sources of error across products and processes
• Create client-facing visualizations to clearly articulate the aM value proposition and identify business opportunities for internal and external stakeholders
• Develop short-term preventive or detective measures, and leading medium/long-term product improvement initiatives arrived at via close collaboration with data transformation, engineering, QA, and production support team members
• Support and inform account leads with respect to client and regional sales mix, performance, and aM contributions
• Communicate clearly across business stakeholders as well as analytics customers
• Identify and access additional data assets that could be leveraged to answer a given business problem
• Coordinate with data engineers as appropriate to design and enable repeatable processes and generate deliverables to answer routine business questions

Minimum Requirements
• 3+ years of professional/internship experience as a Data Analyst or Business Intelligence Analyst in a similar analytical + technical role
• Familiarity with application of statistics and experience using statistical packages for analyzing large datasets (Excel, R, SPSS, SAS)
• Familiarity with visualization software packages (Data Studio, Tableau, Power

BI)
• Awareness of reporting packages (Business Objects), databases (SQL), programming (XML, Java script, or ETL frameworks)
• Strong analytical and problem-solving skills
• Ability to think quickly on your feet and handle ambiguity
• Excellent written and verbal communication skills
• Ability to execute against multiple projects as part of a team or independently, while managing competing deadlines
• Automotive experience a plus
• Regularly assess your own performance and adapt your work to achieve better results
• Continually look to improve your professional career, as well as strive for personal growth
Compensation/Benefits Information (US Applicants Only)
• S&P Global states that the anticipated base salary range for this position is $59,212 to $103,897. Final base salary for this role will be based on the individual’s geographical location as well as experience and qualifications for the role.
• In addition to base compensation, this role is eligible for an annual incentive plan.
• This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit link
About Automotive Mastermind

Who we are:

Founded in 2012, automotive

Mastermind is a leading provider of predictive analytics and marketing automation solutions for the automotive industry and believes that technology can transform data, revealing key customer insights to accurately predict automotive sales. Through its proprietary automated sales and marketing platform, Mastermind, the company empowers dealers to close more deals by predicting future buyers and consistently marketing to them. automotive

Mastermind is headquartered in New York City. For more information, visit

At automotive

Mastermind, we thrive on high energy at high speed. We’re an organization in hyper-growth mode and have a fast-paced culture to match. Our highly engaged teams feel passionately about both our product and our people. This passion is what…",2025-07-21T00:00:00.000Z,2025-07-25,"['Rigorous identification, analysis, and interpretation of trends or patterns in complex data sets', 'Application of deep, creative, rigorous thinking to solve broad, platform-wide technical and/or business problems', '3+ years of professional/internship experience as a Data Analyst or Business Intelligence Analyst in a similar analytical + technical role', 'Familiarity with application of statistics and experience using statistical packages for analyzing large datasets (Excel, R, SPSS, SAS)', 'Familiarity with visualization software packages (Data Studio, Tableau, Power', 'BI)', 'Awareness of reporting packages (Business Objects), databases (SQL), programming (XML, Java script, or ETL frameworks)', 'Strong analytical and problem-solving skills', 'Ability to think quickly on your feet and handle ambiguity', 'Excellent written and verbal communication skills', 'Ability to execute against multiple projects as part of a team or independently, while managing competing deadlines']","['Mastermind (aM) Product Insights team play a critical role in measuring the effects of aM in the market, communicating the value each product within the portfolio delivers, and identifying opportunities to strengthen the products and the processes by which they are created', 'a Successful Business Intelligence Analyst Will', 'Design and develop management reports and supporting ad hoc analyses answering key questions such as…', 'Is the product performance aligned with the sales pitch?', 'Identify key value drivers and key opportunities for/sources of error across products and processes', 'Create client-facing visualizations to clearly articulate the aM value proposition and identify business opportunities for internal and external stakeholders', 'Develop short-term preventive or detective measures, and leading medium/long-term product improvement initiatives arrived at via close collaboration with data transformation, engineering, QA, and production support team members', 'Support and inform account leads with respect to client and regional sales mix, performance, and aM contributions', 'Communicate clearly across business stakeholders as well as analytics customers', 'Identify and access additional data assets that could be leveraged to answer a given business problem', 'Coordinate with data engineers as appropriate to design and enable repeatable processes and generate deliverables to answer routine business questions']",True,[],,"['Statistical Analysis', 'Data Visualization', 'SQL', 'ETL Frameworks', 'Business Intelligence Reporting', 'Statistical Software Packages', 'Programming for Data Analysis', 'Trend and Pattern Analysis']","Statistical Analysis: Used for analyzing large datasets to identify trends and patterns, supporting business insights and decision-making.; Data Visualization: Creating client-facing visualizations with tools like Tableau, Power BI, and Data Studio to communicate product value and business opportunities.; SQL: Utilized for querying and managing databases to extract and manipulate data for analysis and reporting.; ETL Frameworks: Employed to design repeatable data transformation and loading processes in collaboration with data engineers.; Business Intelligence Reporting: Developing management reports and ad hoc analyses using reporting packages such as Business Objects to answer key business questions.; Statistical Software Packages: Experience with tools like R, SPSS, SAS, and Excel for performing rigorous statistical computations and data analysis.; Programming for Data Analysis: Using programming languages such as JavaScript and XML to support data processing and reporting tasks.; Trend and Pattern Analysis: Identifying and interpreting trends or patterns in complex data sets to inform product and marketing strategies."
fmvkHmSbbWlPSRxiAAAAAA==,Principal Engineer Data Analytics,"Location(s):

United States of America

City/Cities:

Atlanta

Travel Required:

Relocation Provided:

Job Posting End Date:

September 16, 2024

Shift:

Job Description Summary:

General Summary:

We are looking for a highly skilled and experienced Principal Data Engineer to architect and lead the development of our data infrastructure. The successful candidate will possess deep technical expertise in data engineering and will be responsible for designing, building, and managing large-scale data processing systems, ensuring their scalability, reliability, and performance. This role will work closely with data engineering teams, product leads, and business stakeholders in support of Coca-Cola’s North America Operating Unit.

Key Responsibilities:
• Data Pipeline Development:
• Design, develop, and maintain scalable and efficient data pipelines using Azure Data Factory, Azure Synapse, PySpark, and other Azure services that support complex data transformations and large-scale processing.
• Implement ETL/ELT processes to ingest, transform, and load data from various sources into Azure data storage solutions (e.g., Azure Blob Storage, Azure Data Lake, Azure SQL Database)
• Implement and maintain data management frameworks, ensuring data quality, consistency, and security.
• Data Modeling and Warehousing:
• Develop and maintain data models, schemas, and data warehouses to support business intelligence and analytics needs.
• Optimize data storage and retrieval strategies to enhance performance and scalability. Collaboration and Leadership
• Data Integration:
• Integrate data from multiple sources, including on-premises databases, cloud services, APIs, and third-party systems.
• Ensure data quality, consistency, and reliability across all data sources.
• Collaboration and Support:
• Collaborate with cross-functional teams including data scientists, analysts, and business stakeholders to understand data requirements and deliver efficient solutions.
• Troubleshoot and resolve performance bottlenecks and other technical issues related to data infrastructure.
• Mentor and guide junior data engineers, providing technical leadership and fostering a culture of continuous improvement and innovation.
• Automation and Optimization:
• Automate repetitive tasks and processes to improve efficiency and reduce manual intervention.
• Continuously monitor and optimize data pipelines for performance and cost-effectiveness.

Qualifications:
• Bachelor’s degree in Computer Science, Engineering, Information Technology, or 10+ year’s experience in the data engineering field
• Minimum of 8+ years of experience in data engineering or a related role, with a proven track record of working on large-scale data projects.
• Strong expertise in Python and SQL
• Proven experience with Azure and its data warehousing (Synapse, Redshift) and big data technologies (e.g., Spark)
• Proven experience in designing and building scalable data pipelines and data warehouses.
• Deep understanding of database theory, data modeling, and ETL/ELT processes
• Demonstrated ability to work in a fast-paced environment, managing multiple projects and deadlines.
• Excellent problem-solving skills, attention to detail, and ability to think critically and analytically.

Strong communication skills, with the ability to effectively convey complex technical concepts to non-technical stakeholders.

Preferred Qualifications:
• Azure Data Engineer certifications (e.g., Microsoft Certified: Azure Data Engineer Associate).
• Experience with DevOps practices and tools, including CI/CD pipelines, version control, and infrastructure as code (e.g., GitHub Actions, Azure DevOps, Terraform).
• Experience developing in the Power Platform, specifically Power BI and Power Apps
• Additional experience in programming languages Scala, Java, Node.js
• Additional experience in AWS Data Lake technologies, such as AWS Redshift and AWS Glue
• Experience in the consumer packaged goods industry
• Experience with machine learning and AI-driven data processing techniques.

Skills:

Pay Range:

$159,300 - $184,700

Base pay offered may vary depending on geography, job-related knowledge, skills, and experience. A full range of medical, financial, and/or other benefits, dependent on the position, is offered.

Annual Incentive Reference Value Percentage:

30

Annual Incentive reference value is a market-based competitive value for your role. It falls in the middle of the range for your role, indicating performance at target.

Our Purpose and Growth Culture:

We are taking deliberate action to nurture an inclusive culture that is grounded in our company purpose, to refresh the world and make a difference. We act with a growth mindset, take an expansive approach to what’s possible and believe in continuous learning to improve our business and ourselves. We focus on four key behaviors – curious, empowered, inclusive and agile – and value how we work as much as what we achieve. We believe that our culture is one of the reasons our company continues to thrive after 130+ years. Visit Our Purpose and Vision to learn more about these behaviors and how you can bring them to life in your next role at Coca-Cola.

We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity and/or expression, status as a veteran, and basis of disability or any other federal, state or local protected class. When we collect your personal information as part of a job application or offer of employment, we do so in accordance with industry standards and best practices and in compliance with applicable privacy laws.",,2025-07-25,"['The successful candidate will possess deep technical expertise in data engineering and will be responsible for designing, building, and managing large-scale data processing systems, ensuring their scalability, reliability, and performance', 'Bachelor’s degree in Computer Science, Engineering, Information Technology, or 10+ year’s experience in the data engineering field', 'Minimum of 8+ years of experience in data engineering or a related role, with a proven track record of working on large-scale data projects', 'Strong expertise in Python and SQL', 'Proven experience with Azure and its data warehousing (Synapse, Redshift) and big data technologies (e.g., Spark)', 'Proven experience in designing and building scalable data pipelines and data warehouses', 'Deep understanding of database theory, data modeling, and ETL/ELT processes', 'Demonstrated ability to work in a fast-paced environment, managing multiple projects and deadlines', 'Excellent problem-solving skills, attention to detail, and ability to think critically and analytically', 'Strong communication skills, with the ability to effectively convey complex technical concepts to non-technical stakeholders']","['This role will work closely with data engineering teams, product leads, and business stakeholders in support of Coca-Cola’s North America Operating Unit', 'Data Pipeline Development:', 'Design, develop, and maintain scalable and efficient data pipelines using Azure Data Factory, Azure Synapse, PySpark, and other Azure services that support complex data transformations and large-scale processing', 'Implement ETL/ELT processes to ingest, transform, and load data from various sources into Azure data storage solutions (e.g., Azure Blob Storage, Azure Data Lake, Azure SQL Database)', 'Implement and maintain data management frameworks, ensuring data quality, consistency, and security', 'Data Modeling and Warehousing:', 'Develop and maintain data models, schemas, and data warehouses to support business intelligence and analytics needs', 'Optimize data storage and retrieval strategies to enhance performance and scalability', 'Integrate data from multiple sources, including on-premises databases, cloud services, APIs, and third-party systems', 'Ensure data quality, consistency, and reliability across all data sources', 'Collaboration and Support:', 'Collaborate with cross-functional teams including data scientists, analysts, and business stakeholders to understand data requirements and deliver efficient solutions', 'Troubleshoot and resolve performance bottlenecks and other technical issues related to data infrastructure', 'Mentor and guide junior data engineers, providing technical leadership and fostering a culture of continuous improvement and innovation', 'Automation and Optimization:', 'Automate repetitive tasks and processes to improve efficiency and reduce manual intervention', 'Continuously monitor and optimize data pipelines for performance and cost-effectiveness']",False,[],,"['Data Pipeline Development', 'ETL/ELT Processes', 'Azure Data Storage Solutions', 'Data Modeling and Warehousing', 'Data Integration', 'Python', 'SQL', 'Apache Spark', 'Data Quality and Management Frameworks', 'Business Intelligence Tools', 'DevOps and Automation', 'Cloud Data Warehousing']","Data Pipeline Development: Designing and maintaining scalable data pipelines using Azure Data Factory, Azure Synapse, and PySpark to support large-scale data processing and transformations.; ETL/ELT Processes: Implementing extract, transform, and load processes to ingest and transform data from various sources into Azure data storage solutions.; Azure Data Storage Solutions: Utilizing Azure Blob Storage, Azure Data Lake, and Azure SQL Database for storing and managing large volumes of data.; Data Modeling and Warehousing: Developing and maintaining data models, schemas, and data warehouses to support business intelligence and analytics.; Data Integration: Integrating data from multiple sources including on-premises databases, cloud services, APIs, and third-party systems to ensure data consistency and reliability.; Python: Using Python programming language for data engineering tasks including pipeline development and automation.; SQL: Employing SQL for querying, managing, and optimizing data within relational databases.; Apache Spark: Leveraging Spark for big data processing and scalable data transformations within the Azure ecosystem.; Data Quality and Management Frameworks: Implementing frameworks to ensure data quality, consistency, security, and reliability across data systems.; Business Intelligence Tools: Supporting analytics needs through data warehousing and collaboration with BI tools like Power BI.; DevOps and Automation: Applying DevOps practices including CI/CD pipelines and automation to optimize data pipeline performance and reduce manual tasks.; Cloud Data Warehousing: Experience with cloud-based data warehousing technologies such as Azure Synapse and AWS Redshift for scalable data storage and analytics."
GhDl-jKIqt_ZEoiUAAAAAA==,Business Operations Analyst,"About us
• At Sierra, we’re creating a platform to help businesses build better, more human customer experiences with AI. We are primarily an in-person company based in San Francisco, with growing offices in Atlanta, New York, and London.
• We are guided by a set of values that are at the core of our actions and define our culture: Trust, Customer Obsession, Craftsmanship, Intensity, and Family. These values are the foundation of our work, and we are committed to upholding them in everything we do.
• Our co-founders are Bret Taylor and Clay Bavor. Bret currently serves as Board Chair of OpenAI. Previously, he was co-CEO of Salesforce (which had acquired the company he founded, Quip) and CTO of Facebook. Bret was also one of Google's earliest product managers and co-creator of Google Maps. Before founding Sierra, Clay spent 18 years at Google, where he most recently led Google Labs. Earlier, he started and led Google’s AR/VR effort, Project Starline, and Google Lens. Before that, Clay led the product and design teams for Google Workspace.

What you’ll do
• Master Sierra’s daily operations, identify inefficiencies and improve our capabilities by optimizing existing processes and introducing new ones
• Drive end-to-end strategic projects such as building business cases and execution plans for new markets, performing financial and data analysis on product performance, and developing frameworks for annual planning
• Act as a thought partner to leaders across the company to improve business planning, performance & execution
• Coordinate with Sales, Marketing, Product, and Engineering teams to ensure seamless execution of cross-functional projects
• Wear many hats! In this unique role, you’ll have the opportunity to define your future by gaining broad exposure to all aspects of Sierra’s operations

What you’ll bring
• 2-4 years of experience in management consulting, corporate strategy, or business operations
• Proficiency in data analysis tools (e.g., Excel, Google Sheets) and experience with data visualization tools (e.g., Tableau, Looker, or Power BI)
• A detail-oriented, methodical, and process-driven mentality that is focused on both accuracy and efficiency
• Demonstrated ability to manage multiple projects, prioritize effectively, and meet deadlines
• A proactive mindset with the ability to navigate ambiguity, drive and execute initiatives, and deliver results in a fast-paced, dynamic environment
• Strong written and verbal communication skills, with the ability to distill complex ideas and problems into straightforward, actionable recommendations, especially to executives

Even better…
• SQL experience
• Familiarity with CRM platforms (e.g., Salesforce, HubSpot) and marketing automation tools
• Previous 0-1 startup or operational experience

Our values
• Trust: We build trust with our customers with our accountability, empathy, quality, and responsiveness. We build trust in AI by making it more accessible, safe, and useful. We build trust with each other by showing up for each other professionally and personally, creating an environment that enables all of us to do our best work.
• Customer Obsession: We deeply understand our customers’ business goals and relentlessly focus on driving outcomes, not just technical milestones. Everyone at the company knows and spends time with our customers. When our customer is having an issue, we drop everything and fix it.
• Craftsmanship: We get the details right, from the words on the page to the system architecture. We have good taste. When we notice something isn’t right, we take the time to fix it. We are proud of the products we produce. We continuously self-reflect to continuously self-improve.
• Intensity: We know we don’t have the luxury of patience. We play to win. We care about our product being the best, and when it isn’t, we fix it. When we fail, we talk about it openly and without blame so we succeed the next time.
• Family: We know that balance and intensity are compatible, and we model it in our actions and processes. We are the best technology company for parents. We support and respect each other and celebrate each other’s personal and professional achievements.

What we offer

We want our benefits to reflect our values and offer the following to full-time employees:
• Flexible (Unlimited) Paid Time Off
• Medical, Dental, and Vision benefits for you and your family
• Life Insurance and Disability Benefits
• Retirement Plan (e.g., 401K, pension) with Sierra match
• Parental Leave
• Fertility and family building benefits through Carrot
• Lunch, as well as delicious snacks and coffee to keep you energized
• Discretionary Benefit Stipend giving people the ability to spend where it matters most
• Free alphorn lessons

These benefits are further detailed in Sierra's policies and are subject to change at any time, consistent with the terms of any applicable compensation or benefits plans. Eligible full-time employees can participate in Sierra's equity plans subject to the terms of the applicable plans and policies.
Be you, with us

We're working to bring the transformative power of AI to every organization in the world. To do so, it is important to us that the diversity of our employees represents the diversity of our customers. We believe that our work and culture are better when we encourage, support, and respect different skills and experiences represented within our team. We encourage you to apply even if your experience doesn't precisely match the job description. We strive to evaluate all applicants consistently without regard to race, color, religion, gender, national origin, age, disability, veteran status, pregnancy, gender expression or identity, sexual orientation, citizenship, or any other legally protected class.",,2025-07-25,"['2-4 years of experience in management consulting, corporate strategy, or business operations', 'Proficiency in data analysis tools (e.g., Excel, Google Sheets) and experience with data visualization tools (e.g., Tableau, Looker, or Power BI)', 'A detail-oriented, methodical, and process-driven mentality that is focused on both accuracy and efficiency', 'Demonstrated ability to manage multiple projects, prioritize effectively, and meet deadlines', 'A proactive mindset with the ability to navigate ambiguity, drive and execute initiatives, and deliver results in a fast-paced, dynamic environment', 'Strong written and verbal communication skills, with the ability to distill complex ideas and problems into straightforward, actionable recommendations, especially to executives', 'SQL experience', 'Familiarity with CRM platforms (e.g., Salesforce, HubSpot) and marketing automation tools', 'Previous 0-1 startup or operational experience']","['Master Sierra’s daily operations, identify inefficiencies and improve our capabilities by optimizing existing processes and introducing new ones', 'Drive end-to-end strategic projects such as building business cases and execution plans for new markets, performing financial and data analysis on product performance, and developing frameworks for annual planning', 'Act as a thought partner to leaders across the company to improve business planning, performance & execution', 'Coordinate with Sales, Marketing, Product, and Engineering teams to ensure seamless execution of cross-functional projects', 'Wear many hats!', 'In this unique role, you’ll have the opportunity to define your future by gaining broad exposure to all aspects of Sierra’s operations', 'When our customer is having an issue, we drop everything and fix it', 'Craftsmanship: We get the details right, from the words on the page to the system architecture']",False,[],,"['Data Analysis', 'Data Visualization Tools', 'SQL', 'Excel and Google Sheets', 'CRM Platforms']","Data Analysis: Used to perform financial and product performance analysis to inform business decisions and strategic planning.; Data Visualization Tools: Experience with Tableau, Looker, or Power BI to create dashboards and visual reports for business insights and executive communication.; SQL: Utilized for querying and managing data to support analysis and reporting tasks.; Excel and Google Sheets: Proficiency in spreadsheet tools for data manipulation, analysis, and operational reporting.; CRM Platforms: Familiarity with Salesforce and HubSpot to manage customer data and support marketing automation."
q_9ag-oDqGFEDnYmAAAAAA==,"Senior Financial Data Analyst - Strategy & Project Management at HEALTH CONNECT AMERICA, INC Franklin, TN","Senior Financial Data Analyst - Strategy & Project Management job at HEALTH CONNECT AMERICA, INC. Franklin, TN. Overview:

Join Our Impactful Team at Health Connect America!

Before you get started on your journey with Health Connect America , take some time to learn more about us. Health Connect America and its affiliate brands are leaders in providing mental and behavioral health services to children, families, and adults across the nation. We provide our services directly to those in need whether that be within a person's home, their community, or in one of our office settings. HCA is honored to be a part of the communities we serve and the clients we walk alongside as they embark on a journey to self-improvement and more fulfilling lives. At Health Connect America , we are dedicated to making meaningful connections every day through creating quality, affordable opportunities for individuals and families to achieve their greatest potential in a safe, positive living environment.

Come make a difference and grow with us!

Our Brands

Responsibilities:

The Senior Financial Strategy Analyst focusing on Project Management and Data Analytics , reporting to the Vice President of Strategy & Platform Development, will support M&A, key strategic initiatives and financial initiatives within the company. This position will require someone to work in a hybrid capacity (partially remote and partially in the office in Franklin, TN) . This position will provide effective project management and financial strategy coordination across all company departments. This position will use a combination of tools, techniques, and technologies to generate, analyze, report, and interpret moderately complex data used across the organization. This work will support Health Connect America’s future growth plans and will receive executive level attention and exposure.

Essential Duties & Responsibilities:
• Facilitate meetings to ensure focused planning and coordination between teams working on company strategic initiatives
• Develop financial models through benchmarking and process analysis for both M&A and Organic Expansion opportunities
• Assist leadership to produce and monitor key performance indicators to measure and improve team performance
• Complete special projects and initiatives with skillful oversight and support
• Conduct thorough research of historical financial data including analysis on organic growth initiatives
• Coordinate with the Chief Financial Officer (CFO) and the executive team on long-term financial planning
• Assist VP of Strategy & Platform Development to create in-depth investment memorandums and related presentations for review by senior management, private equity sponsors, and other third-party advisors as required
• Assist in creating/executing diligence and integration plans for successful deal execution
• Maintain confidentiality of financial information and investment decisions
• Perform other duties as assigned to support operations and mission of the Company
Qualifications:
• Preferred Education and Experience Credentials:
• CPA
• MBA
• 5-7 years of Accounting/Financial Analysis experience
• Experience in multi-state healthcare organizations
• Preferred Knowledge, Skills, and Abilities:
• Microsoft Programs: Excel, PowerPoint, Outlook, Prophix
• Data Analytics: Alteryx and PowerBI
• Financial Valuation and Modeling

Be Well with HCA:
• We recognize the importance of self-care and work/life balance.
• We offer flexibility in scheduling and provide all employees access to our Employee Assistance Program (EAP), which includes 8 mental health counseling sessions annually.
• Full-time HCA employees enjoy paid time off, paid holidays, and a comprehensive benefits package that includes medical, dental, vision, and other voluntary insurance products.
• Additional benefits include:
• Access to a Health Navigator
• Health Savings Account with company contribution
• Dependent Daycare Flexible Spending Account
• Health Reimbursement Account
• 401(k) Retirement Plan
• Benefits Hub
• Tickets at Work

Join a team where your contributions truly make a difference in the lives of others. Apply now to be part of our dynamic and supportive community at Health Connect America!

Employment at Health Connect America and it's companies is contingent upon meeting the requirements of a comprehensive background investigation prior to joining our team.

Health Connect America and its companies are an Equal Opportunity Employer and consider applicants for employment without regard to race, color, religion, sex, orientation, national origin, age, disability, genetics, or any other basis forbidden under federal, state, or local law. For more information on Equal Opportunity, please click here",2025-07-25T00:00:00.000Z,2025-07-25,"['CPA', 'MBA', '5-7 years of Accounting/Financial Analysis experience', 'Experience in multi-state healthcare organizations', 'Microsoft Programs: Excel, PowerPoint, Outlook, Prophix', 'Data Analytics: Alteryx and PowerBI', 'Financial Valuation and Modeling', 'We recognize the importance of self-care and work/life balance']","['The Senior Financial Strategy Analyst focusing on Project Management and Data Analytics , reporting to the Vice President of Strategy & Platform Development, will support M&A, key strategic initiatives and financial initiatives within the company', 'This position will require someone to work in a hybrid capacity (partially remote and partially in the office in Franklin, TN) ', 'This position will provide effective project management and financial strategy coordination across all company departments', 'This position will use a combination of tools, techniques, and technologies to generate, analyze, report, and interpret moderately complex data used across the organization', 'This work will support Health Connect America’s future growth plans and will receive executive level attention and exposure', 'Facilitate meetings to ensure focused planning and coordination between teams working on company strategic initiatives', 'Develop financial models through benchmarking and process analysis for both M&A and Organic Expansion opportunities', 'Assist leadership to produce and monitor key performance indicators to measure and improve team performance', 'Complete special projects and initiatives with skillful oversight and support', 'Conduct thorough research of historical financial data including analysis on organic growth initiatives', 'Coordinate with the Chief Financial Officer (CFO) and the executive team on long-term financial planning', 'Assist VP of Strategy & Platform Development to create in-depth investment memorandums and related presentations for review by senior management, private equity sponsors, and other third-party advisors as required', 'Assist in creating/executing diligence and integration plans for successful deal execution', 'Maintain confidentiality of financial information and investment decisions', 'Perform other duties as assigned to support operations and mission of the Company']",False,[],,"['Financial Modeling', 'Key Performance Indicators (KPIs)', 'Data Analytics', 'Alteryx', 'Power BI', 'Microsoft Excel']","Financial Modeling: Used to develop financial models for M&A and organic expansion opportunities to support strategic decision-making.; Key Performance Indicators (KPIs): Produced and monitored to measure and improve team and organizational performance.; Data Analytics: Applied to generate, analyze, report, and interpret moderately complex financial and operational data across the organization.; Alteryx: Utilized as a data analytics tool to process and analyze financial and operational data.; Power BI: Used to create dashboards and reports for visualizing financial and strategic data to support decision-making.; Microsoft Excel: Employed for data analysis, financial modeling, and reporting tasks within the financial strategy and project management role."
a0_LjSMjfaSC-SvWAAAAAA==,WFH | Online Data Analyst - Spanish Speaker in the United States,"Are you a detail-oriented individual with a passion for research and a good understanding of national and local geography? This freelance opportunity allows you to work at your own pace and from the comfort of your own home.

A Day in the Life of an Online Data Analyst:
• In this role, you will be working on a project aimed at enhancing the content and quality of digital maps that are used by millions of people worldwide
• Completing research and evaluation tasks in a web-based environment, such as verifying and comparing data, and determining the relevance and accuracy of information.

Join us today and be part of a dynamic and innovative team that is making a difference in the world!

TELUS Digital AI Community

Our global AI Community is a vibrant network of 1 million+ contributors from diverse backgrounds who help our customers collect, enhance, train, translate, and localize content to build better AI models. Become part of our growing community and make an impact supporting the machine learning models of some of the world’s largest brands

Qualification path

No previous professional experience is required to apply to this role, however, working on this project will require you to pass the basic requirements and go through a standard assessment process. This is a part-time long-term project and your work will be subject to our standard quality assurance checks during the term of this agreement.

Basic Requirements
• Full Professional Proficiency in Spanish language
• Being a resident in United States for the last 2 consecutive years and having familiarity with current and historical business, media, sport, news, social media, and cultural affairs in United States
• Ability to follow guidelines and conduct online research using search engines, online maps, and website information
• Flexibility to work across a diverse set of task types, including maps, news, audio tasks, and relevance
• Daily access to a broadband internet connection, computer, and relevant software

Assessment

In order to be hired into the program, you’ll take an open book qualification exam that will determine your suitability for the position and complete ID verification. Our team will provide you with guidelines and learning materials before your qualification exam. You will be required to complete the exam in a specific timeframe but at your convenience.

Equal Opportunity

All qualified applicants will receive consideration for a contractual relationship without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or protected veteran status. At TELUS Digital AI, we are proud to offer equal opportunities and are committed to creating a diverse and inclusive community. All aspects of selection are based on applicants’ qualifications, merits, competence, and performance without regard to any characteristic related to diversity.",2025-07-15T00:00:00.000Z,2025-07-25,"['No previous professional experience is required to apply to this role, however, working on this project will require you to pass the basic requirements and go through a standard assessment process', 'Full Professional Proficiency in Spanish language', 'Being a resident in United States for the last 2 consecutive years and having familiarity with current and historical business, media, sport, news, social media, and cultural affairs in United States', 'Ability to follow guidelines and conduct online research using search engines, online maps, and website information', 'Flexibility to work across a diverse set of task types, including maps, news, audio tasks, and relevance', 'Daily access to a broadband internet connection, computer, and relevant software', 'In order to be hired into the program, you’ll take an open book qualification exam that will determine your suitability for the position and complete ID verification', 'Our team will provide you with guidelines and learning materials before your qualification exam']","['In this role, you will be working on a project aimed at enhancing the content and quality of digital maps that are used by millions of people worldwide', 'Completing research and evaluation tasks in a web-based environment, such as verifying and comparing data, and determining the relevance and accuracy of information', 'This is a part-time long-term project and your work will be subject to our standard quality assurance checks during the term of this agreement']",False,[],,"['Data Verification', 'Online Research', 'Quality Assurance']","Data Verification: The role involves verifying and comparing data to ensure the accuracy and relevance of information used in digital maps.; Online Research: Conducting research using search engines, online maps, and website information to support data quality enhancement.; Quality Assurance: Performing standard quality checks on work outputs to maintain high data standards throughout the project."
XZbRG7Xze6RMrMfPAAAAAA==,Data Analyst - L3,"Wipro Limited (NYSE: WIT, BSE: 507685, NSE: WIPRO) is a leading technology services and consulting company focused on building innovative solutions that address clients' most complex digital transformation needs. Leveraging our holistic portfolio of capabilities in consulting, design, engineering, and operations, we help clients realize their boldest ambitions and build future-ready, sustainable businesses. With over 230,000 employees and business partners across 65 countries, we deliver on the promise of helping our customers, colleagues, and communities thrive in an ever-changing world. For additional information, visit us at www.wipro.com. Job Description

Role Purpose

The purpose of the role is to liaison and bridging the gap between customer and Wipro delivery team to comprehend and analyze customer requirements and articulating aptly to delivery teams thereby, ensuring right solutioning to the customer.

Do

1. Customer requirements gathering and engagement
• Interface and coordinate with client engagement partners to understand the RFP/ RFI requirements
• Detail out scope documents, functional & non-functional requirements, features etc ensuring all stated and unstated customer needs are captured
• Construct workflow charts and diagrams, studying system capabilities, writing specification after thorough research and analysis of customer requirements
• Engage and interact with internal team - project managers, pre-sales team, tech leads, architects to design and formulate accurate and timely response to RFP/RFIs
• Understand and communicate the financial and operational impact of any changes
• Periodic cadence with customers to seek clarifications and feedback wrt solution proposed for a particular RFP/ RFI and accordingly instructing delivery team to make changes in the design
• Empower the customers through demonstration and presentation of the proposed solution/ prototype
• Maintain relationships with customers to optimize business integration and lead generation
• Ensure ongoing reviews and feedback from customers to improve and deliver better value (services/ products) to the customers

2. Engage with delivery team to ensure right solution is proposed to the customer

a. Periodic cadence with delivery team to:
• Provide them with customer feedback/ inputs on the proposed solution
• Review the test cases to check 100% coverage of customer requirements
• Conduct root cause analysis to understand the proposed solution/ demo/ prototype before sharing it with the customer
• Deploy and facilitate new change requests to cater to customer needs and requirements
• Support QA team with periodic testing to ensure solutions meet the needs of businesses by giving timely inputs/feedback
• Conduct Integration Testing and User Acceptance demo's testing to validate implemented solutions and ensure 100% success rate
• Use data modelling practices to analyze the findings and design, develop improvements and changes
• Ensure 100% utilization by studying systems capabilities and understanding business specifications
• Stitch the entire response/ solution proposed to the RFP/ RFI before its presented to the customer

b. Support Project Manager/ Delivery Team in delivering the solution to the customer
• Define and plan project milestones, phases and different elements involved in the project along with the principal consultant
• Drive and challenge the presumptions of delivery teams on how will they successfully execute their plans
• Ensure Customer Satisfaction through quality deliverable on time

3. Build domain expertise and contribute to knowledge repository
• Engage and interact with other BA's to share expertise and increase domain knowledge across the vertical
• Write whitepapers/ research papers, point of views and share with the consulting community at large
• Identify and create used cases for a different project/ account that can be brought at Wipro level for business enhancements
• Conduct market research for content and development to provide latest inputs into the projects thereby ensuring customer delight

Deliver
No. Performance Parameter Measure 1. Customer Engagement and Delivery Management PCSAT, utilization % achievement, no. of leads generated from the business interaction, no. of errors/ gaps in documenting customer requirements, feedback from project manager, process flow diagrams (quality and timeliness), % of deal solutioning completed within timeline, velocity generated. 2. Knowledge Management No. of whitepapers/ research papers written, no. of user stories created, % of proposal documentation completed and uploaded into knowledge repository, No of reusable components developed for proposal during quarter

Mandatory Skills: Data Visualization .

Experience: 3-5 Years .

Expected annual pay for this role ranges from $45,000 to $110,000 . Based on the position, the role is also eligible for Wipro's standard benefits including a full range of medical and dental benefits options, disability insurance, paid time off (inclusive of sick leave), other paid and unpaid leave options.

Reinvent your world. We are building a modern Wipro. We are an end-to-end digital transformation partner with the boldest ambitions. To realize them, we need people inspired by reinvention. Of yourself, your career, and your skills. We want to see the constant evolution of our business and our industry. It has always been in our DNA - as the world around us changes, so do we. Join a business powered by purpose and a place that empowers you to design your own reinvention. Come to Wipro. Realize your ambitions. Applications from people with disabilities are explicitly welcome.",2025-07-13T00:00:00.000Z,2025-07-25,"['Mandatory Skills: Data Visualization ', 'Experience: 3-5 Years ']","['The purpose of the role is to liaison and bridging the gap between customer and Wipro delivery team to comprehend and analyze customer requirements and articulating aptly to delivery teams thereby, ensuring right solutioning to the customer', 'Customer requirements gathering and engagement', 'Interface and coordinate with client engagement partners to understand the RFP/ RFI requirements', 'Detail out scope documents, functional & non-functional requirements, features etc ensuring all stated and unstated customer needs are captured', 'Construct workflow charts and diagrams, studying system capabilities, writing specification after thorough research and analysis of customer requirements', 'Engage and interact with internal team - project managers, pre-sales team, tech leads, architects to design and formulate accurate and timely response to RFP/RFIs', 'Understand and communicate the financial and operational impact of any changes', 'Periodic cadence with customers to seek clarifications and feedback wrt solution proposed for a particular RFP/ RFI and accordingly instructing delivery team to make changes in the design', 'Empower the customers through demonstration and presentation of the proposed solution/ prototype', 'Maintain relationships with customers to optimize business integration and lead generation', 'Ensure ongoing reviews and feedback from customers to improve and deliver better value (services/ products) to the customers', 'Engage with delivery team to ensure right solution is proposed to the customer', 'Periodic cadence with delivery team to:', 'Provide them with customer feedback/ inputs on the proposed solution', 'Review the test cases to check 100% coverage of customer requirements', 'Conduct root cause analysis to understand the proposed solution/ demo/ prototype before sharing it with the customer', 'Deploy and facilitate new change requests to cater to customer needs and requirements', 'Support QA team with periodic testing to ensure solutions meet the needs of businesses by giving timely inputs/feedback', ""Conduct Integration Testing and User Acceptance demo's testing to validate implemented solutions and ensure 100% success rate"", 'Use data modelling practices to analyze the findings and design, develop improvements and changes', 'Ensure 100% utilization by studying systems capabilities and understanding business specifications', 'Stitch the entire response/ solution proposed to the RFP/ RFI before its presented to the customer', 'Support Project Manager/ Delivery Team in delivering the solution to the customer', 'Define and plan project milestones, phases and different elements involved in the project along with the principal consultant', 'Drive and challenge the presumptions of delivery teams on how will they successfully execute their plans', 'Ensure Customer Satisfaction through quality deliverable on time', 'Build domain expertise and contribute to knowledge repository', ""Engage and interact with other BA's to share expertise and increase domain knowledge across the vertical"", 'Write whitepapers/ research papers, point of views and share with the consulting community at large', 'Identify and create used cases for a different project/ account that can be brought at Wipro level for business enhancements', 'Conduct market research for content and development to provide latest inputs into the projects thereby ensuring customer delight', 'Customer Engagement and Delivery Management PCSAT, utilization % achievement, no', 'of leads generated from the business interaction, no', 'of errors/ gaps in documenting customer requirements, feedback from project manager, process flow diagrams (quality and timeliness), % of deal solutioning completed within timeline, velocity generated', 'Knowledge Management No. of whitepapers/ research papers written, no', 'of user stories created, % of proposal documentation completed and uploaded into knowledge repository, No of reusable components developed for proposal during quarter']",False,[],,"['Data Visualization', 'Data Modelling', 'Root Cause Analysis', 'Integration Testing', 'User Acceptance Testing', 'Workflow Diagrams']","Data Visualization: Used to present and communicate data insights effectively to customers and internal teams, supporting solution demonstrations and decision-making.; Data Modelling: Applied to analyze findings and design improvements in solutions, ensuring alignment with business specifications and customer requirements.; Root Cause Analysis: Employed to understand issues in proposed solutions or prototypes before sharing with customers, ensuring quality and accuracy.; Integration Testing: Conducted to validate that implemented solutions work correctly across system components before customer acceptance.; User Acceptance Testing: Performed to ensure solutions meet customer needs and achieve 100% success rate prior to deployment.; Workflow Diagrams: Created to map system capabilities and processes, aiding in requirement analysis and solution design."
0RPj7-j0a7dKpU6NAAAAAA==,"Scientific Business Analyst, Scientific AI- Boston","Who We Are

TetraScience is the Scientific Data and AI Cloud company. We are catalyzing the Scientific AI revolution by designing and industrializing AI-native scientific data sets, which we bring to life in a growing suite of next gen lab data management solutions, scientific use cases, and AI-enabled outcomes.

TetraScience is the category leader in this vital new market, generating more revenue than all other companies in the aggregate. In the last year alone, the world’s dominant players in compute, cloud, data, and AI infrastructure have converged on TetraScience as the de facto standard, entering into co-innovation and go-to-market partnerships: Latest News and Announcements | TetraScience Newsroom:

In connection with your candidacy, you will be asked to carefully review the Tetra Way letter, authored directly by Patrick Grady, our co-founder and CEO. This letter is designed to assist you in better understanding whether TetraScience is the right fit for you from a values and ethos perspective.

It is impossible to overstate the importance of this document and you are encouraged to take it literally and reflect on whether you are aligned with our unique approach to company and team building. If you join us, you will be expected to embody its contents each day.

Who You Are

You are a strategic, analytically minded professional with a passion for bridging scientific insights and cutting-edge technology. You thrive in environments where you can collaborate with scientists, product managers, and engineers to transform complex scientific data into actionable outcomes.

With deep domain knowledge in drug discovery/preclinical development, CMC, or Quality, you are skilled at uncovering innovative use cases that drive AI and machine learning applications. Your ability to engage with scientists and business leaders alike makes you a key player in maximizing the value of scientific data.

You will need to be a high clock speed and forward-thinking individual with a passion for developing requirements for complex solutions targeted to R&D and Quality personas inside of Life Sciences.

You will need to be a high clock-speed, forward-thinking individual with a passion for developing requirements for complex solutions targeted to R&D and Quality personas inside Life Sciences. You embody extreme ownership and have a demonstrated history of deriving maximum value from data through enrichment, analysis, and integration with AI and machine learning applications.

You should also be energized by regularly working onsite with customers. You thrive in dynamic, high-impact, face-to-face collaborative environments where you can build deep relationships and drive scientific transformation firsthand.

Requirements

What You Have Done
• PhD with 15+ years of industry experience in life sciences, preferably across pharma, biotech, or health tech, with deep domain expertise in discovery, preclinical, CMC, and/or Quality.
• Extensive hands-on experience or direct oversight in one or more of the following areas: high throughput screening, preclinical toxicology, materials engineering, analytical development, drug substance (DS) synthesis and manufacturing.
• Delivered requirements for AI/ML-driven solutions in operational or productized environments that improved efficiency, reduced cost, and enhanced data utilization.
• Extensive hands-on experience with scientific data workflows and lab automation; exposure to FAIR principles and modern data architecture is a plus.
• Strong coding or scripting background (e.g., Python, Nextflow, AWS, SDKs) and familiarity with scientific tools, databases, and ontologies is preferred.
• Exceptional communication and storytelling ability to engage technical and executive stakeholders.
• Prior experience in customer-facing, consulting, or commercial-scientific interface roles.

What You Will Do
• You will be a critical team member in a unique partnership to industrialize Scientific AI. As such, you will engage directly with customers onsite up to 4-5 days per week in the Boston Region
• Customer Data Exploration: Investigate diverse customer datasets, identifying enrichment and AI-readiness opportunities.
• Scientific Use Case Development: Collaborate with customers to define, iterate, and implement innovative scientific AI/ML use cases.
• Stakeholder Engagement: Conduct onsite interviews and workshops to deeply understand customer challenges and data landscapes.
• Data Analysis and Enrichment: Perform exploratory data analysis and define transformation workflows that enable scientific AI.
• Workflow Documentation: Develop visual documentation including workflow diagrams, ERDs, and ontology definitions.
• AI Model Evaluation: Provide practical scientific input on model output, with suggestions to improve real-world performance.
• Customer Enablement: Deliver onsite demonstrations, conduct working sessions, and act as a trusted advisor in AI adoption.
• Strategic Insight: Propose new directions, experiments, or platforms that can amplify scientific discovery and development.

Benefits
• 100% employer-paid benefits for all eligible employees and immediate family members
• Unlimited paid time off (PTO)
• 401K
• Remote working opportunities, when not at customer sites
• Company paid Life Insurance, LTD/STD
• A culture of continuous improvement where you can grow your career and get coaching",,2025-07-25,"['You are a strategic, analytically minded professional with a passion for bridging scientific insights and cutting-edge technology', 'You thrive in environments where you can collaborate with scientists, product managers, and engineers to transform complex scientific data into actionable outcomes', 'With deep domain knowledge in drug discovery/preclinical development, CMC, or Quality, you are skilled at uncovering innovative use cases that drive AI and machine learning applications', 'Your ability to engage with scientists and business leaders alike makes you a key player in maximizing the value of scientific data', 'You will need to be a high clock speed and forward-thinking individual with a passion for developing requirements for complex solutions targeted to R&D and Quality personas inside of Life Sciences', 'You will need to be a high clock-speed, forward-thinking individual with a passion for developing requirements for complex solutions targeted to R&D and Quality personas inside Life Sciences', 'You embody extreme ownership and have a demonstrated history of deriving maximum value from data through enrichment, analysis, and integration with AI and machine learning applications', 'PhD with 15+ years of industry experience in life sciences, preferably across pharma, biotech, or health tech, with deep domain expertise in discovery, preclinical, CMC, and/or Quality', 'Extensive hands-on experience or direct oversight in one or more of the following areas: high throughput screening, preclinical toxicology, materials engineering, analytical development, drug substance (DS) synthesis and manufacturing', 'Delivered requirements for AI/ML-driven solutions in operational or productized environments that improved efficiency, reduced cost, and enhanced data utilization', 'Exceptional communication and storytelling ability to engage technical and executive stakeholders', 'Prior experience in customer-facing, consulting, or commercial-scientific interface roles']","['You should also be energized by regularly working onsite with customers', 'You thrive in dynamic, high-impact, face-to-face collaborative environments where you can build deep relationships and drive scientific transformation firsthand', 'You will be a critical team member in a unique partnership to industrialize Scientific AI', 'As such, you will engage directly with customers onsite up to 4-5 days per week in the Boston Region', 'Customer Data Exploration: Investigate diverse customer datasets, identifying enrichment and AI-readiness opportunities', 'Scientific Use Case Development: Collaborate with customers to define, iterate, and implement innovative scientific AI/ML use cases', 'Stakeholder Engagement: Conduct onsite interviews and workshops to deeply understand customer challenges and data landscapes', 'Data Analysis and Enrichment: Perform exploratory data analysis and define transformation workflows that enable scientific AI', 'Workflow Documentation: Develop visual documentation including workflow diagrams, ERDs, and ontology definitions', 'AI Model Evaluation: Provide practical scientific input on model output, with suggestions to improve real-world performance', 'Customer Enablement: Deliver onsite demonstrations, conduct working sessions, and act as a trusted advisor in AI adoption', 'Strategic Insight: Propose new directions, experiments, or platforms that can amplify scientific discovery and development']",True,"['Machine Learning', 'Scientific AI']","Machine Learning: Applied to develop AI/ML-driven solutions that improve operational efficiency, reduce costs, and enhance data utilization in scientific contexts.; Scientific AI: Refers to AI technologies specifically designed and industrialized for scientific data sets and use cases in life sciences.","['Exploratory Data Analysis', 'Data Enrichment', 'Scientific Data Workflows', 'FAIR Data Principles', 'Workflow Documentation', 'Python', 'Nextflow', 'AWS', 'SDKs']","Exploratory Data Analysis: Used to investigate diverse customer datasets and identify opportunities for data enrichment and AI readiness.; Data Enrichment: Applied to enhance scientific data value by integrating and transforming datasets to support AI and machine learning applications.; Scientific Data Workflows: Involved in managing and optimizing lab automation and scientific data pipelines to support research and development processes.; FAIR Data Principles: Referenced as a guideline for managing scientific data to ensure it is Findable, Accessible, Interoperable, and Reusable.; Workflow Documentation: Creating visual documentation such as workflow diagrams, ERDs, and ontology definitions to clarify data processes and structures.; Python: Used as a coding and scripting language to support data analysis, scientific workflows, and integration with AI/ML solutions.; Nextflow: Utilized as a workflow management tool to automate and orchestrate scientific data pipelines.; AWS: Employed cloud infrastructure services to support data storage, processing, and deployment of AI/ML-driven solutions.; SDKs: Used to interface with scientific tools, databases, and ontologies for data integration and analysis."
X_ayPIoPy9Kzho7-AAAAAA==,Data Analyst with Security Clearance,"M&S Consulting was conceived in 2002 with the vision of creating highly effective teams of elite consultants to deliver strategic process and technology solutions to enterprise organizations across the US. Our commitment to delivery in complex environments and long-term customer success has merged process and technology into innovative solutions, established deep pockets of expertise, and enabled innovative transformation for evolving businesses.

We have intentionally cultivated steady growth focused on being approachable and helpful to our dearly valued clients and closely cared-for employees. M&S people simply “care hard”, and this reflects in our work products, our interactions, and our culture.

M&S Consulting is seeking a Data Analyst to work in Huntsville, AL. Candidate must possess an active Top Secret/SCI Eligible clearance.

The Data Analyst will perform analysis on relevant information from a variety of sources to prepare documents, reports, summaries and replies to inquiries, ensuring accuracy and proper format of the information provided. The candidate will manage the compilation, cataloging, caching, distribution, and retrieval of data. The successful candidate will participate in Ad hoc data projects and analyses that produce actionable recommendations that build relevant insights for internal and external stakeholders. The Data Analyst will collect data and run basic reports in response to client inquiries, work closely with key internal stakeholders to ensure sound knowledge of client requirements to support development of best-in-class analytical solutions, and accurately enter required data into one or more databases, documents and/or spreadsheets.

Job Requirements:
• Active Top Secret/SCI Eligibility Clearance
• At least six (6+) years of data analysis experience
• Possess strong statistical and analytical knowledge
• Proficient communication, problem-solving, and critical thinking skills
• Bachelor’s degree in related field OR in lieu of degree, 4 additional years of experience

Preferred:
• UAM (User Activity Monitoring) experience
• M&S Consulting proactively fulfills its role as an equal opportunity employer. We do not discriminate against any employee or applicant for employment because of race, color, sex, religion, age, sexual orientation, gender identity and expression, national origin, marital status, physical or mental disability, status as a protected veteran, or any other characteristic protected by law.",,2025-07-25,"['Candidate must possess an active Top Secret/SCI Eligible clearance', 'Active Top Secret/SCI Eligibility Clearance', 'At least six (6+) years of data analysis experience', 'Possess strong statistical and analytical knowledge', 'Proficient communication, problem-solving, and critical thinking skills', 'Bachelor’s degree in related field OR in lieu of degree, 4 additional years of experience']","['The Data Analyst will perform analysis on relevant information from a variety of sources to prepare documents, reports, summaries and replies to inquiries, ensuring accuracy and proper format of the information provided', 'The candidate will manage the compilation, cataloging, caching, distribution, and retrieval of data', 'The successful candidate will participate in Ad hoc data projects and analyses that produce actionable recommendations that build relevant insights for internal and external stakeholders', 'The Data Analyst will collect data and run basic reports in response to client inquiries, work closely with key internal stakeholders to ensure sound knowledge of client requirements to support development of best-in-class analytical solutions, and accurately enter required data into one or more databases, documents and/or spreadsheets']",True,[],,"['Statistical Analysis', 'Data Compilation and Cataloging', 'Ad Hoc Data Analysis', 'Reporting and Data Visualization', 'Database and Spreadsheet Management']","Statistical Analysis: Used to perform data analysis and generate actionable insights from various data sources.; Data Compilation and Cataloging: Managing the organization, caching, distribution, and retrieval of data to support analysis and reporting.; Ad Hoc Data Analysis: Conducting on-demand data projects and analyses to address specific client inquiries and business needs.; Reporting and Data Visualization: Creating reports and summaries to communicate findings and support decision-making for stakeholders.; Database and Spreadsheet Management: Accurately entering and managing data within databases and spreadsheets to maintain data integrity."
_rU6sFGYh2fmCHkCAAAAAA==,"Sr Business Information Mgmt Analyst (""Credit Card"") - Excel/SQL/Tableau/Python/Jira","Work Location:
Mount Laurel, New Jersey, United States of America

Hours:
40

Pay Details:
$68,640 - $112,320 USD

TD is committed to providing fair and equitable compensation opportunities to all colleagues. Growth opportunities and skill development are defining features of the colleague experience at TD. Our compensation policies and practices have been designed to allow colleagues to progress through the salary range over time as they progress in their role. The base pay actually offered may vary based upon the candidate's skills and experience, job-related knowledge, geographic location, and other specific business and organizational needs.

As a candidate, you are encouraged to ask compensation related questions and have an open dialogue with your recruiter who can provide you more specific details for this role.

Line of Business:
Data & Analytics

Job Description:

The Senior Business Information Management Analyst (US) provides business technical leadership across a broad range of information management functions to support the various areas of data and analytics. Works independently as a senior lead and may manage and direct activities related to analysis, design and support of business data management solutions on various projects ranging up to larger projects.

Position Overview:

This position will support the US DMO (Data Management Office) in executing on the Initiative Data Management team's mandate for the Consumer Banking ""Credit Card"" Portfolios:
• Work on complex business information management initiatives for a key business/functional area that may have enterprise wide scope
• Provide expertise within the specialized field and/or other data management functions that support business needs
• Work closely with cross functional teams to ensure the implementation of data management processes and enforce data governance policies to meet specific project needs, regulatory requirements and best practices
• Support the development of presentations /communications of data quality results
• Understand department objectives and contribute by supporting data management activities
• Support the management of data in accordance with the Enterprise Data Policy, Standards and Strategy/ Enterprise Data Management Office (EDMO) Standards
• Support data related activities and analysis on business projects and initiatives
• Data mapping, understanding flow of data from source to target systems, Well versed with process flows
• Assess current capabilities and high-level business requirements and apply technical background/understanding in the development of system requirements and functional documents
• Work in close partnership with business partners / technology / project teams and stakeholders to plan, elicit, analyze, document, communicate and manage detailed functional specifications

Depth & Scope:
• Expert level professional role, considered subject matter expert with in-depth knowledge / expertise in own domain / field of specialty and working knowledge of broader related areas
• Requires expert level conceptual and practical knowledge for own area of specialty and knowledge of broader related areas
• Advanced analytical and problem solving skills and fluent in one or two programming language
• Works autonomously on a range of tasks and may be relied upon to coach / educate others
• Lead projects of moderately to complex risk and resource requirements; may lead end-to-end processes or functional programs
• In-depth experience working with very large datasets and familiarity with big data technologies
• Keeps abreast of rapid business and technology innovation within business information management field
• Familiar with visualization tools
• Analyzes, designs, develops data repositories, warehouses and marts, data movement, data wrangling, data mapping and transformation (ETL) processes
• Supports solutions, applications, platforms, and/or tools that are leveraged across all functional groups (e.g., Data Scientists, Business Insights & Analytics, etc.)
• May also be responsible for developing sophisticated data preparation frameworks and architecture to create or modify data features for consumption by Data Scientists
• Supports data modeling capabilities in order to structure business data to be consumed / translated into a variety of novel capacities
• Supports business teams in the use and understanding of the data and reporting solutions
• Develops data road map/information management strategies and corresponding technical solutions on integrating, transforming, and/or managing data
• Drives data-centric solution development focusing on complex data integration
• Adopts the Enterprise Data model in alignment with direction from the OCDO and other data & analytics functional groups
• Solicits, analyzes, and understands data requirements (i.e., using market research, requirements gathering, feature planning, user experience / design considerations, etc.) to enable development of information management solutions

Education & Experience:
• Undergraduate degree or Technical Certificate
• 5+ years of relevant experience from a business administration, statistical, mathematical, scientific or financial background
• Proficient knowledge of various data sources, tools and technologies used in preparing summaries and reports
• Analytical and problem solving skills are required to interpret data and draw conclusions
• Knowledge of current and emerging competitor and market trends
• Skill in using analytical software tools, data analysis methods and reporting techniques
• Skill in mentoring/coaching others
• Skill in using computer applications including MS Office
• Ability to communicate effectively in both oral and written form
• Ability to work collaboratively and build relationships
• Ability to work successfully as a member of a team and independently
• Ability to exercise sound judgement in making decisions
• Ability to analyze, organize and prioritize work while meeting multiple deadlines
• Ability to handle confidential information with discretion

Preferred Qualifications:
• Candidates with 2+ years of relevant data experience will be considered
• Experience within the Banking/Financial Services Industry (Consumer banking ""Credit Card"" product business knowledge strongly preferred)
• Experience with Data Risk Management, Data Quality, Data Risk Identification and controls, Data Governance, Data lineage (data mapping, data tracing end to end), Data Transformation, Metadata, etc.
• Familiarity and ability to understand technical architecture/ architecture blueprint and design documentation
• Knowledge of program/project delivery methodologies (Risk/Audit experience is helpful but not required)
• Familiar with business requirements and alignment to technical delivery solutions
• Familiar with Process Controls (identification or testing of controls)
• Communicate effectively with project stakeholders to understand their data needs, address concerns and provide insights
• Self-motivated and driven, forward thinking individual with ability to perform a task with minimal supervision
• MS Office Suite Skills (including Excel/PowerPoint)
• Ability to read SQL/Python or other programming languages
• Data Visualization/Dashboard Development Skills (Tableau/PowerBI)
• Cloud experience preferred (Databricks/Azure)
• Experience with Agile Methodologies a plus
• Experience with Jira/Confluence/ServiceNow

Customer Accountabilities:
• Analyzes and understands business and data requirements to develop complete business solutions, including data models (entity relationship diagrams, dimensional data models) and business rules, data life-cycle management, governance, lineage, metadata and reporting elements.
• Applies automation and innovation on data platforms and on-going on any new development projects / initiatives aligned to business or organizational strategies
• Designs and implements complex business data information management frameworks to provide a solution that meets business requirements
• Collaborates with technology and business partners to resolve issues and ensure requirements and established SLAs
• Works closely with various technology/project teams to understand business data and provide analysis and requirements to ensure the data design / development initiatives are in line with the planned design and standards

Shareholder Accountabilities:
• Works with other various partners/ stakeholders to ensure project success
• Develops business requirements by researching / analyzing and documenting business data requirements
• Provides expert guidance within projects and other various change initiatives to support data impact assessments and data risk mitigation
• Implements processes aligned to data information management standards and ensure data quality (e.g., rules / thresholds / assessments, etc.) and requirements are developed
• Develops and maintains knowledge of data available from upstream sources and data within various platforms
• Identifies critical data / critical data elements to support Business Segment data governance and/or data management frameworks / programs
• May be responsible to understand and utilize business information management data deliverables
• Ensures business data and information is retained and disposed in compliance with enterprise data standards, policies and guidelines
• Performs data profiling using TD tooling and ad hoc system query languages to validate data analysis
• Provides support throughout data lifecycle to resolve data issues and support user community by helping users interpret the data
• Leads the investigation of root causes for data issues and ensure data issues are resolved
• Identifies and/or define knowledge transfer and data expertise activities to support business teams using the information management solutions.
• Adheres to enterprise frameworks or methodologies that relate to data activities for business area
• Ensures business operations follow applicable internal and external requirements (e.g. financial controls, segregation of duties, transaction approvals and physical control of assets)
• Participates in cross-functional / enterprise / initiatives as a subject matter expert helping to identify risk / provide guidance for complex situations
• Conducts meaningful analysis at the functional or enterprise level using results to draw conclusions, make recommendations, assess the effectiveness of programs/ policies/ practices
• Keeps abreast of emerging issues, trends, and evolving regulatory requirements and assess potential impacts
• Maintains a culture of risk management and control, supported by effective processes in alignment with risk appetite

Employee/Team Accountabilities:
• Participates fully as a member of the team, support a positive work environment that promotes service to the business, quality, innovation and teamwork and ensure timely communication of issues/ points of interest
• Provides industry knowledge for own area of expertise and participate in knowledge transfer within the team and business unit
• Keeps current on emerging trends/ developments and grow knowledge of the business, related tools and techniques
• Participates in personal performance management and development activities, including cross training within own team
• Keeps others informed and up-to-date about the status / progress of projects and / or all relevant or useful information related to day-to-day activities
• Contributes to team development of skills and capabilities through mentorship of others, by sharing knowledge and experiences and leveraging best practices.
• Leads, motivates and develops relationships with internal and external business partners / stakeholders to develop productive working relationships.
• Contributes to a fair, positive and equitable environment that supports a diverse workforce
• Acts as a brand ambassador for your business area/function and the bank, both internally and/or externally

Physical Requirements:

Never: 0%; Occasional: 1-33%; Frequent: 34-66%; Continuous: 67-100%
• Domestic Travel - Occasional
• International Travel - Never
• Performing sedentary work - Continuous
• Performing multiple tasks - Continuous
• Operating standard office equipment - Continuous
• Responding quickly to sounds - Occasional
• Sitting - Continuous
• Standing - Occasional
• Walking - Occasional
• Moving safely in confined spaces - Occasional
• Lifting/Carrying (under 25 lbs.) - Occasional
• Lifting/Carrying (over 25 lbs.) - Never
• Squatting - Occasional
• Bending - Occasional
• Kneeling - Never
• Crawling - Never
• Climbing - Never
• Reaching overhead - Never
• Reaching forward - Occasional
• Pushing - Never
• Pulling - Never
• Twisting - Never
• Concentrating for long periods of time - Continuous
• Applying common sense to deal with problems involving standardized situations - Continuous
• Reading, writing and comprehending instructions - Continuous
• Adding, subtracting, multiplying and dividing - Continuous

The above statements are intended to describe the general nature and level of work being performed by people assigned to this job. They are not intended to be an exhaustive list of all responsibilities, duties and skills required. The listed or specified responsibilities & duties are considered essential functions for ADA purposes.

Who We Are:
TD is one of the world's leading global financial institutions and is the fifth largest bank in North America by branches/stores. Every day, we deliver legendary customer experiences to over 27 million households and businesses in Canada, the United States and around the world. More than 95,000 TD colleagues bring their skills, talent, and creativity to the Bank, those we serve, and the economies we support. We are guided by our vision to Be the Better Bank and our purpose to enrich the lives of our customers, communities and colleagues.

TD is de...",2025-07-21T00:00:00.000Z,2025-07-25,"['Requires expert level conceptual and practical knowledge for own area of specialty and knowledge of broader related areas', 'Advanced analytical and problem solving skills and fluent in one or two programming language', 'Lead projects of moderately to complex risk and resource requirements; may lead end-to-end processes or functional programs', 'In-depth experience working with very large datasets and familiarity with big data technologies', 'Keeps abreast of rapid business and technology innovation within business information management field', 'Familiar with visualization tools', 'Undergraduate degree or Technical Certificate', '5+ years of relevant experience from a business administration, statistical, mathematical, scientific or financial background', 'Proficient knowledge of various data sources, tools and technologies used in preparing summaries and reports', 'Analytical and problem solving skills are required to interpret data and draw conclusions', 'Knowledge of current and emerging competitor and market trends', 'Skill in using analytical software tools, data analysis methods and reporting techniques', 'Skill in mentoring/coaching others', 'Skill in using computer applications including MS Office', 'Ability to communicate effectively in both oral and written form', 'Ability to work collaboratively and build relationships', 'Ability to work successfully as a member of a team and independently', 'Ability to exercise sound judgement in making decisions', 'Ability to analyze, organize and prioritize work while meeting multiple deadlines', 'Ability to handle confidential information with discretion', 'Lifting/Carrying (under 25 lbs.)', 'Lifting/Carrying (over 25 lbs.)', 'Twisting - Never', 'Concentrating for long periods of time - Continuous', 'Applying common sense to deal with problems involving standardized situations - Continuous']","['Works independently as a senior lead and may manage and direct activities related to analysis, design and support of business data management solutions on various projects ranging up to larger projects', 'This position will support the US DMO (Data Management Office) in executing on the Initiative Data Management team\'s mandate for the Consumer Banking ""Credit Card"" Portfolios:', 'Work on complex business information management initiatives for a key business/functional area that may have enterprise wide scope', 'Provide expertise within the specialized field and/or other data management functions that support business needs', 'Work closely with cross functional teams to ensure the implementation of data management processes and enforce data governance policies to meet specific project needs, regulatory requirements and best practices', 'Support the development of presentations /communications of data quality results', 'Understand department objectives and contribute by supporting data management activities', 'Support the management of data in accordance with the Enterprise Data Policy, Standards and Strategy/ Enterprise Data Management Office (EDMO) Standards', 'Support data related activities and analysis on business projects and initiatives', 'Data mapping, understanding flow of data from source to target systems, Well versed with process flows', 'Assess current capabilities and high-level business requirements and apply technical background/understanding in the development of system requirements and functional documents', 'Work in close partnership with business partners / technology / project teams and stakeholders to plan, elicit, analyze, document, communicate and manage detailed functional specifications', 'Expert level professional role, considered subject matter expert with in-depth knowledge / expertise in own domain / field of specialty and working knowledge of broader related areas', 'Works autonomously on a range of tasks and may be relied upon to coach / educate others', 'Analyzes, designs, develops data repositories, warehouses and marts, data movement, data wrangling, data mapping and transformation (ETL) processes', 'Supports solutions, applications, platforms, and/or tools that are leveraged across all functional groups (e.g., Data Scientists, Business Insights & Analytics, etc.)', 'May also be responsible for developing sophisticated data preparation frameworks and architecture to create or modify data features for consumption by Data Scientists', 'Supports data modeling capabilities in order to structure business data to be consumed / translated into a variety of novel capacities', 'Supports business teams in the use and understanding of the data and reporting solutions', 'Develops data road map/information management strategies and corresponding technical solutions on integrating, transforming, and/or managing data', 'Drives data-centric solution development focusing on complex data integration', 'Adopts the Enterprise Data model in alignment with direction from the OCDO and other data & analytics functional groups', 'Solicits, analyzes, and understands data requirements (i.e., using market research, requirements gathering, feature planning, user experience / design considerations, etc.)', 'to enable development of information management solutions', 'Analyzes and understands business and data requirements to develop complete business solutions, including data models (entity relationship diagrams, dimensional data models) and business rules, data life-cycle management, governance, lineage, metadata and reporting elements', 'Applies automation and innovation on data platforms and on-going on any new development projects / initiatives aligned to business or organizational strategies', 'Designs and implements complex business data information management frameworks to provide a solution that meets business requirements', 'Collaborates with technology and business partners to resolve issues and ensure requirements and established SLAs', 'Works closely with various technology/project teams to understand business data and provide analysis and requirements to ensure the data design / development initiatives are in line with the planned design and standards', 'Works with other various partners/ stakeholders to ensure project success', 'Develops business requirements by researching / analyzing and documenting business data requirements', 'Provides expert guidance within projects and other various change initiatives to support data impact assessments and data risk mitigation', 'Implements processes aligned to data information management standards and ensure data quality (e.g., rules / thresholds / assessments, etc.) and requirements are developed', 'Develops and maintains knowledge of data available from upstream sources and data within various platforms', 'Identifies critical data / critical data elements to support Business Segment data governance and/or data management frameworks / programs', 'May be responsible to understand and utilize business information management data deliverables', 'Ensures business data and information is retained and disposed in compliance with enterprise data standards, policies and guidelines', 'Performs data profiling using TD tooling and ad hoc system query languages to validate data analysis', 'Provides support throughout data lifecycle to resolve data issues and support user community by helping users interpret the data', 'Leads the investigation of root causes for data issues and ensure data issues are resolved', 'Identifies and/or define knowledge transfer and data expertise activities to support business teams using the information management solutions', 'Adheres to enterprise frameworks or methodologies that relate to data activities for business area', 'Ensures business operations follow applicable internal and external requirements (e.g. financial controls, segregation of duties, transaction approvals and physical control of assets)', 'Participates in cross-functional / enterprise / initiatives as a subject matter expert helping to identify risk / provide guidance for complex situations', 'Conducts meaningful analysis at the functional or enterprise level using results to draw conclusions, make recommendations, assess the effectiveness of programs/ policies/ practices', 'Keeps abreast of emerging issues, trends, and evolving regulatory requirements and assess potential impacts', 'Maintains a culture of risk management and control, supported by effective processes in alignment with risk appetite', 'Participates fully as a member of the team, support a positive work environment that promotes service to the business, quality, innovation and teamwork and ensure timely communication of issues/ points of interest', 'Provides industry knowledge for own area of expertise and participate in knowledge transfer within the team and business unit', 'Keeps current on emerging trends/ developments and grow knowledge of the business, related tools and techniques', 'Participates in personal performance management and development activities, including cross training within own team', 'Keeps others informed and up-to-date about the status / progress of projects and / or all relevant or useful information related to day-to-day activities', 'Contributes to team development of skills and capabilities through mentorship of others, by sharing knowledge and experiences and leveraging best practices', 'Leads, motivates and develops relationships with internal and external business partners / stakeholders to develop productive working relationships', 'Contributes to a fair, positive and equitable environment that supports a diverse workforce', 'Acts as a brand ambassador for your business area/function and the bank, both internally and/or externally', 'Never: 0%; Occasional: 1-33%; Frequent: 34-66%; Continuous: 67-100%', 'Performing sedentary work - Continuous', 'Performing multiple tasks - Continuous', 'Operating standard office equipment - Continuous', 'Responding quickly to sounds - Occasional', 'Sitting - Continuous', 'Standing - Occasional', 'Walking - Occasional', 'Moving safely in confined spaces - Occasional', 'Occasional', 'Squatting - Occasional', 'Bending - Occasional', 'Kneeling - Never', 'Reading, writing and comprehending instructions - Continuous', 'Adding, subtracting, multiplying and dividing - Continuous']",True,[],,"['SQL', 'Python', 'Data Visualization', 'Data Governance', 'Data Mapping and Lineage', 'ETL (Extract, Transform, Load)', 'Data Modeling', 'Data Profiling', 'Big Data Technologies', 'Data Quality Management', 'Data Lifecycle Management', 'Data Preparation Frameworks', 'Business Intelligence (BI) Tools', 'Cloud Platforms', 'Agile Methodologies', 'Jira/Confluence/ServiceNow']","SQL: Used for querying and managing data within relational databases to support data analysis and reporting.; Python: Utilized for data analysis, scripting, and developing data preparation frameworks to support data scientists.; Data Visualization: Skills in tools like Tableau and PowerBI to create dashboards and visual reports for business insights.; Data Governance: Implementing policies and standards to ensure data quality, compliance, and proper data lifecycle management.; Data Mapping and Lineage: Understanding and documenting the flow of data from source to target systems to support data traceability and impact analysis.; ETL (Extract, Transform, Load): Designing and developing data transformation and movement processes to prepare data for analysis and reporting.; Data Modeling: Creating entity relationship diagrams and dimensional data models to structure business data for consumption.; Data Profiling: Using tooling and query languages to validate data quality and identify data issues.; Big Data Technologies: Familiarity with handling very large datasets and associated technologies to support enterprise data management.; Data Quality Management: Developing rules, thresholds, and assessments to ensure accuracy and reliability of business data.; Data Lifecycle Management: Managing data retention and disposal in compliance with enterprise standards and policies.; Data Preparation Frameworks: Developing sophisticated architectures to create or modify data features for downstream consumption by data scientists.; Business Intelligence (BI) Tools: Supporting business teams in using reporting solutions and dashboards for data-driven decision making.; Cloud Platforms: Experience with cloud environments like Databricks and Azure to support data integration and analytics.; Agile Methodologies: Applying Agile practices to manage data projects and collaborate effectively with cross-functional teams.; Jira/Confluence/ServiceNow: Using project management and collaboration tools to track tasks, document requirements, and support delivery."
t0BTf0IG5_6cNstRAAAAAA==,Senior Financial Data Analyst,"Welcome to Koch Industries, one of the largest privately held companies in the world. We are seeking a highly skilled and experienced Senior Financial Data Analyst to join our dynamic team. As a Senior Financial Data Analyst at Koch Industries, you will play a crucial role in analyzing and interpreting financial data to support our strategic decision-making. This is a unique opportunity to utilize your expertise and contribute to the success of a global company. We are looking for a dedicated individual with a strong financial background and a passion for data analysis. If you are a detail-oriented, analytical thinker with excellent communication skills, we encourage you to apply for this exciting position.
Conduct financial data analysis to identify trends, patterns, and insights to support strategic decision-making.
Utilize various data analysis tools and techniques to extract, clean, and transform complex financial data.
Collaborate with cross-functional teams to understand business objectives and provide financial insights and recommendations.
Develop and maintain financial reports and dashboards for senior leadership and stakeholders.
Conduct in-depth financial research and analysis on market trends, competitors, and industry benchmarks.
Monitor and track key performance indicators (KPIs) to identify potential risks and opportunities.
Identify and implement process improvements to enhance the accuracy and efficiency of financial data analysis.
Communicate complex financial information in a clear and concise manner to non-financial stakeholders.
Stay updated on industry trends, regulations, and best practices related to financial data analysis.
Provide training and mentorship to junior analysts to enhance their skills and knowledge.
Collaborate with IT teams to ensure data integrity and security.
Participate in financial planning and forecasting activities to support long-term strategic planning.
Prepare presentations and reports for executive leadership, board of directors, and investors.
Manage multiple projects and prioritize tasks to meet deadlines and deliver high-quality work.
Adhere to ethical and professional standards in all financial data analysis and reporting.

Koch Industries is an Equal Opportunity Employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. We do not discriminate based upon race, religion, color, national origin, sex, sexual orientation, gender identity, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.",,2025-07-25,"['If you are a detail-oriented, analytical thinker with excellent communication skills, we encourage you to apply for this exciting position']","['Conduct financial data analysis to identify trends, patterns, and insights to support strategic decision-making', 'Utilize various data analysis tools and techniques to extract, clean, and transform complex financial data', 'Collaborate with cross-functional teams to understand business objectives and provide financial insights and recommendations', 'Develop and maintain financial reports and dashboards for senior leadership and stakeholders', 'Conduct in-depth financial research and analysis on market trends, competitors, and industry benchmarks', 'Monitor and track key performance indicators (KPIs) to identify potential risks and opportunities', 'Identify and implement process improvements to enhance the accuracy and efficiency of financial data analysis', 'Communicate complex financial information in a clear and concise manner to non-financial stakeholders', 'Stay updated on industry trends, regulations, and best practices related to financial data analysis', 'Provide training and mentorship to junior analysts to enhance their skills and knowledge', 'Collaborate with IT teams to ensure data integrity and security', 'Participate in financial planning and forecasting activities to support long-term strategic planning', 'Prepare presentations and reports for executive leadership, board of directors, and investors', 'Manage multiple projects and prioritize tasks to meet deadlines and deliver high-quality work', 'Adhere to ethical and professional standards in all financial data analysis and reporting']",False,[],,"['Financial Data Analysis', 'Data Cleaning and Transformation', 'Financial Reporting and Dashboards', 'Key Performance Indicators (KPIs) Monitoring', 'Financial Forecasting and Planning', 'Process Improvement']","Financial Data Analysis: Analyzing financial data to identify trends, patterns, and insights that support strategic decision-making within the company.; Data Cleaning and Transformation: Utilizing data analysis techniques to extract, clean, and transform complex financial data for accurate analysis.; Financial Reporting and Dashboards: Developing and maintaining financial reports and dashboards to communicate insights to senior leadership and stakeholders.; Key Performance Indicators (KPIs) Monitoring: Tracking KPIs to identify potential risks and opportunities relevant to financial performance.; Financial Forecasting and Planning: Participating in financial planning and forecasting activities to support long-term strategic business decisions.; Process Improvement: Identifying and implementing improvements to enhance the accuracy and efficiency of financial data analysis processes."
c65hTLkZsP0-LLNjAAAAAA==,Analyst - Leadership & Change Analytics (LCA),"Company:
Oliver Wyman

Description:

Job specification

Job title: Analyst - Leadership & Change Analytics (LCA)

Department: Oliver Wyman Mergers & Acquisitions

Office/region: Boston, MA

Eligibility: Permanent US work authorization

About Oliver Wyman

Oliver Wyman is a global leader in management consulting. With offices in 60 cities across 29 countries, Oliver Wyman combines deep industry knowledge with specialized expertise in strategy, operations, risk management, and organization transformation. The firm has more than 5,000 professionals around the world who work with clients to optimize their business, improve their operations and risk profile, and accelerate their organizational performance to seize the most attractive opportunities. Oliver Wyman is a wholly owned subsidiary of Marsh & McLennan Companies [NYSE: MMC]. For more information, visit www.oliverwyman.com

Team overview:

Oliver Wyman's Leadership and Change Analytics unit is an innovative, fast-growing team of data scientists and organizational change specialists. Organized as part of our cross-industry Mergers and Acquisitions (M&A) practice, we bring sophisticated expertise in behavioral science and people analytics capabilities to bear on business-critical problems for our clients that span industries.

Clients hire us for our depth of insight and expertise; expertise that comes from a combination of specialized domain knowledge in organizational behavior and deep data science and engineering capabilities. We combine analytical rigor and rapid innovation with a relentless focus on client impact. We are passionate about developing our people and support your career progression, including a path to partner. We are looking for candidates who are excited to work in a collaborative, entrepreneurial, and learning-oriented environment, focused on delivering impact through analytics.

The role:

Working with us offers excellent career and growth opportunities for highly motivated early career and college graduates from quantitative disciplines with some exposure to data engineering, business analytics, and/or quantitative social science.

This role offers a mix of research and asset innovation as well as client-facing, project-based analytics. Some travel to client sites is to be expected as part of building client relationships and setting projects on a solid foundation, but most of our work can be conducted from Boston. We will make flexible working hours and market leading work life balance a priority considering your individual needs, however, we require all employees to work in person with their colleagues for a part of each week.

The ideal candidates will possess strong technical skills, capability to work in teams, a strong learning orientation, the ability deliver work efficiently and under high quality standards and have an open and flexible mindset. Must be based in Boston, MA.

Responsibilities will include:
• You will work as part of our small, fast-growing team, in coordination with other Oliver Wyman teams and clients across the globe
• You will work with large and complex datasets producing customized analyses and advanced models using statistical techniques for the client's needs
• You will be given ownership of the model and application development or validation from start to finish with guidance from experienced managers
• You will work on summarizing, presenting and documenting the performed analyses and features of the developed solutions in client-ready formats

Required skills and experience:
• A Bachelor's or Master's degree in a quantitative discipline, e.g. Business Analytics, Data Engineering, Data Science, Computer Science or Engineering, Mathematics, or Statistics
• Strong engineering, analytics, problem solving, and communication skills
• Experience in advanced analytics and data manipulation - e.g. R, SQL, Python preferred
• Experience to work effectively and collaboratively in a team, while being sufficiently self-directed to meet deadlines and produce high-quality output when working independently
• Be able to find innovative, practical and creative solutions to organizational and business issues
• Excellent command of English language (verbal and written)

Compensation: $80,000 annually

Master's student: $85,000 annually

Oliver Wyman, a business of Marsh McLennan (NYSE: MMC), is a management consulting firm combining deep industry knowledge with specialized expertise to help clients optimize their business, improve operations and accelerate performance. Marsh McLennan is a global leader in risk, strategy and people, advising clients in 130 countries across four businesses: Marsh, Guy Carpenter, Mercer and Oliver Wyman. With annual revenue of $24 billion and more than 90,000 colleagues, Marsh McLennan helps build the confidence to thrive through the power of perspective. For more information, visit oliverwyman.com, or follow on LinkedIn and X.

Marsh McLennan is committed to embracing a diverse, inclusive and flexible work environment. We aim to attract and retain the best people and embrace diversity of age background, disability, ethnic origin, family duties, gender orientation or expression, marital status, nationality, parental status, personal or social status, political affiliation, race, religion and beliefs, sex/gender, sexual orientation or expression, skin color, veteran status (including protected veterans), or any other characteristic protected by applicable law. If you have a need that requires accommodation, please let us know by contacting reasonableaccommodations@mmc.com.

Marsh McLennan is committed to hybrid work, which includes the flexibility of working remotely and the collaboration, connections and professional development benefits of working together in the office. All Marsh McLennan colleagues are expected to be in their local office or working onsite with clients at least three days per week. Office-based teams will identify at least one ""anchor day"" per week on which their full team will be together in person.",2025-07-10T00:00:00.000Z,2025-07-25,"['Clients hire us for our depth of insight and expertise; expertise that comes from a combination of specialized domain knowledge in organizational behavior and deep data science and engineering capabilities', 'The ideal candidates will possess strong technical skills, capability to work in teams, a strong learning orientation, the ability deliver work efficiently and under high quality standards and have an open and flexible mindset', 'Must be based in Boston, MA', ""A Bachelor's or Master's degree in a quantitative discipline, e.g. Business Analytics, Data Engineering, Data Science, Computer Science or Engineering, Mathematics, or Statistics"", 'Strong engineering, analytics, problem solving, and communication skills', 'Experience to work effectively and collaboratively in a team, while being sufficiently self-directed to meet deadlines and produce high-quality output when working independently', 'Be able to find innovative, practical and creative solutions to organizational and business issues', 'Excellent command of English language (verbal and written)']","['Working with us offers excellent career and growth opportunities for highly motivated early career and college graduates from quantitative disciplines with some exposure to data engineering, business analytics, and/or quantitative social science', 'This role offers a mix of research and asset innovation as well as client-facing, project-based analytics', 'Some travel to client sites is to be expected as part of building client relationships and setting projects on a solid foundation, but most of our work can be conducted from Boston', 'We will make flexible working hours and market leading work life balance a priority considering your individual needs, however, we require all employees to work in person with their colleagues for a part of each week', 'You will work as part of our small, fast-growing team, in coordination with other Oliver Wyman teams and clients across the globe', ""You will work with large and complex datasets producing customized analyses and advanced models using statistical techniques for the client's needs"", 'You will be given ownership of the model and application development or validation from start to finish with guidance from experienced managers', 'You will work on summarizing, presenting and documenting the performed analyses and features of the developed solutions in client-ready formats']",True,[],,"['Statistical Techniques', 'Data Engineering', 'Business Analytics', 'Python', 'R', 'SQL', 'Model Development and Validation']","Statistical Techniques: Used to develop advanced models and customized analyses on large and complex datasets to meet client needs.; Data Engineering: Involves working with data pipelines and managing data to support analytics and modeling efforts.; Business Analytics: Applied to analyze organizational and business issues and deliver practical, data-driven solutions.; Python: Preferred programming language for data manipulation and advanced analytics tasks.; R: Used for advanced analytics and statistical modeling.; SQL: Used for querying and managing large datasets.; Model Development and Validation: Ownership of building and validating predictive or analytical models from start to finish."
ZDb9DQ2dBOAn6CYzAAAAAA==,Senior Level Data Analyst​/Shipping Logistics​/Sigma Computing​/SQL​/dbt,"Senior Level Data Analyst / Shipping Logistics / Sigma Computing / SQL / dbt

Join to apply for the Senior Level Data Analyst / Shipping Logistics / Sigma Computing / SQL / dbt role at Motion Recruitment
Senior Level Data Analyst / Shipping Logistics / Sigma Computing / SQL / dbt

Join to apply for the Senior Level Data Analyst / Shipping Logistics / Sigma Computing / SQL / dbt role at Motion Recruitment

Our client is a leader in shipping & logistics specializing in container freight and supply chain solutions. Based in Culver City, CA, they provide innovative and efficient freight forwarding services to global clients. As they continue to scale their data infrastructure, they are seeking a skilled Data Analyst with expertise in SQL, DBT and Sigma Computing to join their team. If you’re passionate about data, logistics, and optimizing product development to improve business operations, they invite you to be a part of their growing team!

We’re looking for a Data Analyst with strong business and product acumen to join our growing team. This role is ideal for someone who thrives on uncovering insights that shape product direction, inform operations, and enhance customer experience. You will be instrumental in converting complex logistics data into clear, actionable recommendations, enabling better decisions across product, operations, and business strategy.

Required Skills & Experience
• 3+ years in a Data Analyst or Product Analyst role, preferably in logistics, supply chain, transportation, or tech
• Proficient in SQL for complex data exploration and transformation
• Hands-on experience with dbt for building modular, version-controlled data pipelines
• Strong experience using Sigma Computing to build and manage dashboards
• Demonstrated ability to turn ambiguous problems into clear analytical questions and actionable insights
• Deep understanding of how product features and operational processes impact performance
• Excellent communication skills with the ability to translate data into stories for both technical and non-technical audiences
What You Will Be Doing Tech Breakdown
• 100% Data Analyst (SQL, dbt, Sigma Computing, and Snowflake)
Daily Responsibilities
• Collaborate cross-functionally with Product, Operations, and Engineering teams to identify key business questions and deliver data-driven insights
• Analyze logistics and operational data to evaluate performance, identify inefficiencies, and recommend improvements
• Design, build, and maintain robust data models using dbt to enable scalable, trusted analytics
• Write advanced SQL queries to explore trends in real-time shipment data, driver behavior, and port performance
• Create dynamic dashboards and visualizations in Sigma Computing to communicate findings and monitor KPIs across the organization
• Partner with product managers to design experiments, evaluate feature performance, and support roadmap planning with data
• Proactively surface insights that help the business optimize throughput, reduce dwell time, and improve service reliability
The Offer You Will Receive The Following Benefits
• Medical, Dental, and Vision Insurance
• Unlimited PTO
• Equity
Applicants must be currently authorized to work in the US on a full-time basis now and in the future.

Posted By: Connor Hart Seniority level
• Seniority level

Mid-Senior level
Employment type
• Employment type

Full-time
Job function
• Job function

Information Technology
• Industries Staffing and Recruiting

Referrals increase your chances of interviewing at Motion Recruitment by 2x
Sign in to set job alerts for “Senior Data Analyst” roles.

IT Business Analyst - Data Analysis & Reporting Business Data Analyst - Ambulatory Admin - Full Time 8 Hour Days (Exempt) (Non-Union)
Senior Level Data Analyst / Shipping Logistics / Sigma Computing / SQL / dbt Business Intelligence Analyst, Trust & Safety - USDS

Los Angeles, CA $-$ 2 weeks ago
Senior Level Data Analyst / Shipping Logistics / Sigma Computing / SQL / dbt

Los Angeles, CA $95,000.00-$ 2 weeks ago
Business Analyst, Creator Partnerships, You Tube Business Data Analyst - MSO Clinical Ops - Full Time 8 Hour Days (Exempt) (Non-Union)
Senior Business Systems Analyst (Workday)

Los Angeles Metropolitan Area $-$ 2 weeks ago
Business Analyst II, Prime Video Global Operations Business Analyst IT (Logistics & Supply Chain)
Senior Business Analyst, Workday Adaptive Planning

Los Angeles Metropolitan Area $90,000.00-$ 2 weeks ago
Business Analyst II (ALD) - Health Equity

Los Angeles, CA $77,265.00-$ 3 weeks ago
Senior Analyst, Disputes & eDiscovery - (Hybrid)

We’re unlocking community knowledge in a new way. Experts add insights directly into each article, started with the help of AI.
#J-18808-Ljbffr",2025-07-17T00:00:00.000Z,2025-07-25,"['3+ years in a Data Analyst or Product Analyst role, preferably in logistics, supply chain, transportation, or tech', 'Proficient in SQL for complex data exploration and transformation', 'Hands-on experience with dbt for building modular, version-controlled data pipelines', 'Strong experience using Sigma Computing to build and manage dashboards', 'Demonstrated ability to turn ambiguous problems into clear analytical questions and actionable insights', 'Deep understanding of how product features and operational processes impact performance', 'Excellent communication skills with the ability to translate data into stories for both technical and non-technical audiences', 'Applicants must be currently authorized to work in the US on a full-time basis now and in the future', 'IT Business Analyst - Data Analysis & Reporting Business Data Analyst - Ambulatory Admin - Full Time 8 Hour Days (Exempt) (Non-Union)', 'Senior Level Data Analyst / Shipping Logistics / Sigma Computing / SQL / dbt Business Intelligence Analyst, Trust & Safety - USDS', 'Senior Level Data Analyst / Shipping Logistics / Sigma Computing / SQL / dbt']","['This role is ideal for someone who thrives on uncovering insights that shape product direction, inform operations, and enhance customer experience', 'You will be instrumental in converting complex logistics data into clear, actionable recommendations, enabling better decisions across product, operations, and business strategy', 'What You Will Be Doing Tech Breakdown', '100% Data Analyst (SQL, dbt, Sigma Computing, and Snowflake)', 'Collaborate cross-functionally with Product, Operations, and Engineering teams to identify key business questions and deliver data-driven insights', 'Analyze logistics and operational data to evaluate performance, identify inefficiencies, and recommend improvements', 'Design, build, and maintain robust data models using dbt to enable scalable, trusted analytics', 'Write advanced SQL queries to explore trends in real-time shipment data, driver behavior, and port performance', 'Create dynamic dashboards and visualizations in Sigma Computing to communicate findings and monitor KPIs across the organization', 'Partner with product managers to design experiments, evaluate feature performance, and support roadmap planning with data', 'Proactively surface insights that help the business optimize throughput, reduce dwell time, and improve service reliability']",True,[],,"['SQL', 'dbt', 'Sigma Computing', 'Data Modeling', 'Data Exploration', 'Business Intelligence Dashboards', 'Experiment Design', 'Data-Driven Insights', 'Snowflake']","SQL: Used for complex data exploration and transformation to analyze logistics and operational data.; dbt: Employed to design, build, and maintain modular, version-controlled data pipelines and robust data models for scalable analytics.; Sigma Computing: Utilized to build and manage dynamic dashboards and visualizations for communicating findings and monitoring KPIs.; Data Modeling: Creating robust data models with dbt to enable trusted and scalable analytics in logistics and supply chain contexts.; Data Exploration: Performing advanced SQL queries to explore trends in shipment data, driver behavior, and port performance.; Business Intelligence Dashboards: Developing dashboards in Sigma Computing to provide actionable insights for product, operations, and business strategy.; Experiment Design: Partnering with product managers to design experiments and evaluate feature performance using data.; Data-Driven Insights: Delivering insights from logistics and operational data to inform decisions and optimize business processes.; Snowflake: Used as the data warehouse platform supporting data storage and querying for analytics."
